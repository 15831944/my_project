[{"content":"linux内核中的dup系统调用 内核版本：2.6.14 嵌入式开发交流群：289195589，欢迎加入！ dup系统调用的服务例程为sys_dup函数，定义在fs/fcntl.c中。sys_dup()的代码也许称得上是最简单的之一了，但是就是这么一个简单的系统调用，却成就了linux系统最著名的一个特性：输入/输出重定向。sys_dup()的主要工作就是用来“复制”一个打开的文件号，并使两个文件号都指向同一个文件，下面我们来分析一下它的代码。 1.sys_dup源码分析 asmlinkage long sys_dup(unsigned int fildes)//sys_dup函数的参数，即fildes，是文件描述符fd{\tint ret = -EBADF;\tstruct file * file = fget(fildes);//通过文件描述符找到对应的文件\tif (file)\t\tret = dupfd(file, 0);//分配一个新的文件描述符fd，并将fd和file联系起来\treturn ret;} 1.1fget(fildes) struct file fastcall *fget(unsigned int fd){\tstruct file *file;\tstruct files_struct *files = current->files;//获得当前进程的打开文件表\trcu_read_lock();\tfile = fcheck_files(files, fd);//根据fd从打开文件表files里取出相应的file结构变量\tif (file) {\t\tif (!rcuref_inc_lf(&file->f_count)) {  //增加引用\t\t\t/* File object ref couldn't be taken */\t\t\trcu_read_unlock();\t\t\treturn NULL;\t\t}\t}\trcu_read_unlock();\treturn file;}static inline struct file * fcheck_files(struct files_struct *files, unsigned int fd){\tstruct file * file = NULL;\tstruct fdtable *fdt = files_fdtable(files);\tif (fd < fdt->max_fds)\t\tfile = rcu_dereference(fdt->fd[fd]);\treturn file;} 1.2dupfd(file, 0) static int dupfd(struct file *file, unsigned int start){\tstruct files_struct * files = current->files;\tstruct fdtable *fdt;\tint fd;\tspin_lock(&files->file_lock);\tfd = locate_fd(files, file, start);//分配文件描述符\tif (fd >= 0) {\t\t/* locate_fd() may have expanded fdtable, load the ptr */\t\tfdt = files_fdtable(files);//获得文件描述符表\t\tFD_SET(fd, fdt->open_fds);//设置打开文件标记\t\tFD_CLR(fd, fdt->close_on_exec);\t\tspin_unlock(&files->file_lock);\t\tfd_install(fd, file);//建立fd和file的联系，之后通过fd就可以找到file\t} else {\t\tspin_unlock(&files->file_lock);\t\tfput(file);\t}\treturn fd;} 2.内核初始化中的相关源码分析 static int init(void * unused){\t...\tif (sys_open((const char __user *) \"/dev/console\", O_RDWR, 0) < 0)\t\tprintk(KERN_WARNING \"Warning: unable to open an initial console.\\n\");\t//打开控制台，这样init进程就拥有一个控制台，并可以从中读取输入信息，也可以向其中写入信息\t(void) sys_dup(0);//调用dup打开/dev/console文件描述符两次，这样控制太设备也可以供表述输出和标准错误使用(文件描述符为1和2)\t(void) sys_dup(0);\t//假设sys_open((const char __user *) \"/dev/console\", O_RDWR, 0) 成功执行，init进程就拥有3个文件描述符(标准输入、标准输出和标准错误)\t...} 3.系统重定向 我们通过一个简单的来讲解重定向。 当我们在shell下输入如下命令：“echo hello!”，这条命令要求shell进程执行一个可执行文件echo，参数为“hello!”。当shell接收到命令之后，先找到bin/echo，然后fork()出一个子进程让他执行bin/echo，并将参数传递给它，而这个进程从shell继承了三个标准文件，即标准输入（stdin），标准输出（stdout）和标准出错信息（stderr），它们三个的文件号分别为0、1、2。而至于echo进程的工作很简单，就是将参数“hello!”写道标准输出文件中去，通常都是我们的显示器上。但是如果我们将命令改成“echo hello! > foo”，则在执行时输出将会被重定向到磁盘文件foo中。我们假定在此之前该shell进程只有三个标准文件打开，文件号分别为0、1、2，以上命令行将按如下序列执行： (1) 打开或创建磁盘文件foo，如果foo中原来有内容，则清除原来内容，其文件号为3。 (2) 通过dup()复制文件stdout，即将文件号1出的file结构指针复制到文件号4处，目的是将stdout的file指针暂时保存一下 (3) 关闭stdout，即1号文件，但是由于4号文件对stdout也同时有个引用，所以stdout文件并未真正关闭，只是腾出1号文件号位置。 (4) 通过dup()，复制3号文件（即磁盘文件foo），由于1号文件关闭，其位置空缺，故3号文件被复制到1号，即进程中原来指向stdout的指针指向了foo。 (5) 通过系统调用fork()和exec()创建子进程并执行echo，子进程在执行echo前夕关闭3号和4号文件，只留下0、1、2三个文件，请注意，这时的1号文件已经不是stdout而是磁盘文件foo了。当echo想向stdout文件写入“hello!”时自然就写入到了foo中。 (6) 回到shell后，关闭指向foo的1号与3号文件，再用dup()和close()将2号恢复至stdout，这样shell就恢复了0、1、2三个标准输入/输出文件。 由此可见，当echo程序（或其他）在运行的时候并不知道stdout（对于stdin和stderr同样）指向什么，进程与实际输出文件或设备的结合是在运行时由其父进程“包办”的。这样就简化了子进程的程序设计，因为在设计时只要跟三个逻辑上存在的文件打交道就可以了，类似于面向对象中的多态和重载。","title":"linux内核中的dup系统调用"},{"content":"linux内核中的fastcall和asmlinkage宏 内核版本：2.6.14 嵌入式开发交流群：289195589，欢迎加入！ 在linux内核中我们都会经常见到FASTCALL和armlinkage，它们各有什么不同呢？下面我们来具体分析一下。 在标准C系中函数的形参在实际传入参数的时候会涉及到参数存放的问题，那么这些参数存放在哪里呢？对x86比较了解的话，应该知道这些函数参数和函数内部局部变量一起被分配到了函数的局部堆栈中。linux操作系统支持多种CPU架构，比如x86、ppc和arm等，在不同的处理器结构上不能保证都是通过 局部栈传递参数的。ARM对函数调用过程中的传参定义了一套规则，即 ATPCS，规则中明确指出ARM中R0-R4都是作为通用寄存器使用，在函数调用时处理器从R0-R4中获取参数，在函数返回时再 将需要返回的参数一次存到R0-R4中，也就是说可以将函数参数直接存放在寄存器中，所以为了严格区别函数参数的存放位置，引入了两个标记，即 asmlinkage和FASTCALL，前者表示将函数参数存放在局部栈中,后者则是通知编译器将函数参数用寄存器保存起来。 1.x86平台 #define asmlinkage CPP_ASMLINKAGE __attribute__((regparm(0)))#define FASTCALL(x)\tx __attribute__((regparm(3)))#define fastcall\t__attribute__((regparm(3))) 函数定义前加宏asmlinkage，表示这些函数通过堆栈而不是通过寄存器传递参数。gcc编译器在汇编过程中调用c语言函数时传递参数有两种方法：一种是通过堆栈，另一种是通过寄存器。缺省时采用寄存器，假如你要在你的汇编过程中调用c语言函数，并且想通过堆栈传递参数，你定义的c函数时要在函数前加上宏asmlinkage。 其中 __attribute__是关键字，是gcc的c语言扩展。__attribute__机制是GNU C的一大特色，它可以设置函数属性、变量属性和类型属性等。可以通过它们向编译器提供更多数据，帮助编译器执行优化等。 __attribute__((regparm(0)))：告诉gcc编译器该函数不需要通过任何寄存器来传递参数，参数只是通过堆栈来传递。 __attribute__((regparm(3)))：告诉gcc编译器这个函数可以通过寄存器传递多达3个的参数，这3个寄存器依次为EAX、EDX 和 ECX。更多的参数才通过堆栈传递。这样可以减少一些入栈出栈操作，因此调用比较快。 asmlinkage大都用在系统调用中。有一些情况下是需要明确的告诉编译器，我们是使用stack来传递参数的，比如x86中的系统调用，是先将参数压入stack以后调用sys_*函数的，所以所有的sys_*函数都有asmlinkage来告诉编译器不要使用寄存器来编译。 2.arm平台 对于arm处理器的<asm/linkage.h>，没有定义FASTCALL和armlinkage，所以没有意义（对于ARM平台来说，要符合ATPCS过程调用标准，即通过寄存器传递的。ARM中R0-R4用于存放传入参数，所有函数的参数不应该大于5个，如果超过5个，多余的参数被存放到局部栈中。）。  #ifndef FASTCALL#define FASTCALL(x)\tx#define fastcall#endif#ifndef asmlinkage#define asmlinkage CPP_ASMLINKAGE#endif 3.CPP_ASMLINKAGE #ifdef __cplusplus#define CPP_ASMLINKAGE extern \"C\"#else#define CPP_ASMLINKAGE#endif extern \"C\" 包含双重含义，从字面上即可得到：首先，被它修饰的目标是“extern”的；其次，被它修饰的目标是“C”的。 　　（1） 被extern \"C\"限定的函数或变量是extern类型的extern是C/C++语言中表明函数和全局变量作用范围（可见性）的关键字，该关键字告诉编译器，其声明的函数和变量可以在本模块或其它模块中使用。与extern对应的关键字是static，被它修饰的全局变量和函数只能在本模块中使用。因此，一个函数或变量只可能被本模块使用时，其不可能被extern “C”修饰。 　　（2） 被extern \"C\"修饰的变量和函数是按照C语言方式编译和连接的。","title":"linux内核中的fastcall和asmlinkage宏"},{"content":"在执行shell脚本的时候，shell将会对脚本中的行进行解释，然后执行；对于一些特殊处理的句子，我们可以使用引号或者反斜线来避免shell解释执行之。如下，当在命令行中输入：echo *child.sh env_variable father.sh param.sh profile.sh 125017.sh默认会将当前文件夹下的所有文件都打印出来，但我们需要的是输出一个“*”。可以以这样的方式让shell不去解释星号(*):echo \"*\"*下面是shell引用类型------------------------------\"\"\t双引号''\t单引号`\t反引号\\\t反斜线------------------------------1.双引号使用双引号，可引用除了字符$、`、\\外的任意字符或字符串。例如：STR=\"MX2 is better than MI2\"echo \"$STR\"MX2 is better than MI2也可以去掉双引号：echo $STRMX2 is better than MI2双引号可以使具有特殊含义的词失去其原本的意义，如下：cal       December 2012Sun Mon Tue Wed Thu Fri Sat                         1 2   3   4   5   6   7   8 9  10  11  12  13  14  1516  17  18  19  20  21  2223  24  25  26  27  28  2930  31但是，当我们将cal命令赋给一个变量，如下：CALENDAR=\"cal\"echo $CALENDARcal这里，双引号是cal命令失去了原有的显示日历的功能；这里双引号类似于转义字符。比如DB2中，我们要将这样的字符串（'1','2'）添加到表的一个字段中，那么我们将怎么写呢？db2 => select '1','2' from sysibm.sysdummy11 2- -1 2从这里看到，db2将'1','2'认为是2个字符串，这是因为单引号在数据库中有着特殊的含义。我们要将其转义，然后才可以添加到表中，这个起着转义字符呢就是单引号(')，如下：db2 => select ''1','2'' from sysibm.sysdummy1SQL0104N  在 \"select ''\" 后面找到异常标记\"1','2''\"。预期标记可能包括：\"<space>\"。  SQLSTATE=42601这里除了第一个单引号和最后一个单引号对应之外，其余的都未进行转义，所以报错，下面是正确的写法：db2 => select '''1'',''2''' from sysibm.sysdummy11-------'1','2'在DB2 400上也是同样的写法：select '''1'',''2''' from qsys2/qsqptabl ....+....1....                  Constant value                     '1','2'                      ********  End of data  ******** 如果在字符才中有双引号的话，可以使用反斜杠\"\\\"来进行转义，如下：STR=\"\\\"LENOVO\"echo \"my PC is made by $STR\"my PC is made by \"LENOVO如果将$符号转义了，那么STR变量将失去意义：echo \"my PC is made by \\$STR\"my PC is made by $STR2.单引号单引号与双引号类似，不同的是shell会忽略任何引用值，即屏蔽的单引号内的特殊字符的原本含义。如：echo  ‘my name is  $LOGNAME’其结果为：my name is $LOGNAME3.单引号和双引号的区别单引号‘’：取消除单引号以外的任何字符的特殊含义。如：echo  ‘my name is  $name’其结果为：my name is $name，此时$只作为一个普通字符使用了。 双引号“”：取消除双引号、$号以及_号以外的所有字符的特殊含义单引号是强引用，引号里的值是什么，变量的值就是什么；双引号是弱引用，引号里的值若再包含变量，那在赋值的时候，所有这些变量就被立即替换了。例如：echo \"who am i:$LOGNAME\"\t结果：who am i:yeexun\t\techo \"who am i:'$LOGNAME'\"\t结果：who am i:'yeexun'\t\techo \"who am i:\"$LOGNAME\"\"\t结果：who am i:yeexun\t\techo 'who am i:$LOGNAME'\t结果：who am i:$LOGNAME\techo 'who am i:\"$LOGNAME\"'\t结果：who am i:\"$LOGNAME\"\techo 'who am i:'$LOGNAME''\t结果：who am i:yeexun\t\t4.反引号反引号（`）用于设置系统命令输出到变量，shell认为反引号中的内容是一个系统命令，所以将会执行之：echo `date`Mon Dec 24 16:06:55 CST 2012这和直接输入date命令是一样的：dateMon Dec 24 16:07:12 CST 2012若输入一个非系统命令，则shell不认识此命令，将会报错：echo `DATE`ksh: DATE:  not found关于date命令，参照：http://blog.csdn.net/bobo12082119/article/details/84268315.反斜杠反斜杠起的作用是将一些特殊字符按原样输出，这些特殊字符有：$、*、`、+、^、&、|、\"、?。例如：echo *将当前目录下的文件名和目录名都列出来。echo \\**而使用反斜杠转义之后，就输出了星号。","title":"Unix Shell中单引号、双引号字符、反斜杠、反引号的使用"},{"content":"test命令，测试字符串，文件状态，数字等是否符合我们的需要。test命令适用于对文件、字符串、数字的检测。对于测试输出结果，可以使用$?检测，0表示返回正确，1表示返回错误。test命令格式：test condition 或[ condition ]一、下面是测试文件的状态表------------------------------d\t目录-f\t正规文件-L\t符号链接-r\t可读-s\t文件长度大于0、非空-w\t可写-u\t文件有suid位设置-x\t可执行-----------------------------检查文件week.txt，是否可写，和执行。ls -l week.txt-rw-r--r--   1 b4nx     group         94 Dec 11 10:14 week.txt1.检查是否具有写的权限：[ -w week.txt ] 或 test -w week.txtecho $?02.检查是否具有可执行权限：[ -x week.txt ] 或 test -x week.txtecho $?1文件不可执行。3.检查可读权限：test -r iplist.txtecho $?04.检查文件是否为空：ls -l file.null-rw-r--r--   1 b4nx     group          0 Dec 28 08:38 file.nulltest -s file.nullecho $?11表示否，文件为空或长度为05.检查文件是否为连接文件：ln ../awk/data.f ldatals -l data.f-rw-r--r--   2 b4nx     group        356 Nov 16 19:50 data.f创建的是link文件，怎么这里显示的是普通文件呢？原来创建文件时少写了参数：-srm -r ldataln -s ../awk/data.f ldatals -l ldatalrwxrwxrwx   1 b4nx     group         13 Dec 28 08:58 ldata -> ../awk/data.f查看是否为link文件：[ -L ldata ]echo $?0week.txt文件未普通文件，所以检查是返回1：test -L week.txtecho $?1ls -l week.txt-rw-r--r--   1 b4nx     group         94 Dec 11 10:14 week.txt6.检测目录[ -d other ]echo $?0cd otherpwd***/other使用逻辑操作符-a：逻辑与，一假则假-o：逻辑或，一真则真1.查看2个文件是否都可写[ -w video.txt -a -w video2.txt ]echo $?0ls -l video*-rw-r--r--   1 b4nx     group        195 Dec 10 18:47 video.txt-rw-r--r--   1 b4nx     group        195 Dec 11 09:02 video2.txt查看2个文件是否都为link文件：[ -L video.txt -o -L video2.txt ]echo $?1二、字符串检测，有5种格式：1.test \"str\"2.test operator \"str\"3.test \"str\" operator \"str\"4.[ operator str ]5.[ str operator str ]operator有如下几种：=  ：两字符串相等!= ：两字符串不等-z ：空串-n ：非空串1.等于操作符STR1=\"echo\"STR2=\"echo1\"[ $STR1 = $STR2 ]echo $?1[ \"a\" = \"a\" ]echo $?02.不等于操作符[ $STR1 != $STR2 ]echo $?03.检查是否为空串，或者字符串是否存在[ -z $STR5 ]echo $?1STR5实际不存在，所以结果为1。4.检查非空字符串[ -n $STR1 ]echo $?0三、数值检测：判断2个数字的大小关系，格式：\"num1\" operator \"num2\"[ \"num1\" operator \"num2\"]operator类似数学操作符：-eq：数值相等-ne：数值不等-gt：num1大于num2-lt：num1小于num2-le：num1小于等于num2-ge：num1大于等于num21.两个数字是否相等[ \"304\" -eq \"304\" ]echo $?0[ \"304\" -ne \"304\" ]echo $?12.数值间大小关系NUM1=500[ $NUM1 -gt \"230\" ]echo $?0[ $NUM1 -le \"500\" ]echo $?0[ $NUM1 -lt \"500\" ]echo $?13.多个判断[ $NUM1 -gt \"400\" -a $NUM1 -lt \"1000\" ]echo $?0注意：一个操作符连接的判断要写在一对方括号中。[ $NUM1 -gt \"400\" ] -a [ $NUM1 -lt \"1000\" ]","title":"AIX下test命令简介及使用"},{"content":"1.linux的特点： 优点： （1）免费的、开源的 （2）支持多线程的（并发），多用户的 （3）安全性好 （4）对内存和文件管理优越。 缺点： 操作相对困难 2.linux最小只需要4M内存-》嵌入式开发 3.1973年unix出现了：（源码公开）   unix有以下几种：IBM的aix，sun的solaris，hp unix ,bsd (伯克利分校) 4.unix的精简版 minix，后来为了解决把minix移植到pc，1991-》1994（1.0）linux 5.学习过程中，使用VM[虚拟机]，安装red hat linux（2.4.20-8） 6.linux操作系统：redhat，suse，红旗linux 7.linux常用命令：  （1）startx:显示图形界面  （2）shutdown -h now ：立刻进行关机（halt）  （3）shutdown -r now ：重启  （4）reboot          ：重启  （5）logout          ：注销  （6）su -            ：用户切换 8.尽量少用root帐号登录，因为root权限过高，可以用普通用户，然后用su - 切换到root 用户 9.linux环境下，用vi编辑器开发 Hello.java ： 开发步骤： 1.vi Hello.java 2.输入i 【进入插入模式】 3.输入esc【进入命令模式】 4.输入:  [wq 表示退出保存  q！退出不保存]  【ls -l 列表显示当前目录】 5.javac Hello.java [编译] 6.java Hello [运行] 10.linux环境下开发c程序 1.gcc -v[显示gcc 路径 信息] 2.编译 gcc Hello.cpp  [自定义编译生成文件的名字 gcc -0 myname Hello.cpp] 3.运行./a.out  ","title":"linux学习笔记1"},{"content":"       ㈠ 内核简介           职责：               ① 系统初始化：检查硬件资源并引导系统               ② 进程调度：决定进程的启动及运行时间               ③ 内存管理：为运行的进程分配内存               ④ 安全：校验系统权限、selinux、iptables策略               ⑤ 提供缓存           版本：               ① 常规：一个或多个处理器，但RAM只能是4G或者小于4G               ② PAE：多处理器，且可支持高达64G RAM               ③ XEN：虚拟化所需           内核总是安装在/boot/vmlinuz-*           内核源码可到www.kernel.org网上下载                   ㈡ 内核模块           使用模块的几个理由：               ① 减少内存使用：不需要的驱动程序不会占用内存               ② 灵活性：模块可在系统安装后添加，这些模块通常被称为第三方驱动程序               ③ 最大化运行时间：模块可在不重启的状态下无限次装载和卸载           在引导时需要的动态模块可用grub装入initrd（初始化内存盘）,其他模块可在稍后根据需要装载           这些模块位于/lib/modules/$(uname -r)/目录下                     内核模块工具：           --modprobe：可装载或者卸载模块           装载：[root@Think ~]# modprobe usb_storage           卸载：[root@Think ~]# modprobe -r usb_storage                 模块只有在没有使用的前提下才可以被删除                           --lsmod：列出所有已装载模块的列表、相应的大小及使用量 [root@Think ~]# lsmodModule                  Size  Used bynetloop                10817  0 [permanent]netbk                  80065  0 [permanent]blktap                120485  2 [permanent]blkbk                  24289  0 [permanent]ip6table_filter         6849  0 ip6_tables             18181  1 ip6table_filteript_MASQUERADE          7617  3 iptable_nat            10949  1           --modinfo：显示任意可用模块的信息 [root@Think ~]# modinfo ext3filename:       /lib/modules/2.6.18-308.el5xen/kernel/fs/ext3/ext3.kolicense:        GPLdescription:    Second Extended Filesystem with journaling extensionsauthor:         Remy Card, Stephen Tweedie, Andrew Morton, Andreas Dilger, Theodore Ts'o and otherssrcversion:     26DC008FC415305C5F65313depends:        jbdvermagic:       2.6.18-308.el5xen SMP mod_unload 686 REGPARM 4KSTACKS gcc-4.1module_sig:     883f3504f232fc6dc995cc0b59af121112e44a0a0b5f8ae8f7e90b5a613c37cfc50808c464f9a6d0a0a86a45e9d5fe9b7f9f4ed65957f3ce291b12fd           --/etc/modprobe.conf 配置文件包含适用于装载在系统中的常用模块设置，需要时可另行添加 [root@Think ~]# cat /etc/modprobe.confalias eth0 vmxnetalias scsi_hostadapter mptbasealias scsi_hostadapter1 mptspialias scsi_hostadapter2 ata_piixalias snd-card-0 snd-ens1371options snd-card-0 index=0options snd-ens1371 index=0remove snd-ens1371 { /usr/sbin/alsactl store 0 >/dev/null 2>&1 || : ; }; /sbin/modprobe -r --ignore-remove snd-ens1371        ㈢ 管理initrd image           initrd提供在引导初期要装载的模块           这些模块通常和存储设备及文件系统有关，但也支持其它特性和硬件外设           文件位于/boot/initrd-$(uname -r).img           有时会由于某种原因添加额外的模块：           mkinitrd --with=Module_name /boot/initrd-$(uname -r).img $(uname -r)                  ㈣ 通过/dev访问驱动程序           /dev目录下的文件可用来访问驱动程序           我们可以从这些文件读取或写入数据：           例如：           读取：cat /dev/ttyS0           写入：echo “message” > /dev/ttyS0           这些文件可分两类：           ① 块设备：处理数据存储，使用缓冲              如：              /dev/hda ：IDE硬盘              /dev/sda：SATA硬盘                        ② 字符设备：适用于数据流，不适用缓冲              最常用的字符设备是终端 [root@Think ~]# who am iroot     pts/2        2012-12-31 20:42 (:0.0)              /dev/tty[0-6]:虚拟控制台              /dev/null              /dev/random [root@Think boot]# ll /dev/nullcrw-rw-rw- 1 root root 1, 3 12-31 14:03 /dev/null           “c”代表字符设备         “b”代表块设备           1,3：代表主号码为1，副号码为3           主号码确定访问哪个驱动程序           副号码可以让驱动程序区别相识的物理设备          ㈤ 用udev管理/dev           Linux有个文化叫：设备即文件           udev可管理保存在/dev/目录下的文件           udev在插入或者拔出相应的设备时，可随时生成和删除文件           而且还允许系统管理员添加规则，以便修改/dev中默认的名称和权限，规则在/etc/udev/rules.d/目录下                   ㈥ 在/dev中添加文件           永久性：           ① 先在/etc/udev/rules.d/中创建新文件           ② 然后插入如下说明：              KERNEL==\"sda\",NAME=\"usbkey\",SYMLINK=\"usbstorage\"              这可令下次插入/dev/sda时生成一个名为usbkey的设备文件和一个名为usbstorage的符号链接           临时性：              mknod /dev/usbdevice  b 8 0                      ㈦ 用/proc进行内核配置           /proc是一个虚拟文件系统（文件没有保存到硬盘上，重新引导后修改会被重新初始化）           用来显示进程信息、内存资源、硬件设备等           使用strings命令浏览效果会比较好           一些有趣的/proc条目           只读：               /proc/<PID>：正在运行的进程的信息               /proc/cpuinfo：处理器信息               /proc/meminfo：主内存使用               /proc/swaps：交换分区使用               /proc/modules：动态装载的模块               /proc/mounts：挂载的文件系统               /proc/net：网络活性和配置               /proc/version： 内核版本           读写：               /proc/sys/kernel/hostname               /proc/sys/net/ipv4/ip_forward :IP转发（开或者关）               /proc/sys/vm/drop_caches：强制内核从缓存释放一些内存               /proc/sys/vm/swappiness：显示将内存转换到转换设备的积极程度                       ㈧ sysctl：浏览和设定内核参数           显示所有参数及其值           sysctl -a           临时设定：           sysctl -w net.ipv4.tcp_syncookies=1           永久性设定：           /etc/sysctl.conf添加参数           操作完成后：                     sysctl -p           可使新的配置文件与内核同步                   ㈨ 一些练习           ① 关闭ping相应 [root@Think ~]# cat /proc/sys/net/ipv4/icmp_echo_ignore_all 0[root@Think ~]# echo 1 > /proc/sys/net/ipv4/icmp_echo_ignore_all[root@Think ~]# cat /proc/sys/net/ipv4/icmp_echo_ignore_all 1[root@Think ~]# ping 192.168.1.107PING 192.168.1.107 (192.168.1.107) 56(84) bytes of data.64 bytes from 192.168.1.107: icmp_seq=1 ttl=128 time=0.674 ms64 bytes from 192.168.1.107: icmp_seq=2 ttl=128 time=0.598 ms64 bytes from 192.168.1.107: icmp_seq=3 ttl=128 time=0.659 ms--- 192.168.1.107 ping statistics ---3 packets transmitted, 3 received, 0% packet loss, time 2001msrtt min/avg/max/mdev = 0.598/0.643/0.674/0.044 ms      但是：C:\\Users\\asus>ping 192.168.1.115正在 Ping 192.168.1.115 具有 32 字节的数据:请求超时。请求超时。请求超时。请求超时。192.168.1.115 的 Ping 统计信息:    数据包: 已发送 = 4，已接收 = 0，丢失 = 4 (100% 丢失)，      对/proc虚拟文件系统的改动是暂时的，如果你想永久性更该可参考上面  ","title":"Linux 内核服务学习笔记"},{"content":"文件标识符是从0开始到9结束的整数，指明了与进程相关的特定数据流的源。默认情况下始终有3个“文件描述符”处于打开状态，0、1、2分别为stdin、stdout、stderr。 重定向描述符有以下用法：   : >filename 把文件filename截断为0长度；如果文件不存在则创建长度为0的文件。   command 1 > fielname 把标准输出重定向到文件fielname   command 2 > filename 把标准错误重定向到文件fielname   command > filename 2>&1（等价于command & > filename）把标准输出和标准错误一起重定向到文件filename   command >&m 把标准输出重定向到文件描述符m   command <&- 把关闭标准输入   n<&m 将FD为m的输入拷贝到FD为n中   n>&- 关闭FD为n的输出   n<&- 关闭FD为n的输入   n <> filename 为了读写filename，把文件filename打开并且分配文件描述符n给它，如果文件filename不存在则创建它。   备注：猜测&字符所起到的作用是取址，0~9标志了一个文件描述符数组，&m表示取数组下表为m的文件描述符，单独一个&字符表示stdout和stderr。当然这些都只是猜测，是为了更容易理解和记忆重定向的用法。  ","title":"Linux基本命令之重定向"},{"content":" 174总是提示磁盘空间满，于是写个脚本，定时清空那些大问题（〉300M），脚本如下： #!/sbin/sh ####################script begin############################ echo \"######################`date`####################\" find_del() {   LOGDIR=$1   cd $LOGDIR || { echo \"$LOGDIR not exists.\";exit 0 ;}   echo \"list files need to clear...\"   find . -name \"*.log.*\" -size +300000 -exec ls {} \\;            for file in `find . -name \"*.log.*\" -size +300000` ; do  　cat /dev/null > $file  　#echo $file    done    echo \"cleared!!\"            echo \"#####################################################\" } HOMEDIR=/tnms/jrtu cd $HOMEDIR || { echo \"$HOMEDIR not exists.\";exit 0 ;} for dir in `ls -l | grep '^d' | awk '{ print $NF }' | grep 'jrtu\\-[0-9]'` ; do  ##取/tnms/jrtu目录下以　\"jrtu-数字\"　开头的目录名;   if [ -d $dir ] ; then       echo $dir       logdir=\"$dir/logs\"       echo $logdir       find_del $logdir       cd $HOMEDIR || { echo \"$HOMEDIR not exists.\";exit 0 ;} #退回到HOME目录， #因为find_del会改换到jrtu目录下，所以下次循环就得不到下个目录名了！   fi done #####################script end############################ 注： ls -l | grep '^d' | awk '{ print $NF }' | grep 'jrtu\\-[0-9]'　取/tnms/jrtu目录下以　\"jrtu-数字\"　开头的目录名;","title":"清空目录下的日志"},{"content":"1.在进入grub引导界面时，请输入e   在选中第二行 输入e   在最后输入 1 【单用户级别】   vi /etc/inittab 修改级别 2.ls [显示文件和目录]   ls -a 显示隐藏文件   ls -l 列表显示   ls -al 3.建立目录：mkdir 4.删除空目录：rmdir 5.tab键可以自动补全 6.文件复制：cp 文件 目录 7.删除文件和目录：rm 文件  rm -rf  【删除所有内容（包括目录和文件） r递归 f强制】 8.more:分页显示 9.| ：管道命令   把上一个命令的结果交给 | 后面的命令处理 10.在文本中查询内容：grep -n \"查找的内容\" 文件名 11.按照文件名查找文件：find / -name 文件名 12.重定向：>  (把结果保存到一个文件) （覆盖写）            >> (追加写)","title":"linux学习笔记3"},{"content":"HBASE安装部署过程 安装HBASE先决条件 SHH安装，并且有公用ssh无密码跳转账号：admin（机器默认会安装SSH） 在namenode和各个slave上用机器名互相ping，ping不通的话，无法进行 JAVA环境安装（JDK1.6即可兼容HBASE-0.90.3版本） HADOOP环境安装（HADOOP版本为0.20.2完全兼容HBASE-0.90.3版本） 安装路径：/home/admin/deploy/hadoop-0.20.2 安装HBASE 安装HBASE版本为HBASE-0.90.3 安装路径：/home/admin/deploy/ HBASE-0.90.3   核心配置文件 hbaseenv.sh：该文件用来配置hbase所需的特殊环境变量： HBASE环境变量的设置（如果在~/.bash_profile中设置了环境变量，这里可以不进行配置） export JAVA_HOME=/home/admin/deploy/java6 export HADOOP_HOME=/home/admin/deploy/hadoop-0.20.2 expoet HBASE_HOME=/home/admin/deploy/HBASE-0.90.3 JAVA虚拟机性能调优（省略不用修改的内容） export HBASE_MASTER_OPTS=\"-ea-Xmx2048m -Xms1024m -Xmn512m exportHBASE_REGIONSERVER_OPTS=\"-Xmx2048m -Xms1024m -Xmn512m export HBASE_ZOOKEEPER_OPTS=\"-Xmx2048m-Xms1024m -Xmn512m 补充解释：  这里的XMS与XMX指的是JAVA虚拟机内存分配策略中的最大可用内存和最小内存设置。 不建议将XMS与XMX设置成一样。因为java的垃圾回收器在内存使用达到XMS值的时候才会开始回收，如果2个值一样，那么JAVA会在使用完所有内存时才会回收垃圾，导致内存LOAD一直很高。 关于XMN这个参数是JAVA内存机制中的年轻代。 整个JVM内存大小=年轻代大小 + 年老代大小 +持久代大小。 持久代一般固定大小为64m，所以增大年轻代后，将会减小年老代大小。此值对系统性能影响较大，Sun官方推荐配置为整个堆的3/8。这里为了便于计算，取整个堆的一半。 另外：如果JAVA内存设置过小，HBASE启动会报错 Error occurred during initialization of VM       hbase-site.xml：hbase-site. xml配置文件，重要参数如下： <property>   <name>dfs.tmp.dir<\/name>   <value>/home/admin/deploy/hdfs/<\/value>  <\/property> 设置hdfs本地存放路径，与hadoop保持一致即可。 property>    <name>hbase.rootdir<\/name>    <value>hdfs://xxxxxxxxxx:9000/hbase<\/value>    <description>The directory shared by regionservers.<\/description>   <\/property> Hbase根目录地址，启动hadoop配置的路径hdfs://xxxxxxxxxx:9000/后跟hbase即可。 <property>    <name>hbase.tmp.dir<\/name>    <value>/home/admin/deploy/hdfs/hbase<\/value>    <description>Temporary directory on the local filesystem.    <\/description>  Hbase文件存放的本地路径。  <property>    <name>hbase.zookeeper.quorum<\/name>    <value> xxxxxxxxxx <\/value>  <\/property> HBASE集群的zookeeper的地址，本次安装部署为单机部署，所以集群内容只有一个机器。 <property>    <name>hbase.zookeeper.property.dataDir<\/name>    <value>/home/admin/deploy/hdfs/zookeeper<\/value>    <description>Property from ZooKeeper's config zoo.cfg.      The directory where the snapshot is stored.    <\/description>  <\/property> HBASE集群的zookeeper数据存放的地址     配置regionservers： xxxxxxxxxx 添加关联机器地址即可，单机部署只需要Master   启动与停止 启动脚本：start-hbase.sh（直接启动即可）： /home/admin/deploy/hbase-0.90.3-cdh3u1/bin/start-hbase.sh xxxxxxxxxx: starting zookeeper, logging to /home/admin/deploy/hbase-0.90.3-cdh3u1/bin/../logs/hbase-admin-zookeeper-xxxxxxxxxx.out starting master, logging to /home/admin/deploy/hbase-0.90.3-cdh3u1/bin/../logs/hbase-admin-master-xxxxxxxxxx.out xxxxxxxxxx: starting regionserver, logging to /home/admin/deploy/hbase-0.90.3-cdh3u1/bin/../logs/hbase-admin-regionserver-xxxxxxxxxx.out 停止脚本：stop-all.sh（返回内容如下）： stopping hbase.... xxxxxxxxxx: stopping zookeeper.   一些潜规则（权限切换） 在admin账号下使用hbase，需要更改hbase上的目录的权限，此时需要在hbase账号下执行以下两条命令： hadoopfs -chown -R admin:admin / hadoop fs -chown -R hadoop:hadoop /user/hadoop/mapred/system","title":"HBASE安装部署过程"},{"content":"audit子系统提供了一种纪录系统安全方面信息的方法，同时能为系统管理员在用户违反系统安全法则或存在违反的潜在可能时，提供及时的警告信息，这些audit子系统所搜集的信息包括：可被审计的事件名称，事件状态（成功或失败），别的安全相关的信息。 可被审计的事件，通常，这些事件都是定义在系统调用级别的。 脚本/APPS - 命令 - 函数（库） - System Call （系统调用） - 底层Kernel Cat /etc/fstab 命令执行 ltrace cat /etc/fstab 追踪库 Strace cat /etc/fstab 追踪系统调用 [/usr/share/man/man3] #ls -l | wc -l 6489 [/usr/share/man/man2] #ls -l | wc –l 381 明确自己要审计什么？ [root@node1 ~]# service auditd status auditd (pid  2815) is running... [root@node1 ~]# rpm -qf /etc/init.d/auditd  audit-1.7.17-3.el5 [root@node1 ~]# auditctl -s AUDIT_STATUS: enabled=1 flag=1 pid=2815 rate_limit=0 backlog_limit=320 lost=0 backlog=0 enabled=1开启审计 [root@node1 ~]# man auditctl 中的 EXAMPLE auditctl -w /etc/shadow -p wa -w 监控 -p 权限      r=read, w=write,  x=execute,  a=attribute(所属者所属组) auditctl -w /etc/ -p wa   （a是属性） [root@node1 ~]# auditctl -w /tmp/ -p rwxa [root@node1 ~]# auditctl -l LIST_RULES: exit,always dir=/tmp (0x4) perm=rwxa auditctl -l  查看所有 auditctl -D 删除清空 [root@node1 ~]# ls /tmp/ [root@node1 ~]# cat /var/log/audit/audit.log  。。。 。。。 type=SYSCALL msg=audit(1330126454.024:552): arch=40000003 syscall=5 success=yes exit=3 a0=9560868 a1=18800 a2=805e560 a3=9560850 items=1 ppid=11329 pid=13571 auid=0 uid=0 gid=0 euid=0 suid=0 fsuid=0 egid=0 sgid=0 fsgid=0 tty=pts3 ses=66 comm=\"ls\" exe=\"/bin/ls\" key=(null) type=CWD msg=audit(1330126454.024:552):  cwd=\"/root\" type=PATH msg=audit(1330126454.024:552): item=0 name=\"/tmp/\" inode=2031617 dev=fd:00 mode=041777 ouid=0 ogid=0 rdev=00:00  审计搜索 [root@node1 ~]# ausearch -f /tmp/ ---- time->Sat Feb 25 07:34:14 2012 type=PATH msg=audit(1330126454.024:552): item=0 name=\"/tmp/\" inode=2031617 dev=fd:00 mode=041777 ouid=0 ogid=0 rdev=00:00 type=CWD msg=audit(1330126454.024:552):  cwd=\"/root\" type=SYSCALL msg=audit(1330126454.024:552): arch=40000003 syscall=5 success=yes exit=3 a0=9560868 a1=18800 a2=805e560 a3=9560850 items=1 ppid=11329 pid=13571 auid=0 uid=0 gid=0 euid=0 suid=0 fsuid=0 egid=0 sgid=0 fsgid=0 tty=pts3 ses=66 comm=\"ls\" exe=\"/bin/ls\" key=(null) [root@node1 ~]# auditctl -w /etc/shadow -p rwxa -k \"SHADOW\"（-k 关键字） 使用普通用户修改密码 [user1@node1 ~]$ passwd Changing password for user user1. Changing password for user1 (current) UNIX password:  New UNIX password:  Retype new UNIX password:  passwd: all authentication tokens updated successfully. [root@node1 ~]# ausearch -k \"SHADOW\" time->Sat Feb 25 07:47:43 2012 type=PATH msg=audit(1330127263.467:575): item=4 name=\"/etc/shadow\" inode=4949304 dev=fd:00 mode=0100400 ouid=0 ogid=0 rdev=00:00 type=PATH msg=audit(1330127263.467:575): item=3 name=\"/etc/shadow\" inode=4950505 dev=fd:00 mode=0100400 ouid=0 ogid=0 rdev=00:00 type=PATH msg=audit(1330127263.467:575): item=2 name=\"/etc/nshadow\" inode=4949304 dev=fd:00 mode=0100400 ouid=0 ogid=0 rdev=00:00 type=PATH msg=audit(1330127263.467:575): item=1 name=\"/etc/\" inode=4947969 dev=fd:00 mode=040755 ouid=0 ogid=0 rdev=00:00 type=PATH msg=audit(1330127263.467:575): item=0 name=\"/etc/\" inode=4947969 dev=fd:00 mode=040755 ouid=0 ogid=0 rdev=00:00 type=CWD msg=audit(1330127263.467:575):  cwd=\"/home/user1\" type=SYSCALL msg=audit(1330127263.467:575): arch=40000003 syscall=38 success=yes exit=0 a0=d9d317 a1=d9d1d6 a2=d9f5e4 a3=0 items=5 ppid=13633 pid=13661 auid=0 uid=505 gid=505 euid=0 suid=0 fsuid=0 egid=505 sgid=505 fsgid=505 tty=pts7 ses=77 comm=\"passwd\" exe=\"/usr/bin/passwd\" key=\"SHADOW\" auid 初始登录uid [root@node1 ~]# auditctl -l LIST_RULES: exit,always dir=/tmp (0x4) perm=rwxa LIST_RULES: exit,always watch=/etc/shadow perm=rwxa key=SHADOW [root@node1 ~]# auditctl -w /tmp -p rwxa [root@node1 ~]# auditctl -a exit,always -F dir=/tmp/ -F perm=rwxa [root@node1 ~]# auditctl -l LIST_RULES: exit,always dir=/tmp (0x4) perm=rwxa LIST_RULES: exit,always dir=/tmp/ (0x5) perm=rwxa -a exit,always -F 规则字段 always 总是记录审计 none 不记 exit：行为完成后记录审计（一般常用） entry：行为刚开始时记录审计（某些规则要求） auditctl -a exit,always -F auid!=0 -F uid=0 -S all -F 字段 -S syscall all 所有系统调用（行为） audictctl -a exit,always -F auid!=0 -F uid=0 -S all -k \"ALL\" ausearch -k \"ALL\" 工作中常对 /tmp /etc 审计，攻击者常用/tmp提权 aureport --help aureport -h aureport -l （login）","title":"audit 审计"},{"content":"问题描述： CentOS安装完成Tomcat后，访问本地：http://localhost:8080/正确。但局域网内无法访问 原因： /etc/init.d/iptables status Table: filter Chain INPUT (policy ACCEPT) num  target     prot opt source               destination         1    RH-Firewall-1-INPUT  all  --  0.0.0.0/0            0.0.0.0/0           Chain FORWARD (policy ACCEPT) num  target     prot opt source               destination         1    RH-Firewall-1-INPUT  all  --  0.0.0.0/0            0.0.0.0/0           Chain OUTPUT (policy ACCEPT) num  target     prot opt source               destination         Chain RH-Firewall-1-INPUT (2 references) num  target     prot opt source               destination         1    ACCEPT     all  --  0.0.0.0/0            0.0.0.0/0           2    ACCEPT     icmp --  0.0.0.0/0            0.0.0.0/0           icmp type 255 3    ACCEPT     esp  --  0.0.0.0/0            0.0.0.0/0           4    ACCEPT     ah   --  0.0.0.0/0            0.0.0.0/0           5    ACCEPT     udp  --  0.0.0.0/0            224.0.0.251         udp dpt:5353 6    ACCEPT     udp  --  0.0.0.0/0            0.0.0.0/0           udp dpt:631 7    ACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0           tcp dpt:631 8    ACCEPT     all  --  0.0.0.0/0            0.0.0.0/0           state RELATED,ESTABLISHED 9    ACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0           state NEW tcp dpt:22 10   REJECT     all  --  0.0.0.0/0            0.0.0.0/0           reject-with icmp-host-prohibited 会得到一系列信息，说明防火墙开着。 解决： /etc/init.d/iptables stop Flushing firewall rules:                                   [  OK  ] Setting chains to policy ACCEPT: filter                    [  OK  ] Unloading iptables modules:                                [  OK  ] 永久关闭:?chkconfig --level 35 iptables off       参考地址：http://blog.csdn.net/on_my_way20xx/article/details/8165345","title":"CentOS配置Tomcat后，本地可以访问但局域网内无法访问"},{"content":"linux学习笔记4 1.在linux中的每个用户必须属于一个组，不能独立于组外。在linux中，每个文件有所有者，所在组，其他组的概念。 文件的所有者：就是文件的创建者 文件所在组：就是文件创建者所在组 其它组：除开文件的所有者和所在组的用户外，系统的其他用户都是文件的其它组。 ls -ahl 2.添加组：groupadd 组名 3.查看linux中所有组的信息：vi  /etc/group  cat /etc/group | more[只查看不能修改] 4.创建用户，并同时指定该用户所在组 useradd -g 组名 用户名 5.查看linux中所有用户信息: vi /etc/passwd cat /etc/passwd 6.-rw-r--r-- -:文件类型，-表示普通文件 rw-:文件所有者对该文件的权限 r--：文件所在组对该文件的权限 r--：文件其他组用户对该文件的权限 7.文件权限分为3种：r可读 用4表示 w可写 用2表示 x可执行 用1表示 8.如何修改文件的访问权限：chmod 777 文件名 7=4+2+1=r+w+x 所有者 所在组成员 其他组成员 9.who am i :查看当前用户名 10.改变用户所在组： 在root下可以修改用户所在组： usermod -g 组名 用户名","title":"linux学习笔记4"},{"content":"第七章：管理文件系统 ext文件系统 采用称作索引节点的系统来存放虚拟目录中所存储文件的信息 索引节点系统在每个物理设备上创建一个单独的表（索引节点表）来存储这些文件信息 存储在虚拟目录中的每一个文件在索引节点表中都有一个条目。条目名称的扩展部分来自其跟踪每个文件的额外数据，包括 文件名 文件大小 文件的属主 文件的属组 文件的访问权限 指向存有文件数据的每个硬盘块的指针 Linux通过唯一的数值（索引节点号）来引用索引节点表中的每一个索引节点，这个值是创建文件时由文件系统分配的 文件系统通过索引节点号而不是文件全名及路径来标识文件 ext2文件系统 索引节点表为文件增添了创建时间、修改时间、和最后访问时间 将最大文件大小增到2TB（在ext2后期版本中增大到32TB） 改变了文件存储方式，减轻碎片化 文件系统每次存储或更新文件时，它都要用新信息更新索引节点表。如果过程中发生意外，即使文件数据正常的更新到文件系统上但是节点表记录没有完成更新，ext2文件系统甚至不知道那个文件的存在 日志文件系统 会先将文件的修改写入到临时文件（称作journal，日志）中，然后在数据成功写到存储设备和索引节点表之后，再删除对应的日志条目。如果出现意外，系统将在下次读取日志文件并处理上次留下的未写入的数据 三种不同的广泛使用的日志方法 方法 描述 数据模式 索引节点和文件都会被写入日志，丢失数据风险低，但性能差 排序模式 只有索引节点数据会被写入日志，但只有数据成功写入后才删除；性能和安全之间的良好折中 回写模式 只有索引节点数据会被写入日志，但不管文件数据何时写入；丢失数据风险高，但仍比不用日志好 数据模式是目前为止最安全的保护数据方法，但也是最慢的 ext3文件系统 和ext2文件系统相同的索引节点表结构，但给每个存储设备增加了一个日志文件，来将准备写入存储设备的数据先写进日志文件 默认情况下，ext3文件系统用排序模式的日志功能（可以在创建文件系统时修改） 无法恢复误删的文件，没有任何内建的数据压缩功能，不支持加密文件 ext4文件系统 支持数据压缩和加密。支持区段（extent） 区段在存储上按块分配空间，但在索引节点表中只保存起始块的位置。（由于无需列出所有用来存储文件中数据的数据块，它可以在索引节点表中节省一些空间） 整合了块预分配（block preallocation） 可以给一个已知要变大的文件预留空间，为此文件分配所有期望的块。文件系统用0填满预留块，并知道不要将他们分给其他文件 Reiser文件系统 只支持回写日志模式 可以在线调整已有文件系统的大小 采用尾部压缩（tail packing）技术，能将一个文件的数据填进另一个文件的数据块中的空白空间 （此系统的首席开发人员Hans Reiser还在监狱……） JFS文件系统 采用顺序日志方法 采用基于区段的文件分配，除了IBM Linux版本外，很少JFS文件系统很少使用 XFS文件系统 采用回写模式的日志 可以在线调整文件系统大小（只能扩大，不能缩小） 操作文件系统 创建分区 fdisk 必须指定要分区的存储设备的设备名才能启动 如果是第一次给该设备分区，fdisk会警告设备上没有分区表 fdisk命令 命令 描述 a 设置一个标识，说明这个分区是可启动的 b 编辑BSD Unix系统用的磁盘标签 c 设置DOS兼容标识 d 删除分区 l 显示可用的分区类型 m 显示命令选项 n 添加一个新分区 o 创建DOS分区表 p 显示当前分区表 q 退出，不保存更改 s 为Sun Unix系统创建一个新磁盘标签 t 修改分区的系统ID u 改变使用存储单位 v 验证分区表 w 将分区表写入磁盘 x 高级功能 分区可按主分区（primary partition）和扩展分区（extended partition）创建 主分区可以被文件系统格式化，扩展分区只能容纳其他主分区 每个存储设备上只能有4个分区，可以通过创建多个扩展分区然后在扩展分区内创建主分区拉进行扩展 创建文件系统 在将数据保存到这个设备之前，必须用某种文件系统格式化它，每种文件系统类型都有自己的命令行程序格式化分区 工具 用途 mkefs 创建一个ext文件系统 mkefs2 创建一个ext2文件系统 mkfs.ext3 创建一个ext3文件系统 mkfs.ext4 创建一个ext4文件系统 mkreiserfs 创建一个ReiferFS文件系统 jfs_mkfs 创建一个JFS文件系统 mkfs.xfs 创建一个XFS文件系统 所有的文件系统命令都允许通过不带选项的简单命令来创建默认文件系统 $sudo mkfs.ext4 /dev/sdc1 挂载 $sudo mkdir /mnt/testing $sudo mount -t ext4 /dev/sdc1 /mnt/testing 这样只是临时挂载，重启之后不会再次挂载 如果想启动时挂载，可以将文件系统添加到/etc/fstab文件中 如果出错了 fsck命令用来检查和修复任意类型的Linux文件系统 语法： fsck options filesystem 可以在命令行列出多个要检查的文件系统条目 文件系统可以通过设备名、在虚拟目录中的挂载点以及分配给文件系统的唯一UUID值来引用 注意：fsck命令使用/etc/fstab文件来自动决定挂载到系统上的存储设备的文件系统 如果设备通常不挂载，则需使用-t手动指定文件系统类型 选项 描述 -a 如果检查到错误，自动修复文件系统 -A 检查/etc/fstab文件中列出的所有文件系统 -C 给支持进度条功能的文件系统显示一个进度条（只有ext2、ext3） -N 不进行检查，只显示哪些检查会执行 -r 出现错误时提示 -R 使用-A选项时跳过根文件系统 -s 检查多个文件系统时，依次进行检查 -t 指定要检查的文件系统类型 -T 启动时不显示头信息 -V 在检查时产生详细输出 -y 检测到错误时自动修复文件系统 有些命令是重复的，是因为试图为多个命令实现一个共用的前端带来的部分问题 有些文件系统修复命令有一些额外的可用选项 只能在未挂载的文件系统上运行fsck 想在根文件系统上运行fsck，需要用Linux LiveCD启动系统，然后在根文件系统上运行fsck 逻辑卷管理器 可将令一块硬盘上的分区加到已有文件系统，动态的向已有文件系统添加空间 逻辑卷管理布局 硬盘称为物理卷（Physical Volume，PV）（实际上是硬盘上的分区） 多个物理卷元素可以组成卷组（Volume Group，VG）（物理卷元素可分布在多个物理硬盘、多个分区）。卷组方便扩展 逻辑卷管理系统会把卷组当做物理硬盘一样对待 逻辑卷为Linux提供了创建文件系统的分区环境，作用类似Linux中的物理硬盘。Linux系统将逻辑卷当做物理分区对待 可以使用任意一种标准Linux文件系统来格式化逻辑卷 Linux中的LVM 1.快照（snapshot） 最早的Linux LVM允许将一个已有的逻辑卷在逻辑卷在线的状态下复制到另一个设备。此功能叫做快照 快照允许在复制的同时运行关键任务的Web服务器或数据库服务器 LVM1只允许创建只读快照，创建了快照就不能写入了 LVM2允许创建可读写快照。可以删除原先的逻辑卷，将快照作为替代挂载上（对快速故障转移或要修改数据的程序试验非常有用。一旦失败，就要重启系统） 2.条带化（striping） 可跨多个硬盘创建一个逻辑卷 Linux LVM将文件写入逻辑卷时，文件中的数据会被分散到多个硬盘上，每个后继数据块会被写到下一个硬盘上 条带化有助于提高性能。因为这样不用等待单个硬盘移动读写磁头到多个不同位置。这个改进同样适用于读取顺序访问的文件，因为LVM可同时从多个硬盘读取数据 3.镜像 实时更新的逻辑卷一个完整的备份 创建镜像后时，LVM会将原始逻辑卷同步到镜像副本中 一旦原始同步完成，LVM会为文件系统的每次写过程进行两次写过程（主逻辑卷、镜像副本） 使用Linux LVM 1.定义物理卷 将硬盘上的物理分区转换成Linux LVM使用的物理卷区段 sudo pvcreate /dev/sdc1 为PV定义了使用的物理卷 pvdisplay可以显示已创建的物理卷列表 2.创建卷组 从物理卷中创建一个或多个卷组 sudo vgcreate Vol1 /dev/sdc1 使用/dev/sdc1分区上的物理卷创建了一个名为Vol1的卷组 vgdisplay可以显示细节 3.创建逻辑卷 lvcreate用来创建逻辑卷 选项 长选项 描述 -c --chunksize 指定快照逻辑卷的单位大小 -C --contiguous 设置或重置连续分配策略 -i --stripes 指定条带数 -I --stripesize 指定每个条带数的大小 -l --extents 指定分配给新逻辑卷的逻辑块数，或者要用的逻辑块的百分比 -L --size 指定分配给新逻辑卷的硬盘大小   --minor 指定设备的次设备号 -m mirrors 创建设备的镜像数 -M --persistent 让次设备号一直有效 -n --name 指定新逻辑卷的名称 -p --permission 为逻辑卷设置读/写权限 -r --readahead 设置预读扇区数 -R --regionsize 指定镜像逻辑卷 -s --snapshot 创建镜像逻辑卷 -Z --zero 设置在新逻辑卷的前1KB数据为0 sudo lvcreate -l 100%FREE -n lvtest Vol1 lvdisplay用来显示细节 4.创建文件系统 sudo mkfs.ext4 /dev/Vol1lvtest 然后用mount将其挂载 sudo mount /dev/Vol1lvtest test 注意：mkfs.ext4和mount命令中用到的路径是卷组名和逻辑卷名，而不是物理分区路径 5.修改LVM Linux LVM包中共用的命令 命令 功能 vgchange 激活和禁用卷组 vgremove 删除卷组 vgextent 将物理卷加到卷组中 vgreduce 从卷组中删除物理卷 lvexend 增加逻辑卷的大小 lvreduce 减少逻辑卷的大小 注意：手动增加或减小逻辑卷大小时，存储在逻辑卷中的文件系统需要手动修复来处理大小上的改变。大多数文件系统包含重新调整文件系统格式的命令行程序，比如给ext2和ext3文件系统用resize2fs 转贴请保留以下链接 本人blog地址 http://su1216.iteye.com/ http://blog.csdn.net/su1216/","title":"《Linux命令行与shell脚本编程大全》 第七章 学习笔记"},{"content":"1、下面是计算机主要部件的简化视图（如右图） 多数计算机有两种运行模式：内核态和用户态 软件中最基础的部分是操作系统，它运行在内核态。在这个模式，操作系统拥有对所有硬件的完全访问权，可以执行机器能够执行的任何指令 那些会影响机器的控制或可进行I/O（输入/输出）操作的指令，在用户态中的程序里是禁止的 2、Linux或Windows操作系统的源代码有五百万行数量级 3、操作系统：一种运行在内核态的软件 4、批处理系统：指加载在计算机上的一个系统软件，在它的控制下，计算机能够自动地成批处理一个或多个用户的作业 5、多道程序设计：计算机内存中同时存放几道相互独立的程序，但它们在管理程序控制下，相互穿插运行 6、处理器： （1）cpu是从内存中取出指令并执行。在每个cpu基本周期中，首先从内存中取出指令，解码以确定其类型和操作数，接着执行之。然后取指、解码并执行下一条指令。按照这一方式，程序被执行完成 （2）由于用来访问内存以得到指令或数据的时间要比执行指令花费的时间长得多，故所有cpu内部都有用来保存关键变量和临时数据的寄存器 这样，通常在指令集中提供一些指令，用以将一个字从内存调入寄存器，以及将一个字从寄存器存入内存 寄存器： 通用寄存器：保存变量和临时结果 专门寄存器：包括程序计数器（保存将要取出下一条指令的内存地址）、堆栈指针（指向内存中当前栈的顶端）、程序状态字（包含了条件码位（由比较指令设置）、cpu优先级、模式（内核或用户态）以及各种其他控制位） （3）操作系统必须知晓所有的寄存器，每次停止一个运行着的程序时，OS必须保存所有的寄存器，这样稍后该程序被再次运行时，可以把这些寄存器重新载入 （4）现代CPU具有同时取出多条指令的机制（如下图） （5）在用户态，为从操作系统中欧冠获得服务，用户程序必须使用系统调用，系统调用陷入内核并调用操作系统。TRAP指令把用户态切换成内核态，并启用操作系统（计算机使用陷阱而不是一条指令来执行系统调用） 7、存储器 寄存器和cpu相同材料制成，故和cpu一样快，访问它们没有时延 高速缓存：多数由硬件控制。最常用的高速缓存行放置在cpu内部或非常接近cpu的高速缓存中，高速缓存价格昂贵，有些机器有两级或三级高速缓存，每一级比前面的慢且容量大 缓存的作用：多数OS在内存中保留频繁使用的文件（的一部分），以避免从磁盘中重复地调取这些文件 现代cpu中设计了两个缓存，第一级或称为L1缓存总是在cpu中，通常用将已解码的指令调入cpu的执行引擎。对于那些频繁使用的数据字，多数芯片安排有第二个缓存，典型的L1缓存大小为16KB，往往还设计有二级缓存，称为L2缓存，用来存放近来所使用过的若干兆字节的内存字。L1和L2缓存之间的差别在于时序。对L1缓存的访问，不存在任何延时，而对L2缓存的访问，则会延时1或2个时钟周期 8、Intel多核芯片和AMD多核芯片采用的L2缓存的方式是不一样的，如下图 内存：主存RAM（随机访问存储器）、ROM（只读存储器）：用于启动计算机的引导加载模块 同样非易失性的，但可擦除重复的 闪存：数码相机的胶卷、便携式音乐播放器的磁盘 磁盘：比较慢，其随机访问慢是由于磁盘是一种机械装置 许多计算机支持一种虚拟内存机制，这种机制使得期望运行大于物理内存的程序成为可能，其方法是将程序放在磁盘上，而将主存（RAM）作为一种缓存，用来保存最频繁使用的部分程序。这种机制需要快速地映像内存地址，以便把程序生成的地址转换为有关字节在RAM中的物理地址。这种映像由cpu中的一个部件，称存储器管理单元（MMU）来完成 9、I/O设备 I/O设备一般包括两个部分：设备控制器和设备本身。控制器是插在电路板上的一块芯片或一组芯片，这块电路板物理地控制设备。它从OS接受命令。控制器的任务是为OS提供一个简单的接口，每类设备控制器都不同的，故需要不同的软件进行控制。专门与控制器对话，发出命令并接收响应的软件，称为设备驱动程序 总线：计算机中的硬件是使用各种总线实现数据传输和通信的 10、启动计算机","title":"操作系统原理——简单总结"},{"content":"学习这么linux这么长时间了，感觉还是没有深入进去了，今天重新看了一遍linux内存管理机制，将这些零碎的笔记写下来，以后也方便记忆，感觉现在真的是很喜欢linux，嘿嘿～ Linux内存管理的基础知识 内存管理程序提供以下一些功能 1：大地址空间，用户程序使用的内存数量可以超过物理上实际所有的内存数量 2：内存保护，进程的内存是私有的，不能被其他的进程所读取和修改，而且内存管理程序可以防止进程覆盖代码和只读数据 3：内存映射，可以把一个文件映射到虚拟内存区域，并把该文件当作内存来访问 4；对物理内存的公平访问，内存管理程序确保所有的进程都能公平的访问计算机的内存资源，这样可以确保理想的系统性能 5：共享虚拟内存，内存管理程序允许共享他们的一部分 存储空间： 在32为存储系统中，存储空间的地址范围从0*00000000到0*xFFFFFFFF。共4G存储范围 2：内存空间:系统的内存空间特指上面的RAM内存空间 3：内存页：Linux是以页为单位来管理物理内存的，一页大小一般等于4096B。也页容量越大，系统中可能存在的内存碎片越多 进程内存管理 对于任何一个普通文件来讲，都会涉及5种不同的数据段，即代码段，数据段，BBS段，堆和栈 1：代码段，代码段用来存放可执行文件的操作指令，也就是说它是可执行程序在内存中的映像。代码段需要防止在运行时被非法修改，所以只能运行读取操作，不允许写入操作 2：数据段；数据段用来存放可执行文件中已经初始化的全局变量，换句话说就是存放程序的静态分配的变量和全局变量 3：BBS段，BBS段包含了程序中未初始化的全局变量，在内存中BBS全部置零 4：堆（heap）堆用于存放进程中运行中被动态分配的内存段，它的大小并不固定，可以扩张或缩减。当进程调用malloc等函数分配内存时，新分配的内存就被动态的添加到堆上，当利用free函数释放内存时，被释放的内存从堆中删除 5：栈，栈是用户存放程序临时创建的局部变量。由于栈有先进先出的特点，所以特别方便用来保存/恢复调用现场 ～ 进程内存的分配与释放 创建进程fork()，程序载入execve（），映射文件mmap(),动态内存分配malloc（）等进程相关操作都需要分配内存给进程。不过这时进程申请和获得的还不是实际的内存，而是虚拟内存。进程所能直接操作的地址读为虚拟地址，当进程没有获得物理内存时，从内核获得的仅仅是虚拟的内存区域，而不是实际的物理地址，进程没有获得物理内存，获得仅仅是对一个新的线性地址的使用权。实际的物理内存只有当进程真的去访问新获取的虚拟地址时，才会由“请求页机制”产生缺页中断，从而进入分配实际页面的例程。 虚拟空间的管理 内核空间和用户空间 在linux系统中，内核在最高级执行，也称为“系统态”，在这一级可以执行任何操作。而在应用程序则执行在最低级，即所谓的“用户态”。在这一级处理器禁止对硬件的直接访问和对内存的未授权访问。模块是在所谓的“内核空间”中运行的，而应用程序则是在“用户空间运行的”。他们分别应用不同的内存映射，也就是程序代码使用不同的“地址空间”。 模块的作用就是扩展内核的功能，是运行在内核空间的模块化代码。模块的某些函数作为系统调用执行，而某些函数则负责处理中断。各个模块被分别编译并连接成一组目标文件，这些文件能被载入正在运行的内核，或从正在运行的内核中卸载。模块采用的是另一种途径，内核提供一个插槽，它就像一个插件，在需要时，插入内核中使用，不需要从内核中拔出。 内核模块与应用程序存在这区别。应用程序从头到尾完成一个任务，而模块则是为以后处理某些请求而注册自己，完成这个任务后，它的主函数就立即中止了。 天色已晚，要去吃饭了，晚上不让来实验室了，明天接着写完吧～嘎嘎","title":"Linux的进程与内存管理"},{"content":"前言 装了个杀毒软件，没有发现病毒，卸载。又装一杀毒软件，找到数百病毒，机器奇慢无比。于是卸载之。刚卸载完，发现有病毒入侵，与之格斗半日，终于将其歼灭。结果发现好多地方出现了问题，如搜索面板被清空，服务丢失，磁盘管理不能用等等，全是问题。 在工行的保护程序提示更新时竟然发现，installer又不行了。提示：不能访问windows installer。打开服务管理面板，发现该服务已经不再了，如是，想办法恢复（前面刚用SC命令恢复了“Logical Disk Manager Administrative Service” 服务，重启动后竟然成功了）： 恢复步骤 在Windows XP系统下： 第一步：使用记事本编写1.reg文件，内容如下： Windows Registry Editor Version 5.00 [HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\MSIServer] \"ImagePath\"=- \"ImagePath\"=hex(2):25,00,53,00,79,00,73,00,74,00,65,00,6d,00,52,00,6f,00,6f,00,\\ 74,00,25,00,5c,00,53,00,79,00,73,00,74,00,65,00,6d,00,33,00,32,00,5c,00,6d,\\ 00,73,00,69,00,65,00,78,00,65,00,63,00,2e,00,65,00,78,00,65,00,20,00,2f,00,\\ 56,00,00,00  然后将文件保存为“.reg”格式，双击该文件，将文件内容导入注册表。   第二步：点击开始－－>运行，输入CMD命令，在弹出的CMD命令提示符窗口中输入“msiexec /regserver”，然后打开服务管理面板，看Windows Installer 服务是否出现，若出现则说明修复成功。  可能需要重启电脑，若该服务没有启动，要手工启动。","title":"不能访问windows installer解决"},{"content":"1.为什么要学习linux？ （1）性能卓越：linux是一个开源、免费的操作系统，其稳定性、安全性、处理多并发已经得到业界的认可，目前很多中型、大型甚至是巨型项目都在使用linux。          linux操作系统：redhat，suse，fedora，红旗linux，ubuntu。 （2）为了工作：软件公司迫切需要能熟练掌握linux的程序员。          linux系统管理员          linux程序员：linux软件工程师（PC），linux嵌入式开发（单片机，芯片）   2.如何学习linux？    学习流程：    （1）linux平台上的开发，包括Vi，gcc，gdb，make，jdk，tomcat，mysql，和linux基本操作。    （2）加深c语言功底《c专家编程》或是java语言    （3）学习Unix环境高级编程《Unix环境高级编程》     （4）linux应用系统开发、linux嵌入式开发   3.先know how，再know why，“做中学”，适当囫囵吞枣，“琢磨别人怎么做”   4.原理和实践并重   5.学习内容介绍：    基础部分：linux基础知识，linux常用命令80个，linux分区、vi、权限。。。。    实用部分：samba安装与配置，linux网络环境配置，crontab使用，jdk/apache/mysql/ssh/rpm安装与配置    linux下java网络编程，shell初步介绍。   6.推荐书籍：    （1）鸟哥的linux私房菜    （2）linux从入门到精通    （3）linux内核完全剖析                      ","title":"linux学习笔记0"},{"content":"Nagios学习笔记之（一）最初搭建 2012-07-17 13:05:08 标签：linux 监控 nagios cacti 版权声明：原创作品，如需转载，请与作者联系。否则将追究法律责任。 Nagios学习笔记之一最初搭建 一、简介： Nagios是一款开源的免费网络监视工具，能有效监控Windows、Linux和Unix的主机状态，交换机路由器等网络设置，打印机等。在系统或服务状态异常时发出邮件或短信报警第一时间通知网站运维人员，在状态恢复后发出正常的邮件或短信通知。 二、搭建过程： OS： CentOS 5.5 x86_64（最小化即可） Nagios主程序： nagios-cn-3.4.1 Nagios插件： nagios-plugins-1.4.15.tar.gz 2.1安装前： 2.1.1安装依赖包，下载源程序包 1.  #cd /etc/yum.repos.d/   2.  #rm -fr ./*   3.  #wget wget http://mirrors.163.com/.help/CentOS-Base-163.repo   4.  #yum makecache  #删除系统自带的yum源，下载网易的网络源并更新缓存 1.  #yum -y install gcc glibc glibc-common gd gd-devel httpd  #安装必须的依赖包 1.  #wget http://prdownloads.sourceforge.net/sourceforge/nagios/nagios-3.4.1.tar.gz  2.  #wget http://prdownloads.sourceforge.net/sourceforge/nagiosplug/nagios-plugins-1.4.15.tar.gz  #下载nagios主程序以及插件程序 2.1.2正式安装： 1.  #groupadd nagcmd   2.  #useradd -G nagcmd nagios   3.  #usermod -G nagcmd apache  #创建一个用户组名为nagcmd用于从Web接口执行外部命令。将nagios用户和apache用户都加到这个组中。 1.  #tar zxf nagios-3.4.1.tar.gz   2.  #cd nagios   3.  #./configure --prefix=/usr/local/nagios --with-command-group=nagcmd  4.  #解压程序包，并进行预编译前的配置（默认用户就是nagios，所以只需指定组）   5.  #make all                         #编译Nagios程序包源码   6.  #make install                     #安装二进制运行程序   7.  #make install-init                #初始化脚本   8.  #make install-config              #配置文件样本   9.  #make install-commandmode         #设置运行目录权限   10. #make install-webconf             #安装Nagios的WEB配置文件到Apache的conf.d目录下  #htpasswd -c /usr/local/nagios/etc/htpasswd.users nagiosadmin #创建一个nagiosadmin的用户用于登录Nagios的web界面。 #service httpd restart #重启apache使服务生效 1.  #tar zxf nagios-plugins-1.4.15.tar.gz   2.  #cd nagios-plugins-1.4.15   3.  #./configure --prefix=/usr/local/nagios --with-nagios-user=nagios --with-nagios-group=nagios   4.  #make && make install   5.  #编译安装nagios插件  #chkconfig --add nagios #chkconfig nagios on #chkconfig httpd on #添加系统服务并设开机自启 #/usr/local/nagios/bin/nagios -v /usr/local/nagios/etc/nagios.cfg #验证配置文件是否正确，如下图则没问题： #service nagios start #启动服务 #vim /root/.bashrc #添加一条：alias check='/usr/local/nagios/bin/nagios -v /usr/local/nagios/etc/nagios.cfg' #source /root/.bashrc #在以后的配置和调试过程中，经常需要检查配置文件，所以加条别名为了方便 #备注：注意防火墙和Selinux（都关了即可） 输入http://IP/nagios，输入前面设置的用户名密码后，如下图即安装成功。 安装后： 问题1：打开http://ip/nagios，输入口令验证后出现“You don't have permission to access /nagios/ on this server” 解决方法：没装php导致，yum -y install php，装好，重启httpd和nagios   问题2：如果提示“Whoops!   Error: Could not read object configuration data! ”，这是因为没有启动nagios后台进程，执行以下命令 解决方法：/usr/local/nagios/bin/nagios -d /usr/local/nagios/etc/nagios.cfg   问题3：Nagios显示类似错误：HTTP WARNING: HTTP/1.1 403 Forbidden - 5240 bytes in 0.002 second response time。该错误表明在apache web根目录没有index.html文件。 解决方法：在web根目录（如:/var/www/html/目录）建立index.html文件，重启apache和nagios即可。     问题4：安装nagios-plugins，make时出现如下报错： make[2]: *** [check_http.o] Error 1 make[2]: Leaving directory `/mnt/nagios-plugins-1.4.13/plugins' make[1]: *** [all-recursive] Error 1 make[1]: Leaving directory `/mnt/nagios-plugins-1.4.13' make: *** [all] Error 2   解决办法：yum -y install openssl openssl-devel，然后重新执行./configure，再编译安装。 Nagios学习笔记之（二）监控部署 2012-08-02 00:01:38 标签：linux 监控 nagios cacti 原创作品，允许转载，转载时请务必以超链接形式标明文章 原始出处 、作者信息和本声明。否则将追究法律责任。http://xtony.blog.51cto.com/3964396/950826  Nagios学习笔记之（二）监控部署   前言：本篇致力于初涉Nagios的同学，老鸟绕行！   前面已经把最基本的Nagios以及插件安装好了，现在只能对本机进行监控，要想监控远程主机，就必须通过类似于NRPE的软件来实现。 监控端和被监控端都要装nrpe，因为靠此来通信，nrpe是通过ssl来通信的，所以比较安全。 用到ssl就得装相关支持的包：yum -y install openssl openssl-devel 现在开始来安装nrpe： 以下操作在监控端进行： 首先把下载下来的nrpe-2.12.tar解压（自行网上下载） 1.  #tar zxf nrpe.2.12.tar  2.  #cd nrpe-2.12  3.  #./configure   4.  #make all  5.  #make install-plugin  安装完成后会在/usr/local/nagios/libexec/下生成check_nrpe文件 下面定义一个check_nrpe监控命令（默认装好以后没有被nagios调用） 顺带说下监控整体思想： 1.要定义监控的主机或服务 2.执行什么命令来监控 3.出现问题要通知的人 4.采用什么方式通知，邮件|短信    -----后续再细说 修改/usr/local/nagios/etc/commands.cfg（定义命令的文件），添加如下内容：  1.  define command {  2.      command_name    check_nrpe  3.      command_line    $USER1$/check_nrpe -H $HOSTADDRESS$ -c $ARG1$  4.  }  至此监控端暂时完事。   以下操作在被监控端进行： 需要两个文件： nagios-plugins-1.4.15.tar    （nrpe依赖于这个插件） nrpe-2.12.tar                （远程通信）   首先创建安装用户： useradd -s /sbin/nologin nagios 解压安装Nagios插件： 1.  #tar xzf nagios-plugins-1.4.15.tar.gz   2.  #cd nagios-plugins-1.4.15  3.  #./configure --prefix=/usr/local/nagios --with-nagios-user=nagios --with-nagios-group=nagios  4.  #make && make install  解压安装nrpe： 1.  #tar zxf nrpe.2.12.tar  2.  #cd nrpe-2.12  3.  #./configure   4.  #make all  5.  #make install-plugin  6.  #make install-daemon  7.  #make install-daemon-config  8.  #make install-xinetd  安装完毕。 接下来把nrpe交由xinetd来监听（好处：修改nrpe的配置文件不需要重启服务） vim /etc/xinetd.d/nrpe 将only_from = 后面加上监控端的地址 确保/etc/services有nrpe 5666/tcp #NRPE这一行，没有则添加 重启xinetd服务，至此被监控端配置完毕。   接下来测试下连通性，在监控端执行： /usr/local/nagios/libexec/check_nrpe -H 被监控端的地址 如能显示 “NRPE v2.12”，表明NRPE可以和被监控端正常通信。   部署前的工作基本OK了。 下面来说说，服务器上具体是怎么部署监控的。 首先来看下Nagios的目录结构 bin                   #存放执行文件，如nagios，以及后续安装的扩展程序 etc                   #存放配置文件，如nagios.cfg主配文件，平时部署维护操作最多的文件夹 include               #存放引用文件，默认为空 libexec               #存放执行命令，如check_load等，里面有很多命令，需要熟练掌握 sbin                  #存放一些cgi，平时一般不用动 share                 #存放一些网页文件，平时一般不用动 var                   #存放一些产生的数据文件，平时一般不用动 比较重要的就是etc和libexec。 下面说下如何定义一台主机以及主机上的服务： 首先修改：/usr/local/nagios/etc/nagios.cfg 去掉cfg_dir=/usr/local/nagios/etc/servers前面的注释 mkdir //usr/local/nagios/etc/servers 将来新建的主机以及服务都可以存放在这下面，建议把主机和服务写在一个配置文件中，按主机来划分，便于管理。 例如： 要监控一台http服务器 可以在servers下面新建一个以cfg结尾的文件 vim simple-http.cfg 1.  define host{                          #定义一个主机  2.          use linux-server              #引用etc/objects/templates.cfg中的linux-server配置（后续细说）  3.          host_name http                #定义一个主机名，并不是http的实际主机名，任意即可，但要继续，后面要调用  4.          alias http                    #定义一个别名  5.          address 192.168.1.1           #指定地址  6.  }  7.  define service{                       #定义一个服务  8.          use generic-service           #引用etc/objects/templates.cfg中的generic-service配置（后续细说）  9.          host_name http                #引用主机名  10.         service_description CPU Load  #定义监控服务名，就是在web网页上显示的服务名  11.         check_command check_nrpe!check_load  #定义要执行的命令：让check_nrpe调用被监控端的check_load命令执行  12. }                                     #以下类似（备注：每条定义的命令都必须在etc/nrpe.cfg中明确定义）           13. define service{           14.         use generic-service  15.         host_name http  16.         service_description Current Users  17.         check_command check_nrpe!check_users  18. }  19. define service{  20.         use generic-service  21.         host_name http  22.         service_description Disk Free Space /  23.         check_command check_nrpe!check_root  24. }  25. define service{  26.         use generic-service  27.         host_name http  28.         service_description Total Processes  29.         check_command check_nrpe!check_total_procs  30. }  31. define service{  32.         use generic-service  33.         host_name http  34.         service_description Zombie Processes  35.         check_command check_nrpe!check_zombie_procs  36. }  保存以后，check一下，没问题重载nagios的配置文件 service nagios reload 登录网页后就会看见定义监控的项目了。   后续：配置文件详解 Nagios学习笔记之（三）配置详解 2012-08-09 13:33:29 标签：配置 监控 nagios 详解 cfg 版权声明：原创作品，如需转载，请与作者联系。否则将追究法律责任。 Nagios学习笔记之（三）配置详解   前言： 上篇先实现的监控部署，就是想先搭建起来，有点小成就，现在再来看配置文件中的详解。只有把其中配置文件中的联系都理解清楚了，才能方便日后自己自定义的检测。Nagios的配置文件还是有其鲜明的特点的。 网上也有很多零零闪闪的配置讲解，但大多都不够详解，此篇为自己整理，当然也参考了网络上的信息，有配置的解释还有自己的一些备注，可能还有很多不完善的地方，后续会慢慢补充，希望看的人能看懂，还有就是自己以后能看懂，呵呵。 好了，不多说了，开始！   一、目录层次： Nagios以及其插件，安装并配置好了以后，目录层次如下： 1.  bin              #Nagios执行程序所在目录，包括nagios、npc、nrpe等；  2.  etc              #Nagios配置文件位置，重点；  3.  libexec          #Nagios插件目录，里面有具体监控的各种插件，重点；  4.  sbin             #Nagios Cgi文件所在目录，也就是执行外部命令所需文件所在的目录；  5.  share            #Nagios网页文件所在的目录，也就是web页面给我们展示的文件；  6.  include          #Nagioscgi文件的外部调用；  7.  var              #Nagios日志文件、spid 等文件所在的目录。  二、配置文件概览： Nagios所有的配置文件以cfg为结尾，在默认装好以后会在etc/下生成一些，我们来逐个看下：   1.  etc/nagios.cfg         #Nagios主配置文件，所有的cfg文件（外部调用除外）必须都在此文件中引用才能生效；  2.  etc/resource.cfg       #定义$USER1$变量，设置插件路径；  3.  etc/nrpe.cfg           #定义nrpe检测命令的文件，在command中引用；  4.  etc/objects下：  5.      commands.cfg    #定义命令执行的文件，比如check_tcp、check_local_disk等，由后面定义服务的配置文件来引用；  6.      contacts.cfg    #定义联系人的文件，比如服务down了通知的对象；  7.      localhost.cfg   #定义本机的监控条目，默认生成；  8.      printer.cfg     #定义打印机的文件，默认未启用，在生产环境中意义不大；  9.      switch.cfg      #定义监控路由器和交换机的配置文件，默认未启用；  10.     templates.cfg   #定义服务类型的文件，样本文件，比如定义的linux-server就是在此文件中预先定义好；  11.     timeperiods.cfg #定义要监控时间段文件，比如24x7，workhours等；  12.     windows.cfg     #定义监控Windows的文件，默认未启用。      备注：这些文件的名字不是一定的，只要里面的内容正确就可以，Nagios可以自动识别，比如你把commands.cfg和localhost.cfg的文件名互换，都是没有问题的。   三、各配置文件详解：（考虑篇幅，只列举部分） 1.etc/nagios.cfg（主配置文件） 1.  log_file=/usr/local/nagios/var/nagios.log                         2.  # 这个变量用于设定Nagios在何处创建其日志文件。  3.  # OBJECT CONFIGURATION FILE(S)  4.  # 对象的配置文件  5.  # 可以指定单个对象的配置文件, 如下所示：  6.  cfg_file=/usr/local/nagios/etc/objects/commands.cfg    7.  #定义其命令文件  8.  cfg_file=/usr/local/nagios/etc/objects/contacts.cfg        9.  #定义联系人文件  10. cfg_file=/usr/local/nagios/etc/objects/timeperiods.cfg   11. #定义时间段文件  12. cfg_file=/usr/local/nagios/etc/objects/templates.cfg       13. #定义样本文件  14. cfg_file=/usr/local/nagios/etc/objects/localhost.cfg        15. # 定义监测本地（ Linux ）主机  16.   17. #cfg_file=/usr/local/nagios/etc/objects/windows.cfg      18. # 定义监测（ windows ）主机  19.   20. #cfg_file=/usr/local/nagios/etc/objects/switch.cfg          21. # 定义监测路由器或交换机  22.    23. #cfg_file=/usr/local/nagios/etc/objects/printer.cfg          24. # 定义监测打印机  25.    26. # 也可以告诉Nagios处理所有配置文件（带有.cfg扩展名）在特定的目录使用cfg_dir指令如下所示：  27. #cfg_dir=/usr/local/nagios/etc/servers  28. #cfg_dir=/usr/local/nagios/etc/printers  29. #cfg_dir=/usr/local/nagios/etc/switches  30. #cfg_dir=/usr/local/nagios/etc/routers    总结：配置文件里的变量: 日志文件： 格式：    log_file=<file_name> 样例：    log_file=/usr/local/nagios/var/nagios.log   说明： 这个变量用于设定Nagios在何处创建其日志文件。它应该是你主配置文件里面的第一个变量，当Nagios找到你配置文件并发现配置里有错误时会向该文件中写入错误信息。如果你使能了日志回滚，Nagios将在每小时、每天、每周或每月对日志进行回滚。   对象配置文件： 格式：    cfg_file=<file_name> 样例： cfg_file=/usr/local/nagios/etc/hosts.cfg cfg_file=/usr/local/nagios/etc/servers.cfg cfg_file=/usr/local/nagios/etc/commands.cfg   说明： 该变量用于指定一个包含有将用于Nagios监控对象的对象配置文件。对象配置文件中包括有主机、主机组、联系人、联系人组、服务、命令等等对象的定义。配置信息可以切分为多个文件并且用cfg_file=语句来指向每个待处理的配置文件.   对象配置目录: 格式：    cfg_dir=<directory_name> 样例： cfg_dir=/usr/local/nagios/etc/commands cfg_dir=/usr/local/nagios/etc/servers cfg_dir=/usr/local/nagios/etc/hosts   说明： 该变量用于指定一个目录，目录里包含有将用于Nagios监控对象的对象配置文件。所有的在这个目录下的且以.cfg为扩展名的文件将被作为配置文件来处理。另外，Nagios将会递归该目录下的子目录并处理其子目录下的全部配置文件。你可以把配置放入不同的目录并且用cfg_dir=语句来指向每个待处理的目录。   2.etc/objects/commands.cfg（命令配置文件） 1.  #定义通知的方式，主机发生故障通知和服务发送故障通知  2.  define command{  3.          command_name    notify-host-by-email  4.          command_line    /usr/bin/printf \"%b\" \"***** Nagios *****\\n\\nNotification Type: $NOTIFICATIONTYPE$\\nHost: $HOSTNAME$\\nState: $HOSTSTATE$\\nAddress: $HOSTADDRESS$\\nInfo: $H  5.  OSTOUTPUT$\\n\\nDate/Time: $LONGDATETIME$\\n\" | /bin/mail -s \"** $NOTIFICATIONTYPE$ Host Alert: $HOSTNAME$ is $HOSTSTATE$ **\" $CONTACTEMAIL$  6.          }  7.   #定义通知的方式，服务发生故障通知和服务发送故障通知  8.  # 'notify-service-by-email' command definition  9.  define command{  10.         command_name    notify-service-by-email  11.         command_line    /usr/bin/printf \"%b\" \"***** Nagios *****\\n\\nNotification Type: $NOTIFICATIONTYPE$\\n\\nService: $SERVICEDESC$\\nHost: $HOSTALIAS$\\nAddress: $HOSTADDRESS$\\nS  12. tate: $SERVICESTATE$\\n\\nDate/Time: $LONGDATETIME$\\n\\nAdditional Info:\\n\\n$SERVICEOUTPUT$\\n\" | /bin/mail -s \"** $NOTIFICATIONTYPE$ Service Alert: $HOSTALIAS$/$SERVICEDESC$ is $SE  13. RVICESTATE$ **\" $CONTACTEMAIL$  14.         }  15. #定义检测主机是否存活的命令，command_name是最后在服务中的引用名，而它是调用的check_ping命令来实现的  16. define command{  17.         command_name    check-host-alive  18.         command_line    $USER1$/check_ping -H $HOSTADDRESS$ -w 3000.0,80% -c 5000.0,100% -p 5  19.         }  20. #定义检测主机cpu负载的命令  21. define command{  22.         command_name    check_local_load  23.         command_line    $USER1$/check_load -w $ARG1$ -c $ARG2$  24.         }  25. #定义检测主机进程的命令  26. define command{  27.         command_name    check_local_procs  28.         command_line    $USER1$/check_procs -w $ARG1$ -c $ARG2$ -s $ARG3$  29.         ｝  30. #定义检测主机tcp端口的命令  31. define command{  32.         command_name    check_tcp  33.         command_line    $USER1$/check_tcp -H $HOSTADDRESS$ -p $ARG1$ $ARG2$  34.         }  总结： 命令配置文件： 格式：     define command{        command_name    命令名        command_line       命令调用的实际插件路径以及阀值        ｝ 样例： cfg_file=/usr/local/nagios/etc/hosts.cfg cfg_file=/usr/local/nagios/etc/servers.cfg cfg_file=/usr/local/nagios/etc/commands.cfg   说明： 该变量用于指定一个包含有将用于Nagios监控命令的配置文件。对象配置文件中包括有命令名以及实际插件路径以及阀值的定义。   3./etc/objects/templates.cfg（样本配置文件） 1.  此定义的为类，也就是日后定义主机或者服务时指定的name引用  2.  define service{  3.          name                            generic-service   #通过name来指定服务类名，这里的generice-service是一个类名   4.          active_checks_enabled               1             #设定启用活动监测服务  5.          passive_checks_enabled              1             #设定启用被动监测服务  6.          parallelize_check                   1             #设定启用并发活动监测服务  7.          obsess_over_service                 1             #设定启用服务防停滞  8.          check_freshness                     0             #设定关闭更新监测  9.          notifications_enabled               1             #设定启用事件通知    10.         event_handler_enabled               1             #设定启用事件处理程序  11.         flap_detection_enabled              1             #设定启用状态抖动监测  12.         failure_prediction_enabled          1             #设定启用故障预测  13.         process_perf_data                   1             #设定启用进程性能数据记录  14.         retain_status_information           1             #设定启用状态信息保存功能。当Nagios重新启动的时候不会是空数据，而是先显示上次离线时最后保留的状态数据。  15.         retain_nonstatus_information        1             #设定启用非状态信息保存功能。当Nagios重新启动的时候不会是空数据，而是先显示上次离线时最后保留的非状态数据  16.         is_volatile                         0             #设定服务非易失  17.         check_period                      24x7            #设定监控的时间段  18.         max_check_attempts                  3             #设定监测失败后最多尝试次数  19.         normal_check_interval              10             #设定正常监测服务的间隔，单位分  20.         retry_check_interval                2             #设定监测失败后尝试的间隔，单位分  21.         contact_groups                  admins            #定义通知联系人租  22.         notification_options            w,u,c,r ,d        #设定监测指定服务产生的事件通知的条件选项。这里后面跟上一些级别类型参数：  23.                                                                w代表warning告警；  24.                                                                u代表unknown未知；  25.                                                                c代表critical严重；  26.                                                                r代表recover恢复；  27.                                                                d代表down奔溃。  28.         notification_interval              60               #设定服务通知的间隔  29.         notification_period               24x7              #设定服务通知运行时间  30.          register                           0               #设定register表明本段定义的是一个服务类，而不是具体的服务    31.         }           4.etc/objects/localhost.cfg（本机监控文件） 1.  define host{                         #此定义的为监控主机的配置文件  2.          use              linux-server       #引用类，在templates.cfg中预定义  3.          host_name        localhost          #指定主机名，并不是实际机器的主机名，自己定义，方便以后在定义服务时调用  4.          alias            localhost          #别名  5.          address          127.0.0.1          #指定监控主机的地址  6.          }  7.  define service{                       #此定义为监控主机服务的配置文件  8.          use              local-service       #引用类，在templates.cfg中预定义  9.          host_name        localhost           #指定主机名，在host段中预定义  10.         service_description  PING            #监控服务的名称，也就是在web页面上显示的监控项目  11.         check_command    check_ping!100.0,20%!500.0,60%    #具体监控的命令以及阀值  12.         }   备注：以上定义的主机和服务，没有指定通知联系人，那是因为在其中引用了类，而templates.cfg中定义的类是有指定联系人的。        5.etc/objects/contacts.cfg（联系人配置文件） 1.  define contact{  2.          contact_name        nagiosadmin     #定义联系人的名称，方便以后在监控项目中调用     3.          use                 generic-contact #引用类，在templates.cfg中预定义  4.          alias               Nagios Admin    #别名     5.          email               test@abc.com    #邮件地址  6.          }  7.  define contactgroup{  8.          contactgroup_name    admins         #定义联系人组的名称，方便一次性发送多人  9.          alias                Nagios Administrators   #别名  10.         members              nagiosadmin    #定义组成员，这里nagiosadmin，也就是上面contact_name的值  11.         }           6.etc/objects/timeperiods.cfg（时间段配置文件） 1.  define timeperiod{                        #定义时间段的配置文件  2.          timeperiod_name 24x7              #指定时间段的名称，方便以后在服务里调用  3.          alias           24 Hours A Day, 7 Days A Week   #别名  4.          sunday          00:00-24:00       #具体的时间段定义  5.          monday          00:00-24:00       #一周24小时  6.          tuesday         00:00-24:00  7.          wednesday       00:00-24:00  8.          thursday        00:00-24:00  9.          friday          00:00-24:00  10.         saturday        00:00-24:00  11.         }  12. define timeperiod{                        #定义时间段的配置文件  13.         timeperiod_name workhours         #指定时间段的名称，方便以后在服务里调用  14.         alias           Normal Work Hours #别名  15.         monday          09:00-17:00       #具体的时间段定义  16.         tuesday         09:00-17:00       #周一到周五的上班时间  17.         wednesday       09:00-17:00  18.         thursday        09:00-17:00  19.         friday          09:00-17:00  20.         }    四、总结： 看过了以上配置文件的详解，来总结下监控一台主机和主机上的服务，必要的条件。 1.首先定义其监控主机，其中注意的就是引用的类必须在templates.cfg中预定义（所有未指定的条目，都按照类的定义载入） 2.再就是监控主机中的资源以及服务，指定的name必须在主机配置文件中预定义，还有就是指定的命令必须在command.cfg中预定义 3.还有就是类中定义的联系人或者联系人组必须在contacts.cfg中预定义 4.再有的细节问题，就自己慢慢摸索了、 备注：以上所说的预定义，其实写在任意位置都是可以的，只是为了有条理，日后也方便查找问题。   五、示例： 新建一台监控远程192.168.1.1主机，以及cpu、内存、硬盘使用率、进程数以及僵尸进程的配置文件。 解：vim etc/objects/192..168.1.1.cfg define host{         use linux-server         host_name test         alias test_1         address 192.168.1.1 } define service{         use generic-service         host_name test         service_description CPU Load         check_command check_nrpe!check_load } define service{         use generic-service         host_name test         service_description Current Users         check_command check_nrpe!check_users } define service{         use generic-service         host_name test         service_description Disk Free Space /         check_command check_nrpe!check_root } define service{         use generic-service         host_name test         service_description Total Processes         check_command check_nrpe!check_total_procs } define service{         use generic-service,services-pnp         host_name Mailbak         service_description Zombie Processes         check_command check_nrpe!check_zombie_procs } 具体检测的命令都在libexec/下，每条检测命令后面加--help来查看其用法。   定义好后，检查下配置文件，然后重载nagios服务，就可以在web页面上查看了。   记录到此，旨在详解！也为日后方便查看！ Nagios学习笔记之（四）外部扩展 2012-08-13 15:56:12 标签：监控 nagios rrdtool pnp sendEmail 版权声明：原创作品，如需转载，请与作者联系。否则将追究法律责任。  Nagios学习笔记之（四）外部扩展： 前言：上篇说了nagios的配置文件详解，相信都对其中的逻辑关系有了一些了解，其实这就行了，不可能一下子把它100%弄懂，我也是刚懂了60%左右吧，在日后的使用过程中，逐渐熟悉，慢慢消化。。 此篇为nagios安装配置实现以后的一些功能扩展以及技巧，玩监控的应该也知道cacti，没错，cacti以图形见长，那图绘的叫一个美观，羡慕？没事，只要安装些额外的插件，nagios迅速也可以绘出图来，没有cacti那么美观而已，不过看效果够用了，毕竟nagios不是专业看图的。   在这里再说下nagios的常用功能： 1.监控主机资源(处理器负载、磁盘使用情况等) 2.监控网络服务 (SMTP、POP3、HTTP、NNTP、PING 等) 3.在服务或主机产生问题和修复时获得通知(通过邮件、页面或用户定制的方式) 4.可以自定义写脚本来进行灵活的监控（nagios有监控脚本的固定格式）   好了，开始说下nagios安装pnp的过程吧！ 一、nagios安装pnp图形插件 1.首先安装必要的软件包： 1.  yum -y install php-gd rrdtool-perl rrdtool librrds-perl perl-Time-HiRes      （rrdtool这里采用的是yum直接安装，也可源码安装，但安装过程较繁琐，本人第一次是源码安装，后面全都采用yum装了，看个人爱好）   2.1.下载最新的pnp程序并安装： 1.  wget http://cdnetworks-kr-1.dl.sourceforge.net/project/pnp4nagios/PNP-0.6/pnp4nagios-0.6.6.tar.gz  2.  tar zxf pnp4nagios-0.6.6.tar.gz  3.  cd pnp4nagios-0.6.6.tar.gz  4.  ./configure --with-nagios-user=nagios --with-nagios-group=nagcmd      #编译前的预配置，nagcmd为你安装nagios时指定的组  5.  make all                      #编译  6.  make install                  #安装  7.  make install-webconf          #安装web配置文件  8.  make install-config           #安装样例配置文件  9.  make install-init             #初始化服务    2.2.初始化配置并重启服务： cd /usr/local/pnp4nagios/etc rename .cfg-sample .cfg *.cfg-sample cd pages rename .cfg-sample .cfg *.cfg-sample cd ../check_commands rename .cfg-sample .cfg *.cfg-sample                                                                     #意思就是把左右以.cfg-sample的样例文件直接变成.cfg service npcd restart          #最后重启npc服务   3.配置nagios以支持pnp绘图： 3.1.首先就是修改nagios的主配置文件，打开数据传输 vim nagios.cfg process_performance_data=1                          #默认是0，改为1 host_perfdata_command=process-host-perfdata                  service_perfdata_command=process-service-perfdata   #这两项默认注释，去掉注释即可   3.2.再就是修改nagios的命令配置文件，定义其使用的插件 vim commands.cfg 1.  ##添加  2.  # 'process-host-perfdata' command definition  3.  define command{  4.          command_name    process-host-perfdata  5.          command_line    /usr/local/pnp4nagios/libexec/process_perfdata.pl  6.          }  7.  # 'process-service-perfdata' command definition  8.  define command{  9.          command_name    process-service-perfdata  10.         command_line    /usr/local/pnp4nagios/libexec/process_perfdata.pl  11.         }               #把原有的注释，添加即可，也可在其上直接修改  3.3.下面就是配置nagios的样本文件，定义后续要引用的类 vim templates.cfg 1.  define host {  2.  name       hosts-pnp  3.  action_url /pnp4nagios/graph?host=$HOSTNAME$&srv=_HOST_  4.  register   0  5.  }  6.  define service {  7.  name       services-pnp  8.  action_url /pnp4nagios/graph?host=$HOSTNAME$&srv=$SERVICEDESC$  9.  register   0  10. }                        #在最后添加即可    4.最后就是在想看到图的主机或者服务的配置文件中引用类 在name那行，本身引用的类后面加上hosts-pnn或者services-pnp，以“，”隔开 示例： 主机类： 1.  define host{  2.          use linux-server,hosts-pnp         #添加至此就ok了  3.          host_name mail  4.          alias mail  5.          address 192.168.1.1  6.  }    服务类： 1.  define service{  2.          use generic-service,services-pnp    #添加至此就ok了  3.          host_name mail  4.          service_description CPU Load  5.          check_command check_nrpe!check_load  6.          contact_groups    mailadm  7.  }  最后检查nagios的配置文件，check（第一篇说过），没问题就重载nagios服务。 过一会会在/usr/local/pnp4nagios/var/perfdata/下生成以监控主机的cfg文件名的文件夹，里面会有.rrd和.xml的文件，那些就是收集的数据了。 在网页上的效果如下图：   二、nagios报警邮件技巧 我们在配置nagios邮件报警的时候，会发现是调用本机的sendmail或者postfix，没有的话还得装，最主要的就是有的服务需要smtp认证，这就导致告警邮件有可能被拒收！！！ 其实有个小工具可以解决这个棘手的问题：sendEmail sendEmail简介： 1.采用perl语言编写，小巧灵活 2.绿色软件，不需安装，直接可以执行 3.参数自定义，可多线程发送 4.可被任意程序所调用，方便   好了，介绍完了，那么就来说下怎么用它来实现nagios的报警邮件吧！ 1.首先下载其软件： 1.  wget http://caspian.dotconf.net/menu/Software/SendEmail/sendEmail-v1.55.tar.gz    2.解压、给与执行权限并改变PATH  1.  tar zxf sendEmail-v1.55.tar.gz  2.  cd sendEmail-v1.55  3.  cp sendEmail /usr/local/bin  4.  chmod 755 /usr/local/bin/sendEmail    3.测试是否可以正常发送邮件 其用法如下： -f   表示发送者的邮箱 -t   表示接收者的邮箱 -s   表示SMTP服务器的域名或者ip -u   表示邮件的主题 -xu 表示SMTP验证的用户名 -xp 表示SMTP验证的密码 -m  表示邮件的内容 1.  /usr/local/bin/sendEmail –f nagios@test.com –t tony@test.com –s mail.test.com –u “nagios test” –xu nagios –xp abc123 –m test    4.下面是重头戏，怎么让nagios调用其来发送告警邮件 需要修改command.cfg文件，修改notify-host-by-email和notify-service-by-email对应的命令执行路径   示例如下：  1.  define command {  2.          command_name           notify-host-by-email  3.          command_line           /usr/bin/printf \"%b\" \"***** Nagios *****\\n\\nNotification Type: $NOTIFICATIONTYPE$\\nHost: $HOSTNAME$\\n  4.  State: $HOSTSTATE$\\nAddress: $HOSTADDRESS$\\nInfo: $HOSTOUTPUT$\\n\\nDate/Time: $LONGDATETIME$\\n\" | /usr/sbin/sendEmail -f 邮箱名  5.   -t $CONTACTEMAIL$ -s 邮件服务器地址 -u \"** $NOTIFICATIONTYPE$ Host Alert: $HOSTNAME$ is $HOSTSTATE$ **\" -xu smtp认证名 -xp 密码  6.          register                        1  7.  }  8.    9.  define command {  10.         command_name           notify-service-by-email  11.         command_line           /usr/bin/printf \"%b\" \"***** Nagios *****\\n\\nNotification Type: $NOTIFICATIONTYPE$\\n\\nService: $SERVIC  12. EDESC$\\nHost: $HOSTALIAS$\\nAddress: $HOSTADDRESS$\\nDate/Time: $LONGDATETIME$\\n\\nAdditional Info:\\n\\n$SERVICEOUTPUT$\" | /usr/sbin/sendEmail -f  13.  邮箱名 -t $CONTACTEMAIL$ -s 邮件服务器地址 -u \"** $NOTIFICATIONTYPE$ Service Alert: $HOSTALIAS$/$SERVICEDESC$ is $SERVI  14. CESTATE$ **\" -xu smtp认证名 -xp 密码  15.         register                        1  16. }  备注：其实sendEmail是一个十分有用的程序,nagios可以调用，别的程序也可以，这样就不用装sendmail或者posfix浪费服务器资源了，也更方便了。   三、如何定义非默认的检测条目 在我们进行定义监控主机或者服务的时候，可能会遇到这样的问题，就是比如：要监控http服务，check_http默认是检测的80端口，而要监控的主机http不是80端口监听的，那么我们如何来监控呢？ 这里要分机器，如果是linux的话，需要修改被监控端的nrpe.cfg配置文件；如果是Windows的话，需要在监控服务的配置文件中更改。   例如：要监控某机器的http服务，监控端口为8080 1.linux机器： 修改被监控端的nrpe.cfg文件 vim nrpe.cfg command[check_http]=/usr/local/nagios/libexec/check_http  -H 127.0.0.1 -p 8080 -w 5 -c 10 -4 （默认可能没有，需要手动添加） 备注：所以定义监控远程主机的命令，都必须在被监控端的nrpe.cfg文件中定义，否则不能监控！   2.windows机器： 直接修改监控端的定义服务的配置文件 例： define service{         use generic-service         host_name server         service_description HTTP         check_command check_http! } 假如被监控端http的监控端口不是80，那么nagios就会告警，合理利用--help。 /usr/local/nagios/libexec/check_http --help（贴出其中一部分）   1.  Options:   2.   -h, --help                            #显示帮助   3.      Print detailed help screen   4.   -V, --version                         #显示版本   5.      Print version information   6.   -H, --hostname=ADDRESS                #指定要监控的主机名   7.      Host name argument for servers using host headers (virtual host)   8.      Append a port to include it in the header (eg: example.com:5000)   9.   -I, --IP-address=ADDRESS              #指定要监控主机的ip   10.     IP address or name (use numeric address if possible to bypass DNS lookup).   11.  -p, --port=INTEGER                    #指定要监控的端口，默认80   12.     Port number (default: 80)   13.  -4, --use-ipv4                        #使用ipv4协议   14.     Use IPv4 connection   15.  -6, --use-ipv6                        #使用ipv6协议   16.     Use IPv6 connection   17.  -S, --ssl=VERSION                     #使用ssl加密，默认端口就是443   18.     Connect via SSL. Port defaults to 443. VERSION is optional, and prevents   19.     auto-negotiation (1 = TLSv1, 2 = SSLv2, 3 = SSLv3).   20.    21. 所以假如监控的端口不是80的话，比如8080，改成下面：  22. define service{  23.         use generic-service  24.         host_name server  25.         service_description HTTP  26.         check_command check_nrpe!check_http -p 8080  27. }  其它监控插件也是类似，只要加上想要的参数，指定值就可以了。 这也是本人在部署的时候大意留下的。。 好了，先到这里，后续会补充。  ","title":"Nagios学习笔记"},{"content":"                                           《谈谈Windows核心编程系列》导读         谈谈Windows核心编程系列终于发布完了。        发布这些文章的目的：          一是为了总结之用，当需要的时候可以迅速的找出。         二也是在记录学习轨迹。         慢慢的养成了一种习惯，好像不写笔记就不算读过书一样。读书的时候会不自觉的加快速度，有时候看的不是很仔细，有时甚至看了很多遍还是不能明白作者的意图。而记录学习笔记不仅需要眼睛看，还需要手脑并用，虽然会很费时间但是对却对加深理解很有帮助。        这些文章大都参考自《Windows核心编程》第五版。偶尔穿插些其他书上的内容或代码。以期能够更有说服力。希望这些文章能对初学者有所帮助！！               转载请注明出处，谢谢！！     《windows核心编程系列》一谈谈windows中的错误处理机制 《windows核心编程系列》二谈谈ANSI和Unicode字符集 《windows核心编程系列》三谈谈内核对象及句柄的本质 《windows核心编程系列》四谈谈进程的建立和终止 《windows核心编程系列》五谈谈线程基础 《windows核心编程系列》六谈谈线程调度、优先级和关联性 《windows核心编程系列》七谈谈用户模式下的线程同步 《Windows核心编程系列》八谈谈用内核对象进行线程同步 《Windows核心编程系列》九谈谈同步设备IO与异步设备IO之同步设备IO 《Windows核心编程系列》十谈谈﻿﻿﻿﻿同步设备IO与异步设备IO之异步IO 《Windows核心编程系列》十一谈谈Windows线程池 《Windows核心编程系列》十二谈谈Windows内存体系结构 《Windows核心编程系列》十三谈谈在应用程序中使用虚拟内存 《Windows核心编程系列》十四谈谈默认堆和自定义堆 《windows核心编程系列》十五谈谈windows线程栈 《windows核心编程系列》十六谈谈内存映射文件 《windows核心编程系列》十七谈谈dll 《windows核心编程系列》十八谈谈windows钩子 《windows核心编程系列》十九谈谈使用远程线程来注入DLL。 《Windows核心编程系列》二十谈谈DLL高级技术 《windows核心编程系列》二十一谈谈基址重定位和模块绑定 《windows核心编程系列》二十二谈谈修改导入段拦截API。  ","title":"[置顶] 《谈谈Windows核心编程系列》导读 《windows核心编程系列》一谈谈windows中的错误处理机制 《windows核心编程系列》二谈谈ANSI和Unicode字符集 《windows核心编程系列》三谈谈内核对象及句柄的本质 《windows核心编程系列》四谈谈进程的建立和终止 《windows核心编程系列》五谈谈线程基础 《windows核心编程系列》六谈谈线程调度、优先级和关联性 《windows核心编程系列》七谈谈用户模式下的线程同步 《Windows核心编程系列》八谈谈用内核对象进行线程同步 《Windows核心编程系列》九谈谈同步设备IO与异步设备IO之同步设备IO 《Windows核心编程系列》十谈谈﻿﻿﻿﻿同步设备IO与异步设备IO之异步IO 《Windows核心编程系列》十一谈谈Windows线程池 《Windows核心编程系列》十二谈谈Windows内存体系结构 《Windows核心编程系列》十三谈谈在应用程序中使用虚拟内存  《Windows核心编程系列》十四谈谈默认堆和自定义堆 《windows核心编程系列》十五谈谈windows线程栈 《windows核心编程系列》十六谈谈内存映射文件 《windows核心编程系列》十七谈谈dll 《windows核心编程系列》十八谈谈windows钩子 《windows核心编程系列》十九谈谈使用远程线程来注入DLL。 《Windows核心编程系列》二十谈谈DLL高级技术 《windows核心编程系列》二十一谈谈基址重定位和模块绑定 《windows核心编程系列》二十二谈谈修改导入段拦截API。"},{"content":"                           堆      前面我们说过堆非常适合分配大量的小型数据。使用堆可以让程序员专心解决手头的问题，而不必理会分配粒度和页面边界之类的事情。因此堆是管理链表和数的最佳方式。但是堆进行内存分配和释放时的速度比其他方式都慢，而且无法对物理存储器的调拨和撤销调拨进行控制。        什么是堆？        在系统内部堆就是一块预定的地址空间区域。刚开始堆的大部分页面都没有调拨物理存储器。随着我们不断的从堆中分配内存，堆管理器会给堆调拨越来越多的物理存储器。这些物理存储器始终是从页交换文件中分配的。释放堆中的内存时，堆管理器会撤销已调拨的物理存储器。        进程默认堆。        进程初始化时，系统会在进程的地址空间中创建一个堆。这个堆被称为进程的默认堆。默认情况下，这个堆的地址空间区域大小是1MB。程序员可以控制这个大小。我们可以在创建应用程序时用/HEAP连接器开关来改变默认堆的大小。由于DLL没有与之关联的堆，因此在创建DLL时，不应该使用/HEAP开关。         /HEAP:reserve[,commit]        由于许多Windows函数会用到进程默认堆，因此对默认堆的访问必须一次进行。系统会保证在任何情况下只让一个线程从默认堆中分配或释放内存块。如果应用程序只有一个线程，而我们又希望以最快的方式访问堆，我们应该创建自己的堆，而不要使用默认堆。        默认堆由系统创建和释放，我们无法销毁默认堆。每个堆都有一个标识自己的句柄，所有分配和释放内存块的堆函数都会在参数中使用到这个堆句柄。我们可以调用GetProcessHeap来得到默认堆的句柄。     HANDLE GetProcessHeap();        创建额外堆的时机:        一：对数据保护。创建两个或多个独立的堆，每个堆保存不同的结构，对两个堆分别操作，可以使问题局部化。        二：更有效的内存管理。创建额外的堆，管理同样大小的对象。这样在释放一个空间后可以刚好容纳另一个对象。        三：内存访问局部化。将需要同时访问的数据放在相邻的区域，可以减少缺页中断的次数。        四：避免线程同步开销。默认堆的访问是依次进行的。堆函数必须执行额外的代码来保证线程安全性。通过创建额外的堆可以避免同步开销。        五：快速释放。我们可以直接释放整个堆而不需要手动的释放每个内存块。这不但极其方便，而且还可以更快的运行。        创建额外的堆        我们可以调用HeapCreate来创建额外的堆：     HANDLE HeapCreate(     DWORD fdwOptions,     SIZE_T dwInitilialize,     SIZE_T dwMaximumSize);        fdwOptions表示对堆的操作该如何进行。可以传入0，   HEAP_NO_SERIALIZE， HEAP_GENERATE_EXCEPTIONS，HEAP_CREATE_ENABLE_EXECUTE或这些标志的组合。 HEAP_NO_SERIALIZE告诉堆管理器堆管理器不负责堆的线程安全性。对堆的线程安全性的控制由程序员控制。        HEAP_GENERATE_EXCEPTIONS标志告诉系统，每当在堆中分配或重新分配内存块失败时抛出一个异常。用来通知应用程序有错误发生。        dwInitialSize表示一开始要调拨给堆的字节数。如果需要HeapCreate会把这个值向上取整到cpu页面大小的整数倍。        dwMaximumSize表示堆所能增长到的最大大小。即系统为堆所预定的地址空间的最大大小。如果试图分配的内存块超过最大大小，分配操作会失败。如果dwMaximumSize为0，则表明创建的堆是可增长的，没有一个指定上限。        函数执行成功HeapCreate会返回一个句柄，标识了新创建的堆。   堆创建后，需要从堆中分配内存时，要调用HeapAlloc函数：     PVOID HeapAlloc(     HANDLE hHeap,     DWORD fdwFlags,     SIZE_T dwBytes);        hHeap是一个堆句柄，表示要从哪个堆分配内存。        fdwFlags用来执行一些标志。这些标志会对分配产生一些影响。总共有三个标志：             HEAP_ZERO_MEMORY，HEAP_GENERATE_EXCEPTIONS和HEAP_NO_SERIALIZE。        HEAP_ZERO_MEMORY会让HeapAlloc返回之前把内存块的内容都清0 。        HEAP_GENERATE_EXCEPTIONS用来告诉系统如果堆中没有足够的内存来满足分配请求，此次调用的 HeapAlloc应抛出异常。可以在创建堆时指定这个标志，只要在这个堆上分配内存，如果内存不足都抛出异常。        如果分配成功HeapAlloc会返回内存块地址。否则将会返回NULL。        默认情况下，对堆的访问会依次进行。当任何程序试图从堆中分配一块内存时，HeapAlloc会执行以下操作：        1：遍历已分配的内存的链表和闲置内存的链表。        2：找到一块足够大的闲置内存块。        3：分配一块新的内存，将2找到的内存块标记为已分配。        4：将新分配的内存块添加到已分配的链表中。        注意：在分配大于1MB的内存时应该避免使用堆函数，而应该使用VirtualAlloc函数。        HeapReAlloc可以改变堆中某一块内存的大小：     PVOID HeapReAlloc(     HANDLE hHeap,     DWORD fdwFlags,     PVOID pvMem,     SIZE_T dwBytes);   hHeap用来标识一个堆。   fdwFlags用来在调整内存块大小时用到这些标志。可以有以下标志：HEAP_GENERATE_EXCEPTIONS，HEAP_NO_SERIALIZE，HEAP_ZERO_MEMORY，HEAP_REALLOC_IN_PLACE_ONLY。   前两个标志与前面介绍的一样。只有当增大内存块时HEAP_ZERO_MEMORY才有用。额外的字节会被清0。   在增大内存块时HeapReAlloc可能会移动内存块，HEAP_REALLOC_IN_PLACE_ONLY标志告诉HeapReAlloc尽量不要移动内存块。如果不移动不能增大内存块，则HeapReAlloc返回新地址。   pvMem指定要调整大小的内存块。   dwBytes指定内存块的新大小。   分配一块内存后，调用HeapSize可以获得这块内存的实际大小：     SIZE_T HeapSize(    HANDLE hHeap,    DWORD fdwFlags,    LPCVOID pvMem);   hHeap用来标识堆。   pvMem表示内存地址。   dwFlags可以是0或HEAP_NO_SERIALIZE   当不要使用一块内存时可以调用HeapFree来释放它：     BOOL HeapFree(    HANDLE hHeap,    DWORD fdwFlags,    PVOID pvMem);   如果操作成功则返回TRUE。调用这个函数可能会使堆管理器撤销一些已经调拨的物理存储器。   如果应用程序不再需要自己创建的堆，可以调用HeapDestroy来销毁它：     BOOL HeapDestroy(HANDLE hHeap);   此时系统会收回堆所占用的物理存储器和地址空间区域。执行成功则返回TRUE。如果我们不调用此函数主动销毁自己创建的堆，在进程结束时，系统会替我们销毁。我们不能调用此函数销毁默认堆，默认堆由系统管理。   在C++中使用堆   在C++中我们可以调用new操作符来分配类对象。不需要时可以调用delete来释放它。如     CA *pCA=new CA;   在编译此段代码时，编译器会首先检查类CA是否重载了new操作符成员函数。如果找到编译器会调用这个函数。否额，会调用C++标准的new操作符。     deleted pCA;   对此句代码C++编译器会执行与上面类似的步骤，只有CA类没有重载delete操作符成员函数时，才会调用标准的C++delete运算符。   通过对C++类的new和delete操作符进行重载，我们可以非常容易的将堆函数加以运用：     class CA{  public:       CA();       ~CA();  public:       void *operator new(size_t size);       void*operator delete(void*p);};   上述代码调用operator new和operator delete是从默认堆中分配的内存。我们可以让其在自己创建的堆中分配内存，一般让所有对象共享同一个堆，每个对象都创建一个堆为导致额外的性能开销。可以采用计数法来对堆的生存期进行控制。   ToolHelp函数允许我们枚举进程的堆以及分配的内存块。它包括一下函数：Heap32First,Heap32Next,Heap32ListFirst和Heap32ListNext。   由于进程在自己的地址空间可以有多个堆，GetProcessHeaps可以让我们得到这些堆的句柄。     DWORD GetProcessHeaps(     DWROD dwNumHeaps,     PHANDLE phHeaps);   phHeaps是一个数组指针。用以存储返回的堆句柄。   dwNumHeaps是数组大小。   函数返回句柄数组个数。   函数所返回的句柄数组中也包括进程的默认堆的句柄。     HANDLE hHeaps[20];DWORD dwHeaps=GetProcessHeaps(20,hHeaps);   HeapValidate可以验证堆的完整性。     BOOL HeapValidate(    HANDLE hHeap,    DWORD fdwFlags,    LPCVOID pvMem);   通常在调用这个函数时，我们会传一个堆句柄和一个标志0，并传入NULL给pvMem。该函数会遍历堆中的各个内存块，确保没有任何一块内存被破坏。如果给pvMem制定一块内存地址，那么函数就只检查这一块内存的完整性。   为了让堆中闲置的内存块能重新结合在一起，并撤销调拨给堆中闲置内存块的存储器，可以调用HeapCompact：   UINT HeapCompact(    HANDLE hHeap,    DWORD fdwFlags);   一般来说会传0给fdwFlags。   下面两个函数要配对使用，用于线程同步： BOOL HeapLock(HANDLE hHeap);BOOL HeapUnlock(HANDLE hHeap);     当第一个线程调用HeapLock时，它就占有了堆。其他线程在调用堆函数时，系统就会暂停其他线程。只有当第一个线程调用HeapUnlock之后才会唤醒被暂停的进程。   HeapAlloc，HeapSize，HeapFree这些函数会在内部调用HeapLock和HeapUnlock，一般来说不需要自己去调用HeapLock和HeapUnlock。   最后一个函数是HeapWalk，它允许我们遍历堆的内容。只用于调试。具体不再介绍。             以上参考自《Windows核心编程》第五版第三部分，如有纰漏，请不吝指正！！                                                                      2012.12.28于山西大同","title":"《Windows核心编程系列》十四谈谈默认堆和自定义堆"},{"content":"                    Windows socket 基础        Windows socket是一套在Windows操作系统下的网络编程接口。它不是一种网络协议，而是一个开放的、支持多个协议的Windows下的网络编程接口 。      Windows socket是以Unix socket为基础，因此Windows socket中的许多函数名与Unix都是一样的。除此之外它还允许开发人员充分利用Windows的消息驱动机制进行程序设计开发。        套接字是应用层到运输层的接口。套接字用以表示一条连接的两端。每一个端点由ip和端口组成。因此套接字是由两端点的ip和端口组成。        端口是运输层的概念，每个端口对应一个进程。因此一条连接表示一个进程与另一个进程建立联系。        应用程序可以使用两种套接字。流套接字和数据包套接字。分别对应TCP和UDP。        TCP提供面向连接的可靠的、无重复、有序的数据流服务。而UDP提供面向数据包的，不保证数据是可靠的、有序的和无重复的。        Windows sockets中定义的套接字类型SOCKET来表示套接字：   typedef unsigned int u_int;typedef u_int SOCKET;           其实所谓的SOCKET的类型只不过是unsigned int的别名罢了。INVALID_SOCKET表示一个无效的套接字，除此之外的0--INVALID_SOCKET-1都表示一个有效的套接字。因此在创建套接字后，都需要与INVALID_SOCKET比较，看创建的套接字是否有效。 SOCKET s=socket(...);if(INVALID_SOCKET==s){  //创建失败。}          Windows SOCKET可以支持多种不同的网络协议，并且提供与协议无关的编程接口。因此开发人员就可以相同的格式开发使用任一协议的网络应用程序,而不去关心各种协议的不同。        每种协议都有一套不同的IP定址方案（即表示主机地址的方式）。TCP协议和UDP协议通过IP协议传输数据。        而Windows SOCKET通过AF_INET地址家族为IP协议定址。     #define AF_INET 2        网络中每台主机都有一个IP地址，用32位数字来表示。TCP和UDP必须指定端口号。在Windows SOCKET中sockaddr_in 结构被用来指定IP和端口号。     struct sockaddr_in{   short sin_family;   u_short sin_port;   struct in_addr sin_addr;   char sin_zero[8];};        sin_family表示地址家族。使用TCP/IP协议的应用程序必须为aF_INET，来告诉系统使用IP地址家族 。      sin_port指定服务的端口号。1024--49151范围内的数据被作为服务端口号，可以由用户自定义。    sin_zero字段作为填充字段。以便使得该结构与SOCKADDR结构长度相同。 in_addr的定义如下：   struct in_addr {                union {                                struct{                        u_char s_b1,s_b2,s_b3,s_b4;                        }S_un_b;                       struct {                       u_short s_w1,s_w2;                       } S_un_w;                  u_long S_addr;                } S_un;          }        很显然它是一个存储ip地址的联合体,有三种表达方式：        第一种用四个字节来表示IP地址的四个数字；      第二种用两个双字节来表示IP地址；      第三种用一个长整型来表示IP地址。        给in_addr赋值的一种最简单方法是使用inet_addr函数，它可以把一个代表IP地址的字符串赋值转换为in_addr类型，如addrto.sin_addr.s_addr=inet_addr(\"192.168.0.2\");        其反函数是inet_ntoa，可以把一个in_addr类型转换为一个字符串。         sockaddr类型sockaddr类型是用来表示socket地址的类型，同上面的sockaddr_in类型相比，sockaddr的适用范围更广，因为sockaddr_in只适用于TCP/IP地址。   sockaddr的定义如下：     struct sockaddr {        u_short sa_family;      char  sa_data[14];};          可知sockaddr有16个字节，而sockaddr_in也有16个字节，所以sockaddr_in是可以强制类型转换为sockaddr的。事实上也往往使用这种方法。      不同cpu处理多字节时处理方式不同。Intel x86cpu对多字节的处理方式为高对高低对低。但是在网络上采用的是高对低，低对高的方式。因此也就存在所谓主机字节序和网络字节序的处理问题。        Htonl和htons函数实现主机字节顺序和网络字节序的转换功能。H代表host，主机。N代表net。L代表long。S代表short。   当然也有从网络字节序到主机字节序的转换函数：ntohl和ntohs。        除了支持TCP/IP协议之外，Windows SOCKET还支持IPX/SPX、ATM和红外线通信协议等等，它们都有自己的定址方法，感兴趣的同学可以参考其他资料。        基本的套接字编程。      在使用套接字进行编程之前，无论是服务器还是客户端都必须加载Windows SOCKET动态库。函数WSAStartup就实现了此功能。它是套接字应用程序必须调用的第一个函数。     int WSAStartup(   WORD wVersionRequested,   LPWSADATA lpwsadata);        第一个参数指定准备加载的Windows SOCKET动态库的版本。一般使用宏MAKEWORD构造。如MAKEWORD(2,2）表示加载2.2版本。         WSADATA会返回被加载动态链接库的基本信息。如是否加载成功，以及当前实际使用的版本。具体结构不再介绍。        初始化socket之后，需要创建套接字。socket函数和WSASocket函数可以实现此功能。     SOCKET socket(               int af,               int type,               int protocao);   af表示使用协议的地址家族。创建TCP或UDP的套接字是使用AF_INET。   type表示套接字的类型。有SOCK_STREAM、SOCK_DGRAM和SOCK_RAM三种类型。分别表示流、数据包、原始套接字。   protocol，指示使用的协议。对于SOCK_STREAM套接字类型，该字段可以为IPPROTO_TCP或0。对于SOCK_DGRAM套接字类型，该字段为IPPROTO_UDP或0。   当函数创建成功时，返回一个新建的套接字句柄。否则将返回INVALID_SOCKET。如     SOCKET s=socket(AF_INET,SOCK_STREAM,0);if(INVALID_SOCKET){   //失败。}   bind函数   在创建套接字之后就需要调用bind函数将其绑定到一个已知的地址上。     int bind(SOCKET s,       const struct sockaddr*name,       int namlen);   s为要绑定的套接字，name为要绑定的地址。namelen为sockaddr长度。   函数调用成功将返回0，否则返回值为SOCKET_ERROR。如果程序不关心分配给它的地址，可使用INADDR_ANY或将端口号设为0。端口号为0时，Windows SOCKET将给应用程序分配一个值在1024-5000之间唯一的端口号。   示例：   struct sockaddr_in addr;int nServerPort=5500;int nErrorCode;addr.family=AF_INET;addr.port=htons(nServerPort);addr.sin_addr.S_addr=htonl(INADDR_ANY);SOCKET s=socket(AF_INET,SOCK_STREAM,0);if(s==INVALID_SOCKET){  //失败。}nErrorCode=bind(s,(SOCKADDR*)&addr,sizeof(addr));if(nErrorCode==SOCKET_ERROR){  //失败。}   listen函数将套接字设定为监听模式。     int listen （   SOCKET s,   int backlog);   s为要设置监听模式的套接字。 backlog指定等待连接的最大队列长度。 当函数成功时返回0，否则返回SOCKET_ERROR。 假如backlog为3，则说明最大等待连接的最大值为3.如果有四个客户端同时向服务器发起请求，那么第四个连接将会发生WSAEWOULDBLOCK错误。当服务器接受了一个请求，就将该请求从请求队列中删去。     int ret=listen(s,3);if(ret==SOCKET_ERROR){   //失败。}   accept函数接受客户端的一个连接请求。     SOCKET accept{     SOCKET s,     struct sockaddr*addr,     int *addrlen);   s为监听套接字。   addr返回客户端地址。   addrlen返回addr的长度。   函数执行成功时：   1：主机接受了等待队列的第一个请求。   2：addr结构返回客户端地址。   3：返回一个新的套接字句柄。服务器可以使用该套接字与客户端进行通信。而监听套接字仍用于接受客户端连接。   SOCKET sListen；//监听套接字。SOCKET sAccept;//接受套接字。sockaddr_in addrClient;//客户端地址。int addrClientLen=sizeof(addrClient);sAccept=accept(sListen,(SOCKADDR*)&addrClient,&addrClientLent);if(INVALID_SOCKET==sAccept){   //失败。}     recv()函数 recv()和WSARecv()函数用于接收数据。   int recv(      SOCKET s,      char *buf,      int len,      int flags);   s为接收数据套接字。   buff接受缓冲区。   len缓冲区长度。   flags:该参数影响函数的行为。它可以是0，MEG_PEEK和MSG_OOB。0表示无特殊行为。MSG_PEEK会使有用的数据被复制到buff中，但没有从系统缓冲区内将这些数据删除。MSG_OOB表示处理外带数据。   recv函数返回接收的字节数。当函数执行失败时返回SOCKET_ERROR。     SOCKET s;char buff[128];nReadlen=recv(s,buff,128,0);if(SOCKET_ERROR==nReadlen){}   send函数 send()和WSASend()用于发送数据。     int send(    SOCKET s,    const char *buff,    int len,    int flags);   s为发送套接字。   buff为发送缓冲区。   len发送数据长度。   flags可以是0或MSG_DONTROUTE或MSG_OOB。0表示无特殊行为。MSG_DONTROUTEyaoqiu传输层不要将此数据路由出去。MSG_OOB表示该数据应该被外带发送。   函数成功时返回实际发送的字节数。失败返回SOCKET_ERROR。     SOCKET s;char buff[128];int ret;strcpy(buff,”sendData”);ret=send(s,strlen(buff),0);if(SOCKET_ERROR==ret){}   closesocket()函数   closesocket()函数用以关闭套接字。释放套接字所占资源。     int closesocket(    SOCKET s);   调用过closesocket函数的套接字继续使用时会返回WSAENOTSOCK错误。   shutdown()函数。   Shutdown()函数用于通知对方不再发送数据或者不再接收数据或者既不发送也不接收数据。     int shutdown(   SOCKET s,   int how);   how参数可以是： SD_RECEIVE表示不再接收数据，不允许再调用接收数据函数。 SD_SEND表示不再发送数据。 SD_BOTH表示既不发送也不接收数据。     connect函数实现连接服务器的功能。   int connect(       SOCKET s,       const struct sockaddr*name,       int namelen);     s为套接字。     name为服务器地址。     namelen为sockaddr结构长度。     函数执行成功返回0，否则返回SOCKET_ERROR。     SOCKET s;ULONG ulServIp;USHORT ServPort;int ret;SOCKADDR_IN servAddr;servAddr.sin_family=AF_INET;servAddr.sin_addr.S_addr=htonl(ulServIp);servAddr.sin_port=htons(ServPort);int len=sizeof(servaddr);ret=connect(s,(SOCKADDR*)&servAddr,sizeof(servAddr));if(ret==SOCKET_ERROR){｝        创建套接字后，可以对它的各种属性进行设置。可以调用getsockopt()函数来返回套接字选项信息。setsockopt()设置套接字选项。   getsockopt()函数   它用于获取套接字选项信息：     int getsockopt(SOCKET s,int level,int optname,char *optval,int optlen);   s为要取得选项的套接字。 level为选项级别，有SOL_SOCKET和IPPROTO_TCP两个级别。 optname套接字选项名称。 optval该参数返回套接字选项名称对应的值。 optlen为缓冲区optval大小。 函数成功，返回值为0。否则返回SOCKET_ERROR。   int Bufflen;int noptlen=sizeof(nBufflen);int ret=getsockopt(s,SOL_SOCKET,SO_RCVBUF,(char*)&BuffLen,&noptlen);if(ret==SOCKET_ERROR){}   setsockopt函数。   它可以设置套接字选项。若不能正确设置socket属性，则数据的发送和接收会失败     int setsockopt(              SOCKET s,              int level,              int optname,              char *optval,              int optlen);   s为要取得选项的套接字。   level为选项级别，有SOL_SOCKET和IPPROTO_TCP两个级别。 optname套接字选项名称。 optval参数设置套接字选项的值。 optlen为optval大小。   下列代码首先调用getsockopt函数获得默认接收缓冲区的大小，然后调用setsockopt将接收缓冲区大小设置为原来的10倍。再次调用getsockopt来检查是否设置成功。     int opt;int noptlen=sizeof(opt);int ret=getsockopt(s,SOL_SOCKET,SO_RECVBUFF,(char*)&opt,noptlen);if(ret==SOCKET_ERROR){}opt*=10;ret=setsockopt(s,SOL_SOCKET,SO_RECVBUFF,(char*)&opt,noptlen);if(ret==SOCKET_ERROR){}int newopt;getsockopt(s,SOL_SOCKET,SO_RECVBUFF,(char*)&newopt,&noptlen);if(newopt!=opt){  //设置失败。}   当设置SOL_SOCKET选项级别时，调用setsockopt函数和getsockopt函数所设置或获取的信息为套接字本身的特征，这些信息与基层协议无关。   SOL_SOCKET级别包括一下类型： SO_ACCEPTCONN      bool类型。如果为真，表明套接字处于监听模式。 SO_BROADCAST       bool类型，如果为真，表明套接字已设置成广播消息发送。 SO_DEBUG           bool类型。如果为真，则允许输出调试信息。 SO_DONTLINGER      bool类型。如果为真，则禁止SO_LINGER。 SO_DONTROUTE       bool类型。如果为真，则不会做出路由选择。 SO_ERROR           int 类型。返回和重设以具体套接字为基础的错误代码。 SO_KEEKPALIVE       bool类型。如果为真，则套接字在会话过程中会发送保持活动消息。 SO_LINGER           struct linger*类型，设置或获取当前的拖延值。 SO_OOBINLINE        bool如果为真，则带外数据会在普通数据流中返回。 SO_RECVBUF          int类型。设置或获取接收缓冲区长度。 SO_REUSEADDR        bool类型。如果为真，套接字可以与一个正在被其他套接字使用的地址绑定。 SO_SNDBUF           bool类型。设置或获取发送缓冲区大小。 SO_TYPE            int类型。返回套接字类型，如SOCK_DGREAM，SOCK_STREAM。 SO_SNDTIMEO         int类型。设置或获取套接字在发送数据的超时时间。 SO_RECVTIMEO        int类型，设置或获取套接字在接收数据的超时时间。        WSAGetLastError函数       该函数用来在Socket相关API失败后读取错误码，根据这些错误码可以对照查出错误原因。         GetComputerName()用来获取计算机名称： BOOL GetComputerName( LPTSTR lpBuffer, LPDWORD lpnSize);plBuffer是用来存储返回的名称的缓冲区。      lpBuffer为缓冲区。      lpnSize为缓冲区大小。同时它也返回计算机名称的长度。      此函数不属于winsock库函数。使用之前不需要初始化库。      使用方法为：     TCHAR szHostName[20];    DWORD dwSize = 20;    GetComputerName( szHostName, &dwSize );        gethostname函数：      此函数为WinSock库函数，使用之前需要初始化WinSock库。     int  gethostname(char  *name, int namelen);      name为存储主机名缓冲区。      namelen为缓冲区长度。 以上参考自《Windows sockets网络开发--基于Visual C++实现》如有纰漏，请不吝赐教！！！                                             2012.12.28于山西大同","title":"Windows socket基础"},{"content":"<Directory \"/var/www/html\">    AddHandler mod_python .py     PythonHandler mptest    PythonDebug On<\/Directory>/etc/httpd/conf.d/python.conf","title":"mod_python配置文件"},{"content":"linux学习笔记2 1.linux下的文件目录： linux的文件系统是采用层级式的树状结构，最上层目录是根目录“/” root目录：存放root用户的相关文件 home目录：存放普通用户的相关文件 bin目录： 存放常用命令的目录 sbin目录：要具有一定的权限才可以使用的命令 mnt目录： 默认挂载光驱和软驱的目录 boot目录：存放引导相关的文件 etc目录：存放配置相关的文件 var目录：存放经常变化的文件 usr目录：存放安装文件的默认文件夹 2.显示当前在那个路径下：pwd 3.linux用户管理 添加用户：useradd 用户名 [root用户或者具有root权限的用户才可以添加用户] 设置密码：passwd 用户名   [给用户设置密码] 删除用户：userdel 用户名【删除用户】 删除用户以及用户主目录：userdel -r 用户名 4.linux指定运行级别(0-6)： 0:关机 1：单用户 2：多用户状态没有网络服务 --3：多用户状态有网络服务 4：系统未使用保留给用户 --5：图形界面 6：系统重启 常用运行级别是3和5,要修改默认的运行级别可改文件/etc/inittab的id：5：initdefault：这一行的中的数字  ","title":"linux学习笔记2"},{"content":"第八章：安装软件程序 包管理基础 每个主要的Linux发行版都利用包管理系统的某些形式来控制安装软件应用和库 PMS（Package Manager System）利用一个数据库来记录： 1.Linux系统上已安装了什么软件包 2.每个包安装了什么文件 3.每个已安装软件包的版本 软件包存储在服务器上，这些服务器称为库（repository） PMS会检查包的依赖关系，并在安装要求的包之前提供安装所有额外的软件包 PMS并没有一个标准的工具。基于Debian的发行版，比如Ubuntu和Linux Mint，在他们PMS工具的底层用的是dpkg。基于Red Hat的发行版，比如Fedora、openSUSE和Mandriva，在他们PMS工具的底层用的是rpm 基于Debian的系统 用aptitude管理软件包 aptitude命令会进入全屏模式，q=退出 如果想查看系统上一个已经安装了的软件包的信息，可以用下述命令 aptitude show package_name 注意：aptitude show命令并不表明这个软件包已经在系统上安装了，它只是从软件库中得到详细的软件包信息 dpkg -L package_name：查看与此软件包关联的所有文件 dpkg --search absolute_file_name：查看某个特定文件属于哪个软件包，必须用绝对路径 用aptitude安装软件包 aptitude search package_name：搜索特定软件包 aptitude install package_name：安装特定软件包 用aptitude更新软件 aptitude safe-upgrade：将所有已安装的包更新到软件库中的最新版本（检查依赖关系） aptitude full-upgrade和aptitude dist-upgrade不会检查其中依赖关系 用aptitude卸载软件 aptitude purge package_name：卸载此软件包以及关联的软件包 aptitude remove package_name：只卸载此软件包 aptitude库 库位置存储在文件/etc/apt/source.list中 source.list中条目格式 deb (or deb-src) address distribution_name package_type_list deb：编译后程序的源 deb-src：源代码的源 address：软件库的web地址 distribution_name：这个特定软件库的发行版版本的名称 package_type_list：库里面有什么类型的包 基于Red Hat的系统 列出已安装的软件包 yum list installed Mandriva和openSUSE安装方法 描述 前端工具 命令 Mandriva urpm rpm -qa > installed_software openSUSE zypper zypper search -I > installed_software 查看特定软件包信息 yum list xterm yum list installed xterm Mandriva和openSUSE查看方法 信息类型 前端工具 命令 包信息 urpm urpmq -i package_name 是否安装 urpm rpm -q package_name 包信息 zypper zypper search -s package_name 是否安装 zypper 同样命令，在Status列查找一个i yum providers file_name ：查看某个特定文件属于哪个软件包 yum会从两个库中查找：fedora和installed 用yum安装软件 yum install package_name（自动查找依赖关系） 本地安装（local installation） yum localinstall package_name.rpm 用yum更新软件 yum list updates：列出所有针对已安装包的可用更新 yum update package_name：更新指定包 yum update：更新上述列表中所有软件包 Mandriva和openSUSE更新软件包方法 前端工具 命令 urpm urpm --auto-update --update zypper zypper update 用yum卸载软件 yum remove package_name：只删除软件包，保留配置文件和数据文件 yum erase package_name：删除软件包及其所有文件 Mandriva和openSUSE卸载软件包方法 前端工具 命令 urpm urpme package_name zypper zypper remove package_name 处理损坏的包依赖关系 有时在安装多个软件包时，某个包的软件依赖关系可能会被另一个包的安装覆盖掉。称为损坏的包依赖关系（broken dependency） 首先尝试 yum clean all 然后试着用yum的update选项 如果没有解决问题，再尝试 yum deplist package_name 如果还没解决，最后尝试 yum update --skip-broken --skip-broken允许忽略关系损坏的包而更新其他包 Mandriva和openSUSE修复损坏依赖关系方法 前端工具 命令 urpm urpmi -clean zypper zypper verify yum软件库 位置：/etc/yum.repos.d yum repolist：查看正在从什么库获得软件 Mandriva和openSUSE软件库 动作 前端工具 命令 显示库 urpm urpmq --list-media 添加库 urpm urpmi.addmedia path_name 显示库 zypper zypper repos 添加库 zypper zypper addrepo path_name 从源码安装 下载压缩包，解压后安装README或AAAREADME文件中建议的方式操作即可 最后，用make编译源码，然后make install安装 转贴请保留以下链接 本人blog地址 http://su1216.iteye.com/ http://blog.csdn.net/su1216/","title":"《Linux命令行与shell脚本编程大全》 第八章 学习笔记"},{"content":"1、在用户空间中实现线程 （1）特点：内核对线程包一无所知。从内核角度考虑，就是按正常的方式管理，即单线程进程（存在运行时系统） （2）优点： 用户级线程包可以在不支持线程的操作系统上实现 保存线程状态的过程和调用程序都只是本地过程，故启动它们比进程内核调用效率更高 不需要陷阱，不需要上下文切换，也不需要对内存高速缓存进行刷新，使得线程调用非常快捷 （3）缺点： 线程发生I/O或页面故障引起的阻塞时，如果调用阻塞系统调用则内核由于不知道有多线程的存在，而会阻塞整个进程从而阻塞所有线程 一个单独的进程内部，没有时钟中断，所以不可能用轮转调度的方式调度线程 2、在内核中实现线程 （1）特点： 当某个线程希望创建一个新线程或撤销一个已有线程时，它进行一个系统调用 （2）优点： 所有能够阻塞线程的调用都以系统调用的形式实现，代价可观 当一个线程阻塞时，内核根据选择可以运行另一个进程的线程，而用户空间实现的线程中，运行时系统始终运行自己进程中的线程 说明：由于内核创建线程代价大，故有线程回收 3、信号是发给进程而不是线程的，当一个信号到达时，应该由哪一个线程处理它？线程可以“注册”它们感兴趣的信号。但如果两个或更多的线程注册了相同的信号，会发生什么呢？ 下面是线程包实现图 4、混合实现 在这种模型中，每个内核级线程有一个可以轮流使用的用户级线程集合 补充：在用户级线程中，每个进程里的线程表由运行时系统管理。当一个线程转换到就绪状态或阻塞状态时，在该线程表中存放重新启动该线程所需的信息，与内核在进程表中存放的进程的信息完全一样","title":"线程实现的两种方式——用户空间和内核中"},{"content":"关于终端编码问题最终版—Securecrt下可用 最终解决编码问题的5个配置选项 一．首先是VIM编辑器的3个编码参数。这里牵涉到VIM与系统的编码，和VIM与终端的编码在vimrc中配置 1.fileencodings 上面这个参数是VIM文件IO的编码 2. encodings 上面这个参数是vim内部运行机制的编码，与系统的交互编码，需要与系统一致 3.termencoding 上面这个参数与VIM与终端的交互，也就是输出到终端最终的编码格式，与终端设置需要一致。 二．系统的编码配置参数 1. LC_ALL   LANG 上面的2个参数即可视为系统的编码 三．终端的编码配置如下          1.在字体选项中，标准字体，精确字体，字符编码，unicode选项共同决定了终端对系统字符编码的识别 最终的理解为： 【在如下情况可显示不出现乱码，但输入会有乱码】 1.终端配置字体与vim中termencoding参数编码一致 2.系统配置字体与vim中fileencodings,encodings一致 3.系统配置和终端配置不一致 如果需要可输入中文，并且显示不出现乱码，只要调整系统配置和终端配置一致即可。 给出参考配置2套 第一套：GBK编码 1.      .vimrc中 setfileencodings=cp936 set encoding=cp936 settermencoding=cp936 2.      .bash_profile中 exportLC_ALL='zh_CN.GBK' exportLANG='zh_CN.GBK' 3.      终端 第二套：UTF-8编码 1．.vimrc中 setfileencodings=utf-8 set encoding= utf-8 settermencoding= utf-8 2.      .bash_profile中 exportLC_ALL='en_US.UTF-8' exportLANG='en_US.UTF-8' 3.      终端","title":"关于linux终端编码问题最终版—Securecrt下可用"},{"content":"进程：正在运行的程序 1、网络服务器：当一个请求进入时，服务器检查是否其需要的网页在缓存中。如果是，则把网页发送回去，如果不是，则启动一个磁盘请求以获取网页。然而，从cpu的角度看，磁盘请求需要漫长的时间（因磁盘的速度远小于内存处理，且是外围设备），这时一般是先切换到其他进程运行 2、在某一瞬间，一个cpu只能运行一个进程，但在1秒钟期间，它可能运行多个进程，这样就产生了并行的错觉（伪并行），但如果该系统有两个或多个cpu（多核）共享一个物理内存，则是真正硬件并行，同一瞬间能运行多个进程 3、进程模型： 一个进程就是一个正在执行程序的实例，包括程序计数器 、寄存器和变量的当前值 每个进程有自己的逻辑程序计数器，并且每个程序都独立地运行。实际上只有一个物理程序计数器，所以在每个程序运行时，它的逻辑程序计数器被装入实际的程序计数器中。当该程序执行结束（或暂停执行）时，物理程序计数器被保存在内存中该进程的逻辑程序计数器中 4、进程和程序的区别 厨师做菜的例子：厨师是处理器（cpu），而做菜的各种原材料就是输入数据，做菜的食谱就是程序。进程就是厨师阅读食谱，取来各种原料以及做菜一系列动作总和 5、创建进程：前台进程、后台进程（守护进程） 键入一个命令或双击一个图标就启动一个程序，这两个动作的任一都会开始一个新的进程，并在其中运行所选择的程序 从技术上看，新进程都是由于一个已存在的进程执行了一个用于创建进程的系统调用而创建的 UNIX系统中 只有一个系统调用可以用来创建新、进程fork。调用fork后，这两个进程（父和子进程）拥有相同的存储映像、同样的环境字符串和同样的打开文件。然后，子进程执行execve或一个类似的系统调用，以修改其存储映像并运行一个新的程序 Windows系统中 情形正相反，一个win32函数调用CreateProcess既处理进程创建，也负责把正确的程序装入新的进程 在UNIX和Windows中，进程创建后，父进程和子进程有各自不同的地址空间。在UNIX中，子进程的初始化地址空间是父进程的一个副本。但是这里涉及两个不同的地址空间，可认为是后来修改了子进程的地址空间，让它不同于父进程的。但是对于一个新创建的进程而言，确实有可能共享其创建者的其他资源，如打开的文件等。而Windows中，从一开始父进程的地址空间和子进程的地址空间就是不同的了 6、进程的层次结构 在UNIX中，进程和它的所有子女以及后裔共同组成一个进程组，当用户从键盘发出一个信号时，该信号被送给当前与键盘相关的进程组中的所有成员（它们通常是在当前窗口创建的所有活动进程）每个进程可以分别获取该信号、忽略该信号或采取默认的动作，即被该信号杀死。 相反，Windows中没有进程层次的概念，所有的进程地位相同，唯一类似于进程层次的暗示是在创建进程的时候，父进程得到一个特别的令牌（称句柄），该句柄可以用来控制子进程。但是，它有权把该句柄传送给某个其他进程，这样就不存在进程层次了。在UNIX中，进程就不能剥夺其子女的“继承权”。 7、进程的状态（如下图） 1、进程为等待输入而阻塞 2、调度程序选择另一个进程 3、调度程序选择这个进程 4、出现有效的输入 所有关于中断处理、启动进程和停止进程的具体细节都隐藏在调度程序中 8、进程的实现——>为实现进程模型，OS维护着一张表格（一个结构数组），即进程表。每个进程占用一个进程表项（有些地方称这些表项为进程控制块）。该表项包含了进程状态的重要信息，包含程序计数器、堆栈指针、内存分配状况、所打开文件状态、调度信息，以及其他在进程由运行态转换到就绪态或阻塞态时必须保存的信息，从而保证该进程随后能再次启动，就像从未被中断过一样","title":"进程"},{"content":"1、线程和进程的最大区别： 进程拥有自己的地址空间（存放程序正文和数据以及其他资源，对应内存），而多个 线程共享同一个地址空间和所有可用数据 2、使用线程原因： （1）在许多应用中同时发生着多种活动，其中某些活动随着时间的推移会被阻塞。通过将这些应用程序分解成可以准并行运行的多个顺序线程，程序设计模型会变得更简单，且不会因某一步I/O则程序卡死 （2）线程比进程更轻量级，创建一个线程较创建一个进程要快10~100倍 3、线程应用举例：文字处理软件：一个线程和用户交互，一个线程在得到通知时进行文档的重新格式化，一个线程周期性地将RAM中的内容写到磁盘上。（三个线程使用一样的地址空间，即共享内存，于是它们都可以访问同一个正在编辑的文件） 4、构造服务器的三种方法 模型                                                             特征 多线程                                                   并行性、阻塞系统调用 单线程进程                                           无并行性、阻塞系统调用 有限状态机                                          并行性、非阻塞系统调用、中断 说明：现在只有多线程和单线程这两种设计了，虽然有限状态机是高性能的，但是编程难度大，不再顺序运行，并且每次都要显示地保存或重新装入相应的计算状态 5、线程必须在某个进程中执行，进程用于把资源集中到一起，而线程则是在cpu上被调用的实体 在线程中有一个程序计数器用来记录接着要执行哪一条指令 线程中拥有寄存器，用来保存线程当前的工作变量 线程中还有一个堆栈，用来记录执行历史，其中每一帧保存了一个已调用的但是还没有从中返回的过程。 6、各个线程都可以访问进程地址空间中的每一个内存地址，所以一个线程可以读、写或甚至清除另一个线程的堆栈。故线程之间是没有保护的。 7、如果一个线程打开一个文件，该文件对该进程中的其他线程都可见，这些线程可以对该文件进行读写。由于资源管理的单位是进程而非线程 8、多线程情况下，进程通常会从当前的单个线程开始。这个线程有能力通过调用一个库函数创建新的线程。通常线程不存在父子层次关系，都是平等的。当一个线程完成工作后，可以通过调用一个库过程退出。该线程接着消失，不再可调度 9、thread_yield它允许线程自动放弃cpu（进入就绪状态飞）而让另一个线程运行 还引发了很多问题：不同于进程，线程库无法利用时钟中断强制线程让出cpu，考虑UNIX的fork系统调用引发的问题： 如果父进程有多个线程，你那么它的子进程也应该拥有这些线程吗？如果不是，则该子进程可能会工作不正常，因为在该子进程中的线程都是绝对必要的。如果子进程拥有了与父进程一样的多个线程，如果父进程在read系统调用（比如键盘）上被阻塞了会发生什么情况？是两个线程被阻塞在键盘上（一个属于父进程，另一个属于子进程）吗？在键入一行输入之后，这两个线程都得到该输入的副本吗？还是仅仅父进程得到或者子进程得到？类似的问题在网络连接时也会出现。另一类问题和线程共享许多数据结构的事实相关。如果一个线程关闭了某个文件，而另一个线程还在该文件上进行读操作时会怎样？假设有两个线程同时都没有内存，都开始分配更多的内存，这样会分配两次，这些都是父子进程会引起的，怎样处理呢？","title":"线程"},{"content":"linux-2.6.14移植到S3C2440 嵌入式开发交流群2：289195589，欢迎加入！ 现在应该很少使用2.6.14的内核了，但由于项目需要，最近移植了2.6.版本的内核到S3C2440上，并移植了CS8900网卡驱动(网卡驱动移植参考http://blog.csdn.net/ce123/article/details/8424399)。之所以移植网卡驱动，是因为yaffs2格式的文件系统一直挂载不成功，启动后的错误信息如下： Mounted devfs on /dev Freeing init memory: 92K Failed to execute /linuxrc.  Attempting defaults... Kernel panic - not syncing: No init found.  Try passing init= option to kernel. 这个问题只能先放一下，最后成功挂载nfs。yaffs2格式文件系统的问题以后再深入研究。整理一下最近做过的东西，怕遗忘了。 1.顶层Makefile的修改 ARCH\t\t?= armCROSS_COMPILE\t?= arm-linux-交叉编译器的使用请参考http://blog.csdn.net/ce123/article/details/8333421 2.修改时钟频率 linux/arch/arm/mach-s3c2410/mach-smdk2440.c static void __init smdk2440_map_io(void){\ts3c24xx_init_io(smdk2440_iodesc, ARRAY_SIZE(smdk2440_iodesc));\ts3c24xx_init_clocks(12000000);//12M\ts3c24xx_init_uarts(smdk2440_uartcfgs, ARRAY_SIZE(smdk2440_uartcfgs));\ts3c24xx_set_board(&smdk2440_board);} 3.修改机器ID linux/arch/arm/tools/mach-types s3c2440 ARCH_S3C2440 S3C2440 168 这个值要和uboot中的值对应起来，在uboot的arch/arm/tools/mach-types中有如下定义： #define MACH_TYPE_S3C2440              168 这两个值一样即可。 4.设置Nand Flash分区 4.1建立Nand Flash分区表 在linux/arch/arm/mach-s3c2410/devs.c中增加 #include <linux/mtd/partitions.h>#include <linux/mtd/nand.h>#include <asm/arch/nand.h>/* NAND parititon */static struct mtd_partition smdk_default_nand_part[] = {\t[0]= {              .name      = \"Board_uboot\",              .offset     = 0x00000000,              .size = 0x00080000,       },\t[1]= {              .name      = \"Board_kernel\",              .offset= 0x00240000,              .size = 0x00200000,       },\t[2]= {             .name      = \"Board_yaffs2\",             .offset= 0x00440000,             .size =  0x0FB40000,       }};name：代表分区名字 size：代表flash分区大小(单位：字节) offset：代表flash分区的起始地址(相对于0x0的偏移) 划分3个区，分别存放uboot， kernel和文件系统。 4.2.加入Nand Flash分区 static struct s3c2410_nand_set smdk_nand_sets[] = {\t[0] = {\t\t.name\t\t= \"NAND\",\t\t.nr_chips\t= 1,\t\t.nr_partitions\t= ARRAY_SIZE(smdk_default_nand_part),\t\t.partitions\t= smdk_default_nand_part,\t},};nr_partitions： 指明partition_info中定义的分区数目 partitions：分区信息表 4.3.建立Nand Flash芯片支持 static struct s3c2410_platform_nand smdk_nand_info = {\t.tacls\t\t= 20,\t.twrph0\t\t= 60,\t.twrph1\t\t= 20,\t.nr_sets\t= ARRAY_SIZE(smdk_nand_sets),\t.sets\t\t= smdk_nand_sets,};tacls，twrph0，twrph1的意思见S3C2440的数据手册，这3个值最后会被设置到NFCONF中。 sets：支持的分区集 nr_set：分区集的个数 4.4.加入Nand Flash芯片支持到Nand Flash驱动 struct platform_device s3c_device_nand = {\t.name\t\t  = \"s3c2410-nand\",\t.id\t\t  = -1,\t.num_resources\t  = ARRAY_SIZE(s3c_nand_resource),\t.resource\t  = s3c_nand_resource,\t.dev = {\t\t.platform_data = &smdk_nand_info\t}}; name：设备名称 id：有效设备编号，如果只有唯一的一个设备为-1，有多个设备从0开始计数. num_resource：有几个寄存器区 resource：寄存器区数组首地址 dev：支持的Nand Flash设备 4.5指定启动时初始化 linux/arch/arm/mach-s3c2410/mach-smdk2440.c static struct platform_device *smdk2440_devices[] __initdata = {\t&s3c_device_usb,\t&s3c_device_lcd,\t&s3c_device_wdt,\t&s3c_device_i2c,\t&s3c_device_iis,\t&s3c_device_nand,//增加}; 5.禁止Flash ECC校验 修改drivers/mtd/nand/s3c2410.c 文件s3c2410_nand_init_chip()函数，在该函数体最后加上一条语句: chip->eccmode = NAND_ECC_NONE; 6.支持devfs 在2.6.14中已经不支持devfs了，内核配置文件中已经没有了相关的配置选择，但其代码还保留了。修改fs/Kconfig文件找到menu \"Pseudo filesystems\"添加如下语句： config DEVFS_FS\tbool \"/dev file system support (OBSOLETE)\"\tdepends on EXPERIMENTAL\thelp\t  This is support for devfs, a virtual file system (like /proc) which\t  provides the file system interface to device drivers, normally found\t  in /dev. Devfs does not depend on major and minor number\t  allocations. Device drivers register entries in /dev which then\t  appear automatically, which means that the system administrator does\t  not have to create character and block special device files in the\t  /dev directory using the mknod command (or MAKEDEV script) anymore.\t  This is work in progress. If you want to use this, you *must* read\t  the material in <file:Documentation/filesystems/devfs/>, especially\t  the file README there.\t  Note that devfs no longer manages /dev/pts!  If you are using UNIX98\t  ptys, you will also need to mount the /dev/pts filesystem (devpts).\t  Note that devfs has been obsoleted by udev,\t  <http://www.kernel.org/pub/linux/utils/kernel/hotplug/>.\t  It has been stripped down to a bare minimum and is only provided for\t  legacy installations that use its naming scheme which is\t  unfortunately different from the names normal Linux installations\t  use.\t  If unsure, say N.config DEVFS_MOUNT\tbool \"Automatically mount at boot\"\tdepends on DEVFS_FS\thelp\t  This option appears if you have CONFIG_DEVFS_FS enabled. Setting\t  this to 'Y' will make the kernel automatically mount devfs onto /dev\t  when the system is booted, before the init thread is started.\t  You can override this with the \"devfs=nomount\" boot option.\t  If unsure, say N.config DEVFS_DEBUG\tbool \"Debug devfs\"\tdepends on DEVFS_FS\thelp\t  If you say Y here, then the /dev file system code will generate\t  debugging messages. See the file\t  <file:Documentation/filesystems/devfs/boot-options> for more\t  details.\t  If unsure, say N.config DEVPTS_FS_XATTR\tbool \"/dev/pts Extended Attributes\"\tdepends on UNIX98_PTYS\thelp\t  Extended attributes are name:value pairs associated with inodes by\t  the kernel or by users (see the attr(5) manual page, or visit\t  <http://acl.bestbits.at/> for details).\t  If unsure, say N.config DEVPTS_FS_SECURITY\tbool \"/dev/pts Security Labels\"\tdepends on DEVPTS_FS_XATTR\thelp\t  Security labels support alternative access control models\t  implemented by security modules like SELinux.  This option\t  enables an extended attribute handler for file security\t  labels in the /dev/pts filesystem.\t  If you are not using a security module that requires using\t  extended attributes for file security labels, say N.config TMPFS\tbool \"Virtual memory file system support (former shm fs)\"\thelp\t  Tmpfs is a file system which keeps all files in virtual memory.\t  Everything in tmpfs is temporary in the sense that no files will be\t  created on your hard drive. The files live in memory and swap\t  space. If you unmount a tmpfs instance, everything stored therein is\t  lost.\t  See <file:Documentation/filesystems/tmpfs.txt> for details. 7.内核裁剪 7.1内核配置文件 将arch/arm/configs/s3c2410_defconfig .config拷到内核目录树根下： cp arch/arm/configs/s3c2410_defconfig .config make menuconfig 将s3c2410_defconfig 导入，在s3c2410_defconfig基础上，裁剪内核。 7.2内核选项 Loadable module support >                         [*] Enable loadable module support                         [*] Automatic kernel module loading     System Type >                         [*] S3C2410 DMA support      Floating point emulation >                          [*] NWFPE math emulation 接下来要做的是对内核MTD子系统的设置      Device Drivers >                       Memory Technology Devices (MTD) >                         [*] MTD partitioning support        /*支持MTD分区，这样我们在前面设置的分区才有意义*/                         [*] Command line partition table parsing    /*支持从命令行设置flash分区信息，灵活*/                       RAM/ROM/Flash chip drivers >                        <*> Detect flash chips by Common Flash Interface (CFI) probe                        <*> Detect nonCFI AMD/JEDECcompatible flash chips                        <*> Support for Intel/Sharp flash chips                        <*> Support for AMD/Fujitsu flash chips                        <*> Support for ROM chips in bus mapping                      NAND Flash Device Drivers >                        <*> NAND Device Support                        <*> NAND Flash support for S3C2410/S3C2440 SoC                    Character devices >                       [*] Nonstandard serial port support                       [*] S3C2410 RTC Driver 接下来做的是针对文件系统的设置      File systems >                       <> Second extended fs support #去除对ext2的支持                 Pseudo filesystems >                        [*] /proc file system support                        [*] Virtual memory file system support (former shm fs)                        [*] /dev file system support (OBSOLETE)                        [*] Automatically mount at boot (NEW)              这里会看到我们前先修改fs/Kconfig的成果，devfs已经被支持上了                Miscellaneous filesystems >                Network File Systems >                       <*> NFS file system support 7.3编译 make即可。 8.总结 以前将linux-2.6.30.4移植S3C2440(http://blog.csdn.net/ce123/article/details/6581248)，基本过程很相似。照着这个过程一般都能移植好一个内核，但明白这个过程背后的东西才是王道。","title":"linux-2.6.14移植到S3C2440"},{"content":"1 ssh 在Cygwin中执行：$ ssh username@remotehost 2 scp 命令scp基于SSH协议，可以将本地文件拷贝到远程服务上的指定目录，格式如下：   $ scp filename username@remotehost:remotedirectory   执行：$ scp ipmsg.log admin@10.25.1.202:/home/admin 3 ftp/sftp 首先用root用户登录远程Linux服务器，将admin用户添加到FTP账户中。   通过echo命令追加一行到user_list文件中：# echo admin >> user_list   之后通过service命令开启FTP服务：# service vsftpd start   现在就可以在本机访问FTP远程服务器了，然后通过put命令上传文件了。   在Cygwin中执行：$ sftp admin@10.25.1.202 4 SSH Windows Client SSH提供了一个scp2.exe作为Windows下的scp命令工具。   具体位置：C:\\Program Files (x86)\\SSH Communications Security\\SSH Secure Shell   参考资料   scp命令 http://www.cnblogs.com/hitwtx/archive/2011/11/16/2251254.html   Windows SSH Client - SCP2 Syntax http://unix.business.utah.edu/doc/applications/sshsf_windows_client/scp2_syntax.html  ","title":"上传文件到服务器的Linux命令"},{"content":"     首先我要说明下我不是书籍的共同编写者和推销这本书的人。我只是作为一个看客对这本书做一个客观点的评价！希望大家能够了解这本书的一些特性和适合我们哪一类人群。      最近在微博上看到一个关于Exchange Server 2010 sp1 发布的书，作者是王淑江！因为基于Exchange 2010 的书简直太少了，类似的工具书除了台湾的人基本上没有基本可以值得查阅的书。这样来说这本书可以填补了很多人认为国内没有值得看的书的空白，我觉得还是可以适合没有基础的人作为学习Exchange server 2010的入门书籍，同时也可以作为有一定基础的人作为命名参考的工具书。      另外我们在给客户做培训的时候经常提到一个概念，3W和H。 3W 指的是What\\when\\why 概念，H指的是How To,从大的方向来说，这是一本H教程的书，也有部分的3W概念。不过不是太深，如果你对书的期望是3W级别，建议您购买英文的原版书，那样看起来才非常的有FEEL。 从书名来看，Exchange 2010 管理与实践，可能很多朋友就说，都2013了，还学2010 有什么用？没错2013是最新出来的，但是基于2010 的学习深入后学习2013你就会觉得游刃有余了。我们先来看看封面： 这个风格很像微软的Resource Kit，这也预示着这是一本工具书，我们在看看他的目录： 从目录上来看，我们很容易看出他的风格属于典型的HOW TO风格，这对于很多Exchange 管理员来说是一个很大的福音。我经常会在论坛或者讨论组里面经常受到弹窗，问我什么命令能达到他们想要的效果。有了这本书之后，你很多命令和做法都不用愁了。直接就可以按照你的需求达到您想要的工具书目的了。   我们看看内页，基本上都是图文并茂，纯粹的理论很少，你如果希望能够很快的找到某个问题地答案，看了这些图片你将很快的达到你想要的目标：   因此各位如果对英语理解不好，或者对英文有恐惧症的话，这本书将是你不可多得的工具书，能够协助您更好地管理Exchange 2010,也可以作为你将来的Exchange 2013 及后期版本的Exchange Server 管理的跳板。 这本书的购买地址如下： http://www.amazon.cn/gp/product/B00AIW9DS0/ref=oh_details_o00_s00_i00   大家在看完这本书后，可以在这里留下你的一点感言！        ","title":"推荐一本Exchange 2010 的书-Exchange Server 2010 sp2管理实践！"},{"content":"                  在应用程序中使用虚拟内存         Windows提供了以下三种机制对内存进行操控：       一：虚拟内存。最适合来管理大型对象数据或大型结构数组。       二：内存映射文件。最适合用来管理大型数据流，以及在同一机 器上运行的多个进程之间共享数据。       三：堆。最适合用来管理大量的小型对象。       很多人都对VirtualAlloc和malloc 或new的区别不是很清楚，我也一样。今天搜索下了，发现这句话说的很清楚了：       VirtualAlloc要进入内核模式，算法特复杂，比较慢，而且分配粒度是4k，用来分配小块内存很浪费       malloc先用VirtualAlloc弄一大块内存，后面在堆上分配时就不用进入内核模式，算法也简单些，而且分配粒度比较小       VirtualAlloc只能分配4KB为单位的页面，适合大型数据或者内存映射文件等用途。而堆的申请分配就没有这个限制，更为灵活。   有的人嫌malloc还不够精简，于是又在堆上面开辟自己的内存池，更加轻量级        本文将主要介绍虚拟内存。       Windows提供了一些用来操纵虚拟内存 的函数，我们可以通过这些函数直接预订地址空间区域，并给这些预订的区域调拨来自页交换文件的物理存储器。         预定地址空间区域。       可以通过调用VirtualAlloc函数来运行：     PVOID VirtualAlloc(      PVOID pvAddress,      SIZE_T dwSize,      DWORD fdwAllocationType,      DWORD fdwProtect);       pvAddress是内存地址。用来告诉我们想要运行地址空间中的哪一块。       当传入NULL时，系统会自动找到一块闲置区域。       如果在pvAddress标识的内存块中找不到闲置区域，或闲置区域不够大函数将返回NULL。       如果VirtualAlloc能满足我们的要求，它会预定一块区域并返回该区域的基地址。       dwSize用来指定我们想要预订的区域大小。以字节为单位。 系统始终以cpu页面大小整数倍来预定区域。且起始地址是按照分配粒度64kB的整数倍来预定的。       fdwAllocationType用来告诉系统我们到底是要预订还是要调拨物理存储器。如果要预订区域可以传入：MEM_RESERVE。如果我们想让系统从尽可能高的内存地址来预定区域，必须传入NULL给pvAddress，同时对MEM_TOP_DOWN和MEM_RESERVE标志进行按位或操作。       fdwProtect给区域指定保护属性。区域的保护属性对调拨给该区域的物理存储器不起任何作用。无论指定何种保护属性，只要还未给该区域调拨物理存储器都会导致访问违规。   预订时指定的属性应该跟调拨时指定的属性相同，这样系统内部处理效率会更高。       调拨物理存储器       预定区域后还需要给该区域调拨物理存储器。系统会从页交换文件中调拨物理存储器给该区域。在调拨物理存储器时，起始地址和区域大小始终都是页面大小的整数倍。调拨物理存储器同样需要调用VirtualAlloc。但这次我们需要传入MEM_COMMIT来作为fdwAllocationType的值。       pvAddress标识要调拨物理存储器的区域的起始地址。       dwSize表示物理存储器的大小。以字节为单位。我们并不需要给整个区域都调拨物理存储器。       有了起始地址和大小就可以标识一段区域。       同时预定和调拨物理存储器       有时我们项同时预定区域并给该区域调拨物理存储器。同样需要调用VirtualAlloc。但是MEM_RESERVE要和MEM_COMMIT按位或并将它们传给fdwAllocationType。此时系统会为整个区域调拨物理存储器。       撤销调拨物理存储器及释放区域。       要撤销调拨给区域的物理存储器或是释放地址空间中的一整块区域。可以调用VirtualFree函数：     BOOL VirtualFree(     LPVOID pvAddress,     SIZE_T dwSize,     DWORD fdwFreeType);   pvAddress参数必须是区域的基地址。该地址就是预定区域时VirtualAlloc返回的地址。由于系统在内部会记录该地址处的区域大小，因此我们可以且必须传入0给dwSize。   当传入MEM_RELEASE给fdwFreeType时是想告诉系统撤销调拨给该区域的所有物理存储器，并释放该区域。   我们可以撤销调拨给该区域的一部分物理存储器。此时需要传入pvAddress来告诉系统我们想要撤销调拨的区域的起始地址。dwSize传入想要撤销调拨区域的物理存储器大小，并传入MEM_DECOMMIT给fdwFreeType。   和调拨物理存储器一样，撤销调拨也是基于页面粒度的。也就是说，如果给定的地址位于一个页面中，那么系统会撤销调拨整个页面。如果dwSize为0，而pvAddress又是该区域的基地址，那么VirtualFree会调拨给该区域的所有页面。   改变保护属性   实际中我们很少需要改变已调拨物理存储器的保护属性。比如，我们可以写一个管理链表的程序，把链表中的节点保存在一个已预订的区域中。我们可以设计这样的链表处理函数，让它们在每个函数的开头把物理存储器的保护属性改成PAGE_READWRITE，访问后，再把保护属性改回FPAGE_NOACCESS。这样就可以保护链表数据免受程序中其他缺陷的影响。   我们可以调用VirtualProtect函数来改变一个内存页面的保护属性：     BOOL VirtualProtect(    PVOID pvAddress,    SIZE_T dwSize,    DWORD flNewProtect,    PDWORD pflOldProtect);   pvAddress指向内存基地址。   dwSize表示要改变保护区域的大小，以字节为单位。   flNewProtect可以是除了PAGE_WRITECOPY和PAGE_EXECUTE_WRITECOPY之外的任何PAGE_*属性。 pflOldProtect是一个指针，返回原来的属性。一定不可以传入NULL，必须传入一个有效的地址给VirtualProtect，否则函数执行失败。   由于保护属性是与整个物理存储页相关联的，VirtualProtect会改变pvAddress和dwSize跨越的所有页面的属性。而不会仅仅对一个字节改变属性，这是没有意义的。   重置物理存储器的内容   当我们修改物理内存页时，系统会尽量把改动把持在内存中。当应用程序在运行时，可能需要将数据载入内存，系统会在内存中查找可用的页面。如果找到闲置页面，就将数据载入此页面。如果没有找到，系统就会采用一定的算法，置换一些页面。如果该页面已经被修改过，系统会将这些页面置换到页交换文件。   Windows提供一项特性，使得应用程序能够提高自身的性能。这一特性就是重置物理存储器。重置物理存储器的意思是告诉系统一个或几个物理存储器页中数据没有被修改过。在需要闲置页面时，可以直接将它们覆盖，而不需要将它们写入页交换文件。有些应用程序需要在一小段时间内使用存储器，之后就不需要保存存储器中的内容。为了提高性能，应用程序应该告诉系统此页面没有被修改过，不要在页交换文件中保存存储页。 为了重置存储器，应用程序应该调用VirtualAlloc函数并在第二个参数中传MEM_RESET标志。     PINT pnData=(PINT)VirtualAlloc(NULL,1024,MEM_RELEASE|MEM_COMMIT,PAGE_READWRITE);pnData[0]=100;pnData[1]=200;VirtualAlloc((PVOID)pnData,sizeof(int),MEM_RESET,PAGE_READWRITE);   这段代码首先调拨了一块存储器，然后将这块内存的前4个字节标记为可以被重置。但是重置存储器的操作会调用失败。第二个VirtualAlloc会返回NULL。GetLastError会返回ERROR_INVALID_ADDRESS。   这是因为在传入MEM_RESET给VirtualAlloc时，函数会把基地址向下取整到页面大小的整数倍。（其他标志时都是向上去整，此处要注意。）其目的是确保在同一页面中还有其他重要数据的情况下，不会把它们丢弃。前面的例子，向下去整到页面整数倍是0，这是没有意义的。也就是说我们重置的页面必须是一个或几个完整的页面。不足一页的为了保护数据就不将它们设为可重置。   还要注意MEM_RESET不能和其他标志一起使用，它不合群，只能单独使用。否则调用会失败。   VirtualQuery函数。   VirtualQuery可以用来查询与地址空间有关的特定信息。比如大小，存储器类型及保护属性。     DWORD VirtualQuery(     LPCVOID pvAddress,     PMEMORY_BASIC_INFORMATION pmbi,     DWORD dwLength);   pvAddress指定需要查询的虚拟内存地址。   dwLength指定MEMORY_BASIC_INFORMATION结构大小。   pmbi返回MEM_BASIC_INFORMATION结构地址。该地址定义如下： typedef struct _MEMORY_BASIC_INFORMATION{    PVOID BaseAddress;//等于pvAddress向下取整到页面大小。    PVOID AllocationBase;//区域基地址。    DWORD AllocationProtect;//预定区域时的保护属性。    SIZE_T RegionSize;//区域大小。以字节为单位。以BaseAddress为起始地址。    DWORD State;//区域页面的状态。    DWORD Protect;//保护属性    DWORD Type;//}MEMORY_BASIC_INFORMATION,*PMEMORY_BASIC_INFROMATION;     VirtualQueryEx与VirtualQuery的区别就是它可以传入一个进程句柄。也就意味着它可以查询其他进程地址空间的信息。   GlobalMemoryStatus可以用来取得当前内存状态的动态信息：     VOID GlobalMemoryStatus(LPMEMORYSTATUS lpBuffer);   MEMORYSTATUS结构定义如下：     typedef struct _MEMORYSTATUS {   DWORD dwLenght;//此结构大小。调用函数前必须初始化。   DWORD dwMemoryLoad;//   SIZE_T dwTotalPhys;   SIZE_T dwAvailablePhys;   SIZE_T dwTotalPageFile;   SIZE_T dwAvailablePageFile;   SIZE_T dwTotalVirtual;   SIZE_T dwAvailVirtual;  }MEMORYSTATUS,*LPMEMORYSTATUS;   dwMemoryLoad成员告诉我们内存管理系统有多忙，它可以是0-100之间的任何值。实际中，这个值没有什么用处。 dwTotalPhys成员表示物理内存总量。   dwAvailPhys成员表示可分配的内存总理。都是以字节为单位。   dwTotalPageFile表示硬盘页交换文件最多能存放多少字节的数据。   dwTotalVirtual表示地址空间中各进程私有的那部分字节数。比2G少128k.从0x00000000-0x0000FFFF（空指针赋值分区）和从0x7FFF0000-0x7FFFFFFF（64KB进入分区）这两个分区应用程序不能访问。   dwAvailVirtual是唯一一个与进程有关的成员。它表示还有多少闲置的地址空间可以被使用。也就说dwTotalVirtual-进程预定的地址空间就等于dwAvailVirtual。   系统信息   操作系统的许多值是由系统所运行的主机决定的，如页面大小和分配粒度。使用GetSystemInfo可以获得与主机有关的值：   VOID GetSystemInfo(LPSYSTEM_INFO psi);SYSTEM_INFO结构定义如下：typedef struct _SYSTEM_INFO{    union{                 struct  {                              WORD wProcessorArchitecture;                              WORD wReserved;                           };           };    DWORD dwPageSize;    LPVOID lpMinimumApplicationAddress;    LPVOLID lpMaximumApplicationAddress;    DWORD_PTR dwActiveProcessorMask;    DWORD dwNumberOfProcessor;    DWORD dwProcessorType;    DWORD dwAllocationGranularity;    WORD wProcessorLevel;    WORD wProcessorRevision;}SYSTEM_INFO,*LPSYSTEM_INFO;   上述这么多成员只有四个与内存有关。   dwPageSize表示cpu页面大小在x86和x64机器中，该值为4K。   lpMinimumApplicationAddress给出进程中可用地址空间最小的内存地址。由于每个进程地址空间最开始的64K是闲置的，因此该值为64K。   lpMaximumApplicationAddress给出每个进程私有地址空间中最大的 可用内存地址。   dwAllocationGranularity表示用于预定地址空间区域的分配粒度   其他的成员稍微做下介绍：   wReserved为今后拓展保留，不要使用。   dwNumOfProcessor机器cpu的数量。   dwActiveProcessorMask位掩码，用来表示哪些cpu处于活动状态。可以用来运行线程。   dwProcessorType已经作废。不再使用。   wProcessorArchitecture表示处理器的体系结构。如x86,x64;   wProcessorLevel进一步细分处理器的体系结构，比如Intel奔腾2或奔腾4.   wProcessorRevision进一步对wProcessLevel进行细分。   //以下代码演示了可重置内存及以上介绍的各个函数的使用。 #include\"windows.h\"#include<iostream>#include\"tchar.h\"TCHAR TextData[]=TEXT(\"c:\\Users\\yangyang\\documents\\visual studio 2010\\Projects\\MEM_RESET\\MEM_RESET\\main.cppc:\\Users\\yangyang\\documents\\visual studio 2010\\Projects\\MEM_RESET\\MEM_RESET\\main.cpp\");int main(int argc,char**argv){\t\tPTSTR pszData=(PTSTR)VirtualAlloc(NULL,1024,MEM_RESERVE|MEM_COMMIT,PAGE_READWRITE);\tif(pszData==NULL)\t{\t\tMessageBox(NULL,TEXT(\"分配失败\"),TEXT(\"\"),MB_OK);\t}\t_tcscpy_s(pszData,1024,TextData);\tint ret=MessageBox(NULL,TEXT(\"以后是否还要访问该段内存？\"),TEXT(\"\"),MB_YESNO);\tif(ret==IDNO)\t{\t\tMEMORY_BASIC_INFORMATION mbi;\t\tVirtualQuery(pszData,&mbi,sizeof(mbi));\t\tVirtualAlloc(pszData,mbi.RegionSize,MEM_RESET,PAGE_READWRITE);\t}\tMEMORYSTATUS mst;\tGlobalMemoryStatus(&mst);\tPVOID pvAddress=VirtualAlloc(NULL,mst.dwAvailVirtual,MEM_RESERVE|MEM_COMMIT,PAGE_READWRITE);\tif(pvAddress)\t{\t\tZeroMemory(pvAddress,mst.dwAvailVirtual);\t}\tif(!_tcscmp(TextData,pszData))\t{\t\tMessageBox(NULL,TEXT(\"已经保存！\"),TEXT(\"\"),MB_YESNO);\t}\telse\t{\t\tMessageBox(NULL,TEXT(\"未保存！\"),TEXT(\"\"),MB_YESNO);\t}\tgetchar();\tVirtualFree(pvAddress,0,MEM_RELEASE);\tVirtualFree(pszData,0,MEM_RELEASE);\treturn 0;}               本文参考自《Windows核心编程》第五版第三部分。如有错误请不吝指正！                                                                                2012.12.27于山西大同","title":"《Windows核心编程系列》十三谈谈在应用程序中使用虚拟内存"},{"content":"setup中选中的是开机启动的服务 service：常驻内存的进程，service必然有对应的daemon（守护进程）， daemon分两类： stand_alone: 一直在内存中，反应较快 super daemon: 用一个特殊的super daemon（由xinetd进程实现）管理，客户端请求的时候才唤醒，客户端请求结束后服务关闭。反应较慢 xinetd用来管理其他daemon，其本身是一个stand_alone的daemon daemon命名：相应service名后面加d ----------------------------------------------------------------------------------------------------------------------- 端口：用来分辨不用的服务请求（同一个网址用www和用ftp访问端口就不一样，www默认端口号：80） 端口号对应在  /etc/services  ,不建议修改 一些目录： /etc/init.d                       启动脚本放置处,所有服務的預設啟動 script 都是放在這裡的， /etc/sysconfig/*           各种服务初始化环境配置文件 /etc/xinetd.conf,     /etc/xinetd.d/*      super daemon 配置文件 ----------------------------------------------------------------------------------------------------------------------- stand_alone 服务的启动：（有时只有sudo才可以） 1. /etc/init.d/* (start|stop|restart|...)    2.用service 启动，service只是一个script，可以分析后面的参数 用法：  service [service name]  (start|stop|restart|...)               service --status-all         显示所有stand alone服务 super daemon管理的服务的启动： step1.  修改配置文件 /etc/xinetd.d/*  ,设置\"disable=no\"        step2.  修改完配置后要重启xinetd （需要sudo） 查看哪些已启动：grep -i 'disable'   /etc/xinetd.d/* ----------------------------------------------------------------------------------------------------------------------- 防火墙配置 主要通过两个文件：/etc/hosts.allow     /etc/hosts.deny 格式：  <服务（程序名）> : <IP / 域 / 主机名> : <操作> 一般把允许的IP放在hosts.allow，拒绝的放在hosts.deny 例如：  vi /etc/hosts.allow     rsync: 192.168.0.0/255.255.255.0 : allow     ======》后面的“: allow” 可以省略，因为是在hosts.allow中，默认就是allow ----------------------------------------------------------------------------------------------------------------------- 查看系统启动的服务 查看网络服务： netstat -tulp 查看监听服务： netstat -lnp 查看所有服务： service --status-all  ----------------------------------------------------------------------------------------------------------------------- 设置开机启动的服务  （使用chkconfig） 查看rsunc是否已经启动       netstat -tlup |grep rsync 查看是否默认启动：              chkconfig --list rsync 关闭服务自启动：                  chkconfig rsync off                                                   service xinetd restart  （不要忘了这一步） 可以在setup中选中，则开机启动","title":"认识Linux系统服务（鸟哥18章）"},{"content":"  这里说下Linux 系统怎么通过openssl命令生成 证书。   首先执行如下命令生成一个key   openssl genrsa -des3 -out ssl.key 1024   然后他会要求你输入这个key文件的密码。不推荐输入。因为以后要给nginx使用。每次reload nginx配置时候都要你验证这个PAM密码的。   由于生成时候必须输入密码。你可以输入后 再删掉。   mv ssl.key xxx.key   openssl rsa -in xxx.key -out ssl.key    rm xxx.key    然后根据这个key文件生成证书请求文件    openssl req -new -key ssl.key -out ssl.csr    以上命令生成时候要填很多东西 一个个看着写吧（可以随便，毕竟这是自己生成的证书）     最后根据这2个文件生成crt证书文件    openssl x509 -req -days 365 -in ssl.csr -signkey ssl.key -out ssl.crt     这里365是证书有效期 推荐3650哈哈。这个大家随意。最后使用到的文件是key和crt文件。     如果需要用pfx 可以用以下命令生成     openssl pkcs12 -export -inkey ssl.key -in ssl.crt -out ssl.pfx     在需要使用证书的nginx配置文件的server节点里加入以下配置就可以了。    ssl on;    ssl_certificate /home/ssl.crt;    ssl_certificate_key /home/ssl.key;    ssl_session_timeout 5m;    ssl_protocols SSLv2 SSLv3 TLSv1;    ssl_ciphers ALL:!ADH:!EXPORT56:RC4+RSA:+HIGH:+MEDIUM:+LOW:+SSLv2:+EXP;    ssl_prefer_server_ciphers on;     然后重启nginx就大功告成了","title":"自己制作ssl证书：自己签发免费ssl证书，为nginx生成自签名ssl证书"},{"content":"        以Xen虚拟系统安装树为例         在Xen虚拟机半虚拟化环境中安装Linux虚拟系统时需要使用系统安装树         安装树是一个目录，包含了所有系统的安装文件及相关程序         这个目录可以使用HTTP、FTP和NFS等方式提供给Xen虚拟机用于系统的安装                 配置步骤如下：                     ① yum install httpd                                                                                                      ② service httpd start                启动 httpd：                                               [确定]                            ③ mkdir /var/www/html/rhel                         ④ mount -o loop /mnt/hgfs/vmshare/rhel-server-5.8-i386-dvd.iso /var/www/html/rhel/                         ⑤ df -h              文件系统              容量  已用 可用 已用% 挂载点              /dev/sda2             9.5G  7.5G  1.6G  83% /              /dev/sda1              99M   13M   81M  14% /boot              tmpfs                 506M     0  506M   0% /dev/shm              none                  506M  104K  506M   1% /var/lib/xenstored              .host:/               170G   47G  123G  28% /mnt/hgfs              /mnt/hgfs/vmshare/rhel-server-5.8-i386-dvd.iso                                    3.3G  3.3G     0 100% /var/www/html/rhel                                                ⑥ service httpd restart                停止 httpd：                                               [确定]                启动 httpd：                                               [确定]                            ⑦ firefox 192.168.1.114/rhel                                   ","title":"Linux 系统安装树的创建"},{"content":"命令报错时就用sudo，切记！ 因为这个浪费了N多时间，ca…… OS:fedora17.i686 & fedora17.x86_64 现在已经改成不用 imapXXXX的了 改成 守护进程rpc.nfsd 安装守护进程程序:... ---------------------------------------------------------------------------------------------------------------------------------- 搜索:yum search nfs 得到:nfs-utils.i686 : NFS utilities and supporting clients and daemons for the kernel NFS server 看描述就是这货了. 安装:yum install nfs-utils  使用: rpc.nfsd [数量]        #设置最大线程 man 8 rpc.nfsd        #查看 帮助 ---------------------------------------------------------------------------------------------------------------------------------- 配置可用NFS服务器的目录 vi /etc/exports   加入允许被其他计算机访问的目录和访问权限 如： /home 192.168.0.*  (rw,sync,no_root_squash)    这些地址可以访问/home,()内表示权限限制 ro/rw:  只读/可读可写 sync:同步写磁盘（允许修改） no_root_squash:表示客户端root用户对该目录具有写权限 一般只改目录和IP，权限部分不做修改 ---------------------------------------------------------------------------------------------------------------------------------- 关闭防火墙：   sudo service iptables stop （若要在防火墙添加例外的话，编辑 /etc/hosts.allow   加入  nfs: 192.168.0.90，但实测无效！） ---------------------------------------------------------------------------------------------------------------------------------- 启用新的配置 exportfs 指令主要的三个作用： 1. exportfs -rv 重新读取共享配置文件，马上生效  2. exportfs -auv 马上停止所有本机上的NFS共享，并不改变 /etc/exports 文件的内容，只是当前停止共享 3. exportfs -av 显示所有当前机器上的NFS共享目录信息 ---------------------------------------------------------------------------------------------------------------------------------- 启动服务: sudo systemctl restart nfs-server.service 老版本的fedora（如14）：   su -c 'service nfs restart' 或?且    rpc.mountd  由于nfs通过rpc(Remote Procedure Call, 远程过程调用)协议来使用远程计算机上的文件，因此系统中的RPC服务必须启动 否则在下一步挂载可能出现:          mount.nfs: access denied by server while mounting 127.0.0.1:/home ---------------------------------------------------------------------------------------------------------------------------------- 挂载  (在其他机子上挂载本机共享的目录) mount -t nfs 127.0.0.1:/home    /mnt/share #将127.0.0.1:/home 挂载到本机的/mnt/share目录下 像/home/tom/doc/nfsroot 这样的目录必须保证这条路径所有文件夹都是有相应的权限的. chmod -R或许会用得着  卸载:   umount /mnt/share 开机时自动挂载:      vi /etc/fstab 192.168.0.90:/etc  /mnt/share  nfs   ro    0  0 ---------------------------------------------------------------------------------------------------------------------------------- 参考原文：http://zodiac1111.github.com/blog/2012/09/17/linux-fedora-17-install-nfs-server/","title":"Linux/Fedora 17下安装配置NFS服务器"},{"content":"作者:zhanhailiang 日期:2012-12-27 今天新来的产品的同事因业务需求需要将她的Window系统连上我们的开发机Linux，自然需要在Samba里添加一个新用户。 linux-06bq:/usr/local/services/samba/bin # ./smbpasswd -a sunjingNew SMB password:Retype new SMB password:Failed to add entry for user sunjing. 百度给出的结论是”添加的Samba用户首先必须是Linux用户”，一下子豁朗开郎。 linux-06bq:/etc/samba # useradd sunjinglinux-06bq:/usr/local/services/samba/bin # ./smbpasswd -a sunjingNew SMB password:Retype new SMB password:Added user sunjing. 接下来在Windows机器上【控制面板】→【凭证管理器】中添加Windows凭证： 网络地址：xxx.xxx.xxx.xxx(即需要连接的Linux开发机的IP)用户名：sunjing密码：给Samba添加sunjing用户时设置的密码 最后，在【资源管理器】里直接【映射网络驱动器】，连上开发机即可。 smbpasswd命令的常用方法 smbpasswd -a 增加用户（要增加的用户必须以是系统用户）smbpasswd -d 冻结用户，就是这个用户不能在登录了smbpasswd -e 恢复用户，解冻用户，让冻结的用户可以在使用smbpasswd -n 把用户的密码设置成空.             要在global中写入 null passwords -truesmbpasswd -x  删除用户 参考文档： 如何在samba服务器上添加用户(修正版)","title":"如何添加Samba用户"},{"content":"1、netstart -ano | grep 8383 查看 2、杀：lsof -i :8383|grep -v \"PID\"|awk '{print \"kill -9\",$2}'|sh ","title":"tomcat6端口被占用"},{"content":"Linux下自带的PHP不支持HTTP库，需要自己安装 pecl_http组件安装步骤如下：         1. 组件安装       1.1 安装php-devel开发组件           yum install php-devel       1.2 安装php-pecl组件           yum install php-pecl-memcache       1.3 安装pecl_http的扩展包           pecl install pecl_http           命令pecl install pecl_http的安装过程中可能会出现如下的错误：           a. configure: error: could not find zlib.h           解决方法: yum install zlib-devel           b.  configure: error: could not find curl/curl.h           解决方法: yum install curl-devel     2. 组件配置      pecl install pecl_http成功结束后执行如下命令，添加php对http.so的支持       touch /etc/php.d/http.ini       echo \"; Enable http extension module\" >> /etc/php.d/http.ini       echo \"extension=http.so\" >> /etc/php.d/http.ini 官网参考文档：http://cn2.php.net/manual/zh/book.http.php","title":"Linux下 PHP 安装pecl_http方法"},{"content":"1、cmd进入tomcat bin目录 有一个service.bat ，在中然后执行 service install tomcat6  启动服务 net start tomcat6 关闭服务 net stop tomcat6","title":"tomcat6注册服务//"},{"content":"1、在window 7 上搭建CVS服务器的时候，创建用户的时候要run cmd as administrator，否则无法创建cvs用户。 命令是： set cvsroot=c:\\cvsroot cvs passwd -r SystemUserName -a CVSUSerName 2、在import项目进入CVS服务期的时候，要注意，psd，wav这些文件默认为文本文件，如果直接导入，会造成文件破损。要import as binary。 3、如果binay已经被按照文本导入，在客户端删除，这些破损的文件，commit到服务器，再把这些binary拷贝的工作文件加，选择add selected as binary。commit到服务器即可。","title":"CVS 服务器搭建及使用"},{"content":"先来说下场景，需要写一个爬虫，定时从某个接口地址获取数据，然后存入本地数据库。 因此就需要一个可定时执行的东西，之前在the5fire的知识体系中除了可以在数据库中定时执行某个存储过程或者sql语句，如何在系统中定时执行某个任务还没有概念。 于是，请教了同事。知道在ubuntu中，准确的说是在linux中，有这么东西——crontab，专门用来定制执行任务。简单解说一番，就会用了。 虽然这个东西比较简单，但为了保证知识体系的完整，还是要查查crontab是个什么。 crontab单词的意思是：定时任务。 crontab命令常见于Unix和类Unix的操作系统之中，用于设置周期性被执行的指令。该命令从标准输入设备读取指令，并将其存放于“crontab”文件中，以供之后读取和执行。该词来源于希腊语 chronos(χρόνος)，原意是时间。 通常，crontab储存的指令被守护进程激活， crond常常在后台运行，每一分钟检查是否有预定的作业需要执行。这类作业一般称为cron jobs。 有了上面的概念，再来看crontab的使用就会清晰些。 既然是系统每分钟都要检查一下，那么必然要有一个检查的依据，如配置文件或者什么的。 还是来看看百科： crontab文件包含送交cron守护进程的一系列作业和指令。每个用户可以拥有自己的crontab文件；同时，操作系统保存一个针对整个系统的crontab文件，该文件通常存放于/etc或者/etc之下的子目录中，而这个文件只能由系统管理员来修改。 　　crontab文件的每一行均遵守特定的格式，由空格或tab分隔为数个领域，每个领域可以放置单一或多个数值。 好了，开始使用了。估计有些人从定义就知道他要怎么用了。不过我还是想记录下。 使用步骤： 1、终端运行crontab -e [解释：编辑配置文件] 2、选择你要用的编辑器，一般人会选择vi。 3、此时配置文件已打开，只需要按照他的格式写配置即可。 好吧，简单到我都觉得。。 举个例子： 在我的home目录下有一个python脚本，helloworld.py    #coding:utf-8    print 'hello world by crontab!' 我想要这个脚本在每天的早上7点30执行。 因此这个 任务的crontab配置文件就是：    # m h  dom mon dow   command    30 7 * * * python /home/the5fire/testcrontab.py >>/home/the5fire/testcrontab.log 2>&1 简单解释下，这个配置的意思就是在每天的7：30用python运行我的家目录下的testcrontab.py文件，并将输出内容输出到testcrontab.log中，后面那个2>&1的意思是把错误的输出也输出到标准输出（2表示错误，2>表示错误输出，&表示等同于，1表示正确），因此如果运行出错也会把错误输出到之前定义的log中。 另外关于合适执行命令还有些要说。 上面只是定时几点执行，那么我怎么设置它按照某一频率执行。比如每分钟执行依次。 对应的配置就是    # m h  dom mon dow   command    */1 * * * * python /home/the5fire/testcrontab.py >>/home/the5fire/testcrontab.log 2>&1 再来一个场景，我想在每天的早上六点到八点之间，每隔3分钟执行一次的配置怎么写：    # m h  dom mon dow   command    */3 6-8 * * * python /home/the5fire/testcrontab.py >>/home/the5fire/testcrontab.log 2>&1 到此应该都会使用了吧，五个星号表示不同的执行单位(分、时、日、月、年)，而那个反斜线表示频率。","title":"ubuntu定时执行任务crontab的使用"},{"content":"什么是Ubuntu? 简要的说,ubuntu是linux的一种，什么是linux,好吧，你还不适合装ubuntu 为什么要用Ubuntu？ 首先，开章明义，并不是所有的人都适全用Ubunt。我总结了一下，适合用的人主要有 一、想欢乱装系统的人。（我想他们也不需要看我这文章了） 二、想真正学习电脑的人（如想明白电脑的启动过程是怎么样的，NTFS、fat是什么，它们和LINUX的文件有什么不同，为什么windows要磁盘碎片整理，为什么linux不用，为什么Linux中病毒的可能性比中彩票还难等等） 三、要学Linux／unix编程的人 四、感觉windows很难看的人。 五、想在本地做个服务器的人。 最后，还有一点要说的，linux刚开如学的时候，会不习惯，主要是安软件的方式（对于普通的桌面用户来说），连续用一个月左右就会感觉windows不习惯了，哈哈。 好了，开始进入正题吧 这次我们先用WUBI安装，什么是WUBI?简单的来说，就是相当于把ubuntu当成一个软件来安装在windows下，之所以不教大家直接安装在真实的硬盘，是因为一方面，我想减少大家初学linux的压力，所以没有必要马上安装到真机上。另一方面，我知道，有一部分同学会觉得ubuntu不适合他们，到时要是想删除，就不像WUBI安装的方式这么容易。 1、软件准备： （A）Ubuntuiso安装光盘 下载：这里有几个地址： 电子科技大学的同学可到栋力无限的linux源下：http://ubuntu.dormforce.net/iso/12.04/（推荐） 外校的可到163源下：http://mirrors.163.com/ubuntu-releases/12.04 选ubuntu-12.04.1-desktop-i386,iso(图中，倒数第三个）下载   （B）ultraiso (有虚拟光驱的同学不需要下） 下载：http://www.crsky.com/soft/1134.html 2、安装 打开ultraiso后（选继续试用），文件－打开，选择刚下的ubuntu镜像，打开 将wubi拉出来，关闭ultaiso 打开wubi,选择ubuntu安装位置，安装大小（建议选一点），填写好密码 安装。重启电脑。 重启后，界面如下 选择中文（简体）－>安装ubuntu->继续－>清除整个磁盘并安装Ubuntu(这里只是在WUBI虚拟安装，所谓的整个盘，只是你给的一个文件，放心选这个）之后就按提示安装，（一定要把网线给断了，不然安装时会自动边网，那你就慢慢等吧） 大约十分钟，就安装好了（没边网线的情况下） 重启，选择Ubuntu系统，输入密码、进入系统，大概是这个样子   总算安好了。 QQ怎么安啊？？ 看不了电影啊！！ 升级怎么这么慢啊！！ 写了这么久，好累啊。下次再写，当然，十分欢迎邮件交流： 2575029833＠qq.com","title":"在windows下安装ubuntu 12.04的方法"},{"content":"1：根据进程名显示进程号 [root@web151 ~]# pidof java 31786 25034 11931 2：如何限制用户的最小密码长度 修改/etc/login.defs里面的PASS_MIN_LEN的值。比如限制用户最小密码长度是8： PASS_MIN_LEN 8 3：如何使新用户首次登陆后强制修改密码 #useradd -p '' testuser; chage -d 0 testuser 4：更改Linux启动时用图形界面还是字符界面 cd /etc vi inittab 将id:5:initdefault: 其中5表示默认图形界面 改id:3: initdefault: 3表示字符界面 5：禁止在后台使用CTRL-ALT-DELETE重起机器 cd /etc/inittab vi inittab 在文件找到下面一行 # Trap CTRL-ALT-DELETE ca::ctrlaltdel:/sbin/shutdown -t3 -r now （注释掉这一行） 如： # Trap CTRL-ALT-DELETE #ca::ctrlaltdel:/sbin/shutdown -t3 -r now 6：防止任何人使用su 命令成为root vi /etc/pam.d/su，在开头添加下面两行： auth sufficient /lib/security/pam_rootok.so auth required /lib/security/Pam_wheel.so group=wheel 然后把用户添加到\"wheel\"组：chmod -G10 usernam 7：设定登录黑名单 vi /etc/pam.d/sshd 增加 auth required /lib/security/pam_listfile.so item=user sense=deny file=/etc/sshd_user_deny_list onerr=succeed 所有/etc/sshd_user_deny_list里面的用户被拒绝ssh登录 8：禁止某个用户通过ssh登录 在/etc/ssh/sshd_conf添加 AllowUsers 用户名 或者 AllowGroups 组名 或者 DenyUsers 用户名 9：只允许某个IP登录，拒绝其他所有IP 在 /etc/hosts.allow 写: sshd: 1.2.3.4 在 /etc/hosts.deny 写: sshd: ALL 用 iptables 也行: iptables -I INPUT -p tcp -dport 22 -j DROP iptables -I INPUT -p tcp -dport 22 -s 1.2.3.4 -j ACCEPT 10：实现RedHat非正常关机的自动磁盘修复 先登录到服务器，然后在/etc/sysconfig里增加一个文件autofsck,内容如下： AUTOFSCK_DEF_CHECK=yes PROMPT=yes 1：根据进程名显示进程号 [root@web151 ~]# pidof java 31786 25034 11931 2：如何限制用户的最小密码长度 修改/etc/login.defs里面的PASS_MIN_LEN的值。比如限制用户最小密码长度是8： PASS_MIN_LEN 8 3：如何使新用户首次登陆后强制修改密码 #useradd -p '' testuser; chage -d 0 testuser 4：更改Linux启动时用图形界面还是字符界面 cd /etc vi inittab 将id:5:initdefault: 其中5表示默认图形界面 改id:3: initdefault: 3表示字符界面 5：禁止在后台使用CTRL-ALT-DELETE重起机器 cd /etc/inittab vi inittab 在文件找到下面一行 # Trap CTRL-ALT-DELETE ca::ctrlaltdel:/sbin/shutdown -t3 -r now （注释掉这一行） 如： # Trap CTRL-ALT-DELETE #ca::ctrlaltdel:/sbin/shutdown -t3 -r now 6：防止任何人使用su 命令成为root vi /etc/pam.d/su，在开头添加下面两行： auth sufficient /lib/security/pam_rootok.so auth required /lib/security/Pam_wheel.so group=wheel 然后把用户添加到\"wheel\"组：chmod -G10 usernam 7：设定登录黑名单 vi /etc/pam.d/sshd 增加 auth required /lib/security/pam_listfile.so item=user sense=deny file=/etc/sshd_user_deny_list onerr=succeed 所有/etc/sshd_user_deny_list里面的用户被拒绝ssh登录 8：禁止某个用户通过ssh登录 在/etc/ssh/sshd_conf添加 AllowUsers 用户名 或者 AllowGroups 组名 或者 DenyUsers 用户名 9：只允许某个IP登录，拒绝其他所有IP 在 /etc/hosts.allow 写: sshd: 1.2.3.4 在 /etc/hosts.deny 写: sshd: ALL 用 iptables 也行: iptables -I INPUT -p tcp -dport 22 -j DROP iptables -I INPUT -p tcp -dport 22 -s 1.2.3.4 -j ACCEPT 10：实现RedHat非正常关机的自动磁盘修复 先登录到服务器，然后在/etc/sysconfig里增加一个文件autofsck,内容如下： AUTOFSCK_DEF_CHECK=yes PROMPT=yes","title":"Linux 操作技巧"},{"content":"$request_uri This variable is equal to the *original* request URI as received from the client including the args. It cannot be modified. Look at $uri for the post-rewrite/altered URI. Does not include host name. Example: \"/foo/bar.php?arg=baz\" $uri This variable is the current request URI, without any arguments(see $args for those). This variable will reflect any modifications done so far by internal redirects or theindex module. Note this may be different from $request_uri, as $request_uri is what was originally sent by the browser before any such modifications. Does not include the protocol or host name. Example:/foo/bar.html $args This variable is the GET parameters in request line, e.g. foo=123&bar=blahblah; This variable could be changed.   You can check them by adding the variable in log_format and finding out the value in the tail of access.log ! Do you get it??It's amazing!!!   参考： http://wiki.nginx.org/HttpCoreModule#.24request_uri http://blog.sina.com.cn/s/blog_4ff12f66010158lk.html  ","title":"$request_uri和$uri"},{"content":"1, yum不能安装django 解决：需要安装yum的EPEL源 2, httpd.conf的配置稍显麻烦 解决：按照django的部署文档进行配置。另外比较方便的是把django的project放到/usr/local/django/mysite下，也就是说把这个目录作为django的project目录。 3, 如果有数据库，比如redis，由于SELinux阻止，httpd不能访问redis，会报\"403 Permission denied\"错误。 解决：执行setsebool -P httpd_can_network_connect 1 和 setsebool -P httpd_can_network_connect_db 1，使httpd能够使用网络链接和数据库连接（没时间试是不是启用一个就行了）。 # 另外用yum install redis安装的redis本身就是配置好了的，不需要另创建配置文件，而且已经配置成了只能在本地访问，如果需要外部访问需要修改。","title":"通过django-wsgi部署在apache上碰到的问题和解决方法"},{"content":"我的U盘插上后， fdisk -l查看U盘信息得知是/dev/sdb 先将U盘制作分区表。 fdisk/dev/sdb   用p命令查看得知有一个fat32分区， 将他去掉，用d命令， 然后用n命令新增加一个主分区， n后选择p（primarypartition）， 然后Partition number (1-4): 1， 再用n命令新增加第二个主分区， 然后用a命令，把第一个和第二个主分区设置为可引导。 最后用w命令写入。   格式化分区为ext3， mkfs -t ext3/dev/sdb1 mkfs -text3 /dev/sdb2   然后挂载系统 mkdir/mnt/sdb1 mount -text3 /dev/sdb1 /mnt/sdb1 mkdir/mnt/sdb2 mount -text3 /dev/sdb2 /mnt/sdb2   然后将bt5光盘解开后，把casper和preseed文件夹拷贝到第一个分区的根目录下。 将linux deepin的整个光盘iso文件放入第二个分区的根目录下。   然后先安装grub到/mnt/sdb1 grub-install --root-directory=/mnt/sdb1 /dev/sdb   将/boot/grub/grub.conf拷贝到，u盘上对应的目录下 然后编辑grub.conf   timeout         20default         0title           Windows 7map             (hd0) (hd1)map             (hd1) (hd0)rootnoverify    (hd1,0)makeactivechainloader     +1title backtrack 5root (hd0,0)kernel/casper/vmlinuz root=/dev/sdb1 file=/preseed/custom.seed boot=casperlocale=zh_CN text--initrd/casper/initrd.gztitle linux deepinroot (hd0,1)kernel/boot/grub/core.imgsavedefaultboot 这个配置文件就是说明，U盘第一个分区用grub引导的bt5，U盘第二个分区由grub引导core.img 然后引导交给core.img，这个core.img是grub2的img。 此时第二个分区上还没有core.img，这个会在后面创建，我们先这样写。   然后将grub安装到MBR上， 输入grub命令 grub> root(hd1,0) Filesystem type is ext2fs, partition type 0x83 grub> setup (hd1) Checking if \"/boot/grub/stage1\"exists... yes Checking if \"/boot/grub/stage2\"exists... yes Checking if\"/boot/grub/e2fs_stage1_5\" exists... yes Running \"embed /boot/grub/e2fs_stage1_5(hd1)\"...  15 sectors are embedded.succeeded Running \"install /boot/grub/stage1 (hd1)(hd1)1+15 p (hd1,0)/boot/grub/stage2 /boot/grub/grub.conf\"... succeededDone.grub> quit 然后插着U盘重启系统，就应该可以顺利进入bt5系统了，bt5是基于ubuntu的，进入系统后， 将grub2写入第二个分区。 grub-install --root-directory=/mnt/sdb2 /dev/sdb 此时写入的是grub2。 然后编辑grub2的配置文件，grub.cfg，此文件内容如下： ## DO NOT EDIT THISFILE## It isautomatically generated by /usr/sbin/grub-mkconfig using templates# from /etc/grub.dand settings from /etc/default/grub#### BEGIN/etc/grub.d/00_header ###set timeout=10### END/etc/grub.d/00_header ### ### BEGIN/etc/grub.d/05_debian_theme ###setmenu_color_normal=white/blacksetmenu_color_highlight=black/light-gray### END/etc/grub.d/05_debian_theme ### ### BEGIN/etc/grub.d/10_linux ###menuentry\"linux deepin\" {loopbackloop (hd0,2)/deepin_12.06_zh-hans_i386.isolinux(loop)/casper/vmlinuz boot=casperiso-scan/filename=/deepin_12.06_zh-hans_i386.iso locale=zh_CN.UTF-8 nopromptnoejectinitrd(loop)/casper/initrd.lz} grub的配置文件里分区是(hd0,0)，而grub2的配置文件里分区是 (hd0,2)，因为grub里面分区从0开始，而grub2里面分区是从1开始的。 此时grub2的MBR会覆盖掉grub的MBR，所以我们需要重启系统，进入一个正常的linux系统， 然后再执行一遍安装grub到MBR的命令，将grub的MBR覆盖掉grub2的MBR。 grub> root(hd1,0) Filesystem type is ext2fs, partition type 0x83 grub> setup (hd1) Checking if \"/boot/grub/stage1\"exists... yes Checking if \"/boot/grub/stage2\"exists... yes Checking if\"/boot/grub/e2fs_stage1_5\" exists... yes Running \"embed /boot/grub/e2fs_stage1_5(hd1)\"...  15 sectors are embedded.succeeded Running \"install /boot/grub/stage1 (hd1)(hd1)1+15 p (hd1,0)/boot/grub/stage2 /boot/grub/grub.conf\"... succeededDone.grub> quit此时再重启，你就拥有了双linux系统的U盘。","title":"利用grub和grub2制作双系统的启动U盘"},{"content":"突然发现，之前那个文件夹中的文件名也是要修改的。。。so，又写了一个脚本。欢迎拍砖讨论！ #! /usr/bin/env python## This is a .py file to replace a letter or a word with the letter# or the word provided## Author: luotuo# Date: 2012.12.26#import sysimport osdef usage():    print \"Usage:\"    print \"./rename argv[1] argv[2] argv[3]\"    print \"Here, argv[1] is the dirctory you choose\"    print \"argv[2] is the letter or word you want to replace\"    print \"argv[3] is the letter or word you want to use\"    def traversal_dir(dir, old_word, new_word):    list_dir = os.listdir(dir)    for l in list_dir:        if os.path.isfile(os.path.join(dir, l)):            rename(os.path.join(dir, l), old_word, new_word)        else:            path = os.path.join(dir, l)            traversal_dir(path, old_word, new_word)            def rename(filename, old_word, new_word):    if os.path.basename(filename).find(old_word) == -1:        return    else:        name = os.path.basename(filename)        name = name.replace(old_word, new_word)        name = \"/\" + name        #print os.path.dirname(filename)        full_name = os.path.dirname(filename) + name        #print full_name        os.rename(filename, full_name)def main(argv):    if len(argv) != 3:        print \"Please see the Usage\"        usage()    else:        old_word = argv[1]        new_word = argv[2]        if os.path.isfile(argv[0]):            rename(argv[0], old_word, new_word)        else:            # argv[0] is a directory            dir = argv[0]            # traversal it            traversal_dir(dir, old_word, new_word)if __name__ == '__main__':    main(sys.argv[1:])","title":"修改文件名中的字段"},{"content":"实验室干活儿，突然有需求，要修改一个文件夹下N个文件（我也不知道有多少个，木有数过）中的同一个word，so，写了一个这个玩意儿。。。欢迎讨论和拍砖！发现自己要多看看Python的doc了。。。 #! /usr/bin/env python## This is .py file for modifying words in a directory## Author: luotuo# Date: 2012.12.26#import osimport sysdef print_usage():    print \"The Usage:\"    print \"./modify_words argv1 argv2 argv3\"    print \"Here, argv1 is the directory or file you want to modify\"    print \"argv2 is the word you want to modify\"    print \"argv3 is the new word you want to use\"    def traversal_dir(dir, old_word, new_word):    dir_list = os.listdir(dir)    for l in dir_list:        if os.path.isfile(os.path.join(dir, l)):            # Open it and replace            path = os.path.join(dir, l)            replace_word(path, old_word, new_word)        else:            path = os.path.join(dir, l)            traversal_dir(path, old_word, new_word)def replace_word(file, old_word, new_word):    try:        f = open(file, 'r')        path = os.path.dirname(file)        filename = \"/temp_\" + os.path.basename(file)        filename = path + filename        f_temp = open(filename, 'w')        # FIXME: It can be optimized later        for line in f.readlines():            line = line.replace(old_word, new_word)            if line:                f_temp.write(line)        f.close()        name = \"/\" + os.path.basename(file)        os.remove(file)        f_temp.close()        os.rename(filename, path+name)    except:        print \"There is something wrong!\"def main(argv):    # check sys.argv    # argv[0]: directory or file    # argv[1]: old words    # argv[2]: new words    if len(argv) != 3:        print \"The arguments are wrong!\"        print_usage()        sys.exit(1)    else:        # handle it        dest = argv[0]        old_word = argv[1]        new_word = argv[2]        # check if the argv[0] is a directory or not        if os.path.isdir(dest):            # Traversal the directory            traversal_dir(dest, old_word, new_word)        else:            # check if the argv[0] is a file or not            if os.path.isfile(dest):                # Open it and replace the word                replace_word(dest, old_word, new_word)            else:                print_usage()                sys.exit(1)if __name__ == '__main__':    main(sys.argv[1:])","title":"修改文本文件中的word"},{"content":"【fedora16亲测成功】 NFS：linux 和linux之间共享文件 Samba： linux和win之间，win和win之间 一 安装如下软件包 samba服务器ip为 192.168.100.105 [root@jumper pub]# rpm -qa | grep samba samba-client-3.0.33-3.37.el5 samba-3.0.33-3.37.el5 samba-common-3.0.33-3.37.el5 二 修改配置文件 [root@jumper pub]# vi /etc/samba/smb.conf 找到[global]标签，添加内容： [global]         workgroup = WORKGROUP  //设置工作组         server string = %U's Samba %v   //描述信息，％U代表当前登陆用户         security = user   //安全级别，user需要用户名和密码，share级别则不要 log file = /var/log/Samba/log.%m     //日志文件保存路径％m你的windows主机名 max log size = 50    //日志最大容量 （其实[global]下的内容都是非必须的～） 找到 \" #============ Share Definitions ================= \" 这个位置 添加： [lzqSamba]                       //建立一个共享名为lzqSamba的共享 comment = lzq's image Samba   //描述信息 path = /home/lzq/image   //共享路径 public = no                     //是否允许guest用户访问（相当于guest ok = yes/no） valid users = lzq              //可用 writable = yes                //是否可写，如果不设置，默认也是可写 write list = lzq                //可以写入的用户列表（@代表用户组） 三 创建用户     首先确保用户名已经是系统用户     再将系统用户添加为samba用户 smbpasswd -a lzq    会提示输入密码     SAMBA用户的密码与系统用户的密码没任何关系，但是samba用户一定要首先是系统用户 重启samba服务：  sudo /etc/init.d/smb restart 四 客户端访问 1) 默认共享的是用户的家目录 即 /home/lzq 我在配置文件里又共享一个/home/lzq/image,所以可以看见两个共享目录 2) 在linux里查看samba共享 [root@jumper pub]# smbclient -L //192.168.100.105 -U smb Password:  Domain=[JUMPER] OS=[Unix] Server=[Samba 3.0.33-3.37.el5]         Sharename       Type      Comment         ---------       ----      -------         pub             Disk      Public Stuff         IPC$            IPC       IPC Service (Samba Server Version 3.0.33-3.37.el5)         smb             Disk      Home Directories Domain=[JUMPER] OS=[Unix] Server=[Samba 3.0.33-3.37.el5]         Server               Comment         ---------            -------         Workgroup            Master         ---------            -------         WORKGROUP            JUMPER 3) 在linux客户端挂载samba共享目录 [root@mo-nginx04 ~]# mount.cifs //192.168.100.105/pub /mnt -o username=smb Password:  [root@mo-nginx04 ~]# df -h Filesystem            Size  Used Avail Use% Mounted on /dev/sda2              48G  661M   45G   2% / /dev/sda6             161G   37G  116G  25% /opt /dev/sda3              48G  1.8G   44G   4% /usr /dev/sda1             388M   17M  351M   5% /boot tmpfs                 3.9G     0  3.9G   0% /dev/shm //192.168.100.105/pub                       825G  105G  679G  14% /mnt 4) 在windows客户端使用samba共享: 在ie浏览器(firefox貌似不行)里输入 \\\\192.168.100.105 ,再输入smb用户名,密码,就可以看见共享内容了. 或者在cmd里输入\\\\192.168.100.105 参考： http://www.linuxidc.com/Linux/2011-03/33636.htm","title":"liunx下安装配置Samba服务器"},{"content":"          今天浏览优秀博文 时看到这样一篇《克服敲代码之“痒”》，越读越是深刻体会到克制写代码的冲动的必要性。于是忍不住也要写一写自己近来做系统的心得。        如果说差劲的程序员有两种，一种是开始就写 main函数的；还有一种是上来就上网找各种类库源代码的。 那么，或许我就开创了第三种，就是还没弄清需求分析就直接上手了，实在是最差劲的了。清楚的记得当时做机房收费系统时，没有明白结账那块的关系，建数据库时没有建全，也没有考虑到要某些字段需加标记，不太清楚结账要将哪些数据进行怎样的处理，就这样开始做，做到后面更没有心情去分析了，在初步理解的情况下把结账部分做完了。结果，数据库搞得有点乱，程序更是不成样子，整个结账的功能算是废了，因为需求没弄明白，做出来的东西是不能要的。代码写的再好又怎样，还不是推倒重来，仔仔细细又分析了一遍，弄明白了其中的关系，然后再做感觉终于是顺了！        直接写代码确实很爽，很有成就感，可是正是应了那句话：前面写得越是爽，后面后果越严重。推倒重来舍不得，毕竟做了那么久又有好多重复性工作，想想都可怕，不重新做吧，眼前这个东西又不行，代码这东西，写的时候好写，改的时候可不好改，不然怎么有了“修改代码的艺术”呢？越发觉得软件设计流程、高内聚低耦合等等，凡是软件工程有所提及均为王道！        还有一个问题，便是注释。通过重新分析数据库、代码，我发现自己写的代码竟然有点不认识了。突然想起米老师的那句话：代码不只是给计算机看的，更是给人看的！为什么这么说，以前不懂，现在懂了。任何一款软件都不是一个人一天两天完成的，也不是一旦完成便永久不再理会。浩大的工程需要很多人花费很长时间去开发，开发完成后还要经过长时间的维护，直到软件生命周期结束。这个过程中，代码主要是给人看的。就算软件已被废弃，有时候我们还会参考它，需要看其中的代码。所以，原来那种想法实在是太幼稚了，正如做笔记，不是做过了便永久不再看了，写下来的东西不一定是自己的，它们的作用更是为了让我们再次阅读且易懂。        有开发经验不等于有职业素养。如果自己写的代码过上10天给自己看，会有恶心的感觉，那么恭喜自己吧，说明这里还需要提高，我们还有很大的提升空间！       不得不思考，真正的高手是如何完成一项任务的呢？","title":"第一次品尝到急于下手带来的苦果"},{"content":"//获取考勤机上所有用户id和姓名$webSource=file_get_contents(\"http://192.168.1.202/csl/query\");preg_match_all(\"/uid value=(\\d{1,})>/\",$webSource,$user);foreach($user[1] as $u)  $userStr.=$u.\",\";//获取考勤记录$webSource=file_get_contents(\"http://192.168.1.202/csl/query?action=run&uid={$userStr}&sdate=2012-12-26&edate=2012-12-26\");preg_match_all(\"/<td width=20%>(.*?)<\\/td>                        \t\t\t<td width=20%>(.*?)<\\/td>                  \t      \t\t\t<td width=20%>(.*?)<\\/td>\t\t\t\t\t\t<td width=10%>(.*?)<\\/td>/iU\",$webSource,$records);\t\t\t\tfor($i=0;$i<count($records[0]);$i++){\t$name=$records[3][$i]?$records[3][$i]:\"未录姓名\";\techo $name.\", \".$records[1][$i].\" \".$records[4][$i].\"<br>\";}\t 中控考勤机软件可以将考勤机记录实时下载到本地数据库里， 很让人恼怒的是考勤机软件经常与设备断开连接，断开还不会自动重连， 可考前太差了，之前的几种方案也都无从谈起了。 苦思之后，想起直接用考勤机ip访问有web页面。所以有了上面的代码。跨过考勤机软件。。  比读考勤软件的access数据库方便多了， 改天做好同步到通达OA的代码，分享~","title":"中控考勤机http方式读取考勤记录"},{"content":"ipconfig /flushdns     C:\\Users\\Administrator>ipconfig /flushdns Windows IP 配置 已成功刷新 DNS 解析缓存。 C:\\Users\\Administrator>   C:\\Users\\Administrator>ipconfig /displaydns Windows IP 配置 无法显示 DNS 解析缓存。  ","title":"清除本机DNS缓存"},{"content":"vmware 9 中安装好了solaris 10 u10后，虽然已经在虚拟机配置中为solaris指定了网卡及其类型，可是在solaris系统能却只能看到lo0，没有找到任何想要的e1000g0的东西。 解决方法如下： 1. 打开Solaris 10.vmx，找到如下内容 ethernet0.present = \"TRUE\" ethernet0.connectionType = \"nat\" ethernet0.virtualDev = \"e1000\" ethernet0.wakeOnPcktRcv = \"FALSE\" ethernet0.addressType = \"generated\"    确定设备标识为e1000。 2. 开启虚拟机，在/etc目录下查找hostname.e1000g0、/etc/dhcp.e1000g0文件，没有则创建，编辑hostname.e1000g0的内容为主机名。 3. 执行ifconfig e1000g0 plumb。 3. 执行ifconfig e1000g0 dhcp获取动态ip地址。 4. 重启，执行ifconfig e1000g0 dhcp status查看dhcp状态","title":"在虚拟机vmware中为solaris添加网卡备记"},{"content":"ipconfig /displaydns       记录名称. . . . . . . : blog.csdn.net     记录类型. . . . . . . : 1     生存时间. . . . . . . : 472     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 117.79.93.222     passport.csdn.net     ----------------------------------------     记录名称. . . . . . . : passport.csdn.net     记录类型. . . . . . . : 1     生存时间. . . . . . . : 281     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 117.79.93.208     mscrl.microsoft.com     ----------------------------------------     记录名称. . . . . . . : mscrl.microsoft.com     记录类型. . . . . . . : 5     生存时间. . . . . . . : 177     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     CNAME 记录  . . . . . : certrevoc.vo.msecnd.net     tajs.qq.com     ----------------------------------------     记录名称. . . . . . . : tajs.qq.com     记录类型. . . . . . . : 1     生存时间. . . . . . . : 1260     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 180.153.210.81     static.googleadsserving.cn     ----------------------------------------     记录名称. . . . . . . : static.googleadsserving.cn     记录类型. . . . . . . : 5     生存时间. . . . . . . : 171     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     CNAME 记录  . . . . . : pagead46.l.doubleclick.net     www.csdn.net     ----------------------------------------     记录名称. . . . . . . : www.csdn.net     记录类型. . . . . . . : 1     生存时间. . . . . . . : 6     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 117.79.93.222     pingtcss.qq.com     ----------------------------------------     记录名称. . . . . . . : pingtcss.qq.com     记录类型. . . . . . . : 1     生存时间. . . . . . . : 72     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 119.147.2.30     记录名称. . . . . . . : pingtcss.qq.com     记录类型. . . . . . . : 1     生存时间. . . . . . . : 72     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 183.60.7.169     a.pongo.cn     ----------------------------------------     记录名称. . . . . . . : a.pongo.cn     记录类型. . . . . . . : 1     生存时间. . . . . . . : 170     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 114.112.54.243     cgi.connect.qq.com     ----------------------------------------     记录名称. . . . . . . : cgi.connect.qq.com     记录类型. . . . . . . : 5     生存时间. . . . . . . : 32     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     CNAME 记录  . . . . . : webproxy-sz.qplus.com     api.csdn.net     ----------------------------------------     记录名称. . . . . . . : api.csdn.net     记录类型. . . . . . . : 1     生存时间. . . . . . . : 184     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 117.79.93.208     www.gstatic.com     ----------------------------------------     记录名称. . . . . . . : www.gstatic.com     记录类型. . . . . . . : 1     生存时间. . . . . . . : 174     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 74.125.128.120     pinghot.qq.com     ----------------------------------------     记录名称. . . . . . . : pinghot.qq.com     记录类型. . . . . . . : 5     生存时间. . . . . . . : 127     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     CNAME 记录  . . . . . : pingfore.qq.com     action.tenpay.com     ----------------------------------------     记录名称. . . . . . . : action.tenpay.com     记录类型. . . . . . . : 1     生存时间. . . . . . . : 4526     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 121.14.98.185     记录名称. . . . . . . : action.tenpay.com     记录类型. . . . . . . : 1     生存时间. . . . . . . : 4526     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 119.147.64.116     passport.pongo.cn     ----------------------------------------     记录名称. . . . . . . : passport.pongo.cn     记录类型. . . . . . . : 1     生存时间. . . . . . . : 442     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 114.112.54.235     pagead2.googlesyndication.com     ----------------------------------------     记录名称. . . . . . . : pagead2.googlesyndication.com     记录类型. . . . . . . : 5     生存时间. . . . . . . : 141     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     CNAME 记录  . . . . . : pagead46.l.doubleclick.net     hm.baidu.com     ----------------------------------------     记录名称. . . . . . . : hm.baidu.com     记录类型. . . . . . . : 5     生存时间. . . . . . . : 188     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     CNAME 记录  . . . . . : hm.e.shifen.com     counter.csdn.net     ----------------------------------------     记录名称. . . . . . . : counter.csdn.net     记录类型. . . . . . . : 1     生存时间. . . . . . . : 474     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 117.79.93.222     s117.cnzz.com     ----------------------------------------     记录名称. . . . . . . : s117.cnzz.com     记录类型. . . . . . . : 5     生存时间. . . . . . . : 11     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     CNAME 记录  . . . . . : c.cnzz.com     write.blog.csdn.net     ----------------------------------------     记录名称. . . . . . . : write.blog.csdn.net     记录类型. . . . . . . : 1     生存时间. . . . . . . : 511     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 117.79.93.222     cmdn.net     ----------------------------------------     记录名称. . . . . . . : cmdn.net     记录类型. . . . . . . : 1     生存时间. . . . . . . : 34     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 117.79.157.253     my.csdn.net     ----------------------------------------     记录名称. . . . . . . : my.csdn.net     记录类型. . . . . . . : 1     生存时间. . . . . . . : 52     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 117.79.93.196     img.my.csdn.net     ----------------------------------------     记录名称. . . . . . . : img.my.csdn.net     记录类型. . . . . . . : 1     生存时间. . . . . . . : 352     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 117.79.93.196     openapi.qzone.qq.com     ----------------------------------------     记录名称. . . . . . . : openapi.qzone.qq.com     记录类型. . . . . . . : 1     生存时间. . . . . . . : 183     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 119.147.79.31     c.cnzz.com     ----------------------------------------     记录名称. . . . . . . : c.cnzz.com     记录类型. . . . . . . : 5     生存时间. . . . . . . : 32     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     CNAME 记录  . . . . . : c.split.cnzz.com     csdnimg.cn     ----------------------------------------     记录名称. . . . . . . : csdnimg.cn     记录类型. . . . . . . : 1     生存时间. . . . . . . : 473     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 117.79.93.221     ptlogin2.qq.com     ----------------------------------------     记录名称. . . . . . . : ptlogin2.qq.com     记录类型. . . . . . . : 1     生存时间. . . . . . . : 53     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 121.14.76.234     记录名称. . . . . . . : ptlogin2.qq.com     记录类型. . . . . . . : 1     生存时间. . . . . . . : 53     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 123.151.45.43     记录名称. . . . . . . : ptlogin2.qq.com     记录类型. . . . . . . : 1     生存时间. . . . . . . : 53     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 183.60.3.162     记录名称. . . . . . . : ptlogin2.qq.com     记录类型. . . . . . . : 1     生存时间. . . . . . . : 53     数据长度. . . . . . . : 4     部分. . . . . . . . . : 答案     A (主机)记录  . . . . : 119.147.74.122   C:\\Users\\Administrator>  ","title":"显示本机DNS缓存"},{"content":"法一：使用Sniffer抓包       在网络中的任意一台主机上运行抓包软件，捕获所有到达本主机的数据包。如果发现某个IP不断发送ARP Request请求包，这台主机一定就是病毒源。          原理：无论是何种ARP病毒变种，行为方式主要有两种：一是欺骗网关，二是欺骗网内的所有主机。最终的结果是在网关的ARP缓存表中，网内所有活动主机的MAC地址均为中病毒主机的MAC地址；网内所有主机的ARP缓存表中，网关的MAC地址也都是中病毒主机的MAC地址。前者保证了从网关到网内主机的数据报被发送到中毒主机，后者则相反，使得主机发往网关的数据报均被发送到中毒主机。 方法二：使用arp -a命令       任意选择两台不能上网的主机，在命令提示符状态下运行arp -a命令，如果在结果中，两台电脑除了网关的IP，MAC地址对应项外，都包含了另外一个IP，这可以断定这个IP就是病毒源。          原理：一般情况下，网内的主机只和网关通信。正常情况下，一台主机的ARP缓存中应该只有网关的MAC地址。如果有了其他主机的MAC地址，说明本地主机和这台主机最近有过数据通信发生。如果某台主机既不是网关也不是服务器，但和网内的其他主机都有数据通信活动，且此时又是ARP病毒的发作时期，那么病毒源就是他了。 方法三：使用tracert命令       在任意一台受影响的主机上，在命令提示符状态下运行tracert命令，具体的命令行为：tracert IP（该IP为外网地址），在跟踪一个外网地址时，第一跳却是另一个IP（不是网关地址），则这个IP就是病毒源。          原理：中毒主机在受影响的主机和网关之间，扮演着“中间人”的角色。所有本应该到达网关的数据包，由于错误的MAC地址，均被发送到了中毒主机上，此时中毒主机在该网络中充当缺省网关的作用。","title":"网络中arp中毒的一些解决方法"},{"content":"选择Install or upgrade an existing system Skip Basic Storage Devices RHEL6 / CentOS6 / Oracle Linux 6 的网卡默认onboot=no,要勾上Connect automatically partition The \"Package Group Selection\" screen allows you to select the required package groups, and individual packages within the details section. When you've made your selection, click the \"Next\" button. If you want the server to have a regular gnome desktop you need to include the following package groups from the \"Desktops\" section: Desktops Desktop Desktop Platform Fonts General Purpose Desktop Graphical Administration Tools X Windows System reboot 最后关闭iptables和SELinux","title":"Oracle Linux 6 Installation"},{"content":"XML_Curl模块：         1 架构：freeswitch是由各个模块组成，xml_curl模块主要作用是可以实现将freeswitch的相关xml配置文件通过webserver的方式管理，如下图，当在freeswitch开启了xml_curl接口的时候，通过配置文件，比如将freeswitch的注册用户都通过webserver来管理，这样当有用户注册请求发给freeswitch的时候，就会向webserver发起request请求，webserver返回一个XML，从而实现对freeswitch的配置文件进行管理。                  2  如何配置：首先在源码的modules.conf开启mod_xml_curl模块，然后重新编译make/make install          #timers/mod_timerfd xml_int/mod_xml_cdr xml_int/mod_xml_curl #xml_int/mod_xml_ldap        3 在freeswitch的安装目录下：/usr/local/freeswitch/conf/autoload_configs，在该目录的xml_curl.conf.xml该配置文件中去配置FS的哪个配置文件需要去哪个Webserver获得配置文件，如用户配置，具体directory返回什么形式的XML，可参考 http://wiki.freeswitch.org/wiki/Mod_xml_curl  <binding name=\"directory\">      <param name=\"gateway-url\"             value=\"http://172.24.2.116:7001/cti/queryExtension.do\"                    bindings=\"directory\"/>       4  在将freeswitch启动的方式有两种方式启动该模块，一种临时开启，当freeswitch启动后，修改了第三步的xml后请过fs cli连接到FS的控制台后，通过reload xml使修改后的xml生效，然后通过reload mod_xml_curl使其模块开启，还可以通过xml_curl debug_on将其Debug模式打开，观察详细的日志。 http_cache 模块       配置类似于xml_curl模块，详细参考 http://wiki.freeswitch.org/wiki/Mod_http_cache     ","title":"Freeswitch的http_cache模块与xml_curl模块"},{"content":"    安装时遇到“无效驱动器 W:” （盘符可能有很多种情况）。这是我ghost装Win7后， 在安装 jdk 时候遇见的， 这个问题也导致了 word 不能正常打开文件， 很多软件无法 安装。     解决方法是，首先，     win7： 开始》右键打开 计算机 属性 》 左边的 高级系统设置     xp： 右键打开桌面上 我的电脑 的属性 》 高级 选项卡     然后，打开“环境变量”，应该会发现当前用户的环境变量里个 TEMP 和 TMP 两个 环境变量，值是报错的那个W:\\userTemp （视个人情况而定）,系统变量里面也有 TEMP  和 TMP ，值是 W:\\sysTemp。     由于W：不存在导致的，把它改成你现有的某个盘就可以了，比如改成 C:\\userTemp 和 C:\\sysTemp 。     记得两个都要改！","title":"无效驱动器 问题"},{"content":"引言 在用svn做版本库控制期间，遇到了新建版本库无法提交代码的bug，追查原因发现是权限设置问题，记录一下rwx针对文件和目录的权限设置 一般权限 r(read,读取) 对文件而言，具有读取文件内容的权限 对目录而言，具有浏览目录结构的权限 w(write,写入) 对文件而言，具有新增、修改文件内容的权限 对目录而言，具有删除、移动目录内文件的权限 x(execute,执行) 对文件而言，具有文件执行的权限 对目录而言，该用户具有进入目录的权限","title":"linux下的文件和目录权限"},{"content":"有时候我们会觉得系统响应很慢，但是又找不到原因，这时就要查平均负载了，看它是否有大量的进程在排队等待。 查看Linux系统的平均负载 1.平均负载的概念 有时候我们会觉得系统响应很慢，但是又找不到原因，这时就要查平均负载了，看它是否有大量的进程在排队等待。特定的时间间隔内运行队列中的平均进程数可以反映系统的繁忙程度，所以我们通常会在自己的网站或系统变慢时第一时间查系统的负载，即CPU的平均负载。 2.查看平均负载 究竟应该如何查看平均负载呢？最简单的命令是uptime，如下所示： [root@localhost ~]# uptime    11:31:11 up 11 days, 19:01,2 users,load average: 0.02, 0.01, 0.00  目前的主流服务器都是双4核，有相当强悍的CPU，做一般的应用服务的话，Linux系统的负载这块倒不用我们担心。 还可以用w命令来查看，顺便可以查看一下系统当前有哪些用户，他们占用了哪些终端，如下所示： [root@localhost ~]# w  命令显示结果如下所示： 11:33:00 up 11 days, 19:03,2 users,load average: 0.00, 0.00, 0.00   USER TTYFROMLOGIN@ IDLE JCPU PCPU WHAT   root pts/1113.57.224.3 09:032:11m0.04s0.04s -bash   root pts/2113.57.224.3 11:310.00s0.02s0.00s w  另外，还有动态命令top，这个命令也可以反映系统负载情况，在下面的命令提示中，我们只关心加粗字体部分。 [root@localhost ~]# top  系统会动态地显示内容，结果如下所示： top - 15:01:25 up 12 days,3:46,2 users,load average: 1.76, 2.14, 2.20   Tasks: 116 total, 1 running, 115 sleeping, 0 stopped, 0 zombie   Cpu(s): 47.5% us, 14.6% sy,0.0% ni, 37.6% id,0.3% wa,0.1% hi,0.0% si   Mem: 8180164k total,7673268k used, 506896k free,74592k buffers   Swap:0k total,0k used,0k free,4613728k cached  第一行内容正是系统目前的负载情况，再通过uptime查看一下。 [root@ud50053 ~]# uptime  结果如下所示： 15:02:50 up 12 days,3:48,2 users,load average: 1.75, 2.07, 2.17  原来它所表示的是过去的1分钟、5分钟和15分钟内进程队列中的平均进程数量。 这里需要注意的是load average这个输出值，这三个值的大小一般不能大于系统逻辑CPU的个数，例如，本输出中系统有4个逻辑CPU，如果load average的三个值长期大于4时，说明CPU很繁忙，负载很高，可能会影响系统性能，但是偶尔大于4时，倒不用担心，一般不会影响系统性能。相反，如果load average的输出值小于CPU的个数，则表示CPU还有空闲，比如本例中的输出，CPU是比较空闲的。 这时候可以结合vmstat命令来判断我们的系统是否过于繁忙，如果确定很繁忙的话，就要考虑是否更换服务器或增加CPU的个数了。总结如下： 如果r经常大于系统的逻辑CPU个数，且id经常少于50，则表示CPU的负荷很重。","title":"Linux系统的平均负载"},{"content":"centos下载地址：http://mirror.centos.org/centos/ CentOS 是 RHEL（Red Hat Enterprise Linux）源代码再编译的产物，而且在 RHEL 的基础上修正了不少已知的 Bug ，相对于其他 Linux 发行版，其稳定性值得信赖。 Scientific Linux下载地址：https://www.scientificlinux.org/download 它旨在与Red Hat Enterprise Linux完全兼容，它也提供了上游产品中未收入的额外软件包。这当中最值得一提的是各种文件系统，包括Cluster Suite和Global File System（GFS）、FUSE、OpenAFS、Squashfs、Unionfs，以及对Intel无线固件的无线网络支持、MadWiFi和NDISwrapper、Sun Java及Java Development Kit（JDK）、轻量级的IceWM窗口管理器、面向统计计算的R语言环境，以及Alpine邮件客户端。同时它也强调自主方便的定制，用户可以根据自己的需求做相应修改，可以使用脚本或者Anaconda给自己定制最小化的安装模式。 CentOS 6.0已经于2011年7月上旬发布。此Linux版本发布以后，使用Scientific Linux的用户也可以使用Cent OS6.0。但Scientific Linux有着更好的维护团队和更新速度。","title":"linux下载地址"},{"content":"Java的图片处理工具类： 可实现以下常用功能：缩放图像、切割图像、图像类型转换、彩色转黑白、文字水印、图片水印等 import java.awt.AlphaComposite;import java.awt.Color;import java.awt.Font;import java.awt.Graphics;import java.awt.Graphics2D;import java.awt.Image;import java.awt.Toolkit;import java.awt.color.ColorSpace;import java.awt.geom.AffineTransform;import java.awt.image.AffineTransformOp;import java.awt.image.BufferedImage;import java.awt.image.ColorConvertOp;import java.awt.image.CropImageFilter;import java.awt.image.FilteredImageSource;import java.awt.image.ImageFilter;import java.io.File;import java.io.IOException;import javax.imageio.ImageIO;/** * 图片处理工具类：<br> * 功能：缩放图像、切割图像、图像类型转换、彩色转黑白、文字水印、图片水印等 * @author Administrator */public class ImageUtils {    /**     * 几种常见的图片格式     */    public static String IMAGE_TYPE_GIF = \"gif\";// 图形交换格式    public static String IMAGE_TYPE_JPG = \"jpg\";// 联合照片专家组    public static String IMAGE_TYPE_JPEG = \"jpeg\";// 联合照片专家组    public static String IMAGE_TYPE_BMP = \"bmp\";// 英文Bitmap（位图）的简写，它是Windows操作系统中的标准图像文件格式    public static String IMAGE_TYPE_PNG = \"png\";// 可移植网络图形    public static String IMAGE_TYPE_PSD = \"psd\";// Photoshop的专用格式Photoshop    /**     * 程序入口：用于测试     * @param args     */    public static void main(String[] args) {        // 1-缩放图像：        // 方法一：按比例缩放        ImageUtils.scale(\"e:/abc.jpg\", \"e:/abc_scale.jpg\", 2, true);//测试OK        // 方法二：按高度和宽度缩放        ImageUtils.scale2(\"e:/abc.jpg\", \"e:/abc_scale2.jpg\", 500, 300, true);//测试OK        // 2-切割图像：        // 方法一：按指定起点坐标和宽高切割        ImageUtils.cut(\"e:/abc.jpg\", \"e:/abc_cut.jpg\", 0, 0, 400, 400 );//测试OK        // 方法二：指定切片的行数和列数        ImageUtils.cut2(\"e:/abc.jpg\", \"e:/\", 2, 2 );//测试OK        // 方法三：指定切片的宽度和高度        ImageUtils.cut3(\"e:/abc.jpg\", \"e:/\", 300, 300 );//测试OK        // 3-图像类型转换：        ImageUtils.convert(\"e:/abc.jpg\", \"GIF\", \"e:/abc_convert.gif\");//测试OK        // 4-彩色转黑白：        ImageUtils.gray(\"e:/abc.jpg\", \"e:/abc_gray.jpg\");//测试OK        // 5-给图片添加文字水印：        // 方法一：        ImageUtils.pressText(\"我是水印文字\",\"e:/abc.jpg\",\"e:/abc_pressText.jpg\",\"宋体\",Font.BOLD,Color.white,80, 0, 0, 0.5f);//测试OK        // 方法二：        ImageUtils.pressText2(\"我也是水印文字\", \"e:/abc.jpg\",\"e:/abc_pressText2.jpg\", \"黑体\", 36, Color.white, 80, 0, 0, 0.5f);//测试OK                // 6-给图片添加图片水印：        ImageUtils.pressImage(\"e:/abc2.jpg\", \"e:/abc.jpg\",\"e:/abc_pressImage.jpg\", 0, 0, 0.5f);//测试OK    }    /**     * 缩放图像（按比例缩放）     * @param srcImageFile 源图像文件地址     * @param result 缩放后的图像地址     * @param scale 缩放比例     * @param flag 缩放选择:true 放大; false 缩小;     */    public final static void scale(String srcImageFile, String result,            int scale, boolean flag) {        try {            BufferedImage src = ImageIO.read(new File(srcImageFile)); // 读入文件            int width = src.getWidth(); // 得到源图宽            int height = src.getHeight(); // 得到源图长            if (flag) {// 放大                width = width * scale;                height = height * scale;            } else {// 缩小                width = width / scale;                height = height / scale;            }            Image image = src.getScaledInstance(width, height,                    Image.SCALE_DEFAULT);            BufferedImage tag = new BufferedImage(width, height,                    BufferedImage.TYPE_INT_RGB);            Graphics g = tag.getGraphics();            g.drawImage(image, 0, 0, null); // 绘制缩小后的图            g.dispose();            ImageIO.write(tag, \"JPEG\", new File(result));// 输出到文件流        } catch (IOException e) {            e.printStackTrace();        }    }    /**     * 缩放图像（按高度和宽度缩放）     * @param srcImageFile 源图像文件地址     * @param result 缩放后的图像地址     * @param height 缩放后的高度     * @param width 缩放后的宽度     * @param bb 比例不对时是否需要补白：true为补白; false为不补白;     */    public final static void scale2(String srcImageFile, String result, int height, int width, boolean bb) {        try {            double ratio = 0.0; // 缩放比例            File f = new File(srcImageFile);            BufferedImage bi = ImageIO.read(f);            Image itemp = bi.getScaledInstance(width, height, bi.SCALE_SMOOTH);            // 计算比例            if ((bi.getHeight() > height) || (bi.getWidth() > width)) {                if (bi.getHeight() > bi.getWidth()) {                    ratio = (new Integer(height)).doubleValue()                            / bi.getHeight();                } else {                    ratio = (new Integer(width)).doubleValue() / bi.getWidth();                }                AffineTransformOp op = new AffineTransformOp(AffineTransform                        .getScaleInstance(ratio, ratio), null);                itemp = op.filter(bi, null);            }            if (bb) {//补白                BufferedImage image = new BufferedImage(width, height,                        BufferedImage.TYPE_INT_RGB);                Graphics2D g = image.createGraphics();                g.setColor(Color.white);                g.fillRect(0, 0, width, height);                if (width == itemp.getWidth(null))                    g.drawImage(itemp, 0, (height - itemp.getHeight(null)) / 2,                            itemp.getWidth(null), itemp.getHeight(null),                            Color.white, null);                else                    g.drawImage(itemp, (width - itemp.getWidth(null)) / 2, 0,                            itemp.getWidth(null), itemp.getHeight(null),                            Color.white, null);                g.dispose();                itemp = image;            }            ImageIO.write((BufferedImage) itemp, \"JPEG\", new File(result));        } catch (IOException e) {            e.printStackTrace();        }    }        /**     * 图像切割(按指定起点坐标和宽高切割)     * @param srcImageFile 源图像地址     * @param result 切片后的图像地址     * @param x 目标切片起点坐标X     * @param y 目标切片起点坐标Y     * @param width 目标切片宽度     * @param height 目标切片高度     */    public final static void cut(String srcImageFile, String result,            int x, int y, int width, int height) {        try {            // 读取源图像            BufferedImage bi = ImageIO.read(new File(srcImageFile));            int srcWidth = bi.getHeight(); // 源图宽度            int srcHeight = bi.getWidth(); // 源图高度            if (srcWidth > 0 && srcHeight > 0) {                Image image = bi.getScaledInstance(srcWidth, srcHeight,                        Image.SCALE_DEFAULT);                // 四个参数分别为图像起点坐标和宽高                // 即: CropImageFilter(int x,int y,int width,int height)                ImageFilter cropFilter = new CropImageFilter(x, y, width, height);                Image img = Toolkit.getDefaultToolkit().createImage(                        new FilteredImageSource(image.getSource(),                                cropFilter));                BufferedImage tag = new BufferedImage(width, height, BufferedImage.TYPE_INT_RGB);                Graphics g = tag.getGraphics();                g.drawImage(img, 0, 0, width, height, null); // 绘制切割后的图                g.dispose();                // 输出为文件                ImageIO.write(tag, \"JPEG\", new File(result));            }        } catch (Exception e) {            e.printStackTrace();        }    }        /**     * 图像切割（指定切片的行数和列数）     * @param srcImageFile 源图像地址     * @param descDir 切片目标文件夹     * @param rows 目标切片行数。默认2，必须是范围 [1, 20] 之内     * @param cols 目标切片列数。默认2，必须是范围 [1, 20] 之内     */    public final static void cut2(String srcImageFile, String descDir,            int rows, int cols) {        try {            if(rows<=0||rows>20) rows = 2; // 切片行数            if(cols<=0||cols>20) cols = 2; // 切片列数            // 读取源图像            BufferedImage bi = ImageIO.read(new File(srcImageFile));            int srcWidth = bi.getHeight(); // 源图宽度            int srcHeight = bi.getWidth(); // 源图高度            if (srcWidth > 0 && srcHeight > 0) {                Image img;                ImageFilter cropFilter;                Image image = bi.getScaledInstance(srcWidth, srcHeight, Image.SCALE_DEFAULT);                int destWidth = srcWidth; // 每张切片的宽度                int destHeight = srcHeight; // 每张切片的高度                // 计算切片的宽度和高度                if (srcWidth % cols == 0) {                    destWidth = srcWidth / cols;                } else {                    destWidth = (int) Math.floor(srcWidth / cols) + 1;                }                if (srcHeight % rows == 0) {                    destHeight = srcHeight / rows;                } else {                    destHeight = (int) Math.floor(srcWidth / rows) + 1;                }                // 循环建立切片                // 改进的想法:是否可用多线程加快切割速度                for (int i = 0; i < rows; i++) {                    for (int j = 0; j < cols; j++) {                        // 四个参数分别为图像起点坐标和宽高                        // 即: CropImageFilter(int x,int y,int width,int height)                        cropFilter = new CropImageFilter(j * destWidth, i * destHeight,                                destWidth, destHeight);                        img = Toolkit.getDefaultToolkit().createImage(                                new FilteredImageSource(image.getSource(),                                        cropFilter));                        BufferedImage tag = new BufferedImage(destWidth,                                destHeight, BufferedImage.TYPE_INT_RGB);                        Graphics g = tag.getGraphics();                        g.drawImage(img, 0, 0, null); // 绘制缩小后的图                        g.dispose();                        // 输出为文件                        ImageIO.write(tag, \"JPEG\", new File(descDir                                + \"_r\" + i + \"_c\" + j + \".jpg\"));                    }                }            }        } catch (Exception e) {            e.printStackTrace();        }    }    /**     * 图像切割（指定切片的宽度和高度）     * @param srcImageFile 源图像地址     * @param descDir 切片目标文件夹     * @param destWidth 目标切片宽度。默认200     * @param destHeight 目标切片高度。默认150     */    public final static void cut3(String srcImageFile, String descDir,            int destWidth, int destHeight) {        try {            if(destWidth<=0) destWidth = 200; // 切片宽度            if(destHeight<=0) destHeight = 150; // 切片高度            // 读取源图像            BufferedImage bi = ImageIO.read(new File(srcImageFile));            int srcWidth = bi.getHeight(); // 源图宽度            int srcHeight = bi.getWidth(); // 源图高度            if (srcWidth > destWidth && srcHeight > destHeight) {                Image img;                ImageFilter cropFilter;                Image image = bi.getScaledInstance(srcWidth, srcHeight, Image.SCALE_DEFAULT);                int cols = 0; // 切片横向数量                int rows = 0; // 切片纵向数量                // 计算切片的横向和纵向数量                if (srcWidth % destWidth == 0) {                    cols = srcWidth / destWidth;                } else {                    cols = (int) Math.floor(srcWidth / destWidth) + 1;                }                if (srcHeight % destHeight == 0) {                    rows = srcHeight / destHeight;                } else {                    rows = (int) Math.floor(srcHeight / destHeight) + 1;                }                // 循环建立切片                // 改进的想法:是否可用多线程加快切割速度                for (int i = 0; i < rows; i++) {                    for (int j = 0; j < cols; j++) {                        // 四个参数分别为图像起点坐标和宽高                        // 即: CropImageFilter(int x,int y,int width,int height)                        cropFilter = new CropImageFilter(j * destWidth, i * destHeight,                                destWidth, destHeight);                        img = Toolkit.getDefaultToolkit().createImage(                                new FilteredImageSource(image.getSource(),                                        cropFilter));                        BufferedImage tag = new BufferedImage(destWidth,                                destHeight, BufferedImage.TYPE_INT_RGB);                        Graphics g = tag.getGraphics();                        g.drawImage(img, 0, 0, null); // 绘制缩小后的图                        g.dispose();                        // 输出为文件                        ImageIO.write(tag, \"JPEG\", new File(descDir                                + \"_r\" + i + \"_c\" + j + \".jpg\"));                    }                }            }        } catch (Exception e) {            e.printStackTrace();        }    }    /**     * 图像类型转换：GIF->JPG、GIF->PNG、PNG->JPG、PNG->GIF(X)、BMP->PNG     * @param srcImageFile 源图像地址     * @param formatName 包含格式非正式名称的 String：如JPG、JPEG、GIF等     * @param destImageFile 目标图像地址     */    public final static void convert(String srcImageFile, String formatName, String destImageFile) {        try {            File f = new File(srcImageFile);            f.canRead();            f.canWrite();            BufferedImage src = ImageIO.read(f);            ImageIO.write(src, formatName, new File(destImageFile));        } catch (Exception e) {            e.printStackTrace();        }    }    /**     * 彩色转为黑白      * @param srcImageFile 源图像地址     * @param destImageFile 目标图像地址     */    public final static void gray(String srcImageFile, String destImageFile) {        try {            BufferedImage src = ImageIO.read(new File(srcImageFile));            ColorSpace cs = ColorSpace.getInstance(ColorSpace.CS_GRAY);            ColorConvertOp op = new ColorConvertOp(cs, null);            src = op.filter(src, null);            ImageIO.write(src, \"JPEG\", new File(destImageFile));        } catch (IOException e) {            e.printStackTrace();        }    }    /**     * 给图片添加文字水印     * @param pressText 水印文字     * @param srcImageFile 源图像地址     * @param destImageFile 目标图像地址     * @param fontName 水印的字体名称     * @param fontStyle 水印的字体样式     * @param color 水印的字体颜色     * @param fontSize 水印的字体大小     * @param x 修正值     * @param y 修正值     * @param alpha 透明度：alpha 必须是范围 [0.0, 1.0] 之内（包含边界值）的一个浮点数字     */    public final static void pressText(String pressText,            String srcImageFile, String destImageFile, String fontName,            int fontStyle, Color color, int fontSize,int x,            int y, float alpha) {        try {            File img = new File(srcImageFile);            Image src = ImageIO.read(img);            int width = src.getWidth(null);            int height = src.getHeight(null);            BufferedImage image = new BufferedImage(width, height,                    BufferedImage.TYPE_INT_RGB);            Graphics2D g = image.createGraphics();            g.drawImage(src, 0, 0, width, height, null);            g.setColor(color);            g.setFont(new Font(fontName, fontStyle, fontSize));            g.setComposite(AlphaComposite.getInstance(AlphaComposite.SRC_ATOP,                    alpha));            // 在指定坐标绘制水印文字            g.drawString(pressText, (width - (getLength(pressText) * fontSize))                    / 2 + x, (height - fontSize) / 2 + y);            g.dispose();            ImageIO.write((BufferedImage) image, \"JPEG\", new File(destImageFile));// 输出到文件流        } catch (Exception e) {            e.printStackTrace();        }    }    /**     * 给图片添加文字水印     * @param pressText 水印文字     * @param srcImageFile 源图像地址     * @param destImageFile 目标图像地址     * @param fontName 字体名称     * @param fontStyle 字体样式     * @param color 字体颜色     * @param fontSize 字体大小     * @param x 修正值     * @param y 修正值     * @param alpha 透明度：alpha 必须是范围 [0.0, 1.0] 之内（包含边界值）的一个浮点数字     */    public final static void pressText2(String pressText, String srcImageFile,String destImageFile,            String fontName, int fontStyle, Color color, int fontSize, int x,            int y, float alpha) {        try {            File img = new File(srcImageFile);            Image src = ImageIO.read(img);            int width = src.getWidth(null);            int height = src.getHeight(null);            BufferedImage image = new BufferedImage(width, height,                    BufferedImage.TYPE_INT_RGB);            Graphics2D g = image.createGraphics();            g.drawImage(src, 0, 0, width, height, null);            g.setColor(color);            g.setFont(new Font(fontName, fontStyle, fontSize));            g.setComposite(AlphaComposite.getInstance(AlphaComposite.SRC_ATOP,                    alpha));            // 在指定坐标绘制水印文字            g.drawString(pressText, (width - (getLength(pressText) * fontSize))                    / 2 + x, (height - fontSize) / 2 + y);            g.dispose();            ImageIO.write((BufferedImage) image, \"JPEG\", new File(destImageFile));        } catch (Exception e) {            e.printStackTrace();        }    }    /**     * 给图片添加图片水印     * @param pressImg 水印图片     * @param srcImageFile 源图像地址     * @param destImageFile 目标图像地址     * @param x 修正值。 默认在中间     * @param y 修正值。 默认在中间     * @param alpha 透明度：alpha 必须是范围 [0.0, 1.0] 之内（包含边界值）的一个浮点数字     */    public final static void pressImage(String pressImg, String srcImageFile,String destImageFile,            int x, int y, float alpha) {        try {            File img = new File(srcImageFile);            Image src = ImageIO.read(img);            int wideth = src.getWidth(null);            int height = src.getHeight(null);            BufferedImage image = new BufferedImage(wideth, height,                    BufferedImage.TYPE_INT_RGB);            Graphics2D g = image.createGraphics();            g.drawImage(src, 0, 0, wideth, height, null);            // 水印文件            Image src_biao = ImageIO.read(new File(pressImg));            int wideth_biao = src_biao.getWidth(null);            int height_biao = src_biao.getHeight(null);            g.setComposite(AlphaComposite.getInstance(AlphaComposite.SRC_ATOP,                    alpha));            g.drawImage(src_biao, (wideth - wideth_biao) / 2,                    (height - height_biao) / 2, wideth_biao, height_biao, null);            // 水印文件结束            g.dispose();            ImageIO.write((BufferedImage) image,  \"JPEG\", new File(destImageFile));        } catch (Exception e) {            e.printStackTrace();        }    }    /**     * 计算text的长度（一个中文算两个字符）     * @param text     * @return     */    public final static int getLength(String text) {        int length = 0;        for (int i = 0; i < text.length(); i++) {            if (new String(text.charAt(i) + \"\").getBytes().length > 1) {                length += 2;            } else {                length += 1;            }        }        return length / 2;    }}  ","title":"Java的图片处理工具类"},{"content":"这个工具是IBM推出的用于性能分析的免费工具，支持AIX、Linux平台。 nmon 工具可以为 AIX 和 Linux 性能专家提供监视和分析性能数据的功能，其中包括： CPU 使用率 内存使用情况 内核统计信息和运行队列信息 磁盘 I/O 速度、传输和读/写比率 文件系统中的可用空间 磁盘适配器 网络 I/O 速度、传输和读/写比率 页面空间和页面速度 CPU 和 AIX 规范 消耗资源最多的进程 IBM HTTP Web 缓存 用户自定义的磁盘组 计算机详细信息和资源 异步 I/O，仅适用于 AIX 工作负载管理器 (WLM)，仅适用于 AIX IBM TotalStorage? Enterprise Storage Server? (ESS) 磁盘，仅适用于 AIX 网络文件系统 (NFS) 动态 LPAR (DLPAR) 更改，仅适用于面向 AIX 或 Linux 的 pSeries p5 和 OpenPower 还包括一个用来从 nmon 的输出生成图形并创建可以在 Web 站点显示的 .gif 文件的新工具。 安装非常简单，下载来解压即可。 [root@servm248 ~]# wget http://sourceforge.net/projects/nmon/files/nmon_linux_14g.tar.gz --2012-12-25 16:27:04--  http://sourceforge.net/projects/nmon/files/nmon_linux_14g.tar.gz 正在解析主机 sourceforge.net... 216.34.181.60 Connecting to sourceforge.net|216.34.181.60|:80... 已连接。 已发出 HTTP 请求，正在等待回应... 302 Found 位置：http://sourceforge.net/projects/nmon/files/nmon_linux_14g.tar.gz/download [跟随至新的 URL] --2012-12-25 16:27:04--  http://sourceforge.net/projects/nmon/files/nmon_linux_14g.tar.gz/download Connecting to sourceforge.net|216.34.181.60|:80... 已连接。 已发出 HTTP 请求，正在等待回应... 302 Found 位置：http://downloads.sourceforge.net/project/nmon/nmon_linux_14g.tar.gz?r=&ts=1356424025&use_mirror=nchc [跟随至新的 URL] --2012-12-25 16:27:14--  http://downloads.sourceforge.net/project/nmon/nmon_linux_14g.tar.gz?r=&ts=1356424025&use_mirror=nchc 正在解析主机 downloads.sourceforge.net... 216.34.181.59 Connecting to downloads.sourceforge.net|216.34.181.59|:80... 已连接。 已发出 HTTP 请求，正在等待回应... 302 Found 位置：http://nchc.dl.sourceforge.net/project/nmon/nmon_linux_14g.tar.gz [跟随至新的 URL] --2012-12-25 16:27:14--  http://nchc.dl.sourceforge.net/project/nmon/nmon_linux_14g.tar.gz 正在解析主机 nchc.dl.sourceforge.net... 211.79.60.17, 2001:e10:ffff:1f02::17 Connecting to nchc.dl.sourceforge.net|211.79.60.17|:80... 已连接。 已发出 HTTP 请求，正在等待回应... 200 OK 长度：4064553 (3.9M) [application/x-gzip] Saving to: `nmon_linux_14g.tar.gz' 100%[=====================================================================================================================================================>] 4,064,553    775K/s   in 7.3s     2012-12-25 16:27:22 (544 KB/s) - `nmon_linux_14g.tar.gz' saved [4064553/4064553] [root@servm248 ~]# mkdir nmon [root@servm248 ~]# tar -zxf nmon_linux_14g.tar.gz -C nmon [root@servm248 ~]# cd nmon [root@servm248 nmon]# ./nmon_linux_x86 -bash: ./nmon_linux_x86: 权限不够 [root@servm248 nmon]# chmod +x * [root@servm248 nmon]# ./nmon_linux_x86 很简单，这样就安装完成并启动nmon了。 这界面上可以根据提示输入相关字母以显示相关性能参数，比如显示cpu、内存、磁盘，那么输入cmd即可在界面上动态显示这3个性能数据。 其他几个常用的快捷键+和-修改刷新间隔，t显示进程信息，h显示帮助。./nmon_linux_x86 -h查看帮助。 其他使用方法 ./nmon_linux_x86 -f -s 20 -c 180 --间隔20秒执行180次=1个小时并输出到文件，这个命令在ssh登陆注销之后能够在后台继续运行 ./nmon_linux_x86 -F out.txt -s 2 -c 10 --间隔0秒执行10次收集信息并输出到文件out.txt sort  out.txt > out.csv --将out文件输出到csv方便查看 当然还有更方便的查看结果工具nmon_analyser，打开这个工具然后选择使用nmon生成的数据文件即可查看报告。 -The End-","title":"nmon免费性能分析工具"},{"content":"信号量是一种用于提供不同进程或一个给定进程的不同线程间同步手段。 在Posix中，已经有一套信号接口，用于同一个进程中不同线程同步，其接口为： int sem_init(sem_t *sem, int pshared, unsigned int value);int sem_wait(sem_t *sem);int sem_trywait(sem_t *sem);int sem_timedwait(sem_t *sem, const struct timespec *abs_timeout);int sem_destroy(sem_t *sem);int sem_getvalue(sem_t *sem); 但Posix标准实现信号量的主要的目的是提供一种进程间同步的方式，注意重点是解决进程间，不过信号量也可以用于线程间同步。 进程间同步通过有名信号量(sem_open(), sem_close(), sem_unlink(), sem_wait(), sem_post(), sem_getvalue(), sem_trywait()) 线程间同步一般通过互斥锁和条件变量来实现，但具体情况，还要看应用场景。 下面主要介绍通过互斥锁和条件变量实现信号实现，代码比较简单： #ifndef __DL_SEMA_H__#define __DL_SEMA_H__#ifdef __cplusplus#if __cplusplusextern \"C\" {#endif#endiftypedef void*   dl_sema_t;extern intdl_sema_create(dl_sema_t *pSema, unsigned int init_cnt);extern intdl_sema_destroy(dl_sema_t sema);extern intdl_sema_p(dl_sema_t sema, int timeout);extern intdl_sema_v(dl_sema_t sema);#ifdef __cplusplus#if __cplusplus}#endif#endif#endif /*  __DL_SEMA_H__ */ #include <pthread.h>#include <stdlib.h>#include <sys/time.h>           /* gettimeofday() */#include \"dl_sema.h\"#ifdef __cplusplus#if __cplusplusextern \"C\" {#endif#endif#define SEMA_MAGIC              0xF147258Fstruct sema_info{        unsigned int magic;        int     cnt;        pthread_mutex_t mutex;        pthread_cond_t  cond;};/* abstime = millsec + the current time */void dl_gettime(struct timespec *abstime, int millsec){        long sec, nsec;        struct timeval cur_time;        gettimeofday(&cur_time, 0);        nsec = cur_time.tv_usec * 1000;        sec = cur_time.tv_sec;        nsec += (millsec%1000)*1000000;        abstime->tv_nsec = nsec % 1000000000;        sec += millsec/1000;        sec += nsec / 1000000000;        abstime->tv_sec = sec;}/* create a semaphore with init_cnt */int dl_sema_create(dl_sema_t *pSema, unsigned int init_cnt){        struct sema_info *sema;        if(!pSema) return -1;        sema = malloc(sizeof(struct sema_info));        if(!sema) return -1;        if(pthread_mutex_init(&(sema->mutex), 0) != 0){                free(sema);                return -1;        }        if( pthread_cond_init(&(sema->cond), 0) != 0){                pthread_mutex_destroy(&(sema->mutex));                free(sema);                return -1;        }        sema->cnt = init_cnt;        sema->magic = SEMA_MAGIC;        *pSema = sema;        return 0;}int dl_sema_p(dl_sema_t sema, int timeout){        struct sema_info *psema = (struct sema_info*) sema;        int ret = 0;        if(!psema || (psema->magic != SEMA_MAGIC) ) return -1;        pthread_mutex_lock(&(psema->mutex));        if(psema->cnt <= 0){                /* wait forever */                if(timeout == 0){                        while(psema->cnt <= 0){                                if((ret = pthread_cond_wait(&(psema->cond), &(psema->mutex))) != 0){                                        pthread_mutex_unlock(&(psema->mutex));                                        return ret;                                }                        }                }                else {                        struct timespec abs_time;                        dl_gettime(&abs_time, timeout);                        while(psema->cnt <= 0){                                ret = pthread_cond_timedwait(&(psema->cond),                                                                &(psema->mutex),                                                                &abs_time);                                if(ret != 0){                                        pthread_mutex_unlock(&(psema->mutex));                                        return ret;                                }                        }                }        }        psema->cnt--;        pthread_mutex_unlock(&(psema->mutex));        return 0;}int dl_sema_v(dl_sema_t sema){        int ret = 0;        struct sema_info* psema = (struct sema_info*)sema;        if(!psema || (psema->magic != SEMA_MAGIC) ) return -1;        pthread_mutex_lock(&(psema->mutex));        psema->cnt++;        ret = pthread_cond_signal(&(psema->cond));        if(ret != 0){                psema->cnt--; /* roll back */                pthread_mutex_unlock(&(psema->mutex));                return ret;        }        pthread_mutex_unlock(&(psema->mutex));        return 0;}int dl_sema_destroy(dl_sema_t sema){        struct sema_info* psema = (struct sema_info*)sema;        int ret = 0;        if(!psema || (psema->magic != SEMA_MAGIC) ) return -1;        psema->magic = 0;        if((ret = pthread_mutex_destroy(&(psema->mutex))) != 0) return ret;          if((ret = pthread_cond_destroy(&(psema->cond))) != 0) return ret;        free(psema);        return 0;}#ifdef __cplusplus#if __cplusplus}#endif#endif //简单测试代码：#include <stdio.h>#include <pthread.h>#include <stdlib.h>#include \"dl_sema.h\"void *thread_1(void *arg){        int ret;        dl_sema_t sema = (dl_sema_t)arg;        ret = dl_sema_p(sema, 3000);/* 3s timeout */        if(ret == 0)printf(\"the semaphore come up !\\n\");        dl_sema_destroy(sema);        return 0;}void *thread_2(void *arg){        dl_sema_t sema = (dl_sema_t)arg;        dl_sema_v(sema);        printf(\"OK!!!!\\n\");        return 0;}int main(int argc, char**argv){        pthread_t thid;        dl_sema_t sema;        if(dl_sema_create(&sema, 0))                printf(\"dl_sema_init failed.\\n\");        pthread_create(&thid, 0, thread_1, sema);        pthread_create(&thid, 0, thread_2, sema);        sleep(5);        return 0;}","title":"【Linux】线程间同步实现--通过互斥锁和条件变量"},{"content":"#include <sys/time.h>#include <signal.h>#include <unistd.h>#include <stdio.h>/* ARGSUSED */static void catch_sigalrm(int sig){\tprintf(\"%s\\n\", \"SIGALRM received.\");\treturn ;}static void (*Signal (int sig, void (*handler)(int)))(int){  \tstruct sigaction act, oact;  \tact.sa_handler = handler;  \tact.sa_flags = 0;#ifdef SA_INTERRUPT  \tact.sa_flags |= SA_INTERRUPT;#endif  \tif (sigaction(sig, &act, &oact))\t\treturn SIG_ERR;  \treturn oact.sa_handler;}int main(void){\tstruct itimerval it;\tSignal(SIGALRM, &catch_sigalrm);\tit.it_interval.tv_sec = 1;\tit.it_interval.tv_usec = 0;\tit.it_value.tv_sec = 1;\tit.it_value.tv_usec = 0;\t\tsetitimer(ITIMER_REAL, &it, NULL);\t/* CONSTCOND */\tfor (;;)\t\tpause();\t/* NOTREACHED */  return 0;}","title":"Linux 下设置时间间隔的Signal函数"},{"content":"LINUX中断机制与信号 中断和异常   l 中 断（也称硬件中断） 定义：中断是由其他硬件设备依照CPU时钟周期信号随机产生的。 分类： 可屏蔽中断 非可屏蔽中断 来源：间隔定时器和I/O   l 异 常（也称软件中断） 定义：当指令执行时由 CPU控制单元 产生的，异常也称为“异步中断”是因为只有在 一条指令终止执行后CPU才会发出中断。 分类： 处理器探测到的异常 ²  故障 ²  陷阱 ²  异常终止 编程异常(也称软中断 ) ²  int指令 来源：程序的错误产生的 内核必须处理的异常(例如：缺页和内核服务的请求 -int) 异常处理 l  当发生异常时，CPU 控制单元产生一个硬件出错码。 l  CPU根据该中断吗找到中断向量表内的对应向量，根据该向量转到中断处理程序。 l  中断处理程序处理完之后向当前进程发送一个SIG*** 信号。 l  若进程定义了相应的信号处理程序则转移到相应的程序执行，若没有，则执行内核定义的操作。 中断处理 l  设备产生中断 l  PIC（可编程中断控制器）会产生一个对应的中断向量 l  和中断向量表中的每一个中断向量进行比较，转到对应的中断处理程序 l  中断处理程序进行保存现场，做相关处理，恢复现场 l  内核调度，返回用户进程   硬件中断的上半部和下半部及实现方式 l 硬件中断的分类 ²  紧急的 —— 这类中断必须立即执行 ²  非紧急的 —— 也必须立即执行 ²  非紧急可延迟的 —— 上半部立即执行，下半部延迟执行   硬件中断任务（处理程序）是一个快速、异步、简单地对硬件做出迅速响应并在最短时间内完成必要操作的中断处理程序。硬中断处理程序可以抢占内核任务并且执 行时还会屏蔽同级中断或其它中断，因此中断处理必须要快、不能阻塞。这样一来对于一些要求处理过程比较复杂的任务就不合适在中断任务中一次处理。比如，网卡接收数据的过程中,首先网卡发送中断信号告诉 CPU 来取数据，然后系统从网卡中读取数据存入系统缓冲区中，再下来解析数据然后送入应用层。这些如果都让中断处理程序来处理显然过程太长，造成新来的中断丢失。因此Linux 开发人员将这种任务分割为两个部分，一个叫上底，即中断处理程序，短平快地处理与硬 件相关的操作（如从网卡读数据到系统缓存）；而把对时间要求相对宽松的任务（如解析数据的工作）放在另一个部分执行，这个部分就是我们这里要讲的下半底。 下半底是一种推后执行任务，它将某些不那么紧迫的任务推迟到系统更方便的时刻运行。因为并不是非常紧急，通常还是比较耗时的，因此由系统自行安排运行时机，不在中断服务上下文中执行。内核中实现 下半底的手段经过不断演化，目前已经从最原始的BH(bottom thalf)演生出 BH 、 任务队列（Task queues） 、软中断（Softirq） 、Tasklet、 工作队列（Work queues ） （2.6内核中新出现的）。     其中的软中断和异常中提到的软中断的区别： 主要是用来处理非紧急可延迟的硬件中断 Linux系统定定义的，不是用户定义，并且个数有限   关于软中断和硬中断的其它解析： 软中断一般是指由指令int引起的 “ 伪 ” 中断动作 —— 给 CPU 制造一个中断的假象；而硬中断则是实实在在由 8259 的连线触发的中断。因此，严格的 讲， int 与 IRQ 毫无关系，但二者均与中断向量有关系。 int 引起的中断， CPU 是从指令中取得中断向量号；而 IRQ 引起的中断， CPU 必须从数据线上取回中断号，接下来 CPU 的工作就一样了：保护现场、根据中断号得到中断处理程序地址、执行中断处理、恢复现场继续执行被中断的指令。   在软中断和硬中断之间的区别是什么？ ①硬中断是由外部事件引起的因此具有随机性和突发性；软中断是执行中断指令产生的，无面外部施加中断请求信 号，因此中断的发生不是随机的而是由程序安排好的。 ②硬中断的中断响应周期，CPU 需要发中断回合信号（ NMI 不需要），软中断的中断响应周 期， CPU 不需发中断回合信号。 ③硬中断的中断号是由中断控制器提供的（NMI 硬中断中断号系统指定为 02H ）；软中断的中断号由指令直接给出， 无需使用中断控制器。 ④硬中断是可屏蔽的（NMI 硬中断不可屏蔽），软中断不可屏蔽。   LINUX信号机制 l 信号本质 信号是异步的进程间通讯机制,是在软件层次上对中断机制的一种模拟，在原理上，一个进程收到一个信号与处理器收到一个中断请求可以说是一样的。信号是异步的，一个进程不必通过任何操作来等待信号的到达，事实上，进程也不知 道信号到底什么时候到达。 信号是进程间通信机制中唯一的异步通信机制，可以看作是异步通知，通知接收信号的进程有哪些事情发生了。内核也可以因为内部事件而给进程发送信号，通知进程发生了某个事件。注意，信号只是用来通知某进程发生了什么事件，并不给 该进程传递任何数据。 l 产生信号的条件主要有： 1.  用户在终端 按下某些键时，终端驱动程序会发送信号给前台进程，例如Ctrl-C产生 SIGINT 信 号， Ctrl-/ 产生 SIGQUIT 信号， Ctrl-Z 产生 SIGTSTP 信号。 2.  硬件异常产生信号，这些条件由硬件检测到并通知内核，然后内核向当前进程发送适当的信号。例如当前进程执行了 除以0的指令， CPU 的运算单元会产生异常，内核将这个异常解释为 SIGFPE 信号发送给进 程。再比如当前进程访问了非法内存地址，， MMU 会产生异常，内核将这个异常解释为 SIGSEGV 信 号发送给进程。 3.  一个进程调用kill(2) 函数可以发送信 号给另一个进程。 4.  可以用kill(1) 命令发送信号给某个 进程， kill(1) 命令也是调用 kill(2) 函 数实现的，如果不明确指定信号则发送 SIGTERM信号，该信号的默认处理动作是终止进程。 5.  当 内核检测到某种软件条件发生时也可以通过信号通知进程，例如闹钟超时产生SIGALRM信 号，向读端已关闭的管道写数据时产生 SIGPIPE 信号。 l 进程对信号的处理： 1.  忽略此信号。 2.  执行该信号的默认处 理动作。 3.  提供一个信号处理函数，要求内核在处理该信号时切换到用户态执行这个处理函 数，这种方式称为捕捉（Catch） 一个信号。 l 信号与中断的相似点： （1）采用了相同的异步通信方式； （2）当检测出有信号或中断请求时，都暂停正在执行的程序而转去执行相应的处理程序； （3）都在处理完毕后返回到原来的断点； （4）对信号或中断都可进行屏蔽。 l 信号与中断的区别： （1）中断有优先级，而信号没有优先级，所有的信号都是平等的； （2）信号处理程序是在用户态下运行的，而中断处理程序是在核心态下运行； （3）中断响应是及时的，而信号响应通常都有较大的时间延迟。 l 信号机制具有以下三方面的功能： （1）发送信号。发送信号的程序用系统调用 kill( ) 实现； （2）预置对信号的处理方式。接收信号的程序用 signal( ) 来实现对处理方式的预置； （3）收受信号的进程按事先的规定完成对相应事件的处理。 l 信号捕获过程   本图出自ULK 注：从上图可以看出，信号的处理时机是在当前进程由于系统调用、中断或者异常而进 入系统空间以后，从系统空间返回到用户空间前夕（这样做主要是出于效率的考虑，和 进程的调用时机一致，从系统调用返回意味着要离开内核态而返回到用户态，而状态的 转换要花费一定的时间，因此，在返回到用户态前，系统把在内核态该处理的事全部做 完）。 下图为异常和函数产生信号的方式以及进程的处理过程       另外提供两个关于LINUX中断机制和信号机制的学习文章   关于软中断：http://www.ibm.com/developerworks/cn/linux/kernel/interrupt/index.html   关于信号：http://www.ibm.com/developerworks/cn/linux/l-ipc/part2/index1.html http://www.ibm.com/developerworks/cn/linux/l-ipc/part2/index2.html","title":"LINUX中断机制与信号"},{"content":"Linux内存管理(上) 摘要：本章首先以应用程序开发者的角度审视Linux的进程内存管理，在此基础上逐步深入到内核中讨论系统物理内存管理和内核内存地使用方法。力求从外自内、水到渠成地引导网友分析Linux地内存管理与使用。在本章最后我们给出一个内存映射地实例，帮助网友们理解内核内存管理与用户内存管理之间地关系，希望大家最终能驾驭Linux内存管理。    转自：http://blog.csdn.net/kanghua 前言 内存管理一向是所有操作系统书籍不惜笔墨重点讨论的内容，无论市面上或是网上都充斥着大量涉及内存管理的教材和资料。因此我们这里所要写的Linux内存管理采取必重就轻的策略，从理论层面就不去板门弄斧，贻笑大方了。我们最想做的和可能做到的是以开发者的角度谈谈对内存管理的理解，最终目的是把我们在内核开发中使用内存的经验和对Linux内存管理的认识与大家共享。 当然这其中我们也会设计一些诸如段页等内存管理的基本理论，但我们目的不是为了强调理论，而是为了指导理解开发中的实践，所以仅仅点到为止，不做深究。 遵循“理论来源于实践”的“教条”，我们先不必一下子就钻入内核里去看系统内存到底是如何管理，那样往往会让你陷入似懂非懂的窘境（我当年就犯了这个错误！）。所以最好的方式是先从外部（用户编程范畴）来观察进程如何使用内存，等到对大家内存使用有了较直观的认识后，再深入到内核中去学习内存如何被管理等理论知识。最后再通过一个实例编程将所讲内容融会贯通。 进程与内存 进程如何使用内存？ 毫无疑问所有进程（执行的程序）都必须占用一定数量的内存，它或是用来存放从磁盘载入的程序代码，或是存放取自用户输入的数据等等。不过进程对这些内存的管理方式因内存用途不一而不尽相同，有些内存是事先静态分配和统一回收的，而有些却是按需要动态分配和回收的。 对任何一个普通进程来讲，它都会涉及到5种不同的数据段。稍有编程知识的朋友都该能想到这几个数据段种包含有“程序代码段”、“程序数据段”、“程序堆栈段”等。不错，这几种数据段都在其中，但除了以上几种数据段之外，进程还另外包含两种数据段。下面我们来简单归纳一下进程对应的内存空间中所包含的5种不同的数据区。 代码段：代码段是用来存放可执行文件的操作指令，也就是说是它是可执行程序在内存种的镜像。代码段需要防止在运行时被非法修改，所以只准许读取操作，而不允许写入（修改）操作——它是不可写的。 数据段：数据段用来存放可执行文件中已初始化全局变量，换句话说就是存放程序静态分配[1]的变量和全局变量。 BSS段[2]：BSS段包含了程序中未初始化全局变量，在内存中 bss段全部置零。 堆（heap）：堆是用于存放进程运行中被动态分配的内存段，它大小并不固定，可动态扩张或缩减。当进程调用malloc等函数分配内存时，新分配的内存就被动态添加到堆上（堆被扩张）；当利用free等函数释放内存时，被释放的内存从堆中被剔除（堆被缩减） 栈：栈是用户存放程序临时创建的局部变量，也就是说我们函数括弧“{}”中定义的变量（但不包括static声明的变量，static意味这在数据段中存放变量）。除此以外在函数被调用时，其参数也会被压入发起调用的进程栈中，并且待到调用结束后，函数的返回值也回被存放回栈中。由于栈的先进先出特点，所以栈特别方便用来保存/恢复调用现场。从这个意义上将我们可以把堆栈看成一个临时数据寄存、交换的内存区。 进程如何组织这些区域？ 上述几种内存区域中数据段、BSS和堆通常是被连续存储的——内存位置上是连续的，而代码段和栈往往会被独立存放。有趣的是堆和栈两个区域关系很“暧昧”，他们一个向下“长”（i386体系结构中栈向下、堆向上），一个向上“长”，相对而生。但你不必担心他们会碰头，因为他们之间间隔很大（到底大到多少，你可以从下面的例子程序计算一下），绝少有机会能碰到一起。 下图简要描述了进程内存区域的分布： 数据段 BSS 代码段 堆 栈 “事实胜于雄辩”，我们用一个小例子（原形取自《User-Level Memory Management》）来展示上面所讲的各种内存区的差别与位置。 #include<stdio.h> #include<malloc.h> #include<unistd.h> int bss_var; int data_var0=1; int main(int argc,char **argv) {   printf(\"below are addresses of types of process's mem/n\");   printf(\"Text location:/n\");   printf(\"/tAddress of main(Code Segment):%p/n\",main);   printf(\"____________________________/n\");   int stack_var0=2;   printf(\"Stack Location:/n\");   printf(\"/tInitial end of stack:%p/n\",&stack_var0);   int stack_var1=3;   printf(\"/tnew end of stack:%p/n\",&stack_var1);   printf(\"____________________________/n\");   printf(\"Data Location:/n\");   printf(\"/tAddress of data_var(Data Segment):%p/n\",&data_var0);   static int data_var1=4;   printf(\"/tNew end of data_var(Data Segment):%p/n\",&data_var1);   printf(\"____________________________/n\");   printf(\"BSS Location:/n\");   printf(\"/tAddress of bss_var:%p/n\",&bss_var);   printf(\"____________________________/n\");   char *b = sbrk((ptrdiff_t)0);   printf(\"Heap Location:/n\");   printf(\"/tInitial end of heap:%p/n\",b);   brk(b+4);   b=sbrk((ptrdiff_t)0);   printf(\"/tNew end of heap:%p/n\",b); return 0;  } 它的结果如下 below are addresses of types of process's mem Text location:    Address of main(Code Segment):0x8048388 ____________________________ Stack Location:    Initial end of stack:0xbffffab4    new end of stack:0xbffffab0 ____________________________ Data Location:    Address of data_var(Data Segment):0x8049758    New end of data_var(Data Segment):0x804975c ____________________________ BSS Location:    Address of bss_var:0x8049864 ____________________________ Heap Location:    Initial end of heap:0x8049868    New end of heap:0x804986c 利用size命令也可以看到程序的各段大小，比如执行size example会得到 text data bss dec hex filename 1654 280   8 1942 796 example 但这些数据是程序编译的静态统计，而上面显示的是进程运行时动态值，但两者是对应的。   从前面的例子，我们对进程使用的逻辑内存分布已经先睹为快。这部分我们就继续进入操作系统内核看看进程对内存具体是如何进行分配和管理的。 从用户向内核看，所使用的内存表象形式会依次经历“逻辑地址”——“线形地址”——“物理地址”几种形式（关于几种地址的解释在前面已经讲述了）。逻辑地址经段机制转化成线性地址；线性地址又经过页机制转化为物理地址。（但是我们要知道Linux系统虽然保留了段机制，但是将所有程序的段地址都定死为0-4G，所以虽然逻辑地址和线性地址是两种不同的地址空间，但在Linux中逻辑地址就等于线性地址，它们的值是一样的）。沿着这条线索，我们所研究的主要问题也就集中在下面几个问题。 1.         进程空间地址如何管理？ 2.         进程地址如何映射到物理内存？ 3.         物理内存如何被管理？ 以及由上述问题引发的一些子问题。如系统虚拟地址分布;内存分配接口;连续内存分配与非连续内存分配等。   进程内存空间 Linux操作系统采用虚拟内存管理技术，使得每个进程都有各自互不干涉的进程地址空间。该空间是块大小为4G的线性虚拟空间，用户所看到和接触的都是该虚拟地址，无法看到实际的物理内存地址。利用这种虚拟地址不但能起到保护操作系统的效果（用户不能直接访问物理内存），而且更重要的是用户程序可使用比实际物理内存更大的地址空间（具体的原因请看硬件基础部分）。 在讨论进程空间细节前，请大家这里先要澄清下面几个问题。 l        第一、4G的进程地址空间被人为的分为两个部分——用户空间与内核空间。用户空间从0到3G（0xC0000000），内核空间占据3G到4G。用户进程通常情况下只能访问用户空间的虚拟地址，不能访问内核空间虚拟地址。例外情况只有用户进程进行系统调用（代表用户进程在内核态执行）等时刻可以访问到内核空间。 l        第二、用户空间对应进程，所以每当进程切换，用户空间就会跟着变化；而内核空间是由内核负责映射，它并不会跟着进程改变，是固定的。内核空间地址有自己对应的页表（init_mm.pgd），用户进程各自有不同的页表（。 l        第三、每个进程的用户空间都是完全独立、互不相干的。不信的话，你可以把上面的程序同时运行10次（当然为了同时运行，让它们在返回前一同睡眠100秒吧），你会看到10个进程占用的线性地址一模一样。   进程内存管理 进程内存管理的对象是进程线性地址空间上的内存镜像,这些内存镜像其实就是进程使用的虚拟内存区域（memory region）。进程虚拟空间是个32或64位的“平坦”（独立的连续区间）地址空间（空间的具体大小取决于体系结构）。要统一管理这么大的平坦空间可绝非易事，为了方便管理，虚拟空间被化分为许多大小可变的(但必须是4096的倍数)内存区域，这些区域在进程线性地址中像停车位一样有序排列。这些区域的划分原则是“将访问属性一致的地址空间存放在一起”，所谓访问属性在这里无非指的是“可读、可写、可执行等”。 如果你要查看某个进程占用的内存区域，可以使用命令cat /proc/<pid>/maps获得（pid是进程号，你可以运行上面我们给出的例子——./example &;pid便会打印到屏幕），你可以发现很多类似于下面的数字信息。 由于程序example使用了动态库，所以除了example本身使用的的内存区域外，还会包含那些动态库使用的内存区域（区域顺序是：代码段、数据段、bss段）。 我们下面只抽出和example有关的信息，除了前两行代表的代码段和数据段外，最后一行是进程使用的栈空间。 ------------------------------------------------------------------------------- 08048000 - 08049000 r-xp 00000000 03:03 439029                               /home/mm/src/example 08049000 - 0804a000 rw-p 00000000 03:03 439029                               /home/mm/src/example …………… bfffe000 - c0000000 rwxp ffff000 00:00 0 ---------------------------------------------------------------------------------------------------------------------- 每行数据格式如下： （内存区域）开始－结束访问权限  偏移  主设备号：次设备号 i节点  文件。 注意，你一定会发现进程空间只包含三个内存区域，似乎没有上面所提到的堆、bss等，其实并非如此，程序内存段和进程地址空间中的内存区域是种模糊对应，也就是说，堆、bss、数据段（初始化过的）都在进程空间种由数据段内存区域表示。   在Linux内核中对应进程内存区域的数据结构是: vm_area_struct,内核将每个内存区域作为一个单独的内存对象管理，相应的操作也都一致。采用面向对象方法使VMA结构体可以代表多种类型的内存区域－－比如内存映射文件或进程的用户空间栈等，对这些区域的操作也都不尽相同。 vm_area_strcut结构比较复杂，关于它的详细结构请参阅相关资料。我们这里只对它的组织方法做一点补充说明。vm_area_struct是描述进程地址空间的基本管理单元，对于一个进程来说往往需要多个内存区域来描述它的虚拟空间，如何关联这些不同的内存区域呢？大家可能都会想到使用链表，的确vm_area_struct结构确实是已链表形式链接，不过位了方便查找，内核又以红黑树（以前的内核使用平衡树）的形式组织内存区域，以便降低搜索耗时。并存两种组织形式，并非冗余：链表用于需要遍历全部节点的时候用，而红黑树适用于在地址空间中定位特定内存区域的时候。内核为了内存区域上的各种不同操作都能获得高性能，所以同时使用了这两种数据结构。 下图反映了进程地址空间的管理模型： mmap 进程内存描述符   Vm_area_struct 进程虚拟地址 进程的地址空间对应的描述结构是“内存描述符结构”,它表示进程的全部地址空间，——包含了和进程地址空间有关的全部信息，其中当然包含进程的内存区域。 进程内存的分配与回收 创建进程fork()、程序载入execve()、映射文件mmap()、动态内存分配malloc()/brk()等进程相关操作都需要分配内存给进程。不过这时进程申请和获得的还不是实际内存，而是虚拟内存，准确的说是“内存区域”。进程对内存区域的分配最终多会归结到do_mmap（）函数上来（brk调用被单独以系统调用实现，不用do_mmap()）， 内核使用do_mmap()函数创建一个新的线性地址区间。但是说该函数创建了一个新VMA并不非常准确，因为如果创建的地址区间和一个已经存在的地址区间相邻，并且它们具有相同的访问权限的话，那么两个区间将合并为一个。如果不能合并，那么就确实需要创建一个新的VMA了。但无论哪种情况， do_mmap()函数都会将一个地址区间加入到进程的地址空间中－－无论是扩展已存在的内存区域还是创建一个新的区域。 同样释放一个内存区域使用函数do_ummap(),它会销毁对应的内存区域。 如何由虚变实！    从上面已经看到进程所能直接操作的地址都为虚拟地址。当进程需要内存时，从内核获得的仅仅时虚拟的内存区域，而不是实际的物理地址，进程并没有获得物理内存（物理页框——页的概念请大家参与硬件基础一章），获得的仅仅是对一个新的线性地址区间的使用权。实际的物理内存只有当进程真的去访问新获取的虚拟地址时，才会由“请页机制”产生“缺页”异常，从而进入分配实际页框的例程。 该异常是虚拟内存机制赖以存在的基本保证——它会告诉内核去真正为进程分配物理页，并建立对应的页表，这之后虚拟地址才实实在在映射到了系统物理内存上。（当然如果页被换出到磁盘，也会产生缺页异常，不过这时不用再建立页表了） 这种请页机制把页框的分配推迟到不能再推迟为止，并不急于把所有的事情都一次做完（这中思想由点想涉及模式中的代理模式（proxy））。之所以能这么做是利用了内存访问的“局部性原理”，请页带来的好处是节约了空闲内存，提高了系统吞吐。要想更清楚的了解请页，可以看看《深入理解linux内核》一书。 这里我们需要说明在内存区域结构上的nopage操作，该操作是当发生访问的进程虚拟内存而发现并未真正分配页框时，该方法变被调用来分配实际的物理页，并为该页建立页表项。在最后的例子中我们会演示如何使用该方法。     系统物理内存管理  虽然应用程序操作的对象是映射到物理内存之上的虚拟内存，但是处理器直接操作的却是物理内存。所以当用程序访问一个虚拟地址时，首先必须将虚拟地址转化成物理地址，然后处理器才能解析地址访问请求。地址的转换工作需要通过查询页表才能完成，概括的讲，地址转换需要将虚拟地址分段，使每段虚地址都作为一个索引指向页表，而页表项则指向下一级别的页表或者指向最终的物理页面。 每个进程都有自己的页表。进程描述符号的pgd域指向的就是进程的页全局目录。席面我们借用《linux设备驱动程序》中的一幅图大致看看进程地址空间到物理页之间的转换关系。          上面的过程说起简单，做起难呀。因为在虚拟地址映射到页之前必须先分配物理页——也就是说必须先从内核获取空闲页，并建立页表。下面我们介绍一下内核管理物理内存的机制。 [1]静态分配内存就是编译器在编译程序的时候根据源程序来分配内存.动态分配内存就是在程序编译之后, 运行时调用运行时刻库函数来分配内存的.静态分配由于是在程序运行之前,所以速度快,效率高, 但是局限性大.动态分配在程序运行时执行, 所以速度慢,但灵活性高.   [2]术语\"BSS\"已经有些年头了，它是block started by symbol的缩写。因为未初始化的变量没有对应的值,所以并不需要存储在可执行对象中。但是因为C标准强制规定未初始化的全局变量要被赋予特殊的默认值(基本上是0值)，所以内核要从可执行代码装入变量(未赋值的)到内存中，然后将零页映射到该片内存上，于是这些未初始化变量就被赋予了0值。这样做避免了在目标文件中进行显式地初始化，减少空间浪费（来自《Linux内核开发》）","title":"Linux内存管理(上)"},{"content":"Linux内存管理(下) 物理内存管理（页管理） Linux内核管理物理内存是通过分页机制实现的，它将整个内存划分成无数4k(在i386体系结构中)大小页，从而分配和回收内存的基本单位便是内存页了。利用分页管理有助于灵活分配内存地址，因为分配时不必要求必须有大块的连续内存[1]，系统可以东一页、西一页的凑出所需要的内存供进程使用。虽然如此，但是实际上系统使用内存还是倾向于分配连续的内存块，因为分配连续内存时，页表不需要更改，因此能降低TLB的刷新率（频繁刷新会很大增加访问速度）。 鉴于上述需求，内核分配物理页为了尽量减少不连续情况，采用了“伙伴”关系来管理空闲页框。伙伴关系分配算法大家不应陌生——几乎所有操作系统书都会提到,我们不去详细说它了，如果不明白可以参看有关资料。这里只需要大家明白Linux中空闲页面的组织和管理利用了伙伴关系，因此空闲页面分配时也需要遵循伙伴关系，最小单位只能是2的幂倍页面大小。内核中分配空闲页框的基本函数是get_free_page/get_free_pages，它们或是分配单页或是分配指定的页框（2、4、8…512页）。  注意：get_free_page是在内核中分配内存，不同于malloc在用户空间中分配，malloc利用堆动态分配，实际上是调用brk()系统调用，该调用的作用是扩大或缩小进程堆空间（它会修改进程的brk域）。如果现有的内存区域不够容纳堆空间，则会以页面大小的倍数位单位，扩张或收缩对应的内存区域，但brk值并非以页面大小为倍数修改，而是按实际请求修改。因此Malloc在用户空间分配内存可以以字节为单位分配,但内核在内部仍然会是以页为单位分配的。    另外需要提及的是，物理页在系统中由页框结构struct paga描述，系统中所有的页框存储在数组mem_map[]中，可以通过该数组找到系统中的每一页（空闲或非空闲）。而其中的空闲页框则可由上述提到的以伙伴关系组织的空闲页链表（free_area[MAX_ORDER]）索引。  内核内存使用 Slab     所谓尺有所长，寸有所短。以页为最小单位分配内存对于内核管理系统物理内存来说的确比较方便，但内核自身最常使用的内存却往往是很小（远远小于一页）的内存块——比如存放文件描述符、进程描述符、虚拟内存区域描述符等行为所需的内存都不足一页。这些用来存放描述符的内存相比页面而言，就好比是面包屑与面包。一个整页中可以聚集多个这种这些小块内存；而且这些小块内存块也和面包屑一样频繁地生成/销毁。   为了满足内核对这种小内存块的需要，Linux系统采用了一种被称为slab分配器的技术。Slab分配器的实现相当复杂，但原理不难，其核心思想就是“存储池[2]”的运用。内存片段（小块内存）被看作对象，当被使用完后，并不直接释放而是被缓存到“存储池”里，留做下次使用，这无疑避免了频繁创建与销毁对象所带来的额外负载。 Slab技术不但避免了内存内部分片（下文将解释）带来的不便（引入Slab分配器的主要目的是为了减少对伙伴系统分配算法的调用次数——频繁分配和回收必然会导致内存碎片——难以找到大块连续的可用内存），而且可以很好利用硬件缓存提高访问速度。     Slab并非是脱离伙伴关系而独立存在的一种内存分配方式，slab仍然是建立在页面基础之上，换句话说，Slab将页面（来自于伙伴关系管理的空闲页框链）撕碎成众多小内存块以供分配，slab中的对象分配和销毁使用kmem_cache_alloc与kmem_cache_free。   Kmalloc Slab分配器不仅仅只用来存放内核专用的结构体，它还被用来处理内核对小块内存的请求。当然鉴于Slab分配器的特点，一般来说内核程序中对小于一页的小块内存的求情才通过Slab分配器提供的接口Kmalloc来完成（虽然它可分配32 到131072字节的内存）。从内核内存分配角度讲kmalloc可被看成是get_free_page（s）的一个有效补充，内存分配粒度更灵活了。 有兴趣的话可以到/proc/slabinfo中找到内核执行现场使用的各种slab信息统计，其中你会看到系统中所有slab的使用信息。从信息中可以看到系统中除了专用结构体使用的slab外，还存在大量为Kmalloc而准备的Slab（其中有些为dma准备的）。     内核非连续内存分配（Vmalloc）   伙伴关系也好、slab技术也好，从内存管理理论角度而言目的基本是一致的，它们都是为了防止“分片”，不过分片又分为外部分片和内部分片之说，所谓内部分片是说系统为了满足一小段内存区（连续）的需要，不得不分配了一大区域连续内存给它，从而造成了空间浪费；外部分片是指系统虽有足够的内存，但却是分散的碎片，无法满足对大块“连续内存”的需求。无论何种分片都是系统有效利用内存的障碍。slab分配器使得含与一个页面内众多小块内存可独立被分配使用，避免了内部分片，节约了空闲内存。伙伴关系把内存块按大小分组管理，一定程度上减轻了外部分片的危害，因为页框分配不在盲目，而是按照大小依次有序进行，不过伙伴关系只是减轻了外部分片，但并未彻底消除。你自己笔画一下多次分配页框后，空闲内存的剩余情况吧。 所以避免外部分片的最终思路还是落到了如何利用不连续的内存块组合成“看起来很大的内存块”——这里的情况很类似于用户空间分配虚拟内存，内存逻辑上连续，其实影射到并不一定连续的物理内存上。Linux内核借用了这个技术，允许内核程序在内核地址空间中分配虚拟地址，同样也利用页表（内核页表）将虚拟地址影射到分散的内存页上。以此完美地解决了内核内存使用中的外部分片问题。内核提供vmalloc函数分配内核虚拟内存，该函数不同于kmalloc，它可以分配较Kmalloc大得多的内存空间（可远大于128K，但必须是页大小的倍数），但相比Kmalloc来说Vmalloc需要对内核虚拟地址进行重影射，必须更新内核页表，因此分配效率上要低一些（用空间换时间） 与用户进程相似内核也有一个名为init_mm的mm_strcut结构来描述内核地址空间，其中页表项pdg=swapper_pg_dir包含了系统内核空间（3G-4G）的映射关系。因此vmalloc分配内核虚拟地址必须更新内核页表，而kmalloc或get_free_page由于分配的连续内存，所以不需要更新内核页表。   空闲页框 APP 内存区域 vm_area_structs malloc、fork、excute、mmap brk/do_map get_free_page(s) 用户空间 内核空间 进程虚拟地址空间   系统调用 进程页表   请页异常 内核程序 物理内存影射区 Vmalloc分配区 slab get_free_page(s) 内核页表 get_free_page(s) 请页异常 vmalloc分配的内核虚拟内存与kmalloc/get_free_page分配的内核虚拟内存位于不同的区间，不会重叠。因为内核虚拟空间被分区管理，各司其职。进程空间地址分布从０到３G(其实是到PAGE_OFFSET,在0x86中它等于0xC0000000)，从3G到vmalloc_start这段地址是物理内存映射区域（该区域中包含了内核镜像、物理页框表mem_map等等）比如我使用的系统内存是64M(可以用free看到)，那么(3G——3G+64M)这片内存就应该映射物理内存，而vmalloc_start位置应在3G+64M附近（说附近因为是在物理内存映射区与vmalloc_start期间还回存在一个8M大小的gap来防止跃界）,vmalloc_end的位置接近4G(说接近是因为最后位置系统会保留一片128k大小的区域用于专用页面映射，还由可能会由高端内存映射区，这些都是细节，这里我们不做纠缠)。       进程地址空间 物理内存映射区   ０ 3G 内核虚拟空间 Vmalloc_start Vmalloc_end 上图是内存分布的模糊轮廓   　  由get_free_page或Kmalloc函数所分配的连续内存都陷于物理映射区域，所以它们返回的内核虚拟地址和实际物理地址仅仅是相差一个偏移量（PAGE_OFFSET），你可以很方便的将其转化为物理内存地址，同时内核也提供了virt_to_phys（）函数将内核虚拟空间中的物理影射区地址转化为物理地址。要知道，物理内存映射区中的地址与内核页表是有序对应，系统中的每个物理页框都可以找到它对应的内核虚拟地址（在物理内存映射区中的）。 而vmalloc分配的地址则限于vmalloc_start与vmalloc_end之间。每一块vmalloc分配的内核虚拟内存都对应一个vm_struct结构体（可别和vm_area_struct搞混，那可是进程虚拟内存区域的结构），不同的内核虚拟地址被4k打大小空闲区的间隔，以防止越界——见下图）。与进程虚拟地址的特性一样，这些虚拟地址可与物理内存没有简单的位移关系，必须通过内核页表才可转换为物理地址或物理页。它们有可能尚未被映射，在发生缺页时才真正分配物理页框。   这里给出一个小程序帮助大家认请上面几种分配函数所对应的区域。 #include<linux/module.h> #include<linux/slab.h> #include<linux/vmalloc.h> unsigned char *pagemem; unsigned char *kmallocmem; unsigned char *vmallocmem; int init_module(void) {  pagemem = get_free_page(0);  printk(\"<1>pagemem=%s\",pagemem);  kmallocmem = kmalloc(100,0);  printk(\"<1>kmallocmem=%s\",kmallocmem);  vmallocmem = vmalloc(1000000);  printk(\"<1>vmallocmem=%s\",vmallocmem); } void cleanup_module(void) {  free_page(pagemem);  kfree(kmallocmem);  vfree(vmallocmem); }   内存管理实例 代码功能介绍 我们希望能通过访问用户空间的内存达到读取内核数据的目的，这样便可进行内核空间到用户空间的大规模信息传输。 具体的讲，我们要利用内存映射功能，将系统内核中的一部分虚拟内存映射到用户空间，从而使得用户空间地址等同与被映射的内核内存地址。 代码结构体系介绍 内核空间内存分配介绍 因此我们将试图写一个虚拟字符设备驱动程序，通过它将系统内核空间映射到用户空间——将内核虚拟内存映射到用户虚拟地址。当然映射地址时少不了定位内核空间对应的物理地址，并且还要建立新的用户页表项，以便用户进程寻址时能找到对应的物理内存。 从中应该看出，需要我完成既定目标，我们需要获得：被映射内核空间物理地址和建立对应的用户进程页表。 在内核空间中主要存在kmalloc分配的物理连续空间和vmalloc分配的非物理连续空间。kmalloc分配的空间往往被称为内核逻辑地址，由于它是连续分配（直接处理物理页框），而且分配首地址一定，所以其分配的内核虚拟地址对应的实际物理地址很容易获得：内核虚拟地址—PAGE_OFFSET（0xC0000000）（内核有对应例程virt_to_phys）即等于物理地址，而且其对应的页表属于内核页表（swapper_pg_dir）——在系统初始化时就以建立，因此省去了建立页表的工作。 而vmalloc分配的空间被称为内核虚拟地址，它的问题相对要复杂些，这是因为其分配的内核虚拟内存空间并非直接操作页框，而是分配的是vm_struct结构。该结构逻辑上连续但对应的物理内存并非连续，也就是说它vamlloc分配的内核空间地址所对应的物理地址并非可通过简单线性运算获得。从这个意义上讲，它的物理地址在分配前是不确定的，因此虽然vmalloc分配的空间与kmalloc一样都是由内核页表来映射的，但vmalloc分配内核虚拟地址时必须更新内核页表。   注释：vmalloc分配的内核虚拟内存与kmalloc/get_free_page分配的内核逻辑内存位于不同的区间，不会重叠。因为内核空间被分区管理，各司其职。进程空间地址分布从０到３G(其实是到PAGE_OFFSET,在0x86中它等于0xC0000000)，从3G到vmalloc_start这段地址是物理内存映射区域（该区域中包含了内核镜像、物理页框表mem_map等等）比如我使用的系统内存是64M(可以用free看到)，那么(3G——3G+64M)这片内存就应该映射物理内存，而vmalloc_start位置应在3G+64M附近（说附近因为是在物理内存映射区与vmalloc_start期间还回存在一个8M大小的gap来防止跃界）,vmalloc_end的位置接近4G(说接近是因为最后位置系统会保留一片128k大小的区域用于专用页面映射，还由可能会由高端内存映射区，这些都是细节，这里我们不做纠缠)。        另一个需要澄清的是，vmalloc分配的内核空间，其结构是vm_area，可千万别与用户空间malloc分配的vm_area_struct结构混淆。前者由内核页表映射，而后者则由用户页表映射。     进程地址空间   物理内存映射区kmalloc分配    Vmalloc 分配区   ０   3G（page_offset）   内核虚拟空间   Vmalloc_start   Vmalloc_end   上图是内存分布的模糊轮廓   实例蓝图 为了近可能丰富我们的例子程序的场景，我们选择映射vmalloc分配的内核虚拟空间(下面我们简称为vk地址)到用户空间。 要知道用户进程操作的是虚拟内存区域vm_area_struct，我们此刻需要将用户vma区间利用用户页表映射到vk对应的物理内存上去（如下图所示）。这里主要工作便是建立用户也表项完成映射工作，而这个工作完全落在了vma->nopage[3]操作上，该方法会帮助我们在发生“缺页”时，动态构造映射所需物理内存的页表项。     用户虚拟空间Vm_area_struct Vk空间vm_struct 物理内存 Vma->nopage         我们需要实现nopage方法，动态建立对应页表，而在该方法中核心任务是寻找到vk地址对应的内核逻辑地址[4]。这必然需要我们做以下工作： a)         找到vmalloc虚拟内存对应的内核页表，并寻找到对应的内核页表项。 b)        获取内核页表项对应的物理页框指针。 c)        通过页框得到对应的内核逻辑地址。 基本函数 我们实例将利用一个虚拟字符驱动程序，驱动负责将一定长的内核虚拟地址(vmalloc分配的)映射到设备文件上，以便可以通过访问文件内容来达到访问内存的目的。这样做的最大好处是提高了内存访问速度，并且可以利用文件系统的接口编程（设备在Linux中作为特殊文件处理）访问内存，降低了开发难度。    Map_driver.c就是我们的虚拟字符驱动程序，不用说它要实现文件操作表（file_operations——字符驱动程序主要做的工作便是实现该结构）中的，为了要完成内存映射，除了常规的open/release操作外，必须自己实现mmap操作，该函数将给定的文件映射到指定的地址空间上，也就是说它将负责把vmalloc分配的内核地址映射到我们的设备文件上。 我们下面就谈谈mmap操作的实现细节： 文件操作的mmap操作是在用户进行系统调用mmap[5]时被执行的，而且在调用前内核已经给用户找到并分配了合适的虚拟内存区域vm_area_struct，这个区域将代表文件内容，所以剩下要做的便是如何把虚拟区域和物理内存挂接到一起了，即构造页表。由于我门前面所说的原因，我们系统中页表需要动态分配，因此不可使用remap_page_range函数一次分配完成，而必须使用虚拟内存区域自带的nopage方法，在现场构造页表。这样以来，文件操作的mmap的方法只要完成“为它得到的虚拟内存区域绑定对应的操作表vm_operations”即可。于是主要的构造工作就落在了vm_operations中的nopage方法上了。 Nopage方法中核心内容上面已经提到了是“寻找到vk地址对应的内核逻辑地址”，这个解析内核页表的工作是需要自己编写辅助函数vaddr_to_kaddr来完成的，它所作的工作概括来讲就是上文提到的a/b/c三条。 有关整个任务执行路径请看下图。 STEP BY STEP 编译map_driver.c为map_driver.o模块,具体参数见Makefile 加载模块：insmod map_driver.o 生成对应的设备文件 1 在/proc/devices下找到map_driver对应的设备命和设备号：grep mapdrv /proc/devices 2 建立设备文件mknod  mapfile c 254 0  （在我系统里设备号为254）     利用maptest读取mapfile文件，将取自内核的信息（”ok”——我们在内核中在vmalloc分配的空间中填放的信息）打印到用户屏幕。   全部程序下载 mmap.tar （感谢Martin Frey，该程序主体出自他的灵感）             [1]还有些情况必须要求内存连续，比如DMA传输中使用的内存，由于不涉及页机制所以必须连续分配。 [2]这种存储池的思想在计算机科学里广泛应用，比如数据库连接池、内存访问池等等。 [3]构建用户也表项，除了使用nopage一次一页的动态构造，还又一种方法remap_page_range可以一次构造一段内存范围的也表项，但显然这个方法时针对物理内存连续被分配时使用的，而我们vk对应的物理内存并非连续，所以这里使用nopage。 [4]很多人一定会问，为什么不直接找到物理地址那，而要找内核逻辑地址呢？没错，我们本意应该是获得物理地址，但是为了利用内核提供的一些现成的例程，如virt_to_page等（它们都是针对内核逻辑地址而言的），我们不妨转化成内核逻辑地址来做，别忘了内核逻辑地址与理地址仅仅相差一个偏移量。 [5] 系统调用mmap原形是void *mmap2(void *start, size_t length, int prot, int flags, int fd, off_t pgoff)。","title":"Linux内存管理(下)"},{"content":"Linux 程序设计    linux 程序设计表现为两种特殊类型的文件 ： 可执行文件和脚本文件.      1* /bin : 二进制文件目录，用于存放启动系统时用到的程序。      2* /usr/bin : 用户二进制文件目录，用于存放用户使用的标准程序。      3* /usr/local/bin : 本地二进制文件目录，用于存放软件安装的程序。      4* 可选的 OS 组件和第三方应用程序可能被安装在 /opt 目录下，安装程序可以通过用户安装的脚本将路径添加到PATH环境变量中。 linux  用 : (冒号)分隔PATH变量里的条目, linux用 正斜杠 /  分隔文件里的目录名！ 文本编辑器 ： Emacs C 语言编译器 GNU C  gcc 1.2.4 开发系统导引    1，应用程序 2，头文件 3，库文件    库是一组预先编译好的函数的集合。 标准系统库文件一般存储在 /lib 和 /usr/lib 目录中。     库文件的名字总是以 lib 开头，随后的部分指明是什么库 1)，.a 代表传统的静态函数库 2), .so 代表共享函数库 -------------------------------     静态库 【meself】 gcc -c bill.c fred.cvi libady_bill.h 『/*     This is libady_bill.h. It declares the functions fred and bill for users*/void bill(char*);void fred(int);』vi program.c 『    #include <stdlib.h>    #include \"libady_bill.h\"    int main() {        bill(\"Hello World\");        exit(0);    }』gcc -c program.cgcc -o program program.o bill.o./programar crv libfoo.a bill.o fred.ogcc -o program program.o libfoo.a./programgcc -o program program.o -L. -lfoo 1.3 获得帮助   man gcc   info gcc","title":"Linux程序设计-notes [第一章]"},{"content":"Linux系统调用 摘要：本期重点和大家讨论系统调用机制。其中涉及到了一些及系统调用的性能、上下文深层问题，同时也穿插着讲述了一些内核调试方法。并且最后试验部分我们利用系统调用与相关内核服务完成了一个搜集系统调用序列的特定任务，该试验具有较强的实用和教学价值。  转自：http://blog.csdn.net/kanghua 什么是系统调用    顾名思意，系统调用说的是操作系统提供给用户程序调用的一组“特殊”接口。用户程序可以通过这组“特殊”接口来获得操作系统内核提供的服务，比如用户可以通过文件系统相关的调用请求系统打开文件、关闭文件或读写文件，可以通过时钟相关的系统调用获得系统时间或设置系统时间等。 从逻辑上来说，系统调用可被看成是一个内核与用户空间程序交互的接口——它好比一个中间人，把用户进程的请求传达给内核，待内核把请求处理完毕后再将处理结果送回给用户空间。 系统服务之所以需要通过系统调用提供给用户空间的根本原因是为了对系统“保护”，因为我们知道Linux的运行空间分为内核空间与用户空间，它们各自运行在不同的级别中，逻辑上相互隔离。所以用户进程在通常情况下不允许访问内核数据，也无法使用内核函数，它们只能在用户空间操作用户数据，调用户用空间函数。比如我们熟悉的“hello world”程序（执行时）就是标准的户空间进程，它使用的打印函数printf就属于用户空间函数，打印的字符“hello word”字符串也属于用户空间数据。 但是很多情况下，用户进程需要获得系统服务（调用系统程序），这时就必须利用系统提供给用户的“特殊”接口——系统调用了，它的特殊性主要在于规定了用户进程进入内核的具体位置；换句话说用户访问内核的路径是事先规定好的，只能从规定位置进入内核，而不准许肆意跳入内核。有了这样的陷入内核的统一访问路径限制才能保证内核安全无虞。我们可以形象地描述这种机制：作为一个游客，你可以买票要求进入野生动物园，但你必须老老实实的坐在观光车上，按照规定的路线观光游览。当然，不准下车，因为那样太危险，不是让你丢掉小命，就是让你吓坏了野生动物。   Linux的系统调用      对于现代操作系统，系统调用是一种内核与用户空间通讯的普遍手段，Linux系统也不例外。但是Linux系统的系统调用相比很多Unix和windows等系统具有一些独特之处，无处不体现出Linux的设计精髓——简洁和高效。      Linux系统调用很多地方继承了Unix的系统调用（但不是全部），但Linux相比传统Unix的系统调用做了很多扬弃，它省去了许多Unix系统冗余的系统调用，仅仅保留了最基本和最有用的系统调用，所以Linux全部系统调用只有250个左右（而有些操作系统系统调用多达1000个以上）。 这些系统调用按照功能逻辑大致可分为“进程控制”、“文件系统控制”、“系统控制”、“存管管理”、“网络管理”、“socket控制”、“用户管理”、“进程间通信”几类，详细情况可参阅文章系统调用列表 如果你想详细看看系统调用的说明，可以使用man 2syscalls命令查看，或干脆到<内核源码目录>/include/asm-i386/unistd.h源文件种找到它们的原本。 熟练了解和掌握上面这些系统调用是对系统程序员的必备要求，但对于一个开发内核者或内核开发者来[1]说死记硬背下这些调用还远远不够。如果你仅仅知道存在的调用而不知道为什么它们会存在，或只知道如何使用调用而不知道这些调用在系统中的主要用途，那么你离驾驭系统还有不小距离。 要弥补这个鸿沟，第一，你必须明白系统调用在内核里的主要用途。虽然上面给出了数种分类，不过总的概括来讲系统调用主要在系统中的用途无非以下几类： l        控制硬件——系统调用往往作为硬件资源和用户空间的抽象接口，比如读写文件时用到的write/read调用。 l        设置系统状态或读取内核数据——因为系统调用是用户空间和内核的唯一通讯手段[2]，所以用户设置系统状态，比如开/关某项内核服务（设置某个内核变量），或读取内核数据都必须通过系统调用。比如getpgid、getpriority、setpriority、sethostname l        进程管理——一系列调用接口是用来保证系统中进程能以多任务，在虚拟内存环境下得以运行。比如 fork、clone、execve、exit等 第二，什么服务应该存在于内核；或者说什么功能应该实现在内核而不是在用户空间。这个问题并不没有明确的答案，有些服务你可以选择在内核完成，也可以在用户空间完成。选择在内核完成通常基于以下考虑： l        服务必须获得内核数据，比如一些服务必须获得中断或系统时间等内核数据。 l        从安全角度考虑，在内核中提供的服务相比用户空间提供的毫无疑问更安全，很难被非法访问到。 l        从效率考虑，在内核实现服务避免了和用户空间来回传递数据以及保护现场等步骤，因此效率往往要比实现在用户空间高许多。比如,httpd等服务。 l        如果内核和用户空间都需要使用该服务，那么最好实现在内核空间，比如随机数产生。    理解上述道理对掌握系统调用本质意义很大，希望网友们能从使用中多总结，多思考。   系统调用、用户编程接口（API）、系统命令、和内核函数的关系 系统调用并非直接和程序员或系统管理员打交道，它仅仅是一个通过软中断机制（我们后面讲述）向内核提交请求，获取内核服务的接口。而在实际使用中程序员调用的多是用户编程接口——API，而管理员使用的则多是系统命令。 用户编程接口其实是一个函数定义，说明了如何获得一个给定的服务，比如read()、malloc()、free（）、abs()等。它有可能和系统调用形式上一致，比如read()接口就和read系统调用对应，但这种对应并非一一对应，往往会出现几种不同的API内部用到统一个系统调用，比如malloc()、free（）内部利用brk( )系统调用来扩大或缩小进程的堆；或一个API利用了好几个系统调用组合完成服务。更有些API甚至不需要任何系统调用——因为它不必需要内核服务，如计算整数绝对值的abs（）接口。 另外要补充的是Linux的用户编程接口遵循了在Unix世界中最流行的应用编程界面标准——POSIX标准，这套标准定义了一系列API。在Linux中（Unix也如此）这些API主要是通过C库（libc）实现的，它除了定义的一些标准的C函数外，一个很重要的任务就是提供了一套封装例程（wrapper routine）将系统调用在用户空间包装后供用户编程使用。 不过封装并非必须的，如果你愿意直接调用，Linux内核也提供了一个syscall()函数来实现调用，我们看个例子来对比一下通过C库调用和直接调用的区别。   #include <syscall.h> #include <unistd.h> #include <stdio.h> #include <sys/types.h> int main(void) { long ID1, ID2; /*-----------------------------*/ /* 直接系统调用*/ /* SYS_getpid (func no. is 20) */ /*-----------------------------*/ ID1 = syscall(SYS_getpid); printf (\"syscall(SYS_getpid)=%ld/n\", ID1); /*-----------------------------*/ /* 使用\"libc\"封装的系统调用 */ /* SYS_getpid (Func No. is 20) */ /*-----------------------------*/ ID2 = getpid(); printf (\"getpid()=%ld/n\", ID2); return(0); }   系统命令相对编程接口更高了一层，它是内部引用API的可执行程序，比如我们常用的系统命令ls、hostname等。Linux的系统命令格式遵循系统V的传统，多数放在/bin和/sbin下（相关内容可看看shell等章节）。 有兴趣的话可以通过strace ls或strace hostname命令查看一下它们用到的系统调用，你会发现诸如open、brk、fstat、ioctl等系统调用被用在系统命令中。 下一个需要解释一下的问题是内核函数和系统调用的关系，内核函数大家不要想像的过于复杂，其实它们和普通函数很像，只不过在内核实现，因此要满足一些内核编程的要求[3]。系统调用是一层用户进入内核的接口，它本身并非内核函数，进入内核后，不同的系统调用会找到对应到各自的内核函数——换个专业说法就叫：系统调用服务服务例程。实际对请求服务的是内核函数而非调用接口。 比如系统调用 getpid实际就是调用内核函数sys_getpid。 asmlinkage long sys_getpid(void) {        return current->tpid; } Linux系统种存在许多的内核函数，有些是内核文件种自己使用的，有些则是可以export出来供内核其他部分共同使用的，具体情况自己决定。 内核公开的内核函数——export出来的——可以使用命令ksyms 或 cat/proc/ksyms来查看。另外网上还有一本归纳分类内核函数的书叫作《The Linux Kernel API Book》，有兴趣的读者可以去看看。     总而言之，从用户角度向内核看，依次是系统命令、编程接口、系统调用和内核函数。再讲述了系统调用实现后，我们会回过头来看看整个执行路径。 系统调用实现 Linux中实现系统调用利用了0x86体系结构中的软件中断[4]。软件中断和我们常说的中断(硬件中断)不同之处在于——它是通过软件指令触发而并非外设，也就是说又编程人员出发的一种异常，具体的讲就是调用int $0x80汇编指令，这条汇编指令将产生向量为128的编程异常。 之所以系统调用需要借助异常实现，是因为当用户态的进程调用一个系统调用时，CPU便被切换到内核态执行内核函数[5]，而我们在i386体系结构部分已经讲述过了进入内核——进入高特权级别——必须经过系统的门机制，这里异常实际上就是通过系统门陷入内核（除了int 0x80外用户空间还可以通过int3——向量3、into——向量4、bound——向量5等异常指令进入内核，而其他异常用户空间程序无法利用，都是由系统使用的）。 我们更详细的解释一下这个过程。int $0x80指令目的是产生一个编号为128的编程异常，这个编程异常对应的中断描述符表IDT中的第128项——也就是对应的系统门描述符。门描述符中含有一个预设的内核空间地址，它指向了系统调用处理程序：system_call()（别和系统调用服务程序混淆,这个程序在entry.S文件中用汇编语言编写）。 很显然所有的系统调用都会统一的转到这个地址，但Linux一共有2、3百个系统调用都从这里进入内核后又该如何派发它们到各自的服务程序去呢？别发昏，解决这个问题的方法非常简单：首先Linux为每个系统调用都进行了编号（0—NR_syscall），同时在内核中保存了一张系统调用表，该表中保存了系统调用编号和其对应的服务例程，因此在系统调入通过系统门陷入内核前，需要把系统调用号一并传入内核，在x86上，这个传递动作是通过在执行int0x80前把调用号装入eax寄存器实现的。这样系统调用处理程序一旦运行，就可以从eax中得到数据，然后再去系统调用表中寻找相应服务例程了。 除了需要传递系统调用号以外，许多系统调用还需要传递一些参数到内核，比如sys_write(unsigned int fd, const char * buf, size_t count)调用就需要传递文件描述符号fd和要写入的内容buf和写入字节数count等几个内容到内核。碰到这种情况，Linux会有6个寄存器使用来传递这些参数：eax (存放系统调用号)、 ebx、ecx、edx、esi及edi来存放这些额外的参数（以字母递增的顺序）。具体做法是在system_call( )中使用SAVE_ALL宏把这些寄存器的值保存在内核态堆栈中。     有始便有终，当服务例程结束时，system_call( ) 从eax获得系统调用的返回值，并把这个返回值存放在曾保存用户态 eax寄存器栈单元的那个位置上。然后跳转到ret_from_sys_call( )，终止系统调用处理程序的执行。 当进程恢复它在用户态的执行前，RESTORE_ALL宏会恢复用户进入内核前被保留到堆栈中的寄存器值。其中eax返回时会带回系统调用的返回码。（负数说明调用错误，0或正数说明正常完成）   我们可以通过分析一下getpid系统调用的真是过程来将上述概念具体化，分析getpid系统调用一个办法是查看entry.s中的代码细节，逐步跟踪源码来分析运行过程，另外就是可借助一些内核调试工具，动态跟踪运行路径。 假设我们的程序源文件名为getpid.c，内容是： #include <syscall.h> #include <unistd.h> #include <stdio.h> #include <sys/types.h> int main(void) { long ID; ID = getpid(); printf (\"getpid()=%ld/n\", ID); return(0); } 将其编译成名为getpid的执行文件”gcc –o getpid <路径>/getpid.c”, 我们使用KDB来产看它进入内核后的执行路径。 l         激活KDB (按下pause键，当然你必须已经给内核打了KDB补丁);设置内核断点 “bp sys_getpid” ;退出kdb “go”;然后执行./getpid 。瞬间，进入内核调试状态,执行路径停止在断点sys_getpid处。 l         在KDB>提示符下，执行bt命令观察堆栈，发现调用的嵌套路径，可以看到在sys_getpid是在内核函数system_call中被嵌套调用的。 l         在KDB>提示符下，执行rd命令查看寄存器中的数值，可以看到eax中存放的getpid调用号——0x00000014(=20). l         在KDB>提示符下，执行ssb（或ss）命令跟踪内核代码执行路径,可以发现sys_getpid执行后，会返回system_call函数，然后接者转入ret_from_sys_call例程。（再往后还有些和调度有关其他例程，我们这里不说了它们了。）   结合用户空间的执行路径，大致该程序可归结为一下几个步骤： 1  该程序调用libc库的封装函数getpid。该封装函数中将系统调用号_NR_getpid（第20个）压入EAX寄存器， 2  调用软中断 int 0x80 进入内核。 （以下进入内核态） 3  在内核中首先执行system_call，接着执行根据系统调用号在调用表中查找到对应的系统调用服务例程sys_getpid。 4．执行sys_getpid服务例程。 5．执行完毕后，转入ret_from_sys_call例程，系统调用中返回。      内核调试是一个很有趣的话题，方法多种多样，我个人认为比较好用的是UML（user mode linux+gdb）和 KDB这两个工具。尤其KDB对于调试小规模内核模块或查看内核运行路径很有效，对于它的使用方法可以看看Linux内核调试器内幕这片文章。 系统调用思考     系统调用的内在过程并不复杂，我们不再多说了，下面这节我们主要就系统调用所涉及的一些重要问题作一些讨论和分析，希望这样能更有助了解系统调用的精髓。 调用上下文分析 系统调用虽说是要进入内核执行，但它并非一个纯粹意义上的内核例程。首先它是代表用户进程的，这点决定了虽然它会陷入内核执行，但是上下文仍然是处于进程上下文中，因此可以访问进程的许多信息（比如current结构——当前进程的控制结构），而且可以被其他进程抢占（在从系统调用返回时，由system_call函数判断是否该再调度），可以休眠，还可接收信号[6]等等。 所有这些特点都涉及到了进程调度的问题，我们这里不做深究，只要大家明白系统调用完成后，再回到或者说把控制权交回到发起调用的用户进程前，内核会有一次调度。如果发现有优先级别更高的进程或当前进程的时间片用完，那么就会选择高优先级的进程或重新选择进程运行。除了再调度需要考虑外，再就是内核需要检查是否有挂起的信号，如果发现当前进程有挂起的信号，那么还需要先返回用户空间处理信号处理例程（处于用户空间），然后再回到内核，重新返回用户空间，有些麻烦但这个反复过程是必须的。   调用性能问题 系统调用需要从用户空间陷入内核空间，处理完后，又需要返回用户空间。其中除了系统调用服务例程的实际耗时外，陷入/返回过程和系统调用处理程序（查系统调用表、存储/恢复用户现场）也需要花销一些时间，这些时间加起来就是一个系统调用的响应速度。系统调用不比别的用户程序，它对性能要求很苛刻，因为它需要陷入内核执行，所以和其他内核程序一样要求代码简洁、执行迅速。幸好Linux具有令人难以置信的上下文切换速度，使得其进出内核都被优化得简洁高效；同时所有Linux系统调用处理程序和每个系统调用本身也都非常简洁。 绝大多数情况下，Linux系统调用性能是可以接受的，但是对于一些对性能要求非常高的应用来说，它们虽然希望利用系统调用的服务，但却希望加快相应速度，避免陷入/返回和系统调用处理程序带来的花销，因此采用由内核直接调用系统调用服务例程，最好的例子就HTTPD——它为了避免上述开销，从内核调用socket等系统调用服务例程。   什么时候添加系统调用  系统调用是用户空间和内核空间交互的唯一手段，但是这并非时说要完成交互功能非要添加新系统调用不可。添加系统调用需要修改内核源代码、重新编译内核，因此如果想灵活的和内核交互信息，最好使用一下几种方法。 l        编写字符驱动程序 利用字符驱动程序可以完成和内核交互数据的功能。它最大的好处在于可以模块式加载，这样以来就避免了编译内核等手续，而且调用接口固定，容易操作。 l        使用proc文件系统 利用proc文件系统修订系统状态是一种很常见的手段，比如通过修改proc文件系统下的系统参数配置文件（/proc/sys），我们可以直接在运行时动态更改内核参数；再如，通过下面这条指令：echo 1 > /proc/sys/net/ip_v4/ip_forward开启内核中控制IP转发的开关。类似的，还有许多内核选项可以直接通过proc文件系统进行查询和调整。 l        使用虚拟文件系统 有些内核开发者认为利用ioctl（）系统调用（字符设备驱动接口）往往会似的系统调用意义不明确，而且难控制。而将信息放入到proc文件系统中会使信息组织混乱，因此也不赞成过多使用。他们建议实现一种孤立的虚拟文件系统来代替ioctl()和/proc，因为文件系统接口清楚，而且便于用户空间访问，同时利用虚拟文件系统使得利用脚本执行系统管理任务更家方便、有效。     实验部分   代码功能介绍 我们希望收集Linux系统运行时系统调用被执行的信息，既实时获取系统调用日志。这些日志信息将能以可读形式实时的返回给用户空间，以便用户观察或做近一步的日志分析（如入侵检测等）。 所以简单的讲实验代码集需要完成以下几个基本功能： 第一：记录系统调用日志，将其写入缓冲区（内核中），以便用户读取； 第二：建立新的系统调用，以便将内核缓冲中的系统调用日志返回到用户空间。 第三：循环利用系统调用，以便能动态实时返回系统调用日志。   代码结构体系介绍 基本函数 代码功能一节介绍中的基本功能对应程序代码集中的三个子程序。它们分别是syscall_auydit、Sys_audit和auditd。接下来我们介绍代码具体结构。 日志记录例程Syscall_audit syscall_audit该程序是一个内核态的服务例程，该例程负责记录系统调用的运行日志。 记录系统调用日志的具体做法是在内核中修改系统调用处理程序system_call[7]，在其中需要监控的每个调用（在我们例子钟222个系统调用都监控了，当然你也可以根据自己需求有选择的监控）执行完毕后都插入一个日志记录指令，该指令会转去调用内核服务函数syscall_audit来记录该次调用的信息[8]。 Syscall_audit内核服务例程会建立了一个内核缓冲区来存放被记录的函数。当搜集的数据量到达一定阀值时（比如设定为到达缓冲区总大小的%80，这样作可避免在丢失新调用），唤醒系统调用进程取回数据。否则继续搜集，这时系统调用程序会堵塞在一个等待队列上，直到被唤醒，也就是说如果缓冲区还没接近满时，系统调用会等待（被挂起）它被填充。 系统调用Sys_audit 由于系统调用是在内核中被执行，因此记录其执行日志也应该在内核态收集，所以我们需要利用一个新的系统调用来完成将内核信息带回到用户空间——sys_audit就是我们新填加的系统调用，它功能非常简单，就是从缓冲区中取数据返回用户空间。 为了保证数据连续性，防止丢失。我们会建立一个内核缓冲区存放每刻搜集到的日志数据，并且当搜集的数据量到达一定阀值时（比如设定为到达缓冲区总大小的%80），系统调用进程就会被唤醒[9]，以取回数据。否则在日志搜集时，系统调用程序会堵塞在等待队列上，直到被唤醒，也就是说如果缓冲区还没接近满时，系统调用会等待它被填充。 用户空间服务程序auditd 不用多说，我们需要一个用户空间服务进程来不断的调用audit系统调用，取回系统中搜集到的的调用日志信息。要知道，长时间的调用日志序列对于分析入侵或系统行为等才有价值。   把代码集成到内核中 除了上面介绍的内容外，我们还需要一些辅助性，但却很必要的工作，这些工作将帮助我们将上述代码灵活地机结成一体，完成需要的功能。 n        其一是修改entry.S汇编代码，该代码中含有系统调用表和系统调用入口代码system_call。我们首先需要在系统调用表中加入新的系统调用（名为sys_audit,223号。.long SYMBOL_NAME(sys_audit)）；下来在系统调用入口中加入跳转到日志记录服务例程中（跳转 “je auditsys”， 而auditsys代码段会真正调用系统调用记录例程syscall_audit）； n        其二是填加代码文件audit.c，该文件中包含syscall_audit与系统调用sys_audit两个函数体，我们这里只说包含函数体，而并非函数，是因为这里我们并不想把函数的实现在内核中写死，而是希望利用了函数指针，即做了两个钩子函数，来完成把具体函数实现放在模块中完成，以便能动态加载，方便调试（请见下一节介绍）。 u      其三是修改i386_ksyms.c文件，再最后加入 extern void (*my_audit)(int,int); EXPORT_SYMBOL(my_audit); extern int(*my_sysaudit)(unsigned char,unsigned char*,unsigned short,unsigned char); EXPORT_SYMBOL(my_sysaudit); ，这样做是为了导出内核符号表，以便能模块代码中能挂接上以上函数指针。 n        其四是修改内核原代码目录下/kernel自目录下的Makefile文件，很简单，只需要在obj-y    := 。。。。。最后加上audit.o，告诉编译内核是把audit.o编进去。   关键代码解释         我们的日志收集例程与取日志系统调用这两个关键函数的实现是放在内核模块中实现。其中有些需要解释的地方： 1.        模块编程的必要原则，如初始化、注销等都应该实现，所不同的是我们在初始化与注销时会分别挂上或卸下[10]了两个钩子函数的实现。 2.      我们系统调用日志记录采用了一个结构体：syscall_buf，它含有诸如系统调用号——syscall、进程ID——pid、调用程序名——comm[COMM_SIZE]等字段，共52字节；我们的内核缓冲区为audit_buf，它是一个可容纳100个syscall_buf的数组。 3.      系统调用实现极简单，要做的仅仅是利用__copy_to_user[11]将内核缓冲中的日志数据取到用户空间。为了提高效率，在缓冲区未满时（未到%80的阀值时），系统调用会挂起等待wait_event_interruptible(buffer_wait, current_pos >= AUDIT_BUF_SIZE*8/10)；相应地当缓冲区收集快满时，则唤醒系统调用继续收集日志wake_up_interruptible(&buffer_wait)。 4.      最后要补充说明一下，在auditd用户服务程序中调用我们新加的系统调用前必须利用宏_syscall4(int, audit, u8, type, u8 *, buf, u16, len, u8, reset)来“声明”该调用——展开成audit函数原形，以便进行格式转换和参数传递，否则系统不能识别。 取回数据 Audit系统调用 用户程序auditd 系统调用服务例程sys_audit 系统调用日志缓冲 Audit.o模块 my_sysaudit钩子函数 my_audit钩子函数 用户空间 内核空间 日志记录例程syscall_audit 描述日志数据流向   描述系统调用关系   程序体系图   STEP BY STEP 下面具体讲述一下如何添加这个调用。 1 修改entry.S ——在其中的添加audit调用，并且在system_call中加入搜集例程。（该函数位于<内核源代码>/arch/i386/kernel/下） 2 添加audit.c文件到<内核源代码>/arch/i386/kernel/下——该文件中定义了 sys_audit和syscall_audit两个函数需要的钩子函数（my_audit和my_sysaudit），它们会在entry.S中被使用。 3 修改<内核源代码>/arch/i386/kernel/i386-kysms.c文件，在其中导出my_audit与my_sysaudit两个钩子函数。因为只有在内核符号表里导出，才可被其他内核函数使用，也就是说才能在模块中被挂上。 4 修改<内核源代码>/arch/i386/kernel/Makefile文件，将audit.c编译入内核。 到这可以重新编译内核了，新内核已经加入了检测点了。下一步是编写模块来实现系统调用与内核搜集服务例程的功能了。 1 编写名为audit的模块，其中除了加载、卸载模块函数以外主要实现了mod_sys_audit与mod_syscall_audit两个函数。它们会分别挂载到my_sysaudit和my_audit两个钩子上。 2 编译后将模块加载 insmod audit.o。（你可通过dmesg查看是加载信息） 3 修改/usr/include/asm/unistd.h ——在其中加入audit的系统调用号。这样用户空间才可找到audit系统调用了。 4 最后，我们写一个用户deamon程序，来循环调用audit系统调用，并把搜集到的信息打印到屏幕上。 完了。系统调用还有许多细节，请大家查看有关书记吧。不罗索了。再见。   相关代码请下载 auditexample.tar（实现于2.4.18内核）。   感谢SAL的开发者，例子程序基本框架来自于它们的灵感。   [1]我们说的开发内核者指开发系统内核，比如开发驱动模块机制、开发系统调用机制；而内核开发者则是指在内核基础之上进行的开发，比如驱动开发、系统调用开发、文件系统开发、网络通讯协议开发等。我们杂志所关注的问题主要在内核开发层次，即利用内核提供的机制进行开发。   [2]对Linux而言，系统调用是用户程序访问内核的唯一手段，无论是/proc方式或设备文件方式归根到底都是利用系统调用完成的。 [3]内核编程相比用户程序编程有一些特点，简单的讲内核程序一般不能引用C库函数（除非你自己实现了，比如内核实现了不少C库种的String操作函数）；缺少内存保护措施；堆栈有限（因此调用嵌套不能过多）；而且由于调度关系，必须考虑内核执行路径的连续性，不能有长睡眠等行为。 [4]软件中断虽然叫中断，但实际上属于异常（更准确说是陷阱）——CPU发出的中断——而且是由编程者触发的一种特殊异常。 [5]系统调用过程可被理解成——由内核在核心态代表应用程序执行任务。 [6]除了进程上下文外，Linux系统中还有另一种上下文——它被成为中断上下文。中断上下文不同于进程上下文，它代表中断执行，所以和进程是异步进行而且可以说毫不相干的。这种上下文中的程序，要避免睡眠因为无法被抢占。 [7]System_call是个通用的系统调用服务程序，或说系统调用入口程序，因为任何一个系统调用都要经过system_call统一处理（查找系统调用表，跳转到相应调用的服务例程），所以任何一次系统调用的信息都可被syscall_audit记录下来。   [8] 这里我们主要记录诸如调用时刻、调用者PID、程序名等信息，这些信息可从xtime或current这些全局变量处取得。 [9] 这里需要利用等待队列，具体声明见DECLARE_WAIT_QUEUE_HEAD(buffer_wait)。   [10] 所谓挂上或卸下其实就是将函数指针指向模块中实现的函数或指向空函数，但要知道这些函数指针一定是要导出到内核符号表中的，否则找不到。 [11] 这是一个系统提供的内核函数，目的就是从内核向用户空间传递数据。","title":"Linux系统调用详解"},{"content":"http://blog.chinaunix.net/uid-23622436-id-3311579.html cat /proc/cpuinfo中的信息 processor       逻辑处理器的id。 physical id    物理封装的处理器的id。 core id        每个核心的id。 cpu cores      位于相同物理封装的处理器中的内核数量。 siblings       位于相同物理封装的处理器中的逻辑处理器的数量。   1 查看物理CPU的个数 #cat /proc/cpuinfo |grep \"physical id\"|sort |uniq|wc –l 2、   查看逻辑CPU的个数 #cat /proc/cpuinfo |grep \"processor\"|wc –l 3、  查看CPU是几核 #cat /proc/cpuinfo |grep \"cores\"|uniq 4、  查看CPU的主频 #cat /proc/cpuinfo |grep MHz|uniq  5、  # uname -a (查看当前操作系统内核信息)   Linux euis1 2.6.9-55.ELsmp #1 SMP Fri Apr20 17:03:35 EDT 2007 i686 i686 i386 GNU/Linux   6、  # cat /etc/issue | grep Linux   (查看当前操作系统发行版信息)    Red Hat Enterprise Linux AS release 4(Nahant Update 5 7、  # cat  /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c    (看到有8个逻辑CPU, 也知道了CPU型号)             8  Intel(R)Xeon(R) CPU  E5410   @ 2.33GHz    8 、  # cat/proc/cpuinfo | grep physical | uniq -c      4   physicalid     : 0      4   physicalid     : 1      (说明实际上是两颗4核的CPU)   10、# getconf LONG_BIT        32       (说明当前CPU运行在32bit模式下, 但不代表CPU不支持64bit)   11、# cat /proc/cpuinfo | grep flags | grep 'lm ' | wc –l       8     (结果大于0, 说明支持64bit计算. lm指long mode, 支持lm则是64bit)   12、如何获得CPU的详细信息：   linux命令：cat /proc/cpuinfo  13、用命令判断几个物理CPU，几个核等：   逻辑CPU个数：    # cat /proc/cpuinfo | grep\"processor\" | wc -l   物理CPU个数：    # cat /proc/cpuinfo | grep\"physical id\" | sort | uniq | wc -l   14、每个物理CPU中Core的个数：    # cat /proc/cpuinfo | grep\"cpu cores\" | wc -l   15、是否为超线程？如果有两个逻辑CPU具有相同的”coreid”，那么超线程是打开的。每个物理CPU中逻辑CPU(可能是core, threads或both)的个数：     # cat /proc/cpuinfo | grep \"siblings\"     1.查看CPU信息命令   cat /proc/cpuinfo   2.查看内存信息命令   cat /proc/meminfo   3.查看硬盘信息命令   fdisk -l 查看CPU信息（型号） # cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c       8  Intel(R) Xeon(R) CPU            E5410   @ 2.33GHz (看到有8个逻辑CPU, 也知道了CPU型号) # cat /proc/cpuinfo | grep physical | uniq -c       4 physical id      : 0       4 physical id      : 1 (说明实际上是两颗4核的CPU) PS：Jay added on 10th, May, 2011 # 其实是可能有超线程HT技术，不一定是有4核，也可能是2核4线程；当时还理解不清楚 # getconf LONG_BIT    32 (说明当前CPU运行在32bit模式下, 但不代表CPU不支持64bit) # cat /proc/cpuinfo | grep flags | grep ' lm ' | wc -l    8 (结果大于0, 说明支持64bit计算. lm指long mode, 支持lm则是64bit) 再完整看cpu详细信息, 不过大部分我们都不关心而已. # dmidecode | grep 'Processor Information' 查看内存信息 # cat /proc/meminfo # uname -a Linux euis1 2.6.9-55.ELsmp #1 SMP Fri Apr 20 17:03:35 EDT 2007 i686 i686 i386 GNU/Linux (查看当前操作系统内核信息) # cat /etc/issue | grep Linux Red Hat Enterprise Linux AS release 4 (Nahant Update 5) (查看当前操作系统发行版信息) 查看机器型号 # dmidecode | grep \"Product Name\"   查看网卡信息 # dmesg | grep -i eth","title":"Linux中查看CPU信息"},{"content":"学习嵌入式linux开发的一点建议 PS： 找不到合适地方，只好发在“原创经验”里。这事实上并不是我的什么“原创经验”，因为我也是才自学嵌入式linux开发一个月多那么一点点（还请多多多指导啊～～呵呵》》》）。在网上浏览时，看到了如何学习嵌入式linux开发的相关内容，（应该说是一些嵌入式linux培训机构的课程差不多）然后自己整理了一下。 对于是应该学嵌入式linux应用开发呢，还是系统开发，又或者是驱动开发呢？希望下面的内容能给我们这些初学者有帮助。（仅供参考） 一、编程比较熟悉，只关心系统移植，应该学什么？ 1）系统移植的方法 2）制作Bootloader 3）编译调试内核 4）定制文件系统 即：嵌入式linux系统开发 二、编程不太会，学会简单的系统移植，创建出开发平台就行，应该学什么？ 1）熟悉linux操作系统具体操作 2）熟悉并可以编译linux内核 3）熟悉嵌入式linux系统开发的整体流程 4）熟悉linux系统调用，能够熟练编写linux应用程序，包括网络、图形等 5）了解linux设备驱动程序的开发 即：嵌入式linux应用开发 三、系统编程和移植都比较熟悉了，但是硬件是自己设计的，应该学什么？ 1）linux字符设备驱动程序 2）内核内存管理与中断处理 3）块设备驱动程序，MTD以及文件系统 4）网络驱动程序 5）USB设备驱动程序开发 6）帧缓冲驱动程序和DMA 即：嵌入式linux设备驱动开发 四、系统移植和编程都比较熟悉，硬件驱动也不用自己做，对内核比较感兴趣，应该学什么？ 1）进程调度和抢占内核实现分析 2）内存管理 3）内核中的定时 4）中断和异常 5）系统调用和IPC 6）文件系统 即：linux内核开发 五、移植、应用、内核、驱动通通都懂，想锦上添花、技高一筹，应该学什么？ 1）常用的几种调试手段，如printk/printascii，kgdb/gdb调试，BDI2000调试器等方法 2）优化时常使用的内核函数跟踪工具（KFT）、linux跟踪工具（LTT），以及常用的基准测试工具（例如LMBench，LTP）。通过跟踪手段定位系统大延迟、解决相应的bug，进行内核优化 即：嵌入式linux调试技术与性能分析 无论学习以上哪种嵌入式linux的开发，掌握C/C＋＋和对linux操作系统是最基本的","title":"学习嵌入式Linux开发的方向说明"},{"content":"原帖：http://my.oschina.net/leejun2005/blog/64346 （1）快速删除大量小文件     今天遇见一个百万级的cache目录，删了20+分钟只删掉一个目录。。。。     在网上找到了一种巧妙的快速删除方法，原理很简单，使用rsync同步一个空目录即可。对于万级文件的目录基本是秒删，回车就OK。     步骤如下：       1、建立一个空目录         mkdir -p /tmp/rsync_blank     2、确立需要清空的目标目录         /data/ooxx     3、使用rsync同步删除（注意目录后面的“/”），整体效率会快一个数量级的样子。         rsync --delete-before -a -H -v --progress --stats /tmp/rsync_blank/ /data/ooxx/     选项说明：     –delete-before 接收者在传输之前进行删除操作     –progress 在传输时显示传输过程     -a 归档模式，表示以递归方式传输文件，并保持所有文件属性     -H 保持硬连接的文件     -v 详细输出模式     -stats 给出某些文件的传输状态       一般我们不需要显示进度，使用以下命令即可         rsync --delete-before -a -H /tmp/rsync_blank/ /data/ooxx/ 　　这样我们要删除的 cache目录就会被清空了。  tips：   当SRC和DEST文件性质不一致时将会报错   当SRC和DEST性质都为文件【f】时，意思是清空文件内容而不是删除文件   当SRC和DEST性质都为目录【d】时，意思是删除该目录下的所有文件，使其变为空目录   最重要的是，它的处理速度相当快，处理几个G的文件也就是秒级的事   最核心的内容是：rsync实际上用的就是替换原理  　　（2）快速复制大量小文件方法  　　1，在需要对大量小文件进行移动或复制时，用cp、mv都会显得很没有效率，可以用tar先压缩再解压缩的方式。  　　2，在网络环境中传输时，可以再结合nc命令，通过管道和tcp端口进行传输。  　　nc和tar可以用来快速的在两台机器之间传输文件和目录，比ftp和scp要来得简单的多。  　　由于nc是一个超轻量的命令，所以一般busybox都会集成它。当一个linux终端，比如linux pda,  　　通过usblan的方式连接到另一台linux主机的时候，这样的嵌入式终端上一般不会集成ftp server, ssh server  　　这样比较笨重的服务，这个时候， nc可能成为唯一的上传手段。  　　比如将机器A上的mytest目录上传到到机器 B（192.168.0.11）上，只需要：  　　在机器B上，用nc来监听一个端口，随便就好，只要不被占用；并且将收到的数据用tar展开。-l代表监听模式。  　　#nc -l 4444 |tar -C /tmp/dir -zxf -  　　然后，在A上通过nc和 tar发送test目录。使用一致的4444的端口。  　　#tar -zcvf  -  test|nc 192.168.0.11 4444 REF: http://www.blogjava.net/hongqiang/archive/2012/07/12/382939.html","title":"linux下面快速删除大量文件及快速复制大量小文件"},{"content":"Linux命令：hdparm 功能说明：显示与设定硬盘的参数。 语　　法：hdparm [-CfghiIqtTvyYZ][-a <快取分区>][-A <0或1>][-c ][-d <0或1>][-k <0或1>][-K <0或1>][-m <分区数>][-n <0或1>][-p ][-P <分区数>][-r <0或1>][-S <时间>][-u <0或1>][-W <0或1>][-X <传输模式>][设备] 补充说明：hdparm可检测，显示与设定IDE或SCSI硬盘的参数。 参　　数： -a<快取分区>   设定读取文件时，预先存入块区的分区数，若不加上<快取分区>选项，则显示目前的设定。 -A<0或1>   启动或关闭读取文件时的快取功能。 -c   设定IDE32位I/O模式。 -C   检测IDE硬盘的电源管理模式。 -d<0或1>   设定磁盘的DMA模式。 -f   将内存缓冲区的数据写入硬盘，并清楚缓冲区。 -g   显示硬盘的磁轨，磁头，磁区等参数。 -h   显示帮助。 -i   显示硬盘的硬件规格信息，这些信息是在开机时由硬盘本身所提供。 -I   直接读取硬盘所提供的硬件规格信息。 -k<0或1>   重设硬盘时，保留-dmu参数的设定。 -K<0或1>   重设硬盘时，保留-APSWXZ参数的设定。 -m<磁区数>   设定硬盘多重分区存取的分区数。 -n<0或1>   忽略硬盘写入时所发生的错误。 -p   设定硬盘的PIO模式。 -P<磁区数>   设定硬盘内部快取的分区数。 -q   在执行後续的参数时，不在屏幕上显示任何信息。 -r<0或1>   设定硬盘的读写模式。 -S<时间>   设定硬盘进入省电模式前的等待时间。 -t   评估硬盘的读取效率。 -T   平谷硬盘快取的读取效率。 -u<0或1>   在硬盘存取时，允许其他中断要求同时执行。 -v   显示硬盘的相关设定。 -W<0或1>   设定硬盘的写入快取。 -X<传输模式>   设定硬盘的传输模式。 -y   使IDE硬盘进入省电模式。 -Y   使IDE硬盘进入睡眠模式。 -Z   关闭某些Seagate硬盘的自动省电功能。     Linux下也可以使用32Bit I/O和DMA。 1使用 /sbin/hdparm -c1 /dev/hda(hdb,hdc..)打开32Bit传输模式。 [root@localhost ~]# /sbin/hdparm -c1 /dev/hda /dev/hda:  setting 32-bit IO_support flag to 1  IO_support   =  1 (32-bit) 2使用命令 /sbin/hdparm -d1 /dev/hda(hdb,hdc...)打开DMA。 [root@localhost ~]# /sbin/hdparm -d1 /dev/hda /dev/hda:  setting using_dma to 1 (on)  using_dma    =  1 (on) 3最后使用 /sbin/hdparm -k1 /dev/hda 以使硬盘在Reset之后保持上面的设定。 [root@localhost ~]# /sbin/hdparm -k1 /dev/hda /dev/hda:  setting keep_settings to 1 (on)  keepsettings =  1 (on) 这么一来，硬盘读写速度应该可以提高。 [root@localhost ~]# hdparm -t /dev/hda /dev/hda:  Timing buffered disk reads:   44 MB in  3.04 seconds =  14.50 MB/sec 但是，上面的设置只是对当前的系统有效，当再次重启系统时，又得重新设置了。 如果要使每次系统启动时都打开DMA，可以在/etc/rc.d/rc.local文件中添加上面的命令来实现： [root@anima lwg]# echo \"/sbin/hdparm -c1 -d1 -k1 /dev/hda\" >> /etc/rc.d/rc.local [root@anima lwg]#   【赛迪网-IT技术报道】目前很多朋友都用上了大容量的DMA或UDMA-33标准的硬盘。在微软的Windows98下为了使得DMA或UDMA-33标准的硬盘提高数据传输速率，可以在计算机的CMOS或操作系统中打开IDE硬盘的DMA(直接存储器存取)这项功能。但是在Linux平台中，Linux是不会自动的打开DMA模式，所以在Linux中使用这些IDE接口的UDMA-33标准的硬盘感觉数据传输远远没有在Windows中快。事实上，Linux平台中也可以通过软件来打开DMA模式，以下就是Linux下的硬盘提速的具体做法。 首先，在Linux下打开DMA模式之前，最重要的事情就是备份硬盘上的数据。因为在开启DMA模式之后谁也无法预料到硬盘是否还能正常工作，数据是否还完整。把Linux下所有的重要数据备份到其他硬盘或是CD-R等存储媒介上是最好的选择，请不要把数据备份在同一块硬盘上，更不能把数据备份到同一个硬盘分区。 第二步需要修改hdparm目录下的一些设备节点参数。但是修改这些参数必须以超级用户（ROOT）的身份登陆Linux系统才行。普通Linux用户没有这个权限修改hdparm目录下的东西。下面就是一个修改硬盘设备节点参数的例子，注意，不同型号，不同容量的硬盘可能列出的参数不太一样，但是修改的过程和方法大体上是一样的。 # /sbin/hdparm /dev/hda /dev/hda: multcount = 0 (off) I/O support = 0 (default 16-bit) unmaskirq = 0 (off) using_dma = 0 (off) keepsettings = 0 (off) nowerr = 0 (off) readonly = 0 (off) readahead = 8 (on) geometry = 629/240/63， sectors = 9514260， start = 0 # 要注意的是，OFF代表此参数不起作用，ON表示打开此功能或模式。上面的参数列表写的非常清楚，Multcount（多扇区读） 没有打开；此硬盘格式为16位格式；DMA数据传输模式没有打开。很显然，这样的参数并没有使硬盘达到最佳的优化，没有能完全发挥当今高速IDE硬盘的性能。 为了优化硬盘，提高硬盘的数据传输速率，首先还是要了解以下这些参数的含义： c3 ：就是把硬盘的16位格式转换为32位模式。 m16 ：改变硬盘的多路扇区的读功能，-m16可以使得硬盘一次读入16个扇区的数据。但是不是所有的硬盘都支持这个功能。使用hdparm -i /dev/hda 可以察看您的硬盘最大能读写的扇区数目。 d1X34：在支持DMA-capable的硬盘中，这个参数可以支持双DMA通道的数据传输模式。 d1X66：在支持UDMA-capable的硬盘中，这个参数可以支持双DMA通道的数据传输模式。 了解以上参数的作用和含义之后，现在请您仔细检查硬盘上面上的标签，看看您的硬盘是否支持DMA 或者 UDMA模式，然后才对照这些参数来优化您的硬盘，以防出现不可预见的错误。 优化硬盘的参数，也可以参考下面的例子，注意，不是所有的硬盘都适用一下的优化参数，请按照实际情况来设置参数： # hdparm -d1X66 -m16 -c3 /dev/hda # hdparm /dev/hda /dev/hda: multcount = 16 (on) I/O support = 3 (32-bit w/sync) unmaskirq = 0 (off) using_dma = 1 (on) keepsettings = 0 (off) nowerr = 0 (off) readonly = 0 (off) readahead = 8 (on) geometry = 629/240/63， sectors = 9514260， start = 0 修改完这些参数之后，有时候并不能一次性把硬盘优化成功。如果在硬盘还在正常工作的时候修改这些数据，硬盘会进入“休眠”状态。这就需要等硬盘灯会熄灭，硬盘不处于繁忙状态下优化硬盘参数比较容易成功。 hdparm的改变是一个临时的状态，下次再次启动Linux系统的时候hdparm将会消失。所以要想永久的保存修改后的信息，就必须把修改后的参数和数据写入/etc/rc.d/rc.local或者/etc/rc.local文件，甚至比启动过程要早运行的程序中。 最后要提醒大家的是，如果您的主板的芯片组或Linux内核kernel（比如内核kernel版本过于陈旧，2.2版以前)如果不支持UDMA模式，那就没有必要去修改硬盘设备的参数了。升级主板或者kernel是解决这个问题的较好选择。   hdparm -tT /dev/hda 测试硬盘速度 hdparm -A1 /dev/hda 开启硬盘预读取功能 hdparm -c3 /dev/hda 开启硬盘32位 hdparm -d1 /dev/hda 开启DMA －d 和 －A 参数对IDE硬盘读写性能影响最大   hdparm - 获取/设置硬盘参数 总览 hdparm [ -a [扇区数] ] [ -A [0|1] ] [ -c [芯片组模式] ] [ -C ] [ -d [0|1] ] [ -f ] [ -g ] [ -i ] [ -k [0|1] ] [ -K [0|1] ] [ -L [0|1] ] [ -m [扇区数] ] [ -p [0|1|2|3|4|5] ] [ -P [扇区数] ] [ -q ] [ -r [0|1] ] [ -S [超时] ] [ -T ] [ -t ] [ -u [0|1] ] [ -v ] [ -W [0|1] ] [ -X [传输模式] ] [ -y ] [ -Y ] [ -Z ] [设备] .. 描述 hdparm 提供一个实现各种硬盘控制动作的命令行接口,它由内建 Linux IDE/ST-506设备驱动程序支持.要实现这种功能需要Linux 核心版本为1.2.13或更高.在早期的核心下有一些选项可能不能正 常工作.另外,一些选项只是为包含了新的IDE设备驱动程序的核心 所支持,像2.0.10版或者更高版本的核心.如果hdparm程序是在使用 旧的核心文件(在目录usr/include/linux下)的机器上被编译的,这 些选项将无法获得. 选项 当未给出标记时, -acdgkmnru 被作为假设值 (除非一个给定的设备是SCSI设备或某种老式 XT型MFM/RLL,在这种情况下 -gr 和 -adgr 分别是默认值). -a 为文件系统提前获得/设置扇区号,可以用来改善连续读取大文件时的系统性能,具体方式为提前读取额外的预期中正在运行的任务所需要的 数据块.在当前核心版本(2.0.10版)中默认设置为8个扇区(4KB).对于 大多数用途,这个值看起来不错,但在一个大多数文件访问行为是随机 搜索的系统中,设置一个小一些的值可能效果会更好.当然,很多 IDE驱动器也有一个独立的内建的预读功能,这在很多情况下可以缓解 对文件系统预读功能的需求. -A 关闭/打开IDE驱动器预读功能(通常默认为打开). -c 查询/打开(E)IDE 32-bit I/O 支持.一个数字的参数可以被用来 打开/关闭32-bit I/O 支持.当前支持的值包括 0 关闭 32-bit I/O 支持, 1 打开 32-bit 数据传输, 和 3 以一个芯片组要求的特殊的 sync 流程打开 32-bit data 传输. 值 3 几乎对所有的32-bit IDE 芯片组起作用,但导致稍微多一些的系统开销. 注意,32-bit数据传输仅仅用于通过PCI或VLB总线与接口卡的连接; 所有的IDE驱动器通过排线从接口卡获得的连接仅为16-bit. -C 检查当前IDE能耗模式状态, 结果将是下面几种之一未知 (驱动器不支持此命令), 活动/闲置 (普通操作), 待机 (低能耗模式,驱动器待机), or 睡眠 (最低能耗模式, 驱动器被完全关闭). 选项 -S, -y, -Y, and -Z 用来操纵能耗模式. -d 为驱动器关闭/打开 \"using_dma\" 标志. 此选项仅对一些支持 DMA并且对于IDE驱动程序来说是已知的驱动器-接口组合 (包括所有被支持的XT接口).特别的,Intel Triton 芯片组 能和很多驱动器一起实现总线控制 DMA 操作.(根据实验).使用 -X34 选项与 -d1 选项组合确保驱动器自身是为多字DMA模式2设计的. 使用DMA不一定对吞吐量或系统性能有改进,但很多人信赖它. -E 设置光盘驱动器速度.对于一般性操作这不是必须的,因为驱动器将自动地自行选择自己的速度.如果你想要使用它,就在选项后提供一个数字,通常是2或4. -f 当设备退出时同步并刷新指针高速缓存.此操作也作为选项 -t 和 -T 定时的一部分被执行 -g 显示驱动器物理位置(柱面,磁头,扇区),设备的大小(以扇区为单位), 以及相对于驱动器起始的设备偏移量(以扇区为单位). -h 显示简要使用信息(帮助). -i 显示引导驱动器时获得的识别信息,如果有的话. 这是一种现代IDE驱动器特性,可能不被较老式的设备支持. 返回的数据可能是或不是当前的,这取决于自系统引导后的行为. 然而,当前的复合模式的扇区计数始终被给出. 要获得更多的关于识别信息的详细阐释,请查阅 AT Attachment Interface for Disk Drives (ANSI ASC X3T9.2 working draft, revision 4a, April 19/93). -I 直接从驱动器获取识别信息, 并以原始的,未经过修改和更正的形式显示. 否则便与选项 -i 相同. -k 获得/设置驱动器 keep_settings_over_reset 标志. 当此标志被设置,驱动程序将在一个软性的重置后保护选项 -dmu (如同在出错恢复流程中完成的那样) 此标志默认值为关 , 以防止可能由与 -dmu 组合设置导致的驱动器重置循环. 选项 -k 应该仅在你确信用一组选定的设置进行正确的系统操作之后被设置. 实际中,校验驱动器能够读/些并且在此过程中没有出错记录(核心消息, 大多数系统上/var/adm/messages中),是测试一个配置(在用-k之前)必须的. -K 设置驱动器的 keep_features_over_reset 标志. 此项设置使驱动器在软性重置后保留 -APSWXZ 标志的设置 (如同在出错恢复流程中完成的那样). 并非所有的驱动器都支持此项特性. -L 设置驱动器的doorlock标志. 设置为 将锁住一些移动式硬驱动器(像 Syquest,ZIP,Jazz..)的 门锁机构.设置为 一般Linux根据驱动器用法自动维护门锁机构.(当安装一个文件 系统时锁住).但在系统关闭时,如果根分区在一个移动式磁盘上, 可能会有麻烦,因为在关闭后根分区仍在处在安装状态(只读). 所以,使用这个命令在根文件系统以只读的方式重新被安装 ,用户可以在关闭后从驱动器中移走磁盘. -m 获得/设置驱动器多重扇区I/O的扇区数.设置为 0 关闭这项特性.多重扇区模式(aka IDE Block 模式),是大多数 现代硬盘驱动器的一项特性,它允许每次I/O中断传输多个扇区, 而不是通常的一次中断一个.当这项特性被打开时,操作系统 处理磁盘I/O的开销降低30-50%.在许多系统上,它也会在任何 地方增加5% - 50% 的数据流量大多数驱动器支持最小的设置 为2,4,8或,16个(扇区).较大的设置也可能存在,这取决于驱 动器.在许多系统上设置为16或32看起来是最理想的. Western Digital在他们的许多驱动器上推荐设置为4或8. 归因于微小的(32kB)磁盘缓冲和非最优化的缓冲算法. 选项 -i 被用来查出一个已安装驱动器支持的最大设置 (在输出中查找 MaxMultSect 值).一些驱动器声称支持多重扇区模式, 但在某些设置下丢失数据.在极少的情况下,这样的失败会导致 严重的文件系统损坏. -p 尝试为指定的PIO模式对IDE接口芯片重编程,或者尝试为驱动器支持 的最佳的PIO模式进行自动调整.核心中仅针对于一些\"知名\"的芯片组支持这项特性,甚至这种支持不一定是最好的.一些IDE芯片组不能为 一个单一的驱动器改变PIO模式,在这种情况下此选项可能导致PIO 模式的设置影响到 两个 驱动器.许多IDE芯片组支持少于或多于标准的六个(0到5)PIO模式, 所以实际实现的精确速度设置将由芯片组和驱动器复杂的配合改变. 谨慎使用. 这项特性不包含任何针对不谨慎的保护措施,一个不成功的结果 可能导致 严重的文件系统损坏. -P 为驱动器的内部预读机制设置最大扇区数. 不是所有的驱动器都支持这项特性. -q 安静的操作下一个标志,压制正常输出. 当从/etc/rc.c/rc.local运行时,可用来减轻屏幕混乱程度. 不适用于 -i 或 -v 或 -t 或 -T 标志. -r 获得/设置驱动器的只读标志.当被设置时,设备上的写操作被禁止. -R 登记一个IDE接口. 危险. 参见 -U 选项获取更多信息. -S 设置驱动器待机(低速运转)超时值. 驱动器根据此值决定在关闭主轴电机以节约能耗之前等待多长 时间(没有磁盘操作).在这种状态下,驱动器可能需要来响应一 个接下来的磁盘访问,虽然大多数驱动器要快很多.超时值的编 码有些特别.值0表示\"关\".值1到240被指定为5秒的倍数, 也就是超时可以从5秒到20分钟.值241到251指定30分钟的1到11倍, 也就是超时可以从30分钟到5.5个小时.值252表示超时21分钟, 253设置一个销售商定义的超时,255表示21分15秒. -T 用于以基准测试和比较为目的的缓存读取计时.要得到有意义的结果, 应该在内存不少于2M,系统没有其它活动(没有其它活动的程序) 的条件下,重复操作2-3次.它显示了不存取磁盘直接从Linux缓存 读取数据的速度.这项测量实际上标示了被测系统的处理器,缓存 和内存的吞吐量. 如果标志 -t 也被指定,那么一个基于 -T 输出结果的修正量将被综合到 -t 操作报告的结果中. -t 用于以基准测试和比较为目的的缓存读取计时.要得到有意义的结果, 应该在内存不少于2M,系统没有其它活动(没有其它活动的程序) 的条件下,重复操作2-3次.它显示了不使用预先的数据缓冲从磁盘 这项测量标示了Linux下没有任何文件系统开销时磁盘可以支持多快的连续数据读取.为确保测量的精确,缓存在 -t 的过程中通过BLKFLSBUF控制被刷新. 如果标志 -T 也被指定,那么一个基于 -T 数促结果的修正量将被综合到 -t 操作报告的结果中. -u 获得/设置驱动器\"不屏蔽中断\"标志.设置为 1 允许驱动器在磁盘中断处理过程中不屏蔽别的中断, 它极大改善了Linux的响应性能,并排除了\"串行端口溢出\"错误. 谨慎使用: 一些驱动器/控制器组合不能承受可能是潜在的 I/O 增长, 而导致 严重的文件系统损坏. 特别, CMD-640B 和 RZ1000 (E)IDE 接口可能是 不可靠的 (由于某种硬件缺陷),当在早于 2.0.16 版本的核心下使用此选项时. 关闭这些接口的(通常通过设置BIOS/CMOS) IDE 预读 特性可以安全的解决这个问题. -U 注销一个IDE接口. 危险. -R 的对应选项. 是为特别设计用来做热交换的硬件准备的(很罕见!). 使用时要有充分的知识和 非常的谨慎 ,因为它很容易终止或破坏你的系统. hdparm 的源代码包括一个 'contrib' 目录,里面有一些 用户捐赠的在一台 ThinkPad 600E的UltraBay上作热交换的记录. 自己去冒险吧. -v 显示所有的设置, 除了 -i (像 -acdgkmnru 对于 IDE, -gr 对于 SCSI 或 -adgr 对于 XT). 这也是未指定任何标志时的默认操作. -W 关闭/打开 IDE 驱动器的写缓存特性 (通常默认为 OFF ). -X 为较新的 (E)IDE/ATA2 驱动器设置 IDE 传输模式 . 特别是当在一个被支持的接口芯片组(像 Intel 430FX Triton) 上打开通向一个驱动器的DMA时与选项 -d1 组合使用,在这里用 -X34 来选择多字 DMA 模式2 传输. 对于支持 UltraDMA burst timings 的系统,用 -X66 来选择 UltraDMA mode2 传输 (你需要在这之前为 UltraDMA 准备好被支持的芯片组). 另外, 几乎没有必要 使用此标志,因为大多数/全部现代 IDE 驱动器默认它们最快的 PIO 传输模式为打开. 所以摆弄它是没有必要的也是冒险的. 在支持 alternate 传输模式的驱动器上, -X 可以被 仅 用来选择模式. 在改变传输模式之前, 应该为新模式的设置给 IDE 接口跳线或编程(见 -p 标志) 以防止数据的丢失或损坏. 请非常小心地使用它! 对于 Linux 使用的 PIO 传输模式,此值就是要求的 PIO 模式号加 8. 这样, 值 09 设置 PIO mode1, 10 设置 PIO mode2, 11 设置 PIO mode3. 设置为 00 还原驱动器的默认 PIO 模式, 01 关闭 IORDY. 对于多字 DMA, 使用的值时要求的 DMA 模式号加 32. 对于 UltraDMA ,相应的值是要求 UltraDMA 模式号加64. -y 迫使一个 IDE 驱动器立即进入低能耗 待机 模式, 通常使它低速运转. 当前能耗模式状态可以用 -C 标志来检查. -Y 迫使一个 IDE 驱动器立即进入最低能耗 睡眠 模式, 使它完全关闭. 一个来自硬件或软件的重置 可以重新唤醒驱动器. ( 如果需要,Linux IDE 驱动器将自动产生一个重置 ). -Z 关闭某些 Seagate 驱动器(STxxx 型?)的自动节能功能, 以防止它们在不适当的时候空转或低速运转. BUGS 像上面提到的, -m 扇区数 和 -u 1 选项尤其要小心使用, 最好在一个只读文件系统上使用. 大多数驱动器和这些特性配合得很好,但有一些驱动器/控制器 组合不是100%兼容的.使用可能导致文件系统损坏. 请在实验之前给所有的数据作备份! 某些选项 (例如: -r 对于 SCSI) 可能在旧的核心下因为核心不 支持必要的 icctl() 而不能工作. 虽然这个命令只是为使用 (E)IDE 硬盘设备准备的,但有几个选项也能够(允许)用于带有 XT 接口的 SCSI 硬盘设备和 MFM/RLL 硬盘. 最后操作步骤简洁： Linux下也可以使用32Bit I/O和DMA。使用 /sbin/hdparm -c1 /dev/hda(hdb,hdc..)打开32Bit传输模式，使用命令 /sbin/hdparm -d1 /dev/hda(hdb,hdc...)打开DMA。最后使用 /sbin/hdparm -k1 /dev/hda 以使硬盘在Reset之后保持上面的设定， 这么一来，硬盘读写速度应该可以提高一倍以上。  ","title":"Linux下提高硬盘读写速度"},{"content":"首先介绍下背景，Linux 音频系统非常不完全简史： 1. OSS3 是 Linux 内核中比较老的声音系统，目前已逐渐废弃 2. OSS4 开发的时候是闭源软件，所以 2002 年 ALSA 被用来替代 OSS3 作为 Linux 内核中的声音构架 3. 2007 年的时候 4Front Technologies 发布了 GPL 版本的 OSS4，此时 ALSA 已成气候 关于 ALSA，OSS4，PulseAudio 和 Jack 一知半解版介绍（Esd 等就此省略一万字）： 1. ALSA 目前是 Linux 内核上标准的音频框架，但是仅支持 Linux 系统，没有软件混响。对各种设备的支持非常全面。 2. OSS4 由于错过时机而没能成为官方内核的一部分，但是它的跨平台性远好于 ALSA，支持 Windows、BSD 和许多 UNIX，其 API 据说也更适合开发。OSS4 有实时、低延时的特性，支持软件混响，所有操作在内核层实现。但是对 USB 设备的支持明显薄弱许多。 3. PulseAudio 是为 POSIX 兼容环境设计的一个声音代理程序，内置软件混响。PulseAudio 可以将程序对声音系统的请求代理到 ALSA、OSS 等多种后端，甚至可以通过网络传输这些讯息。 4. Jack 是一个专业级的声音服务系统，跨平台性强，其表现对内核的实时性要求较 PulseAudio 高一些，在一般的操作系统上 Jack 没有前者流行。 Ubuntu 默认使用 ALSA 作为底层声音驱动，程序则与 PulseAudio 交互，这是一个很不错的方案。然而作者偶尔会遇到 ALSA 被独占其他软件无法发声的问题，才随着 #ubuntu-cn 上的 OSS4 热潮赶了把时髦。 换 OSS4 是要折腾的，折腾就是有风险的，以下为折腾的理由： 1. 默认的 ALSA 在你的电脑上不能正常工作 2. 纯粹喜欢 OSS4，不喜欢 ALSA 3. 想要跟风折腾 换 OSS4 的具体好处： 1. 某些情况下音质更好 2. 低延迟，低 CPU 占用 3. 自带软件混响 4. 文档更全面 换 OSS4 的具体坏处： 1. 有些硬件不被支持 2. 对 midi 支持很差 3. USB 声音设备支持仍处于试验性阶段 4. 自己折腾可能会把系统声音系统搞跨 开始说安装 OSS4 的具体方法。（注明：我是用第三种方法装的；如果你用了第二种不成功的话一定要记住卸载：appt-get remove packge<name>否则你用其他方法时会出现configure文件的覆盖粘贴错误；最后一点就是可能有其他文章会让你配置好几个项，但是我只配了第一个就好了ubuntu 12.04） 方法一 到 OSS4 官方网站下载免费商业版， 下载页面。 选择相应的版本，比如 Linux 2.6 (x86) (DEB)，点 Submit 获得下载链接。注意这个版本按许可证仅可以使用一年。 得到 deb 文件后双击安装（或者 sudo dpkg -i oss-linux*.deb）。 方法二 Ubuntu 10.10 可以直接从软件仓库安装版本略旧的 OSS4： sudo apt-get install oss4-base oss4-dkms oss4-gtk Ubuntu 10.04 和 11.04 不可以使用这个方法，10.04 仓库中的 oss4-dkms 存在打包问题无法正确构建内核模块，11.04 因为内核新（linux >= 2.6.36）而 oss4 版本太老而无法成功构建内核模块。 方法三 如果你像我一样喜欢开源版，又喜欢折腾，那么我们一起来编译最新版的。 首先安装 mercurial 以便取回最新版代码： sudo apt-get install mercurial 取出代码： cd ~ hg clone http://opensound.hg.sourceforge.net:8000/hgroot/opensound/opensound oss-devel 创建编译目录，OSS4 需要在空目录编译： cd ~/ sudo rm -rf oss42build mkdir oss42build 编译并安装，假设你的主目录是 /home/aron： cd oss42build/ NO_WARNING_CHECKS=yes /home/aron/oss-devel/configure --enable-libsalsa=NO make sudo make deb sudo dpkg -i oss*.deb 安装结束，如果没有遇到错误接下来开始配置： 1. 尽管 OSS4 内建了软件混响，我还是没有删除 PulseAudio，因为 Ubuntu 的桌面环境很多部件仅设置了 PulseAudio 后端。我不想一一折腾，而只是尽量让程序使用 OSS4，毕竟主要的播放器等都支持自定义音频输出。如果你也这样想，照下面做；如果你不想，跳过这段。 A. 修改 PulseAudio 设置使其默认使用 OSS4 输出： gksu gedit /etc/pulse/default.pa 添加一行： load-module module-oss device=”/dev/dsp” sink_name=output source_name=input mmap=0","title":"在 Ubuntu 上换用 OSS4 声音系统"},{"content":"Android4.0固件生产工具说明                          by：xian 一、准备阶段 1.1 工具简介 该工具为全志A10方案中附带程序，默认只支持ubuntu10.04 64位系统下运行。鉴于不同型号液晶屏，每种型号液晶屏可能在规格上有细微差别，该差别直接导致同种分辨率的固件在不同型号液晶屏上出现 显示模糊、抖得、黑屏无法显示 等现象。特着手对该工具做部分修改，使之能在windows系统上制作android4.0固件。用户可根据需求修改\\chips\\sun4i\\configs\\crane目录下对应配置文件然后打包生产对应固件。 1.2 准备固件制作中间文件   该打包工具制作中需要用到android4.0源码编译后生成的system.img boot.img recovery.img 三个中间文件。由于源码过于庞大，下载、搭建环境、编译、制作固件等过程耗费时间精力过多，这里只提供以上3个中间文件供用户使用。 用户只需将该3个文件文件复制到打包工具img文件夹下即可完成准备阶段 二、Linux系统下固件制作 1.1手动打包说明 1.用户如需要修改屏幕配置，可以修改chips/sun4i/configs/crane/android4.0_lvds_*文件中对应配置信息。 2.linux下打包前需将打包所需文件加入导入环境变量,如: export CRANE_IMAGE_OUT=$(pwd)/img 该目录下包涵打包所需文件: boot.img/recovery.img/system.img 3.然后在该目录下调用pack 打包,打包格式如下: ./pack -c sun4i -p crane -b android4.0_lvds_1920_1080 流程如下: 打包成功后会在当前目录下生产android4.0_lvds_1920_1080.img文件 如图: 1.2 自动打包说明 直接执行sh ./pack_linux.sh 一步完成以上所有工作 三、windows系统下固件制作 直接运行根目录下pack_windows.bat即可开启windows下打包脚本程序，如图： 选择6即可制作分辨率为1920_1080的固件包 , （win7 系统下制作过程中会弹出三个询问对话框，全选是 即可） 打包成功时显示如下 生成文件如下 点击下载android4.0固件生成器","title":"全志A10 android4.0 windows+linux版固件生成器"},{"content":"区别 1. 静态函数库    这类库的名字一般是libxxx.a；利用静态函数库编译成的文件比较大，因为整个 函数库的所有数据都会被整合进目标代码中，他的优点就显而易见了，即编译后的执行程序不需要外部的函数库支持，因为所有使用的函数都已经被编译进去了。当然这也会成为他的缺点，因为如果静态函数库改变了，那么你的程序必须重新编译。静态库第一次调用比动态库快。 2. 动态函数库    这类库的名字一般是libxxx.so;相对于静态函数库，动态函数库在编译的时候 并没有被编译进目标代码中，你的程序执行到相关函数时才调用该函数库里的相应函数，因此动态函数库所产生的可执行文件比较小。由于函数库没有被整合进你的程序，而是程序运行时动态的申请并调用，所以程序的运行环境中必须提供相应的库。动态函数库的改变并不影响你的程序，所以动态函数库的升级比较方便。 linux系统有几个重要的目录存放相应的函数库，如/lib /usr/lib。 gcc一些参数解析 -shared：指定生成动态链接库 -static：指定生成静态链接库 -fPIC：表示编译为位置独立的代码，用于编译共享库。目标文件需要创建成位置无关码，概念上就是在可执行程序装载它们的时候，它们可以放在可执行程序的内存里的任何地方。 -L.：表示要连接的库在当前目录中 -l：指定链接时需要的动态库。编译器查找动态连接库时有隐含的命名规则，即在给出的名字前面加上lib，后面加上.so来确定库的名称 -Wall：生成所有警告信息 -ggdb：此选项将尽可能的生成gdb的可以使用的调试信息 -g：编译器在编译的时候产生调试信息 -c：只激活预处理、编译和汇编,也就是把程序做成目标文件(.o文件) -Wl,options：把参数(options)传递给链接器ld。如果options中间有逗号,就将options分成多个选项,然后传递给链接程序 一：静态库 1、编写代码common.h #include <stdio.h> tmain.c #include \"common.h\"void pr1();void pr2();int main(void){        pr1();        printf(\"this is tmain\");        pr2();} pr2.c #include \"common.h\"void pr2(){       printf(\"this is pr2\");   } pr1.c #include \"common.h\"void pr1(){       printf(\"this is pr1\");   } 2、生成中间文件 gcc -c *.c 3、链接静态库 为了在编译程序中正确找到库文件,静态库必须按照 lib[name].a 的规则命名,如下例中[name]=pr.  ar -rsv libpr.a pr1.o pr2.o  正在创建 a - pr1.o  a - pr2.o  4、编译主文件 链接第三步生成的静态库 gcc -o tmain tmain.c -L. -lpr 二：动态库 1、链接动态库 gcc -fPIC -shared -o pr.so pr1.c pr2.c 生成一个 pr.so 库文件 2、动态库隐式调用 gcc -o tmain tmain.c ./pr.so ./tmain 3、动态库显式调用 略 三、库依赖查看 ldd --help","title":"linux c 动态库和静态库"},{"content":"linux学习篇5---- 《鸟哥的Linux私房菜基础学习篇（第三版）》读书笔记 1.文件系统特性 Linux 操作系统的档案权限(rwx)与文件属性(拥有者、群组、时间参数等)。 文件系统通常会将这两部分的数据分别存放在不同癿区块，权限与属性放置到inode中，至于实际数据则放置到 datablock区块中。 另外，还有一个超级区块 (superblock) 会记录整个文件系统的整体信息，包括 inode 不 block 的总量、使用量、剩余量等。 superblock：记录此 filesystem 的整体信息，包括inode/block的总量、使用量、剩余量， 以及文件系统的格式与相关信息等；  inode：记录档案的属性，一个档案占用一个inode，同时记录此档案的数据所在的每个 block 号码； block：实际记录档案的内容，若档案太大时，会占用多个 block 。 inode/block 资料存取示意图 如图 第一个为索引式文件系统（linux） 第二个为Fat  没有inode   无法一次读出所有的block号     所以一个文件的block分散太厉害的话  容易出现磁盘碎片 ps.  df指令查看挂载情况 2.与目录树的关系 当我们在 Linux 下的 ext 文件系统建立一个目录时， ext会分配一个 inode 与至少一块 block 给该目录。其中，inode 记录该目录的相关权限与属性，并可记录分配到的那块block 号码； 而block则是记录在这个目录下的文件名与该文件名占用的 inode 号码数据。 3.EXT3/EXT4 档案的存取 新增一个档案，此时文件系统的行为是： 1. 先确定用户对于欲新增档案的目彔是否具有 w 与 x 的权限，若有的话才能新增； 2. 根据 inode bitmap 找到没有使用的 inode 号码，并将新档案的权限/属性写入； 3. 根据 block bitmap 找到没有使用中的 block 号码，并将实际的数据写入 block 中，且更新 inode 的 block 指向数据； 4. 将刚刚写入的 inode 与 block 数据同步更新 inode bitmap 与 block bitmap，并更新 superblock 的内容。 4.日志式文件系统 (Journaling filesystem) 为了避免意外中断导致inode block中数据未同步到中介数据中去（上边的第四步）我们的前辈们想到一个方式， 如果在我们的 filesystem 当中规划出一个区块，该区块专门在记录写入或修订档案时的步骤， 那不就可以简化一致性检查的步骤了？也就是说： 1. 预备：当系统要写入一个档案时，会先在日志记录区块中记录某个档案准备要写入的信息； 2. 实际写入：开始写入档案的权限与数据；开始更新 metadata 的数据； 3. 结束：完成数据与 metadata 的更新后，在日志记录区块当中完成该档案的记录。 在这样的程序当中，万一数据的记录过程当中发生了问题，那么我们的系统只要去检查日志记录区块， 就可以知道那个档案发生了问题，针对该问题来做一致性的检查即可，而不必针对整块 filesystem 去检查， 这样就可以达到快速修复 filesystem 的能力了！这就是日志式档案最基础的功能。 5.Linux 文件系统的运作： 异步处理: 当系统加载一个档案到内存后，如果该档案没有被更改过，则在内存区段的档案数据会被设定为干净 (clean)的。 但如果内存中的档案数据被更改过了(例如你用 vi 去编辑过这个档案)，此时该内存中的 数据会被设定为脏的 (Dirty)。此时所有的动作都还在内存中执行，并没有写入到磁盘中！ 系统会不定 时的将内存中设定为『Dirty』的数据写回磁盘，以保持磁盘与内存数据的一致性。 你也可以利用 sync 指令来强迫写入磁盘。 Linux 文件系统与内存的关系： 系统会将常用的档案数据放置到主存储器的缓冲区，以加速文件系统的读/写； 承上，因此 Linux 的物理内存最后都会被用！加速系统效能； 你可以手动使用 sync 来强迫内存中设定为 Dirty 的档案回写到磁盘中； 若正常关机时，关机指令会主动呼叫 sync 来将内存的数据回写入磁盘内； 但若不正常关机(如跳电、当机或其他不明原因)，由于数据尚未回写到磁盘内， 因此重新启动后 可能会花很多时间在进行磁盘检验，甚至可能寻致文件系统的损毁(非磁盘损毁)。 ps。 .df：列出文件系统的整体磁盘使用量；  du：评估文件系统的磁盘使用量(常用在评估目录所占容量) 6.实体链接不符号链接： ln Hard Link (实体链接, 硬式连结或实际连结) 每个档案都会占用一个 inode ，档案内容由 inode 的记录来指向； 想要读取该档案，必须要经过目录记录的文件名来指向到正确的 inode 号码才能读取。 如图。 目标1 和目标2的block都记录了 同一个inode 这个inode指向一个档案数据内容 好处： 在于如果你将任何一个『档名』删除，其实 inode 与 block 都还是存在的！ 此时你可以透过另一个『档名』来读取到正确的档案数据！此外，不管你使用哪个『档名』来编辑， 最终的结果都会写入到相同癿 inode 与 block 中，因此均能进行据的修改！  一般来说，使用 hard link 指定链接文件时，磁盘的空间与 inode 的数目都不会改发！ 我们还是由图来看，由图中可以知道， hard link 只是在某个目录下的 block 多写入一个关连数据而已，既不会增加 inode 也不会耗用 block 数量！（就像是指针一样） 局限： 不能跨 Filesystem； 不能 link 目录。 Symbolic Link (符号链接，亦即是快捷方式) Symbolic link 就是在建立一个独立的档案，而这个档案会让数据的读取指向他 link 的那个档案的档名！由亍只是利用档案来做为指向的动作， 所以，当来源档被删除后，symbolic link 癿档案会无法打开 如图。   目标1指向的是目标2的inode  如果目标2被删除   这目标1也无法找到数据 这个 Symbolic Link 与 Windows 的快捷方式可以给他划上等号，由 Symbolic link 所建立的档案为一个独立的新档案，所以会占用掉 inode 与 block ！ 修改连接档的数据  源档案也会改变    ln [-sf] 来源文件 目标文件 -s ：如果不加任何参数就进行连结，那就是hard link，至于 -s 就是symbolic link  -f ：如果 目标文件 存在时，就主动的将目标文件直接移除后再建立！ ps. 新建目录的连接档数目为2    分别为当前目录以及上一级目录   新建后上一级目录的连接档数目会加1 7.磁盘的分割、格式化、检验与挂载： 磁盘分区： fdisk fdisk [-l] 装置名称 -l ：输出后面接的装置所有的partition 内容。若仅有 fdisk -l 时， 则系统将会把整个系统内能够搜索到的装置的 partition 均列出来。 分区后： partprobe 这个指令。这个指令的执行很简单， 他仅是告知核心必须要读取新的分割表而已，因此并不会在屏幕上出现任何信息！ 磁盘格式化：mkfs mkfs [-t 文件系统格式] 装置文件名 磁盘检验： fsck, badblocks fsck [-t 文件系统] [-ACay] 装置名称 通常使用这个指令的场合都是在系统出现极大的问题，导致你在 Linux 开机的时候得进入单人单机模式下进入维护的行为时，必项使用此指令！ 执行 fsck 时， 被检查癿 partition 务必不可挂载到系统上！亦即是需要在卸除的状态 磁盘挂载与卸除： mount umount mount 文件系统 目录 umount 目录或者文件系统 8. 开机挂载：/etc/fstab 及 /etc/mtab p286 9.特殊装置 loop 挂载 (映象档不刻录就挂载使用) mount -o loop /root/centos5.2_x86_64.iso 10.建立大档案以制作 loop 装置档案 假设我要建立一个空的档案在 /home/loopdev ，那可以这样做： [root@www ~]# dd if=/dev/zero of=/home/loopdev bs=1M count=512 格式化  mkfs -t ext3 /home/loopdev 挂载  mount -o loop /home/loopdev /media/cdrom/ 11.内存置换空间(swap)的建置 使用实体分割槽建置swap 建立 swap 分割槽的方式也是非常的简单！透过底下几个步骤： 1. 分割：先使用 fdisk 在你的磁盘中分割中一个分割槽给系统作为 swap 。由亍 Linux 癿 fdiskyu预设会将分割槽的 ID设定为 Linux 的文件系统，所以你可能还得要设定一下 sy stem ID 就是了。 2. 格式化：利用建立 swap 格式的『mkswap装置文件名』就能够格式化该分割槽成为 swap 格式啰 3. 使用：最后将该 swap 装置启动，方法为：『swapon装置文件名』。 4. 观察：最终透过 free 这个指令来观察一下内存的用量吧！ ps.fdisk无法支持2T以上的分割槽  这个时候就需要用到parted","title":"linux学习篇5--- 文件系统 实体连接与符号链接 磁盘 分割挂载 格式化 swap"},{"content":"转载请注明本文出处：leonidasFlames的blog,链接为：Linux下PostgresQL数据库C语言接口：libpq （一）     libpq 是 PostgreSQL的C语言应用程序的接口。libpq 是一套允许客户程序向PostgreSQL 后端服务进程发送查询 并且获得查询返回的库．libpq 同时也是其他几个 PostgreSQL 应用接口下面的引擎， 包括libpq++ （C++），libpgtcl（Tcl），Perl，和ecpg。 注意事项： 1. 在C语言程序中，需要包含<libpq-fe.h>头文件，并必须在编译时添加相应链接标记：-lpq。 2. 在C++语言程序中，有两套头文件及其库函数，分别是早期的<libpq++.h>和<pqxx/pqxx>，两者库函数完全不同。其中<libpq++.h>为更早期的，网上示例较多。   一、libpq库下C语言程序对PostgreSQL数据的访问连接   1.首先看一个简单示例： #include <iostream> #include<postgresql/libpq-fe.h> using namespace std; /******************************************************************************/ int main(int argc, char** argv) {       const char*conninfo=\"hostaddr=127.0.0.1 user=Meme dbname=MyDatabasepassword=123\";         PGconn* conn=PQconnectdb(conninfo);       if(PQstatus(conn)==CONNECTION_OK)     {         cout<<\"连接PostgreSQL数据库 成功！\"<<endl;         PQfinish(conn);         cout<<\"与PostgreSQL数据库连接 关闭！\"<<endl;     }     else     {         cout<<\"连接失败！\"<<endl;     }     return 0; } /******************************************************************************/ 2. 与后端数据库服务器建立一个新的连接 PGconn　*PQconnectdb(const char *conninfo) ; 从字符串conninfo传参以建立与Database的连接。字符串中可以包含如下信息 host 主机 hostaddr 主机IP地址 port 端口或套接字扩展文件名 dbname 数据库名 user 用户名 password 用户密码 option 调试选项 及connect_timeout，tty，sslmode，requiressl等其他不常用信息。 一般使用的是：     const char* conninfo=\"hostaddr=127.0.0.1user=Meme dbname=MyDatabase password=123\"; 以上这几种必要信息。字符串写法大致为”关键字=数值 “形式，参照该示例即可。 3. PGconn *PQsetdbLogin(const char* pghost,const char* pgport,const char*pgoption,const char* pgtty,const char* dbname,const char* login,const char* pwd); 该函数是PGconnectdb()前身，功能上一致，区别在于固定个数的参数，具体可参照官方文档。由于PGconnectdb()在使用上更为灵活，首推使用PGconnectdb()。   4. 关闭连接 void PQfinish(PGconn* conn); 释放被PGconn对象使用的存储器，PGconn指针不可再使用   5. 返回连接状态。 ConnStatusType PQstatus(const PGconn* conn); 返回状态，最常用的是这两个： CONNECTION_OK 与DB成功连接 CONNECTION_BAD与DB连接失败 通常，一个OK状态将保持到PQfinish()，但一个通讯失败可能导致状态过早地变为BAD。这时，程序可试用PQreset()恢复。   6. 重新连接 void PQreset(PGconn* conn);   7. 与数据库服务器建立一个非阻塞连接 PGconn* PQconnectStart(const char* conninfo); PosgresPollingStatusType *PQconnectPoll(PGconn *conn); 你的应用执行线程在运行时不会阻塞远端I/O。你必须在调用PQconnectPoll()之前确保socket处于正确的状态。这两个函数都不会阻塞线程。 PostgreSQL libpq的数据库连接方面简单使用就是这些，参照上文示例，我们已经可以让C语言程序成功连接PostgreSQL数据库了，以后的文章将接着介绍libpq的其他函数，诸如数据库查询函数等等。","title":"Linux下PostgresQL数据库C语言接口：libpq （一）数据库连接"},{"content":"Currently I have no idea how to organize the whole contents, I will update it later give your more comfort to read this and may this can be helpful for your work. 1. How to use Cscope to browse Linux kernel code 1.1) First, make sure you have cscope installed in your Linux distribution (I used Redhat 6.0). Usually, these Linux destros installed cscope by default. 1.2) Second is to generate the database used by cscope ( you can find more details here: http://cscope.sourceforge.net/large_projects.html, but if you does not care details, focus on my tutorial is enough :).  You can use the following command(suppose \"#\" is the command line prompt):         # scope -R -b -k   scope have lots of options for you to customize generating symbol database. Here we can only use these three options for Linux kernel source.   \"-R\": recursively search for source files in directory tree.   \"-b\":  build the cross-reference only   \"-k\": \"kernel mode\", turn off the use of default include dir (usually /usr/include/), this really make sense. You really do not hope to jump to some user level function definition when you try locate a kernel function call. 1.3) Cscope has its own gui to browse and search the desired symbols. But, it can use Vim or emacs or other famous editors to show the searched results. I'm not familiar with emacs, so I will only give the BKM (Best known methods) in Vim editor. Vim editor of 6.x or new version basically includes built-in support for cscope. If you happenly has vim source and you can recompile the source with option --enable-scope. But the suggested way is to download the latest version and got everything fixed. There is a good tutorial about how to use cscope in vim (http://cscope.sourceforge.net/cscope_vim_tutorial.html), But you do not to read it if you just want to get your environment cscope+Vim work. So stay with me.  You need to download a vim plugin (http://cscope.sourceforge.net/cscope_maps.vim) and put it in your $HOME/.vim/plugin directory. If you do not have such directory, make it now. After done all of above you need to close the Vim editor since your changes upon Vim configure can only effect when you restart Vim again. Now lets restart your Vim editor, you may got some error messges, it looks like this: line 45:E568: duplicate cscope database not added To fix this issue, you can edit your $HOME/.vim/plugin/cscope_maps.vim, and change \"set cscopeverbose\" to \"set nocscopeverbose\". Also you need to add a line \"set nocscopeverbose\" in your $HOME/.vimrc. After all of these configure and fixes. Now let us check how cscope can be used in Vim 1.4) The best known method of how to a vim plugin is to check its source code. But we may not need those advanced operation, let us just focus on the most easily usage: search a symbol in source tree Put your cursor on some symbol (function/variable/type definitions) and type \"<CTRL>+\\\" (combine <ctrl>  and \"\\\") and another quick type for \"s\". And you will see the list of results pop up just like the ctags. Choose the one you want to jump to. And type \"<CTRL>+t\" to go back. (Here the symbol \"+\" only means you should type the key on its left and then type the key on it right, please do not type \"+\")","title":"Cscope how to"},{"content":"  1. java.lang.NoClassDefFoundError 问题：无法运行.class文件 解决：路径不正确，需转到.class文件所在的路径即可。     类找不到异常是因为JVM找不到class文件。为什么没找到呢？去哪里找呢？当前路径？实际不是。实际是去环境变量有个叫CLASSPATH中去找路径。按顺序从前往后。   A如果CLASSPATH（windows下小写也可以，但是建议大写，否则linux就不行了）没有配置,默认的CLASSPATH就是当前路径。   B如果CLASSPATH配置了，那么就按你配置的来。   直接利用 java –cp目录类文件的主文件名 2.Exception in thread “main” java.lang.NoSuchMethodError：main 问题：不能运行.class文件 解决：没有main方法，加上main方法即可。       找到class文件,文件中缺少main方法。主方法，也就是程序入口方法。就好比QQ，运行QQ程序首先要执行启动登录界面方法。 3. java.lang.ArithmeticException public class P{  public static void main(String[] args)\t{\t    double d3 = 0/0;//问题出现在这里。            System.out.println(d3);\t}}   此程序运行时会出现如下错误。","title":"学习过程中遇到的Exception"},{"content":"一、几个重要设备端Gadget驱动结构体： 1. struct usb_gadget {//代表一个UDC设备          /* readonly to gadget driver */                 const struct usb_gadget_ops *ops; //设备的操作集                struct usb_ep *ep0; //ep0（USB协议中的端点0）, 处理setup()请求                struct list_head ep_list; /* of usb_ep */本设备支持的端点链表                enum usb_device_speed speed; //如：USB_SPEED_LOW、USB_SPEED_FULL等                unsigned is_dualspeed:1; //支持full/high speed                unsigned is_otg:1; //OTG的特性                unsigned is_a_peripheral:1; //当前是A-peripheral，而不是A-host                 unsigned b_hnp_enable:1;                 unsigned a_hnp_support:1;                 unsigned a_alt_hnp_support:1;                 const char *name;                struct device dev;          }; 2. struct usb_gadget_driver {//代表一个gadget设备driver，如：file_storage.c中的fsg_driver //又如：如zero.c中的zero_driver                char *function; //一个字符串，如\"Gadget Zero\"                 enum usb_device_speed speed;                 int (*bind)(struct usb_gadget *);       //常用语将dev 与driver的绑定，类似于probe，会被底层Gadget自动调用                void (*unbind)(struct usb_gadget *);    //与bind作用相反                int (*setup)(struct usb_gadget *,    const struct usb_ctrlrequest *);    //用于usb设备setup阶段的USB_REQ_GET_DESCRIPTOR等主机端的请求处理，完成USB设置阶段和具体功能相关的交互                void (*disconnect)(struct usb_gadget *);                void (*suspend)(struct usb_gadget *);                 void (*resume)(struct usb_gadget *)        /* FIXME support safe rmmod */                 struct device_driver driver;          }; 3. struct usb_gadget_ops {//代表设备的操作集                        int (*get_frame)(struct usb_gadget *);                        int (*wakeup)(struct usb_gadget *);                        int (*set_selfpowered) (struct usb_gadget *, int is_selfpowered);                        nt (*vbus_session) (struct usb_gadget *, int is_active);                        int (*vbus_draw) (struct usb_gadget *, unsigned mA);                        int (*pullup) (struct usb_gadget *, int is_on);                        int (*ioctl)(struct usb_gadget *,                        unsigned code, unsigned long param);          }; 4. struct usb_ep {//代表一个端点                        void *driver_data //                         ...                        const struct usb_ep_ops *ops; //端点的操作集，如上                        struct list_head ep_list; //gadget的所有ep的list                        ...         };    5.     struct usb_ep_ops {//表示端点的操作集                         ...                         int (*queue) (struct usb_ep *ep, struct usb_request *req,                         gfp_t gfp_flags); //将一个usb_request提交给endpoint                         //是数据传输的关键函数                         ...         }; 6.  struct usb_request {//表示一个传输的请求，这与usb host端的urb类似                        void *buf;                         unsigned length;                         dma_addr_t dma;                        unsigned no_interrupt:1;                        unsigned zero:1;                        unsigned short_not_ok:1;                        void (*complete)(struct usb_ep *ep,  struct usb_request *req);   //一个usb请求提交完成后的回调函数                        void *context;                        struct list_head list;                        int status;                        unsigned actual;         }; 7.  struct usb_ctrlrequest (用在setup函数中） |-----------------------| | __u8    bRequestType -| | __u8    bRequest     -| | __le16 -wValue       -| | __le16 -wIndex       -| | __le16 -wLength      -| |-----------------------| 这个数据结构就是SETUP信包的内容，而缓冲区的内容，就是随后的数据信包的内容。 --------------------------------------------------------------- bRequestType     D7     数据的传输方向：0表示从主机到设备； 1表示从设备到主机；     D6~5   命令的类型：   0表示标准命令；    1表示类命令；      2表示厂商提供的命令； 3保留；     D4~0   接收对象；     0表示设备；       1表示接口；       2表示端点；         3表示其他； bRequest     命令的序号(其实就是命令)；所有的命令都是以不同编码值的方式传递给设备的，bRequest就表示USB命令的编码值 wValue, wIndex     这两个字段对于不同的命令有不同的含义 wLength     表示在完成命令控制传输的数据阶段，要求传输数据的字节长度。一般不论是输入还是输出都要求给出准确的数字。当命令不需要传输数据时，此字段设为0 二、Gadget层驱动提供的几个常用的函数： 1. usb_gadget_register_driver  注册usb_gadget_driver类型的驱动 2. usb_gadget_unregister_driver 注销usb_gadget_driver类型驱动 3. struct usb_ep * __init usb_ep_autoconfig (     struct usb_gadget        *gadget,     struct usb_endpoint_descriptor    *desc )    用于根据端点描述符及控制器端点情况，分配一个合适的端点。 4. static inline struct usb_request *usb_ep_alloc_request(struct usb_ep *ep,                                gfp_t gfp_flags)  分配一个usb_request 3. 通过Gadget Core 驱动，向usb_ep发送usb_request, 请求读写 static inline int usb_ep_queue(struct usb_ep *ep,                    struct usb_request *req, gfp_t gfp_flags);     三、USB gadget功能驱动        如果内核已经支持了SOC的UDC驱动，很多时候，我们可以只关心这部分代码的编写。那么我们如何编写出一个类似usb 功能驱动呢？        usb 功能驱动应该至少要实现如下功能：        .       实现USB协议中端点0部分和具体功能相关的部分（UDC驱动无法帮我们完成的部分）。如：USB_REQ_GET_DESCRIPTOR、USB_REQ_GET_CONFIGURATION等；                        完成了这个功能以后，USB主机端系统就会设别出我们是一个什么样的设备。                .       实现数据交互功能                        即如何实现向硬件控制器的端点发出读、写请求来完成数据交互；                .       具体功能的实现如：如何实现一个usb net驱动，或是一个usb storage驱动。 四、实例 Linux内核2.6.28中 drivers/usb/gadget/Zero.c的源码提供了一个编写USB 设备端的驱动框架（利用Gadget层提供的函数，当然底层还需要有UDC层的支持）。 该例子的功能是： USB 设备端提供了一个USB_DIR_IN 用于接收主机数据的端点，同时通过产生一个字符设备与之关联，对其进行读的操作： 字符设备只定义了如下接口 struct file_operations usb_zero_fops = {                 .owner = THIS_MODULE,                 .read = usb_zero_read,                 .open = usb_zero_open,                 .release = usb_zero_release,         }; 完整的源代码： /* * zero.c -- Gadget Zero, for simple USB development         * lht@farsight.com.cn         * All rights reserved.*/         /* #define VERBOSE_DEBUG */ #include <linux/kernel.h>         #include <linux/utsname.h>         #include <linux/device.h>         #include <linux/usb/ch9.h>         #include <linux/usb/gadget.h>         #include \"gadget_chips.h\"         #include <linux/slab.h>         #include <linux/module.h>         #include <linux/init.h>         #include <linux/usb/input.h>         #include <linux/cdev.h>         #include <asm/uaccess.h>         #include <linux/fs.h>         #include <linux/poll.h>         #include <linux/types.h> /* size_t */         #include <linux/errno.h> /* error codes */         #include <asm/system.h>         #include <asm/io.h>         #include <linux/sched.h> /*-------------------------------------------------------------------------*/         static const char shortname[] = \"zero\";         static const char loopback[] = \"loop input to output\";         static const char longname[] = \"Gadget Zero\";         static const char source_sink[] = \"source and sink data\";         #define STRING_MANUFACTURER 25         #define STRING_PRODUCT 42         #define STRING_SERIAL 101         #define STRING_SOURCE_SINK 250         #define STRING_LOOPBACK 251 //#define DRIVER_VENDOR_NUM 0x0525 /* NetChip */         //#define DRIVER_PRODUCT_NUM 0xa4a0 /* Linux-USB \"Gadget Zero\" */         #define DRIVER_VENDOR_NUM 0x5345 /* NetChip */         #define DRIVER_PRODUCT_NUM 0x1234 /* Linux-USB \"Gadget Zero\" */ static int usb_zero_major = 251;         /*-------------------------------------------------------------------------*/         static const char *EP_OUT_NAME; /* sink */         /*-------------------------------------------------------------------------*/ /* big enough to hold our biggest descriptor */         #define USB_BUFSIZ 256         struct zero_dev { //zero设备结构                     spinlock_t lock;                     struct usb_gadget *gadget;                     struct usb_request *req; /* for control responses */                     struct usb_ep *out_ep;                     struct cdev cdev;                     unsigned char data[128];                     unsigned int data_size;                     wait_queue_head_t bulkrq;         };         #define CONFIG_LOOPBACK 2         static struct usb_device_descriptor device_desc = { //设备描述符                     .bLength = sizeof device_desc,                     .bDescriptorType = USB_DT_DEVICE,                     .bcdUSB = __constant_cpu_to_le16(0x0110),                     .bDeviceClass = USB_CLASS_VENDOR_SPEC,                     .idVendor = __constant_cpu_to_le16(DRIVER_VENDOR_NUM),                     .idProduct = __constant_cpu_to_le16(DRIVER_PRODUCT_NUM),                     .iManufacturer = STRING_MANUFACTURER,                     .iProduct = STRING_PRODUCT,                     .iSerialNumber = STRING_SERIAL,                     .bNumConfigurations = 1,         };         static struct usb_endpoint_descriptor fs_sink_desc = { //端点描述符                     .bLength = USB_DT_ENDPOINT_SIZE,                     .bDescriptorType = USB_DT_ENDPOINT,    .bEndpointAddress = USB_DIR_OUT, //对主机端来说，输出                     .bmAttributes = USB_ENDPOINT_XFER_BULK,         }; static struct usb_config_descriptor loopback_config = { //配置描述符                     .bLength = sizeof loopback_config,                     .bDescriptorType = USB_DT_CONFIG,                     /* compute wTotalLength on the fly */                     .bNumInterfaces = 1,                     .bConfigurationValue = CONFIG_LOOPBACK,                     .iConfiguration = STRING_LOOPBACK,                     .bmAttributes = USB_CONFIG_ATT_ONE | USB_CONFIG_ATT_SELFPOWER,                     .bMaxPower = 1, /* self-powered */         };         static const struct usb_interface_descriptor loopback_intf = { //接口描述符                     .bLength = sizeof loopback_intf,                     .bDescriptorType = USB_DT_INTERFACE,     .bNumEndpoints = 1,                     .bInterfaceClass = USB_CLASS_VENDOR_SPEC,                     .iInterface = STRING_LOOPBACK,         };         /* static strings, in UTF-8 */         #define STRING_MANUFACTURER 25         #define STRING_PRODUCT 42         #define STRING_SERIAL 101         #define STRING_SOURCE_SINK 250         #define STRING_LOOPBACK 251         static char manufacturer[50];         /* default serial number takes at least two packets */         static char serial[] = \"0123456789.0123456789.0123456789\";         static struct usb_string strings[] = { //字符串描述符                     { STRING_MANUFACTURER, manufacturer, },                     { STRING_PRODUCT, longname, },                     { STRING_SERIAL, serial, },                     { STRING_LOOPBACK, loopback, },                     { STRING_SOURCE_SINK, source_sink, },                     { } /* end of list */         }; static struct usb_gadget_strings stringtab = {                     .language = 0x0409, /* en-us */                     .strings = strings,         }; static const struct usb_descriptor_header *fs_loopback_function[] = {                     (struct usb_descriptor_header *) &loopback_intf,                     (struct usb_descriptor_header *) &fs_sink_desc,                     NULL,         }; static int         usb_zero_open (struct inode *inode, struct file *file) //打开设备         {                   struct zero_dev *dev =                     container_of (inode->i_cdev, struct zero_dev, cdev);                     file->private_data = dev;                   init_waitqueue_head (&dev->bulkrq);          return 0;         } static int         usb_zero_release (struct inode *inode, struct file *file) //关闭设备         {                   return 0;         }         static void free_ep_req(struct usb_ep *ep, struct usb_request *req)         {                     kfree(req->buf);                     usb_ep_free_request(ep, req);         }         static struct usb_request *alloc_ep_req(struct usb_ep *ep, unsigned length)//分配请求         {                     struct usb_request *req;             req = usb_ep_alloc_request(ep, GFP_ATOMIC);                     if (req) {                                 req->length = length;                                 req->buf = kmalloc(length, GFP_ATOMIC);                                 if (!req->buf) {                                         usb_ep_free_request(ep, req);                                         req = NULL;                                 }                     }                     return req;         }         static void source_sink_complete(struct usb_ep *ep, struct usb_request *req)//请求完成函数         {                     struct zero_dev *dev = ep->driver_data;                     int status = req->status;                     switch (status) {                     case 0: /* normal completion */                                if (ep == dev->out_ep) {                                         memcpy(dev->data, req->buf, req-> actual);//返回数据拷贝到req->buf中，                                                                                                     //dev->data_size=req->length;                                         dev->data_size=req->actual; //实际长度为req-> actual；需要确认         req –>short_not_ok为0。参考gadget.h中关于usb_request结构的注释                                 }                                 break;                      /* this endpoint is normally active while we're configured */                     case -ECONNABORTED: /* hardware forced ep reset */                     case -ECONNRESET: /* request dequeued */                     case -ESHUTDOWN: /* disconnect from host */                                printk(\"%s gone (%d), %d/%d\\n\", ep->name, status,                                                   req->actual, req->length);                     case -EOVERFLOW: /* buffer overrun on read means that                                                               * we didn't provide a big enough                                                               * buffer.                                                               */                     default:         #if 1                                printk(\"%s complete --> %d, %d/%d\\n\", ep->name,                                                   status, req->actual, req->length);         #endif                     case -EREMOTEIO: /* short read */                                break;                     }                     free_ep_req(ep, req);                     wake_up_interruptible (&dev->bulkrq); //唤醒读函数         } static struct usb_request *source_sink_start_ep(struct usb_ep *ep)//构造并发送读请求         {                     struct usb_request *req;                     int status;                     //printk(\"in %s\\n\",__FUNCTION__);                     req = alloc_ep_req(ep, 128);                     if (!req)                                return NULL;                     memset(req->buf, 0, req->length);                     req->complete = source_sink_complete; //请求完成函数                     status = usb_ep_queue(ep, req, GFP_ATOMIC); //递交请求                     if (status) {                              struct zero_dev *dev = ep->driver_data;                              printk(\"start %s --> %d\\n\", ep->name, status);                              free_ep_req(ep, req);                              req = NULL;                     }                     return req;         }         ssize_t         usb_zero_read (struct file * file, const char __user * buf, size_t count,loff_t * f_pos) //读设备         {                     struct zero_dev *dev =file->private_data;                     struct usb_request *req;                     int status;                     struct usb_ep *ep;                     struct usb_gadget *gadget = dev->gadget;                     ssize_t ret = 0;                     int result;                     ep=dev->out_ep;                     source_sink_start_ep(ep);//构造、递交读请求                     if (count < 0)                              return -EINVAL;                     interruptible_sleep_on (&dev->bulkrq);//睡眠，等到请求完成                     if (copy_to_user (buf,dev->data,dev->data_size)) //拷贝读取的数据到用户空间                     {                          ret = -EFAULT;                     }                     else                     {                         ret = dev->data_size;                     }                     return ret;         } struct file_operations usb_zero_fops = {                 .owner = THIS_MODULE,                 .read = usb_zero_read,                 .open = usb_zero_open,                 .release = usb_zero_release,         }; static void         usb_zero_setup_cdev (struct zero_dev *dev, int minor)//注册字符设备驱动         {                 int err, devno = MKDEV (usb_zero_major, minor);      cdev_init(&dev->cdev, &usb_zero_fops);                 dev->cdev.owner = THIS_MODULE;                 err = cdev_add (&dev->cdev, devno, 1);                 if (err)                    printk (\"Error adding usb_rcv\\n\");         } static void zero_setup_complete(struct usb_ep *ep, struct usb_request *req)//配置端点0的请求 完成处理         {                    if (req->status || req->actual != req->length)                       printk(\"setup complete --> %d, %d/%d\\n\",                                       req->status, req->actual, req->length);         }         static void zero_reset_config(struct zero_dev *dev) //复位配置         {                       usb_ep_disable(dev->out_ep);                       dev->out_ep = NULL;         }         static void zero_disconnect(struct usb_gadget *gadget)//卸载驱动时被调用，做一些注销工作         {                    struct zero_dev *dev = get_gadget_data(gadget);                    unsigned long flags;                    unregister_chrdev_region (MKDEV (usb_zero_major, 0), 1);                    cdev_del (&(dev->cdev));                    zero_reset_config(dev);                    printk(\"in %s\\n\",__FUNCTION__);         } static int config_buf(struct usb_gadget *gadget,                       u8 *buf, u8 type, unsigned index)         {                    //int is_source_sink;                    int len;                    const struct usb_descriptor_header **function;                    int hs = 0;                    function =fs_loopback_function;//根据fs_loopback_function，得到长度，                                                          //此处len=配置（9）+1个接口（9）+1个端点（7）=25                    len = usb_gadget_config_buf(&loopback_config,                                       buf, USB_BUFSIZ, function);                    if (len < 0)                                       return len;                    ((struct usb_config_descriptor *) buf)->bDescriptorType = type;                    return len;         } static int set_loopback_config(struct zero_dev *dev)         {                 int result = 0;                 struct usb_ep *ep;                 struct usb_gadget *gadget = dev->gadget;                 ep=dev->out_ep;                 const struct usb_endpoint_descriptor *d;                 d = &fs_sink_desc;                 result = usb_ep_enable(ep, d); //激活端点                 //printk(\"\");                 if (result == 0) {                                 printk(\"connected\\n\"); //如果成功，打印“connected”                 }                 else                                 printk(\"can't enable %s, result %d\\n\", ep->name, result);                 return result;         }         static int zero_set_config(struct zero_dev *dev, unsigned number)         {                 int result = 0;                 struct usb_gadget *gadget = dev->gadget;                 result = set_loopback_config(dev);//激活设备                 if (result)                         zero_reset_config(dev); //复位设备                 else {                         char *speed; switch (gadget->speed) {                         case USB_SPEED_LOW: speed = \"low\"; break;                         case USB_SPEED_FULL: speed = \"full\"; break;                         case USB_SPEED_HIGH: speed = \"high\"; break;                         default: speed = \" \"; break;                         }                 }                 return result;         }         /***         zero_setup完成USB设置阶段和具体功能相关的交互部分         ***/         static int         zero_setup(struct usb_gadget *gadget, const struct usb_ctrlrequest *ctrl)         {                 struct zero_dev *dev = get_gadget_data(gadget);                 struct usb_request *req = dev->req;                 int value = -EOPNOTSUPP;                 u16 w_index = le16_to_cpu(ctrl->wIndex);                 u16 w_value = le16_to_cpu(ctrl->wValue);                 u16 w_length = le16_to_cpu(ctrl->wLength); /* usually this stores reply data in the pre-allocated ep0 buffer,                    * but config change events will reconfigure hardware.                    */                 req->zero = 0; switch (ctrl->bRequest) {                 case USB_REQ_GET_DESCRIPTOR: //获取描述符                         if (ctrl->bRequestType != USB_DIR_IN)                                goto unknown;                         switch (w_value >> 8) {                         case USB_DT_DEVICE: //获取设备描述符                                 value = min(w_length, (u16) sizeof device_desc);                                 memcpy(req->buf, &device_desc, value);                                 break;                         case USB_DT_CONFIG: //获取配置，注意：会根据fs_loopback_function读取到接口、端点描述符，注意通过config_buf完成读取数据及数量的统计。                                 value = config_buf(gadget, req->buf,                                                 w_value >> 8,                                                 w_value & 0xff);                                 if (value >= 0)                                         value = min(w_length, (u16) value);                                 break; case USB_DT_STRING:                                 value = usb_gadget_get_string(&stringtab,                                                 w_value & 0xff, req->buf);                                 if (value >= 0)                                         value = min(w_length, (u16) value);                                 break;                         }                         break; case USB_REQ_SET_CONFIGURATION:                         if (ctrl->bRequestType != 0)                                 goto unknown;                         spin_lock(&dev->lock);                         value = zero_set_config(dev, w_value);//激活相应的端点                         spin_unlock(&dev->lock);                         break; default:         unknown:                         printk(                                 \"unknown control req%02x.%02x v%04x i%04x l%d\\n\",                                 ctrl->bRequestType, ctrl->bRequest,                                 w_value, w_index, w_length);                   }                   /* respond with data transfer before status phase */                   if (value >= 0) {                         req->length = value;                         req->zero = value < w_length;                         value = usb_ep_queue(gadget->ep0, req, GFP_ATOMIC);//通过端点0完成setup                         if (value < 0) {                                        printk(\"ep_queue --> %d\\n\", value);                                        req->status = 0;                                        zero_setup_complete(gadget->ep0, req);                         }                   }                   /* device either stalls (value < 0) or reports success */                   return value;         }         static void zero_unbind(struct usb_gadget *gadget) //解除绑定         {                 struct zero_dev *dev = get_gadget_data(gadget); printk(\"unbind\\n\");                 unregister_chrdev_region (MKDEV (usb_zero_major, 0), 1);                 cdev_del (&(dev->cdev));                 /* we've already been disconnected ... no i/o is active */                 if (dev->req) {                         dev->req->length = USB_BUFSIZ;                         free_ep_req(gadget->ep0, dev->req);                 }                 kfree(dev);                 set_gadget_data(gadget, NULL);         }         static int __init zero_bind(struct usb_gadget *gadget) //绑定过程         {                 struct zero_dev *dev;                 struct usb_ep *ep;                 int gcnum;                 usb_ep_autoconfig_reset(gadget);                 ep = usb_ep_autoconfig(gadget, &fs_sink_desc);//根据端点描述符及控制器端点情况，分配一个合适的端点。                 if (!ep)                         goto enomem;                 EP_OUT_NAME = ep->name; //记录名称                 gcnum = usb_gadget_controller_number(gadget);//获得控制器代号                 if (gcnum >= 0)                         device_desc.bcdDevice = cpu_to_le16(0x0200 + gcnum);//赋值设备描述符                 else {                         pr_warning(\"%s: controller '%s' not recognized\\n\",                               shortname, gadget->name);                         device_desc.bcdDevice = __constant_cpu_to_le16(0x9999);         }         dev = kzalloc(sizeof(*dev), GFP_KERNEL); //分配设备结构体         if (!dev)                 return -ENOMEM;         spin_lock_init(&dev->lock);         dev->gadget = gadget;         set_gadget_data(gadget, dev);         dev->req = usb_ep_alloc_request(gadget->ep0, GFP_KERNEL);//分配一个请求         if (!dev->req)                 goto enomem;         dev->req->buf = kmalloc(USB_BUFSIZ, GFP_KERNEL);         if (!dev->req->buf)                 goto enomem;         dev->req->complete = zero_setup_complete;         dev->out_ep=ep; //记录端点（就是接收host端数据的端点）         printk(\"name=%s\\n\",dev->out_ep->name); //打印出这个端点的名称         ep->driver_data=dev;         device_desc.bMaxPacketSize0 = gadget->ep0->maxpacket;         usb_gadget_set_selfpowered(gadget);         gadget->ep0->driver_data = dev;         snprintf(manufacturer, sizeof manufacturer, \"%s %s with %s\",                 init_utsname()->sysname, init_utsname()->release,         gadget->name); /**************************字符设备注册*******************/         dev_t usb_zero_dev = MKDEV (usb_zero_major, 0);         int result = register_chrdev_region (usb_zero_dev, 1, \"usb_zero\");         if (result < 0)         {                 printk (KERN_NOTICE \"Unable to get usb_transfer region, error %d\\n\",result);                 return 0;         }         usb_zero_setup_cdev (dev, 0);         return 0;     enomem:         zero_unbind(gadget);         return -ENOMEM;     } /*-------------------------------------------------------------------------*/         static struct usb_gadget_driver zero_driver = { //gadget驱动的核心数据结构         #ifdef CONFIG_USB_GADGET_DUALSPEED                         .speed = USB_SPEED_HIGH,         #else                         .speed = USB_SPEED_FULL,         #endif                         .function = (char *) longname,                         .bind = zero_bind,                         .unbind = __exit_p(zero_unbind),                         .setup = zero_setup,                         .disconnect = zero_disconnect,                         //.suspend = zero_suspend, //不考虑电源管理的功能                         //.resume = zero_resume,                         .driver = {                                 .name = (char *) shortname,                                 .owner = THIS_MODULE,                         },         };         MODULE_AUTHOR(\"David Brownell\");         MODULE_LICENSE(\"GPL\");         static int __init init(void)         {                 return usb_gadget_register_driver(&zero_driver); //注册驱动，调用bind绑定到控制器         }         module_init(init); static void __exit cleanup(void)         {                 usb_gadget_unregister_driver(&zero_driver); //注销驱动，通常会调用到unbind解除绑定， //在s3c2410_udc.c中调用的是disconnect方法         }         module_exit(cleanup);","title":"Linux gadget USB设备端驱动程序（kernel 2.6.28）"},{"content":"linux上用v4l2函数接口获取视频主要是一个步骤流程，一步步做就很容易，现已我在qt下编写的一个读取摄像头视频的程序中的相关代码为例。 首先打开视频设备，比如/dev/video0， fd = open(dev_name.toStdString().c_str(), O_RDWR/*|O_NONBLOCK*/, 0);    if(-1 == fd)    {        emit display_error(tr(\"open: %1\").arg(QString(strerror(errno))));        return -1;    }然后初始化设备     v4l2_capability cap;    v4l2_cropcap cropcap;    v4l2_crop crop;    v4l2_format fmt;    if(-1 == ioctl(fd, VIDIOC_QUERYCAP, &cap))    {   //查询设备功能        if(EINVAL == errno)        {            emit display_error(tr(\"%1 is no V4l2 device\").arg(dev_name));        }        else        {            emit display_error(tr(\"VIDIOC_QUERYCAP: %1\").arg(QString(strerror(errno))));        }        return -1;    }    if(!(cap.capabilities & V4L2_CAP_VIDEO_CAPTURE))    {   //视频采集        emit display_error(tr(\"%1 is no video capture device\").arg(dev_name));        return -1;    }    if(!(cap.capabilities & V4L2_CAP_STREAMING))    {   //视频流        emit display_error(tr(\"%1 does not support streaming i/o\").arg(dev_name));        return -1;    }    CLEAR(cropcap);    cropcap.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;    if(0 == ioctl(fd, VIDIOC_CROPCAP, &cropcap))    {        CLEAR(crop);        crop.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;        crop.c = cropcap.defrect;        if(-1 == ioctl(fd, VIDIOC_S_CROP, &crop))        {            if(EINVAL == errno)            {                emit display_error(tr(\"VIDIOC_S_CROP not supported\"));            }            else            {                emit display_error(tr(\"VIDIOC_S_CROP: %1\").arg(QString(strerror(errno))));                return -1;            }        }    }    else    {        emit display_error(tr(\"VIDIOC_CROPCAP: %1\").arg(QString(strerror(errno))));        return -1;    }    CLEAR(fmt);    fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;    fmt.fmt.pix.width = 640;    fmt.fmt.pix.height = 480;    fmt.fmt.pix.pixelformat = V4L2_PIX_FMT_YUYV;//YUV4:2:2    fmt.fmt.pix.field = V4L2_FIELD_INTERLACED;//隔行扫描    if(-1 == ioctl(fd, VIDIOC_S_FMT, &fmt))    {  //设置视频格式        emit display_error(tr(\"VIDIOC_S_FMT\").arg(QString(strerror(errno))));        return -1;    }    if(-1 == init_mmap())    {  //初始化mmap，内存映射        return -1;    }初始化mmap        v4l2_requestbuffers req;    CLEAR(req);    req.count = 4;    req.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;    req.memory = V4L2_MEMORY_MMAP;    if(-1 == ioctl(fd, VIDIOC_REQBUFS, &req))    {   //请求buf        if(EINVAL == errno)        {            emit display_error(tr(\"%1 does not support memory mapping\").arg(dev_name));            return -1;        }        else        {            emit display_error(tr(\"VIDIOC_REQBUFS %1\").arg(QString(strerror(errno))));            return -1;        }    }    if(req.count < 2)    {        emit display_error(tr(\"Insufficient buffer memory on %1\").arg(dev_name));        return -1;    }    buffers = (buffer*)calloc(req.count, sizeof(*buffers));//分配内存大小    if(!buffers)    {        emit display_error(tr(\"out of memory\"));        return -1;    }    for(n_buffers = 0; n_buffers < req.count; ++n_buffers)    {        v4l2_buffer buf;        CLEAR(buf);        buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;        buf.memory = V4L2_MEMORY_MMAP;        buf.index = n_buffers;        if(-1 == ioctl(fd, VIDIOC_QUERYBUF, &buf))        {   //获取buf信息起始位置，长度等            emit display_error(tr(\"VIDIOC_QUERYBUF: %1\").arg(QString(strerror(errno))));            return -1;        }        buffers[n_buffers].length = buf.length;        buffers[n_buffers].start =                mmap(NULL, // start anywhere                     buf.length,                     PROT_READ | PROT_WRITE,                     MAP_SHARED,                     fd, buf.m.offset);//映射        if(MAP_FAILED == buffers[n_buffers].start)        {            emit display_error(tr(\"mmap %1\").arg(QString(strerror(errno))));            return -1;        }    }开始捕获视频 int VideoDevice::start_capturing(){    unsigned int i;    for(i = 0; i < n_buffers; ++i)    {        v4l2_buffer buf;        CLEAR(buf);        buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;        buf.memory =V4L2_MEMORY_MMAP;        buf.index = i;//        fprintf(stderr, \"n_buffers: %d\\n\", i);        if(-1 == ioctl(fd, VIDIOC_QBUF, &buf))        {   //把buf排成一列            emit display_error(tr(\"VIDIOC_QBUF: %1\").arg(QString(strerror(errno))));            return -1;        }    }    v4l2_buf_type type;    type = V4L2_BUF_TYPE_VIDEO_CAPTURE;    if(-1 == ioctl(fd, VIDIOC_STREAMON, &type))    {        emit display_error(tr(\"VIDIOC_STREAMON: %1\").arg(QString(strerror(errno))));        return -1;    }    return 0;}获取一帧图像 int VideoDevice::get_frame(void **frame_buf, size_t* len){    v4l2_buffer queue_buf;    CLEAR(queue_buf);    queue_buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;    queue_buf.memory = V4L2_MEMORY_MMAP;    if(-1 == ioctl(fd, VIDIOC_DQBUF, &queue_buf))    {   //从队列中取出一个buf        switch(errno)        {        case EAGAIN://            perror(\"dqbuf\");            return -1;        case EIO:            return -1 ;        default:            emit display_error(tr(\"VIDIOC_DQBUF: %1\").arg(QString(strerror(errno))));            return -1;        }    }    *frame_buf = buffers[queue_buf.index].start;    *len = buffers[queue_buf.index].length;    index = queue_buf.index;    return 0;}获取完后，将这一帧图像的buf放回去 int VideoDevice::unget_frame(){    if(index != -1)    {        v4l2_buffer queue_buf;        CLEAR(queue_buf);        queue_buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;        queue_buf.memory = V4L2_MEMORY_MMAP;        queue_buf.index = index;        if(-1 == ioctl(fd, VIDIOC_QBUF, &queue_buf))        {   //将buf放入队列            emit display_error(tr(\"VIDIOC_QBUF: %1\").arg(QString(strerror(errno))));            return -1;        }        return 0;    }    return -1;}停止视频捕捉 int VideoDevice::stop_capturing(){    v4l2_buf_type type;    type = V4L2_BUF_TYPE_VIDEO_CAPTURE;    if(-1 == ioctl(fd, VIDIOC_STREAMOFF, &type))    {        emit display_error(tr(\"VIDIOC_STREAMOFF: %1\").arg(QString(strerror(errno))));        return -1;    }    return 0;}卸载摄像头设备 int VideoDevice::uninit_device(){    unsigned int i;    for(i = 0; i < n_buffers; ++i)    {        if(-1 == munmap(buffers[i].start, buffers[i].length))        {            emit display_error(tr(\"munmap: %1\").arg(QString(strerror(errno))));            return -1;        }    }    free(buffers);    return 0;}关闭视频设备文件 int VideoDevice::close_device(){    if(-1 == close(fd))    {        emit display_error(tr(\"close: %1\").arg(QString(strerror(errno))));        return -1;    }    return 0;}这就是完整的采集视频的流程，当然可以多增加配置采集的视频格式的代码。","title":"linux v4l2 摄像头采集视频的方法"},{"content":"一  valgrind是什么？ Valgrind是一套Linux下，开放源代码（GPL V2）的仿真调试工具的集合。Valgrind由内核（core）以及基于内核的其他调试工具组成。内核类似于一个框架（framework），它模拟了一个CPU环境，并提供服务给其他工具；而其他工具则类似于插件 (plug-in)，利用内核提供的服务完成各种特定的内存调试任务。Valgrind的体系结构如下图所示： valgrind的结构图 Valgrind包括如下一些工具： Memcheck。这是valgrind应用最广泛的工具，一个重量级的内存检查器，能够发现开发中绝大多数内存错误使用情况，比如：使用未初始化的内存，使用已经释放了的内存，内存访问越界等。这也是本文将重点介绍的部分。 Callgrind。它主要用来检查程序中函数调用过程中出现的问题。 Cachegrind。它主要用来检查程序中缓存使用出现的问题。 Helgrind。它主要用来检查多线程程序中出现的竞争问题。 Massif。它主要用来检查程序中堆栈使用中出现的问题。 Extension。可以利用core提供的功能，自己编写特定的内存调试工具 linux下内存空间布置： 一个典型的Linux C程序内存空间由如下几部分组成： 代码段（.text）。这里存放的是CPU要执行的指令。代码段是可共享的，相同的代码在内存中只会有一个拷贝，同时这个段是只读的，防止程序由于错误而修改自身的指令。 初始化数据段（.data）。这里存放的是程序中需要明确赋初始值的变量，例如位于所有函数之外的全局变量：int val=\"100\"。需要强调的是，以上两段都是位于程序的可执行文件中，内核在调用exec函数启动该程序时从源程序文件中读入。 未初始化数据段（.bss）。位于这一段中的数据，内核在执行该程序前，将其初始化为0或者null。例如出现在任何函数之外的全局变量：int sum; 堆（Heap）。这个段用于在程序中进行动态内存申请，例如经常用到的malloc，new系列函数就是从这个段中申请内存。 栈（Stack）。函数中的局部变量以及在函数调用过程中产生的临时变量都保存在此段中。 Memcheck 能够检测出内存问题，关键在于其建立了两个全局表。 Valid-Value 表： 对于进程的整个地址空间中的每一个字节(byte)，都有与之对应的 8 个 bits；对于 CPU 的每个寄存器，也有一个与之对应的 bit 向量。这些 bits 负责记录该字节或者寄存器值是否具有有效的、已初始化的值。 Valid-Address 表 对于进程整个地址空间中的每一个字节(byte)，还有与之对应的 1 个 bit，负责记录该地址是否能够被读写。 检测原理： 当要读写内存中某个字节时，首先检查这个字节对应的 A bit。如果该A bit显示该位置是无效位置，memcheck 则报告读写错误。 内核（core）类似于一个虚拟的 CPU 环境，这样当内存中的某个字节被加载到真实的 CPU 中时，该字节对应的 V bit 也被加载到虚拟的 CPU 环境中。一旦寄存器中的值，被用来产生内存地址，或者该值能够影响程序输出，则 memcheck 会检查对应的V bits，如果该值尚未初始化，则会报告使用未初始化内存错误。 Valgrind 使用 用法: valgrind [options] prog-and-args [options]: 常用选项，适用于所有Valgrind工具 -tool=<name> 最常用的选项。运行 valgrind中名为toolname的工具。默认memcheck。 h –help 显示帮助信息。 -version 显示valgrind内核的版本，每个工具都有各自的版本。 q –quiet 安静地运行，只打印错误信息。 v –verbose 更详细的信息, 增加错误数统计。 -trace-children=no|yes 跟踪子线程? [no] -track-fds=no|yes 跟踪打开的文件描述？[no] -time-stamp=no|yes 增加时间戳到LOG信息? [no] -log-fd=<number> 输出LOG到描述符文件 [2=stderr] -log-file=<file> 将输出的信息写入到filename.PID的文件里，PID是运行程序的进行ID -log-file-exactly=<file> 输出LOG信息到 file -log-file-qualifier=<VAR> 取得环境变量的值来做为输出信息的文件名。 [none] -log-socket=ipaddr:port 输出LOG到socket ，ipaddr:port LOG信息输出 -xml=yes 将信息以xml格式输出，只有memcheck可用 -num-callers=<number> show <number> callers in stack traces [12] -error-limit=no|yes 如果太多错误，则停止显示新错误? [yes] -error-exitcode=<number> 如果发现错误则返回错误代码 [0=disable] -db-attach=no|yes 当出现错误，valgrind会自动启动调试器gdb。[no] -db-command=<command> 启动调试器的命令行选项[gdb -nw %f %p] 适用于Memcheck工具的相关选项： -leak-check=no|summary|full 要求对leak给出详细信息? [summary] -leak-resolution=low|med|high how much bt merging in leak check [low] -show-reachable=no|yes show reachable blocks in leak check? [no] Valgrind 使用举例（一） 下面是一段有问题的C程序代码test.c ＃i nclude <stdlib.h>void f(void){   int* x = malloc(10 * sizeof(int));   x[10] = 0;  //问题1: 数组下标越界}                  //问题2: 内存没有释放 int main(void){   f();   return 0; } 1、 编译程序test.cgcc -Wall test.c -g -o test2、 使用Valgrind检查程序BUGvalgrind --tool=memcheck --leak-check=full ./test 使用未初始化内存问题 问题分析： 对于位于程序中不同段的变量，其初始值是不同的，全局变量和静态变量初始值为0，而局部变量和动态申请的变量，其初始值为随机值。如果程序使用了为随机值的变量，那么程序的行为就变得不可预期。 下面的程序就是一种常见的，使用了未初始化的变量的情况。数组a是局部变量，其初始值为随机值，而在初始化时并没有给其所有数组成员初始化，如此在接下来使用这个数组时就潜在有内存问题。   结果分析： 假设这个文件名为：badloop.c，生成的可执行程序为badloop。用memcheck对其进行测试，输出如下。   输出结果显示，在该程序第11行中，程序的跳转依赖于一个未初始化的变量。准确的发现了上述程序中存在的问题。 内存读写越界 问题分析： 这种情况是指：访问了你不应该/没有权限访问的内存地址空间，比如访问数组时越界；对动态内存访问时超出了申请的内存大小范围。下面的程序就是一个典型的数组越界问题。pt是一个局部数组变量，其大小为4，p初始指向pt数组的起始地址，但在对p循环叠加后，p超出了pt数组的范围，如果此时再对p进行写操作，那么后果将不可预期。   结果分析： 假设这个文件名为badacc.cpp，生成的可执行程序为badacc，用memcheck对其进行测试，输出如下。   输出结果显示，在该程序的第15行，进行了非法的写操作；在第16行，进行了非法读操作。准确地发现了上述问题。 内存覆盖 问题分析： C 语言的强大和可怕之处在于其可以直接操作内存，C 标准库中提供了大量这样的函数，比如 strcpy, strncpy, memcpy, strcat 等，这些函数有一个共同的特点就是需要设置源地址 (src)，和目标地址(dst)，src 和 dst 指向的地址不能发生重叠，否则结果将不可预期。 下面就是一个 src 和 dst 发生重叠的例子。在 15 与 17 行中，src 和 dst 所指向的地址相差 20，但指定的拷贝长度却是 21，这样就会把之前的拷贝值覆盖。第 24 行程序类似，src(x+20) 与 dst(x) 所指向的地址相差 20，但 dst 的长度却为 21，这样也会发生内存覆盖。   结果分析： 假设这个文件名为 badlap.cpp，生成的可执行程序为 badlap，用 memcheck 对其进行测试，输出如下。   输出结果显示上述程序中第15，17，24行，源地址和目标地址设置出现重叠。准确的发现了上述问题。 动态内存管理错误 问题分析： 常见的内存分配方式分三种：静态存储，栈上分配，堆上分配。全局变量属于静态存储，它们是在编译时就被分配了存储空间，函数内的局部变量属于栈上分配，而最灵活的内存使用方式当属堆上分配，也叫做内存动态分配了。常用的内存动态分配函数包括：malloc, alloc, realloc, new等，动态释放函数包括free, delete。 一旦成功申请了动态内存，我们就需要自己对其进行内存管理，而这又是最容易犯错误的。下面的一段程序，就包括了内存动态管理中常见的错误。   常见的内存动态管理错误包括：   申请和释放不一致 由于 C++ 兼容 C，而 C 与 C++ 的内存申请和释放函数是不同的，因此在 C++ 程序中，就有两套动态内存管理函数。一条不变的规则就是采用 C 方式申请的内存就用 C 方式释放；用 C++ 方式申请的内存，用 C++ 方式释放。也就是用 malloc/alloc/realloc 方式申请的内存，用 free 释放；用 new 方式申请的内存用 delete 释放。在上述程序中，用 malloc 方式申请了内存却用 delete 来释放，虽然这在很多情况下不会有问题，但这绝对是潜在的问题。   申请和释放不匹配 申请了多少内存，在使用完成后就要释放多少。如果没有释放，或者少释放了就是内存泄露；多释放了也会产生问题。上述程序中，指针p和pt指向的是同一块内存，却被先后释放两次。   释放后仍然读写 本质上说，系统会在堆上维护一个动态内存链表，如果被释放，就意味着该块内存可以继续被分配给其他部分，如果内存被释放后再访问，就可能覆盖其他部分的信息，这是一种严重的错误，上述程序第16行中就在释放后仍然写这块内存。 结果分析： 假设这个文件名为badmac.cpp，生成的可执行程序为badmac，用memcheck对其进行测试，输出如下。   输出结果显示，第14行分配和释放函数不一致；第16行发生非法写操作，也就是往释放后的内存地址写值；第17行释放内存函数无效。准确地发现了上述三个问题。 内存泄漏 问题描述： 内存泄露（Memory leak）指的是，在程序中动态申请的内存，在使用完后既没有释放，又无法被程序的其他部分访问。内存泄露是在开发大型程序中最令人头疼的问题，以至于有人说，内存泄露是无法避免的。其实不然，防止内存泄露要从良好的编程习惯做起，另外重要的一点就是要加强单元测试（Unit Test），而memcheck就是这样一款优秀的工具。 下面是一个比较典型的内存泄露案例。main函数调用了mk函数生成树结点，可是在调用完成之后，却没有相应的函数：nodefr释放内存，这样内存中的这个树结构就无法被其他部分访问，造成了内存泄露。 在一个单独的函数中，每个人的内存泄露意识都是比较强的。但很多情况下，我们都会对malloc/free 或new/delete做一些包装，以符合我们特定的需要，无法做到在一个函数中既使用又释放。这个例子也说明了内存泄露最容易发生的地方：即两个部分的接口部分，一个函数申请内存，一个函数释放内存。并且这些函数由不同的人开发、使用，这样造成内存泄露的可能性就比较大了。这需要养成良好的单元测试习惯，将内存泄露消灭在初始阶段。       结果分析： 假设上述文件名位tree.h, tree.cpp, badleak.cpp，生成的可执行程序为badleak，用memcheck对其进行测试，输出如下。   该示例程序是生成一棵树的过程，每个树节点的大小为12（考虑内存对齐），共8个节点。从上述输出可以看出，所有的内存泄露都被发现。Memcheck将内存泄露分为两种，一种是可能的内存泄露（Possibly lost），另外一种是确定的内存泄露（Definitely lost）。Possibly lost 是指仍然存在某个指针能够访问某块内存，但该指针指向的已经不是该内存首地址。Definitely lost 是指已经不能够访问这块内存。而Definitely lost又分为两种：直接的（direct）和间接的（indirect）。直接和间接的区别就是，直接是没有任何指针指向该内存，间接是指指向该内存的指针都位于内存泄露处。在上述的例子中，根节点是directly lost，而其他节点是indirectly lost。 一  valgrind是什么？ Valgrind是一套Linux下，开放源代码（GPL V2）的仿真调试工具的集合。Valgrind由内核（core）以及基于内核的其他调试工具组成。内核类似于一个框架（framework），它模拟了一个CPU环境，并提供服务给其他工具；而其他工具则类似于插件 (plug-in)，利用内核提供的服务完成各种特定的内存调试任务。Valgrind的体系结构如下图所示： valgrind的结构图 Valgrind包括如下一些工具： Memcheck。这是valgrind应用最广泛的工具，一个重量级的内存检查器，能够发现开发中绝大多数内存错误使用情况，比如：使用未初始化的内存，使用已经释放了的内存，内存访问越界等。这也是本文将重点介绍的部分。 Callgrind。它主要用来检查程序中函数调用过程中出现的问题。 Cachegrind。它主要用来检查程序中缓存使用出现的问题。 Helgrind。它主要用来检查多线程程序中出现的竞争问题。 Massif。它主要用来检查程序中堆栈使用中出现的问题。 Extension。可以利用core提供的功能，自己编写特定的内存调试工具 linux下内存空间布置： 一个典型的Linux C程序内存空间由如下几部分组成： 代码段（.text）。这里存放的是CPU要执行的指令。代码段是可共享的，相同的代码在内存中只会有一个拷贝，同时这个段是只读的，防止程序由于错误而修改自身的指令。 初始化数据段（.data）。这里存放的是程序中需要明确赋初始值的变量，例如位于所有函数之外的全局变量：int val=\"100\"。需要强调的是，以上两段都是位于程序的可执行文件中，内核在调用exec函数启动该程序时从源程序文件中读入。 未初始化数据段（.bss）。位于这一段中的数据，内核在执行该程序前，将其初始化为0或者null。例如出现在任何函数之外的全局变量：int sum; 堆（Heap）。这个段用于在程序中进行动态内存申请，例如经常用到的malloc，new系列函数就是从这个段中申请内存。 栈（Stack）。函数中的局部变量以及在函数调用过程中产生的临时变量都保存在此段中。 Memcheck 能够检测出内存问题，关键在于其建立了两个全局表。 Valid-Value 表： 对于进程的整个地址空间中的每一个字节(byte)，都有与之对应的 8 个 bits；对于 CPU 的每个寄存器，也有一个与之对应的 bit 向量。这些 bits 负责记录该字节或者寄存器值是否具有有效的、已初始化的值。 Valid-Address 表 对于进程整个地址空间中的每一个字节(byte)，还有与之对应的 1 个 bit，负责记录该地址是否能够被读写。 检测原理： 当要读写内存中某个字节时，首先检查这个字节对应的 A bit。如果该A bit显示该位置是无效位置，memcheck 则报告读写错误。 内核（core）类似于一个虚拟的 CPU 环境，这样当内存中的某个字节被加载到真实的 CPU 中时，该字节对应的 V bit 也被加载到虚拟的 CPU 环境中。一旦寄存器中的值，被用来产生内存地址，或者该值能够影响程序输出，则 memcheck 会检查对应的V bits，如果该值尚未初始化，则会报告使用未初始化内存错误。 Valgrind 使用 用法: valgrind [options] prog-and-args [options]: 常用选项，适用于所有Valgrind工具 -tool=<name> 最常用的选项。运行 valgrind中名为toolname的工具。默认memcheck。 h –help 显示帮助信息。 -version 显示valgrind内核的版本，每个工具都有各自的版本。 q –quiet 安静地运行，只打印错误信息。 v –verbose 更详细的信息, 增加错误数统计。 -trace-children=no|yes 跟踪子线程? [no] -track-fds=no|yes 跟踪打开的文件描述？[no] -time-stamp=no|yes 增加时间戳到LOG信息? [no] -log-fd=<number> 输出LOG到描述符文件 [2=stderr] -log-file=<file> 将输出的信息写入到filename.PID的文件里，PID是运行程序的进行ID -log-file-exactly=<file> 输出LOG信息到 file -log-file-qualifier=<VAR> 取得环境变量的值来做为输出信息的文件名。 [none] -log-socket=ipaddr:port 输出LOG到socket ，ipaddr:port LOG信息输出 -xml=yes 将信息以xml格式输出，只有memcheck可用 -num-callers=<number> show <number> callers in stack traces [12] -error-limit=no|yes 如果太多错误，则停止显示新错误? [yes] -error-exitcode=<number> 如果发现错误则返回错误代码 [0=disable] -db-attach=no|yes 当出现错误，valgrind会自动启动调试器gdb。[no] -db-command=<command> 启动调试器的命令行选项[gdb -nw %f %p] 适用于Memcheck工具的相关选项： -leak-check=no|summary|full 要求对leak给出详细信息? [summary] -leak-resolution=low|med|high how much bt merging in leak check [low] -show-reachable=no|yes show reachable blocks in leak check? [no] Valgrind 使用举例（一） 下面是一段有问题的C程序代码test.c ＃i nclude <stdlib.h>void f(void){   int* x = malloc(10 * sizeof(int));   x[10] = 0;  //问题1: 数组下标越界}                  //问题2: 内存没有释放 int main(void){   f();   return 0; } 1、 编译程序test.cgcc -Wall test.c -g -o test2、 使用Valgrind检查程序BUGvalgrind --tool=memcheck --leak-check=full ./test 使用未初始化内存问题 问题分析： 对于位于程序中不同段的变量，其初始值是不同的，全局变量和静态变量初始值为0，而局部变量和动态申请的变量，其初始值为随机值。如果程序使用了为随机值的变量，那么程序的行为就变得不可预期。 下面的程序就是一种常见的，使用了未初始化的变量的情况。数组a是局部变量，其初始值为随机值，而在初始化时并没有给其所有数组成员初始化，如此在接下来使用这个数组时就潜在有内存问题。   结果分析： 假设这个文件名为：badloop.c，生成的可执行程序为badloop。用memcheck对其进行测试，输出如下。   输出结果显示，在该程序第11行中，程序的跳转依赖于一个未初始化的变量。准确的发现了上述程序中存在的问题。 内存读写越界 问题分析： 这种情况是指：访问了你不应该/没有权限访问的内存地址空间，比如访问数组时越界；对动态内存访问时超出了申请的内存大小范围。下面的程序就是一个典型的数组越界问题。pt是一个局部数组变量，其大小为4，p初始指向pt数组的起始地址，但在对p循环叠加后，p超出了pt数组的范围，如果此时再对p进行写操作，那么后果将不可预期。   结果分析： 假设这个文件名为badacc.cpp，生成的可执行程序为badacc，用memcheck对其进行测试，输出如下。   输出结果显示，在该程序的第15行，进行了非法的写操作；在第16行，进行了非法读操作。准确地发现了上述问题。 内存覆盖 问题分析： C 语言的强大和可怕之处在于其可以直接操作内存，C 标准库中提供了大量这样的函数，比如 strcpy, strncpy, memcpy, strcat 等，这些函数有一个共同的特点就是需要设置源地址 (src)，和目标地址(dst)，src 和 dst 指向的地址不能发生重叠，否则结果将不可预期。 下面就是一个 src 和 dst 发生重叠的例子。在 15 与 17 行中，src 和 dst 所指向的地址相差 20，但指定的拷贝长度却是 21，这样就会把之前的拷贝值覆盖。第 24 行程序类似，src(x+20) 与 dst(x) 所指向的地址相差 20，但 dst 的长度却为 21，这样也会发生内存覆盖。   结果分析： 假设这个文件名为 badlap.cpp，生成的可执行程序为 badlap，用 memcheck 对其进行测试，输出如下。   输出结果显示上述程序中第15，17，24行，源地址和目标地址设置出现重叠。准确的发现了上述问题。 动态内存管理错误 问题分析： 常见的内存分配方式分三种：静态存储，栈上分配，堆上分配。全局变量属于静态存储，它们是在编译时就被分配了存储空间，函数内的局部变量属于栈上分配，而最灵活的内存使用方式当属堆上分配，也叫做内存动态分配了。常用的内存动态分配函数包括：malloc, alloc, realloc, new等，动态释放函数包括free, delete。 一旦成功申请了动态内存，我们就需要自己对其进行内存管理，而这又是最容易犯错误的。下面的一段程序，就包括了内存动态管理中常见的错误。   常见的内存动态管理错误包括：   申请和释放不一致 由于 C++ 兼容 C，而 C 与 C++ 的内存申请和释放函数是不同的，因此在 C++ 程序中，就有两套动态内存管理函数。一条不变的规则就是采用 C 方式申请的内存就用 C 方式释放；用 C++ 方式申请的内存，用 C++ 方式释放。也就是用 malloc/alloc/realloc 方式申请的内存，用 free 释放；用 new 方式申请的内存用 delete 释放。在上述程序中，用 malloc 方式申请了内存却用 delete 来释放，虽然这在很多情况下不会有问题，但这绝对是潜在的问题。   申请和释放不匹配 申请了多少内存，在使用完成后就要释放多少。如果没有释放，或者少释放了就是内存泄露；多释放了也会产生问题。上述程序中，指针p和pt指向的是同一块内存，却被先后释放两次。   释放后仍然读写 本质上说，系统会在堆上维护一个动态内存链表，如果被释放，就意味着该块内存可以继续被分配给其他部分，如果内存被释放后再访问，就可能覆盖其他部分的信息，这是一种严重的错误，上述程序第16行中就在释放后仍然写这块内存。 结果分析： 假设这个文件名为badmac.cpp，生成的可执行程序为badmac，用memcheck对其进行测试，输出如下。   输出结果显示，第14行分配和释放函数不一致；第16行发生非法写操作，也就是往释放后的内存地址写值；第17行释放内存函数无效。准确地发现了上述三个问题。 内存泄漏 问题描述： 内存泄露（Memory leak）指的是，在程序中动态申请的内存，在使用完后既没有释放，又无法被程序的其他部分访问。内存泄露是在开发大型程序中最令人头疼的问题，以至于有人说，内存泄露是无法避免的。其实不然，防止内存泄露要从良好的编程习惯做起，另外重要的一点就是要加强单元测试（Unit Test），而memcheck就是这样一款优秀的工具。 下面是一个比较典型的内存泄露案例。main函数调用了mk函数生成树结点，可是在调用完成之后，却没有相应的函数：nodefr释放内存，这样内存中的这个树结构就无法被其他部分访问，造成了内存泄露。 在一个单独的函数中，每个人的内存泄露意识都是比较强的。但很多情况下，我们都会对malloc/free 或new/delete做一些包装，以符合我们特定的需要，无法做到在一个函数中既使用又释放。这个例子也说明了内存泄露最容易发生的地方：即两个部分的接口部分，一个函数申请内存，一个函数释放内存。并且这些函数由不同的人开发、使用，这样造成内存泄露的可能性就比较大了。这需要养成良好的单元测试习惯，将内存泄露消灭在初始阶段。       结果分析： 假设上述文件名位tree.h, tree.cpp, badleak.cpp，生成的可执行程序为badleak，用memcheck对其进行测试，输出如下。   该示例程序是生成一棵树的过程，每个树节点的大小为12（考虑内存对齐），共8个节点。从上述输出可以看出，所有的内存泄露都被发现。Memcheck将内存泄露分为两种，一种是可能的内存泄露（Possibly lost），另外一种是确定的内存泄露（Definitely lost）。Possibly lost 是指仍然存在某个指针能够访问某块内存，但该指针指向的已经不是该内存首地址。Definitely lost 是指已经不能够访问这块内存。而Definitely lost又分为两种：直接的（direct）和间接的（indirect）。直接和间接的区别就是，直接是没有任何指针指向该内存，间接是指指向该内存的指针都位于内存泄露处。在上述的例子中，根节点是directly lost，而其他节点是indirectly lost。","title":"valgrind 的使用简介 ."},{"content":"分别转载自多处： https://www.ibm.com/developerworks/cn/linux/l-cn-nohup/ http://hhlenglish.blog.51cto.com/151687/95604 http://www.cnblogs.com/Bob-FD/archive/2011/10/20/Bob.html","title":"linux后台运行程序及恢复"},{"content":"MD5加密算法 - MD5在线加密 在一些初始化处理后，MD5以512位分组来处理输入文本，每一分组又划分为16个32位子分组。算法的输出由四个32位分组组成，将它们级联形成一个128位散列值。 首先填充消息使其长度恰好为一个比512位的倍数仅小64位的数。填充方法是附一个1在消息后面，后接所要求的多个0，然后在其后附上64位的消息长度（填充前）。这两步的作用是使消息长度恰好是512位的整数倍（算法的其余部分要求如此），同时确保不同的消息在填充后不相同。 四个32位变量初始化为： A=0x01234567 B=0x89abcdef C=0xfedcba98 D=0x76543210 它们称为链接变量（chaining variable） 接着进行算法的主循环，循环的次数是消息中512位消息分组的数目。 将上面四个变量复制到别外的变量中：A到a，B到b，C到c，D到d。 主循环有四轮（MD4只有三轮），每轮很相拟。第一轮进行16次操作。每次操作对a，b，c和d中的其中三个作一次非线性函数运算，然后将所得结果加上第四个变量，文本的一个子分组和一个常数。再将所得结果向右环移一个不定的数，并加上a，b，c或d中之一。最后用该结果取代a，b，c或d中之一。 以一下是每次操作中用到的四个非线性函数（每轮一个）。 F(X,Y,Z)=(X&Y)|((~X)&Z) G(X,Y,Z)=(X&Z)|(Y&(~Z)) H(X,Y,Z)=X^Y^Z I(X,Y,Z)=Y^(X|(~Z)) (&是与,|是或,~是非,^是异或) 这些函数是这样设计的：如果X、Y和Z的对应位是独立和均匀的，那么结果的每一位也应是独立和均匀的。 函数F是按逐位方式操作：如果X，那么Y，否则Z。函数H是逐位奇偶操作符。 设Mj表示消息的第j个子分组（从0到15），<< FF(a,b,c,d,Mj,s,ti)表示a=b+((a+(F(b,c,d)+Mj+ti)<< GG(a,b,c,d,Mj,s,ti)表示a=b+((a+(G(b,c,d)+Mj+ti)<< HH(a,b,c,d,Mj,s,ti)表示a=b+((a+(H(b,c,d)+Mj+ti)<< II(a,b,c,d,Mj,s,ti)表示a=b+((a+(I(b,c,d)+Mj+ti)<< 这四轮（64步）是： 第一轮 FF(a,b,c,d,M0,7,0xd76aa478) FF(d,a,b,c,M1,12,0xe8c7b756) FF(c,d,a,b,M2,17,0x242070db) FF(b,c,d,a,M3,22,0xc1bdceee) FF(a,b,c,d,M4,7,0xf57c0faf) FF(d,a,b,c,M5,12,0x4787c62a) FF(c,d,a,b,M6,17,0xa8304613) FF(b,c,d,a,M7,22,0xfd469501) FF(a,b,c,d,M8,7,0x698098d8) FF(d,a,b,c,M9,12,0x8b44f7af) FF(c,d,a,b,M10,17,0xffff5bb1) FF(b,c,d,a,M11,22,0x895cd7be) FF(a,b,c,d,M12,7,0x6b901122) FF(d,a,b,c,M13,12,0xfd987193) FF(c,d,a,b,M14,17,0xa679438e) FF(b,c,d,a,M15,22,0x49b40821) 第二轮 GG(a,b,c,d,M1,5,0xf61e2562) GG(d,a,b,c,M6,9,0xc040b340) GG(c,d,a,b,M11,14,0x265e5a51) GG(b,c,d,a,M0,20,0xe9b6c7aa) GG(a,b,c,d,M5,5,0xd62f105d) GG(d,a,b,c,M10,9,0x02441453) GG(c,d,a,b,M15,14,0xd8a1e681) GG(b,c,d,a,M4,20,0xe7d3fbc8) GG(a,b,c,d,M9,5,0x21e1cde6) GG(d,a,b,c,M14,9,0xc33707d6) GG(c,d,a,b,M3,14,0xf4d50d87) GG(b,c,d,a,M8,20,0x455a14ed) GG(a,b,c,d,M13,5,0xa9e3e905) GG(d,a,b,c,M2,9,0xfcefa3f8) GG(c,d,a,b,M7,14,0x676f02d9) GG(b,c,d,a,M12,20,0x8d2a4c8a) 第三轮 FF(a,b,c,d,M0,7,0xd76aa478) FF(d,a,b,c,M1,12,0xe8c7b756) FF(c,d,a,b,M2,17,0x242070db) FF(b,c,d,a,M3,22,0xc1bdceee) FF(a,b,c,d,M4,7,0xf57c0faf) FF(d,a,b,c,M5,12,0x4787c62a) FF(c,d,a,b,M6,17,0xa8304613) FF(b,c,d,a,M7,22,0xfd469501) FF(a,b,c,d,M8,7,0x698098d8) FF(d,a,b,c,M9,12,0x8b44f7af) FF(c,d,a,b,M10,17,0xffff5bb1) FF(b,c,d,a,M11,22,0x895cd7be) FF(a,b,c,d,M12,7,0x6b901122) FF(d,a,b,c,M13,12,0xfd987193) FF(c,d,a,b,M14,17,0xa679438e) FF(b,c,d,a,M15,22,0x49b40821)   可以第四轮 II(a,b,c,d,M0,6,0xf4292244) II(d,a,b,c,M7,10,0x432aff97) II(c,d,a,b,M14,15,0xab9423a7) II(b,c,d,a,M5,21,0xfc93a039) II(a,b,c,d,M12,6,0x655b59c3) II(d,a,b,c,M3,10,0x8f0ccc92) II(c,d,a,b,M10,15,0xffeff47d) II(b,c,d,a,M1,21,0x85845dd1) II(a,b,c,d,M8,6,0x6fa87e4f) II(d,a,b,c,M15,10,0xfe2ce6e0) II(c,d,a,b,M6,15,0xa3014314) II(b,c,d,a,M13,21,0x4e0811a1) II(a,b,c,d,M4,6,0xf7537e82) II(d,a,b,c,M11,10,0xbd3af235) II(c,d,a,b,M2,15,0x2ad7d2bb) II(b,c,d,a,M9,21,0xeb86d391)如下选择： 在第i步中，ti是4294967296*abs(sin(i))的整数部分,i的单位是弧度。 (2的32次方) 所有这些完成之后，将A，B，C，D分别加上a，b，c，d。然后用下一分组数据继续运行算法，最后的输出是A，B，C和D的级联。  ","title":"MD5算法"},{"content":"httpd -k restart 关键是找到httpd这个文件 如果 [root@test bin]# httpd restart-bash: httpd: command not found 明显是bash在path所指的目录下找不到httpd，试试找到它，然后用绝对路径。 比如我们这里是 /usr/local/apache2/bin/httpd -k restart","title":"Linux 如何重启 apache"},{"content":"Linux Crontab 定时任务 收集整理 一、  Cron 介绍        cron是Linux下的计划任务工具，它是linux的服务器端程序。cron启动后，它会读取它的所有配置文件（全局性配置文件/etc/crontab，以及每个用户的计划任务配置文件）每分钟读一次？？？，然后cron会根据命令和执行时间来按时来调用度工作任务。  Notice that tasks will be started based on the cron's system daemon's notion of time and timezones.        本机使用的CentOS下的命令名叫/usr/sbin/crond  二、Cron 服务        crond服务的启动关闭         启动：service crond start         停止：service crond stop         重启：service crond restart         查看状态：service crond status         重新载入配置：service crond reload         你也可以将这个服务在系统启动的时候自动启动，在/etc/rc.d/rc.local这个脚本的末尾加上：         /sbin/service crond start  三、Cron 主配置文件        cron 的主配置文件是 /etc/crontab，它包括下面几行：  SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root HOME=/  # run-parts 01 * * * * root run-parts /etc/cron.hourly 02 4 * * * root run-parts /etc/cron.daily 22 4 * * 0 root run-parts /etc/cron.weekly 42 4 1 * * root run-parts /etc/cron.monthly        前四行是用来配置 cron 任务运行环境的变量。        SHELL 变量的值告诉系统要使用哪个 shell 环境（在这个例子里是 bash shell）；        PATH 变量定义用来执行命令的路径。        cron 任务的输出被邮寄给 MAILTO 变量定义的用户名。如果 MAILTO 变量被定义为空白字符串（MAILTO=\"\"），电子邮件就不会被寄出。        HOME 变量可以用来设置在执行命令或脚本时使用的主目录。        如你在 /etc/crontab 文件中所见，它使用 run-parts 脚本来执行 /etc/cron.hourly、/etc/cron.daily、/etc/cron.weekly 和 /etc/cron.monthly 目录中的脚本，这些脚本被相应地每小时、每日、每周、或每月执行。这些目录中的文件应该是 shell 脚本。         如果某 cron 任务需要根据调度来执行，而不是每小时、每日、每周、或每月地执行，它可以被添加到/etc/cron.d目录中。该目录中的所有文件使用和 /etc/crontab 中一样的语法。 四、Crontab 命令使用        cron服务提供crontab命令来设定cron服务的，以下是这个命令的一些参数与说明：         crontab -u //设定某个用户的cron服务，一般root用户在执行这个命令的时候需要此参数         crontab -l//列出某个用户cron服务的详细内容         crontab -r //删除某个用户的cron服务         crontab -e//编辑某个用户的cron服务         比如说root查看自己的cron设置：crontab -u root -l         再例如，root想删除fred的cron设置：crontab -u fred -r         每次编辑完某个用户的cron设置后，cron自动在/var/spool/cron下生成一个与此用户同名的文件，此用户的cron信息都记录在这个文件中，这个文件是不可以直接编辑的，只可以用crontab -e来编辑。cron启动后每过一份钟读一次这个文件，检查是否要执行里面的命令。因此此文件修改后不需要重新启动cron服务。  五、Crontab 任务配置格式        我们可以用crontab -e添加要执行的命令。 命令执行的结果，无论是标准输出还是错误输出，都将以邮件形式发给用户。        全局性配置格式        #f1 f2 f3 f4 f5 user command         用户自身配置格式        #f1 f2 f3 f4 f5 command  说明： f1 表示分钟0～59 f2 表示小时0～23 f3 表示日期1～31 f4 表示月份1～12 f5 表示星期0～6（0代表星期天） command 表示要执行的程式。 还可以用一些特殊符号： * 代表所有的取值范围内的数字，如f1的值是 * 表示每分钟， /代表每的意思,如f2的值是 */5 表示每5个小时， - 代表从某个数字到某个数字,如f3的值是 1-10 表示1号到10号， ,分开几个离散的数字，如f4的值是 3，5，6 表示每年的三、五、六月份。 一些示例： 30 21 * * * /usr/local/etc/rc.d/httpd restart 上面的例子表示每晚的21:30重启apache。 45 4 1,10,22 * * /usr/local/etc/rc.d/httpd restart 上面的例子表示每月1、10、22日的4 : 45重启apache。 10 1 * * 6,0 /usr/local/etc/rc.d/httpd restart 上面的例子表示每周六、周日的1 : 10重启apache。 0,30 18-23 * * * /usr/local/etc/rc.d/httpd restart 上面的例子表示在每天18 : 00至23 : 00之间每隔30分钟重启apache。                   　 　 　　 　 　　　　　　 　　　　　　　　 　　　　　　　　 　　　　　　　 　　　　　　　　　　　　　　　　　　　　  命令 解释 43 21 * * * 21:43 执行 15 05 * * * 05:15 执行 0 17 * * * 17:00 执行 0 17 * * 1 每周一的17:00 执行 0,10 17 * * 0,2,3 每周日,周二,周三的17:00和17:10 执行 0-10 17 1 * * 毎月1日从17:00到7:10毎隔1分钟 执行 0 0 1,15 * 1 毎月1日和15日和周一的0:00 执行 42 4 1 * * 毎月1日的 4:42分 执行 0 21 * * 1-6 周一到周六 21:00 执行 0,10,20,30,40,50 * * * * 每隔10分 执行 */10 * * * * 每隔10分 执行 * 1 * * * 从1:0到1:59 每隔1分钟 执行 0 1 * * * 1:00 执行 0 */1 * * * 毎时0分 每隔1小时 执行 0 * * * * 毎时0分 每隔1小时 执行 2 8-20/3 * * * 8:02,11:02,14:02,17:02,20:02 执行 30 5 1,15 * *  1日 和 15日的 5:30 执行 六、& 后天执行命令         当在前台运行某个作业时，终端被该作业占据；而在后台运行作业时，它不会占据终端。可以使用&命令把作业放到后台执行。          如：                 30 2 * * */data/app/scripts/hotbackup/hot_database_backup.sh &          在后台运行作业时要当心：需要用户交互的命令不要放在后台执行，因为这样你的机器就会在那里傻等。不过，作业在后台运行一样会将结果输出到屏幕上，干扰你的工作。如果放在后台运行的作业会产生大量的输出，最好使用下面的方法把它的输出重定向到某个文件中：         如：                 command >out.file 2>&1 &         在这个例子中，2>&1表示所有的标准输出和错误输出都将被重定向到一个叫做out.file 的文件中。 2>&1 含义 先看一个例子： 0 2 * * * /u01/test.sh >/dev/null2>&1 & 这句话的意思就是在后台执行这条命令，并将错误输出2重定向到标准输出1，然后将标准输出1全部放到/dev/null 文件，也就是清空。 在这里有有几个数字的意思：       0表示键盘输入       1表示标准输出       2表示错误输出. 我们也可以这样写： 0 2 * * * /u01/test.sh  >/u01/out.file &  --这里没写，默认是1 0 2 * * * /u01/test.sh  1>/u01/out.file & 0 2 * * * /u01/test.sh  2>/u01/out.file & 0 2 * * * /u01/test.sh  2>/u01/out.file  2>&1 &  将tesh.sh 命令输出重定向到out.file, 即输出内容不打印到屏幕上，而是输出到out.file文件中。  2>&1 是将错误输出重定向到标准输出。 然后将标准输入重定向到文件out.file。  &1 表示的是文件描述1，表示标准输出，如果这里少了&就成了数字1，就表示重定向到文件1。  & ：后台执行   测试： ls 2>1 ： 不会报没有2文件的错误，但会输出一个空的文件1； ls xxx 2>1： 没有xxx这个文件的错误输出到了1中； ls xxx 2>&1： 不会生成1这个文件了，不过错误跑到标准输出了； ls xxx >out.txt 2>&1 == ls xxx1>out.txt 2>&1；  因为重定向符号>默认是1，这句就把错误输出和标准输出都传到out.txt 文件中。 2>&1写在后面的原因         格式：command > file 2>&1  == command  1> file 2>&1  首先是command > file将标准输出重定向到file中， 2>&1 是标准错误拷贝了标准输出，也就是同样被重定向到file中，最终结果就是标准输出和错误都被重定向到file中。  如果改成： command 2>&1 >file，2>&1标准错误拷贝了标准输出的行为，但此时标准输出还是在终端。>file 后输出才被重定向到file，但标准错误仍然保持在终端。","title":"Linux Crontab 定时任务 整理"},{"content":"大多数的Linux发行版都装备了很多Linux系统监控工具，充分合理的利用这些工具，可以找出系统运行的性能瓶颈，包括硬盘瓶颈、CPU及内存瓶颈和网络瓶颈。本文介绍的20个工具只是最基本的，因此也十分实用。 需要监控Linux服务器系统性能吗？尝试下面这些系统内置或附件的工具吧。大多数Linux发行版本都装备了大量的监控工具。这些工具提供了能用作取得相关信息和系统活动的量度指标。你能使用这些工具发现造成性能问题可能原因。此次讨论到的工具只是分析和调试服务器下面问题时最基本工具中的一部分。 51CTO编辑推荐：Linux监控工具大全 1.找出瓶颈 2.硬盘（存储）瓶颈 3.CPU及内存瓶颈 4.网络瓶颈 #1: top - 进程活动 top提供一个当前运行系统实时动态的视图，也就是正在运行进程。在默认情况下，显示系统中CPU使用率最高的任务，并每5秒钟刷新一次。 图01.Linux top命令 常用热键 热键 用途 t 显示摘要信息开关. m 显示内存信息开关. A 分类显示系统不同资源的使用大户。有助于快速识别系统中资源消耗多的任务。 f 添加删除所要显示栏位. o 调整所要显示栏位的顺序. r 调整一个正在运行的进程Nice值. k 结束一个正在运行的进程. z 彩色/黑白显示开关 #2:vmstat -系统活动、硬件及系统信息 使用vmstat命令可以得到关于进程、内存、内存分页、堵塞IO、traps及CPU活动的信息。 # vmstat 3 输出样例： procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------ r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st 0  0      0 2540988 522188 5130400    0    0     2    32    4    2  4  1 96  0  0 1  0      0 2540988 522188 5130400    0    0     0   720 1199  665  1  0 99  0  0 0  0      0 2540956 522188 5130400    0    0     0     0 1151 1569  4  1 95  0  0 0  0      0 2540956 522188 5130500    0    0     0     6 1117  439  1  0 99  0  0 0  0      0 2540940 522188 5130512    0    0     0   536 1189  932  1  0 98  0  0 0  0      0 2538444 522188 5130588    0    0     0     0 1187 1417  4  1 96  0  0 0  0      0 2490060 522188 5130640    0    0     0    18 1253 1123  5  1 94  0  0 显示内存使用详细信息 # vmstat -m 显示内存活动/不活动的信息 # vmstat -a #3: w - 显示谁已登录，他们正在做什么？ w命令显示系统当前用户及其运行进程的信息。 # w username # w vivek 输出样例： 17:58:47 up 5 days, 20:28,  2 users,  load average: 0.36, 0.26, 0.24 USER     TTY      FROM              LOGIN@   IDLE   JCPU   PCPU WHAT root     pts/0    10.1.3.145       14:55    5.00s  0.04s  0.02s vim /etc/resolv.conf root     pts/1    10.1.3.145       17:43    0.00s  0.03s  0.00s w #4：uptime - 告诉系统已经运行了多久？ uptime命令过去只显示系统运行多久。现在，可以显示系统运行多久、当前有多少的用户登录、在过去的1，5，15分钟里平均负载时多少。 # uptime 输入样例： 18:02:41 up 41 days, 23:42,  1 user,  load average: 0.00, 0.00, 0.00 1可以被认为是最优的负载值。负载是会随着系统不同改变得。单CPU系统1-3和SMP系统6-10都是可能接受的。 #5：ps - 显示进程 ps命令显示当前运行进程的快照。使用-A或-e显示所有进程。 # ps -A 输出样例： PID TTY          TIME CMD 1 ?        00:00:02 init 2 ?        00:00:02 migration/0 3 ?        00:00:01 ksoftirqd/0 4 ?        00:00:00 watchdog/0 5 ?        00:00:00 migration/1 6 ?        00:00:15 ksoftirqd/1 .... ..... 4881 ?        00:53:28 java 4885 tty1     00:00:00 mingetty 4886 tty2     00:00:00 mingetty 4887 tty3     00:00:00 mingetty 4888 tty4     00:00:00 mingetty 4891 tty5     00:00:00 mingetty 4892 tty6     00:00:00 mingetty 4893 ttyS1    00:00:00 agetty 12853 ?        00:00:00 cifsoplockd 12854 ?        00:00:00 cifsdnotifyd 14231 ?        00:10:34 lighttpd 14232 ?        00:00:00 php-cgi 54981 pts/0    00:00:00 vim 55465 ?        00:00:00 php-cgi 55546 ?        00:00:00 bind9-snmp-stat 55704 pts/1    00:00:00 ps ps与top非常相似，但ps提供更多的信息。 输出长格式 # ps -Al 输出附加全格式（显示进程在执行时传入的参数） # ps -AlF 显示进程结构 # ps -AlFH 在进程后显示线程 # ps -AlLm 打印服务器上所有进程 # ps ax # ps axu 打印进程树 # ps -ejH # ps axjf # pstree 打印安全信息 # ps -eo euser,ruser,suser,fuser,f,comm,label # ps axZ # ps -eM 查看使用Vivek用户名运行的进程 # ps -U vivek -u vivek u 设置自定义输出格式 # ps -eo pid,tid,class,rtprio,ni,pri,psr,pcpu,stat,wchan:14,comm # ps axo stat,euid,ruid,tty,tpgid,sess,pgrp,ppid,pid,pcpu,comm # ps -eopid,tt,user,fname,tmout,f,wchan 只显示Lighttpd的进程ID # ps -C lighttpd -o pid= 或者 # pgrep lighttpd 或者 # pgrep -u vivek php-cgi 显示PID为55977的进程名称 # ps -p 55977 -o comm= 找出消耗内存最多的前10名进程 # ps -auxf | sort -nr -k 4 | head -10 找出使用CPU最多的前10名进程 # ps -auxf | sort -nr -k 3 | head -10 #6:free - 内存使用情况 free命令显示系统中空闲的、已用的物理内存及swap内存,及被内核使用的buffer。 # free 输出样例： total       used       free     shared    buffers     cached Mem:      12302896    9739664    2563232          0     523124    5154740 -/+ buffers/cache:    4061800    8241096 Swap:      1052248          0    1052248 #7:iostat - CPU平均负载，硬盘活动 iostat命令可报告中央处理器（CPU）的统计信息，各种设备、分区及网络文件系统输入/输出的统计信息。 # iostat 输出样例： Linux 2.6.18-128.1.14.el5 (www03.nixcraft.in)  06/26/2009 avg-cpu:  %user   %nice %system %iowait  %steal   %idle 3.50    0.09    0.51    0.03    0.00   95.86 Device:            tps   Blk_read/s   Blk_wrtn/s   Blk_read   Blk_wrtn sda              22.04        31.88       512.03   16193351  260102868 sda1              0.00         0.00         0.00       2166        180 sda2             22.04        31.87       512.03   16189010  260102688 sda3              0.00         0.00         0.00       1615          0 #8:sar - 搜集和报告系统活动 sar命令用来搜集、报告和储存系统活动信息。查看网路计数器，输入： # sar -n DEV | more 显示最近24小时网络计数器 # sar -n DEV -f /var/log/sa/sa24 | more 你亦可以用sar显示实时情况 # sar 4 5 输出样例： Linux 2.6.18-128.1.14.el5 (www03.nixcraft.in)   06/26/2009 06:45:12 PM       CPU     %user     %nice   %system   %iowait    %steal     %idle 06:45:16 PM       all      2.00      0.00      0.22      0.00      0.00     97.78 06:45:20 PM       all      2.07      0.00      0.38      0.03      0.00     97.52 06:45:24 PM       all      0.94      0.00      0.28      0.00      0.00     98.78 06:45:28 PM       all      1.56      0.00      0.22      0.00      0.00     98.22 06:45:32 PM       all      3.53      0.00      0.25      0.03      0.00     96.19 Average:          all      2.02      0.00      0.27      0.01      0.00     97.70 #9:mpstat - 多处理器使用率 mpstat命令可以显示所有可用处理器的使用情况，处理器编号从0开始。mpstat -P ALL显示每个处理器的平均使用率。 # mpstat -P ALL 输出样例： Linux 2.6.18-128.1.14.el5 (www03.nixcraft.in)   06/26/2009 06:48:11 PM CPU   %user   %nice    %sys %iowait    %irq   %soft %steal   %idle    intr/s 06:48:11 PM all    3.50    0.09    0.34    0.03    0.01    0.17    0.00   95.86   1218.04 06:48:11 PM    0    3.44    0.08    0.31    0.02    0.00    0.12    0.00   96.04   1000.31 06:48:11 PM    1    3.10    0.08    0.32    0.09    0.02    0.11    0.00   96.28     34.93 06:48:11 PM    2    4.16    0.11    0.36    0.02    0.00    0.11    0.00   95.25      0.00 06:48:11 PM    3    3.77    0.11    0.38    0.03    0.01    0.24    0.00   95.46     44.80 06:48:11 PM    4    2.96    0.07    0.29    0.04    0.02    0.10    0.00   96.52     25.91 06:48:11 PM    5    3.26    0.08    0.28    0.03    0.01    0.10    0.00   96.23     14.98 06:48:11 PM    6    4.00    0.10    0.34    0.01    0.00    0.13    0.00   95.42      3.75 06:48:11 PM    7    3.30    0.11    0.39    0.03    0.01    0.46    0.00   95.69     76.89 #10: pmap - 进程的内存使用 pmap命令可以显示进程的内存映射，使用这个命令可以找出造成内存瓶颈的原因。 # pmap -d PID 显示PID为47394进程的内存信息。 # pmap -d 47394 输出样例： 47394:   /usr/bin/php-cgi Address           Kbytes Mode Offset           Device    Mapping 0000000000400000    2584 r-x-- 0000000000000000 008:00002 php-cgi 0000000000886000     140 rw--- 0000000000286000 008:00002 php-cgi 00000000008a9000      52 rw--- 00000000008a9000 000:00000   [ anon ] 0000000000aa8000      76 rw--- 00000000002a8000 008:00002 php-cgi 000000000f678000    1980 rw--- 000000000f678000 000:00000   [ anon ] 000000314a600000     112 r-x-- 0000000000000000 008:00002 ld-2.5.so 000000314a81b000       4 r---- 000000000001b000 008:00002 ld-2.5.so 000000314a81c000       4 rw--- 000000000001c000 008:00002 ld-2.5.so 000000314aa00000    1328 r-x-- 0000000000000000 008:00002 libc-2.5.so 000000314ab4c000    2048 ----- 000000000014c000 008:00002 libc-2.5.so ..... ...... .. 00002af8d48fd000       4 rw--- 0000000000006000 008:00002 xsl.so 00002af8d490c000      40 r-x-- 0000000000000000 008:00002 libnss_files-2.5.so 00002af8d4916000    2044 ----- 000000000000a000 008:00002 libnss_files-2.5.so 00002af8d4b15000       4 r---- 0000000000009000 008:00002 libnss_files-2.5.so 00002af8d4b16000       4 rw--- 000000000000a000 008:00002 libnss_files-2.5.so 00002af8d4b17000 768000 rw-s- 0000000000000000 000:00009 zero (deleted) 00007fffc95fe000      84 rw--- 00007ffffffea000 000:00000   [ stack ] ffffffffff600000    8192 ----- 0000000000000000 000:00000   [ anon ] mapped: 933712K    writeable/private: 4304K    shared: 768000K 最后一行非常重要： * mapped: 933712K 内存映射所占空间大小 * writeable/private: 4304K 私有地址空间大小 * shared: 768000K 共享地址空间大小 #11和#12: netstat和ss - 网络相关信息 netstat可以显示网络链接、路由表信息、接口统计信息、伪装链接和多播成员(multicast memberships),ss命令用来显示网络套接字信息，它允许显示类似netstat一样的信息。关于ss和netstat使用，可参考下列资源。 #13: iptraf - 网络实时信息 iptraf是一个可交互式的IP网络监控工具。它可以生成多种网络统计信息包括：TCP信息、UDP数量、ICMP和OSPF信息、以太网负载信息、节点状态、IP校验错误等。有下面几种信息格式： 不同网络TCP链接传输量 不同网络接口IP传输量 不同协议网络传输量 不同TCP/UDP端口和不同包大小网络传输量 不同第二层地址网络传输量 图02：一般接口信息：不同网络接口IP传输量 图03：不同网络TCP链接传输量 #14：tcpdump：详细的网络流量分析 tcpdump是一个简单网络流量转储工具，然而要使用好需要对TCP/IP协议非常熟悉。例如要显示关于DNS的网络流量，输入： # tcpdump -i eth1 'udp port 53' 显示所有进出80端口IPv4 HTTP包，也就是只打印包含数据的包。例如：SYN、FIN包和ACK-only包输入： # tcpdump 'tcp port 80 and (((ip[2:2] - ((ip[0]&0xf)<<2)) - ((tcp[12]&0xf0)>>2)) != 0)' 显示所有到的FTP会话，输入： # tcpdump -i eth1 'dst 202.54.1.5 and (port 21 or 20' 显示所有到192.168.1.5的HTTP会话 # tcpdump -ni eth0 'dst 192.168.1.5 and tcp and port http' 用wireshark浏览转储文件中的详细信息，输入： # tcpdump -n -i eth1 -s 0 -w output.txt src or dst port 80 #15:strace - 系统调用 追踪系统调用和型号，这对于调试Web服务器和其他服务器非常有用。了解怎样追踪进程和他功能。 #16:/proc文件系统 - 各种内核信息 /proc目录下文件提供了很多不同硬件设备和内核的详细信息。更多详情参见Linux kernel /proc。一般/proc例如： # cat /proc/cpuinfo # cat /proc/meminfo # cat /proc/zoneinfo # cat /proc/mounts #17:Nagios - 服务器及网络监控 Nagios 是一款非常流行的系统及网络监控软件。你可以轻松监控所有的主机、网络设备及服务。它能在发生故障和重新恢复后发送警讯。FAN是\"Fully Automated Nagios\"的缩写。FAN的目标就是由Nagios社群提供Nagios的安装。为了使安装Nagios服务器更加容易，FAN提供一个标准ISO格式的光盘镜像。此发行版中还会包含一组增强用户使用体验的工具。 #18:Cacti - 基于Web的监控工具 Cacti是一套完成的网络图形化解决方案，基于RRDTool的资料存储和图形化功能。Cacti提供一个快速的轮询器、进阶的图形化模板、多种数据采集方法和用户管理功能。这些功能都拥有非常友好易用的界面，确保可以部署在一个包含数百台设备的复杂网络中。它提供关于网络、CPU、内存、已登录用户、Apache、DNS等信息。 #19:KDE System Guard KSysguard是在KDE桌面下一个网络化的系统监控工具。这个工具可以通过SSH会话运行。它提供很多功能，例如可以监控本机和远程主机的客户端/服务器架构，前端图形界面使用所谓传感器得到信息并展现出来。传感器返回的可以是一个简单的数值或是一组表格的信息。针对不同的信息类型，提供一个或多个显示。这些显示被组织多个工作表中，可以工作表可以独体储存和加载。所以，KSysguard不只是一个简单的任务管理器，还是一个可以控制多台服务器的强大工具。 图05：KDE System Guard #20:Gnome System Monitor System Monitor可以显示系统基本信息、监控系统进程、系统资源及文件系统使用率。你也可以使用System Monitor监控和修改系统行为。尽管没有KDE System Guard功能强大，但其提供的基本信息对于入门用户还是非常有用的。 * 显示关于计算机硬件和软件的各种基本信息。 * Linux内核版本 * GNOME版本 * 硬件 * 安装的内存 * 处理器及其速度 * 系统状态 * 当前可用的硬盘空间 * 进程 * 内存及交换空间 * 网络使用率 * 文件系统 * 所有挂载的文件系统及其基本信息 图06：The Gnome System Monitor application 本文来源：http://hi.baidu.com/imlidapeng/blog/item/76cc8b15bf38265af2de32cc.html","title":"管理员必备的20个Linux系统监控工具"},{"content":"最近我们在做一个LCM两屏或三屏兼容的问题,所以首先要在uboot里面读出各屏的id,然后再将读得到的id传给recovery和kernel,实现机器的正常显示. 一.首先实现uboot读lcm的id.           1.bootable/bootloader/lk/target/msm7627a_sku3_Q6_D/rules.mk是uboot里面宏开关,打开所显示的屏宏 DEFINES += DISPLAY_MIPI_CMD_PANEL_ILI9487=1 DEFINES += DISPLAY_MIPI_CMD_PANEL_HX8357=1           2.去初始化mipi的地方先读id. bootable/bootloader/lk/platform/msm_shared/mipi_dsi.c               在函数int mipi_dsi_panel_initialize(struct mipi_dsi_panel_config *pinfo) {        ...... #if defined(DISPLAY_MIPI_CMD_PANEL_ILI9487)||defined(DISPLAY_MIPI_CMD_PANEL_HX8357)     mipi_dsi_cmd_bta_sw_trigger();     dat = mipi_viroyal_manufacture_id();     if(dat == 0x90)     {         lcm_flag = 8357;        //hx8357-c     }     else     {         lcm_flag = 9487;        //ili9487     }          pinfo_tmp =get_panel_info();     memcpy(pinfo, pinfo_tmp, sizeof(struct mipi_dsi_panel_config)); #endif        ...... }            3.读到id后再初始化屏                 struct mipi_dsi_panel_config *get_panel_info(void) {               ......... #elif (DISPLAY_MIPI_CMD_PANEL_ILI9487)||(DISPLAY_MIPI_CMD_PANEL_HX8357)     if (lcm_flag == 8357)         return &hx8357_cmd_panel_info;     else         return &ili9487_cmd_panel_info; #endif                .......... } 这样在uboot里面就成功可以显示图片了,下面是如何将lcm_flag的值传给kernel了. 二.传lcm_flag给kernel      1.uboot里面要做的bootable/bootloader/lk/app/aboot/aboot.c          其实原生态的android系统就有一个将uboot传给kernel的例子,那就是跟踪代码static const char *boot_splash = \" splash=1\";           我做的也是效仿系统做的,先定义一个字符串 static const char *lcm_flg_ili9486 = \" lcmflag=9486\"; static const char *lcm_flg_nt35310 = \" lcmflag=5310\"; 然后在下面的函数copy到kernel void boot_linux(void *kernel, unsigned *tags,         const char *cmdline, unsigned machtype,         void *ramdisk, unsigned ramdisk_size) {    .....         if(!boot_into_recovery)     {         cmdline_len += strlen(boot_splash);         #if DISPLAY_TYPE_MIPI         if (lcm_flag == 8357)         cmdline_len += strlen(lcm_flg_hx8357c);         else         cmdline_len += strlen(lcm_flg_ili9487);         #endif    .....        if (!boot_into_recovery)         {         #if DISPLAY_TYPE_MIPI             if (lcm_flag == 8357)                src = lcm_flg_hx8357c;             else                src = lcm_flg_ili9487;         #endif         if (have_cmdline) --dst;         while ((*dst++ = *src++));    ..... } 这样uboot里面的动作就做完了,即是将uboot里面的数据copy到一个数组里面,这个数组能从uboot传给kernel. 三.kernel接受uboot传来的字符串 msm7627a/kernel/arch/arm/mach-msm/board-msm7x27a.c 在这个函数里面接受(依据自己用的平台阿,要灵活),同样是模仿boot_splash,在代码里添加接受字符串,并转化为数字 /* LK lcm_flag, 0 - off, 1 - on */ int lcm_flag = 0; static int __init lk_lcmflag_setup(char *str) {     lcm_flag = simple_strtol(str, NULL, 0);     printk(\"lcmflag = %d\\n\", lcm_flag);     return 1; } __setup(\"lcmflag=\", lk_lcmflag_setup); 这样就算是取到lcm_flag的值了,然后在具体的驱动中extern int lcm_flag即可,简单吧.其实技术就那样,很怕人认真,呵呵.开个玩笑. 四.把uboot里面的id还要给recovery      上面做完其实lcm可以在uboot和kernel正常显示了,但有一个位置显示会比较诡异,那就是进入\"恢复出厂设置\"的时候,会有一个诡异的画面,哥研究了2天,最终得出结论原来是recovery没有正常的接受到正确的屏的id,于是乎就将正确的id传给内核       还是从bootable/bootloader/lk/app/aboot/aboot.c入手,现在就是要记住关键字static const char *boot_splash_recovery = \" splash=0\";        我就仿效boot_splash_recovery将lcm_flag添加再下面的函数中: void boot_linux(void *kernel, unsigned *tags,         const char *cmdline, unsigned machtype,         void *ramdisk, unsigned ramdisk_size) {   ....     #if DISPLAY_SPLASH_IN_KERNEL     if(!boot_into_recovery)     {                  ........     }     else     {         cmdline_len += strlen(boot_splash_recovery);         #if DISPLAY_TYPE_MIPI          if (lcm_flag == 8357)              cmdline_len += strlen(lcm_flg_hx8357c);          else              cmdline_len += strlen(lcm_flg_ili9487);          #endif     } #endif   ....    if(!boot_into_recovery)         {                       .............         }         else         {             src = boot_splash_recovery;             if (have_cmdline) --dst;             have_cmdline = 1;             while ((*dst++ = *src++));             #if DISPLAY_TYPE_MIPI             if (lcm_flag == 8357)                 src = lcm_flg_hx8357c;             else                 src = lcm_flg_ili9487;             #endif             if (have_cmdline) --dst;             while ((*dst++ = *src++));         }        ...... }     这样recovery就能完全接受uboot里面传来的值,其他的就不用做了.到这里整个系统都可以完全显示完整正确的图片.","title":"如何将uboot里面的参数传给recovery或kernel"},{"content":"转载请注明出处:Ronald的部落格 很多同学在说Linux下配置网络桥接不如Windows方便，如果要共享网络链接很麻烦。其实如果各位能到墙外查查看，很多博客都介绍了如何在Linux下做网络桥接的姿势和动作要领。这里为大家介绍一下。如果你遇到如下问题，这篇文章可以帮助你搞定。 * 对如何在Linux下进行桥接完全没有概念 * 在执行桥接命令时出现cant add wlan0 to bridge br0: Operation not supported。这是由于您的无线网卡没有处于AP模式。处于Managed模式的无线网卡无法进行桥接（不要挣扎了，Managed模式下的网卡没有足够多的信息做桥接，这是802.11规定的）。只要按如下所述使用hostapd即可解决问题 * 在执行iwconfig wlan0 mode Master时出现错误 Error for wireless request \"Set Mode\" (8B06) :    SET failed on device wlan0 ; Invalid argument. 这说明您的网卡不支持硬件Master模式，您同样可以使用hostapd实现软Master模式解决问题。 * 正确设置之后主机无法访问互联网。您可能需要刷新系统原有的路由表，并在br0上，而不是eth0上启动dhcpcd(dhclient) 内核和内核支持 使用bridge功能需要内核支持，大多数预编译内核（如Fedora, Ubuntu等发行版默认安装的内核）都内建了bridge支持。在自编译内核中，你需要启用Networking support --> Networking options --> 802.1d Ethernet Bridging。如果编译为模块，可以通过modprobe bridge将其加载。内核编译的知识和姿势请自行Google。 设置hostapd 我知道有大神可以打开原生的AP(Master)模式。但是不管您是否能通过iwconfig打开AP模式，我都建议使用hostapd设置。安装hostapd的方法请自行Google。大多数发行版可以使用软件包管理器安装。 要设置一个简单的AP需要配置设置文件，以及启动hostapd程序。大多数操作都需要在root用户下操作。 在你认为合适的地方建立内容如下所述，文件名不那么重要的文件_： interface=wlan0driver=nl80211ssid=MyAPchannel=1 这个文件使端口wlan0工作在1信道下，建立一个ssid为MyAP的热点。默认不启用加密。若需设置加密，或需要更多信息，请参考这里 使用命令sudo hostapd /path/to/config/file启动hostapd，注意需要提供绝对路径。 建立设置网络桥接 网络桥接的配置需要使用brctl命令，在Gentoo下通过`sudo emerge -av bridge-utils安装。下面这段命令用于建立一个名叫br0的网桥。并把 wlan0 和 eth0 加入网桥 ifconfig eth0 upifconfig wlan0 upbrctl addbr br0brctl addif br0 eth0brctl addif br0 wlan0ifconfig br0 up 如果没有返回错误，桥接就已经成功了。 新的路由项 需要注意的是，在完成桥接设置后，你需要重新设置路由表，使得default指向br0而不是eth0。要做到这一点，最方便的做法（如果你在一个使用dhcp的网络环境下）是使用dhcpcd -k eth0 && dhcpcd br0来重新设置路由。如果没有DHCP，那您需要手动删除eth0上绑定的IP地址，并在br0上进行设置，最后更改相应的路由表项。我假设如果您会手动配置网络，一定知道我在说什么_*。如果您想更方便的设置，wicd中可以在preference中将wired interface改为br0，然后使用wicd进行配置。如果您这么做，在网桥消失之后（比如重启计算机之后）您需要将刚才的设置改回eth0。","title":"[How To]在Linux下设置无线网络桥接"},{"content":"   《UNIX Linux程序设计教程》               本书在介绍U N I X A P I 各种函数的功能和用途的同时，清晰地阐述了它们所隐含的操作系统基本原 理。书中给出了大量程序设计示例程序，有助于读者理解。   更多<<","title":"《UNIX Linux程序设计教程》"},{"content":"有时候在c 中用一下方式定义struct struct Hello{\tint a;};有时候是不能够使用的，会提示说Hello 不能够resolved ： Type 'Hello' could not be resolved 要用以下方式定义 typedef struct {\tint a;}Hello;","title":"c struct 定义的问题。Type 'Hello' could not be resolved"},{"content":"转自：http://www.gwxdn.com/html/system/linux/2010/0120/6128.html Linux主机名是在安装Linux操作系统的过程中设定的，并作为网络中的某一台主机的唯一标志，但是在安装好Linux系统后，如果想修改主机名，该怎么办呢?本文介绍基于Ubuntu Desktop 9.04。 1、快速查看主机名 在Ubuntu系统中，快速查看主机名有两种方法：一是打开一个GNOME终端窗口，在命令提示符中可以看到主机名，主机名通常位于“@”符号后;二是在终端窗口中输入命令：hostname或uname –n，均可以查看到当前主机名。 2、临时修改主机名 修改主机名最为快速的方法就是使用命令“hostname 新主机名”来改变当前主机名，其中“新主机名”可以用任何合法字符串来表示。不过采用这种方式，新主机名并不保存在系统中，重启系统后主机名将恢复为原先的主机名称。 3、永久修改主机名 在Ubuntu系统中永久修改主机名也比较简单。主机名存放在/etc/hostname文件中，修改主机名时，编辑hostname文件，在文件中输入新的主机名并保存该文件即可。重启系统后，参照上面介绍的快速查看主机名的办法来确认主机名有没有修改成功。 值得指出的是，在其他Linux发行版中，并非都存在/etc/hostname文件。如Fedora发行版将主机名存放在/etc/sysconfig/network文件中。所以，修改主机名时应注意区分是哪种Linux发行版。","title":"linux 修改hostname"},{"content":"chrome、vlc等程序使root用户无法使用的原理是：它获取程序的所有者，如果它是root用户，就让它不能运行。 程序中用到的函数是geteuid()。geteuid就是get essensial user id，获取有效用户id。每一个用户都有一个id，root用户id为0，普通用户id为1000以上。 知道原理后就可以得出解决办法了，就是将geteuid退换成getppid。getppid是获取此进程的父进程id，由于它是独立进程，它的父进程就是init进程（启动后的第一个进程），进程id为1，永远不可能为0。 首先查询程序的位置，以chromium-browser为例， which chromium-browser 路径是/usr/bin/chromium-browser，然后 vim /usr/bin/chromium-browser 输入/geteuid，输入i进入输入模式，将geteuid改成getppid，然后ESC，输入wq，保存退出，这样程序root用户就可以运行了，vlc等其他程序也是一样的办法。","title":"linux上chrome、vlc等程序root不能运行的解决办法"},{"content":"原文地址：http://dadloveu.blog.51cto.com/715500/566129 最近在学Linux，经常遇见: date --date='2 days ago' +%Y%m%d 使用man date的解释也不够详细，后来找到这篇文章，    ","title":"Linux date --date"},{"content":"首先，安装Ruby有很多方法，不过还是这里推荐用 RVM (Ruby Version Manage) 来安装 可能您已经使用过apt安装RVM，或者用ubuntu软件中心，不过为了避免以后出现莫名奇妙的错误，最好还是自己重新安装一下。因此首先清除可能已经的安装好的RVM管理器。 sudo apt-get --purge remove ruby-rvmsudo rm -rf /usr/share/ruby-rvm /etc/rvmrc /etc/profile.d/rvm.sh 之后重新启动终端并检查环境变量（关于环境变量，）： 如果有显示，试一试重新开启终端（Terminal），如果仍有可以尝试重启计算机。 安装 RVM: curl -L get.rvm.io | bash -s -- --auto-dotfiles 其中curl是利用URL语法在命令行方式下工作的文件传输工具。 安装完以后最后能看到这样一段话：  * To start using RVM you need to run `source /home/***/.rvm/scripts/rvm`     in all your open shell windows, in rare cases you need to reopen all shell windows. 故输入 source /home/***/.rvm/scripts/rvm其中***指的是你自己的名字 source命令用法：source FileName 作用:在当前bash环境下读取并执行FileName中的命令。 注：该命令通常用命令“.”来替代。如：source /etc/profile 与 . /etc/profile是等效的。 注意：source命令与shell scripts的区别是，source在当前bash环境下执行命令，而scripts是启动一个子shell来执行命令。这样如果把设置环境变量（或alias等等）的命令写进scripts中，就只会影响子shell,无法改变当前的BASH,所以通过文件（命令列）设置环境变量时，要用source 命令。 关于RVM的详细实用安装与使用方法参见：Installing RVM。安装好RVM后就可以使用它来安装Ruby了。 输入： rvm list knownrvm install 1.9.2 接下来：使用刚刚安装的Ruby rvm use 1.9.2 检查是否工作正常： ruby -v 显示 ruby 1.9.2p320 (2012-04-20 revision 35421) [i686-linux] which ruby 显示 /home/***/.rvm/rubies/ruby-1.9.2-p320/bin/ruby","title":"［Ruby］Ubuntu(12.04)下Ruby的安装与配置 {<笨方法学Ruby (Learn Ruby the Hard Way)>习题一}"},{"content":"        本人小白，经过无数次的尝试和失败之后，终于成功的在win7的基础上安装了win7+Ubuntu 12.10双系统。我不希望他人也想我这样走了这么多冤枉路，所以写下这篇博文，谨以献给那些仍在挣扎的小白们和我浪费的宝贵时间。        最初接触Ubuntu是用wubi安装的，但是用了没多久就发现wubi安装的其实并不好，如果你想要获得更好的体验，还是分区来安装吧，因为wubi安装并算不上真正意义上的双系统，那只能算是win7下安装的一个软件罢了，可以直接在win7中卸载wubi，这样你在ubuntu下的所有文件就全都丢失了。。。。。        后来我决定分区安装Ubuntu,但是历经坎坷啊，在网上找了一写教程，但是有的说的含糊不清，有的照着做了但是却失败了，唉。。。。。      首先声明我的电脑情况：C盘是win7系统，D盘和E盘是文件，F 盘是WIN8，G盘是文件，还有一个多余的空余磁盘H盘       下面总结下我的安装方法吧。。。 一、第一步，划分出一个磁盘，我有一个空白的磁盘H盘可以直接用，右键“计算机”----“管理”，在磁盘管理那删除我的H盘（有重要文件的要事先备份）            如果没有多余的磁盘，可以从比较大的磁盘上分割出一部分，也在磁盘管理中，右键所要分割的磁盘-----右键“压缩卷”就可以了。 二、下载两样东西：1、Ubuntu系统，可以到它的官网下载最新版http://www.ubuntu.org.cn/                                       2、easyBCD,这个也搜的到.这里有一个2.2版本的http://www.onlinedown.net/soft/58174.htm 三、将下载的iso文件放在任一磁盘的根目录。如我的放在了D 盘。再用winrar打开，找到casper文件夹，将里面的initrd.lz和vmlinuz加压到D 盘根目录，还有.disk文         件夹也复制到D盘根目录。 四、打开easyBCD-----添加新条目----NeoGrub----安装---配置。将弹出的文件内容改为      title Install Ubuntu      root (hd0,n)      kernel (hd0,n)/vmlinuz boot=casper iso-scan/filename=/ubuntu-12.10-desktop-i386.iso ro quiet splash locale=zh_CN.UTF-8      initrd (hd0,n)/initrd.lz 红色部分内容改为你所下载的系统文件名，如我的改成了ubuntu-12.10-desktop-amd64.iso 蓝色部分是重点，如我的系统文件放在了D 盘,n就改为4，若是E盘就改为5，若为F盘就改为6.。。。。依次类推 如果放在了C盘，那就要看情况而定了，如果你的磁盘没有隐藏分区，那么C盘就是你的第一个主分区，n就应该是0；如果你的磁盘还有一个隐藏的主分区，比如电脑自带的一键恢复功能，其主要的恢复数据就在那个隐藏分区里面，这时，n就应改写为1。 保存文件并退出 五、这时可以重启了，你会发现启动时多了一个引导项，就是NeoGrub 引导加载器，用上下建选择这个并启动安装程序。 六、接下来就是安装步骤了。这个得千万小心呐。   但是安装之前，会进入试用的Ubuntu界面，首先按下快捷键：CTRL+ALT+T，打开终端，输入：sudo umount -l /isodevice  （注意-l和isodevice之间有      一个空格）     再点击安装Ubuntu 12.10  七、语言选择“简体中文”-----“继续”       选安装类型，我们用其他选项-----“继续”       网络可以不连，因为连上了会下载很长时间，可以安装好系统之后再下载       之后就是分区了，我只这样分的：选择刚才删除的那个分区，点击下面的“+”，依次选为“/”，“30GB”。选择“逻辑分区”、“空间起始。。。”，“EXT4     日志文件”     再添加一个“交换分区”，我给了6G，同样是“逻辑分区”、“空间起始。。。”，。最后添加一个“/home”,可以吧剩下的空间全部分配给它。    最下面的挂载选择“/”区，也就是那个30GB的分区    一路确定之后，就开是按装了，期间会让你选择时区、输入用户名、密码之类的，接下来就是等待了，但是很快，十分钟不到吧。   八、重启之后，进入win7,打开easyBCD,删除“ NeoGrub 引导加载器 “这个启动项，再添加一条启动项，选择linux、选择\"grub 2”,名称自己随意。地址盘选   择我的那个30GB 的分区。 一切就OK 了，最后可以删除D 盘的那些initrd.lz和vmlinuz还有.disk文件夹了。。。。。。。","title":"win7下硬盘安装Ubuntu 12.10"},{"content":"在这里介绍Makefile的基本规则和用法。 Makefile的基本规则为： 目标：依赖1 依赖2 ... 命令 如： hello : hello.c a.c gcc -o hello hello.c a.c 命令能够执行的条件是： 1）目标文件不存在 2）依赖被修改，即被编译的文件被修改，在这里指hello.c 和a.c 具体实现如下： 在命令行输入：vi hello.c然后编辑   1 #include <stdio.h>  2 extern void out( void );  3 int main()  4 {  5     printf( \"hello cs .\\n\" );  6     out();  7     return 0;  8 } 在命令行输入 vi a.c   1 #include <stdio.h>  2 void out()  3 {  4     printf( \"printf a.c\\n\" );  5 }在命令行输入 vi Makefile   1 hello : hello.c a.c  2     gcc -o hello hello.c a.c然后执行： [root@localhost makefile]# makegcc -o hello hello.c a.c[root@localhost makefile]# ./hellohello cs .printf a.c[root@localhost makefile]#  通常需要编译的文件比较多，往往只需要在文件被修改时编译即可，此时Makefile应为   1 hello : hello.o a.o  2     gcc -o hello hello.o a.o  3   4 hello.o : hello.c  5     gcc -o hello.o -c hello.c  6   7 a.o : a.c  8     gcc -o a.o -c a.c-c表示只编译不链接 然后执行： [root@localhost makefile]# makegcc -o hello.o -c hello.cgcc -o a.o -c a.cgcc -o hello hello.o a.o若需要删除编译产生的文件，编辑Makefile   1 hello : hello.o a.o  2     gcc -o hello hello.o a.o  3   4 hello.o : hello.c  5     gcc -o hello.o -c hello.c  6   7 a.o : a.c  8     gcc -o a.o -c a.c  9 clean : 10     rm -rf *.o hello clean:后面的依赖不存在，表示执行make clean时rm -rf *.c hello命令始终执行 返回命令行，执行： [root@localhost makefile]# lsa.c  a.o  hello  hello.c  hello.o  Makefile[root@localhost makefile]# make cleanrm -rf *.o hello[root@localhost makefile]# lsa.c  hello.c  Makefile[root@localhost makefile]# Makefile文件的进一步改进   1 hello : hello.o a.o  2     gcc -o $@ $^  3   4 %.o : %.c  5     gcc -o $@ -c $<  6   7 clean :  8     rm -rf *.o hello $@表示目标文件，$^表示编译两个文件，$<表示编译的是一个文件。 然后执行： [root@localhost makefile]# makegcc -o hello.o -c hello.cgcc -o a.o -c a.cgcc -o hello hello.o a.o[root@localhost makefile]# lsa.c  a.o  hello  hello.c  hello.o  Makefile[root@localhost makefile]# make cleanrm -rf *.o hello[root@localhost makefile]# 在此只是记录下目前学到的一些知识，具体的随后会做详细补充。","title":"Makefile基本规则及应用"},{"content":"一 fedora9无法进入图形界面     我安装的fedora9一直都好用着呢，但因为安装了Qt-x11-4.5.3之后，重启后就无法进入图形界面了，在\"显示细节\"界面之后,.无法进入登录界面，有个光标箭头在那一闪一闪的,然后tom login登录一闪而过，就这样来来回回无法启动。通过网友帮助，终于解决了登录不了的问题，现给出解决方法，希望能给遇到相同问题的人予以帮助。 1. 进入单用户模式 首先启动fedora9，在grub启动后，按下键盘任意键会进入到linux启动项.按下e键，然后按上下键选择类似下面的一行 kernel /boot/vmlinuz-2.6.25-14.EL ro root=UUID=c3ea65a8-7fad-473f-a5/ quiet   把光标移动这行后，再按一下e键，进入编辑这行；在行尾条一个空格 ，然后输入 Linux single 修改后如下：   kernel /boot/vmlinuz-2.6.25-14.EL ro root=UUID=c3ea65a8-7fad-473f-a5/ quiet  Linux single 结束编辑，按回车返回； 接着我们要启动系统，按一下b键启动。即可进入“单用户模式”  1、使用passwd命令进行密码修改 2、改变inittab中的启动模式：  找到 /etc/inittab文件，找到如下一行； id:5:initdefault:  把这里的5改为3 ， 也就是改成如下的： 代码  id:3:initdefault:  保存退出，然后输入命令startx，就可以进入图形界面了！","title":"Linux无法进入图形界面"},{"content":"之前一直在MS SQL SERVER上做开发，一直想去倒腾oracle，苦于没有学习环境，终于决心自己安装个oracle测试环境。 因为是第一次接触，前后花了快一周左右时间，才完全搞定，各种曲折，各种摸索，太费时费神。 所以将安装过程总结成文档，希望能帮助像我一样的oracle初学者。 当中参考了非法小恋的博文，感谢。 安装环境          虚拟机版本:Vmware 7       操作系统版本:Red hat Enterprise Linux 5 32位:                                  Rhel-server-5.4-i386-dvd.iso       数据库版本:Oracle 11g R2 For Linux 32位:                                 Linux_11gR2_database_1of2.zip                                 Linux_11gR2_database_2of2.zip (一)系统安装    1、Linux安装Oracle系统要求 系统要求 说明 内存 必须高于1G的物理内存 交换空间 一般为内存的2倍，例如：1G的内存可以设置swap分区为3G大小 硬盘 5G以上 系统安装这里不做具体介绍了，需要注意的是， 安装完系统后一定要记得安装VMWare Tools,否则在安装oracle时到图形界面会很卡很慢: 执行命令如下：         rpm –ivh VMwareTools-4.0.0-398348.i386.rpm        解压VMwareTools-4.0.0-398348.tar.gz 再执行命令       ./wmware-install.pl 按照提示默认安装，一直回车，在选择虚拟机分辨率时根据自己电脑选在适当的分辨率。 安装成功后reboot –n重新启动, 2.修改操作系统核心参数 在Root用户下执行以下步骤： 1）修改用户的SHELL的限制，修改/etc/security/limits.conf文件 输入命令：vi/etc/security/limits.conf，按i键进入编辑模式，将下列内容加入该文件。 oracle   soft    nproc    2047 oracle   hard    nproc    16384 oracle   soft    nofile     65536 oracle   hard    nofile    65536 编辑完成后按Esc键，输入“:wq”存盘退出 2）修改/etc/pam.d/login文件，输入命令：vi  /etc/pam.d/login，按i键进入编辑模式，将下列内容加入该文件。 session   required    /lib/security/pam_limits.so session   required    pam_limits.so 编辑完成后按Esc键，输入“:wq”存盘退出 3）修改linux内核，修改/etc/sysctl.conf文件，输入命令:vi  /etc/sysctl.conf，按i键进入编辑模式，将下列内容加入该文 fs.file-max = 6815744 fs.aio-max-nr = 1048576 kernel.shmall = 2097152 kernel.shmmax = 2147483648 kernel.shmmni = 4096 kernel.sem = 250 32000 100 128 net.ipv4.ip_local_port_range = 9000 65500 net.core.rmem_default = 4194304 net.core.rmem_max = 4194304 net.core.wmem_default = 262144 net.core.wmem_max = 1048576 编辑完成后按Esc键，输入“:wq”存盘退出 4）要使 /etc/sysctl.conf更改立即生效，执行以下命令。输入：sysctl  -p显示如下： linux:~ # sysctl -p net.ipv4.icmp_echo_ignore_broadcasts = 1 net.ipv4.conf.all.rp_filter = 1 fs.file-max = 6815744 fs.aio-max-nr = 1048576 kernel.shmall = 2097152 kernel.shmmax = 2147483648 kernel.shmmni = 4096 kernel.sem = 250 32000 100 128 net.ipv4.ip_local_port_range = 9000 65500 net.core.rmem_default = 4194304 net.core.rmem_max = 4194304 net.core.wmem_default = 262144 net.core.wmem_max = 1048576   5）编辑 /etc/profile，输入命令：vi  /etc/profile，按i键进入编辑模式，将下列内容加入该文件。 if [ $USER = \"oracle\" ]; then if [ $SHELL = \"/bin/ksh\" ]; then   ulimit -p 16384   ulimit -n 65536 else   ulimit -u 16384 -n 65536 fi fi 编辑完成后按Esc键，输入“:wq”存盘退出 6）创建相关用户和组，作为软件安装和支持组的拥有者。 创建用户，输入命令： groupadd  oinstall groupadd  dba 创建Oracle用户和密码,输入命令： useradd -g oinstall -g dba -m oracle passwd  oracle 然后会让你输入密码，密码任意输入2次，但必须保持一致，回车确认   7）创建数据库软件目录和数据文件存放目录，目录的位置，根据自己的情况来定，注意磁盘空间即可，这里我把其放到oracle用户下,例如： 输入命令： mkdir /home/oracle/app mkdir /home/oracle/app/oracle mkdir /home/oracle/app/oradata mkdir /home/oracle/app/oracle/product 8)更改目录属主为Oracle用户所有，输入命令： chown -R oracle:oinstall /home/oracle/app 9)配置oracle用户的环境变量，首先，切换到新创建的oracle用户下, 输入：su – oracle ，然后直接在输入： vi .bash_profile 按i编辑 .bash_profile,进入编辑模式，增加以下内容： umask 022 export ORACLE_BASE=/home/oracle/app export ORACLE_HOME=$ORACLE_BASE/oracle/product/11.2.0/dbhome_1 export ORACLE_SID=orcl export PATH=$PATH:$HOME/bin:$ORACLE_HOME/bin export LD_LIBRARY_PATH=$ORACLE_HOME/lib:/usr/lib 编辑完成后按Esc键，输入“:wq”存盘退出   数据库安装过程 1）当上述系统要求操作全部完成后，注销系统，在图形界面以Oracle用户登陆。 首先将下载的Oracle安装包复制到linux中，推荐用Xmanager或其他ftp工具拷贝。    打开一个终端，运行unzip命令解压oracle安装文件，如： 输入命令： unzip  Linux_11gR2_database_1of2.zip unzip  Linux_11gR2_database_2of2.zip  解压完成后 cd进入其解压后的目录database 输入命令： cd  database 使用ls命令可以查看解压后database所包含的文件，如下图： 2）执行安装，输入命令：./runInstaller 装到这一步，可以看到，可以查看到有很多的rpm包没有，我们可以从安装linux的光盘或ISO中查找所缺的包，使用ftp上传到linux中，然后使用rpm  –ivh  xxx.rpm  --nodeps –force 来进行安装（其中加上--nodeps -- force代表强制安装，是在直接使用rpm –ivh  xxx.rpm安装不成功的情况下用的）安装过程略。   等到把包全部都安装好的情况下，再次在oracle图形界面中，执行安装过程2，下来在环境检查过程中，就通过了。 安装完成后，系统会提示你需要用root权限执行2个shell脚本。按照其提示的路径，找到其所在的位置，如：我的就在/home/oracle/app/oracle/product/11.2.0/dbhome_1/root.sh 和 /home/oracle/app/oraInventory/orainstRoot.sh 新开启一个终端，输入命令： su – root cd  /home/oracle/app/oracle/product/11.2.0/dbhome_1 sh  root.sh cd /home/oracle/app/oraInventory sh  orainstRoot.sh 数据库建库 1）还是在oracle用户的图形界面oracle用户中，新开启一个终端，直接输入命令dbca会弹出如下界面。我们这里采用定制数据库。 经过漫长的等待，当看到此界面，说明oracle建库完成 配置监听及本地网络服务 1）在oracle用户的图形界面oracle用户中，新开启一个终端，输入命令netca会弹出如下界面。 2）创建监听服务（充当oracle服务器，让别的oracle客户端连接本oracle服务器） 3）配置本地网络服务名（充当oracle客户端，连接别的oracle服务器） 输入连接的oracle服务器的数据库的实例名 输入oracle服务器的ip地址 这样oracle服务器安装配置基本就完成了。 如果上面的测试不通过的话，请参考下面的方法。 首先使用oracle用户登录Linux，然后在shell命令行中执行下面的命令： 第一步：打开Oracle监听 $ lsnrctl start 第二步：进入sqlplus $ sqlplus /nolog SQL> 第三步：使用sysdab角色登录sqlplus SQL> conn /as sysdba 第四步：启动数据库 SQL> startup 经过上面的四个步骤，oracle数据库就可以启动了。 如果在打开监听时遇到下面的报错 cannot restore segment prot after reloc: Permission denied 修改配置文件vi /etc/selinux/config和vi /etc/sysconfig/selinux 将SELINUX设置为disabled： SELINUX=disabled 重新启动","title":"虚拟机环境在linux下安装oracle11gr2"},{"content":"压缩、解压缩(tar/zip/bzip2/gz/gzip/zip) 压缩包也有两种形式，一种是tar.gz包(.tgz包也是这种)，一种是tar.bz2包。 tar.gz包的解压方法：tar zxvf [PackageName].tar.gz tar.bz2包的解压方法：tar jxvf [PackageName].tar.bz2 将压缩包文件解压缩到指定目录： tar -zxvf [压缩文件] -C [解压缩文件目录] 压缩打包命令： tar.gz包的压缩方法：tar zcvf [PackageName].tar.gz [要打包压缩的文件] tar.bz2包的压缩方法：tar jcvf [PackageName].tar.bz2 [要打包压缩的文件] tar linux下面的归档工具。是对文件或者目录进行归档，归成一个文件，但并不压缩。 语法格式 tar [主选项+辅选项] 文件或者目录列表主选项 -c 创建新的档案文件 -r 把要归档的文件追加到档案文件的末尾 -t 列出档案文件中已经归档的文件列表 -u 更新文件，用新文件替代档案中原始文件。如果备份文件中不存在该文件，则把它追加到备份文件的末尾 -x 从档案文件中还原文件辅选项 -f 归档到普通文件 -k 保存已存在的文件。例如在还原的过程中，遇到相同的文件，不会进行覆盖 -m 在还原文件时，把所有文件的修改时间设定为现在时间 -v 报告tar的详细处理过程 -w 每一步都要进行确认 -z 用gzip来压缩/解压缩文件 -j 通过bzip2压缩/解压缩文件 -Z 通过compress程序过滤档案。 例如：将/etc/目录下所有东西归档到当前目录下，取名为wpc.tar，命令如下： tar cvf wpc.tar /etc/ 例如：将当前目录下wpc.tar解压到当前目录下，命令如下： tar xvf wpc.tar ---------------------------------------------------------------------------------------------- 文件压缩 可以将一般的文件进行压缩，或者将归档的文件进行压缩gzip & gunzip 语法格式 gzip [选项] 压缩(解压缩)的文件名gzip默认将源文件压缩为.gz文件，并删除原文件常用选项 -c 将输出写道标准输出上，并保留原文件 -d 对压缩文件进行解压缩 -l 对每个压缩文件，显示字段：压缩文件的大小、未压缩文件的大小、压缩比、未压缩文件的名字 -r 递归式查找指定目录，并压缩或者解压缩其中的所有文件。 -t 检查压缩文件是否完整 -v 对每个压缩和解压缩的文件，显示文件名和压缩比 -num 用指定的数字num设置压缩比，-1或-fast表示最低压缩比，-9或-best表示最高压缩比。系统默认值是6 例如：将当前目录下，wpc.bmp压缩，命令如下： gzip -v wpc.bmp 例如：将当前目录下wpc.bmp.gz解压缩，命令如下： gunzip -d wpc.bmp.gz 命令结果：wpc.bmp.gz被解压缩，并被删除，出现wpc.bmp ---------------------------------------------------------------------------------------------zip & unzip zip与windows的winzip压缩程序产生相同压缩文件.zip。 语法格式 zip 压缩文件名 被压缩文件列表例如：将当前目录下，wpc子目录下面的所有内容压缩成wpc.zip,命令如下： zip wpc.zip wpc/unzip 语法格式 unzip [选项] 压缩文件名.zip常用选项 -x 文件列表 解压缩文件，但不包括“文件列表”中指定的文件 -v 查看压缩文件目录，但不解压 -t 测试文件有无损坏，但不解压 -d 目录 把压缩文件解压到指定目录下 -z 只显示压缩文件的注解 -n 不覆盖已经存在的文件 -o 覆盖已存在的文件且不要求用户确认 -j 不重建文档的目录结构，把所有文件解压到同一目录下例如：将当前目录下wpc.zip解压缩，命令如下： unzip wpc.zip ---------------------------------------------------------------------------------------------- bzip2 语法格式 bzip2 [选项][-压缩等级] 压缩文件名常用选项 -c 或 --stdout 将压缩与解压缩的结果送到标准输出 -d 或 --decompress 执行解压缩 -f 或 --force bzip2在压缩或解压缩时，若输出文件与现有文件同名，预设不会覆盖现有文件，若要覆盖，需要使用此参数 -h 或 --help 显示帮助 -k 或 --keep bzip2在压缩或解压缩后，会删除原始的文件，若要保留原始文件，需要使用此参数 -s 或 --small 降低程序执行时内存的使用量 -t 或 --test 测试.bz2压缩文件的完整性 -v 或 --verbose 压缩或解压缩文件时，显示详细的信息 -z 或 --compress 强制执行压缩 -V 或 --version 显示版本信息 --repetitive-best 若文件中有重复出现的内容，可利用此参数提高压缩效果 --repetitive-fast 若文件中有重复出现的内容，可利用此参数加快执行速度 例如：使用bzip2压缩当前目录下的归档文件wpc.tar，命令如下： bzip2 wpc.tar 例如：解压缩当前目录下wpc.tar.bz2，命令如下： bzip2 -d wpc.tar.bz2注：bunzip2和bzip2 -d效果相同","title":"压缩、解压缩(tar/zip/bzip2/gz/gzip/zip)"},{"content":"----------------------------------------------------------------------------------------make 详解-1 ---------------------------------------------------------------------------------------------------------------------2012年12月26日18:58:16------------------------------------------------------------------------------------------------①make的基本概念make3个重要的概念：\t1.目标 2.依赖关系 3.命令一个简单的Makefile文件:-------------------------------------------------------------------\tall:\t\t\t\t\t\t  \t\techo \"hello world\"\ttest: \t\techo \"just for test\"\t\t\t  -------------------------------------------------------------------all就是目标执行make all的结果如下：-------------------------------------------------------------------echo \"hello world\"hello world                                                -------------------------------------------------------------------执行make test结果如下：-------------------------------------------------------------------echo \"just for test\"just for test\t\t\t-------------------------------------------------------------------  从上可以看出*** all参数告诉make希望构建的目标是哪个*** 如果直接执行make则默认的构建目标是第一个-------------------------------------------------------------------|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||-------------------------------------------------------------------讲上面的内容作一些修改-------------------------------------------------------------------\tall:test\t\t\t\t\t\t\t  \t\t@echo \"hello world\"\ttest: \t\t@echo \"just for test\"\t\t\t  -------------------------------------------------------------------分析：all依赖于test则执行make会出现的结果是：-------------------------------------------------------------------just for testhello world-------------------------------------------------------------------make test 结果是：-------------------------------------------------------------------just for test-------------------------------------------------------------------|||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||||②创建基本的编译环境构造一个简单的程序用于写Makefilesimple/foo.c-------------------------------------------------------------------#include<stdio.h>void foo(){\tprintf(\"This is foo()\");}-------------------------------------------------------------------simple/main.c-------------------------------------------------------------------int main(){\tfoo();\treturn 0;}-------------------------------------------------------------------编写简单的Makefilesimple/Makefile-------------------------------------------------------------------all:main.o foo.o  \tgcc -o simple main.o foo.omain.o:main.c\tgcc -o main.o -c main.cfoo.o:foo.c\tgcc -o foo.o -c foo.cclean:\trm simple main.o foo.o--------------------------------------------------------------------*** make是通过文件的时间戳来判断定哪些文件需要从新编译的make在分析一个规则以创建目标时，如果发现先决条件中的文件时间戳大于目标文件的时间戳，即先决条件中的文件比目标更新。②.1让Makefile更专业一.假目标的用处执行make clean时，make将认为clean当做一个目标来处理，然后clean目标没有任何先决条件，所以当我们构建clean目标时，它会认为clean文件是最新的，从而拒绝进行真正的文件清理操作。*** 目标文件与Makefile中的目标名重名在现实项目中是很难避免的，假目标(phony*** target)概念的提出正是为了解决这种问题。*** 假目标采用.PHONY关键字来定义，注意必须是大写字母。-------------------------------------------------------------------.PHONY:cleanall:main.o foo.o  \tgcc -o simple main.o foo.omain.o:main.c\tgcc -o main.o -c main.cfoo.o:foo.c\tgcc -o foo.o -c foo.cclean:\trm simple main.o foo.o--------------------------------------------------------------------采用.PHONY关键字声明一个目标后，make并不会将其当做一个文件来处理，可以想象由于假目标并不与文件关联，所以每次构建假目标时它所在规则中的命令一定会被执行二.运用\"变量\"提高可维护性--------------------------------------------------------------------.PHONY:cleanCC = gccRM = rmEXE = simpleOBJS = main.o foo.o$(EXE):$(OBJS)\t$(CC) -o $(EXE) -c $(OBJS)main.o:main.c\t$(CC) -o main.o -c main.cfoo.o:foo.c\t$(CC) -o foo.o -c foo.cclean:\t$(RM) -fr $(EXE) $(OBJS) ---------------------------------------------------------------------*** 定义变量时其值可以为空，即无右值*** 引用变量需要采用的方式为\"$()\",\"${}\".\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\重点:$@:用于表示一个规则中的目标。当一个规则中有多个目标时，$@所指的是其中任何造   成规则命令被运行的目标。$^:表示的是规则中的所有先决条件。$<:表示的是规则中的第一个先决条件。\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\下面这个经典的例子：---------------------------------------------------------------------.PHONY:allall: first second third\t@echo \"\\$$@ = $@\"\t@echo \"$$^  = $^\"\t@echo \"$$<  = $<\"first second third:---------------------------------------------------------------------make的输出结果是：---------------------------------------------------------------------$@ = all$^  = first second third$<  = first---------------------------------------------------------------------*** 注意$@对于Bash shell有特殊的意思要在\"$$@\"之前加一个脱字符\"\\\"用$@，$^，$<编写Makefile文件---------------------------------------------------------------------.PHONY:cleanCC = gccEXE = simlpeOBJS = main.o foo.oRM = rm -rf$(EXE):$(OBJS)\t$(CC) -o $@ $^main.o:main.c\t$(CC) -o $@ -c $^foo.o:foo.c\t$(CC) -o $@ -c $^clean:\t$(RM) *.o $(EXE)----------------------------------------------------------------------\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\变量的类别与赋值三种类型：1.\":=\" 2.\"?=\" 3.\"+=\"\":=\":简单扩展变量，对于这种变量，make只对其进行一次展开(意思就是make只认第一     次赋值)。\"?=\":条件赋值，当变量没有定义时就可以定义它，并且将右边的值赋值给它；如果变量     已经定义了，则无法改变其原值，。条件赋值可以为变量赋默认值。\"+=\":追加赋值。----------------------------------------------------------------------------将创建的simple可执行文件放到exes目录讲生成的.o文件放到objs目录----------------------------------------------------------------------------.PHONY:cleanCC = gccMKDIR = mkdirDIR_OBJS = objsDIR_EXES = exesDIRS = $(DIR_OBJS) $(DIR_EXES)EXE = simpleSRCS = $(wildcard *.c)    #通配符得到后缀为.c的文件OBJS = $(SRCS:.c=.o)      OBJS := $(addprefix $(DIR_OBJS)/,$(OBJS))RM = rmFLAGES = -rfall:$(DIRS) $(EXE)$(DIRS):        $(MKDIR) $@$(EXE):$(OBJS)        $(CC) -o $@ $^$(DIR_OBJS)/%.o:%.c        $(CC) -o $@ -c $^clean:        $(RM) $(FLAGES) $(DIRS) $(EXE)-----------------------------------------------------------------------------","title":"makefile详解——1"},{"content":"当内核空间和用户空间存在大量数据交互时, 共享内存映射就成了这种情况下的不二选择; 它能够最大限度的降低内核空间和用户空间之间的数据拷贝, 从而大大提高系统的性能.   以下是创建从内核空间到用户空间的共享内存映射的模板代码(在内核2.6.18和2.6.32上测试通过): 1.内核空间分配内存: #include <linux/types.h> #include <linux/mm.h> #include <linux/vmalloc.h> int mmap_alloc(int require_buf_size) {   struct page *page;     mmap_size = PAGE_ALIGN(require_buf_size); #if USE_KMALLOC //for kmalloc   mmap_buf = kzalloc(mmap_size, GFP_KERNEL);   if (!mmap_buf) {     return -1;   }   for (page = virt_to_page(mmap_buf ); page < virt_to_page(mmap_buf + mmap_size); page++) {     SetPageReserved(page);   } #else //for vmalloc   mmap_buf  = vmalloc(mmap_size);   if (!mmap_buf ) {     return -1;   }   for (i = 0; i < mmap_size; i += PAGE_SIZE) {     SetPageReserved(vmalloc_to_page((void *)(((unsigned long)mmap_buf) + i)));   } #endif   return 0; } 2.用户空间映射内存 int test_mmap() {   mmap_fd = open(\"/dev/mmap_dev\", O_RDWR);   mmap_ptr = mmap(NULL, mmap_size, PROT_READ|PROT_WRITE, MAP_SHARED|MAP_LOCKED, mmap_fd, 0);   if (mmap_ptr == MAP_FAILED) {     return -1;   }   return 0; }   3.内核空间映射内存: 实现file_operations的mmap函数 static int mmap_mmap(struct file *filp, struct vm_area_struct *vma) {   int ret;   unsigned long pfn;   unsigned long start = vma->vm_start;   unsigned long size = PAGE_ALIGN(vma->vm_end - vma->vm_start);   if (size > mmap_size || !mmap_buf) {     return -EINVAL;   } #if USE_KMALLOC   return remap_pfn_range(vma, start, (virt_to_phys(mmap_buf) >> PAGE_SHIFT), size, PAGE_SHARED); #else   /* loop over all pages, map it page individually */   while (size > 0) {           pfn = vmalloc_to_pfn(mmap_buf);           if ((ret = remap_pfn_range(vma, start, pfn, PAGE_SIZE, PAGE_SHARED)) < 0) {             return ret;           }           start += PAGE_SIZE;           mmap_buf += PAGE_SIZE;           size -= PAGE_SIZE;   } #endif   return 0; } static const struct file_operations mmap_fops = {   .owner = THIS_MODULE,   .ioctl = mmap_ioctl,   .open = mmap_open,   .mmap = mmap_mmap,   .release = mmap_release, }; 4.用户空间撤销内存映射 void test_munmap() {      munmap(mmap_ptr, mmap_size);   close(mmap_fd); } 5.内核空间释放内存; 必须在用户空间执行munmap系统调用后才能释放 void mmap_free() { #if USE_KMALLOC   struct page *page;   for (page = virt_to_page(mmap_buf); page < virt_to_page(mmap_buf + mmap_size); page++) {     ClearPageReserved(page);   }   kfree(mmap_buf); #else   int i;   for (i = 0; i < mmap_size; i += PAGE_SIZE) {     ClearPageReserved(vmalloc_to_page((void *)(((unsigned long)mmap_buf) + i)));   }   vfree(mmap_buf); #endif   mmap_buf = NULL; }","title":"Linux内核空间到用户空间的共享内存映射"},{"content":"下面的内容是对其他人基于vi命令的一个总结，所以说应该是比较全面的。很高兴与大家分享。 进入vi的命令 vi filename :打开或新建文件，并将光标置于第一行首 vi +n filename ：打开文件，并将光标置于第n行首 vi + filename ：打开文件，并将光标置于最后一行首 vi +/pattern filename：打开文件，并将光标置于第一个与pattern匹配的串处 vi -r filename ：在上次正用vi编辑时发生系统崩溃，恢复filename vi filename....filename ：打开多个文件，依次进行编辑 移动光标类命令 h ：光标左移一个字符 l ：光标右移一个字符 space：光标右移一个字符 Backspace：光标左移一个字符 k或Ctrl+p：光标上移一行 j或Ctrl+n ：光标下移一行 Enter ：光标下移一行 w或W ：光标右移一个字至字首 b或B ：光标左移一个字至字首 e或E ：光标右移一个字至字尾 ) ：光标移至句尾 ( ：光标移至句首 }：光标移至段落开头 {：光标移至段落结尾 nG：光标移至第n行首 n+：光标下移n行 n-：光标上移n行 n$：光标移至第n行尾 H ：光标移至屏幕顶行 M ：光标移至屏幕中间行 L ：光标移至屏幕最后行 0：（注意是数字零）光标移至当前行首 $：光标移至当前行尾 屏幕翻滚类命令 Ctrl+u：向文件首翻半屏 Ctrl+d：向文件尾翻半屏 Ctrl+f：向文件尾翻一屏 Ctrl＋b；向文件首翻一屏 nz：将第n行滚至屏幕顶部，不指定n时将当前行滚至屏幕顶部。 插入文本类命令 i ：在光标前 I ：在当前行首 a：光标后 A：在当前行尾 o：在当前行之下新开一行 O：在当前行之上新开一行 r：替换当前字符 R：替换当前字符及其后的字符，直至按ESC键 s：从当前光标位置处开始，以输入的文本替代指定数目的字符 S：删除指定数目的行，并以所输入文本代替之 ncw或nCW：修改指定数目的字 nCC：修改指定数目的行 删除命令 ndw或ndW：删除光标处开始及其后的n-1个字 do：删至行首 d$：删至行尾 ndd：删除当前行及其后n-1行 x或X：删除一个字符，x删除光标后的，而X删除光标前的 Ctrl+u：删除输入方式下所输入的文本 搜索及替换命令 /pattern：从光标开始处向文件尾搜索pattern ?pattern：从光标开始处向文件首搜索pattern n：在同一方向重复上一次搜索命令 N：在反方向上重复上一次搜索命令 ：s/p1/p2/g：将当前行中所有p1均用p2替代 ：n1,n2s/p1/p2/g：将第n1至n2行中所有p1均用p2替代 ：g/p1/s//p2/g：将文件中所有p1均用p2替换 选项设置 all：列出所有选项设置情况 term：设置终端类型 ignorance：在搜索中忽略大小写 list：显示制表位(Ctrl+I)和行尾标志（$) number：显示行号 report：显示由面向行的命令修改过的数目 terse：显示简短的警告信息 warn：在转到别的文件时若没保存当前文件则显示NO write信息 nomagic：允许在搜索模式中，使用前面不带“\\”的特殊字符 nowrapscan：禁止vi在搜索到达文件两端时，又从另一端开始 mesg：允许vi显示其他用户用write写到自己终端上的信息 最后行方式命令 ：n1,n2 co n3：将n1行到n2行之间的内容拷贝到第n3行下 ：n1,n2 m n3：将n1行到n2行之间的内容移至到第n3行下 ：n1,n2 d ：将n1行到n2行之间的内容删除 ：w ：保存当前文件 ：e filename：打开文件filename进行编辑 ：x：保存当前文件并退出 ：q：退出vi ：q!：不保存文件并退出vi ：!command：执行shell命令command ：n1,n2 w!command：将文件中n1行至n2行的内容作为command的输入并执行之，若不指定n1，n2，则表示将整个文件内容作为command的输入 ：r!command：将命令command的输出结果放到当前行 寄存器操作 \"?nyy：将当前行及其下n行的内容保存到寄存器？中，其中?为一个字母，n为一个数字 \"?nyw：将当前行及其下n个字保存到寄存器？中，其中?为一个字母，n为一个数字 \"?nyl：将当前行及其下n个字符保存到寄存器？中，其中?为一个字母，n为一个数字 \"?p：取出寄存器？中的内容并将其放到光标位置处。这里？可以是一个字母，也可以是一个数字 ndd：将当前行及其下共n行文本删除，并将所删内容放到1号删除寄存器中。 VI的使用 -------------------------------------------------------------------------------- 一、插入文本 ┌──┬────────────┐ │命令│描述　　　　　　　　　　│ ├──┼────────────┤ │i 　│在当前字符前插入文本　　│ ├──┼────────────┤ │I 　│在行首插入文本 　　　 　│ ├──┼────────────┤ │a 　│在当前字符后添加文本　　│ ├──┼────────────┤ │A 　│在行末添加文本　　　　　│ ├──┼────────────┤ │o 　│在当前行后面插入一空行　│ ├──┼────────────┤ │O 　│在当前行前面插入一空行　│ ├──┼────────────┤ │R 　│以改写方式输入文本　　　│ └──┴────────────┘ 二、移动光标 ┌─────┬───────────┐ │命令　　　│描述　　　　　　　　　│ ├─────┼───────────┤ │j或下箭头 │向下移动一行　　　　　│ ├─────┼───────────┤ │k或上箭头 │向上移动一行　　　　　│ ├─────┼───────────┤ │h或左箭头 │左移一个字符　　　　　│ ├─────┼───────────┤ │l或右箭头 │右移一个字符　　　　　│ ├─────┼───────────┤ │w 　　　　│右移一个词　　　　　　│ ├─────┼───────────┤ │W 　　　　│右移一个以空格分隔的词│ ├─────┼───────────┤ │b 　　　　│左移一个词　　　　　　│ ├─────┼───────────┤ │B 　　　　│左移一个以空格分隔的词│ ├─────┼───────────┤ │0 　　　　│移到行首　　　　　　　│ │Ctrl-F　　│向前翻页　　　　　　　│ ├─────┼───────────┤ │Ctrl-B　　│向后翻页　　　　　　　│ ├─────┼───────────┤ │nG　　　　│到第n行 　　　　　　　│ ├─────┼───────────┤ │G 　　　　│到最后一行　　　　　　│ └─────┴───────────┘ 三、替换文本 ┌─────┬──────┐ │命令　　　│描述　　　　│ ├─────┼──────┤ │$ 　　　　│到行尾　　　│ ├─────┼──────┤ │( 　　　　│到句子的开头│ ├─────┼──────┤ │) 　　　　│到句子的末尾│ ├─────┼──────┤ │{　 　　　│到段落的开头│ ├─────┼──────┤ │}　　 　　│到段落的末尾│ └─────┴──────┘ 四、删除文本 ┌───┬───────────┐ │命令　│描述 　　　　　　 　　│ ├───┼───────────┤ │r 　　│替换一个字符 　　　　 │ ├───┼───────────┤ │c 　　│修改文本直到按下Esc健 │ ├───┼───────────┤ │cw　　│修改下一个词 　　　 　│ ├───┼───────────┤ │cnw　 │修改接下来的n个词 　　│ └───┴───────────┘ 五、文本编辑 ┌──┬──────────────────────┐ │命寺│描述　　　　　　　　　　　　　　　　　　　　│ ├──┼──────────────────────┤ │yy　│将一行文本移到缺省缓冲区中 　　　　 　　　　│ ├──┼──────────────────────┤ │yn　│将下一个词移到缺省缓冲区中 　　 　　　　　　│ ├──┼──────────────────────┤ │ynw │将后面的n个词移到缺省缓冲区中　　　　 　　　│ ├──┼──────────────────────┤ │p 　│如果缺省缓冲区中包含一行文本，则在当前　　　│ │　　│行后面插入一个空行井将缺省缓冲区中的声　　　│ │　　│容粘贴到这一行中；如果缺省缓冲区中包含　　　│ │　　│多个词，把这些词粘贴到光标的右边．　　　　　│ ├──┼──────────────────────┤ │P 　│如果缺省缓冲区中包含一行文本，则正当前 　 　│ │ 　 │行前面插入一个空行井将缺省缓冲区中的内 　 　│ │　　│容粘贴到这一行中；如果缺省缓冲区中包含 　　 │ │ 　 │多个词，把这些词粘贴到光标的左边 　 　 　　│ └──┴──────────────────────┘ 六、保存退出 ┌───────────┬───────────────┐ │命令　　　　　　　　　│描述　　　　　　　　　　　　　│ ├───────────┼───────────────┤ │zz　　　　　　　　　　│保存并退出　　　　　　　　　　│ ├───────────┼───────────────┤ │:w filename　　　　 　│写入文件　　　　　　　　　 　 │ ├───────────┼───────────────┤ │:W　　　　　　　　　　│写入文件　　　　　　　　　　　│ ├───────────┼───────────────┤ │:x　　　　　　　　　　│保存(如果当前文件修改过)并退出│ ├───────────┼───────────────┤ │:q!　　　　　　　　　 │不保存文件，直接退出　　 　　 │ ├───────────┼───────────────┤ │:q　　　　　　　　　　│退出vi　　　　　　　　　　　　│ 一、基本命令介绍 ---- 1．光标命令 k、j、h、l——上、下、左、右光标移动命令。虽然您可以在Linux中使用键盘右边的4个光标键，但是记住这4个命令还是非常有用的。这4个键正是右手在键盘上放置的基本位置。 nG——跳转命令。n为行数，该命令立即使光标跳到指定行。 Ctrl+G——光标所在位置的行数和列数报告。 w、b——使光标向前或向后跳过一个单词。 ---- 2．编辑命令 i、a、r——在光标的前、后以及所在处插入字符命令(i=insert、a=append、r=replace)。 cw、dw——改变(置换)/删除光标所在处的单词的命令 (c=change、d=delete)。 x、d$、dd——删除一个字符、删除光标所在处到行尾的所有字符以及删除整行的命令。 ---- 3．查找命令 ---- /string、?string——从光标所在处向后或向前查找相应的字符串的命令。 ---- 4．拷贝复制命令 ---- yy、p——拷贝一行到剪贴板或取出剪贴板中内容的命令。 二、常见问题及应用技巧 ---- 1．在一个新文件中读/etc/passwd中的内容，取出用户名部分。 ---- vi file ---- :r /etc/passwd 在打开的文件file中光标所在处读入/etc/passwd ---- :%s/:.*//g 删除/etc/passwd中用户名后面的从冒号开始直到行尾的所有部分。 ---- 您也可以在指定的行号后读入文件内容，例如使用命令“:3r /etc/passwd”从新文件的第3行开始读入 /etc/passwd的所有内容。 ---- 我们还可以使用以下方法删掉文件中所有的空行及以#开始的注释行。 ---- #cat squid.conf.default | grep -v ^$ | grep -v ^# ---- 2．在打开一个文件编辑后才知道登录的用户对该文件没有写的权限，不能存盘，需要将所做修改存入临时文件。 ---- vi file ---- :w /tmp/1 保存所做的所有修改，也可以将其中的某一部分修改保存到临时文件，例如仅仅把第20～59行之间的内容存盘成文件/tmp/1，我们可以键入如下命令。 ---- vi file ---- :20,59w /tmp/1 ---- 3．用VI编辑一个文件，但需要删除大段的内容。 ---- 首先利用编辑命令“vi file”打开文件，然后将光标移到需要删除的行处按Ctrl+G显示行号，再到结尾处再按Ctrl+G，显示文件结尾的行号。 ---- :23,1045d 假定2次得到的行号为23和1045，则把这期间的内容全删除，也可以在要删除的开始行和结束行中用ma、mb命令标记，然后利用“:a,bd”命令删除。 ---- 4．在整个文件的各行或某几行的行首或行尾加一些字符串。 ---- vi file ---- :3,$s/^/some string / 在文件的第一行至最后一行的行首插入“some string”。 ---- :%s/$/some string/g 在整个文件每一行的行尾添加“some string”。 ---- :%s/string1/string2/g 在整个文件中替换“string1”成“string2”。 ---- :3,7s/string1/string2/ 仅替换文件中的第3行到第7行中的“string1”成“string2”。 ---- 注意: 其中s为substitute，%表示所有行，g表示global。 ---- 5．同时编辑2个文件，拷贝一个文件中的文本并粘贴到另一个文件中。 ---- vi file1 file2 ---- yy 在文件1的光标处拷贝所在行 ---- :n 切换到文件2 (n=next) ---- p 在文件2的光标所在处粘贴所拷贝的行 ---- :n 切换回文件1 ---- 6．替换文件中的路径。 ---- 使用命令“:%s#/usr/bin#/bin#g”可以把文件中所有路径/usr/bin换成/bin。也可以使用命令“:%s//usr/bin//bin/g”实现，其中“”是转义字符，表明其后的“/”字符是具有实际意义的字符，不是分隔符。","title":"Linux VI 命令全集"},{"content":"//first.c#include <stdio.h>void f(void);int x = 15213;int y = 15212;int main(){\tf();\tprintf(\"x = ox%x y = 0x%x\\n\", x, y);\t\treturn 0;} //bar.cdouble x;void f(){\tx = -0.0;} xxx@ubuntu-64bit-compile:~/share2/learning/csapp/project$ cc first.c bar4.c /usr/bin/ld: Warning: alignment 4 of symbol `x' in /tmp/ccFBxcBU.o is smaller than 8 in /tmp/ccOvyDIy.o xxx@ubuntu-64bit-compile:~/share2/learning/csapp/project$ ./a.out  x = ox0 y = 0x80000000 因为double 类型是8个字节， 而int 类型是4个字节。因此， 负值的双精度浮点表示覆盖存储中 x 和 y的位置。因此就会产生那样的打印结果。 为此， 在项目中， 得到了一条经验教训： 不要忽视 编译警告。。。。  这一点开发人员一直不注意。","title":"链接器解析多重定义的全局变量"},{"content":"linux 编译相关问题 Fuse 编译： FUSE是一个用户态的文件系统框架，使用这个框架设计一个文件系统很简单，由于是初学，就直接到了example文件夹下，看了看文件内的编译命令是 Gcc -Wall `pkg-config fuse --cflags --libs` hello.c -o hello 自己一试，发现完全不行，报错是FUSE_MAIN_REAL()找不到实现，找了半天发现有一篇帖子 实际上这个函数的实现在helper.c中，并且被编译到了相应的链接库中。究其原因，其实是gcc的命令行参数传入的顺序问题。`pkg-config fuse --cflags --libs`这个东西，可以把它理解成一个在fuse安装时定义的变量，可以在终端中输入echo `pkg-config fuse --cflags --libs`即可看到这个变量展开之后所表示的gcc的命令行参数，应该是这种形式“-D_FILE_OFFSET_BITS64 -I/usr/includefuse -pthread -lfuse -lrt=”。其中包含了一个-lfuse命令，它的作用是链接fuse相应的链接库，也就是告诉编译器去哪里能找到fuse_main_real()的实现。事实上gcc要求链接库的命令行参数要放在源代码文件之后，所以将上面的命令改成：   Gcc -Wall hello.c -o hello `pkg-config fuse --cflags --libs`  成功，其实这个错误我找了很久，看了很多外国的网站人家都解决不了（还是人家没这种问题不得而知），国人还是有很多大牛的。 转自：http://blog.csdn.net/zgl07/article/details/7558766","title":"linux 编译相关问题"},{"content":"linux c 信号量编程 信号量 当我们在多用户系统，多进程系统，或是两者混合的系统中使用线程操作编写程序时，我们经常会发现我们有段临界代码，在此处我们需要保证一个进程（或是一个线程的执行）需要排他的访问一个资源。 信号量有一个复杂的编程接口。幸运的是，我们可以很容易的为自己提供一个对于大多数的信号量编程问题足够高效的简化接口。 为了阻止多个程序同时访问一个共享资源所引起的问题，我们需要一种方法生成并且使用一个标记从而保证在临界区部分一次只有一个线程执行。线程相关的方法，我们可以使用互斥或信号量来控制一个多线程程序对于临界区的访问。 编写通用目的的代码保证一个程序排他的访问一个特定的资源是十分困难的，尽管有一个名为Dekker的算法解决方法。不幸的是，这个算法依赖于\"忙等待\" 或是\"自旋锁\"，即一个进程的连续运行需要等待一个内存地址发生改变。在一个多任务环境中，例如Linux，这是对CPU资源的无谓浪费。如果硬件支持，这样的情况就要容易得多，通常以特定CPU指令的形式来支持排他访问。硬件支持的例子可以是访问指令与原子方式增加寄存器值，从而在读取/增加/写入的操作之间就不会有其他的指令运行。 我们已经了解到的一个要行的解决方法就是使用O_EXCL标记调用open函数来创建文件，这提供了原子方式的文件创建。这会使得一个进程成功的获得一个标记：新创建的文件。这个方法可以用于简单的问题，但是对于复杂的情况就要显得烦琐与低效了。 当Dijkstr引入信号量的概念以后，并行编程领域前进了一大步。正如我们在第12章所讨论的，信号量是一个特殊的变量，他是一个整数，并且只有两个操作可以使得其值增加：等待(wait)与信号(signal)。因为在Linux与UNIX编程中，\"wait\"与\"signal\"已经具有特殊的意义了，我们将使用原始概念： 用于等待(wait)的P(信号量变量) 用于信号(signal)的V(信号量变量) 这两字母来自等待(passeren：通过，如同临界区前的检测点)与信号(vrjgeven：指定或释放，如同释放临界区的控制权)的荷兰语。有时我们也会遇到与信号量相关的术语\"up\"与\"down\"，来自于信号标记的使用。 信号量定义 最简单的信号量是一个只有0与1两个值的变量，二值信号量。这是最为通常的形式。具有多个正数值的信号量被称之为通用信号量。在本章的其余部分，我们将会讨论二值信号量。 P与V的定义出奇的简单。假定我们有一个信号量变量sv，两个操作定义如下： P(sv)    如果sv大于0，减小sv。如果sv为0，挂起这个进程的执行。 V(sv)    如果有进程被挂起等待sv，使其恢复执行。如果没有进行被挂起等待sv，增加sv。 信号量的另一个理解方式就是当临界区可用时信号量变量sv为true，当临界区忙时信号量变量被P(sv)减小，从而变为false，当临界区再次可用时被V(sv)增加。注意，简单的具有一个我们可以减小或是增加的通常变量并不足够，因为我们不能用C，C++或是其他的编程语言来表述生成信号，进行原子测试来确定变量是否为true，如果是则将其变为false。这就是使得信号量操作特殊的地方。 一个理论例子 我们可以使用一个简单的理论例子来了解一下信号量是如何工作的。假设我们有两个进程proc1与proc2，这两个进程会在他们执行的某一时刻排他的访问一个数据库。我们定义一个单一的二值信号量，sv，其初始值为1并且可以为两个进程所访问。两个进程然后需要执行同样的处理来访问临界区代码；实际上，这两个进程可以是同一个程序的不同调用。 这两个进程共享sv信号量变量。一旦一个进程已经执行P(sv)操作，这个进程就可以获得信号量并且进入临界区。第二个进程就会被阻止进行临界区，因为当他尝试执行P(sv)时，他就会等待，直到第一个进程离开临界区并且执行V(sv)操作来释放信号量。 所需要的过程如下： semaphore sv = 1; loop forever {     P(sv);     critical code section;     V(sv);     noncritical code section; } 这段代码出奇的简单，因为P操作与V操作是十分强大的。图14-1显示了P操作与V操作如何成为进行临界区代码的门槛。 Linux信号量工具 现在我们已经了解了什么是信号量以及他们在理论上是如何工作的，现在我们可以来了解一下这些特性在Linux中是如何实现的。信号量函数接口设计十分精细，并且提供了比通常所需要的更多的实用性能。所有的Linux信号量函数在通用的信号量数组上进行操作，而不是在一个单一的二值信号量上进行操作。乍看起来，这似乎使得事情变得更为复杂，但是在一个进程需要锁住多个资源的复杂情况下，在信号量数组上进行操作将是一个极大的优点。在这一章，我们将会关注于使用单一信号量，因为在大多数情况下，这正是我们需要使用的。 信号量函数定义如下： #include <sys/sem.h> int semctl(int sem_id, int sem_num, int command, ...); int semget(key_t key, int num_sems, int sem_flags); int semop(int sem_id, struct sembuf *sem_ops, size_t num_sem_ops); 事实上，为了获得我们特定操作所需要的#define定义，我们需要在包含sys/sem.h文件之前通常需要包含sys/types.h与sys/ipc.h文件。而在某些情况下，这并不是必须的。 因为我们会依次了解每一个函数，记住，这些函数的设计是用于操作信号量值数组的，从而会使用其操作向比单个信号量所需要的操作更为复杂。 注意，key的作用类似于一个文件名，因为他表示程序也许会使用或是合作所用的资源。相类似的，由semget所返回的并且为其他的共享内存函数所用的标识符与由fopen函数所返回 的FILE *十分相似，因为他被进程用来访问共享文件。而且与文件类似，不同的进程会有不同的信号量标识符，尽管他们指向相同的信号量。key与标识符的用法对于在这里所讨论的所有IPC程序都是通用的，尽管每一个程序会使用独立的key与标识符。 semget semget函数创建一个新的信号量或是获得一个已存在的信号量键值。 int semget(key_t key, int num_sems, int sem_flags); 第一个参数key是一个用来允许不相关的进程访问相同信号量的整数值。所有的信号量是为不同的程序通过提供一个key来间接访问的，对于每一个信号量系统生成一个信号量标识符。信号量键值只可以由semget获得，所有其他的信号量函数所用的信号量标识符都是由semget所返回的。 还有一个特殊的信号量key值，IPC_PRIVATE(通常为0)，其作用是创建一个只有创建进程可以访问的信号量。这通常并没有有用的目的，而幸运的是，因为在某些Linux系统上，手册页将IPC_PRIVATE并没有阻止其他的进程访问信号量作为一个bug列出。 num_sems参数是所需要的信号量数目。这个值通常总是1。 sem_flags参数是一个标记集合，与open函数的标记十分类似。低九位是信号的权限，其作用与文件权限类似。另外，这些标记可以与 IPC_CREAT进行或操作来创建新的信号量。设置IPC_CREAT标记并且指定一个已经存在的信号量键值并不是一个错误。如果不需要，IPC_CREAT标记只是被简单的忽略。我们可以使用IPC_CREAT与IPC_EXCL的组合来保证我们可以获得一个新的，唯一的信号量。如果这个信号量已经存在，则会返回一个错误。 如果成功，semget函数会返回一个正数；这是用于其他信号量函数的标识符。如果失败，则会返回-1。 semop 函数semop用来改变信号量的值： int semop(int sem_id, struct sembuf *sem_ops, size_t num_sem_ops); 第一个参数，sem_id，是由semget函数所返回的信号量标识符。第二个参数，sem_ops，是一个指向结构数组的指针，其中的每一个结构至少包含下列成员： struct sembuf {     short sem_num;     short sem_op;     short sem_flg; } 第一个成员，sem_num，是信号量数目，通常为0，除非我们正在使用一个信号量数组。sem_op成员是信号量的变化量值。（我们可以以任何量改变信号量值，而不只是1）通常情况下中使用两个值，-1是我们的P操作，用来等待一个信号量变得可用，而+1是我们的V操作，用来通知一个信号量可用。 最后一个成员，sem_flg，通常设置为SEM_UNDO。这会使得操作系统跟踪当前进程对信号量所做的改变，而且如果进程终止而没有释放这个信号量，如果信号量为这个进程所占有，这个标记可以使得操作系统自动释放这个信号量。将sem_flg设置为SEM_UNDO是一个好习惯，除非我们需要不同的行为。如果我们确实变我们需要一个不同的值而不是SEM_UNDO，一致性是十分重要的，否则我们就会变得十分迷惑，当我们的进程退出时，内核是否会尝试清理我们的信号量。 semop的所用动作会同时作用，从而避免多个信号量的使用所引起的竞争条件。我们可以在手册页中了解关于semop处理更为详细的信息。 semctl semctl函数允许信号量信息的直接控制： int semctl(int sem_id, int sem_num, int command, ...); 第一个参数，sem_id，是由semget所获得的信号量标识符。sem_num参数是信号量数目。当我们使用信号量数组时会用到这个参数。通常，如果这是第一个且是唯一的一个信号量，这个值为0。command参数是要执行的动作，而如果提供了额外的参数，则是union semun，根据X/OPEN规范，这个参数至少包括下列参数： union semun {     int val;     struct semid_ds *buf;     unsigned short *array; } 许多版本的Linux在头文件(通常为sem.h)中定义了semun联合，尽管X/Open确认说我们必须定义我们自己的联合。如果我们发现我们确实需要定义我们自己的联合，我们可以查看semctl手册页了解定义。如果有这样的情况，建议使用手册页中提供的定义，尽管这个定义与上面的有区别。 有多个不同的command值可以用于semctl。在这里我们描述两个会经常用到的值。要了解semctl功能的详细信息，我们应该查看手册页。 这两个通常的command值为： SETVAL：用于初始化信号量为一个已知的值。所需要的值作为联合semun的val成员来传递。在信号量第一次使用之前需要设置信号量。 IPC_RMID：当信号量不再需要时用于删除一个信号量标识。 semctl函数依据command参数会返回不同的值。对于SETVAL与IPC_RMID，如果成功则会返回0，否则会返回-1。 使用信号量 正如我们在前面部分的描述中所看到的，信号量操作是相当复杂的。这是最不幸的，因为使用临界区进行多进程或是多线程编程是一个十分困难的问题，而其拥有其自己复杂的编程接口也增加了编程负担。 幸运的是，我们可以使用最简单的二值信号量来解决大多数需要信号量的问题。在我们的例子中，我们会使用所有的编程接口来创建一个非常简单的用于二值信号量的P 与V类型接口。然后，我们会使用这个简单的接口来演示信号量如何工作。 要试验信号量，我们将会使用一个简单的程序，sem1.c，这个程序我们可以多次调用。我们将会使用一个可选的参数来标识这个程序是负责创建信号量还是销毁信号量。 我们使用两个不同字符的输出来标识进入与离开临界区。使用参数调用的程序会在进入与离开其临界区时输出一个X，而另一个程序调用会在进入与离开其临界区时输出一个O。因为在任何指定的时间内只有一个进程能够进入其临界区，所以所有X与O字符都是成对出现的。 试验－－信号量 1 在#include语句之后，我们定义函数原型与全局变量，然后我们进入main函数。在这里使用semget函数调用创建信号量，这会返回一个信号量 ID。如果程序是第一次调用（例如，使用一个参数并且argc > 1来调用），程序就会调用set_semvalue来初始化信号量并且将op_char设置为X。 #include <stdio.h> #include <stdlib.h> #include <unistd.h> #include <sys/types.h> #include <sys/ipc.h> #include <sys/sem.h> #include \"semun.h\" static int set_semvalue(void); static void del_semvalue(void); static int semaphore_p(void); static int semaphore_v(void); static int sem_id; int main(int argc, char **argv) {     int i;     int pause_time;     char op_char = 'O';     srand((unsigned int)getpid());     sem_id = semget((key_t)1234, 1, 0666 | IPC_CREAT);     if(argc > 1)     {         if(!set_semvalue())         {             fprintf(stderr, \"Failed to initialize semaphore/n\");             exit(EXIT_FAILURE);         }         op_char = 'X';         sleep(2);     } 2 然后我们使用一个循环代码进入并且离开临界区10次。此时会调用semaphore_p函数，这个函数会设置信号量并且等待程序进入临界区。     for(i=0;i<10;i++)     {         if(!semaphore_p()) exit(EXIT_FAILURE);         printf(\"%c\", op_char); fflush(stdout);         pause_time = rand() % 3;         sleep(pause_time);         printf(\"%c\", op_char); fflush(stdout); 3 在临界区之后，我们调用semaphore_v函数，在随机的等待之后再次进入for循环之后，将信号量设置为可用。在循环之后，调用del_semvalue来清理代码。         if(!semaphore_v()) exit(EXIT_FAILURE);         pause_time = rand() % 2;         sleep(pause_time);     }     printf(\"/n%d - finished/n\", getpid());     if(argc > 1)     {         sleep(10);         del_semvalue();     }     exit(EXIT_SUCCESS);     } 4 函数set_semvalue在一个semctl调用中使用SETVAL命令来初始化信号量。在我们使用信号量之前，我们需要这样做。 static int set_semvalue(void) {     union semun sem_union;     sem_union.val = 1;     if(semctl(sem_id, 0, SETVAL, sem_union) == -1) return 0;     return 1; } 5 del_semvalue函数几乎具有相同的格式，所不同的是semctl调用使用IPC_RMID命令来移除信号量ID： static void del_semvalue(void) {     union semun sem_union;     if(semctl(sem_id, 0, IPC_RMID, sem_union) == -1)         fprintf(stderr, \"Failed to delete semaphore/n\"); } 6 semaphore_p函数将信号量减1（等待）： static int semaphore_p(void) {     struct sembuf sem_b;     sem_b.sem_num = 0;     sem_b.sem_op = -1;     sem_b.sem_flag = SEM_UNDO;     if(semop(sem_id, &sem_b, 1) == -1)     {         fprintf(stderr, \"semaphore_p failed/n\");         return 0;     }     return 1; } 7 semaphore_v函数将sembuf结构的sem_op部分设置为1，从而信号量变得可用。 static int semaphore_v(void) {     struct sembuf sem_b;     sem_b.sem_num = 0;     sem_b.sem_op = 1;     sem_b.sem_flag = SEM_UNDO;     if(semop(sem_id, &sem_b, 1) == -1)     {         fprintf(stderr, \"semaphore_v failed/n\");         return 0;     }     return 1; } 注意，这个简单的程序只有每个程序有一个二值信号量，尽管如果我们需要多个信号量，我们可以扩展这个程序来传递多个信号量变量。通常，一个简单的二值信号量就足够了。 我们可以通过多次调用这个程序来测试我们的程序。第一次，我们传递一个参数来通知程序他并不负责创建与删除信号量。另一次调用没有传递参数。 下面是两次调用的示例输出结果： $ ./sem1 1 & [1] 1082 $ ./sem1 OOXXOOXXOOXXOOXXOOXXOOOOXXOOXXOOXXOOXXXX 1083 - finished 1082 - finished $ 正如我们所看到了，O与X是成对出现的，表明临界区部分被正确的处理了。如果这个程序在我们的系统上不能正常运行，也许我们需要在调用程序之前使用命令stty -tostop来保证生成tty输出的后台程序不会引起信号生成。 工作原理 这个程序由我们选择使用semget函数所获得的键生成一个信号量标识开始。IPC_CREAT标记会使得如果需要的时候创建一个信号量。 如果这个程序有参数，他负责使用我们的set_semvalue函数来初始化信号量，这是更为通用的semctl函数的一个简化接口。同时，他也使用所提供的参数来决定要输出哪一个字符。sleep只是简单的使得我们在这个程序执行多次之前有时间调用程序的另一个拷贝。在程序中我们使用srand与 rand来引入一些伪随机计数。 这个程序循环十次，在其临界区与非临界区等待一段随机的时间。临界区代码是通过调用我们的semaphore_p与semaphore_v函数来进行保护的，这两个函数是更为通用的semop函数的简化接口。 在删除信号量之前，使用参数调用的程序拷贝会等待其他的调用结束。如果信号量没有删除，他就会继续存在于系统中，尽管已经没有程序再使用他。在实际的程序中，保证我们没有遗留信号是十分重要的。在我们下一次运行程序时，遗留的信号量会引起问题，而且信号量是限制资源，我们必须小心使用。","title":"linux c 信号量编程"},{"content":"ls –a（all）：表示列出所有的文件，包括以\".\"开头的隐藏文件。位于这个列表的起首处的 .. 和 . 依次是指父目录和你的当前目录。 ls –l (long)：列举目录内容的详细信息，包括权限（模式）、所有者、组群、大小、创建日期、文件是否是到系统其它地方的链接，以及链接的指向。 # ls –ltotal 5-rw-r--r--     1 root  root    1668 Oct   3   20:07  anaconda-ks.cfgdrwxr-xr-x     2 root  root    4096 Nov   6   00:04  aa total 5：代表当前目录下文件大小的总和为5K（每个目录的大小都按4K算） drwxr-xr-x 第一个字符有3种 情况：“-”表示普通文件，“d”代表目录，“l”代表连接文件，“b”代 表设备文件。后面的9个字符每3个为一组，分别代表文件所有者、文件所有者所在用户组、其它用户对文件拥 有的权限。每组中3个字符分别代表读、写、执行的权限，若没有 其中的任何一个权限则用“-”表示。执行的权限有两个字符可选“x”代表可执行，“s”代表套接口文件。 紧接着的数字2代 表 “aa”这个目录下的目录文件数目（这个数目=隐藏目录数目+普通目录数目）。如果这个aa是 个普通文件，2就代表这个文件有2个别名（这个文件被人创建了一个硬链接文件） 再接下来的root代 表这个文件（目录）的属主为：用户root 再接下来的root代表这个文件（目录）所属的用户组为：组root 4096 代表文件的大小（字节数），目录的 大小总是为4096字节。 Nov  6 00:04 代表文件（目录）的修改时间。 aa代表文件（目录）的名字。 以上内容链接于：http://blog.lehu.shu.edu.cn/byman/A293366.html","title":"【转】linux ls -al 结果解释"},{"content":"1.指定文件读取makefile make -f name make --file=name 注：用于本目录中没有makefile,Makefile或GNU make,需要手动指定文件去读取。 2.系统调用 man 2 write 3.多窗口切换 :sp /etc/hosts 注：Ctrl+w+上下箭头 4.数据重定向 cat > catfile < ~/.bashrc  将.bashrc文件内容覆盖掉catfile cat > catfile << ~/.bashrc 将.bashrc文件内容累加到catfile 5.文字输入、 cat >catfile <<\"eof\" 注：可直接输入内容，当输入eof的时候表示结束，等价于vim catfile 6.内核代码所在位置    在/usr/src/kernels/2.6.32-71.el6.i686和/lib/modules/2.6.32-71.el6.i686/build或者/lib/modules/2.6.32-71.el6.i686/source make menuconfig图形化配置 7.grep :可用于查找函数实参 (1)在内核目录下查找包含\"request_irq\"字样的字符串。(-R表示递归) grep \"request_irq\" * -R (2)在内核kernel目录下查找包含\"request_irq\"字样的字符串 grep \"request_irq\" kernel -R 8.find:查找文件(必须要带通配符) (1)在内核目录下查找文件名中包含\"fb\"字样的文件 find -name \"*fb*\" (2)在内核的某目录下查找文件名中包含\"fb\"字样的文件 find drivers/net -name \"*fb*\"   locate 文件名：这个速度是最快的 9.压缩 tar cvzf vivi.tar.gz vivi tar cvjf vivi.tar.bz2 vivi   解压 tar xvzf vivi.tar.gz tar xvjf vivi.tar.bz2 注： c:创建，生成文件包 v:更多提示信息 x:提取，从文件包中提取文件 z:使用gzip方式处理 j:使用bzip2方式处理 f:表示文件，后面接着一个文件名 10.名词解释 ABI:应用程序二进制接口 EABI:嵌入式应用程序二进制接口，一般针对于ARM的CPU. 11.快捷方式 ln -s source target 软链接: ln -s var var_l 硬链接：ln    var var_l 区别：软链接不占用空间，硬链接占用空间，但都数据同步 12.复制目录 cp -rf source target 13.使用NAT网络，linux与XP的IP不在一个网段    使用brigde网络，linux与XP的IP必须在一个网段。 14.文件I/O:基于文件描述符的,不带缓存 eg:read ,write,open    标准I/O:基于流缓冲 eg:fopen,fread 15.系统开机加载的内核文件/boot/vmlinuz 但是主机上可以拥有多个内核文件 16.env 环境变量 17.在linux文件系统中，只能在头文件下看到函数声明，一般在/usr/include下 看不到函数的具体定义，因为函数的定义被封装到库里面去了，在/lib下。 使用man，只可以看到一部分函数的定义。 //***************2012.11.17 18.快速寻找指定的函数与变量 1)自行建立 用户目录下touch ./vimrc 每次创建一个ctags，在./vimrc输入 set tags=/opt/FriendlyARM/mini2440/linux-2.6.32.2/tags 2)ctags -R * 3)vi -t tag(把tag替换为欲查找的变量与函数名) 4)Ctrl + ] 进入查询 5)Ctrl + o 返回查询 6)Ctrl + T                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ","title":"linux总结"},{"content":"高级一些的编辑器，都会包含宏功能，vim当然不能缺少了，在vim中使用宏是非常方便的： :qx     开始记录宏，并将结果存入寄存器x q     退出记录模式 @x     播放记录在x寄存器中的宏命令 稍微解释一下，当在normal模式下输入:qx后，你对文本的所有编辑动作将会被记录下来，再次输入q即退出了记录模 式，然后输入@x对刚才记录下来的命令进行重复，此命令后可跟数字，表示要重复多少次，比如@x20，可以重复20次。这个在文本的批处理中是非常有用的。 同时编辑多个文件 在vim众多的插件中，有一个叫minibuffer的插件，就是下面所说的标签页功能了，可以支持同时编辑多个文件。 标签命令 :tabe fn     在一个新的标签页中编辑文件fn gt     切换到下一个标签页 gT     切换到上一个标签页 :tabr     切换到第一个标签页 :tabl     切换到最后一个标签页 :tabm [N]     把当前tab移动到第N个tab之后 对，正如你所想象的那样，跟eclipse, ue等的标签页是一个意思！ 窗口命令 ctrl+w s     水平分割窗口 ctrl+w w     切换窗口 ctrl+w q     退出当前窗口(由于同时有多个文件，此命令不会影响其他窗口) ctrl+w v     垂直分割窗口 其他 vim在保存之前不会对文件做实际的修改，只是加载到缓冲区中，对文件的编辑其实是对缓冲区的编辑，直到:w时才会存入物理文件。 :e file     把file加载到新的缓冲区中 :bn     跳转到下一个缓冲区 :bd     删除缓冲区(关闭文件) :sp fn     分割窗口，并将fn加载到新的窗口中 退出编辑器 :w     将缓冲区写入文件，即保存修改 :wq     保存修改并退出 :x     保存修改并退出 :q     退出，如果对缓冲区进行过修改，则会提示 :q!     强制退出，放弃修改 查找替换 /pattern     向后搜索字符串pattern ?pattern     向前搜索字符串pattern n     下一个匹配(如果是/搜索，则是向下的下一个，?搜索则是向上的下一个) N     上一个匹配(同上) :%s/old/new/g     搜索整个文件，将所有的old替换为new :%s/old/new/gc     搜索整个文件，将所有的old替换为new，每次都要你确认是否替换 复制粘贴 dd     删除光标所在行 dw     删除一个字(word) x     删除当前字符 X     删除前一个字符 D     删除到行末 yy     复制一行，此命令前可跟数字，标识复制多行，如6yy，表示从当前行开始复制6行 yw     复制一个字 y$     复制到行末 p     粘贴粘贴板的内容到当前行的下面 P     粘贴粘贴板的内容到当前行的上面 ]p     有缩进的粘贴，vim会自动调节代码的缩进 \"a     将内容放入/存入a寄存器，可以支持多粘贴板 附：比如常用的一个寄存器就是系统寄存器，名称为+，所以从系统粘贴板粘贴到vim中的命令为\"+p,注意此处的+不表示操作符，二十一个寄存器。 移动光标 在vim中移动光标跟其他的编辑器中有很大的区别，不过一旦学会了，就会飞速的在文本中移动了。 h,j,k,l     上，下，左，右 ctrl-f     上翻一页 ctrl-b     下翻一页 %     跳到与当前括号匹配的括号处，如当前在{，则跳转到与之匹配的}处 w     跳到下一个字首，按标点或单词分割 W     跳到下一个字首，长跳，如end-of-line被认为是一个字 e     跳到下一个字尾 E     跳到下一个字尾，长跳 b     跳到上一个字 B     跳到上一个字，长跳 0     跳至行首，不管有无缩进，就是跳到第0个字符 ^     跳至行首的第一个字符 $     跳至行尾 gg     跳至文件的第一行 gd     跳至当前光标所在的变量的声明处 [N]G     跳到第N行，如0G，就等价于gg，100G就是第100行 fx     在当前行中找x字符，找到了就跳转至 ;     重复上一个f命令，而不用重复的输入fx tx     与fx类似，但是只是跳转到x的前一个字符处 Fx     跟fx的方向相反 ),(     跳转到上/下一个语句 *     查找光标所在处的单词，向下查找 #     查找光标所在处的单词，向上查找 `.     跳转至上次编辑位置 在屏幕上移动 H     移动光标到当前屏幕上最上边的一行 M     移动光标到当前屏幕上中间的一行 L     移动光标到当前屏幕上最下边的一行 书签 ma     把当前位置存成标签a `a     跳转到标签a处 编辑 r     替换一个字符 J     将下一行和当前行连接为一行 cc     删除当前行并进入编辑模式 cw     删除当前字，并进入编辑模式 c$     擦除从当前位置至行末的内容，并进入编辑模式 s     删除当前字符并进入编辑模式 S     删除光标所在行并进入编辑模式 xp     交换当前字符和下一个字符 u     撤销 ctrl+r     重做 .     重复上一个编辑命令 ~     切换大小写，当前字符 g~iw     切换当前字的大小写 gUiw     将当前字变成大写 guiw     将当前字变成小写 >>     将当前行右移一个单位 <<     将当前行左移一个单位(一个tab符) ==     自动缩进当前行 插入模式 i     从当前光标处进入插入模式 I     进入插入模式，并置光标于行首 a     追加模式，置光标于当前光标之后 A     追加模式，置光标于行末 o     在当前行之下新加一行，并进入插入模式 O     在当前行之上新加一行，并进入插入模式 Esc     退出插入模式 可视模式 标记文本 v     进入可视模式，单字符模式 V     进入可视模式，行模式 ctrl+v     进入可视模式，列模式，类似于UE的列模式 o     跳转光标到选中块的另一个端点 U     将选中块中的内容转成大写 O     跳转光标到块的另一个端点 aw     选中一个字 ab     选中括号中的所有内容，包括括号本身 aB     选中{}括号中的所有内容 ib     选中括号中的内容，不含括号 iB     选中{}中的内容，不含{} 对标记进行动作 >     块右移 <     块左移 y     复制块 d     删除块 ~     切换块中内容的大小写","title":"linux下vim命令详解"},{"content":"linux下静态路由修改命令 方法一： 添加路由 route add -net 192.168.0.0/24 gw 192.168.0.1 route add -host 192.168.1.1 dev 192.168.0.1 删除路由 route del -net 192.168.0.0/24 gw 192.168.0.1 add 增加路由 del 删除路由 -net 设置到某个网段的路由 -host 设置到某台主机的路由 gw 出口网关 IP地址 dev 出口网关 物理设备名 增加默认路由 route add default gw 192.168.0.1 默认路由一条就够了 route -n 查看路由表 方法二： 添加路由 ip route add 192.168.0.0/24 via 192.168.0.1 ip route add 192.168.1.1 dev 192.168.0.1 删除路由 ip route del 192.168.0.0/24 via 192.168.0.1 add 增加路由 del 删除路由 via 网关出口 IP地址 dev 网关出口 物理设备名 增加默认路由 ip route add default via 192.168.0.1 dev eth0 via 192.168.0.1 是我的默认路由器 查看路由信息 ip route 保存路由设置，使其在网络重启后任然有效  在/etc/sysconfig/network-script/目录下创建名为route- eth0的文件  vi /etc/sysconfig/network-script/route-eth0  在此文件添加如下格式的内容  192.168.1.0/24 via 192.168.0.1  重启网络验证    /etc/rc.d/init.d/network中有这么几行： # Add non interface-specific static-routes. if [ -f /etc/sysconfig/static-routes ]; then grep \"^any\" /etc/sysconfig/static-routes | while read ignore args ; do /sbin/route add -$args done fi  也就是说，将静态路由加到/etc/sysconfig/static-routes 文件中就行了。   如加入： route add -net 11.1.1.0 netmask 255.255.255.0 gw 11.1.1.1 则static-routes的格式为 any net 11.1.1.0 netmask 255.255.255.0 gw 11.1.1.1  ","title":"linux下静态路由修改命令"},{"content":"LINUX下MYSQL的配置 安装 　　rmp -ivh MySQL-server-4.1.22-0.glibc23.i386.rpm --nodeps 　　rmp -ivh MySQL-client-4.1.22-0.glibc23.i386.rpm --nodeps 查看是否安装成功 　　netstat -atln命令看到3306端口开放说明安装成功 登录 　　mysql [-u username] [-h host] [-p[password]] [dbname] 　　初始无密码，这个mysql可执行文件在/usr/bin/mysql 目录 　　1、数据库目录 　　　　/var/lib/mysql/ 　　2、配置文件 　　　　/usr/share/mysql（mysql.server命令及配置文件） 　　3、相关命令 　　　　/usr/bin(mysqladmin mysqldump等命令) 　　4、启动脚本 　　　　/etc/rc.d/init.d/（启动脚本文件mysql的目录） 修改登录密码 　　MySQL默认没有密码 　　　　usr/bin/mysqladmin -u root password 'new-password' 　　格式：mysqladmin -u用户名 -p旧密码 password 新密码 启动与停止 　　MySQL安装完成后启动文件mysql在/etc/init.d目录下，在需要启动时运行下面命令即可 　　启动： 　　　　/etc/init.d/mysql start 　　停止： 　　　　/usr/bin/mysqladmin -u root -p shutdown 　　重新启动： 　　　　sudo /etc/init.d/mysql restart  　　自动启动： 　　　　察看mysql是否在自动启动列表中/sbin/chkconfig --list 　　　　把MySQL添加到你系统的启动服务组里面去/sbin/chkconfig --add mysql 　　　　把MySQL从启动服务组里面删除/sbin/chkconfig --del mysql 配置 　　将/usr/share/mysql/my-medium.cnf复制到/etc/my.cnf，以后修改my.cnf文件来修改mysql的全局设置 　　将my.cnf文件中的innodb_flush_log_at_trx_commit设成0来优化 　　[mysqld]后添加添加lower_case_table_names设成1来不区分表名的大小写 设置字符集 　　MySQL的默认编码是Latin1，不支持中文，要支持需要把数据库的默认编码修改为gbk或者utf8。 　　1、中止MySQL服务（bin/mysqladmin -u root shutdown） 　　2、在/etc/下找到my.cnf，如果没有就把MySQL的安装目录下的/usr/share/mysql目录下的my-medium.cnf复制到/etc/下并改名为my.cnf即可  　　3、打开my.cnf以后，在[client]和[mysqld]下面均加上default-character-set=utf8，保存并关闭 　　4、启动MySQL服务（bin/mysqld_safe &） 　　查询字符集：show variables like '%set%'; 增加MySQL用户 　　格式：grant select on 数据库.* to 用户名@登录主机 identified by \"密码\" 　　　　   grant select,insert,update,delete on *.* touser_1@'%' Identified by '123'; 　　　　   grant all on *.* touser_1@'localhost' Identified by '123'; 远程访问 　　其一： 　　　　GRANT ALL PRIVILEGES ON *.* TOroot@'%' IDENTIFIED BY 'pw' WITH GRANT OPTION; 　　允许xoops_root用户可以从任意机器上登入MySQL。 　　其二： 　　编辑 /etc/mysql/my.cnf 　　　　>skip-networking => # skip-networking 　　这样就可以允许其他机器访问MySQL了。 　　　　grant all on *.* to'root'@'ip' identified by 'password' with frant option;  　　添加防火墙白名单： 　　　　vim /etc/sysconfig/iptables 　　#加入下面这行，注意把它添加到22端口后面，切记不要放在最后 　　　　-A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT 　　重启防火墙 　　　　/etc/rc.d/init.d/iptables restart 备份与恢复 　　备份 　　进入到库目录，cd /val/lib/mysql 　　　　mysqldump -u root -p --opt aaa > back_aaa 　　恢复 　　　　mysql -u root -p ccc < back_aaa 更改MySQL目录 　　MySQL默认的数据文件存储目录为/var/lib/mysql。假如要把目录移到/home/data下需要进行下面几步： 　　1、把MySQL服务进程停掉：  　　　　mysqladmin -u root -p shutdown 　　2、把/var/lib/mysql整个目录移到/home/data 　　　　mv /var/lib/mysql　/home/data/ 　　3、找到my.cnf配置文件 　　　如果/etc/目录下没有my.cnf配置文件，请到/usr/share/mysql/下找到*.cnf文件，拷贝其中一个到/etc/并改名为my.cnf)中。命令如下： 　　　　cp /usr/share/mysql/my-large.cnf /etc/my.cnf 　　4、编辑MySQL的配置文件/etc/my.cnf 　　　打开my.cnf以后，在[mysqld]下修改如下： 　　　　#socket　 = /var/lib/mysql/mysql.sock　（原内容，为了更稳妥用“#”注释此行） 　　　　  socket　 = /home/data/mysql/mysql.sock　（加上此行） 　　5、修改MySQL启动脚本/etc/rc.d/init.d/mysql，把其中datadir=改成你现在的实际存放路径：  　　　　#datadir=/var/lib/mysql　　　　（注释此行） 　　　　  datadir=/home/data/mysql　　 （加上此行） 　　6、重新启动MySQL服务 　　　　/etc/rc.d/init.d/mysql　start","title":"LINUX下MYSQL的配置"},{"content":"在linux操作系统安装oracle时，需要执行xhost+，执行xhost+报错：xhost: unable to open display。通过以下步骤解决~： 第一步：用root登陆linux，启动vnc服务 vncserver :1； 第二步：根据vnc起来的端口，设置export DISPLAY=localhost:1（1表示vnc在第一个tty上启动的）； 第三步：执行xhost +，并且提示“access control disabled, clients can connect from any host”才正确   linux系统下如果需要打开X-Server的,需要设置显示器位置. 简单的xhost+命令提示我们unable to open display \"\";这个标识DISPLAY环境变量没有设置. DISPLAY变量是用来设置将图形显示到何处.比如CENTOS,你用图形界面登录进去,DISPLAY自动设置为DISPLAY=:0.0表示显式到本地监视器. 那么通过终端工具(例如:putty)进去,运行图形界面的程序,如果没有设置,系统是不允许程序启动的. 如果你不想在其他地方显式图形,只是运行一些后台服务程序,那么你需要做一下操作: export DISPLAY=:0.0 来设置显式方式. 比如上面的xhost +,在设置好DISPLAY之后,就会输出: [root@localhost lib]# xhost + access control disabled, clients can connect from any host   另外:使用xdpyinfo这个命令可以查看显式系统的具体信息. 1.Linux dbca No protocol specified # /usr/bin/xhost + # su - oracle $ export LANG=en_US.UTF-8 $ dbca","title":"解决\"xhost:unable to open display\"的问题"},{"content":"WINDOWS 是以扩展名来决定文件执行方式的 LINUX 是通过权限和文件内容 比如，WINDOWS 下一个 .exe 文件，执行的时候会根据后缀 .exe 来加载文件头（也叫MZ头），然后处理分段执行 而一个 .com 文件，是一个纯二进制文件，直接读到内存中去运行 而 .bat 文件是批处理文件，类似 linux 里面的 shell 倘若把 .exe 改成 .com，或者把 .bat 改成 .exe，就会造成错误或者死机 Linux 却不同，它不管文件的后缀名，但只要有可执行权限，他就会去尝试执行这个程序 #! /bin/bash #! /usr/bin/perl #! /usr/local/php/bin/php 还有 ELF 头格式 不同的文件头决定了不同的执行方式，与后缀名无关 在 Windows 里，后缀名是一个注记符，也起着规定执行方式的重要使命 而在 Linux 里，后缀名仅仅是一个注记符而已   ps:linux中的需要后缀的文件格式 .tar.gz、.tar.bz2、.c等等  ","title":"linux windows 的后缀之别"},{"content":"话说linux的精髓在于命令行，初学的菜鸟是从命令开始linux的学习之旅。 1. 与windows对应 windows所有的操作都基于图形界面操作，比如创建文件夹或文件，点击右键选择新建；又比如在硬盘中搜索某一个文件，在搜索中输入关键字即可。linux则大大不同，当你搜索某个文件时，在终端中调用find命令。完成的功能相似，用两种不同的方式实现。习惯了windows系统中的操作，需要将windows的思路映射到linux的命令中。查看属性 = file； 新建文件 = couch；创建目录 = mkdir; 复制 = cp等等，都说linux强大无比，可从刚接触的前几天，被软件安装折磨的想骂街，又要记乱七八糟的命令，没有强大，只有崩溃。当使用find命令时，我隐约感受到了其强大之处。在windows中，只能搜索关键词，find命令中允许设定参数，大大提高了灵活性，通过参数我们可以按照时间搜索一天之前的文件。霸气侧漏。linux强大之处，还需我等菜鸟继续领悟。 2  Notes (1) 若用户meng的工作目录/home/meng中有一文本文件test.txt，对其进行调用时 /home/meng/test.txt，若现在的工作目录正是/home/meng，调用时直接test.txt (2) 若当前工作目录/home/meng中有一文件夹test 把/home/meng中的ps.txt转移到 test文件夹中, 原本写的命令行为 mv ps.txt /test 结果ps.txt被转移到了根目录，并改名为test。原因在于/test被解释为根目录下的test文本，并非当前目录下的test文件夹。改为 mv ps.txt ./test 结果正确。命令中确定是文件还是目录十分重要 (3)在windows中每个文件都有文件名后缀，当去掉后缀时文件不可用，在linux中非也，linux可以没有后缀，尤其是文本文档，如test.txt可以为test，因此特别注意省略后缀的文件与文件夹名字的区别  ","title":"linux 之命令"},{"content":"因为Linux主要的好处是开源、安全、稳定。对于程序员来说，了解系统的内部代码和运行结构是了解系统、编写出更高品质的程序的思路之一，而且现在Linux的开发和使用越来越普遍，特别是在服务器的应用（你所熟知的gogle、yahoo都是Linux平台的商业软件包），你可以想象一下Linux的应用。而Windows是非开源商业软件，你很难得到它的源码，而且也不能去修改它的内容（否则等着吃官司）。这给应用程序的开发提出了很多难题。另外，Linux并不是纯命令行软件。命令行是基础，然后在其之上运行图形界面平台，常用的有KDE GNOME和XFACE（轻量级）。 php---》apache---》linux php跟apache是完美搭档，apache服务器又跟linux完美搭档。php直接就可以调用linux系统命令，现在知道why了吗？","title":"php与linux究竟有什么渊源？"},{"content":"ubuntu 下安装go 1 安装C语言工具集(可选) sudo apt-get install bison ed gawk gcc libc6-dev make 2 安装SCM 源代码控制管理工具Mercurial(可选)    go源码使用Mercurial管理        2.1 安装mercurial依赖     sudo apt-get install python-setuptools python-dev build-essential        2.2 安装mercurial     sudo easy_install mercurial    3 获取go的源代码 itang@itang-laptop:~/sources$ hg clone -r release https://go.googlecode.com/hg/ go 4 安装go     4.1 编译安装     itang@itang-laptop:~/sources$ cd go/src     itang@itang-laptop:~/sources/go/src$ ./all.bash     ...     --- cd ../test     1 known bugs; 0 unexpected bugs     ---     Installed Go for linux/386 in /home/itang/sources/go.     Installed commands in /home/itang/sources/go/bin.     *** You need to add /home/itang/sources/go/bin to your $PATH. ***     The compiler is 8g.     4.2 配置环境变量     itang@itang-laptop:~/sources/go/src$ gedit ~/.profile     在文件最后加上一下两行:     export GO_HOME=/home/itang/sources/go   //改成自己的目录     export PATH=$GO_HOME/bin:$PATH     itang@itang-laptop:~/sources/go/src$ source ~/.profile 5 hello,world     5.1 coding     ~/sources/go/src$ cd ~/test     ~/test$ gedit hello.go     输入:     package main     import \"fmt\"     func main() {             fmt.Printf(\"hello, 世界\\n\")     }     5.2 编译/链接/运行    go run hello.go界 6 跟上go的最新发布    $ cd go/src    $ hg pull    $ hg update release    $ ./all.bash","title":"Ubuntu下Go语言环境安装"},{"content":"一、memcmp含义 Compare characters in two buffers. int memcmp(    const void* buf1,    const void* buf2,    size_t count );inline int wmemcmp (   const  wchar_t* buf1, const wchar_t* buf2, size_t count); Parameters        buf1    ：  First buffer.        buf2    ：  Second buffer.        count   ： Number of characters.        Return Values   ： The return value indicates the relationship between the buffers.        Return Value Relationship of First count Bytes of buf1 and buf2         < 0         buf1 less than buf2         0         buf1 identical to buf2 > 0 buf1 greater than buf2  二、memcmp与strncmp的区别 int   memcmp(const   void   *   cs,const   void   *   ct,size_t   count)     {     const   unsigned   char   *su1,   *su2;     int   res   =   0;         for(   su1   =   cs,   su2   =   ct;   0   <   count;   ++su1,   ++su2,   count--)     if   ((res   =   *su1   -   *su2)   !=   0)     break;     return   res;   　}         int   strncmp(const   char   *   cs,const   char   *   ct,size_t   count)     {     register   signed   char   __res   =   0;          while   (count)   {     if   ((__res   =   *cs   -   *ct++)   !=   0   ||   !*cs++)     break;     count--;     }         return   __res;     } 1、这两个函数的差别其实还是挺大的，差别在这里：        对于memcmp()，如果两个字符串相同而且count大于字符串长度的话，memcmp不会在\\0处停下来，会继续比较\\0后面的内存单元，直到_res不为零或者达到count次数。         对于strncmp()，由于((__res   =   *cs   -   *ct++)   !=   0   ||   !*cs++)的存在，比较必定会在最短的字符串的末尾停下来，即使count还未为零。具体的例子：         char   a1[]=\"ABCD\";     char   a2[]=\"ABCD\";          对于memcmp(a1,a2,10)，memcmp在两个字符串的\\0之后继续比较     对于strncmp(a1,a2,10），strncmp在两个字符串的末尾停下，不再继续比较。          所以，如果想使用memcmp比较字符串，要保证count不能超过最短字符串的长度，否则结果有可能是错误的。 2、strncmp(\"abcd\",   \"abcdef\",   6)   =   0。比较次数是一样的：       memcmp:在比较到第5个字符也就是'\\0'，*su1   -   *su2的结果显然不等于0，所以满足条件跳出循环，不会再进行后面的比较。我想在其他情况下也一样。       strncmp:同样的道理再比较到第5个字符时结束循环，其实strncmp中“!*cs++”完全等同于“!*ct++”，其作用仅在于当两个字符串相同的情形下，防止多余的比较次数。","title":"memcmp与strncmp的区别"},{"content":"#include <stdio.h>;#define BUFSIZ 256int main (){        char exec_name [BUFSIZ];        readlink (\"/proc/self/exe\", exec_name, BUFSIZ);        puts (exec_name);        return 0;} 下面是我自己封装的一个小小函数: #include <stdio.h>;#define BUFSIZE 256int main (){\tchar *tail=NULL;\tchar *exec_name;\tchar *edir_name;\texec_name=(char *)calloc(sizeof(char),BUFSIZE);\tedir_name=(char *)calloc(sizeof(char),BUFSIZE);\t\treadlink (\"/proc/self/exe\", exec_name, BUFSIZE);\ttail=strrchr(exec_name,'//');\tmemcpy(edir_name,exec_name,tail-exec_name);\t\tprintf(\"exec_name == [%s] \\n\",exec_name);\t// get full name.\tprintf(\"edir_name == [%s] \\n\",edir_name);\t// get dir.\tif(exec_name)\tfree(exec_name);\tif(edir_name)\tfree(edir_name);}  ","title":"在Linux程序中如何获得本进程的可执行文件的全路径？"},{"content":"我的U盘插上后， fdisk -l查看U盘信息得知是/dev/sdb 先将U盘制作分区表。 fdisk/dev/sdb   用p命令查看得知有一个fat32分区， 将他去掉，用d命令， 然后用n命令新增加一个主分区， n后选择p（primarypartition）， 然后Partition number (1-4): 1， 再用n命令新增加第二个主分区， 然后用a命令，把第一个和第二个主分区设置为可引导。 最后用w命令写入。   格式化分区为ext3， mkfs -t ext3/dev/sdb1 mkfs -text3 /dev/sdb2   然后挂载系统 mkdir/mnt/sdb1 mount -text3 /dev/sdb1 /mnt/sdb1 mkdir/mnt/sdb2 mount -text3 /dev/sdb2 /mnt/sdb2   然后将bt5光盘解开后，把casper和preseed文件夹拷贝到第一个分区的根目录下。 将linux deepin的整个光盘iso文件放入第二个分区的根目录下。   然后先安装grub到/mnt/sdb1 grub-install --root-directory=/mnt/sdb1 /dev/sdb   将/boot/grub/grub.conf拷贝到，u盘上对应的目录下 然后编辑grub.conf   timeout         20default         0title           Windows 7map             (hd0) (hd1)map             (hd1) (hd0)rootnoverify    (hd1,0)makeactivechainloader     +1title backtrack 5root (hd0,0)kernel/casper/vmlinuz root=/dev/sdb1 file=/preseed/custom.seed boot=casperlocale=zh_CN text--initrd/casper/initrd.gztitle linux deepinroot (hd0,1)kernel/boot/grub/core.imgsavedefaultboot 这个配置文件就是说明，U盘第一个分区用grub引导的bt5，U盘第二个分区由grub引导core.img 然后引导交给core.img，这个core.img是grub2的img。 此时第二个分区上还没有core.img，这个会在后面创建，我们先这样写。   然后将grub安装到MBR上， 输入grub命令 grub> root(hd1,0) Filesystem type is ext2fs, partition type 0x83 grub> setup (hd1) Checking if \"/boot/grub/stage1\"exists... yes Checking if \"/boot/grub/stage2\"exists... yes Checking if\"/boot/grub/e2fs_stage1_5\" exists... yes Running \"embed /boot/grub/e2fs_stage1_5(hd1)\"...  15 sectors are embedded.succeeded Running \"install /boot/grub/stage1 (hd1)(hd1)1+15 p (hd1,0)/boot/grub/stage2 /boot/grub/grub.conf\"... succeededDone.grub> quit 然后插着U盘重启系统，就应该可以顺利进入bt5系统了，bt5是基于ubuntu的，进入系统后， 将grub2写入第二个分区。 grub-install --root-directory=/mnt/sdb2 /dev/sdb 此时写入的是grub2。 然后编辑grub2的配置文件，grub.cfg，此文件内容如下： ## DO NOT EDIT THISFILE## It isautomatically generated by /usr/sbin/grub-mkconfig using templates# from /etc/grub.dand settings from /etc/default/grub#### BEGIN/etc/grub.d/00_header ###set timeout=10### END/etc/grub.d/00_header ### ### BEGIN/etc/grub.d/05_debian_theme ###setmenu_color_normal=white/blacksetmenu_color_highlight=black/light-gray### END/etc/grub.d/05_debian_theme ### ### BEGIN/etc/grub.d/10_linux ###menuentry\"linux deepin\" {loopbackloop (hd0,2)/deepin_12.06_zh-hans_i386.isolinux(loop)/casper/vmlinuz boot=casperiso-scan/filename=/deepin_12.06_zh-hans_i386.iso locale=zh_CN.UTF-8 nopromptnoejectinitrd(loop)/casper/initrd.lz} grub的配置文件里分区是(hd0,0)，而grub2的配置文件里分区是 (hd0,2)，因为grub里面分区从0开始，而grub2里面分区是从1开始的。 此时grub2的MBR会覆盖掉grub的MBR，所以我们需要重启系统，进入一个正常的linux系统， 然后再执行一遍安装grub到MBR的命令，将grub的MBR覆盖掉grub2的MBR。 grub> root(hd1,0) Filesystem type is ext2fs, partition type 0x83 grub> setup (hd1) Checking if \"/boot/grub/stage1\"exists... yes Checking if \"/boot/grub/stage2\"exists... yes Checking if\"/boot/grub/e2fs_stage1_5\" exists... yes Running \"embed /boot/grub/e2fs_stage1_5(hd1)\"...  15 sectors are embedded.succeeded Running \"install /boot/grub/stage1 (hd1)(hd1)1+15 p (hd1,0)/boot/grub/stage2 /boot/grub/grub.conf\"... succeededDone.grub> quit此时再重启，你就拥有了双linux系统的U盘。","title":"利用grub和grub2制作双系统的启动U盘"},{"content":"功能：为某一个文件或目录在另外一个位置建立一个同不的链接 软链接：ln –s 源文件 目标文件，它只会在你选定的位置上生成一个文件的镜像，不会占用磁盘空间。 硬链接：ln 源文件 目标文件，没有参数-s， 它会在你选定的位置上生成一个和源文件大小相同的文件。 注：无论软链接还是硬链接，文件都保持同步变化。    ","title":"ln 创建链接"},{"content":"手工创建oracle 数据库实例   1.确认oracle实例名,如orcl   2.创建相关的目录，在$ORACLE_BASE/oradata    主要有 $ORACLE_BASE/oradata/orcl/admin/adump     $ORACLE_BASE/oradata/orcl/admin/bdump     $ORACLE_BASE/oradata/orcl/admin/cdump     $ORACLE_BASE/oradata/orcl/admin/pfile     $ORACLE_BASE/oradata/orcl/admin/udump           创建闪存目录     $ORACLE_BASE/oradata/flash_recovery_area  mkdir -p $ORACLE_BASE/oradata/orcl/admin/adump   3.创建初始化文件   　在$ORACLE_HOME/dbs目录下     　命名方法   　init实例名.ora 本例中initorcl.ora     cp init.ora initorcl.ora 即可以生成  vi initorcl.ora 进行编辑  db_name='实例名' 本例中orcl，必须填写  给出各个文件位置    内容如下:  db_name='orcl'  #必须给出的名字  memory_target=1G  processes = 150  audit_file_dest='/opt/oracle/oradata/admin/orcl/adump' #必须给出的名字  audit_trail ='db'  db_block_size=8192  db_domain=''  db_recovery_file_dest='/opt/oracle/oradata/flash_recovery_area' #必须给出的名字  db_recovery_file_dest_size=2G  diagnostic_dest='/opt/oracle' #必须给出的名字  dispatchers='(PROTOCOL=TCP) (SERVICE=orcl)'  open_cursors=300  remote_login_passwordfile='EXCLUSIVE'  undo_tablespace='UNDOTBS1'  # You may want to ensure that control files are created on separate physical  # devices  control_files = (orcl_control1, orcl_control2)  compatible ='11.2.0'    4 设置ORACLE_SID变量  修改.bash_profile  export ORACLE_SID=orcl      5. 建立创建数据库脚本　createdb.sql  create database orcl ==数据SID名称  MAXINSTANCES 1  MAXLOGHISTORY 1  MAXLOGFILES 5  MAXLOGMEMBERS 5  MAXDATAFILES 100  DATAFILE    '/opt/oracle/oradata/orcl/system01.dbf' size 100m reuse autoextend on next 1m maxsize unlimited  sysaux datafile  '/opt/oracle/oradata/orcl/syaux01.dbf' size 100m reuse autoextend on next 1m maxsize unlimited  default temporary tablespace TEMP tempfile  '/opt/oracle/oradata/orcl/temp01.dbf' size 20m reuse autoextend on next 64k maxsize unlimited  undo tablespace UNDOTBS1 datafile  '/opt/oracle/oradata/orcl/undo01.dbf' size 20m reuse autoextend on next 5m maxsize unlimited  logfile  GROUP 1 ('/opt/oracle/oradata/orcl/redo01.dbf') size 10m,  GROUP 2 ('/opt/oracle/oradata/orcl/redo02.dbf') size 10m,  GROUP 3 ('/opt/oracle/oradata/orcl/redo03.dbf') size 10m  CHARACTER SET ZHS16GBK ==字符集  NATIONAL CHARACTER SET AL16UTF16    6 .sqlplus \"/as sysdba\"     startup nomount;       执行创建createdb.sql  @?$ORACLE_BASE/oradata/createdb.sql    7.创建数据字典  @?/rdbms/admin/catalog.sql;  @?/rdbms/admin/catproc.sql;  切换用户system/manager  执行 本人没有执行此脚本,  @?/sqlplus/admin/pupbld.sql;    8.安装全文检索      用sys以sysdba身份登录   创建全文检索表空间   create tablespace ctxsys logging datafile='/opt/oracle/oradata/orcl/ctxsys01.dbf' size 200m autoextend on maxsize unlimited;   执行脚本   @?/ctx/admin/catctx.sql ctxsys ctxsys temp nolock;  --参数说明 密码,表空间 临时表空间 用户状态   connect ctxsys/ctxsys;   @?/ctx/admin/defaults/drdefus.sql       9.配置监听      $ORACLE_HOME/network/admin   vi listener.ora   SID_LIST_orcl=   (SID_DESC=   (SID_NAME=orcl)   (ORACLE_HOME=/opt/oracle/product/11.2.0/db_1)       )    )  orcl=   (DESCRIPTIONI_LIST=   (DESCRIPTION=   (ADDRESS=(PROTOCOL=TCP)   (HOST=192.168.56.100)(PORT=1521)   )   )    10 配置tnsnames.ora         orcl=   (   DESCRIPTION=   (ADDRESS_LIST=   (ADDRESS=(PROTOCOL=TCP)(HOST=192.168.56.100)(PORT=1521)))   (CONNECT_DATA=(SERVICE_NAME=orcl)   )   )  11 手工启停   启动监听:lsnrctl start   停止监听:lsnrctl stop      启动数据库      sqlplus \"/as sysdba\"      startup            关闭数据库      sqlplus \"/as sysdba\"      shutdown","title":"在Linux 上手工创建 oracle 11g R2 数据库"},{"content":"介绍一下Linux的由来和各种发行版本： Linux最早由Linus Benedict Torvalds在1991年开始编写。在这之前，Richard Stallman创建了Free Software Foundation（FSF）组织以及GNU项目，并不断的编写创建GNU程序（此类程序的许可方式均为GPL: General Public License）。在不断的有杰出的程序员和开发者加入到GNU组织中后，便造就了今天我们所看到的Linux，或称GNU/Linux。 Linux的发行版本可以大体分为两类，一类是商业公司维护的发行版本，一类是社区组织维护的发行版本，前者以著名的Redhat（RHEL）为代表，后者以Debian为代表。下面介绍一下各个发行版本的特点： Redhat，应该称为Redhat系列，包括RHEL(Redhat Enterprise Linux，也就是所谓的Redhat Advance Server，收费版本)、Fedora Core(由原来的Redhat桌面版本发展而来，免费版本)、CentOS(RHEL 的社区克隆版本，免费)。Redhat应该说是在国内使用人群最多的Linux版本，甚至有人将Redhat等同于Linux，而有些老鸟更是只用这一个版本的Linux。所以这个版本的特点就是使用人群数量大，资料非常多，言下之意就是如果你有什么不明白的地方，很容易找到人来问，而且网上的一般 Linux教程都是以Redhat为例来讲解的。Redhat系列的包管理方式采用的是基于RPM包的YUM包管理方式，包分发方式是编译好的二进制文件。稳定性方面RHEL和CentOS的稳定性非常好，适合于服务器使用，但是Fedora Core的稳定性较差，最好只用于桌面应用。 Debian，或者称Debian 系列，包括Debian和Ubuntu等。Debian是社区类Linux的典范，是迄今为止最遵循GNU规范的Linux系统。Debian最早由 Ian Murdock于1993年创建，分为三个版本分支（branch）： stable, testing 和 unstable。其中，unstable为最新的测试版本，其中包括最新的软件包，但是也有相对较多的bug，适合桌面用户。testing的版本都经过unstable中的测试，相对较为稳定，也支持了不少新技术（比如SMP等）。而stable一般只用于服务器，上面的软件包大部分都比较过时，但是稳定和安全性都非常的高。Debian最具特色的是apt-get / dpkg包管理方式，其实Redhat的YUM也是在模仿Debian的APT方式，但在二进制文件发行方式中，APT应该是最好的了。Debian的资料也很丰富，有很多支持的社区，有问题求教也有地方可去:) Ubuntu严格来说不能算一个独立的发行版本，Ubuntu是基于 Debian的unstable版本加强而来，可以这么说，Ubuntu就是一个拥有Debian所有的优点，以及自己所加强的优点的近乎完美的 Linux桌面系统。根据选择的桌面系统不同，有三个版本可供选择，基于Gnome的Ubuntu，基于KDE的Kubuntu以及基于Xfc的 Xubuntu。特点是界面非常友好，容易上手，对硬件的支持非常全面，是最适合做桌面系统的Linux发行版本。 Gentoo，伟大的Gentoo 是Linux世界最年轻的发行版本，正因为年轻，所以能吸取在她之前的所有发行版本的优点，这也是Gentoo被称为最完美的Linux发行版本的原因之一。Gentoo最初由Daniel Robbins（FreeBSD的开发者之一）创建，首个稳定版本发布于2002年。由于开发者对FreeBSD的熟识，所以Gentoo拥有媲美 FreeBSD的广受美誉的ports系统 ——Portage包管理系统。不同于APT和YUM等二进制文件分发的包管理系统，Portage是基于源代码分发的，必须编译后才能运行，对于大型软件而言比较慢，不过正因为所有软件都是在本地机器编译的，在经过各种定制的编译参数优化后，能将机器的硬件性能发挥到极致。Gentoo是所有Linux 发行版本里安装最复杂的，但是又是安装完成后最便于管理的版本，也是在相同硬件环境下运行最快的版本。 最后，介绍一下FreeBSD，需要强调的是：FreeBSD并不是一个Linux系统！但FreeBSD与Linux的用户群有相当一部分是重合的，二者支持的硬件环境也比较一致，所采用的软件也比较类似，所以可以将 FreeBSD视为一个Linux版本来比较。FreeBSD拥有两个分支：stable和current。顾名思义， stable是稳定版，而 current则是添加了新技术的测试版。FreeBSD采用Ports包管理系统，与Gentoo类似，基于源代码分发，必须在本地机器编后后才能运行，但是Ports系统没有Portage系统使用简便，使用起来稍微复杂一些。FreeBSD的最大特点就是稳定和高效，是作为服务器操作系统的最佳选择，但对硬件的支持没有Linux完备，所以并不适合作为桌面系统。 下面给为选择一个Linux发行版本犯愁的朋友一些建议： 如果你只是需要一个桌面系统，而且既不想使用盗版，又不想花大量的钱购买商业软件，那么你就需要一款适合桌面使用的Linux发行版本了，如果你不想自己定制任何东西，不想在系统上浪费太多时间，那么很简单，你就根据自己的爱好在ubuntu、kubuntu以及xubuntu中选一款吧，三者的区别仅仅是桌面程序的不一样。 如果你需要一个桌面系统，而且还想非常灵活的定制自己的Linux系统，想让自己的机器跑得更欢，不介意在Linux系统安装方面浪费一点时间，那么你的唯一选择就是Gentoo，尽情享受Gentoo带来的自由快感吧！ 如果你需要的是一个服务器系统，而且你已经非常厌烦各种Linux的配置，只是想要一个比较稳定的服务器系统而已，那么你最好的选择就是CentOS了，安装完成后，经过简单的配置就能提供非常稳定的服务了。 如果你需要的是一个坚如磐石的非常稳定的服务器系统，那么你的唯一选择就是FreeBSD。 如果你需要一个稳定的服务器系统，而且想深入摸索一下Linux的各个方面的知识，想自己定制许多内容，那么我推荐你使用Gentoo。","title":"介绍一下Linux的由来和各种发行版本"},{"content":"可是Linux压缩文件有.gz、.tar.gz、tgz、bz2、.Z、.tar等众多的压缩文件名，此外windows下的.zip和.rar也可以在Linux下使用，不过在Linux使用.zip和.rar的人就太少了。本文就来对这些常见的压缩文件进行一番小结； 　　在具体总结各类压缩文件之前呢，首先要弄清两个概念：打包和压缩。打包是指将一大堆文件或目录什么的变成一个总的文件，压缩则是将一个大的文件通过一些压缩算法变成一个小文件。为什么要区分这两个概念呢？其实这源于Linux中的很多压缩程序只能针对一个文件进行压缩，这样当你想要压缩一大堆文件时，你就得先借助另它的工具将这一大堆文件先打成一个包，然后再就原来的压缩程序进行压缩。 　　Linux下最常用的打包程序就是tar了，使用tar程序打出来的包我们常称为tar包，tar包文件的命令通常都是以.tar结尾的。生成tar包后，就可以用其它的程序来进行压缩了，所以首先就来讲讲tar命令的基本用法： 　　tar命令的选项有很多(用man tar可以查看到)，但常用的就那么几个选项，下面来举例说明一下： 　　# tar -cf all.tar *.jpg 　　这条命令是将所有.jpg的文件打成一个名为all.tar的包。-c是表示产生新的包，-f指定包的文件名。 　　# tar -rf all.tar *.gif 　　这条命令是将所有.gif的文件增加到all.tar的包里面去。-r是表示增加文件的意思。 # tar -uf all.tar logo.gif 　　这条命令是更新原来tar包all.tar中logo.gif文件，-u是表示更新文件的意思。 　　# tar -tf all.tar 　　这条命令是列出all.tar包中所有文件，-t是列出文件的意思 　　# tar -xf all.tar 　　这条命令是解出all.tar包中所有文件，-x是解开的意思 　　以上就是tar的最基本的用法。为了方便用户在打包解包的同时可以压缩或解压文件，tar提供了一种特殊的功能。这就是tar可以在打包或解包的同时调用其它的压缩程序，比如调用gzip、bzip2等。 　　1) tar调用gzip 　　gzip是GNU组织开发的一个压缩程序，.gz结尾的文件就是gzip压缩的结果。与gzip相对的解压程序是gunzip。tar中使用-z这个参数来调用gzip。下面来举例说明一下： 　　# tar -czf all.tar.gz *.jpg 　　这条命令是将所有.jpg的文件打成一个tar包，并且将其用gzip压缩，生成一个gzip压缩过的包，包名为all.tar.gz 　　# tar -xzf all.tar.gz 　　这条命令是将上面产生的包解开。 　　2) tar调用bzip2 　　bzip2是一个压缩能力更强的压缩程序，.bz2结尾的文件就是bzip2压缩的结果。与bzip2相对的解压程序是bunzip2。tar中使用-j这个参数来调用gzip。下面来举例说明一下： 　　# tar -cjf all.tar.bz2 *.jpg 　　这条命令是将所有.jpg的文件打成一个tar包，并且将其用bzip2压缩，生成一个bzip2压缩过的包，包名为all.tar.bz2 　　# tar -xjf all.tar.bz2 　　这条命令是将上面产生的包解开。         3)tar调用compress 　　compress也是一个压缩程序，但是好象使用compress的人不如gzip和bzip2的人多。.Z结尾的文件就是bzip2压缩的结果。与 compress相对的解压程序是uncompress。tar中使用-Z这个参数来调用compress。下面来举例说明一下： 　　# tar -cZf all.tar.Z *.jpg 　　这条命令是将所有.jpg的文件打成一个tar包，并且将其用compress压缩，生成一个uncompress压缩过的包，包名为all.tar.Z 　　# tar -xZf all.tar.Z 　　这条命令是将上面产生的包解开 　　有了上面的知识，你应该可以解开多种压缩文件了，下面对于tar系列的压缩文件作一个小结： 　　1)对于.tar结尾的文件 　　tar -xf all.tar 　　2)对于.gz结尾的文件 　　gzip -d all.gz 　　gunzip all.gz 　　3)对于.tgz或.tar.gz结尾的文件 　　tar -xzf all.tar.gz 　　tar -xzf all.tgz 　　4)对于.bz2结尾的文件 　　bzip2 -d all.bz2 　　bunzip2 all.bz2 　　5)对于tar.bz2结尾的文件 　　tar -xjf all.tar.bz2 　　6)对于.Z结尾的文件 　　uncompress all.Z 　　7)对于.tar.Z结尾的文件 　　tar -xZf all.tar.z 　　另外对于Window下的常见压缩文件.zip和.rar，Linux也有相应的方法来解压它们： 　　1)对于.zip 　　linux下提供了zip和unzip程序，zip是压缩程序，unzip是解压程序。它们的参数选项很多，这里只做简单介绍，依旧举例说明一下其用法： 　　# zip all.zip *.jpg 　　这条命令是将所有.jpg的文件压缩成一个zip包     # unzip all.zip 　　这条命令是将all.zip中的所有文件解压出来 　　2)对于.rar 　　要在linux下处理.rar文件，需要安装RAR for Linux，可以从网上下载，但要记住，RAR for Linux不是免费的；可从http://www.rarsoft.com/download.htm下载RARfor Linux 3.2.0，然后安装： 　　# tar -xzpvf rarlinux-3.2.0.tar.gz 　　# cd rar 　　# make 　　这样就安装好了，安装后就有了rar和unrar这两个程序，rar是压缩程序，unrar是解压程序。它们的参数选项很多，这里只做简单介绍，依旧举例说明一下其用法： 　　# rar a all *.jpg 　　这条命令是将所有.jpg的文件压缩成一个rar包，名为all.rar，该程序会将.rar扩展名将自动附加到包名后。 　　# unrar e all.rar 　　这条命令是将all.rar中的所有文件解压出来 　　到此为至，我们已经介绍过linux下的tar、gzip、gunzip、bzip2、bunzip2、compress、 uncompress、 zip、unzip、rar、unrar等程式，你应该已经能够使用它们对.tar、.gz、.tar.gz、.tgz、.bz2、.tar.bz2、. Z、.tar.Z、.zip、.rar这10种压缩文件进行解压了，以后应该不需要为下载了一个软件而不知道如何在Linux下解开而烦恼了。而且以上方法对于Unix也基本有效。 　　本文介绍了linux下的压缩程式tar、gzip、gunzip、bzip2、bunzip2、compress、uncompress、 zip、 unzip、rar、unrar等程式，以及如何使用它们对.tar、.gz、.tar.gz、.tgz、.bz2、.tar.bz2、.Z、. tar.Z、.zip、.rar这10种压缩文件进行操作。   参考地址：http://hi.baidu.com/sillyboy/item/a519b6864f60ad2a100ef38b","title":"linux下tar gz bz2 tgz z等众多压缩文件的解压方法"},{"content":"system()函数功能强大，很多人用却对它的原理知之甚少，我想大家如果知道了system的具体实现就不会对楼主程序在很多编译器中不能表现自己希望的功能感到费解了。我对linux中的实现比较了解，具体分析这个，windows中的类似就不详解了。 好了，先看linux版system函数的源码： #include #include #include #include int system(const char * cmdstring){    pid_t pid;    int status;    if(cmdstring == NULL){                   return (1);    }    if((pid = fork())<0){            status = -1;    }    else if(pid == 0){        execl(\"/bin/sh\", \"sh\", \"-c\", cmdstring, (char *)0);        -exit(127); //子进程正常执行则不会执行此语句        }    else{            while(waitpid(pid, &status, 0) < 0){                if(errno != EINTER){                    status = -1;                    break;                }            }        }        return status;}  先分析一下原理，然后再看上面的代码大家估计就能看懂了：    当system接受的命令为NULL时直接返回，否则fork出一个子进程，因为fork在两个进程：父进程和子进程中都返回，这里要检查返回的pid，fork在子进程中返回0，在父进程中返回子进程的pid，父进程使用waitpid等待子进程结束，子进程则是调用execl来启动一个程序代替自己，execl(\"/bin/sh\", \"sh\", \"-c\", cmdstring,(char*)0)是调用shell，这个shell的路径是/bin/sh，后面的字符串都是参数，然后子进程就变成了一个shell进程，这个shell的参数是cmdstring，就是system接受的参数。在windows中的shell是command，想必大家很熟悉shell接受命令之后做的事了。     如果上面的你没有看懂，那我再解释下fork的原理：当一个进程A调用fork时，系统内核创建一个新的进程B，并将A的内存映像复制到B的进程空间中，因为A和B是一样的，那么他们怎么知道自己是父进程还是子进程呢，看fork的返回值就知道，上面也说了fork在子进程中返回0，在父进程中返回子进程的pid。 windows中的情况也类似，就是execl换了个又臭又长的名字，参数名也换的看了让人发晕的，我在MSDN中找到了原型，给大家看看： HINSTANCE   ShellExecute(                HWND   hwnd,                LPCTSTR   lpVerb,                LPCTSTR   lpFile,                LPCTSTR   lpParameters,                LPCTSTR   lpDirectory,                INT   nShowCmd    );    用法如下：       ShellExecute(NULL,   \"open\",   \"c:\\\\a.reg\",   NULL,   NULL,   SW_SHOWNORMAL);    你也许会奇怪 ShellExecute中有个用来传递父进程环境变量的参数 lpDirectory，linux中的execl却没有，这是因为execl是编译器的函数（在一定程度上隐藏具体系统实现），在linux中它会接着产生一个linux系统的调用execve, 原型见下：     int execve(const char * file,const char **argv,const char **envp);     看到这里你就会明白为什么system（）会接受父进程的环境变量，但是用system改变环境变量后，system一返回主函数还是没变，这就是我在22楼反复强调的。原因从system的实现可以看到，它是通过产生新进程实现的，从我的分析中可以看到父进程和子进程间没有进程通信，子进程自然改变不了父进程的环境变量。希望小菜们不要拿tc或使用tc库的其他编译器中的system的调用结果来反驳我，这不是一个概念，DOS早死翘翘了，玩linux吧。就说到这里了。","title":"Linux中的system函数详细分析"},{"content":"一、last 命令 last    显示系统开机以来获是从每月初登入者的讯息     -R  省略 hostname 的栏位     -num 展示前 num 个  如：last -3  展示前三行     username 展示 username 的登入讯息     tty 限制登入讯息包含终端机代号 范例： [root@elain ]# last -R -2 root     pts/0        Fri Oct 22 14:23   still logged in    root     pts/0        Fri Oct 22 12:10 - 14:23  (02:13)     wtmp begins Sat Sep  4 00:38:05 2010   [root@elain ]# last -2 root root     pts/0        192.168.8.87     Fri Oct 22 14:23   still logged in    root     pts/0        192.168.8.87     Fri Oct 22 12:10 - 14:23  (02:13)     wtmp begins Sat Sep  4 00:38:05 2010 二、top 命令  top    是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。   top - 14:34:14 up 4 days, 16:20,  2 users,  load average: 0.56, 0.23, 0.32 Tasks:  75 total,   1 running,  74 sleeping,   0 stopped,   0 zombie Cpu(s):  0.0%us,  0.0%sy,  0.0%ni, 99.8%id,  0.2%wa,  0.0%hi,  0.0%si,  0.0%st Mem:   1026824k total,   917580k used,   109244k free,   124708k buffers Swap:  2096472k total,        0k used,  2096472k free,   664320k cached   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                 3078 root      15   0 12720 1032  800 R  0.7  0.1   0:00.02 top                     2463 root      16   0 10232  676  584 S  0.3  0.1   1:33.69 hald-addon-stor            1 root      15   0 10352  692  584 S  0.0  0.1   0:00.61 init                       2 root      RT  -5     0    0    0 S  0.0  0.0   0:00.35 migration/0                3 root      34  19     0    0    0 S  0.0  0.0   0:00.00 ksoftirqd/0                统计信息区前五行是系统整体的统计信息。 第一行是任务队列信息，同 uptime 命令的执行结果。其内容如下： 14:34:14      当前时间 up 4 days      系统已运行时间 2 users              当前登录用户数 0.56, 0.23, 0.32  系统负载，即任务队列的平均长度。三个数值分别为1分钟、5分钟、15分钟前到现在的平均值。 第二行为进程信息，内容如下： Tasks:  75 total    进程总数 1 running            正在运行的进程数 74 sleeping            睡眠的进程数 0 stopped            停止的进程数 0 zombie            僵尸进程数 第三行为CPU信息，当有多个CPU时，这些内容可能会超过两行。内容如下： Cpu(s):  0.0%us            用户空间占用CPU百分比 0.0% sy                    内核空间占用CPU百分比 0.0% ni                    用户进程空间内改变过优先级的进程占用CPU百分比 98.8% id            空闲CPU百分比 0.2% wa                    等待输入输出(IO)的CPU时间百分比 0.0% hi                    cpu处理硬件中断的时间； 0.0% si                 cpu处理软中断的时间； 第四行为内存信息，内容如下： Mem: 1026824k total      物理内存总量 917580k used              使用的物理内存总量 109244k free               空闲内存总量 124708k buffers            用作内核缓存的内存量 第五行为SWAP信息 Swap: 2096472k total    交换区总量 2096472k free              空闲交换区总量 664320k cached            缓冲的交换区总量。 第六行往后是进程列表，常见的这几列的意义分别为： PID(进程号)， USER（运行用户），PR（优先级），NI（任务nice值），VIRT（虚拟内存用量），RES（物理内存用量）， SHR（共享内存用量），S（进程状态），%CPU（CPU占用比），%MEM（内存占用比），TIME+（累计CPU占用时间)。 除了这些信息之外，top还提供了很多命令能帮我们更好的解读这些信息，例如按”M”键可以按内存用量进行排序; 按”P”可以按CPU使用量进行排序，这样一来对于分析系统瓶颈很有帮助；此外，按“f”可以进入交互页面，选择指定的列显示， 例如可以按“b”选择显示PPID，再按一次“b”即可取消显示。”r”可以改变一个进程的nice值；”k”可以向一个进程发信号； ”z”可以使用彩色显示。进程信息区统计信息区域的下方显示了各个进程的详细信息。首先来认识一下各列的含义。 序号    列名    含义 a    PID    进程id b    PPID    父进程id c    RUSER    Real user name d    UID    进程所有者的用户id e    USER    进程所有者的用户名 f    GROUP    进程所有者的组名 g    TTY    启动进程的终端名。不是从终端启动的进程则显示为 ? h    PR    优先级 i    NI    nice值。负值表示高优先级，正值表示低优先级 j    P    最后使用的CPU，仅在多CPU环境下有意义 k    %CPU    上次更新到现在的CPU时间占用百分比 l    TIME    进程使用的CPU时间总计，单位秒 m    TIME+    进程使用的CPU时间总计，单位1/100秒 n    %MEM    进程使用的物理内存百分比 o    VIRT    进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES p    SWAP    进程使用的虚拟内存中，被换出的大小，单位kb。 q    RES    进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA r    CODE    可执行代码占用的物理内存大小，单位kb s    DATA    可执行代码以外的部分(数据段+栈)占用的物理内存大小，单位kb t    SHR    共享内存大小，单位kb u    nFLT    页面错误次数 v    nDRT    最后一次写入到现在，被修改过的页面数。 w    S    进程状态。 x    COMMAND    命令名/命令行 y    WCHAN    若该进程在睡眠，则显示睡眠中的系统函数名 z    Flags    任务标志，参考 sched.h             D=不可中断的睡眠状态             R=运行             S=睡眠             T=跟踪/停止             Z=僵尸进程   默认情况下仅显示比较重要的  PID、USER、PR、NI、VIRT、RES、SHR、S、%CPU、%MEM、TIME+、COMMAND  列。可以通过下面的快捷键来更改显示内容。 更改显示内容通过 f 键可以选择显示的内容。按 f 键之后会显示列的列表，按 a-z  即可显示或隐藏对应的列，最后按回车键确定。 按 o 键可以改变列的显示顺序。按小写的 a-z 可以将相应的列向右移动，而大写的 A-Z  可以将相应的列向左移动。最后按回车键确定。 按大写的 F 或 O 键，然后按 a-z 可以将进程按照相应的列进行排序。而大写的  R 键可以将当前的排序倒转。 三、free 命令  free  [root@elain ]# free              total       used       free     shared    buffers     cached Mem:       1026824     917764     109060          0     124908     664328 -/+ buffers/cache:     128528     898296 Swap:      2096472          0    2096472   第1行 total 内存总数: 1026824 used 已经使用的内存数: 917764 free 空闲的内存数: 109060 shared 当前已经废弃不用，总是0 buffers Buffer Cache内存数: 124908 cached Page Cache内存数:  664328 第2行： -/+ buffers/cache的意思相当于： -buffers/cache 的内存数：1128528 (等于第1行的 used - buffers - cached) +buffers/cache 的内存数: 2752124 (等于第1行的 free + buffers + cached) 第3行： total 交换分区总数: 2096472 used 已经使用的: 0 free 空闲的数: 2096472 free -m    大小以M来显示 四、dstat 命令 yum install -y dstat  dstat      -c     显示CPU情况 -d     显示磁盘情况 -g     显示通信情况      -m     显示内存情况      -n     显示网络情况       -p     显示进程情况      -s     显示swap情况      -t     显示系统时钟      -y     显示系统统计      -f     使用 -C, -D, -I, -N and -S 显示      -v     使用-pmgdsc -D 显示 --ipc   报告IPC消息队列和信号量的使用情况     --lock  enable lock stats     --raw   enable raw stats      --tcp  enable tcp stats     --udp   enable udp stats    --unix   enable unix stats    --mods   stat1,stat2  --integer  show integer values Bbs.Svn8.Com  --nocolor  disable colors (implies --noupdate) Bbs.Svn8.Com --noheaders 只显示一次表头以后就不显示了,使用重定向写入文件时很有用 Bbs.Svn8.Com --noupdate  disable intermediate updates Svn中文网 --output file 写入到CVS文件中  推荐使用 date && dstat -tclmdny 60 一分钟监视一次（注意调节显示的宽度，或去掉-t选项）。 五、iostat 命令  cat /proc/partitions   [root@elain ]# cat /proc/partitions  major minor  #blocks  name 8     0      20971520 sda 8     1        200781 sda1 8     2       8193150 sda2 8     3       2096482 sda3 8     4             1 sda4 8     5      10474348 sda5 major: 主设备号。8 代表 sda。 minor: 次设备号。5 代表 No.5 分区。   blocks: 设备总块数   name: 设备名称。如 sda3。   [root@elain ]# iostat -x Linux 2.6.18-194.11.3.el5 (elain)      2010年10月22日 avg-cpu:  %user   %nice %system %iowait  %steal   %idle            0.17    0.10    0.12    0.05    0.00   99.55 Device:         rrqm/s   wrqm/s   r/s   w/s   rsec/s   wsec/s avgrq-sz avgqu-sz   await  svctm  %util sda               0.17     1.14  0.07  0.35     3.38    11.80    35.72     0.03   59.56   3.64   0.15 sda1              0.00     0.00  0.00  0.00     0.00     0.00    18.96     0.00    8.47   6.65   0.00 sda2              0.05     1.11  0.06  0.35     3.19    11.68    36.24     0.02   60.31   3.64   0.15 sda3              0.00     0.00  0.00  0.00     0.00     0.00    31.65     0.00    8.21   6.47   0.00 sda4              0.00     0.00  0.00  0.00     0.00     0.00     2.00     0.00    6.00   6.00   0.00 sda5              0.11     0.04  0.01  0.01     0.18     0.12    21.11     0.00   39.66   4.71   0.01     rrqm/s: 每秒进行 merge 的读操作数目。即 delta(rmerge)/s wrqm/s: 每秒进行 merge 的写操作数目。即 delta(wmerge)/s r/s: 每秒完成的读 I/O 设备次数。即 delta(rio)/s w/s: 每秒完成的写 I/O 设备次数。即 delta(wio)/s rsec/s: 每秒读扇区数。即 delta(rsect)/s wsec/s: 每秒写扇区数。即 delta(wsect)/s avgrq-sz: 平均每次设备I/O操作的数据大小 (扇区)。即 delta(rsect+wsect)/delta(rio+wio) avgqu-sz: 平均I/O队列长度。即 delta(aveq)/s/1000 (因为aveq的单位为毫秒)。 await: 平均每次设备I/O操作的等待时间 (毫秒)。即 delta(ruse+wuse)/delta(rio+wio) svctm: 平均每次设备I/O操作的服务时间 (毫秒)。即 delta(use)/delta(rio+wio) ％util: 一秒中有百分之多少的时间用于 I/O 操作，或者说一秒中有多少时间 I/O 队列是非空的。 即 delta(use)/s/1000 (因为use的单位为毫秒)   如果 ％util 接近 100％，说明产生的I/O请求太多，I/O系统已经满负荷，该磁盘可能存在瓶颈。   svctm 一般要小于 await (因为同时等待的请求的等待时间被重复计算了)， svctm 的大小一般和磁盘性能有关，CPU/内存的负荷也会对其有影响，请求过多 也会间接导致 svctm 的增加。await 的大小一般取决于服务时间(svctm) 以及 I/O 队列的长度和 I/O 请求的发出模式。如果 svctm 比较接近 await，说明 I/O 几乎没有等待时间；如果 await 远大于 svctm，说明 I/O 队列太长，应用 得到的响应时间变慢，如果响应时间超过了用户可以容许的范围，这时可以考虑 更换更快的磁盘，调整内核 elevator 算法，优化应用，或者升级 CPU。   队列长度(avgqu-sz)也可作为衡量系统 I/O 负荷的指标，但由于 avgqu-sz 是 按照单位时间的平均值，所以不能反映瞬间的 I/O 洪水。 六、vmstat 命令  vmstat 命令报告虚拟内存统计信息和CPU负荷：页面调度，交换，任务交换，CPU利用率。命令的语法是： vmstat       -swap    现时可用的交换内存（k表示）       -free    空闲的内存（k表示）       -disk    显示每秒的磁盘操作。 s表示scsi盘，0表示盘号 [root@elain ]# vmstat 1 3 [一秒刷新一次 总共3次] procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------  r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st  0  0      0 109036 123156 664444    0    0     1     3   37   12  0  0 100  0  0  0  0      0 109036 123156 664444    0    0     0     0 1022   28  0  0 100  0  0  0  0      0 109036 123156 664444    0    0     0     0 1003   17  0  0 100  0  0   如果 r经常大于 4 ，且id经常少于40[空闲CPU]，表示cpu的负荷很重。   目前说来，对于服务器监控有用处的度量主要有： r（运行队列） us（用户CPU） sy（系统CPU） id（空闲）    通过VMSTAT识别CPU瓶颈 r（运行队列）展示了正在执行和等待CPU资源的任务个数。当这个值超过了CPU数目，就会出现CPU瓶颈了。 获得CPU个数的命令(LINUX环境)： cat /proc/cpuinfo|grep processor|wc -l 当r值超过了CPU个数，就会出现CPU瓶颈，解决办法大体几种： 1. 最简单的就是增加CPU个数 2. 通过调整任务执行时间，如大任务放到系统不繁忙的情况下进行执行，进尔平衡系统任务 3. 调整已有任务的优先级     通过VMSTAT识别CPU满负荷 首先需要声明一点的是，vmstat中CPU的度量是百分比的。当us＋sy的值接近100的时候，表示CPU正在接近满负荷工作。 但要注意的是，CPU 满负荷工作并不能说明什么，UNIX总是试图要CPU尽可能的繁忙，使得任务的吞吐量最大化。唯一能够确定CPU瓶颈的还是r（运行队列）的值。  通过VMSTAT识别RAM瓶颈   数据库服务器都只有有限的RAM，出现内存争用现象是Oracle的常见问题。 首先察看RAM的数量，命令如下（LINUX环境）： [root@elain ]# free              total       used       free     shared    buffers     cached Mem:       1026824     918284     108540          0     123180     664448 -/+ buffers/cache:     130656     896168 Swap:      2096472          0    2096472    当然可以使用top等其他命令来显示RAM。 当内存的需求大于RAM的数量，服务器启动了虚拟内存机制，通过虚拟内存，可以将RAM段移到SWAP DISK的特殊磁盘段上， 这样会出现虚拟内存的页导出和页导入现象，页导出并不能说明RAM瓶颈，虚拟内存系统经常会对内存段进行页导出， 但页导入操作就表明了服务器需要更多的内存了，页导入需要从SWAP DISK上将内存段复制回RAM，导致服务器速度变慢。  解决的办法有几种： 1. 最简单的，加大RAM 2. 改小SGA，使得对RAM需求减少 3. 减少RAM的需求（如：减少PGA）   vmstat各项： procs: r-->在运行队列中等待的进程数 b-->在等待io的进程数 w-->可以进入运行队列但被替换的进程 memoy swap-->现时可用的交换内存（k表示） free-->空闲的内存（k表示） pages re－－》回收的页面 mf－－》非严重错误的页面 pi－－》进入页面数（k表示） po－－》出页面数（k表示） fr－－》空余的页面数（k表示） de－－》提前读入的页面中的未命中数 sr－－》通过时钟算法扫描的页面 disk 显示每秒的磁盘操作。 s表示scsi盘，0表示盘号 fault 显示每秒的中断数 in－－》设备中断 sy－－》系统中断 cy－－》cpu交换 cpu 表示cpu的使用状态 cs－－》用户进程使用的时间 sy－－》系统进程使用的时间 id－－》cpu空闲的时间 如果 r经常大于 4 ，且id经常少于40，表示cpu的负荷很重。 如果pi，po 长期不等于0，表示内存不足。 如果disk 经常不等于0， 且在 b中的队列 大于3， 表示 io性能不好。 七、mpstat 命令 mpstat是MultiProcessor Statistics的缩写，是实时系统监控工具。其报告与CPU的一些统计信息，这些信息存放在/proc/stat文件中。  在多CPUs系统里，其不但能查看所有CPU的平均状况信息，而且能够查看特定CPU的信息。mpstat的语法如下： [root@elain ]# mpstat Linux 2.6.18-194.11.3.el5 (elain)      2010年10月22日 16时13分59秒  CPU   %user   %nice    %sys %iowait    %irq   %soft  %steal   %idle    intr/s 16时13分59秒  all    0.17    0.10    0.07    0.05    0.02    0.03    0.00   99.56   1018.86   %user 在internal时间段里，用户态的CPU时间（%），不包含 nice值为负 进程 (usr/total)*100   %nice 在internal时间段里，nice值为负进程的CPU时间（%）   (nice/total)*100   %sys  在internal时间段里，核心时间（%）   (system/total)*100 %iowait 在internal时间段里，硬盘IO等待时间（%） (iowait/total)*100 %irq 在internal时间段里，硬中断时间（%）      (irq/total)*100 %soft 在internal时间段里，软中断时间（%）    (softirq/total)*100 %idle 在internal时间段里，CPU除去等待磁盘IO操作外的因为任何原因而空闲的时间闲置时间（%）(idle/total)*100 %intr/s 在internal时间段里，每秒CPU接收的中断的次数intr/total)*100   total_cur=user+system+nice+idle+iowait+irq+softirq total_pre=pre_user+ pre_system+ pre_nice+ pre_idle+ pre_iowait+ pre_irq+ pre_softirq user=user_cur – user_pre total=total_cur-total_pre   其中_cur 表示当前值，_pre表示interval时间前的值。上表中的所有值可取到两位小数点。   实例: 每2秒产生了2个处理器的统计数据报告 下面的命令可以每2秒产生了2个处理器的统计数据报告，一共产生三个interval 的信息，然后再给出这三个interval的平 均信息。默认时，输出是按照CPU 号排序。第一个行给出了从系统引导以来的所有活跃数据。接下来每行对应一个处理器的 活跃状态。。 [root@elain ]# mpstat -P ALL 2 3 Linux 2.6.18-194.11.3.el5 (elain)      2010年10月22日   16时17分43秒  CPU   %user   %nice    %sys %iowait    %irq   %soft  %steal   %idle    intr/s 16时17分45秒  all    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00   1036.36 16时17分45秒    0    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00   1036.36 16时17分45秒    1    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00      0.00   16时17分45秒  CPU   %user   %nice    %sys %iowait    %irq   %soft  %steal   %idle    intr/s 16时17分47秒  all    0.00    0.00    0.00    0.00    0.00    0.25    0.00   99.75   1045.27 16时17分47秒    0    0.00    0.00    0.00    0.00    0.50    0.00    0.00   99.50   1045.27 16时17分47秒    1    0.50    0.00    0.00    0.00    0.00    0.00    0.00   99.50      0.00   16时17分47秒  CPU   %user   %nice    %sys %iowait    %irq   %soft  %steal   %idle    intr/s 16时17分49秒  all    0.00    0.00    0.25    0.50    0.00    0.00    0.00   99.25   1031.84 16时17分49秒    0    0.00    0.00    0.50    1.49    0.00    0.00    0.00   98.01   1031.84 16时17分49秒    1    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00      0.00   Average:     CPU   %user   %nice    %sys %iowait    %irq   %soft  %steal   %idle    intr/s Average:     all    0.00    0.00    0.08    0.17    0.00    0.08    0.00   99.67   1037.83 Average:       0    0.00    0.00    0.17    0.50    0.17    0.00    0.00   99.17   1037.83 Average:       1    0.17    0.00    0.00    0.00    0.00    0.00    0.00   99.83      0.00 八、sar 命令  该命令是系统维护 的重要工具，主要帮助我们掌握系统资源的使用情况，特别是内存和CPU 的使用情况， 是UNIX系统使用者应该掌握的工具之 一。  sar  -A：所有报告的总和。   　-u：CPU利用率   　-v：进程、I节点、文件和锁表状态。  -d：硬盘使用报告。  -r：没有使用的内存页面和硬盘块。  -g：串口I/O的情况。     -b：缓冲区使用情况。     -a：文件读写情况。     -c：系统调用情况。     -R：进程的活动情况。     -y：终端设备活动情况。     -w：系统交换活动。    实例1：每60秒采样一次，连续采样5次，观察CPU的使用情况，并将采样结果以二进制形式存入当前目录下的文件/sar中，需键入如下命令： [root@elain ]# sar -u -o sar 60 5  Linux 2.6.18-194.11.3.el5 (elain)      2010年10月22日 16时28分47秒       CPU     %user     %nice   %system   %iowait    %steal     %idle 16时29分47秒       all      0.00      0.00      0.00      1.00      0.00     99.00 16时30分47秒       all      0.00      0.00      0.00      1.00      0.00     99.00 16时31分47秒       all      0.00      0.00      0.00      1.50      0.00     98.50 16时32分47秒       all      0.00      0.00      0.00      1.00      0.00     99.00 16时33分57秒       all      0.00      0.00      0.00      1.00      0.00     99.00 Average:          all      0.00      0.00      0.00      1.10      0.00     98.90   在显示内容包括：  %usr：   CPU处在用户模式下的时间百分比。  %sys：   CPU处在系统模式下的时间百分比。  %iowait：CPU等待输入输出完成时间的百分比。  %idle：  CPU空闲时间百分比。  我们应主要注意%wio和%idle，%wio的值过高，表示硬盘存在I/O瓶颈，%idle值高，表示CPU较空闲，如果%idle值高 但系统响应慢时，有可能是CPU等待分配内存， 此时应加大内存容量。%idle值如果持续低于10，那么系统的CPU处理能力相对较低，表明系统中最需要 解决的资源是CPU。  查看二进制文件sar中的内容，则需键入如下sar命令：  sar -u -f sar   实例2：每30秒采样一次，连续采样5次，观察核心表的状态，需键入如下命令：  [root@elain ]# sar -v 30 5 Linux 2.6.18-194.11.3.el5 (elain)      2010年10月22日 16时32分54秒 dentunusd   file-sz  inode-sz  super-sz %super-sz  dquot-sz %dquot-sz  rtsig-sz %rtsig-sz 16时33分54秒     60602       510     50659         0      0.00         0      0.00         0      0.00 16时34分54秒     60602       510     50659         0      0.00         0      0.00         0      0.00 16时35分54秒     60602       510     50659         0      0.00         0      0.00         0      0.00 16时36分54秒     60602       510     50659         0      0.00         0      0.00         0      0.00 16时37分54秒     60602       510     50659         0      0.00         0      0.00         0      0.00 Average:        60602       510     50659         0      0.00         0      0.00         0      0.00   显示内容表示，核心使用完全正常，三个表没有出现溢出现象，核心参数不需调整，如果出现溢出时，要调整相应的核心参数，将对应的表项数加大。  小提示： 怀疑CPU存在瓶颈，可用sar -u 和sar -q来看，怀疑I/O存在 瓶颈，可用sar -b、sar -u和sar-d来看。","title":"Linux诊断命令例解"},{"content":"摘要：信号处理机制是Unix操作系统的一大特点。本文以Linux0.11信号处理相关源码为例，针对几个细节对信号处理的整个流程进行描述，力求简单明了，参考赵炯博士的《Linux内核完全剖析》和潘晓雷的《Linux0.11源码分析》。 一、信号（signal）机制概述 所谓信号，是一种软中断机制，是实现进程间异步通讯的手段。信号的发送和处理是异步的，进程并不知道什么时候会收到信号。信号同中断很像，不同的信号对应不同的信号类型，并且对应不同的信号类型有相应的信号处理函数和信号屏蔽位。 1.信号的来源 程序错误：除零，非法内存访问… 外部信号：终端Ctrl-C产生SGINT信号，定时器到期产生SIGALRM… 显式请求：kill函数允许进程发送任何信号给其他进程或进程组。 2.Linux下查看信号 在Linux下，可以通过以下命令查看系统所有的信号： kill -l 可以通过类似下面的命令显式的给一个进程发送一个信号： kill -2 pid 3.信号的处理 忽略信号：大部分信号可被忽略，除SIGSTOP和SIGKILL信号外（这是超级用户杀掉或停掉任意进程的手段）。 捕获信号：注册信号处理函数，它对产生的特定信号做处理。 让信号默认动作起作用：unix内核定义的默认动作，有5种情况： a) abort：终止进程并产生core文件。 b) stop：终止进程但不生成core文件。 c) 忽略：忽略信号。 d) suspend：挂起进程。 e) continue：若进程是挂起的，则resume进程，否则忽略此信号。 二、深入信号机制内部 1.信号检测和响应的时机 当前进程由于系统调用、中断或异常而进入内核态以后，从内核态返回到用户态之前。 当前进程在内核中进入睡眠以后刚被唤醒的时候（必定是在系统调用中），或者由于不可忽略信号的存在而提前返回到用户空间。 2.Linux 0.11中用于信号处理的数据结构 用于保存信号信息的结构体 struct sigaction {\tvoid (*sa_handler)(int);//信号处理句柄\tsigset_t sa_mask;//信号的屏蔽码，可以阻塞指定的信号\tint sa_flags;//信号选项标志\tvoid (*sa_restorer)(void);//信号恢复函数指针（系统内部使用）}; 进程结构体重关于信号的定义 \tlong signal;\tstruct sigaction sigaction[32];\tlong blocked;\t/* bitmap of masked signals */ 3.信号的预处理操作 do_signal()函数 参数为内核态堆栈中的内容 void do_signal(long signr,long eax, long ebx, long ecx, long edx,\tlong fs, long es, long ds,\tlong eip, long cs, long eflags,\tunsigned long * esp, long ss){\tunsigned long sa_handler;\tlong old_eip=eip;\tstruct sigaction * sa = current->sigaction + signr - 1;\tint longs;\tunsigned long * tmp_esp;\tsa_handler = (unsigned long) sa->sa_handler;\tif (sa_handler==1)\t\treturn;\tif (!sa_handler) {\t\tif (signr==SIGCHLD)\t\t\treturn;\t\telse\t\t\tdo_exit(1<<(signr-1));\t}\tif (sa->sa_flags & SA_ONESHOT)\t\tsa->sa_handler = NULL;\t*(&eip) = sa_handler;\tlongs = (sa->sa_flags & SA_NOMASK)?7:8;\t*(&esp) -= longs;\tverify_area(esp,longs*4);\ttmp_esp=esp;\tput_fs_long((long) sa->sa_restorer,tmp_esp++);\tput_fs_long(signr,tmp_esp++);\tif (!(sa->sa_flags & SA_NOMASK))\t\tput_fs_long(current->blocked,tmp_esp++);\tput_fs_long(eax,tmp_esp++);\tput_fs_long(ecx,tmp_esp++);\tput_fs_long(edx,tmp_esp++);\tput_fs_long(eflags,tmp_esp++);\tput_fs_long(old_eip,tmp_esp++);\tcurrent->blocked |= sa->sa_mask;}对内核态堆栈的修改 4.操作系统进入信号处理 通过上述内容，可以看到操作系统在检测到有信号传入时，首先把内核堆栈中存放返回执行点的eip（指令寄存器）保存为old_eip，然后将eip替换为信号处理函数的地址，然后将内核中保存的“原ESP”（即用户态栈地址）减去一定的值，目的是扩大用户态的栈，然后将内核栈上的内容保存到用户栈上。 之所以把EIP的值设置成信号处理函数的地址，是因为一旦进程返回用户态，就要去执行信号处理程序，所以EIP要指向信号处理程序而不是原来应该执行的地址。 5.操作系统退出信号处理 在前面介绍sigaction数据结构的时候出现了信号活动恢复函数指针sa_restroer，该指针主要用于用户态堆栈的清理，把系统调用后的返回值eax和寄存器ecx,edx以及标志寄存器eflags弹出，完全恢复系统调用后各寄存器和CPU的状态，最后通过ret指令弹出原用户程序的eip（即堆栈中的old_eip）,返回执行用户程序。 但是在Linux内核代码中，并没有 给出此函数的具体定义，查看相关资料，在Linux的Libc函数库中定义有函数如下 编译程序在编译连接用户自定义的信号处理函数时，会将sa_restorer()函数插入到用户程序中。这样，用户在处理完自定义的信号处理函数后，就会继续执行用户代码了。、 注：文中图片来自《Linux内核完全剖析》。","title":"从Linux 0.11内核看Linux信号处理机制"},{"content":"今天在用virtualbox安装红旗linux系统时，加载光盘镜像后显示以下错误： This kernel requires the following features not present on the CPU: pae     Unable to boot - please use a kernel appropriate for your CPU. 经查询，pae是物理内存的扩展，这个是虚拟机设置问题，修改如下： 将扩展特性中的 启用PAE/NX 选中即可，再次重启虚拟机系统并进入安装界面，检测通过，可以正常进行。","title":"VirtualBox安装Linux出现错误"},{"content":"语法:  sed [-hnv] [-e <script>] [-f <script 文件>] [文本文件] 参数:   -e <script>  以选项中指定的script来处理输入的文件 -f <script 文件>   以选项中指定的script文件来处理输入的文件 -h   显示帮助 -n --quiet或--silent  仅显示script处理后的结果. -V 或 --version   显示版本信息 在参数中使用的script语法:  [行号] [/查找字符串/命令  <参数>] [行号] :    [行号, 行号], 指定第一个行号和第二个行号之间的每一行                 [行号!] 除此行之外的所有行                 不指定行号,且没有指定/查找字符串/, 处理输入文件的每一行 a\\<字符串> :   在指定的行后新增一行<字符串> c\\<字符串> :   以<字符串> 取代指定的行 d: 删除指定的行 i\\<字符串> : 在指定的行前新增一行<字符串> p: 显示指定的行 r<文本文件>: 先处理此处指定的文本文件, 然后处理命令行中所指定的文本文件 s/<查找字符串>/<取代字符串>/<取代方式>:  取代方式有3种                                                                                n:  取代第n个找到的<查找字符串>                                                                                g:  取代所有找到的<查找字符串>                                                                                p:  取代后,再显示一次此行 w<文本文件>: 在此文件填入指定字符 y/<查找字符>/<取代字符>/: <查找字符>和<取代字符>的长度必须相同 范例: 查找含有\"target\"的行,在后面新增一行,内容是\" A New Line\" trace@realize:~/study/shell/sed$ cat sed_script /target/a\\A new linetrace@realize:~/study/shell/sed$ cat textfile This is 1st lineThis is target lineThis is last linetrace@realize:~/study/shell/sed$ sed -f sed_script textfile This is 1st lineThis is target lineA new lineThis is last linetrace@realize:~/study/shell/sed$ 将textfile中第1,2行的\"is\"取代为12 trace@realize:~/study/shell/sed$ sed -e 1,2s/is/12/g textfile Th12 12 1st lineTh12 12 target lineThis is last line 将textfile中第1,2行的\"i\"取代为1, \"s\"取代为2: trace@realize:~/study/shell/sed$ sed -e 1,2y/is/12/ textfile Th12 12 12t l1neTh12 12 target l1neThis is last line 将textfile中第2,3行写入newfile文件中 trace@realize:~/study/shell/sed$ cat sed_script 1!w newfiletrace@realize:~/study/shell/sed$ sed -f sed_script textfile This is 1st lineThis is target lineThis is last linetrace@realize:~/study/shell/sed$ cat newfile This is target lineThis is last line","title":"Sed的使用方法"},{"content":"#include <linux/***.h> 是在linux-2.6.29/include/linux下面寻找源文件。 #include <asm/***.h> 是在linux-2.6.29/arch/arm/include/asm下面寻找源文件。 #include <mach/***.h> 是在linux-2.6.29/arch/arm/mach-s3c2410/include/mach下面寻找源文件。 #include<plat/regs-adc.h>在linux-2.6.31_TX2440A20100510\\linux-2.6.31_TX2440A\\arch\\arm\\plat-s3c\\include\\plat #include<linux/module.h>//最基本的文件，支持动态添加和卸载模块。Hello World驱动要这一个文件就可以了 #include <linux/fs.h> //包含了文件操作相关struct的定义，例如大名鼎鼎的struct file_operations                       //包含了struct inode 的定义，MINOR、MAJOR的头文件。 #include <linux/errno.h>//包含了对返回值的宏定义，这样用户程序可以用perror输出错误信息。 #include <linux/types.h>//对一些特殊类型的定义，例如dev_t, off_t, pid_t.其实这些类型大部分都是unsigned int型通过一连串的typedef变过来的，只是为了方便阅读。 #include <linux/cdev.h>//对字符设备结构cdev以及一系列的操作函数的定义。//包含了cdev 结构及相关函数的定义。 #include <linux/wait.h>//等代队列相关头文件//内核等待队列，它包含了自旋锁的头文件 #include<linux/init.h>//初始化头文件 #include<linux/kernel.h>//驱动要写入内核，与内核相关的头文件 #include <linux/slab.h>//包含了kcalloc、kzalloc内存分配函数的定义。 #include <linux/uaccess.h>//包含了copy_to_user、copy_from_user等内核访问用户进程内存地址的函数定义。 #include<linux/device.h>//包含了device、class 等结构的定义 #include <linux/io.h>//包含了ioremap、iowrite等内核访问IO内存等函数的定义。 #include<linux/miscdevice.h>//包含了miscdevice结构的定义及相关的操作函数。 #include<linux/interrupt.h>//使用中断必须的头文件 #include <mach/irqs.h>//使用中断必须的头文件 #include <asm/bitops.h>//包含set_bit等位操作函数，实现Input子系统时可用。 #include<linux/semaphore.h> //使用信号量必须的头文件 #include<linux/spinlock.h>//自旋锁 #include <linux/sched.h>//内核等待队列中要使用的TASK_NORMAL、TASK_INTERRUPTIBLE包含在这个头文件 #include<linux/kfifo.h> //fifo环形队列 #include<linux/timer.h> //内核定时器 #include<linux/input.h> //中断处理  #include <linux/delay.h>//延时头文件 #include <asm/irq.h>//与处理器相关的中断 #include<linux/interrupt.h>//操作系统中断 #include <asm/uaccess.h>//与处理器相关的入口 //#include<asm/arch/regs-gpio.h>//与处理器相关的IO口操作 #include<mach/regs-gpio.h>//同上 //#include<asm/hardware.h>//与处理器相关的硬件 #include<mach/hardware.h>//同上 #include <linux/poll.h> //轮询文件 #include <linux/gpio.h>//操作系统相关的IO口文件 #include <stdio.h>//标准输入输出 #include <stdlib.h>//标准库 #include <unistd.h> #include <sys/ioctl.h>//IO控制   头文件主目录include 头文件目录中总共有32个.h头文件。其中主目录下有13个，asm子目录中有4个，linux子目录中有10个，sys子目录中有5个。这些头文件各自的功能如下，具体的作用和所包含的信息请参见第14章。 <a.out.h>：a.out头文件，定义了a.out执行文件格式和一些宏。 <const.h>：常数符号头文件，目前仅定义了i节点中i_mode字段的各标志位。 <ctype.h>：字符类型头文件，定义了一些有关字符类型判断和转换的宏。 <errno.h>：错误号头文件，包含系统中各种出错号。(Linus从minix中引进的)。 <fcntl.h>：文件控制头文件，用于文件及其描述符的操作控制常数符号的定义。 <signal.h>：信号头文件，定义信号符号常量，信号结构以及信号操作函数原型。 <stdarg.h>：标准参数头文件，以宏的形式定义变量参数列表。主要说明了一个类型（va_list）和3个宏（va_start, va_arg和va_end），用于vsprintf、vprintf、vfprintf函数。 <stddef.h>：标准定义头文件，定义了NULL, offsetof(TYPE, MEMBER)。 <string.h>：字符串头文件，主要定义了一些有关字符串操作的嵌入函数。 <termios.h>：终端输入输出函数头文件，主要定义控制异步通信口的终端接口。 <time.h>：时间类型头文件，主要定义了tm结构和一些有关时间的函数原形。 <unistd.h>：Linux标准头文件，定义了各种符号常数和类型，并声明了各种函数。如，定义了__LIBRARY__，则还包括系统调用号和内嵌汇编_syscall0()等。 <utime.h>：用户时间头文件，定义了访问和修改时间结构以及utime()原型。 （1）体系结构相关头文件子目录include/asm 这些头文件主要定义了一些与CPU体系结构密切相关的数据结构、宏函数和变量。共4个文件。 <asm/io.h>：I/O头文件，以宏的嵌入汇编程序形式定义对I/O端口操作的函数。 <asm/memory.h>：内存拷贝头文件，含有memcpy()嵌入式汇编宏函数。 <asm/segment.h>：段操作头文件，定义了有关段寄存器操作的嵌入式汇编函数。 <asm/system.h>：系统头文件，定义了设置或修改描述符/中断门等的嵌入式汇编宏。 （2）Linux内核专用头文件子目录include/linux <linux/config.h>：内核配置头文件，定义键盘语言和硬盘类型（HD_TYPE）可选项。 <linux/fdreg.h>：软驱头文件，含有软盘控制器参数的一些定义。 <linux/fs.h>：文件系统头文件，定义文件表结构（file,buffer_head,m_inode等）。 <linux/hdreg.h>：硬盘参数头文件，定义访问硬盘寄存器端口、状态码和分区表等信息。 <linux/head.h>：head头文件，定义了段描述符的简单结构，和几个选择符常量。 <linux/kernel.h>：内核头文件，含有一些内核常用函数的原形定义。 <linux/mm.h>：内存管理头文件，含有页面大小定义和一些页面释放函数原型。 <linux/sched.h>： 调度程序头文件，定义了任务结构task_struct、初始任务0的数据， 以及一些有关描述符参数设置和获取的嵌入式汇编函数宏语句。 <linux/sys.h>：系统调用头文件，含有72个系统调用C函数处理程序,以\"sys_\"开头。 <linux/tty.h>：tty头文件，定义了有关tty_io，串行通信方面的参数、常数。 （3）系统专用数据结构子目录include/sys <sys/stat.h>： 文件状态头文件，含有文件或文件系统状态结构stat{}和常量。 <sys/times.h>：定义了进程中运行时间结构tms以及times()函数原型。 <sys/types.h>：类型头文件，定义了基本的系统数据类型。 <sys/utsname.h>：系统名称结构头文件。 <sys/wait.h>：等待调用头文件，定义系统调用wait()和waitpid()及相关常数符号。","title":"linux驱动学习笔记（linux驱动头文件说明）"},{"content":"linux目录结构简析 /    根目录 /bin    常用的命令 binary file 的目录 /boot   存放系统启动时必须读取的档案，包括核心 (kernel) 在内      /boot/grub/menu.lst   GRUB设置      /boot/vmlinuz   内核      /boot/initrd     核心解压缩所需 RAM Disk /dev    系统周边设备      /etc    系统相关设定文件      /etc/DIR_COLORS   设定颜色      /etc/HOSTNAME   设定用户的节点名      /etc/NETWORKING   只有YES标明网络存在      /etc/host.conf 文件说明用户的系统如何查询节点名      /etc/hosts 设定用户自已的IP与名字的对应表      /etc/hosts.allow 设置允许使用inetd的机器使用       /etc/hosts.deny 设置不允许使用inetd的机器使用      /etc/hosts.equiv 设置远端机不用密码       /etc/inetd.conf 设定系统网络守护进程inetd的配置      /etc/gateways 设定路由器      /etc/protocols 设定系统支持的协议      /etc/named.boot 设定本机为名字服务器的配置文件      /etc/sysconfig/network-scripts/ifcfg-eth0   设置IP      /etc/resolv.conf    设置DNS        /etc/X11  X Window的配置文件,xorg.conf 或 XF86Config 這两个 X Server 的设定档      /etc/fstab    记录开机要mount的文件系统      /etc/inittab 设定系统启动时init进程将把系统设置成什么样的runlevel      /etc/issue 记录用户登录前显示的信息      /etc/group 设定用户的组名与相关信息      /etc/passwd 帐号信息      /etc/shadow 密码信息      /etc/sudoers 可以sudo命令的配置文件       /etc/securetty 设定哪些终端可以让root登录      /etc/login.defs 所有用户登录时的缺省配置      /etc/exports 设定NFS系统用的      /etc/init.d/   所有服务的预设启动 script 都是放在這里的，例如要启动或者关闭      /etc/xinetd.d/  這就是所谓的 super daemon 管理的各项服务的设定档目录      /etc/modprobe.conf   内核模块额外参数设定      /etc/syslog.conf   日志设置文件 /home   使用者家目录 /lib    系统会使用到的函数库      /lib/modules   kernel 的相关模块      /var/lib/rpm   rpm套件安装处  /lost+found    系統不正常产生错误时，会将一些遗失的片段放置于此目录下 /mnt     外设的挂载点 /media   与/mnt类似 /opt     主机额外安装的软件 /proc    虚拟目录，是内存的映射      /proc/version   内核版本      /proc/sys/kernel   系统内核功能  /root    系统管理员的家目录 /sbin    系统管理员才能执行的指令 /srv     一些服务启动之后，这些服务所需要取用的资料目录 /tmp     一般使用者或者是正在执行的程序暂时放置档案的地方 /usr     最大的目录，存许多应用程序和文件     /usr/X11R6：   X-Window目录      /usr/src：    Linux源代码     /usr/include：系统头文件     /usr/openwin 存放SUN的OpenWin      /usr/man 在线使用手册     /usr/bin           使用者可执行的 binary file 的目录     /usr/local/bin     使用者可执行的 binary file 的目录     /usr/lib           系统会使用到的函数库      /usr/local/lib     系统会使用到的函数库     /usr/sbin          系统管理员才能执行的指令     /usr/local/sbin    系统管理员才能执行的指令 /var   日志文件     /var/log/secure    记录登入系统存取资料的档案，例如 pop3, ssh, telnet, ftp 等都会记录在此案中     /var/log/wtmp     记录登入者的信息资料, last     /var/log/messages  几乎系统发生的错误信息     /var/log/boot.log  记录开机或者是一些服务启动的时候，所显示的启动或关闭信息     /var/log/maillog   记录邮件存取或往來( sendmail 与 pop3 )的使用者记录     /var/log/cron      记录 crontab 這个例行性服务的內容     /var/log/httpd, /var/log/news, /var/log/mysqld.log, /var/log/samba, /var/log","title":"linux目录结构简析"},{"content":"    最近，一直在看书学习linux设备驱动，从最简单的字符设备驱动入门，能够对驱动的框架和各元素的功能有个宏观的了解。下面详细分析我写的第一个字符设备驱动，整理一些驱动的基础知识，加深印象。先给出一些宏定义和全局变量： #define GLB_MEM_SIZE 0x1000 #define HELLO_MAJOR 250 #define MEM_CLEAR 0x1 int hello_major = HELLO_MAJOR; struct globalmem_dev {     struct cdev cdev;    unsigned char mem[GLB_MEM_SIZE];};                 //此处定义一个全局变量，用于构造一个虚拟的字符设备 struct globalmem_dev *devp; 首先，linux设备驱动属于内核的一部分，具有明显的模块特性。字符设备驱动包括以下几大块： （一）驱动加载和卸载模块 module_init(hello_drv_init); module_exit(hello_drv_exit); 其中module_init和module_exit是内核定义的宏，用于将自己编写的模块加载到内核或者从内核载。hello_drv_init和hello_drv_exit是 我们自己定义的函数，hello_drv_init是驱动的初始化函数，主要完成以下几部分工作： 1. 为字符设备向系统申请设备号 dev_t devno = MKDEV(hello_major, 0);  如果手动分配好主设备号hello_major，则MKDEV宏可生成设备号，其中次设备号为0，而且主设备号占12位，次设备号占20位 register_chrdev_region(devno, 1, \"helloworld\"); 以上函数为向系统手动申请一个设备号记录到chardevs数组当中，设备名为“helloworld”，前提是设备号未被使用 alloc_chrdev_region(devno, 0, 1, \"helloworld\"); 以上函数表示向系统动态申请未被占用的设备号，第一个参数devno用于存放获得的设备号，第二个参数0表示次设备号，第三 个参数1表示只申请一个。 hello_major = MAJOR(devno); hello_minor = MINOR(devno); 以上两个宏分别表示从设备号devno中提取主设备号hello_major和次设备号hello_major 2. 为字符设备的结构体分配内存并初始化 devp = kmalloc(sizeof(struct globalmem_dev), GFP_KERNEL); memset(devp, 0, sizeof(struct globalmem_dev)); 上面GFP_KERNEL是内核分配内存空间的一个标识，表示无内存可用时进入休眠状态。 3. 初始化cdev devno = MKDEV(hello_major, 0); cdev_init(&devp->cdev, &fops);该函数用于初始化cdev的成员，建立cdev和file_operations之间的联系 devp->cdev.owner = THIS_MODULE; 4. 注册cdev cdev_add(&devp->cdev, devno, 1); 向系统添加一个cdev，完成字符设备的注册。 同样，模块卸载的时候，会进行与注册时相对应的三个操作 cdev_del(&devp->cdev);//注销cdevkfree(devp);//释放结构体内存unregister_chrdev_region(MKDEV(hello_major, 0), 1);//释放设备号 （二）file_operations 数据结构体的填充 本人简单理解，应用程序对底层设备的访问是通过open、close、ioctl等函数操作的，而且应用层的这些函数是通过系统调用以及文件系统的一个桥梁作用，最终调用的正是file_operations中与之相对应的函数，所以file_operations 结构体中的函数实现需要由驱动工程师去实现。 static struct file_operations fops ={.owner                = THIS_MODULE,.llseek                  = hello_llseek,.read                   = hello_read,.write                   = hello_write,.ioctl                    = hello_ioctl,.release              = hello_release,} （三）file_operations 结构体中函数的实现下面以最常见的read和write函数作为例子来分析， static int hello_read(struct file *file, char __user *buf, size_t size, loff_t *ppos){unsigned long p = *ppos;//读的位置相对于文件开头的偏移量int ret = 0;//读取偏移位置是否越界，或者字节数太大的判断 if(p >= GLB_MEM_SIZE)    return 0;if(size > GLB_MEM_SIZE - p)    size = GLB_MEM_SIZE - p;//开始读取 if(copy_to_user(buf, (void*)(devp->mem+p), size))    ret = -EFAULT;else{    *ppos += size;    ret = size;    printk(KERN_INFO \"read %d bytes from %d\\n\", size, p);}    return ret;} 其中file是文件结构体指针，buf为用户空间的内存，size是需要读取的字节数，因为内核空间和用户空间的内存不能互相访问，需要借助于copy_to_user函数完成内核空间到用户空间的映射（即拷贝），同理在写的时候，则需要copy_from_user完成用户空间到内存空间的映射，这两个函数返回的都是不能被复制的字节数，所以，如果完全映射（复制）成功，则返回0. static int hello_write(struct file *file, const char __user *buf, size_t count, loff_t *offset){    int ret;    unsigned long p = *offset;    if(p >= GLB_MEM_SIZE)        return 0;    if(count> GLB_MEM_SIZE - p)        count = GLB_MEM_SIZE - p;    if(copy_from_user((devp->mem+p), buf, count))        ret = -EFAULT;    else    {        *ppos += count;        ret = count;        printk(KERN_INFO \"write %d bytes to %d\\n\", count, p);    }    return ret;} （四）头文件和宏 驱动模块中常使用到的头文件，可参考我转载的一篇关于linux驱动头文件的文章。另外，还有一些宏如下： MODULE_AUTHOR(\"W. Yihong <a5131wyh@163.com>\");//模块作者的一些信息声明MODULE_DESCRIPTION(\"hello world driver\"); //模块功能的一些描述MODULE_LICENSE(\"GPL\");//模块许可证的声明，如果不声明LICENSE，则模块加载时会收到内核被污染的警告MODULE_ALIAS(\"platform:myfirst_driver\"); //模块可以调用此宏为自己定义一个或者若干个别称 以上是我对字符设备驱动的一个简单理解，还有很多驱动的机制和内涵并不清楚，需要在以后的实际项目中去慢慢摸索和总结，本人正在入门，希望大家能指出文章不足之处,共同进步。      ","title":"linux字符设备驱动总结分析"},{"content":"Nut lucene+hadoop 分布式并行计算搜索框架 Alpha 9 文档 作者：曾年仔 mail:zengnianzai@163.com blog: http://www.blogjava.net/nianzai/ code: http://code.google.com/p/nutla/ 1、概述 不管程序性能有多高，机器处理能力有多强，都会有其极限。能够快速方便的横向与 纵向扩展是Nut设计最重要的原则，以此原则形成以分布式并行计算为核心的架构设计。以 分布式并行计算为核心的架构设计是Nut区别于Solr、Katta的地方。 Nut是一个Lucene+Hadoop分布式并行计算搜索框架，能对千G以上索引提供7*24小时搜 索服务。在服务器资源足够的情况下能达到每秒处理100万次的搜索请求。 Nut开发环境： jdk1.6.0.23+lucene3.0.3+eclipse3.6.1+hadoop0.20.2+zookeeper3.3.2+hbase0.20.6+m emcached+mongodb+linux 2、特新 a、热插拔 b、可扩展 c、高负载 d、易使用,与现有项目无缝集成 e、支持排序 f、7*24服务 g、失败转移 3、搜索流程 Nut由Index、Search、Client、Cache和DB五部分构成。(Cache实现了对memcached的支持,DB 实现了对hbase,mongodb的支持) Client处理用户请求和对搜索结果排序。Search对请求进行搜索，Search上只放索引，数 据存储在DB中，Nut将索引和存储分离。Cache缓存的是搜索条件和结果文档id。DB存储着 数据，Client根据搜索排序结果,取出当前页中的文档id从DB上读取数据。 用户发起搜索请求给由Nut Client构成的集群，由某个Nut Client根据搜索条件查询Cache 服务器是否有该缓存，如果有缓存根据缓存的文档id直接从DB读取数据，如果没有缓存将 随机选择一组搜索服务器组(Search Group i),将查询条件同时发给该组搜索服务器组里的 n台搜索服务器，搜索服务器将搜索结果返回给Nut Client由其排序，取出当前页文档id， 将搜索条件和当前文档id缓存，同时从DB读取数据。 4、索引流程 Hadoop Mapper/Reducer 建立索引。再将索引从HDFS分发到各个索引服务器。 对索引的更新分为两种：删除和添加（更新分解为删除和添加）。 a、删除 在HDFS上删除索引，将生成的*.del文件分发到所有的索引服务器上去或者对HDFS 索引目录删除索引再分发到对应的索引服务器上去。 b、添加 新添加的数据用另一台服务器来生成。 删除和添加步骤可按不同定时策略来实现。 5、Nut分布式并行计算特点 Nut分布式并行计算虽然也是基于M/R模型，但是与Hadoop M/R模型是不同的。在Hadoop M/R 模型中 Mapper和Reducer是一个完整的流程，Reducer依赖于Mapper。数据源通过Mapper 分发本身就会消耗大量的I/O，并且是消耗I/O最大的部分。所以Hadoop M/R 并发是有限的。 Nut M/R模型是将Mapper和Reducer分离，各自独立存在。在Nut中 索引以及索引管理 构成 M,搜索以及搜索服务器组 构成 R。 以一个分类统计来说明Nut分布式并行计算的流程。假设有10个分类，对任意关键词搜索要 求统计出该关键词在这10个分类中的总数。同时假设有10组搜索服务器。索引以及索引管 理进行索引数据的Mapper，这块是后台独自运行管理的。Nut Client将这10个分类统计分 发到10组搜索服务器上，每组搜索服务器对其中一个分类进行Reducer，并且每组搜索服务 器可进行多级Reducer。最后将最终结果返回给Nut Client。 6、设计图 Nut Client 用户 Nut Search 发起请求 发起请求 返回评分结果 返回排序结果 client 1 。。。。。。Client m 负载均衡器 发起请求 返回排序结果 Nut Cache 排序结果 搜索条件:文档ids 返回结果 Nut DB Key:value ids 返回 Nut Index 索 引 分 发 索 引 分 发 索 引 分 发 索 引 分 发 Zookeeper 服务器状态管理 MR 1 MR 2 。。。。。。MR p sg 1 Search group 1 运行中搜索服务器组 S 1 S 2 。。。 S n 备用中搜索服务器组（可选） B 1 B 2 。。。B i sg 1 sg 2 。。。。。。sg h Search group h 7、Zookeeper服务器状态管理策略 在架构设计上通过使用多组搜索服务器可以支持每秒处理100万个搜索请求。 每组搜索服务器能处理的搜索请求数在1万—1万5千之间。如果使用100组搜索服务器，理 论上每秒可处理100万个搜索请求。 假如每组搜索服务器有100份索引放在100台正在运行中搜索服务器(run)上，那么将索引按 照如下的方式放在备用中搜索服务器(bak)上：index 1,index 2,index 3,index 4,index 5,index 6,index 7,index 8,index 9,index 10放在B 1 上，index 6,index 7,index 8,index 9,index 10,index 11,index 12,index 13,index 14,index 15放在B 2上。。。。。。index 96,index 97,index 98,index 99,index 100,index 5,index 4,index 3,index 2,index 1 放在最后一台备用搜索服务器上。那么每份索引会存在3台机器中（1份正在运行中，2份备 份中）。 尽管这样设计每份索引会存在3台机器中，仍然不是绝对安全的。假如运行中的index 1,index 2,index 3同时宕机的话，那么就会有一份索引搜索服务无法正确启用。这样设计， 作者认为是在安全性和机器资源两者之间一个比较适合的方案。 备用中的搜索服务器会定时检查运行中搜索服务器的状态。一旦发现与自己索引对应的服 务器宕机就会向lock申请分布式锁，得到分布式锁的服务器就将自己加入到运行中搜索服 务器组，同时从备用搜索服务器组中删除自己，并停止运行中搜索服务器检查服务。 为能够更快速的得到搜索结果，设计上将搜索服务器分优先等级。通常是将最新的数据放 Zookeeper 服务器状态管理 Sg 1 Sg 2 。。。。。。 Sg h run lock bak Search group 1 运行中搜索服务器组 S 1 。。。 S n 备用中搜索服务器组 B 1 。。。。B i 在一台或几台内存搜索服务器上。通常情况下前几页数据能在这几台搜索服务器里搜索到。 如果在这几台搜索服务器上没有数据时再向其他旧数据搜索服务器上搜索。 优先搜索等级的逻辑是这样的：9最大为搜索全部服务器并且9不能作为level标识。当搜索 等级level为1，搜索优先级为1的服务器，当level为2时搜索优先级为1和2的服务器，依此 类推。 8、web.xml配置 <!-- 启动zookeeper连接检查 --> <servlet> <servlet-name>ZooKeeperInitServlet<\/servlet-name> <servlet-class>nut.nianzai.servlet.ZooKeeperInitServlet<\/servlet-class> <load-on-startup>1<\/load-on-startup> <\/servlet> <!-- 服务器状态显示 --> <servlet> <servlet-name>StatusServlet<\/servlet-name> <servlet-class>nut.nianzai.servlet.StatusServlet<\/servlet-class> <\/servlet> <servlet-mapping> <servlet-name>StatusServlet<\/servlet-name> <url-pattern>/status.cgi<\/url-pattern> <\/servlet-mapping> 9、搜索插件 a、通过实现QueryPlugin接口来实现自定义查询功能 public class ExampleQueryPlugin implements QueryPlugin { @Override /** * 将自己要实现的查询功能在这实现 */ public Query query(String keyword) throws Exception { Analyzer analyzer = new ChineseAnalyzer(); QueryParser parser1 = new QueryParser(Version.LUCENE_30,\"title\", analyzer); QueryParser parser2 = new QueryParser(Version.LUCENE_30,\"descs\", analyzer); Query query1 = parser1.parse(keyword); query1.setBoost(1.2f); Query query2 = parser2.parse(keyword); query2.setBoost(0.8f); BooleanQuery bq = new BooleanQuery(); bq.add(query1, BooleanClause.Occur.MUST); bq.add(query2, BooleanClause.Occur.SHOULD); return bq; } @Override /** * 实现自己的排序功能 */ public Sort sort() { Sort sort=new Sort(new SortField(\"reviews\", SortField.INT, true)); return sort; } @Override /** * 实现自己的filter功能 */ public Filter filter() { return null; } } b、配置plugin.properties文件 #自定义查询插件名称=自定义查询插件实现类名 basicQuery=nut.nianzai.plugin. ExampleQueryPlugin c、将自定义查询插件和plugin.properties打包生成nut-plugin.jar部署在每台服务的 lib目录中 10、索引插件 a、通过实现IndexPlugin接口来实现自定义生成索引功能 public class ExampleIndexPlugin implements IndexPlugin { private static Analyzer analyzer = new ChineseAnalyzer(); @Override public void create(File file,Iterable<Text> values) { try { IndexWriter indexWriter = new IndexWriter(NIOFSDirectory.open(file),analyzer,true,IndexWriter.MaxFieldLength.UNLIMITED) ; indexWriter.setRAMBufferSizeMB(256); indexWriter.setUseCompoundFile(false); for (Text str : values) { Document doc = new Document(); String[] ss=str.toString().split(\"<<,>>\"); doc.add(new Field(\"id\",ss[0], Field.Store.YES,Field.Index.NOT_ANALYZED)); doc.add(new Field(\"title\", ss[1], Field.Store.NO,Field.Index.ANALYZED)); doc.add(new Field(\"descs\", ss[2], Field.Store.NO,Field.Index.ANALYZED)); doc.add(new Field(\"reviews\",ss[3],Field.Store.YES,Field.Index.NOT_ANALYZED)); indexWriter.addDocument(doc); } indexWriter.optimize(); indexWriter.close(); } catch(Exception e) { e.printStackTrace(); } } @Override public void merge(Directory[] dirs,Directory localWorkingDir) throws IOException { IndexWriter writer = new IndexWriter(localWorkingDir, analyzer, true,IndexWriter.MaxFieldLength.UNLIMITED); writer.setRAMBufferSizeMB(256); writer.setUseCompoundFile(false); writer.addIndexesNoOptimize(dirs); writer.optimize(); writer.close(); } @Override public void delete(Directory dir, String ids) throws IOException { IndexWriter writer = new IndexWriter(dir,analyzer,false,IndexWriter.MaxFieldLength.UNLIMITED); writer.deleteDocuments(NutUtil.getTerms(ids)); writer.close(); } b、配置hadoop.properties文件 indexplugin=nut.nianzai.plugin.ExampleIndexPlugin c、将自定义建索引插件和hadoop.properties文件打包成nut-index.jar放在hadoop环境 中运行 11、HBase数据插入插件 a、通过实现HBasePlugin接口来实现自定义插入数据功能 public class ExampleHBasePlugin implements HBasePlugin { @Override public Put insert(Text value) { String[] ss=value.toString().split(\"<<,>>\"); Put put = new Put(Bytes.toBytes(Integer.parseInt(ss[0]))); put.add(Bytes.toBytes(\"title\"), Bytes.toBytes(\"\"), Bytes.toBytes(ss[1])); put.add(Bytes.toBytes(\"descs\"), Bytes.toBytes(\"\"), Bytes.toBytes(ss[2])); put.add(Bytes.toBytes(\"reviews\"), Bytes.toBytes(\"\"), Bytes.toBytes(ss[3])); return put; } } b、配置hadoop.properties文件 indexplugin=nut.nianzai.plugin.ExampleHBasePlugin c、将自定义建索引插件和hadoop.properties文件打包成nut-hbase.jar放在hadoop环境 中运行 12、测试 public class NutTest { //分布式搜索例子 public static void main(String[] arg) { try { ZkCheck.start(); Thread.sleep(6*1000);//等待6秒,用于通信初始化 //构造查询对象 Parameter parameter=new Parameter(); parameter.setQuery(\"basicQuery\"); parameter.setKeyword(\"soho\"); parameter.setNo(1); parameter.setPs(2); parameter.setSortfield(\"reviews\");//如果实现了排序，指明排序字段，需要根据 这个来对结果进行排序 //只统计 int n=Client.parallelTotal(parameter); System.out.println(n); //搜索 NutDB db=new MongoDB(House.class); NutCached cached=new MemCached(); List<Object> ll=Client.parallelSearch(cached,db,parameter); System.out.println(parameter.getRscount());//返回搜索记录总数 for(int i=0;i<ll.size();i++) { System.out.println(((House)ll.get(i)).getId()); System.out.println(((House)ll.get(i)).getTitle()); System.out.println(((House)ll.get(i)).getDescs()); System.out.println(((House)ll.get(i)).getReviews()); } } catch(Exception e) {e.printStackTrace();} } } 13、服务器端部署 将nut压缩包解压部署在服务器上，根据服务操用途使用相应的启动服务命 a、运行搜索服务器启用命令nutserver.sh或nutserver.bat b、备用搜索服务器启用命令checkserver.sh或checkserver.bat 14、用户管理工具 nut.sh(nut.bat)为命令行用户管理工具。 a、新建一个zookeeper根节点 sh nut.sh zk create 192.168.195.128:2181 nutzk b、查看根节点nutzk下的子节点 sh nut.sh zk list 192.168.195.128:2181 nutzk c、删除根节点nutzk sh nut.sh zk delete 192.168.195.128:2181 nutzk d、将目录（文件）从hdfs 复制到本地目录 sh nut.sh copy h2l hdfs://192.168.195.128:9000/user/nianzai/nutindex/0/ /home/nianzai/index/ e、将目录（文件）从本地复制到hdfs sh nut.sh copy l2h /home/nianzai/1.txt hdfs://192.168.195.128:9000/user/nianzai/input/ f、新建搜索节点 sh nut.sh zk searchgroup 192.168.195.128:2181 sg1","title":"lucene+hadoop 分布式并行计算搜索框架"},{"content":"在运行Ubuntu的时候，因为没有什么需要独显的应用，就想到要关闭独显，只使用集显，省电又降温 理论上适合类似的双显卡切换的笔记本，使用其他笔记本的同学请自行测试可用性 准备工作：安装了ATI闭源驱动的请先卸载，在BIOS里禁用了双显卡切换的请先开启 首先在终端下执行这条命令： cat /sys/kernel/debug/vgaswitcheroo/switch 如果遇到下图情况  开启root之后即可 如果类似这样（主要是两个状态都是Pwr）： 0:IGD:+:Pwr:0000:00:02.01:DIS: :Pwr:0000:01:00.0就说明你的两块显卡都开着，那么就按照下面的步骤做吧 建立一个脚本/usr/local/sbin/vgaswitcher #!/bin/bash if [ \"$(whoami)\" != \"root\" ]; then   echo \"Use as root\"   exit 1fi if [ -z \"$1\" ]; then        cmd=\"OFF\"else   if [ \"$1\" = \"-i\" ]; then      cmd=\"DIGD\"   elif [ \"$1\" = \"-d\" ]; then      cmd=\"DDIS\"   else           cmd=$1   fifi if ([ \"$cmd\" != \"OFF\" ] && [ \"$cmd\" != \"DDIS\" ] && [ \"$cmd\" != \"DIGD\" ]); then        echo \"Bad Command!\"        exit 1fi echo \"$cmd\" > /sys/kernel/debug/vgaswitcheroo/switchcat /sys/kernel/debug/vgaswitcheroo/switch 然后再建立一个启动脚本/etc/init.d/vgaswitch #!/bin/bash if [ \"$1\" != \"start\" ]; then   exit;fi /usr/local/sbin/vgaswitcher/usr/local/sbin/vgaswitcher -i 都建立好以后，执行如下命令： sudo chmod +x /usr/local/sbin/vgaswitcher /etc/init.d/vgaswitch && sudo update-rc.d vgaswitch defaults 重启就可以禁用掉独显了~ 可以再次执行最开始的命令来查看状态： cat /sys/kernel/debug/vgaswitcheroo/switch 现在应该是这样了（一个Pwr，另一个Off）： 0:IGD:+:Pwr:0000:00:02.01:DIS: :Off:0000:01:00.0","title":"ubuntu下禁用独显"},{"content":"今天在linux吧   被几位大神吐槽了   可能是因为问题太愚蠢了吧  具体是什么问题  还真不好意思说   想想还是自己解决吧   看看源码  自己学着来 听说deadbeef比较是linux下比较好的音乐播放器   装了看看 做一下记录   发现自己的ubuntu12.04装了太多东西  真的得好好记录装了什么    之前wine后装了个deepin  music  player 界面还行  但是会出现下面这种状况  不知是自己的机子 问题还是  wine后的后遗症 下面说说deadbeef的安装 deadbeef源码下载地址：http://deadbeef.sourceforge.net/ 安装命令： sudo add-apt-repository ppa:alexey-smirnov/deadbeefsudo apt-get updatesudo apt-get install deadbeef 安装后界面： 部分文件名出现乱码   不知如何解决   谷歌了一下  没试过   试过的朋友 分享一下 http://ihacklog.com/post/patch-deadbeef-to-support-gbk-id3-tags-and-add-lyrics-support.html","title":"ubuntu12.04安装deadbeef"},{"content":"在使用aapt时，出现了/lib/libz.so.1: no version information available 警告信息，但命令还是可以执行的 之前zlib是用yum安装的，版本为1.2.3，网上查了一下，是版本的原因，安装新的版本就好了 从http://zlib.net/下载最新版本 wget http://zlib.net/zlib-1.2.7.tar.gztar zxvf zlib-1.2.7.tar.gzcd zlib-1.2.7.tar.gz./configuremakemake install#覆盖原版本，可以先备份一下原版本cp /usr/local/lib/libz.so.1 /lib/ OK,完成","title":"centos出现/lib/libz.so.1: no version information available解决方案"},{"content":"转自http://bob-0703.iteye.com/blog/970520 echo 1 > /proc/sys/net/ipv4/ip_forward 将ip_forword 默认是0 设置成1 开启转发功能  cp /etc/sysctl.conf /etc/sysctl.conf.default  备份以后修改net.ipv4.ip_forward = 1  192.168.103.20 本机  192.168.103.2 转发到的机器  iptables -t nat -A PREROUTING -d 192.168.103.200 -p tcp -m tcp --dport 3389 -j DNAT --to-destination 192.168.103.2:3389  iptables -t nat -A POSTROUTING -d 192.168.103.2 -p tcp -m tcp --dport 3389  -j SNAT --to-source 192.168.103.200  service iptables save  最后将本机 3389端口给打开  iptables -A RH-Firewall-1-INPUT -m state --state NEW -m tcp -p tcp --dport 3389-j ACCEPT  service iptables save  service iptables restart  查看端口是否开放 /sbin/iptables -L -n ","title":"linux端口转发"},{"content":"对消息队列的操作无非有下面三种类型： 1、 打开或创建消息队列 消息队列的内核持续性要求每个消息队列都在系统范围内对应唯一的键值，所以，要获得一个消息队列的描述字，只需提供该消息队列的键值即可； 注：消息队列描述字是由在系统范围内唯一的键值生成的，而键值可以看作对应系统内的一条路经。 2、 读写操作 消息读写操作非常简单，对开发人员来说，每个消息都类似如下的数据结构： struct msgbuf{long mtype;char mtext[1];}; mtype成员代表消息类型，从消息队列中读取消息的一个重要依据就是消息的类型；mtext是消息内容，当然长度不一定为1。因此，对于发送消息来说，首先预置一个msgbuf缓冲区并写入消息类型和内容，调用相应的发送函数即可；对读取消息来说，首先分配这样一个msgbuf缓冲区，然后把消息读入该缓冲区即可。 3、 获得或设置消息队列属性： 消息队列的信息基本上都保存在消息队列头中，因此，可以分配一个类似于消息队列头的结构(struct msqid_ds，见附录 2)，来返回消息队列的属性；同样可以设置该数据结构。 消息队列API 1、文件名到键值 #include <sys/types.h>#include <sys/ipc.h>key_t ftok (char*pathname, char proj)； 它返回与路径pathname相对应的一个键值。该函数不直接对消息队列操作，但在调用ipc(MSGGET,…)或msgget()来获得消息队列描述字前，往往要调用该函数。典型的调用代码是：    key=ftok(path_ptr, 'a');    ipc_id=ipc(MSGGET, (int)key, flags,0,NULL,0);    … 2.系统V消息队列API 系统V消息队列API共有四个，使用时需要包括几个头文件： #include <sys/types.h>#include <sys/ipc.h>#include <sys/msg.h> 1）int msgget(key_t key, int msgflg) 参数key是一个键值，由ftok获得；msgflg参数是一些标志位。该调用返回与健值key相对应的消息队列描述字。 在以下两种情况下，该调用将创建一个新的消息队列： 如果没有消息队列与健值key相对应，并且msgflg中包含了IPC_CREAT标志位； key参数为IPC_PRIVATE； 参数msgflg可以为以下：IPC_CREAT、IPC_EXCL、IPC_NOWAIT或三者的或结果。 调用返回：成功返回消息队列描述字，否则返回-1。 注：参数key设置成常数IPC_PRIVATE并不意味着其他进程不能访问该消息队列，只意味着即将创建新的消息队列。 2）int msgrcv(int msqid, struct msgbuf *msgp, int msgsz, long msgtyp, int msgflg); 该系统调用从msgid代表的消息队列中读取一个消息，并把消息存储在msgp指向的msgbuf结构中。 msqid为消息队列描述字；消息返回后存储在msgp指向的地址，msgsz指定msgbuf的mtext成员的长度（即消息内容的长度），msgtyp为请求读取的消息类型；读消息标志msgflg可以为以下几个常值的或： IPC_NOWAIT 如果没有满足条件的消息，调用立即返回，此时，errno=ENOMSG IPC_EXCEPT 与msgtyp>0配合使用，返回队列中第一个类型不为msgtyp的消息 IPC_NOERROR 如果队列中满足条件的消息内容大于所请求的msgsz字节，则把该消息截断，截断部分将丢失。 msgrcv手册中详细给出了消息类型取不同值时(>0; <0; =0)，调用将返回消息队列中的哪个消息。 msgrcv()解除阻塞的条件有三个： 消息队列中有了满足条件的消息； msqid代表的消息队列被删除； 调用msgrcv（）的进程被信号中断； 调用返回：成功返回读出消息的实际字节数，否则返回-1。 3）int msgsnd(int msqid, struct msgbuf *msgp, int msgsz, int msgflg); 向msgid代表的消息队列发送一个消息，即将发送的消息存储在msgp指向的msgbuf结构中，消息的大小由msgze指定。 对发送消息来说，有意义的msgflg标志为IPC_NOWAIT，指明在消息队列没有足够空间容纳要发送的消息时，msgsnd是否等待。造成msgsnd()等待的条件有两种： 当前消息的大小与当前消息队列中的字节数之和超过了消息队列的总容量； 当前消息队列的消息数（单位\"个\"）不小于消息队列的总容量（单位\"字节数\"），此时，虽然消息队列中的消息数目很多，但基本上都只有一个字节。 msgsnd()解除阻塞的条件有三个： 不满足上述两个条件，即消息队列中有容纳该消息的空间； msqid代表的消息队列被删除； 调用msgsnd（）的进程被信号中断； 调用返回：成功返回0，否则返回-1。 4）int msgctl(int msqid, int cmd, struct msqid_ds *buf); 该系统调用对由msqid标识的消息队列执行cmd操作，共有三种cmd操作：IPC_STAT、IPC_SET 、IPC_RMID。 IPC_STAT：该命令用来获取消息队列信息，返回的信息存贮在buf指向的msqid结构中； IPC_SET：该命令用来设置消息队列的属性，要设置的属性存储在buf指向的msqid结构中；可设置属性包括：msg_perm.uid、msg_perm.gid、msg_perm.mode以及msg_qbytes，同时，也影响msg_ctime成员。 IPC_RMID：删除msqid标识的消息队列； 调用返回：成功返回0，否则返回-1。 ---------------------------------------------------------------------------------------------------------------------- /*msgserver.c*/ #include <stdlib.h> #include <string.h> #include <errno.h> #include <sys/types.h> #include <sys/ipc.h> #include <sys/msg.h> #include <sys/stat.h> #define   MSG_FILE \"msgserver.c\" #define   BUFFER 255 #define   PERM S_IRUSR|S_IWUSR /* 服务端创建的消息队列最后没有删除,我们要使用ipcrm命令来删除的 */ /* ipcrm -q <msqid> */ struct msgtype {     long mtype;     char buffer[BUFFER+1]; }; int main() {     struct msgtype msg;     key_t key;     int msgid;         if((key=ftok(MSG_FILE,'a'))==-1)     {         fprintf(stderr,\"Creat Key Error:%s/n\", strerror(errno));         exit(1);     }     if((msgid=msgget(key, PERM|IPC_CREAT|IPC_EXCL))==-1)     {         fprintf(stderr, \"Creat Message Error:%s/n\", strerror(errno));         exit(1);     }     printf(\"msqid = %d/n\", msgid);     while(1)     {         msgrcv(msgid, &msg, sizeof(struct msgtype), 1, 0);         fprintf(stderr,\"Server Receive:%s/n\", msg.buffer);         msg.mtype = 2;         msgsnd(msgid, &msg, sizeof(struct msgtype), 0);     }     exit(0); } /* msgclient.c */ #include <stdio.h> #include <stdlib.h> #include <string.h> #include <errno.h> #include <sys/types.h> #include <sys/ipc.h> #include <sys/msg.h> #include <sys/stat.h> #define   MSG_FILE \"msgserver.c\" #define   BUFFER 255 #define   PERM S_IRUSR|S_IWUSR struct msgtype {     long mtype;     char buffer[BUFFER+1]; }; int main(int argc, char **argv) {     struct msgtype msg;     key_t key;     int msgid;         if(argc != 2)     {         fprintf(stderr,\"Usage:%s string/n\", argv[0]);         exit(1);     }         if((key=ftok(MSG_FILE,'a'))==-1)     {         fprintf(stderr,\"Creat Key Error:%s/n\", strerror(errno));         exit(1);     }         if((msgid=msgget(key, PERM))==-1)     {         fprintf(stderr,\"Creat Message  Error:%s/n\", strerror(errno));         exit(1);     }         msg.mtype = 1;     strncpy(msg.buffer, argv[1], BUFFER);     msgsnd(msgid, &msg, sizeof(struct msgtype), 0);      memset(&msg, '/0', sizeof(struct msgtype));     msgrcv(msgid, &msg, sizeof(struct msgtype), 2, 0);     fprintf(stderr, \"Client receive:%s/n\", msg.buffer);     exit(0); }  ","title":"linux消息队列操作 ."},{"content":"一、消息队列的基本概念 消息队列 (也叫做报文队列)是Unix系统V版本中3种进程间通信机制之一。另外两种是信号灯和共享内存。这些IPC机制使用共同的授权方法。只有通过系统调用将标志符传递给核心之后，进程才能存取这些资源。这种系统IPC对象使用的控制方法和文件系统非常类似。使用对象的引用标志符作为资源表中的索引。 消息队列就是一个消息的链表。就是把消息看作一个记录，并且这个记录具有特定的格式以及特定的优先级。对消息队列有写权限的进程可以按照一定的规则添加新消息；对消息队列有读权限的进程则可以从消息队列中读出消息。 Linux采用消息队列的方式来实现消息传递。这种消息的发送方式是：发送方不必等待接收方检查它所收到的消息就可以继续工作下去，而接收方如果没有收到消息也不需等待。这种通信机制相对简单，但是应用程序使用起来就需要使用相对复杂的方式来应付了。新的消息总是放在队列的末尾，接收的时候并不总是从头来接收，可以从中间来接收。 消息队列是随内核持续的并和进程相关，只有在内核重起或者显示删除一个消息队列时，该消息队列才会真正被删除。因此系统中记录消息队列的数据结构 (struct ipc_ids msg_ids)位于内核中，系统中的所有消息队列都可以在结构msg_ids中中找到访问入口。 IPC标识符：每一个I P C目标都有一个唯一的I P C标识符。这里所指的I P C目标是指一个单独的消息队列、一个信号量集或者一个共享的内存段。系统内核使用此标识符在系统内核中指明 I P C目标。 IPC 关键字：想要获得唯一的标识符，则必须使用一个 I P C关键字。客户端进程和服务器端进程必须双方都同意此关键字。这是建立一个客户机/服务器框架的第一步。在System V IPC机制中，建立两端联系的路由方法是和I P C关键字直接相关的。通过在应用程序中设置关键字值，每一次使用的关键字都可以是相同的。一般情况下，可以使用f t o k ( )函数为客户端和服务器端产生关键字值。 二、ipcs 命令 命令ipcs用于读取System V IPC目标的状态。 ipcs -q: 只显示消息队列。 ipcs -s: 只显示信号量。 ipcs -m: 只显示共享内存。 ipcs –help: 其他的参数。       三、消息队列的主要调用   内核中实现消息传递机制的代码基本上都在文件ipc／msg.c中,消息队列的主要调用有下面4个 (1)msgget：调用者提供一个消息队列的键标 (用于表示个消息队列的唯一名字)，当这个消息队列存在的时候， 这个消息调用负责返回这个队列的标识号；如果这个队列不存在，就创建一个消息队列，然后返回这个消息队列的标识号 ，主要由sys_msgget执行。 (2)msgsnd：向一个消息队列发送一个消息，主要由sys_msgsnd执行。 (3)msgrcv：从一个消息队列中收到一个消息，主要由sys_msgrcv执行。 (4)msgctl：在消息队列上执行指定的操作。根据参数的不同和权限的不同，可以执行检索、删除等的操作，主要由sys_msgctl执行。 #include <sys/types.h> #include <sys/ipc.h> #include <sys/msg.h> int     msgget( key_t msgkey , int flag ); 取得一个消息队列的ID，如不存在则建立。 返回值：        成功时：消息队列的ID                 失败时：-1 int     msgsnd( int msqid , struct msgbuf *msgp , size_t msgsiz , int msgflag ); 向消息队列送消息 返回值：        成功时：0                 失败时：-1 msqid是消息队列的ID，size_t msgsiz是结构体成员mdata的大小，msgflag与上一章所讲的共享内存的flag起一样的作用，不过，当这个参数为IPC_NOWAIT的时候，如果消息队列已满，则返回错误值。如果不为IPC_NOWAIT，在消息队列已满 的情况下，会一直等到消息队列有空地方的时候再发送。 注意这里的这个 struct msgbuf *msgp 。要求的格式如下： struct  msgbuf {         long    mtype;         char    mdata[256]; }; long mtype在这里我们用来保存本进程的PID。mdata则是保存要发送的数据。由于mdata的大小不一定（根据实际需要定义），所以这个结构体并没有事先定义好。但是我们定义这个结构体的时候一定要遵循这个规定。你可以改的，只有mdata的大小，和结构体的名称。尽量不要修改结构体成员的名称和类型。实际上，根据mtype，我们还可以有所选择地接受消息。这在下面将会谈到。 int     msgrcv( int msqid , struct msgbuf *msgp , size_t msgsiz , long msgtyp , int msgflag ); 从消息队列取得一个消息 返回值：        成功时：0                 失败时：-1 msqid , *msgp , msgsiz不用说了。long msgtyp是结构体msgbuf的mtype成员。msgflag与上述一样。只不过为IPC_NOWAIT的时候，如果消息队列是空的，则等到有消息可读的时候再读。当不为IPC_NOWAIT的时候，如果消息队列是空的，则返回错误值（与字面上理解的有些相反） 下面这个链接帮助了我更好地理解了msgrcv  中的 long msgtyp这个参数和 struct  msgbuf {         long    mtype;         char    mdata[256]; }; 里的long mtype这个结构体成员。 http://topic.csdn.net/u/20120131/15/235be4a4-3901-41ef-a577-55a5650efeeb.html?14521 同样地，为了控制管理消息队列，一样有一个函数msgctl()如下： #include <sys/types.h> #include <sys/ipc.h> #include <sys/msg.h> int     msgctl( int msqid , int cmd , struct msqid_ds *buf ); 返回值：        成功时：0                 失败时：-1 cmd所指定的值与共享内存部分相同。 最后自己写了一个利用消息队列实现进程通信 基本思路： 我每次将A端发送消息时的消息类型标记为奇数，将B端发送的消息类型为偶数。 A端读取消息类型为偶数的消息（也就是说是从B端发送过来的） B端读取消息类型为奇数的消息（也就是说是从A端发送过来的） //A.c #include <sys/types.h> #include <sys/ipc.h> #include <sys/msg.h> #include <stdio.h> int main() { int count = 0;       /*打印奇数消息类型，发送偶数消息类型*/ int msqid; key_t msgkey; struct msgbuf { long mtype; char mdata[256]; }; struct msgbuf msgdata , *p ; p = &msgdata ; msgkey = ftok( \".\" , 'a' ); /*计算标识符*/ msqid = msgget( msgkey , IPC_CREAT | 0666 ) ;  /*取得消息队列的ID*/ while(1) { printf(\"MiiBotree : \"); fflush( stdin );   /*刷新标准输入缓冲区*/ gets( p->mdata );   /*输入字符串*/ p->mtype = count; if (!msgsnd( msqid , p , sizeof(p->mdata) , 0 ))          /*送消息*/ { count = count + 2; } msgrcv( msqid , p , sizeof(p->mdata) , count+1 , 0 ) ;   /*读消息*/ if (p->mtype % 2 == 1){ printf(\"Firefoxbug:%s\\n\", p->mdata); count += 2; } } return 0; }//B.c #include <sys/types.h> #include <sys/ipc.h> #include <sys/msg.h> #include <stdio.h> int main() { int count = 1; /*打印奇数消息类型，发送偶数消息类型*/ int msqid; key_t msgkey; struct msgbuf { long mtype; char mdata[256]; }; struct msgbuf msgdata , *p ; p = &msgdata ; msgkey = ftok ( \".\" , 'a' ); msqid = msgget( msgkey , IPC_CREAT | 0666 ) ; while(1) { printf(\"Firefoxbug : \"); fflush( stdin ); gets( p->mdata ); p->mtype = count; if (!msgsnd( msqid , p , sizeof(p->mdata) , 0 )) { count = count + 2; } msgrcv( msqid , p , sizeof(p->mdata) , count-1 , 0 ) ; if (p->mtype % 2 == 0){ printf(\"MiiBotree:%s\\n\", p->mdata); count += 2; } } return 0; }A.c和B.c 程序基本上是一样的 这个程序还有一些不完善的地方： 1.每个端口不能连续输入，必须等对方输入以后才 会显示结果。这里我也不清楚怎么回事。gdb的调试还不太会，错误不太会找。希望高手指教，呵呵 2.没有删除消息队列，下次打开时候还会残留以前的消息 最后列出参考资料： http://linux.chinaunix.net/techdoc/develop/2009/04/27/1109110.shtml http://blog.sina.com.cn/s/blog_48c9576b0100joqg.html http://blog.sina.com.cn/s/blog_48c9576b0100joqg.html 《Linux软件工程师（c语言）实用版》","title":"linux消息队列进程通信"},{"content":"国内几家公司和大学提供了开源镜像站，内含主流的开源Linux系统各版本及GNU的各种软件。 网易开源镜像站：http://mirrors.163.com/ <荐> FreeBSD | FreeBSD-updates | archlinux | centos | cpan | cygwin | debian | debian-backports | debian-cd | debian-security | fedora | gentoo | gentoo-portage | kdemod | mandriva | openSUSE | plf | rpmfusion | slackware | tinycorelinux |ubuntu | ubuntu-releases 搜狐开源镜像站：http://mirrors.sohu.com/ 北京交通大学：http://mirror.bjtu.edu.cn/cn/ <教育网荐> 兰州大学：http://mirror.lzu.edu.cn/ <西北高校FTP搜索引擎> 厦门大学：http://mirrors.xmu.edu.cn/ 上海交通大学：http://ftp.sjtu.edu.cn/ 清华大学：http://mirrors.tuna.tsinghua.edu.cn/ http://mirrors.6.tuna.tsinghua.edu.cn/ <IPv6 only> http://mirrors.4.tuna.tsinghua.edu.cn/ <IPv4 only> 天津大学：http://mirror.tju.edu.cn/ 中国科学技术大学：http://mirrors.ustc.edu.cn/ <教育网、电信、IPv6地址> http://mirrors4.ustc.edu.cn/ <教育网、电信> http://mirrors6.ustc.edu.cn/ <IPv6 only> 西南大学：http://linux.swu.edu.cn/swudownload/ 东北大学：http://mirror.neu.edu.cn/ 大连理工大学镜像站： http://mirror.dlut.edu.cn/ 附上几个官方镜像站： kernel 镜像站 : http://www.kernel.org/ Fedora 官方镜像站 ：http://ftp.ps.pl/pub/Linux/fedora-linux/ Debian 官方全球镜像站：http://www.debian.org/mirror/list Ubuntu 官方镜像站 ：http://releases.ubuntu.com/releases/                                  http://cdimage.ubuntu.com/ SUSE 官方镜像站：http://download.opensuse.org/ 开源世界官方镜像站：http://mirror.lupaworld.com/","title":"中国开源镜像站点汇总"},{"content":"Server.c #include <sys/socket.h>#include <sys/types.h>#include <netinet/in.h>#include <arpa/inet.h>#include <stdio.h>#include <stdlib.h>#include <string.h>#include <unistd.h>int main(void) {printf(\"Server is running \\n\");// 地址struct sockaddr_in sockAddr;    /** PROTO: int socket(int domain, int type, int protocol);* domain: AF_INET   ==> ipv5 *         AF_INET6  ==> ipv6*         AF_UNIX   ==> 本地套接字(使用一个文件)* type: SOCK_STREAM (可靠的面向服务或流套接字)*       SOCK_DGEAM  (数据报文服务或数据报文套接字)*       SOCK_SEQPACKET (可靠的连续数据包服务)*       SOCK_RAW (在网络层之上的原始协议)* protocol: 指定实际使用的传输协议。*           IPPORTO_TCP, IPPROTO_SCTP, IPPROTO_UDP, IPPROTO_DCCP 等*           如果是\"0\", 根据选定的domain和type选择使用缺省协议。* 如果发生错误，函数返回值为-1。 否则，函数会返回一个代表新分配的描述符的整数。*/ int socketFD = socket(AF_INET, SOCK_STREAM, 0);if (-1 == socketFD) {perror(\"Cannot create socket\");exit(EXIT_FAILURE);}printf(\" Create socket success! \\n\");memset(&sockAddr, 0, sizeof(struct sockaddr_in));sockAddr.sin_family = AF_INET;sockAddr.sin_port = htons(1100);sockAddr.sin_addr.s_addr = INADDR_ANY;int bind_res = bind(socketFD, (const struct sockaddr *)&sockAddr, sizeof(struct sockaddr_in));if (-1 == bind_res) {perror(\" Error bind failed!\");close(socketFD);exit(EXIT_FAILURE);}printf(\"Bind success ! \\n\");if (-1 == listen(socketFD, 10)){perror(\"Error Listen failed!\");close(socketFD);exit(EXIT_FAILURE);}printf(\"Listen the port ... \\n\");for (;;) {int connectFD = accept(socketFD, NULL, NULL);if (0 > connectFD) {perror(\"Error Accept failed!\");close(socketFD);exit(EXIT_FAILURE);}printf(\"Accept one client ... \\n\");char buf[15];ssize_t rval = recv(connectFD, buf, 15, 0);printf(\"Receive from client... \\n\");if (rval < 0) {perror(\"Error Receive failed!\");shutdown(connectFD, SHUT_RDWR);close(connectFD);close(socketFD);exit(EXIT_FAILURE);} if (rval == 0) {printf(\"Ending connection \\n\");}else {printf(\"Received from client is: \\n\");printf(\"The buf is %s\", buf);}shutdown(connectFD, SHUT_RDWR);close(connectFD);}close(socketFD);return 0;} Client.c #include <sys/types.h>#include <sys/socket.h>#include <netinet/in.h>#include <arpa/inet.h>#include <stdio.h>#include <stdlib.h>#include <string.h>#include <unistd.h>int main(void) {struct sockaddr_in sockAddr;int res;int socketFD = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);if (-1 == socketFD) {perror (\"Cannot create socket\");exit(EXIT_FAILURE);}memset(&sockAddr, 0, sizeof(struct sockaddr_in));sockAddr.sin_family = AF_INET;sockAddr.sin_port = htons(1100);res = inet_pton(AF_INET, \"192.168.0.101\", &sockAddr.sin_addr);if (0 > res) {perror (\"Error: first parameter is not a valid address family\");close(socketFD);exit(EXIT_FAILURE);} else if (0 == res) {perror (\"Error: Secend parameter does not contain valid ip\");close(socketFD);exit(EXIT_FAILURE);}if (-1 == connect(socketFD, (const struct sockaddr *)&sockAddr, sizeof(struct sockaddr_in))) {perror(\"Error Cannot connect to server!\");close(socketFD);exit(EXIT_FAILURE);}char buf[15] = \"Hello World\\n\";if (0 > send(socketFD, buf, 15, 0)) {perror(\"Error Cannot send on stream socket\");close(socketFD);exit(EXIT_FAILURE);}shutdown(socketFD, SHUT_RDWR);printf(\"Send data is: %s\", buf);close(socketFD);return 0;}","title":"Linux下C语言socket编程"},{"content":"Shell特殊字符 # 注释 表示注释   #注释 在引号中间和\\#等表示#本身 echo ${PATH#*:} # 参数替换,不是一个注释 echo $(( 2#101011 )) # 数制转换,不是一个注释   ; 分隔 命令分隔，在一行中写多个命令  echo \"aa\" ; echo \"bb\" 在条件中的if和then如果放在同一行，也用;分隔 ;; case条件的结束   . 命令相当于source命令 命令：source 文件名的前缀，隐藏文件 目录：.当前目录，..父目录 正则表达式：匹配任意单个字符 \"\" 部分引用 支持通配符扩展   '  ‘ 全引用，不进行通配符扩展   \\ 转义   / 目录分隔符   ,  多个命令都被执行，但返回最后一个   ` 后置引用   : 操作符 空操作 死循环：    while : 在if/then中表示什么都不做，引出分支 设置默认参数：   : ${username=`whoami`} 变量替换：    : ${HOSTNAME?} ${USER?} ${MAIL?} 在和 > (重定向操作符)结合使用时,把一个文件截断到0 长度,没有修改它的权限；如果文件在之前并不存在,那么就创建它.如:        : > data.xxx #文件\"data.xxx\"现在被清空了. 与 cat /dev/null >data.xxx 的作用相同 然而,这不会产生一个新的进程,因为\":\"是一个内建命令. 在和>>重定向操作符结合使用时,将不会对想要附加的文件产生任何影响. 如果文件不存在,将创建. * 匹配0个或多个字符；数学乘法；**幂运算   ? 匹配任意一个字符；但在((a>b?a:b))表示c语言中的三目运算   $  取变量的值 echo $PATH 正则表达式中表示行的结尾 ${} 参数替换 ${PAHT} $* 所有参数 $# 参数个数 $$ 进程的ID $? 进程的返回状态 ( ) 命令组，在一个子Shell中运行   (a=3;echo $a) 其中定义的变量在后面不可用 数组初始化： array=(a,b,c) { } 代码块，即一个匿名函数，但其中定义的变量在后面依然可用   { } \\; 用在find的-exec中 $find -name *.txt -exec cat {} \\;   [ ] 测试 [-z $1] 数组元素 a[1]='test' [[]]表示测试 使用[[ ... ]]条件判断结构, 而不是[ ... ], 能够防止脚本中的许多逻辑错误. 比如, &&, ||, <, 和> 操作符能够正常存在于[[ ]]条件判断结构中, 但是如果出现在[ ]结构中的话, 会报错. (( ))数学运算 在正则表达式中表示范围 [a-z] < <<  >  重定向和进程替换  ls -al > a.txt   >  <  还用在ASCII比较 if [[ \"$veg1\" < \"$veg2\" ]]   \\<,\\> 正则表达式中的单词边界.如:bash$grep '\\<the\\>' textfile   | 管道   >| 强制重定向(即使设置了noclobber 选项--就是-C 选项).这将强制的覆盖一个现存文件.   || 逻辑或操作 ；用在两个命令之间的时候，表示在前一个命令结束时，若返回值为 false，继续执行下一个命令   && 逻辑与；用在两个命令之间的时候，表示在前一个命令结束时，若返回值为 true，继续执行下一个命令   & 后台运行   - 参数选项 减号 重定向stdin和stdout：cd /source/directory && tar cf - . ) | (cd /dest/directory && tar xpvf -) 先前的工作目录 cd - 注：使用-开头的文件名和变量名可能会出现一些问题 +   一个命令或者过滤器的选项标记.   ~ home目录 ~+ 当前工作目录 ~- 先前工作目录   ^ 正则表达式中表示行首   $IFS 用来做一些输入命令的分隔符, 默认情况下是空白.     控制字符 修改终端或文本显示的行为. . 控制字符以CONTROL + key这种方式进行组合(同时按下). 控制字符也可以使用8进制或16进制表示法来进行表示, 但是前边必须要加上转义符. 控制字符在脚本中不能正常使用. Ctl-B退格(非破坏性的), 就是退格但是不删掉前面的字符. Ctl-C终结一个前台作业. Ctl-D   从一个shell中登出(与exit很相像).             \"EOF\"(文件结束). 这也能从stdin中终止输入.             在console或者在xterm窗口中输入的时候, Ctl-D将删除光标下字符. 当没有字符时, Ctl-D将退出当前会话, 在一个xterm窗口中, 则会产生关闭此窗口的效果. Ctl-G \"哔\" (beep). 在一些老式的打字机终端上, 它会响一下铃. Ctl-H \"退格\"(破坏性的), 就是在退格之后, 还要删掉前边的字符. Ctl-I 水平制表符. Ctl-J 重起一行(换一行并到行首). 在脚本中, 也可以使用8进制表示法 -- '\\012' 或者16进制表示法 -- '\\x0a' 来表示. Ctl-K垂直制表符. Ctl-L 清屏(清除终端的屏幕显示). 在终端中, 与clear命令的效果相同. 当发送到打印机上时, Ctl-L会让打印机将打印纸卷到最后. Ctl-M 回车. Ctl-Q 恢复(XON).在一个终端中恢复stdin. Ctl-S 挂起(XOFF).          在一个终端中冻结stdin. (使用Ctl-Q可以恢复输入.) Ctl-U 删除光标到行首的所有字符. 在某些设置下, 不管光标的所在位置Ctl-U都将删除整行输入. Ctl-V当输入字符时, Ctl-V允许插入控制字符.  Ctl-V主要用于文本编辑. Ctl-W  当在控制台或一个xterm窗口敲入文本时, Ctl-W将会删除当前光标到左边最近一个空格间的全部字符. 在某些设置下, Ctl-W将会删除当前光标到左边第一个非字母或数字之间的全部字符.","title":"Linux Shell特殊字符和控制字符"},{"content":"PC机上Linux内核升级 一、        准备工作 1.        编译环境准备 首先编译环境的搭建，我是从虚拟机下的redhat RHEL5.3的系统环境进行全部工作的，为了给编译内核一个干净的环境，我在虚拟机下重新安装了Redhat系统。现在比较流行的操作系统还有centos，Fedora，Debian等Linux操作系统   其次，从官网上下载最新稳定版内核http://www.kernel.org/选择好版本后，下载Full Source 全部的源码。   2.        下载解压内核文件   （编译linux3.3.5的内核会出现类型冲突错误，原因是当前Linux系统的c库版本低，参见http://www.oschina.net/question/181920_59668  当编译3.x以上的内核都会出现以上的错误，故采用2.6.27.62的内核进行编译）   把下载的内核文件inux-2.6.27.62.tar.bz2放到系统里面，我的路径是/home/xiaoxiao 将文件解压出来： #cd /home/xiaoxiao #tar –xvfj linux-2.6.27.62.tar.bz2 解压完成后，会生成一个linux-2.6.27.62目录。 解压参数说明： -x解压；-v输出信息；-f 指定解压文件；-j 针对.bz2文件解压   3.        内核升级工具下载安装 initrd：Linux初始 RAM磁盘（initrd）是在系统引导过程中挂载的一个临时根文件系统，用来支持两阶段的引导过程。初始 RAM磁盘（initrd）是在实际根文件系统可用之前挂载到系统中的一个初始根文件系统。initrd与内核绑定在一起，并作为内核引导过程的一部分进行加载。内核然后会将这个 initrd文件作为其两阶段引导过程的一部分来加载模块，这样才能稍后使用真正的文件系统，并挂载实际的根文件系统。 在桌面或服务器Linux 系统中，initrd 是一个临时的文件系统。其生存周期很短，只会用作到真实文件系统的一个桥梁。在没有存储设备的嵌入式系统中，initrd 是永久的根文件系统。 在进行内核编译时,需要进行制作initrd.img.在Fedora下面一般是用mkinitrd,而在Ubuntu/Debian下是用mkintramfs. 从网上下载升级工具：module-init-tools-3.5.tar.bz2 将文件解压，进入目录后，执行命令安装; # tar jvxf module-init-tools-3.5.tar.bz2 (解压module-init-tools)  # cd module-init-tools-3.2 (由/usr/src目录进入module-init-tools目录下) #./configure --prefix=/  这样就安装好了，可以用mkinitrd –help 查看是否安装成功   二、        内核定制   1.      内核定制配置 # cd /home/xiaoxiao/linux-2.6.27.62 (进入到/home/xiaoxiao/linux-2.6.27.62目录下) # make mrproper (该命令可确保源代码目录下没有不正确的.o文件) # make menuconfig (配置内核各选项)   配置内核可以根据需要与爱好使用下面命令中的一个： #make config（基于文本的最为传统的配置界面，不推荐使用） #make menuconfig（基于文本选单的配置界面，字符终端下推荐使用） #make xconfig（基于图形窗口模式的配置界面，需要QT开发库的支持，Xwindow下推荐使用） #make oldconfig（如果只想在原来内核配置的基础上修改一些小地方，会省去不少麻烦） 　　这三个命令中，make xconfig的界面最为友好，如果你可以使用Xwindow，那么就推荐你使用这个命令。 如果你不能使用Xwindow，那么就使用make menuconfig好了。界面虽然比上面一个差点，总比make config的要好多了。 具体的内核配置选项请参见其它参考资料，这里我们可以使用默认配置即可。   （注意：即时只用默认配置，我们也要make menuconfig下，进入图形界面后也要保存退出，保存退出后会在当前目录下产生一个.config配置文件，下一步的make bzImage就会根据这个配置文件来进行内核编译工作，否则不能进行编译工作）     @1. 注意：我采用的redhat5.3 在make menuconfig时会出现这种错误   [root@localhost linux]# make menuconfig   HOSTCC  scripts/basic/fixdep   HOSTCC  scripts/kconfig/conf.o  *** Unable to find the ncurses libraries or the  *** required header files.  *** 'make menuconfig' requires the ncurses libraries.  ***  *** Install ncurses (ncurses-devel) and try again.  *** make[1]: *** [scripts/kconfig/dochecklxdialog] Error 1 make: *** [menuconfig] Error 2   由于redhat系统默认没有安装ncurses所以找不到ncurses libraries 解决方法：用虚拟机的光驱加载redhat的iso文件，在iso文件的Server文件夹中有很多你所需要的安装程序。 进入Server目录：cd /media/RHEL_5.4 i386 DVD/Server 使用命令： ls -al | grep ncurses 即可找到所需要安装的程序 使用命令：“rpm -ivh 文件名  ”即可安装。   三、        内核以及模块的编译安装 1.      编译内核及模块 在/home/xiaoxiao/linux-2.6.27.62目录下，执行以下命令即可编译。编译需要一段时间，给自己倒杯茶耐心等候吧！ # make dep (建立编译时所需的从属文件。注意：如果内核从未编译过，此步可跳过) # make clean (清除内核编译的目标文件。注意：如果内核从未编译过，此步可跳过) # make bzImage (注意大小写。这一步才是真正编译内核) # make modules (编译可加载模块)   内核编译成功后，会在/home/xiaoxiao/linux-2.6.27.62/arch/x86/boot目录中生成一个新内核的映像文件bzImage。   2.      安装模块及内核文件(安装过程中一定要保证根分区有足够的空间！) # make modules_install (安装可加载模块) 安装成功后，系统会在/lib/modules目录下生成一个2.6.27.62子目录，里面存放着新内核的所有可加载模块。 # make install (安装新内核)        make install命令会自动将编译生成的Linux系统内核(/home/xiaoxiao/linux-2.6.27.62/arch/x86/boot/compressed/vmlinux)和符号文件(/home/xiaoxiao/linux-2.6.27.62/System.map)拷贝到/boot目录下，同时生成链接文件vmlinuz和System.map分别指向vmlinuz-2.6.27.62和System.map-2.6.27.62文件；并在/boot的目录下自动生成内核引导临时根文件系统(initrd-2.6.27.62.img)并且将修改 grub配置文件(/boot/grub/grub.conf)引导项，重写引导记录。   查看此grub文件的配置内容： default=1 timeout=5 splashimage=(hd0,0)/grub/splash.xpm.gz hiddenmenu title Red Hat Enterprise Linux Server (2.6.27.62)         root (hd0,0)         kernel /vmlinuz-2.6.27.62 ro root=LABEL=/ rhgb quiet         initrd /initrd-2.6.27.62.img title Red Hat Enterprise Linux Server (2.6.18-164.el5)         root (hd0,0)         kernel /vmlinuz-2.6.18-164.el5 ro root=LABEL=/ rhgb quiet         initrd /initrd-2.6.18-164.el5.img 发现已经将2.6.27.62的内核的引导添加到grub文件中，手动将hiddenmenu注释掉（在行首添加一个#号），否则系统重新启动后不能显示grub菜单。   四、        内核的启动 1.      启动2.6.27内核 重新启动虚拟机系统，将会出现grub的引导菜单，通过键盘的上下键来选择2.6.27.62的内核启动。 进入系统后使用命令查看内核的版本号； #uname –a Linux localhost.localdomain 2.6.27.62 #1 SMP Wed Sep 12 01:31:11 PDT 2012 i686 i686 i386 GNU/Linux 可以看到内核2.6.27.62已经启动，至此大功告成。   五、        相关知识 1.     相关编译工具版本 本次内核编译新内核所涉及软件版本 “gcc –version”可查寻GCC版本 “make –v”可查询 Gnu make版本 “ld –V（v）可查询GNU ld版本 “fdformat --version”命令检查 util-linux版本 “insmod –V”检查module-init-tools 版本- “tune2fs –version”命令可检查 tune2fs 版本 “pppd --version”命令可检查pppd version 2.4.4 “isdnctrl 2>&1|grep version” 命令可检查isdnctrl version 3.9   注：之前编译3.5版本的内核不通过，出现类型冲突错误，初步分析也许跟gcc，make，ld的版本有关系，网上有人说在centos6.0下可以编译通过，故装了个centos6.3系统验证了一下，结果表明3.5内核能编译通过。 现在比较一下redhat RHEL5.3 和centos6.3 相关的版本信息： redhat RHEL5.3： # gcc --version gcc (GCC) 4.1.2 20080704 (Red Hat 4.1.2-46) Copyright (C) 2006 Free Software Foundation, Inc. # make -v GNU Make 3.81 #ld -V GNU ld version 2.17.50.0.6-12.el5 20061020 CentOs6.3： # gcc --version gcc (GCC) 4.4.6 20120305 (Red Hat 4.4.6-4) # make -v GNU Make 3.81 ld -V GNU ld version 2.20.51.0.2-5.34.el6 20100205   Supported emulations:    elf_i386    i386linux    elf_x86_64    elf_l1om   2.      vmlinux vmlinuz bzimage zimage 区别和联系   在编译内核的过程中会产生这几种内核映像文件   vmlinuz 是可引导的、压缩的内核。“vm”代表“Virtual Memory”。Linux 支持虚拟内存，不像老的操作系统比如DOS有640KB内存的限制。Linux能够使用硬盘空间作为虚拟内存，因此得名“vm”。vmlinuz是可执行 的Linux内核，它位于/boot/vmlinuz，它一般是一个软链接。 vmlinuz 的建立有两种方式。一是编译内核时通过“make zImage”创建，然后通过：“cp /usr/src/linux-2.4/arch/i386/linux/boot/zImage /boot/vmlinuz”产生。zImage适用于小内核的情况，它的存在是为了向后的兼容性。二是内核编译时通过命令make bzImage创建，然后通过：“cp /usr/src/linux-2.4/arch/i386/linux/boot/bzImage /boot/vmlinuz”产生。bzImage是压缩的内核映像，需要注意，bzImage不是用bzip2压缩的，bzImage中的bz容易引起 误解，bz表示“big zImage”。 bzImage中的b是“big”意思。 zImage(vmlinuz)和bzImage(vmlinuz)都是用gzip压缩的。它们不仅是一个压缩文件，而且在这两个文件的开头部分内嵌有gzip解压缩代码。所以你不能用gunzip 或 gzip –dc解包vmlinuz。 内 核文件中包含一个微型的gzip用于解压缩内核并引导它。两者的不同之处在于，老的zImage解压缩内核到低端内存(第一个640K)，bzImage 解压缩内核到高端内存(1M以上)。如果内核比较小，那么可以采用zImage 或bzImage之一，两种方式引导的系统运行时是相同的。大的内核采用bzImage，不能采用zImage。 vmlinux是未压缩的内核，vmlinuz是vmlinux的压缩文件。 vmlinux 是ELF文件，即编译出来的最原始的文件。 vmlinuz应该是由ELF文件vmlinux经过OBJCOPY后，并经过压缩后的文件 zImage是vmlinuz经过gzip压缩后的文件，适用于小内核 bzImage是vmlinuz经过gzip压缩后的文件，适用于大内核 通常情况下是不能用vmlinuz解压缩得到vmlinux的   3.      grub.conf 文件解释   default=1 timeout=5 splashimage=(hd0,0)/grub/splash.xpm.gz hiddenmenu title Red Hat Enterprise Linux Server (2.6.27.62)           root (hd0,0)           kernel /vmlinuz-2.6.27.62 ro root=LABEL=/ rhgb quiet           initrd /initrd-2.6.27.62.img        title Red Hat Enterprise Linux Server (2.6.18-164.el5)            root (hd0,0)           kernel /vmlinuz-2.6.18-164.el5 ro root=LABEL=/ rhgb quiet        initrd /initrd-2.6.18-164.el5.img          default: 表示默认启动的操作系统，0表示第一个，1表示第二个，依次类推… 这里是default=1，表示默认启动Red Hat Enterprise Linux Server (2.6.18-164.el5)内核的操作系统 timeout:  超时时间，表示的是出现GRUB界面后,无操作情况下进入default设定的操作系统的时间,如果上下移动选择,则该选项无效 splashimage：指定启动菜单的背景文件(xpm 图像或其gzip 压缩文件)。 Hiddenmenu: 表示隐藏GRUB的启动菜单,直接进入由default庙宇的操作系统中去,为一可选项,删除该项，就可以在开机时显示grub菜单。 title：定义启动操作系统的菜单项名称； root (hd0,0): 设置 Grub 的根设备 (root)为 Linux 内核所在分区； kernel: 后跟 Linux 内核文件为参数，加载 Linux 内核文件； initrd：后跟initrd文件，加载initrd文件系统，用于引导内核的一部分。   grub相关资料可参考： http://blog.csdn.net/zhuliting/article/details/5502636 http://blog.163.com/rao_warrior/blog/static/137801616201022110402347/   六、        PC机上Linux内核升级小结 经过一天的努力，终于在RHEL5.3的系统上成功升级内核，虽然只是从2.6.18升级到2.6.27 ，由于在该系统上编译3.5内核出错（原因已经在第五节分析过了），故升级了2.6.27的版本。编译的过程中，跳过了一个重要的过程，那就是内核的定制，这个需要花更多的时间去搞清楚这些配置选项的功能。 现在抛开Linux内核配置，编译的过程中主要遇到了这几个问题： 第一个是在第二页中已经描述（@1）； 第二个是Linux系统分区的空间问题，我在重装的centos系统中安装3.5内核时，/boot目录已经使用100%，所以在安装操作系统的时候注意手动分区，预留足够大的空间。 第三个是一定要安装mkinitrd软件包，参见第一页。make install 的过程中，会调用这个工具来生成initrd文件来支持内核的启动。","title":"linux内核编译"},{"content":"1、segment fault segment fault是几乎多有C程序员都会碰到的问题，多为内存问题，因为glibc库中基本所有的函数都默认形参指针是非空的，这样以下原因就可能导致段错误： (1)引用一个包含非法值的指针（当然包括空指针）。 (2)未得到正确的权限的时候进行访问，例如往只读的内存地址写数据。 (3)内存越界（数组越界，变量类型不一致等） 调试segment fault的几种常见方法： (1) 打印log，这种方法的前提是你知道在哪行代码附近会出问题； (2) gdb调试，对于小代码，可以逐行调试，大工程就比较头疼咯； (3) core dump调试，当一个程序崩溃时，在进程当前工作目录的core文件中复制了该进程的存储图像。core文件仅仅是一个内存映象(同时加上调试信息)，主要是用来调试的。 首先，设置core大小 #设置core大小为无限 ulimit -c unlimited #设置文件大小为无限 ulimit unlimited 使用core文件调试程序 看下面的例子： /*core_dump_test.c*/#include <stdio.h>const char *str = \"test\";void core_test(){    str[1] = 'T';}int main(){    core_test();    return 0;}   编译： gcc–g core_dump_test.c -o core_dump_test 如果需要调试程序的话，使用gcc编译时加上-g选项，这样调试core文件的时候比较容易找到错误的地方。 执行： ./core_dump_test 段错误 调式core文件 core文件是个二进制文件，需要用相应的工具来分析程序崩溃时的内存映像,在Linux下可以用GDB来调试core文件。 gdb core_dump_test core Loaded symbols for /lib/ld-linux.so.2 #0 0x080482fd in core_test () at core_dump_test.c:7 7           str[1] = 'T'; (gdb) where #0 0x080482fd in core_test () at core_dump_test.c:7 #1 0x08048317 in main () at core_dump_test.c:12 #2 0x42015574 in __libc_start_main () from /lib/tls/libc.so.6 GDB中键入where，就会看到程序崩溃时堆栈信息（当前函数之前的所有已调用函数的列表（包括当前函数），gdb只显示最近几个），我们很容易找到我们的程序在最后崩溃的时候调用了core_dump_test.c第7行的代码，导致程序崩溃。注意：在编译程序的时候要加入选项-g。您也可以试试其他命令，　如　fram、list等。更详细的用法，请查阅GDB文档。          ","title":"linux下调试方法记录"},{"content":"相关函数 　　open（打开文件） 　　相关函数 　　read，write，fcntl，close，link，stat，umask，unlink，fopen 　　头文件 　　#include<sys/types.h> 　　#include<sys/stat.h> 　　#include<fcntl.h> 　　定义函数 　　int open( const char * pathname,int flags); 　　int open( const char * pathname,int flags,mode_t mode); 函数说明 　　参数pathname 指向欲打开的文件路径字符串。下列是参数flags 所能使用的标志位： 　　O_RDONLY 以只读方式打开文件 　　O_WRONLY 以只写方式打开文件 　　O_RDWR 以可读写方式打开文件。 　　上述三种标志位是互斥的，也就是不可同时使用，但可与下列的标志位利用OR(|)运算符组合。 　　O_CREAT 若欲打开的文件不存在则自动建立该文件。 　　O_EXCL 如果O_CREAT 也被设置，此指令会去检查文件是否存在。文件若不存在则建立该文件，否则将导致打开文件错误。此外，若O_CREAT与O_EXCL同时设置，并且欲打开的文件为符号连接，则会打开文件失败。 　　O_NOCTTY 如果欲打开的文件为终端机设备时，则不会将该终端机当成进程控制终端机。 　　O_TRUNC 若文件存在并且以可写的方式打开时，此标志位会令文件长度清为0，而原来存于该文件的 资料也会消失。 　　O_APPEND 当读写文件时会从文件尾开始移动，也就是所写入的数据会以附加的方式加入到文件后面。 　　O_NONBLOCK 以不可阻断的方式打开文件，也就是无论有无数据读取或等待，都会立即返回进程之中。 　　O_NDELAY 同O_NONBLOCK。 　　O_SYNC 以同步的方式打开文件。 　　O_NOFOLLOW 如果参数pathname 所指的文件为一符号连接，则会令打开文件失败。 　　O_DIRECTORY 如果参数pathname 所指的文件并非为一目录，则会令打开文件失败。 参数mode 组合 　　此为Linux2.2以后特有的标志位，以避免一些系统安全问题。参数mode 则有下列数种组合，只有在建立新文件时才会生效，此外真正建文件时的权限会受到umask值所影响，因此该文件权限应该为（mode-umaks）。 　　S_IRWXU 00700 权限，代表该文件所有者具有可读、可写及可执行的权限。 　　S_IRUSR 或S_IREAD， 00400权限，代表该文件所有者具有可读取的权限。 　　S_IWUSR 或S_IWRITE，00200 权限，代表该文件所有者具有可写入的权限。 　　S_IXUSR 或S_IEXEC， 00100 权限，代表该文件所有者具有可执行的权限。 　　S_IRWXG 00070权限，代表该文件用户组具有可读、可写及可执行的权限。 　　S_IRGRP 00040 权限，代表该文件用户组具有可读的权限。 　　S_IWGRP 00020权限，代表该文件用户组具有可写入的权限。 　　S_IXGRP 00010 权限，代表该文件用户组具有可执行的权限。 　　S_IRWXO 00007权限，代表其他用户具有可读、可写及可执行的权限。 　　S_IROTH 00004 权限，代表其他用户具有可读的权限 　　S_IWOTH 00002权限，代表其他用户具有可写入的权限。 　　S_IXOTH 00001 权限，代表其他用户具有可执行的权限。 返回值 　　若所有欲核查的权限都通过了检查则返回文件描述符，表示成功，只要有一个权限被禁止则返回-1。 错误代码 　　EEXIST 参数pathname 所指的文件已存在，却使用了O_CREAT和O_EXCL标志位。 　　EACCESS 参数pathname所指的文件不符合所要求测试的权限。 　　EROFS 欲测试写入权限的文件存在于只读文件系统内。 　　EFAULT 参数pathname指针超出可存取内存空间。 　　EINVAL 参数mode 不正确。 　　ENAMETOOLONG 参数pathname太长。 　　ENOTDIR 参数pathname不是目录。 　　ENOMEM 核心内存不足。 　　ELOOP 参数pathname有过多符号连接问题。 　　EIO I/O 存取错误。 附加说明 　　使用access()作用户认证方面的判断要特别小心，例如在access()后再作open()空文件可能会造成系统安全上的问题。   O_LARGEFILE       linux大文件问题     32位LINUX系统对文件大小有个限制,最大只能达到2^31 - 1字节,也就是2G,即使文件系统支持更大的4000G的文件.具体为啥有这个限制我也说不清.只是在做一个数据库的TPC-H测试时发现的.上网找了几个资料,汇总一下大文件的解决之道.       对于用C语言的API打开的文件,也就是用fopen(const char *filename, int mode)方式打开的文件,只需要在编译时加入一个参数,告诉系统在文件内部使用64位的偏移地址就行了:-D_USE_FILE_OFFSET_BITS=64,原有程序不需要做任何改动,保持程序的可移植性.       另外,也可以使用LINUX自己的库函数进行文件操作:open(const char *filename, int flags, int mode)或者open(const char *filename, int flags)打开文件.只是其中的flags参数需要多加一个O_LARGEFILE.如下所示:   int fp = open(\"myfile\", O_WRONLY | O_TRUNC | O_CREAT | O_LARGEFILE, 644);        然而,对于O_LARGEFILE的引用却来的很不方便,在加入所有必需的头文件fcntl.h, sys/stat.h, sys/types.h等等后,还会被编译器提示O_LARGEFILE没有定义.这时,需要使用下面的方法使O_LARGEFILE变的有意义:        1 #define __USE_LARGEFILE64        2 #include <fcntl.h>        3 // 其它头文件,等等        4         5 int fp = open(\"myfile\", O_TRUNC | O_CREAT | O_RDWR | O_LARGEFILE, 644);  ","title":"Linux 系统函数记录 open"},{"content":"Linux c 函数　　#include<unistd.h> 　　int dup（int fd）； 　　int dup2（int fd1，int fd2）； 　　两个均为复制一个现存的文件的描述 　　两个函数的返回：若成功为新的文件描述，若出错为-1； 　　由dup返回的新文件描述符一定是当前可用文件描述中的最小数值。用dup2则可以用fd2参数指定新的描述符数值。如果fd2已经打开，则先关闭。若fd1=fd2，则dup2返回fd2，而不关闭它。通常使用这两个系统调用来重定向一个打开的文件描述符。","title":"Linux 系统函数记录 dup"},{"content":"使用C语言编写程序需要获得当前精确时间（UNIX到现在的时间），或者为执行计时，可以使用gettimeofday()函数。它的[1]： 　　#include <sys/time.h> 　　int gettimeofday(struct timeval *tv, struct timezone *tz); 　　其参数tv是保存获取时间结果的结构体，参数tz用于保存时区结果（若不使用则传入NULL即可）。 　　结构体timeval的定义为： 　　struct timeval { 　　long int tv_sec; // 秒数 　　long int tv_usec; // 微秒数 　　} 　　它获得的时间精确到微秒（1e-6 s)量级。在一段代码前后分别使用gettimeofday可以计算代码执行时间： 　　struct timeval tv_begin, tv_end; 　　gettimeofday(&tv_begin, NULL); 　　foo(); 　　gettimeofday(&tv_end, NULL); 　　执行时间（微秒） = 1000000 * (tv_end.tv_sec - tv_begin.tv_sec) + tv_end.tv_usec - tv_begin.tv_usec;","title":"Linux 系统函数记录 gettimeofday"},{"content":"相关函数 　　dup，open，fseek 表头文件 　　#include<sys/types.h> 　　#include<unistd.h> 定义函数 　　off_t lseek(int fildes,off_t offset ,int whence); 函数说明 　　每一个已打开的文件都有一个读写位置，当打开文件时通常其读写位置是指向文件开头，若是以附加的方式打开文件(如O_APPEND)，则读写位置会指向文件尾。当read()或write()时，读写位置会随之增加，lseek()便是用来控制该文件的读写位置。参数fildes 为已打开的文件描述词，参数offset 为根据参数whence来移动读写位置的位移数。 　　Offset：偏移量，每一读写操作所需要移动的距离，单位是字节的数量，可正可负（向前移，向后移）。 参数 　　whence为下列其中一种:（SEEK_SET,SEEK_CUR和SEEK_END和依次为0，1和2）. 　　SEEK_SET 将读写位置指向文件头后再增加offset个位移量。 　　SEEK_CUR 以目前的读写位置往后增加offset个位移量。 　　SEEK_END 将读写位置指向文件尾后再增加offset个位移量。 　　当whence 值为SEEK_CUR 或SEEK_END时，参数offet允许负值的出现。 　　下列是较特别的使用方式: 　　1) 欲将读写位置移到文件开头时: 　　lseek（int fildes,0,SEEK_SET）； 　　2) 欲将读写位置移到文件尾时: 　　lseek（int fildes，0,SEEK_END）； 　　3) 想要取得目前文件位置时: 　　lseek（int fildes，0,SEEK_CUR）； 返回值 　　当调用成功时则返回目前的读写位置，也就是距离文件开头多少个字节。若有错误则返回-1，errno 会存放错误代码。 附加说明 　　Linux系统不允许lseek（）对tty装置作用，此项动作会令lseek（）返回ESPIPE。","title":"linux 系统函数记录 lseek"},{"content":"ntohl() 简述 含义 　　将一个无符号长整形数从网络字节顺序转换为主机字节顺序。 头文件 　　#include <arpa/inet.h> 函数形式 　　uint32_t ntohl(uint32_t netlong); 　　netlong：一个以网络[字节顺序表达的32位数。 注释 　　本函数将一个32位数由网络字节顺序转换为主机字节顺序。 返回值 　　ntohl()返回一个以主机字节顺序表达的数。 参见 　　htonl(), htons(), ntohs().","title":"Linux C语言开发函数学习 之一 ntohl()"},{"content":"——Lilytask2.5基于Win32thread的实现 段孟成(dmc@net.pku.edu.cn)          Lilytask是以任务为单位的并行编程模型，Lilytask2.5β版最初是在Linux系统上基于POSIX thread实现的，为了更好的适应并行计算环境中的异构性，又在β版的基础上实现了for Windows版，在实现过程中，需要用Win32thread library替换POSIXthread library，下文将主要描述POSIX thread(下文称之pthread)与Win32thread的关系以及在Lilytask2.5 for Windows中的具体实现。   一．什么是线程。       线程(thread)是为了提高系统内程序的并发(concurrency)执行程度而提出来的概念，它是比进程更小的能够独立运行的基本单位。在引入线程的系统中，线程是处理器调度(schedule)的基本单位，而传统的进程则只是资源分配的基本单位。同一进程中的线程共享这个进程的全部资源与地址空间，除此之外，线程基本上不拥有其他任何系统资源，当然，每个线程也必须拥有自己的程序计数器(Program Counter)，寄存器堆(register file)和栈(stack)等等。即线程是一个轻量级实体(light-weight entity)，它的结构(thread structure)相对简单，在切换速度上非常得快，同一进程中的线程切换不会引起进程的切换，对于并行计算来讲，有效的利用线程能够改善计算的效率，简化计算的复杂性，所以Lilytask正是基于线程实现的。   二．线程的标准。        目前，主要有三种不同的线程库的定义，分别是Win32，OS/2，以及POSIX，前两种定义只适合于他们各自的平台，而POSIX 定义的线程库是适用于所有的计算平台的，目前基本上所有基于UNIX的系统都实现了pthread。本文主要讨论Win32和POSIX的线程定义。 线程的实现一般有两种方法，一是用户级的线程(user-level thread library)，另一种是核心级的线程(kernel-level library)。对于用户级的线程来说，它只存在于用户空间中(user space)，它的创建，撤销和切换都不利用系统调用，与核心无关；而核心级的线程依赖于核心，它的创建，撤销和切换都是由核心完成的，系统通过核心中保留的线程控制块来感知线程的存在并对线程进行控制。Win32thread是基于核心级线程实现的，而pthread部分是基于用户级线程实现的。   三．pthread和Win32thread的具体实现。 1．关于线程创建和消亡的操作。 1.1 创建和撤销一个POSIX线程 pthread_create(&tid, NULL, start_fn, arg); pthread_exit(status); 1.2 创建和撤销一个Win32线程 CreateThread(NULL, NULL, start_fn, arg, NULL, NULL); ExitThread(status); start_fn是该线程要执行的代码的入口。线程创建后，就拥有了一个TID(thread ID)，以后对于该线程的操作都是通过TID来进行的。Win32虽然也定义了TID，但是它对于线程的操作是通过另外定义的一个句柄(handle)来进行的，总之，在线程创建完毕后，都有一个唯一了标识符来确定对该线程的引用。线程的撤销可以显式的调用上面列举的函数来实现，如果没有显式调用撤销函数，则该线程执行的函数(即start_fn)返回时，该线程被撤销。关于创建和撤销线程，POSIX和Win32并无太大的区别。 2．关于线程的等待(join or wait for)的操作。 在多线程模型下，一个线程有可能必须等待其他的线程结束了才能继续运行。比如说司机和售票员，司机只有当售票员确定所有的人都上车了，即售票员的行动结束以后才能开车，在这之前司机必须等待。 2.1等待一个POSIX线程 pthread_join(T1); 2.2等待一个Win32线程 WaitForSingleObject(T1); 当调用上面的函数是，调用者会被阻塞起来，直到要等待的线程结束。对于POSIX，线程分为可等待(non-detached)和不可等待(detached)，只能对可等待的线程调用pthread_join()，而对不可等待的线程调用pthread_join()时，会返回一个错误。对于不可等待的线程，当线程消亡时，它的线程结构，栈，堆等资源会自动的归还给操作系统；而对于可等待的线程，当它消亡时并不自动归还，而需要程序员显式的调用等待函数来等待这个线程，由等待函数负责资源的归还。在线程创建的时候，你可以且定该线程是否为不可等待，如果没有显式确定，则默认为可等待。当然也可以通过调用pthread_detach()来动态的修改线程是否可等待。在Win32的线程中没有不可等待这个概念，所有的线程都是可以等待的，另外，Win32还提供一个调用WaitForMulitpleObject(T[])，可以用来等待多个线程。 关于为什么要使用等待操作，上面解释的很清楚，但实际上并不是如此，我们之所以要使用等待操作，是因为我们认为序关系中的前驱线程结束以后，后续线程才能从阻塞态恢复执行，在这里我们要明白一个问题，我们等待的仅仅是前驱线程执行的任务结束而不是前驱线程本身的结束，或许前驱线程在执行完任务后会有一些其它的操作，那么等待前驱线程的结束会浪费我们的时间，所以通常不是利用上面的等待函数，而是利用下面要提到的同步机制(synchronization)来解决这个问题。 3．关于线程挂起(suspend)的操作。 线程的挂起是指线程停止执行，进入睡眠状态，直到其他线程调用一个恢复函数时，该线程才脱离睡眠状态，恢复执行。        3.1 挂起和恢复一个Win32线程 SuspendThread(T1); ResumeThread(T1); POSIX并没有实现线程的挂起和恢复操作，对于某些场合，挂起操作可能非常有用，但在大多数情况下，挂起操作可能会带来致命的错误，如果被挂起的线程正拥有一个互斥量(mutex)或一个临界区(critical section)，则不可避免的会出现死锁状态，所以通常也不使用挂起操作，如果一定要使用，必须检查会不会出现死锁情况。 4．关于线程的强制撤销(cancellation or killing)的操作。 一个线程有可能会通知另一个线程执行撤销操作，比如一个发送信息线程和一个接收信息线程，当发送方法送完所有信息，自身需要撤销时，它必须通知接受方发送完毕并且要求接受方也要撤销。对于上面的这种情况，POSIX称为cancellation，Win32称为killing，在实质上二者并没有多大区别。        4.1 撤销一个POSIX线程 pthread_cancel(T1);        4.2 撤销一个Win32线程 TerminateThread(T1); 5．线程的调度(scheduling) 线程的调度机制通常分为两种：一种是进程局部调度(process local scheduling)，一种是系统全局调度(system global scheduling)。局部调度是指线程的调度机制都是线程库自身在进程中完成的，与核心没有关系。POSIX对于两种调度机制都实现了，而Win32由于实现的是核心级线程，所以它的调度机制是全局的。线程的调度机制相当复杂，但对于线程库的使用者而不是开发者而言，线程的调度并不是最重要的东西，因为它主要是由操作系统和线程库来实现，并不需要使用者使用多少。 6．线程的同步机制(synchronization) 线程的同步是一个非常重要的概念，也是使用者最需要注意的地方之一。如果线程的同步机制使用不当，非常容易造成死锁。同步机制是基于原子操作(atomic action)实现的，所谓原子操作是指该操作本身是不可分割的。为什么要使用线程同步机制？因为在程序中，可能会有共享数据和共享代码，对于共享数据，我们要确保对该数据的访问(通常是对数据的修改)是互斥的，不能两个线程同时访问这个共享数据，否则会造成错误；而对于共享的代码，如果这段代码要求的是互斥执行(通常把这段代码称为临界区)，则也需要同步机制来实现。另外，对于一个线程，可能会需要等待另一个线程完成一定的任务才能继续执行，在这种情况下，也需要同步机制来控制线程的执行流程。通常，同步机制是由同步变量来实现的，一般说来，同步变量分为互斥量，信号量和条件量。 6．1互斥量mutex是最简单的同步变量，它实现的操作实际上就是一把互斥锁，如果一个线程拥有了这个mutex，其他线程在申请拥有这个mutex的时候，就会被阻塞，直到等到先那个线程释放这个mutex。在任何时候，mutex至多只有一个拥有者，它的操作是完全排他性的。        6.1.1 POSIX的mutex操作 pthread_mutex_init(MUTEX, NULL); pthread_mutex_lock(MUTEX); pthread_mutex_trylock(MUTEX); pthread_mutex_timedlock(MUTEX, ABSTIME); pthread_mutex_unlock(MUTEX); pthread_mutex_destroy(MUTEX);        6.1.2 Win32的mutex操作 CreateMutex(NULL, FALSE, NULL); WaitForSingleObject(MUTEX); ReleaseMutex(MUTEX); CloseHandle(MUTEX); POSIX的mutex操作提供了trylock和timedlock的调用，目的是为了防止死锁，Win32的wait操作本身可以设定超时，因此可以用设定超时的方法来模拟POSIX中的trylock，虽然二者在操作的集合上不等势，但显然二者在功能上是等价的。另外，Win32还提供一个叫做CriticalSeciton的互斥量，简单说来，它就是一个轻量级的mutex，并且只能实现统一进程中的线程的同步，不能实现跨进程的线程间的同步。CriticalSection较之mutex来说，更快更高效，而且与POSIX相似，CriticalSection操作提供一个TryEnterCriticalSection的操作，用来监测该CriticalSection是否被锁上。但它没有实现与timedlock相似的功能。        6.1.3 Win32的CriticalSection操作 InitializeCriticalSection(&cs); EnterCriticalSection(&cs); TryEnterCriticalSection(&cs); LeaveCriticalSection(&cs); DeleteCriticalSection(&cs); 6．2信号量semaphore最初是由E.W.Dijkstra于20世纪60年代引入的。通常，信号量是一个计数器和对于这个计数器的两个操作(分别称之为P，V操作)，以及一个等待队列的总和。一个P操作使得计数器减少一次，如果计数器大于零，则执行P操作的线程继续执行，如果小于零，那么该线程就会被放入到等待队列中；一个V操作使得计数器增加一次，如果等待队列中由等待的线程，便释放一个线程。简单的，我们可以通过一个图示来了解P，V操作的意义： P操作：                                                                V操作： continue 从图中可以看出，信号量的操作实际上是包括了互斥量的。一般地说来，信号量的操作可以在不同的线程中进行，而互斥量只能在同一个线程中操作，当互斥量和信号量要同时操作时，一定要注意互斥量的lock操作和信号量的P操作的顺序，通常应该是信号量的P操作在互斥量的lock操作之前，否则容易出现死锁。而互斥量的unlock操作和信号量的V操作则不存在这种序关系。 6.2.1 POSIX的信号量操作 sem_init(SEM, 0, VALUE); sem_wait(SEM); sem_trywait(SEM); sem_destroy(SEM); 6.2.2 Win32的信号量操作 CreateSemaphore(NULL, 0, MaxVal, NULL); WaitForSingleObject(SEM); ReleaseSemaphore(SEM); CloseHandle(SEM);        6．3条件量condition variables是一种非常类似于信号量的同步变量，不同的是，信号量关注的是counter的计数是多少，而条件量关注的仅仅是条件是否满足，换一句话说，条件量可以简单看作是计数器最大取值不超过1的信号量，但在它绝对不是信号量的简单实现，某些情况下，它比信号量更直观。同信号量一样，条件量是由一个待测条件，一组PV操作和一个等待队列组成的。它的PV操作和信号量的PV操作也非常的类似。 但是必须注意一点，在信号量中，lock和unlock是在信号量内部完成的，也就是说不需要使用者显式指定一个互斥量来进行互斥操作，而对于条件量来说，就必须显式地指定一个互斥量来保证操作的原子性。所以条件量总是与一个相关的互斥量成对出现的。        6.3.1 POSIX的条件量的操作 phtread_cond_init(COND, NULL); phtread_cond_wait(COND, MUTEX); phtread_cond_timedwait(COND, MUTEX, TIME); phtread_cond_signal(COND); phtread_cond_broadcast(COND); phtread_cond_destroy(COND); 其中broadcast是用来唤醒所有等在该条件量上的线程。 Win32中并没有条件量这个概念，但是它实现了一种叫做Event的同步变量，实质上和条件量是差不多的。   总体上来讲，POSIX和Win32实现的线程库在功能上基本上重叠的，也就是说用其中一种线程库实现的程序大多数的时候都能够比较容易的用另一种线程库来实现。下面列出了一张表，对比了一下两个线程库的异同：   POSIX thread library Win32 thread library 设计思想 简单 复杂 级别 用户级/核心级 核心级 调度策略 进程局部/系统全局 系统全局 线程挂起/恢复 未实现 实现 互斥量 实现 实现 信号量 实现 实现 条件量 实现 实现(事件对象Event) 线程创建/撤销 实现 实现 线程等待 实现 实现   四．Lilytask2.5的Win32thread实现。 Lilytask中涉及到的Win32thread，主要表现在线程的创建和同步两个方面上，下面就简单的讲述以下这两个方面的实现。 1．线程的创建以及相关的处理。 在每一个节点上，主线程要创建相应的线程：接收消息线程，发送消息线程，如果同一节点上的taskpool数目超过一个，则还要创建从处理线程，在lily_initial函数里边，要创建这几个线程： //创建接收线程，启动_thread_routine_recv thread_id=CreateThread(NULL,0,(LPTHREAD_START_ROUTINE)_thread_routine_recv,                           NULL, 0, NULL); //创建发送线程，启动_thread_routine_send thread_id2=CreateThread(NULL,0,(LPTHREAD_START_ROUTINE)_thread_routine_recv,                              NULL, 0, NULL); //创建从处理线程 for(i=0; i<numofthrs-1; i++) {      thrid=CreateThread(NULL, 0, (LPTHREAD_START_ROUTINE)lily_run_ready_task,                              (void*)i, 0, NULL); } 在创建完线程后，主线程和从线程都要求取得本线程的tid以及handle。线程的id用来确定该线程对应的taskpool是哪一个，线程的handle用来引用其自身，在wait的过程中会用到。在pthread的实现中， tid和handle是一体的，由pthread_self调用就可以得到；而对于Win32thread来说，要稍微的麻烦一点，tid和handle是不同的，所以要分别保存线程的id和handle。得到线程的id用GetCurrentThreadId，而与此对应的有GetCurrentThread，是不是用该函数就能得到线程的handle呢？答案不一定的。GetCurrentThread返回的是一个pseudo-handle，是一个伪句柄，只能由GetCurrentThread的调用者引用，即thread本身才能引用这个pseudo-handle，而我们的要求是其他的线程也可以引用这个handle，所以GetCurrentThread并不能满足我们的要求。但是，我们可以通过调用DuplicateHandle来复制一个真实的句柄，DuplicateHandle可以把一个进程中的一个handle(可以是pseudo-handle)复制给另一个进程的一个handle，得到是一个真实的其他线程也可以引用的handle： //保存线程的id taskpool[numofthrs-1].pthid2=GetCurrentThreadId(); //保存线程的handle DuplicateHandle(GetCurrentProcess(),GetCurrentThread(),GetCurrentProcess(),          &taskpool[numofthrs-1].pthid, 0, FALSE, DUPLICATE_SAME_ ACCESS); 2．线程的同步问题。 Lilytask基于任务并行来实现，并且定义了任务的序关系，这就使得任务间必然存在等待的情形，所以在Lilytask中，线程的同步问题非常的重要。在Lilytask中，互斥量被大量使用，一方面是大量临界资源的存在，另一方面是配合条件量的使用，上文已经指出，Win32 thread库中并没有实现条件量，与此对应的是Event Object，但是在Lilytask2.5βforWindows的实现中，我们并没有用Event Object，一是因为利用Event Object的实现相对麻烦一些，而信号量则相对简单易懂；另一原因是在Lilytask中用到的条件量，在大多数时候可以看作是一个最大值不超过1的信号量，基于上面的两个原因，Lilytask for Windows的主要的同步机制是利用互斥量和信号量来实现的。在Win32 thread中提供一个API：SignalObjectAndWait，可以用这个函数来模拟条件量的wait。条件量的wait操作在上文中的图示已经画出来了，其关键是开始时要lock临界区，然后判断条件，如果条件不成立，则unlock和sleep，其中unlock和sleep必须是原子操作的，正好SignalObjectAndWait也具有这个特性，所以用来模拟条件量非常的方便。 //互斥量作为临界区的锁来使用 WaitForSingleObject(taskpool[i].mutex_readylist_access, INFINITE); taskpool[i].isSignal=TRUE; ……               //临界区操作 ReleaseMutex(taskpool[i].mutex_readylist_access);   //互斥量与信号量配合使用，实现的条件量的Wait操作 WaitForSingleObject(taskpool[i].mutex_readylist_access, INFINITE); ……             //临界区操作 SignalObjectAndWait(taskpool[i].mutex_readylist_access,               taskpool[i].cond_readylist_access, INFINITE, FALSE); WaitForSingleObject(taskpool[i].mutex_readylist_access, INFINITE); ……            //临界区操作 ReleaseMutex(taskpool[i].mutex_readylist_access); 信号量的释放操作，相对而言就比较简单，与pthread下的实现并无二样。 除此之外，线程的同步还涉及到lily_finalize时要等待所有从线程的结束，虽然我们说过完全可以用信号量计数的方法取代wati(join)线程的方法，但就Lilytask这个实例来讲，用wait线程的方法更简单明了。 //等待从线程的结束 for(i=0; i<numofthrs-1; i++) { WaitForSingleObject(taskpool[i].pthid, INFINITE); …… } 另外还有一些关于线程的同步操作，比如pthread中trylock, timedlock等等，在上文的讨论中已经详细的说明了在Win32thread环境中的解决方法，就不一一赘述了。   五．总结。 总的说来，这二者在实现上是不一样的，但在提供给用户的接口上，基本上是一样的(当然，你可以说API的名字是不一样的，但我们探讨仅仅是API的实质即它提供给用户的功能接口)。对于Lilytask，之所以要做for Windows的版本，是基于系统的异构性的原因，Lilytask可以向上为用户屏蔽掉系统异构的差异，提供给用户一个不透明的编程模式，用户只需用Lilytask的原语写并行程序，不需要考虑系统的异构性，即用户写得程序无需做任何改动就可以在不同的系统上运行，而这些解决异构这些繁琐的问题这是由Lilytask的预编译器调用不同的库来实现的，大大的减轻了用户的负担。   参考资料： [1]BilLiews & Daniel J. Berg, Pthreads Primer——AGuide to MultiThreaded Programming.","title":"从pthread到Win32 thread"},{"content":"关于编码ansi、GB2312、unicode与utf-8的区别 先做一个小小的试验： 在一个文件夹里，把一个txt文本（文本里包含“今天的天气非常好”这句话）分别另存为ansi、unicode、utf-8这三种编码的txt文件。然后，在该文件夹上点击右键，选择“搜索(E)…”。 搜索“天气”二字，可以搜索出ansi和unicode这两种编码的txt文件，搜索不出utf-8编码的文件。 原因： 1.中文操作系统默认ansi编码，生成的txt文件默认为ansi编码，所以，可以搜索出来。 2.unicode是国际通用编码，所以，可以搜索出来。 3.utf-8编码是unicode编码在网络之间（主要是网页）传输时的一种“变通”和“桥梁”编码。utf-8在网络之间传输时可以节约数据量。所以，使用操作系统无法搜索出txt文本。   按照utf-8创始人的愿望： 端（unicode）——传输（utf-8）——端（unicode）   但是，后来，许多网站开发者在开发网页时直接使用utf-8编码。 端（utf-8）——传输（utf-8）——端（utf-8） 所以，在浏览器上看到的编码是：unicode（utf-8）。正因为在浏览器上这么并列地列出unicode（utf-8），造成许多网友（甚至不少程序员）误认为unicode=utf-8。其实，按照utf-8创始人的原意，在开发网页时使用utf-8编码是错误的做法，并且，早期的浏览器也不支持解析utf-8编码。但是，众人的力量是巨大的，微软不得不“趋炎附势”，在浏览器上支持解析utf-8编码。   问题是：utf-8编码影响了网站开发者，或者说，网站开发者“扩展”了utf-8编码的使用范围。但是，网站开发者仍然无法影响各类文档的开发者，所以，word文档和一些国际通用的文档仍然使用unicode编码而不使用utf-8编码。   比如：“严”的Unicode码是4E25，UTF-8编码是E4B8A5，两者是不一样的。   在中文和日文操作系统里生成的（txt和xml）文件的编码虽然都是ansi，但是，在简体中文系统下，ansi 编码代表 GB2312 编码，在日文操作系统下，ansi 编码代表 JIS 编码。不同 ansi 编码之间互不兼容，当信息在国际间交流时，无法将属于两种语言的文字，存储在同一段 ansi 编码的文本中。   结论：国际文档（txt和xml）使用unicode编码是正宗做法；操作系统和浏览器都能够“理解”unicode编码。浏览器“迫于压力”才“理解”utf-8编码。但是，操作系统有时只认unicode编码。 Unicode与Unicode big endian的区别：你吃鸡蛋时先吃小头还是先吃大头？Unicode与Unicode big endian的区别就是在编码时小头优先与大头优先的区别。“随波逐流”使用Unicode就OK了。 我（不是程序员）这几年一直因为编码问题，感到非常困惑，查了许多资料，在国际文档的实际应用中也遇到过许多问题，所以，“感性”地总结了上述观点，不一定准确（或者说，不一定正确）。","title":"ansi，unicode，gb2312，utf-8编码之间的区别"},{"content":"刚学,如果有问题看manual,不多说 两个文件说明下testlib.lua在当前目录下，maxmin.lua在当前目录的子目录lualibs下。 即./testlib.lua,./lualibs/maxmin.lua 测试过没有问题，大致可以清楚的阐述lua中的模块是怎么个样子，下面上代码： testlib.lua local maxmin = require \"lualibs.maxmin\"local test={3,23,63,32,1,2}local min=maxmin.findmin(test)local max=maxmin.findmax(test)io.write(\"test array:\")for _,v in pairs(test)do    io.write(v,\" \")endio.write(\"\\n\")print(\"min:\" ,min)print(\"max:\" ,max) maxmin.lua --[[ type 1maxmin={}local function min(a,b)    if a < b then return a    else return b endendlocal function max(a,b)    if a > b then return a    else return b endendfunction maxmin.findmax(...)    local data = ...    m = data[1]     for _,v in ipairs(data)    do        m=max(m,v)    end    return mendfunction maxmin.findmin(...)    local data = ...    m = data[1]    for _,v in ipairs(data)    do        m=min(m,v)    end    return mendreturn maxmin--]]---[[ type 2 无返回值,将table设置到package,之后外部require的时候照样能取到local M={}local modname = \"lualibs.maxmin\"_G[modname]=Mpackage.loaded[modname]=M--下面5行也可都注释掉--导出需要使用的全局变量到局部local print = printlocal ipairs= ipairs--设置模块环境为当前环境,即不需要_Glocal _ENV=M --lua 5.2,如果是之前版本则用setfenv(1,M)local function min(a,b)    if a < b then return a    else return b endendfunction M.max(a,b)    if a > b then return a    else return b endendfunction M.findmax(...)    local data = ...    m = data[1]    for _,v in ipairs(data)    do        m=M.max(m,v)    end    return mendfunction M.findmin(...)    local data = ...    m = data[1]    for _,v in ipairs(data)    do        m=min(m,v)    end    return mend--]]--[[ type 3 使用lua5.1中的module函数,5.2没有module函数module(...,package.seeall)local function min(a,b)    if a < b then return a    else return b endendlocal function max(a,b)    if a > b then return a    else return b endendfunction maxmin.findmax(...)    local data = ...    m = data[1]     for _,v in ipairs(data)    do        m=max(m,v)    end    return mendfunction maxmin.findmin(...)    local data = ...    m = data[1]    for _,v in ipairs(data)    do        m=min(m,v)    end    return mend--]]","title":"lua模块几种形式"},{"content":"对  变量  指针  指针的指针  挺晕的， 今天在 Linux 下写的这程序，我想看看到底是怎么指的. #include <stdio.h>int main(){\tint a = 10;\tint * p;\tint **str;\tp = &a;\tstr = &p;\tprintf(\"  a = %d \\n\",a);\tprintf(\" &a = %d \\n\",&a);\tprintf(\"\\n\");\tprintf(\" *p = %d \\n\",*p);\tprintf(\"  p = %d \\n\",p);\tprintf(\" &p = %d \\n\",&p);\tprintf(\"\\n\");\tprintf(\"**s = %d \\n\",**str);\tprintf(\" *s = %d \\n\",*str);\tprintf(\"  s = %d \\n\",str);\tprintf(\" &s = %d \\n\",&str);} a ,  p = &a; str = &p; [root@localhost Cdiy]# ./mypoint   a = 10  &a = -1079081744  *p = 10   p = -1079081744  &p = -1079081748 **s = 10  *s = -1079081744   s = -1079081748  &s = -1079081752 [root@localhost Cdiy]# 可以看出 ， 初始化的时候 ， 内存分配在   44， 48， 52 三个连续的位置 . a 内的值 为10 ， a 的地址为44 . 指针 p 指向 a 地址，p 指针变量值 为 a 的地址 ，就是所以对 p 进行寻址   *p  = 10 (a 内的值) ; 指针的指针 str 指向 指针p 地址 ，对 str 寻址 *str = a 的地址 ，再对 *str  寻址  **str = 10 (a 内的值) ;","title":"变量 指针 指针的指针"},{"content":"1. 安装vsftpd   sudo apt-get install vsftpd    安装后会自动新建一个用户ftp,密码ftp,作为匿名用户登录的默认用户            sudo /etc/init.d/vsftpd restart   重启ftp server     sudo /etc/init.d/vsftpd start      sudo /etc/init.d/vsftpd stop 2. 配置 /etc/vsftpd.conf 1)  用户进入时路径:        默认的路径是  /srv/ftp, 可修改.      local_root=/home/ftp   #本地用户登录后路径      anon_root=/home/ftp   #匿名用户登录后路径 2)  匿名用户设置      anonymous_enable=YES   #允许匿名用户登录      anon_upload_enable=YES  #允许匿名用户上传文件, 相关文件夹必须有写权限,同时  write_enable=YES 开启       #anon_mkdir_write_enable=YES  #允许匿名用户新建文件夹  推荐关闭      anon_umask=022  #用户上传文件的权限设置, umask为权限的补码      chown_uploads=YES  #修改匿名用户上传文件的所有者, 所有者可通过chown_username=whoever 来设置,不推荐使用root      ftp_username=    # 匿名用户所使用的系统用户名.默认下,此参数在配置文件中不出现, 值为ftp      sword=YES   # 控制匿名用户登入时是否需要密码,YES不需要,NO需要.默认值为NO. 3)  本地用户设置      基本与匿名用户设置一致       4)  目录访问控制      #chroot_list_enable=YES   # 将用户锁在自己目录中, 具体用户在chroot_list_file中设置      #chroot_list_file=/etc/vsftpd.chroot_list  # 指出被锁定在自家目录中的用户的列表文件.文件格式为一行一用户.      #chroot_local_user=YES   # 将本地用户锁定在自家目录中. 当此项被激活时,chroot_list_enable和chroot_local_users参数的作用将发生变化, chroot_list_file所指定文件中的用户将不被锁定在自家目录.本参数被激活后,可能带来安全上的冲突,特别是当用户拥有上传 shell访问等权限时.因此,只有在确实了解的情况下,才可以打开此参数.默认值为NO. 5)  其他设置      xferlog_enable=YES  #使用上传/下载日志, 日志文件默认为/var/log/vsftpd.log, 可以通过xferlog_file更改      dirmessage_enable=YES  #进入目录时显示此目录下message_file选项指定的文件(默认为.message)的内容      use_localtime=YES  #使用本地时间, 否则使用GMT      connect_from_port_20=YES  #使用20号端口 6)  安全选项      idle_session_timeout=600   #  秒, 用户会话空闲后10分钟断开      data_connection_timeout=120 # 将数据连接空闲2分钟断开      accept_timeout=60   # 将客户端空闲1分钟后断      connect_timeout=60  #中断1分钟后又重新连接      local_max_rate=50000 # bite 本地用户传输率50K      anon_max_rate=30000  # bite 匿名用户传输率30K      pasv_min_port=50000  # 将客户端的数据连接端口改在50000      pasv_max_port=60000  # 50000—60000之间      max_clients=200  # FTP的最大连接数      max_per_ip=4  # 每IP的最大连接数      listen_port=5555 # 从5555端口进行数据连接","title":"ubuntu配置ftp server"},{"content":"linux是我们这周的学习任务 一、linux目录的介绍 只有一个/ 根目录，所有的文件都在这个根目录下 Bin    保存的是 可执行的文件 Etc  保存的是配置文件，而且Linux的命令都是通过配置文件来实现的 Home  家目录  保存了一些用户 ，通过 cd ~ 切换 Usr   这个保存的是安装的软件的目录 Mnt  挂在一些镜像文件的目录 Media 保存的是下载的镜像光驱文件 二、linux系统引导流程 1固件自检--------firmware  固件-------固化到主板芯片中的一段程序，通过CMOS/BIOS 用来加电自检 CMOS --- =存储器  给所有的芯片加电 BIOS------basic  Input Output System  简单的输入输出系统-----连接软件和硬件之间的一座桥梁-----软件 的命令和硬件的命令结合 2，加载操作系统的内核 Bootloader  引导着我们去找到这个操作系统的内核 Linux下有一个常用的自启动程序----grub--- Boot 目录下面存放的是引导找到操作系统内核的命令 通过grub.conf文件找 Title-------操作系统的名称 root (hd0,0)  hd0-----ide 硬盘0 第几块硬盘---0 第几个分区（） Sd ------scisi  Kernel   操作系统内核的版本号 3，加载了内核 内核有哪些功能：驱动硬件，驱动---软件驱使硬件动起来 开启 init 命令 /etc/inittab 因为不同的运行级别加载的服务是不一样的，比如图形界面和单用户界面 Inittab------判断你默认的运行级别是什么 通过initdefault来判断我们默认的启动级别 初始化系统------通过:/etc/rc.d/rc.sysinit 这个脚本来实现加载系统的基本服务，不管你是什么运行级别都要执行这个脚本 默认的字体----系统的时间----环境变量 3，我们还要根据你不同的运行级别 去 开启不同的服务 不同的运行级别 开启不同的服务是怎么来实现的呢？ /etc/rc.d/rc Rc------他就是用来根据不同的启动级别 开启不同的服务 原理：先判断 你默认的启动级别，再去根据这个启动级别 执行相应的 rcX.D这个脚本 进一步引导去找到具体的操作系统的内核 Etc 目录里面的文件其实大部分是 软连接 ------用来找到具体的脚本的   三、心得 学习linux老师的讲解很深刻：1）一定要区别windows系统的各个操作习惯  2）一定要与cmd相区别   3）在windows里不区分大小写，但是在linux中，严格区分大小写！ 在给文件取名时一定要注意：1）不能用 /   2）其他的符号都可以，但是不建议用@#￥%等等  3）重点空格一定要注意，可用但是，我们为什么不建议用呢？原因是-->>在linux中的命令操作时，指令与文件之间用空格分隔，如果你的文件名取名有空格，那么，linux系统是不会区分出来的，那么他就傻了，不会再执行你的指令。例子：现在新建一个文件目录mkdir a b ,但是当你进入a b文件夹时，就会cd a b这样就乱了 其中比较牛的几个命令必须知道，而且很常用：pwd 、rm、mv、cp、vi、tar、gzip、chown、cd 、mkdir  pwd ---查看当前所在位置     rm  -----移除 文件/文件夹  格式：rm 文件名称      rm  -R  目录名称  mv  比较牛B，为什么说他牛呢？   1）首先它是一个用作貌似剪切功能的命令          格式：mv   文件名称 /  -R  目录名称   移动到的路径   2）还有文件名目录名称重命名的功能                  格式：mv   原文件名   新文件名    移动地址 cp  复制功能     格式：cp   文件名 /  -R 目录名  复制到何处（地址） vi  文本编辑命令    格式：vi  文件名                     （进行编辑内容，后按ESC后Shift加冒号q 回车(退出编辑，但是不保存)  ；按ESC后Shift加冒号wq 回车(退出并且保存文件内容)；按ESC后Shift加冒号wq！ 回车(强制退出并且保存文件内容) tar 压缩文件/解压文件  命令   tar  -czvf  要压缩的文件.tar.gz  压缩到哪（路径） 其中参数czvf含义为：c 创建档案文件  z以zip格式压缩或解压文件  v显示打包详细信息  f指定档案文件的名称  tar  -xvf    要解压文件的名称.tar.gz  解压到哪          其中的参数为：x解压文件 v显示打包详细信息  f指定档案文件的名称 gzip其实包含在tar中 chown 更改文件的所有者   如一个文件a它的所有者是root  现在我们将他的所偶有着改成syl  chown syl  a  即可 chmod 更改文件的权限         格式：chmod  数字/ u=rwx  文件名称         其中r是可读   w是可写   x可执行 cat 查看文件内容 find  查找   格式：find  目录   文件名称   由于linux课程还未学习完成，最近的知识点就与大家分享到此！！！谢谢","title":"linux有心得了(完成了)"},{"content":"照妖镜和火眼金睛 　　如果在 linux 下编写 C 程序，那么你将获得两个犀利的法宝： 照妖镜 　　一个C程序（max.c）： #define MAX(a,b) ((a)>=(b)?(a):(b))int main(){    int c=MAX(1,2); // 注注注注释    return 0;} 　　程序很简单，就是定义和使用一个MAX宏，宏在正式编译前是会被替换为本来面目的，我们现在看到的不是它的真身。让我们用照妖镜来照照： gcc -E -o max2.c max.c 　　这里的 -o max2.c 是让 gcc 把要输出东西输出到 max2.c 文件中。 　　妖怪！快快现形吧： # 1 \"max.c\"# 1 \"<built-in>\"# 1 \"<命令行>\"# 1 \"max.c\"int main(){ int c=((1)>=(2)?(1):(2)); return 0;} 　　上面就是max2.c中的内容，MAX(1,2) 被替换成了 ((1)>=(2)?(1):(2))，这只孽畜终于现形了！ 　　照妖镜的作用就是替换宏，但是宏好像大家都不太用。不过宏在 现代 linux 内核源代码中简直是运用到了极致，甚至可以说 linux 内核是由 C、宏、汇编 写出来的。宏是可以嵌套的，也就是说宏的 参数 或 右部 中还可以出现能够被替换的宏，所以情况就相当复杂了——十个字符的简单的一条语句，当被还原为本来面目时，可能就变成七八十个字符了，要分析这样的语句，照妖镜就大显神威了。 　　关于宏，后面会独立出一篇来介绍。 火眼金睛 　　照妖镜应该是不如火眼金睛的，火眼金睛可以看到及其微小的细节。下面我写了个Hello World （hello.c）： #include <stdio.h>int main(){    printf(\"Hello, World!\\n\");    return 0;} 　　Hello World 就不用解释了吧，鼎鼎有名啊！O(∩_∩)O~，然后我们用火眼金睛来看一下： gcc -S -o hello.s hello.c 　　Hello World 的汇编版就出来了(hello.s)：     .file   \"hello.c\"    .section    .rodata.LC0:    .string \"Hello, World!\"    .text.globl main    .type   main, @functionmain:    pushl   %ebp    movl    %esp, %ebp    andl    $-16, %esp    subl    $16, %esp    movl    $.LC0, (%esp)    call    puts    movl    $0, %eax    leave    ret    .size   main, .-main    .ident  \"GCC: (GNU) 4.5.1 20100924 (Red Hat 4.5.1-4)\"    .section    .note.GNU-stack,\"\",@progbits 　　其内容我们后面再慢慢分析，现在只要知道怎么用“火眼金睛”就行了，接下来的几篇都得靠悟空了。 　　照妖镜和火眼金睛其实都是靠截断编译过程得到中间产物的，gcc的完整编译过程是： 预处理->编译->汇编->链接 　　使用不同的编译选项可以得出不同的中间产物： 编译阶段 命令 截断后的产物     C源程序 预处理 gcc -E 替换了宏的C源程序(没有了#define,#include…), 删除了注释 编译 gcc -S 汇编源程序 汇编 gcc -c 目标文件，二进制文件， 允许有不在此文件中的外部变量、函数 链接 gcc 可执行程序，一般由多个目标文件或库链接而成， 二进制文件，所有变量、函数都必须找得到 　　也许有同学发现了 -c 我还没讲呢！二进制文件的分析后面也有用到，但是很少，用到的时候再说吧。","title":"照妖镜和火眼金睛"},{"content":"1.VI（visual interface）文本编辑器 2.系统默认安装好的（精简） 3.启动vi:直接在命令行输入vi即可，在哪个目录下启动，默认保存在哪个目录下 4.vi启动后分为3种模式：  插入模式：文字的编辑,内容的输入  命令模式：执行相应的命令（如：查找，替换，复制，粘贴，剪切...）  末行模式：特殊的命令模式（对文档进行保存，关闭..） 5.如何切换模式  命令模式－－－－插入模式（i或insert）  插入模式－－－－命令模式（ESC）  命令模式－－－－末行模式（:）  末行模式－－－－命令模式（ESC） 6.命令模式下：  光标的移动:上下左右方向键或（k,j,h,l）  行号的显示与隐藏：set nu/set nonu  撤销:u  文本的复制: yw(复制从光标开始向后的一个单词)    nyw(复制从光标开始向后的N个单词)    yy(复制从光标开始一行文本)    nyy(复制从光标开始的n行文本)  文本的粘贴:p 7.末行模式下：(在命令模式下输入:)  文件的命名：:f 文件名  文件的保存:w  文件的退出：q（q!表示不保存直接退出，wq保存退出）  将N1到N2的内容复制到N3开始的行：N1,N2 co N3  N1到N2的内容复制到N3开始的行：N1,N2 m N3  光标的跳转：直接输入n，n表示行号。  删除行:d 删除当前行  删除多行:nd 删除n行  删除一个区间：N1,N2 d  文件的查找和替换：   直接输入？｜／后面输入要查找的字符串即可   将查找的内容写入到另外的文件当中：?str/w file   将查找的内容替换：N1,N2  s/str1/str2/g  str1查找的内容 st：r2替换的内容 /g表示替换当前行 n1，n2表示范围  vi可以同时打开多个文件，文件之间的切换可以通过next和prev来实现   ","title":"Linux vi编辑器的使用"},{"content":"LDD第二章到第六章的综合复习。 用循环缓冲区实现一个FIFO，支持多个reader和writer，利用信号量在竞态下保护数据区域，并且在无数据的时候阻塞读，数据满的时候阻塞写，可以通过ioctl返回FIFO状态。 需要的技术： 1、信号量：竞争与锁的机制。 2、等待队列：进程的休眠与唤醒。用两种方式实现读写阻塞。 3、poll：返回文件可读或者可写的状态，为select调用。 4、ioctl：返回或者传入特定结构体，在本例中为FIFO的状态。   其实无论驱动程序逻辑多么复杂，基本的框架都是一些操作函数的实现，一个字符设备的大致框架如下： 将cdev嵌入自己的结构体里，可以支持更多的属性，而不是利用全局变量（等待队列、信号量等）进行管理 （一）初始化工作 1、请求设备号（指定或动态分配主设备号，请求子设备号） 2、分配结构体内存并初始化内部关键变量（申请buffer，初始化信号量等） 3、注册设备，步骤cdev_alloc --> cdev_init --> cdev_add，其中我们的字符设备是嵌套在fifo struct里面的，所以alloc工作在第二步已经做好。 （二）清理工作 1、注销设备，cdev_del 2、释放fifo struct内存，包括申请的buffer内存 3、回收设备号 执行完rmmod之后可以检查cat /proc/devices是否将我们申请的设备号释放完毕 （三）文件操作 1、open：包括必要的初始化和统计工作，以及与权限相关的操作 2、release：资源回收 3、read&write：对于数据的操作，在普通文件中主要是数据的读写，f_pos的移动；fifo中不支持lseek，但是需要在特定条件下阻塞读和写，在满足条件时唤醒，并且维护wp和rp以保证循环buffer的正常。 4、ioctl：用于对设备的控制，返回设备的状态，比如fifo当前的使用情况，或者是设备中每个变量的状态，如天线数据的子帧号等；也可以用作小数据量的传输。 5、mmap：用于用户空间和设备之间的内存映射。 6、poll：用于返回可读写状态等； 7、llseek：用于移动当前读写位置。 （四）调试支持 /proc文件，可以用来传输小数据量的数据，辅助调试。利用proc文件传输大量数据可能会导致设备驱动程序组织的比较乱，不建议使用。   代码还有bug，write函数无法写入，暂时先贴在下面，请各位高手指点一下小弟~   #include <linux/init.h>#include <linux/module.h>#include <linux/moduleparam.h>#include <linux/fs.h>\t\t// struct  file and file_operations#include <linux/types.h>\t// typedef dev_t, etc.#include <linux/kdev_t.h>#include <linux/poll.h>\t\t// interface poll_wait...#include <linux/kernel.h>\t// printk(), min()#include <linux/errno.h>\t// error codes#include <linux/cdev.h>\t\t// cdev_add()#include <linux/ioctl.h>\t// _IOW,etc.#include <linux/slab.h>\t\t// kmalloc()#include <linux/fcntl.h>#include <linux/sched.h>\t// schedule() and TASK_*#include <asm/uaccess.h>\t// interface copy_from_user and copy to user#include <asm/system.h>\t\t// cli(), *_flagsMODULE_LICENSE(\"GPL\");struct cdev_fifo{\twait_queue_head_t inq, outq;\t\t// read/write wait queue\tchar *buffer, *end;\t\t\t// loop buffer begin and end\tint bufsize;\t\t\t\t// loop buffer size\tchar *rp, *wp;\t\t\t\t// read/write position\tint nreaders, nwriters;\t\t\t// readers/writers counter\tstruct fasync_struct *async_queue;\tstruct semaphore sem_buf;\t\t// mutex\tstruct cdev cdev;\t\t\t// char device};struct cdev_info{\tint bufsize;\tint nreaders;\tint nwriters;\tint spacefreesize;};#define CDEV_IOC_MAGIC 'k'#define CDEV_IOC_MAXNR 2#define CDEV_IOC_GETINFO _IOWR(CDEV_IOC_MAGIC, 0, struct cdev_info)static int cdev_fifo_major = 0;static int cdev_fifo_minor = 0;static int cdev_fifo_num = 1;static int cdev_fifo_size = 4000;module_param(cdev_fifo_major, int, 0);\t\t//insmod xxx.ko cdev_fifo_major = 254module_param(cdev_fifo_minor, int, 0);\tmodule_param(cdev_fifo_num, int, 0); \t module_param(cdev_fifo_size, int, 0);static struct cdev_fifo *cdev_fifo_devices;static ssize_t cdev_open(struct inode *, struct file *);static ssize_t cdev_release(struct inode *, struct file *);static ssize_t cdev_read(struct file *, char *, size_t, loff_t*);static ssize_t cdev_write(struct file *, const char *, size_t, loff_t*);//no use of llseek static loff_t cdev_llseek(struct file *, loff_t, int);static unsigned int cdev_poll(struct file *, poll_table *);static int cdev_ioctl(struct inode *, struct file *, unsigned int, unsigned long);static int cdev_fasync(int, struct file *, int);struct file_operations cdev_fops = {\t.owner = THIS_MODULE,\t.open = cdev_open,\t.read = cdev_read,\t.write = cdev_write,\t.llseek = no_llseek,\t.ioctl = cdev_ioctl,\t.poll = cdev_poll,\t.fasync = cdev_fasync,\t.release = cdev_release,};static void cdev_fifo_setup_cdev(struct cdev_fifo *dev, int index){\tint err, devno = MKDEV(cdev_fifo_major, cdev_fifo_minor+index);\t// register char device\t// cdev_alloc --> cdev_init --> cdev_add\tcdev_init(&dev->cdev, &cdev_fops);\tdev->cdev.owner = THIS_MODULE;\tdev->cdev.ops = &cdev_fops;\terr = cdev_add(&dev->cdev, devno, 1);\tif (err)\t\tprintk(\"Error %d adding cdev_fifo %d.\\n\", err, index);}static int __init cdev_module_init(void){\tint result, i;\tdev_t dev = 0;\t// ask a range of minor numbers to work with\tif (cdev_fifo_major)\t\t\t// for certain major number\t{\t\tdev = MKDEV(cdev_fifo_major, cdev_fifo_minor);\t\tresult = register_chrdev_region(dev, cdev_fifo_num, \"cdev_fifo\");\t}\telse\t\t\t\t\t// for dynamic allocated major number\t{\t\t// allocate dev major\t\tresult = alloc_chrdev_region(&dev, cdev_fifo_minor /*dev minor*/, cdev_fifo_num /*count*/, \"cdev_fifo\");\t\tcdev_fifo_major = MAJOR(dev);\t}\tif (result < 0)\t{\t\tprintk(\"cdev_fifo can't get major %d\\n\", cdev_fifo_major);\t\treturn result;\t}\t// allocate fifo devices according to the number when module loaded\tcdev_fifo_devices = kmalloc(cdev_fifo_num * sizeof(struct cdev_fifo), GFP_KERNEL); \tif (!cdev_fifo_devices)\t\t// allocate failure\t{\t\tunregister_chrdev_region(dev, cdev_fifo_num);\t\tresult = -ENOMEM;\t\treturn result;\t}\tprintk(\"kmalloc struct success.\\n\");\t// initialize device struct variables\tmemset(cdev_fifo_devices, 0, cdev_fifo_num * sizeof(struct cdev_fifo));\tfor (i = 0; i < cdev_fifo_num; ++i)\t{\t\tinit_waitqueue_head(&(cdev_fifo_devices[i].inq));\t\tinit_waitqueue_head(&(cdev_fifo_devices[i].outq));\t\tsema_init(&(cdev_fifo_devices[i].sem_buf), 1);\t\tcdev_fifo_setup_cdev(cdev_fifo_devices+i, i);\t}\t\tprintk(\"cdev_fifo register success.\\n\");\treturn 0;}static void __exit cdev_module_exit(void){\tint i;\tdev_t devno = MKDEV(cdev_fifo_major, cdev_fifo_minor);\tif (cdev_fifo_devices)\t{\t\tfor (i = 0; i < cdev_fifo_num; ++i)\t\t{\t\t\tcdev_del(&(cdev_fifo_devices[i].cdev));\t// remove devices\t\t\tkfree(cdev_fifo_devices[i].buffer);\t\t}\t\tkfree(cdev_fifo_devices);\t\t\t// free memory\t\tcdev_fifo_devices = NULL;\t}\tunregister_chrdev_region(devno, cdev_fifo_num);\t\t// free device number\tprintk(\"cdev_fifo unregister success.\\n\");}/* * file management: open and close*/static int cdev_open(struct inode *inode, struct file *filp){\tstruct cdev_fifo *dev;\tdev = container_of(inode->i_cdev, struct cdev_fifo, cdev);\tfilp->private_data = dev; //for read, write...\t\tif (down_interruptible(&dev->sem_buf))\t\treturn -ERESTARTSYS;\tif (!dev->buffer)\t{\t\t// allocate the buffer\t\tdev->buffer = kmalloc(cdev_fifo_size, GFP_KERNEL);\t\tif (!dev->buffer)\t\t{\t\t\tup(&dev->sem_buf);\t\t\treturn -ENOMEM;\t\t}\t}\tdev->bufsize = cdev_fifo_size;\tdev->end = dev->buffer + dev->bufsize;\tdev->rp = dev->wp = dev->buffer; // rd and wr from the beginning\t\t// count readers and writers\tif (filp->f_mode & FMODE_READ)\t\tdev->nreaders++;\tif (filp->f_mode & FMODE_WRITE)\t\tdev->nwriters++;\tup(&dev->sem_buf);\tprintk(\"\\\"%s\\\" open file successful\\n\", current->comm);\treturn nonseekable_open(inode, filp);}static int cdev_release(struct inode *inode, struct file *filp){\tstruct cdev_fifo *dev = filp->private_data;\tcdev_fasync(-1, filp, 0);\tif (down_interruptible(&dev->sem_buf))\t\treturn -ERESTARTSYS;\tif (filp->f_mode & FMODE_READ)\t\tdev->nreaders--;\tif (filp->f_mode & FMODE_WRITE)\t\tdev->nwriters--;\tif (dev->nreaders + dev->nwriters == 0)\t{\t\tkfree(dev->buffer);\t// free memory\t\tdev->buffer = NULL;\t}\tup(&dev->sem_buf);\treturn 0;}/* * data management: read and write*/static ssize_t cdev_read(struct file *filp, char *buf, size_t len, loff_t *f_pos){\tstruct cdev_fifo *dev = filp->private_data;\tif (down_interruptible(&dev->sem_buf))\t\treturn -ERESTARTSYS;\t\t// interrupted\twhile (dev->rp == dev->wp)\t\t// fifo empty, read nothing\t{\t\tup(&dev->sem_buf);\t\t// release lock\t\tif (filp->f_flags & O_NONBLOCK)\t\t\treturn -EAGAIN;\t\tprintk(\"\\\"%s\\\" reading: going to sleep\\n\", current->comm);\t\tif (wait_event_interruptible(dev->inq, (dev->rp != dev->wp)))\t\t\treturn -ERESTARTSYS;\t// signal: tell fs layer handle it\t\tif (down_interruptible(&dev->sem_buf))\t\t\treturn -ERESTARTSYS;\t}\t// fifo is not empty, return data\tif (dev->wp > dev->rp)\t\tlen = min(len, (size_t)(dev->wp - dev->rp));\telse\t\t\t\t// wp rrapped, return end-rp\t\tlen = min(len, (size_t)(dev->end - dev->rp));\tif (copy_to_user(buf, dev->rp, len))\t{\t\tup(&dev->sem_buf);\t\treturn -EFAULT;\t}\tdev->rp += len;\tif (dev->rp == dev->end)\t\tdev->rp = dev->buffer;\tup(&dev->sem_buf);\t// wake up writers\twake_up_interruptible(&dev->outq);\tprintk(\"\\\"%s\\\" did read %li bytes\\n\", current->comm, (long)len);\treturn len;}// return free space sizestatic int spacefree(struct cdev_fifo *dev){\tif (dev->rp == dev->wp)\t{\t\treturn dev->bufsize - 1;\t}\treturn ((dev->rp + dev->bufsize - dev->wp)) - 1;}// wait for free space for writingstatic int cdev_getwritespace(struct cdev_fifo *dev, struct file *filp){\twhile (spacefree(dev) == 0) \t\t// fifo full \t{\t\tDEFINE_WAIT(wait);\t\tup(&dev->sem_buf);\t\tif (filp->f_flags & O_NONBLOCK)\t\t\treturn -EAGAIN;\t\tprintk(\"\\\"%s\\\" writing: going to sleep\\n\", current->comm);\t\tprepare_to_wait(&dev->outq, &wait, TASK_INTERRUPTIBLE);\t\tif (spacefree(dev) == 0)\t// check condition!!!\t\t\tschedule();\t\tfinish_wait(&dev->outq, &wait);\t\tif (signal_pending(current))\t\t\treturn -ERESTARTSYS;\t//signal wake up\t\tif (down_interruptible(&dev->sem_buf))\t\t\treturn -ERESTARTSYS;\t}\treturn 0;}static ssize_t cdev_write(struct file *filp, const char *buf, size_t len, loff_t *f_pos){\tstruct cdev_fifo *dev = filp->private_data;\tint result;\tprintk(\"request semaphore\\n\");\tif (down_interruptible(&dev->sem_buf))\t\treturn -ERESTARTSYS;\tprintk(\"get semaphore, check space.\\n\");\tresult = cdev_getwritespace(dev, filp);\tif (result)\t\treturn result;\tprintk(\"write space free.\\n\");\t// space is free, begin to write\tlen = min(len, (size_t)spacefree(dev));\tif (dev->wp >= dev->rp)\t\tlen = min(len, (size_t)(dev->end - dev->wp));\telse\t\tlen = min(len, (size_t)(dev->rp - dev->wp -1));\tprintk(\"Going to accept %li bytes to %p from %p\\n\", (long)len, dev->wp, buf);\tif (copy_from_user(dev->wp, buf, len))\t{\t\tup(&dev->sem_buf);\t\treturn -EFAULT;\t}\tdev->wp += len;\tif (dev->wp == dev->end)\t\tdev->wp = dev->buffer;\t\t//wp wrapped\tup(&dev->sem_buf);\twake_up_interruptible(&dev->inq);\t//wake up read and select\tif (dev->async_queue)\t\tkill_fasync(&dev->async_queue, SIGIO, POLL_IN);\tprintk(\"\\\"%s\\\" did write %li bytes.\\n\", current->comm, (long)len);\treturn sizeof(int);}static int cdev_ioctl(struct inode *inode, struct file *filp, unsigned int cmd, unsigned long arg){\tint retval = 0;\tstruct cdev_info curinfo;\tstruct cdev_fifo *dev = filp->private_data;\tif (_IOC_TYPE(cmd) != CDEV_IOC_MAGIC)\t\treturn -ENOTTY;\tif (_IOC_NR(cmd) > CDEV_IOC_MAXNR)\t\treturn -ENOTTY;\tswitch (cmd)\t{\t\tcase CDEV_IOC_GETINFO:\t\t\tcurinfo.bufsize = dev->bufsize;\t\t\tcurinfo.nreaders = dev->nreaders;\t\t\tcurinfo.nwriters = dev->nwriters;\t\t\tcurinfo.spacefreesize = spacefree(dev);\t\t\tif (copy_to_user((unsigned char __user *)arg, &curinfo, sizeof(curinfo)))\t\t\t{\t\t\t\tprintk(\"cdev_fifo ioctl error: copy_to_user\\n\");\t\t\t\tretval = -EFAULT;\t\t\t}\t\t\tbreak;\t\tdefault:\t\t\treturn -ENOTTY;\t}\treturn retval;}static unsigned int cdev_poll(struct file *filp, poll_table *wait){\tstruct cdev_fifo *dev = filp->private_data;\tunsigned int mask = 0;\tif (down_interruptible(&dev->sem_buf))\t\treturn -ERESTARTSYS;\tpoll_wait(filp, &dev->inq, wait);\tpoll_wait(filp, &dev->outq, wait);\tif (dev->rp != dev->wp)\t\tmask |= POLLIN | POLLRDNORM;\t// readable\tif (spacefree(dev))\t\tmask |= POLLOUT | POLLWRNORM;\t// writable\tup(&dev->sem_buf);\treturn mask;}static int cdev_fasync(int fd, struct file *filp, int mode){\tstruct cdev_fifo *dev = filp->private_data;\treturn fasync_helper(fd, filp, mode, &dev->async_queue);}module_init(cdev_module_init);module_exit(cdev_module_exit);   测试程序： 测试读   #include <stdio.h>#include <sys/types.h>#include <sys/stat.h>#include <fcntl.h>int main(){\tchar buf[256];\tint readlen = 0, retlen;\tFILE* fd;\tfd = fopen(\"/dev/fifocdev\", \"r\");\tif (fd != -1)\t{\t\twhile(1)\t\t{\t\t\tprintf(\"enter read len=\");\t\t\tscanf(\"%d\",&readlen);\t\t\tretlen = fread((void*)buf, sizeof(char), readlen, fd);\t\t\tbuf[retlen] = '\\0';\t\t\tprintf(\"read size= %d, content=%s.\\n\", retlen, buf);\t\t}\t\t\t\tfclose(fd);\t}\telse\t\tprintf(\"open error.\\n\");\treturn 0;}   测试写   #include <stdio.h>#include <string.h>#include <sys/types.h>#include <sys/stat.h>#include <fcntl.h>int main(){\tchar buf[256];\tint readlen = 0, retlen;\tFILE* fd;\tmemset(buf,0,sizeof(buf));\tfd = fopen(\"/dev/fifocdev\", \"w\");\tif (fd != -1)\t{\t\twhile(1)\t\t{\t\t\tprintf(\"enter write string=\");\t\t\tscanf(\"%s\",(char*)&buf);\t\t\tprintf(\"strlen=%d\\n\",strlen(buf));\t\t\tretlen = fwrite((char*)&buf, sizeof(char), strlen(buf)+1, fd);\t\t\tprintf(\"write size= %d, content=%s.\\n\", strlen(buf)+1, buf);\t\t}\t\t\t\tfclose(fd);\t}\telse\t\tprintf(\"open error.\\n\");\treturn 0;}   ioctl   #include <stdio.h>#include <sys/types.h>#include <sys/stat.h>#include <sys/ioctl.h>#include <fcntl.h>#define DEVICE_FILENAME \"/dev/fifocdev\"struct cdev_info{\tint bufsize;\tint nreaders;\tint nwriters;\tint spacefreesize;};#define CDEV_IOC_MAGIC 'k'#define CDEV_IOC_GETINFO _IOWR(CDEV_IOC_MAGIC, 0, struct cdev_info)int main(){\tstruct cdev_info info;\tint dev;\tdev = open(DEVICE_FILENAME, O_RDWR | O_NDELAY);\tif (dev >= 0)\t{\t\tprintf(\"open dev success.\\n\");\t\tioctl(dev, CDEV_IOC_GETINFO, &info);\t\tprintf(\"bufsize=%d.\\n\", info.bufsize);\t\tprintf(\"nreaders=%d.\\n\", info.nreaders);\t\tprintf(\"nwriters=%d.\\n\", info.nwriters);\t\tprintf(\"spacefreesize=%d.\\n\", info.spacefreesize);\t\tclose(dev);\t}\telse\t\tprintf(\"open device error.\\n\");\treturn 0;}   可以用ioctl和dmesg辅助调试。 在insmod之后，根据/proc/devices里面的主次设备号建立字符设备文件 sudo mknod c 251 0   问题： 直接运行./testwritefifo，会出现段错误，fwrite的地方报错 利用sudo ./testwritefifo，返回写入成功，但是dmesg并没有看到pringk 出来的写入操作（没进去write函数），ioctl也发现FIFO的freesize并没有变化，但是nwriter确实是+1了，说明测试写FIFO程序打开文件成功了。（从dmesg也可以看到writefifo open file successful）。","title":"Linux驱动学习(四)——高级字符设备驱动程序"},{"content":"struct map_info {  char *name;  unsigned long size;  resource_size_t phys; #define NO_XIP (-1UL)  void __iomem *virt;  void *cached;  int bankwidth; #ifdef CONFIG_MTD_COMPLEX_MAPPINGS  map_word (*read)(struct map_info *, unsigned long);  void (*copy_from)(struct map_info *, void *, unsigned long, ssize_t);  void (*write)(struct map_info *, const map_word, unsigned long);  void (*copy_to)(struct map_info *, unsigned long, const void *, ssize_t); #endif  void (*inval_cache)(struct map_info *, unsigned long, ssize_t);  void (*set_vpp)(struct map_info *, int);  unsigned long map_priv_1;  unsigned long map_priv_2;  void *fldrv_priv;  struct mtd_chip_driver *fldrv; }; 1 从nor 驱动程序的入口函数开始，分析需要自己写的代码部分 xx_nor_init   >struct map_info   *nor_map = kzmalloc()//分配一个map_info的结构体，然后填充   >simple_map_init(nor_map)//填充map_info结构体的read copy_from write copy_to 指针函数   >struct mtd_info   *nor_mtd = do_map_probe(\"cfi_probe\", nor_map);    do_map_probe       >struct mtd_chip_driver *drv=get_mtd_chip_driver(name)//指到芯片相应的结构体变量       +get_mtd_chip_driver       +  >list_for_each(pos, &chip_drvs_list) //遍历mtd_chip_driver结构体链表 chip_drvs_list 中的每一个元素       +      >strcmp(this->name, name) //比较mtd_chip_driver结构体中的名字和传入的参数名字是否相同，       +                                //相同就把相应的mtd_chip_driver结构体变量的地址返回       >struct mtd_info *ret = drv->probe(map);//调用mtd_chip_driver结构体变量提供的probe函数       >module_put(drv->module);//减小引用计数       >return ret;返回probe函数得到的mtd_info结构体指针 2 在代码中，先使用cfi 操作的方式调用do_map_probe函数，如果不支持的话，再使用jedec操作方式调用do_map_probe函数   那么，接下来就分析cfi 的操作方式   a.cfi方式的nor flash操作     分析linux-2.6.22源码分析\\linux-2.6.22\\drivers\\mtd\\chips\\cfi_probe.c 这个文件     先定义了一个全局变量结构体      static struct mtd_chip_driver cfi_chipdrv = {       .probe  = cfi_probe,       .name  = \"cfi_probe\",       .module  = THIS_MODULE      };     模块的入口函数static int __init cfi_probe_init(void) //比以前的驱动入口函数多了个__init，个人估计是这个                                                         //c文件应该是被编译进内核了，也就是比用户的驱动程序                                                         //再早地运行        >register_mtd_chip_driver(&cfi_chipdrv); //把cfi_chipdrv加入到mtd_chip_driver结构体链表 chip_drvs_list 中           >list_add(&drv->list, &chip_drvs_list);     那么当用户的驱动程序调用do_map_probe(\"cfi_probe\", nor_map)时，就用把“cfi_probe” 与mtd_chip_driver结构体链表     chip_drvs_list 中的每一个元素的.name项比较，相同就把对应的元素返回，然后调用它的probe函数。     所以当调用了do_map_probe(\"cfi_probe\", nor_map)后，再调用ret->probe()函数，其实就是在调用cfi_probe()。         cfi_probe.c中还定义了一个如下的全局变量     static struct chip_probe cfi_chip_probe = {      .name  = \"CFI\",      .probe_chip = cfi_probe_chip     };   分析cfi_probe的代码：       cfi_probe(struct map_info *map)       >mtd_do_chip_probe(map, &cfi_chip_probe)       +  >struct cfi_private *cfi= genprobe_ident_chips(map, &cfi_chip_probe);//首先探测下看是否支持CFI       +     >genprobe_new_chip(map, &cfi_chip_probe, &cfi)       +        >cfi_chip_probe->probe_chip() //调用chip_probe结构体的probe_chip函数，       +        ||                              //这里也就是： cfi_probe_chip       +         =cfi_probe_chip()  //在cfi_probe_chip()函数中实现了CFI方式 对nor flash的探测。       >check_cmd_set(map, 1)          >cfi_cmdset_0020 //CONFIG_MTD_CFI_STAA          >cfi_cmdset_unknown  //default                  >cfi_cmdset_0001 //CONFIG_MTD_CFI_INTELEXT                  >cfi_cmdset_0002 //CONFIG_MTD_CFI_AMDSTD               //填充函数完成mtd_info结构体的操作函数         mtd->erase   = cfi_amdstd_erase_varsize;        mtd->write   = cfi_amdstd_write_words;        mtd->read    = cfi_amdstd_read;        mtd->sync    = cfi_amdstd_sync;        mtd->suspend = cfi_amdstd_suspend;        mtd->resume  = cfi_amdstd_resume;        mtd->flags   = MTD_CAP_NORFLASH;       由nand flash相关驱动的代码分析可知，当应用程序对块设备如nor flash，进行读写等操作时，文件系统经过       一系列的函数调用，最后会调用块设备驱动程序里的mtd_info结构体的erase write read等操作函数，上述函数       则正好完成了相应的接口，从而完成对Nor flash硬件的读、写与擦除。       到此就完成了CFI方式下对Nor Flash的操作   b.jedec方式的nor flash操作        开始的部分和CFI方式相类似：     static struct mtd_chip_driver jedec_chipdrv = {      .probe = jedec_probe,      .name = \"jedec_probe\",      .module = THIS_MODULE     };     static int __init jedec_probe_init(void)        >register_mtd_chip_driver(&jedec_chipdrv) //加入到chip_drvs_list链表中             >list_add(&drv->list, &chip_drvs_list);     用户提供的驱动调用do_map_probe后，会比较传入的\"操作方式\"与链表中的.name进行比较，如果有jedec_probe     则最终会调用jedec_probe     jedec_probe       >mtd_do_chip_probe          >struct mtd_info *mtd = check_cmd_set(map, 1)          //看到这里发现，又和CFI方式殊途同归啦！接下来又是设置mtd_info结构体中相关的操作函数     3.接下来，就用内存来模拟一个nor flash       闲话不说，上代码： virtual_nor_probe.c如下： /*  *参考drivers\\mtd\\chips\\Cfi_probe.c  *参考drivers\\mtd\\chips\\map_ram.c  *此程序还有一点瑕疵:就是rmmod时不能卸载驱动，这是为什么呢?  *  */ #include<linux/kernel.h> #include<linux/module.h> #include<linux/init.h> #include<linux/gfp.h> #include<linux/slab.h> #include<linux/mtd/map.h> #include<linux/mtd/mtd.h> #include<asm/page.h> static struct mtd_info * v_nor_probe(struct map_info *map); static struct mtd_chip_driver v_nor_drv = {  .probe  = v_nor_probe,  .name   = \"v_nor_probe\",  .module = THIS_MODULE, }; static int v_nor_erase(struct mtd_info *mtd, struct erase_info *instr) {  struct map_info *map = mtd->priv;  map_word allff;/*定义一个nor位宽相同的数组*/  unsigned long i;  allff = map_word_ff(map);/*全写入1*/  for(i=0;i<instr->len;i+= map_bankwidth(map)) /*擦除:也就是全写入1*/   map_write(map, allff, instr->addr + i);  instr->state = MTD_ERASE_DONE;  mtd_erase_callback(instr);  return 0; } static int v_nor_read(struct mtd_info *mtd, loff_t from, size_t len, size_t *retlen, u_char *buf) {  struct map_info *map = mtd->priv;  map_copy_from(map, buf, from, len);  *retlen = len;  return 0; } static int v_nor_write(struct mtd_info *mtd, loff_t to, size_t len, size_t *retlen, const u_char *buf) {  struct map_info *map = mtd->priv;  map_copy_to(map, to, buf, len);  *retlen = len;  return 0; } static void v_nor_sync(struct mtd_info *mtd) {  /*nothing to do*/  static int cnt;  printk(\"  *kernel virtual sync: %d\\n\",++cnt); } static struct mtd_info * v_nor_probe(struct map_info *map) {  struct mtd_info *mtd;  mtd = kzalloc(sizeof(struct mtd_info), GFP_KERNEL);  if(!mtd){   printk(\"v_nor_probe:kzalloc mtd_info failed\\n\");   return NULL;  }  map->fldrv = &v_nor_drv;  mtd->priv  = map;  mtd->name  = map->name;  mtd->size  = map->size;  mtd->type  = MTD_RAM;  mtd->erase = v_nor_erase;  mtd->read  = v_nor_read;  mtd->write = v_nor_write;  mtd->sync  = v_nor_sync;  mtd->flags = MTD_CAP_RAM;  mtd->writesize = 1;  mtd->erasesize = PAGE_SIZE;  while( mtd->size & (mtd->erasesize -1) )   mtd->erasesize >>= 1;  __module_get(THIS_MODULE);  return mtd; } static int __init virtual_nor_init(void) {  register_mtd_chip_driver(&v_nor_drv);  return 0; } static void __exit virtual_nor_exit(void) {  unregister_mtd_chip_driver(&v_nor_drv); } module_init(virtual_nor_init); module_exit(virtual_nor_exit); MODULE_LICENSE(\"GPL\");   virtual_nor_dev.c 如下： /*  * 其实可以把这两个程序写成一个程序，或者写成一个平台驱动  */ #include<linux/kernel.h> #include<linux/init.h> #include<linux/module.h> #include<linux/slab.h> #include<linux/mtd/mtd.h> #include<linux/mtd/map.h> #include<linux/mtd/partitions.h> #include<linux/gfp.h> #include<asm/sizes.h> #define V_NOR_SIZE 0x100000 static struct mtd_info  *v_nor_mtd; static struct map_info   *v_nor_map; static char *v_nor_flash; static struct mtd_partition v_nor_parts[]= {  [0] = {   .name   = \"vitual_nor1\",   .offset = 0,   .size   = SZ_256K,  },  [1] = {   .name   = \"vitual_nor2\",   .offset = MTDPART_OFS_APPEND,   .size   = MTDPART_SIZ_FULL,  }, }; static int gq_nor_init(void) {  v_nor_flash = kzalloc(V_NOR_SIZE, GFP_KERNEL);  if(!v_nor_flash){   printk(\"malloc memory vitual nor failed\\n\");   return -1;  }  /* 1 为结构体分配内存*/  v_nor_map = kzalloc(sizeof(struct map_info), GFP_KERNEL);  if(!v_nor_map){   printk(\"nor:map_info alloc failed\\n\");   return -1;  }   /* 2 设置结构体*/  v_nor_map->name  = \"vitual_gq_nor\";  v_nor_map->size  = 0x100000;/*nor flash的容量,要大于2M==实际大小*/  v_nor_map->phys  = (resource_size_t)v_nor_flash;/*虚拟磁盘\"物理地址\"*/  v_nor_map->bankwidth = 2;/*位宽=bankwidth*8 */  v_nor_map->virt  = v_nor_flash;/*v_nor_flash本身就是虚拟地址，所以不需要再进行映射*/ #if 0  v_nor_map->virt  = ioremap(nor_map->phys,nor_map->size);/*为nor flash映射内存空间*/  if(!nor_map->virt){   printk(\"nor flash map memory failed\\n\");   kfree(nor_map);   return -2;  } #endif  simple_map_init(v_nor_map);  v_nor_mtd = do_map_probe(\"v_nor_probe\", v_nor_map);  if(!v_nor_mtd)  {   v_nor_mtd = do_map_probe(\"jedec_probe\", v_nor_map);   if(!v_nor_mtd){    printk(\"do_map_probe failed\\n\");    kfree(v_nor_mtd);    return -3;   }  }  v_nor_mtd->owner = THIS_MODULE;  /* 3 add_mtd_partitions*/  if(add_mtd_partitions(v_nor_mtd,v_nor_parts,2)){   printk(\"add_mtd_partitions failed \\n\");   return -4;  }  return 0; } static void gq_nor_exit(void) {  del_mtd_partitions(v_nor_mtd); // iounmap(nor_map->virt);  kfree(v_nor_map);  kfree(v_nor_mtd); } module_init(gq_nor_init); module_exit(gq_nor_exit); MODULE_LICENSE(\"GPL\");        ","title":"linux块设备驱动程序分析之 nor flash驱动分析 以及使用内存模拟 nor flash"},{"content":"from：http://bbs.chinaunix.net/thread-1321303-1-1.html 请问 linux下怎样把几个静态库（libabc.a...）编译成一个动态库（libtest.so） 我用 gcc -shared -fPIC libabc.a libdef.a -o libtest.so   生成的 libtest.so 只有空架子， 没内容，  静态库都是用 ar cru 一批 .o 文件产生的。  谢谢 sorry, 先前帖子写错了。这是Makefile LIBDIR = ./lib SRCDIR = ./src VPATH  = $(SRCDIR) PROJ  = iccp OPT   = DEFS  = LIST  = >> cc.lst 2>&1 CC = gcc LIBRARY = $(LIBDIR)/$(PROJ).so OBJECTS = $(LIBDIR)/mem.a \\         $(LIBDIR)/slog.a        \\         $(LIBDIR)/util.a        \\         $(LIBDIR)/mlogl.a        \\         $(LIBDIR)/asn1l.a        \\         $(LIBDIR)/mmsl.a        \\         $(LIBDIR)/mmsle.a        \\         $(LIBDIR)/mvl.a        \\         $(LIBDIR)/mi.a        \\         $(LIBDIR)/ositcpe.a         all: $(LIBRARY) $(LIBRARY): $(OBJECTS)         rm -f $(LIBRARY)         $(CC) -shared -fPIC $(OBJECTS) -Wl,-soname -Wl,$@ -o $@ -lc $(LIST)         @echo \"FINISHED CREATING $(LIBRARY) LIBRARY\" $(LIST)         @echo \"-----------------------------------------------------\" $(LIST) $(LIBDIR)/mem.a:          $(MAKE) $(AM_MAKEFLAGS) -f mem.mk $(LIBDIR)/slog.a:          $(MAKE) $(AM_MAKEFLAGS) -f slog.mk $(LIBDIR)/util.a:          $(MAKE) $(AM_MAKEFLAGS) -f util.mk $(LIBDIR)/mlogl.a:          $(MAKE) $(AM_MAKEFLAGS) -f mlogl.mk $(LIBDIR)/asn1l.a:          $(MAKE) $(AM_MAKEFLAGS) -f asn1l.mk $(LIBDIR)/mmsl.a:          $(MAKE) $(AM_MAKEFLAGS) -f mmsl.mk $(LIBDIR)/mmsle.a:          $(MAKE) $(AM_MAKEFLAGS) -f mmsle.mk $(LIBDIR)/mvl.a:          $(MAKE) $(AM_MAKEFLAGS) -f mvl.mk $(LIBDIR)/mi.a:          $(MAKE) $(AM_MAKEFLAGS) -f mi.mk $(LIBDIR)/ositcpe.a:          $(MAKE) $(AM_MAKEFLAGS) -f ositcpe.mk ls -l lib 显示 : total 1456 -rw-r--r-- 1 root root  43078 2008-11-27 17:36 asn1l.a -rwxrwxr-x 1 root root   3928 2008-11-27 17:36 iccp.so -rw-r--r-- 1 root root   4748 2008-11-27 17:31 mem.a -rw-r--r-- 1 root root 211968 2008-11-27 17:36 mi.a -rw-r--r-- 1 root root 137024 2008-11-27 17:36 mlogl.a -rw-r--r-- 1 root root 314742 2008-11-27 17:36 mmsl.a -rw-r--r-- 1 root root 310012 2008-11-27 17:36 mmsle.a -rw-r--r-- 1 root root 144370 2008-11-27 17:36 mvl.a -rw-r--r-- 1 root root 147536 2008-11-27 17:36 ositcpe.a -rw-r--r-- 1 root root  26370 2008-11-27 17:35 slog.a -rw-r--r-- 1 root root  94846 2008-11-27 17:36 util.a 还有， 编译库，makefile 中是不是需要显式的加前缀 lib ? 谢谢 都不愿意回答啊？ 我自己观察别的lib 的编译流程， 找到了解决办法： $(CC) -shared -fPIC $(OBJECTS) -Wl,-soname -Wl,$@ -o $@ 改成： $(CC) -shared -fPIC -Wl,--whole-archive   $(OBJECTS) -Wl,--no-whole-archive  -Wl,-soname -Wl,$@ -o $@ 即可 网上有人说必须把 .a 解开 再 重新连接。其实不需要。 附： g++和gcc的一些编译参数说明 zz for(int var=0; var<5; var++){     ... } var++; //使用for循环中定义的变量 cout << var << endl;加-fno-for-scope后可以通过编译：g++ main.cpp -fno-for-scope   int typeof; //与关键字重名 typeof = 1; cout << typeof << endl;加-fno-gnu-keywords后可以通过编译：g++ main.cpp -fno-gnu-keywords   int and, xor; //使用了and, xor等操作符来作为变量名 and = 1; xor = 2; cout << \"and = \" << and << \" xor = \" << xor << endl;加-fno-operator-names后可以通过编译：g++ main.cpp -fno-operator-names   /usr/bin/cc -> /etc/alternatives/cc -> /usr/bin/gcc -> gcc-4.3cc与gcc是同一个程序   cc main.c -S编译成汇编文件main.s   cc main.s -o main可以直接编译汇编文件为可执行文件   cc main.c -o main -v加-v可以查看头文件及库文件的搜索路径及具体的编译参数   cc main.c -o main -L. -lfunc cc main.c -o main ./libfunc.so可以以二种形式使用动态库   g++ main.cpp -o main gcc main.cpp -o main -lstdc++使用g++及gcc来编译 以下为对参数--no-whole-archive及--whole-archive的尝试，先构造三个C文件://a.c void afunc() { printf(\"inside a afunc()/n\"); } void samefunc() { printf(\"in samefunc of a.c/n\"); }   //b.c void bfunc() { printf(\"inside a bfunc()/n\"); } void samefunc() { printf(\"in samefunc of b.c/n\"); }   //test.c extern void afunc(); extern void bfunc(); void testfunc()  {     afunc();     bfunc(); }   先用以下的命令来生成test.o, a.sa, b.sa文件: gcc a.c -c -o a.o ar -q a.o a.sa gcc b.c -c -o b.o ar -q b.o b.sa gcc test.c -c -o test.o   gcc -shared -Wl,--no-whole-archive a.sa b.sa -Wl,--no-whole-archive -o m.so上面的命令运行通过, 但生成的文件中是不包含afunc, bfunc, samefunc的,不可用   gcc -shared test.o -Wl,--no-whole-archive a.sa b.sa -Wl,--no-whole-archive -o m.so上面的命令运行失败, 错误如下: b.sa(b.o): In function `samefunc': b.c:(.text+0x14): multiple definition of `samefunc' a.sa(a.o):a.c:(.text+0x14): first defined here collect2: ld returned 1 exit status   gcc -shared -Wl,--no-whole-archive a.sa b.sa -Wl,--no-whole-archive test.o -o m.so上面的命令运行通过,与再上面的命令相比,只是调换了test.o在命令行中的位置 但生成的文件中是不包含afunc, bfunc, samefunc的,不可用   如果以以下方式修改test.c //test.c #include <stdio.h> #include <stdlib.h> extern void afunc(); extern void bfunc(); void testfunc() {     afunc();     //bfunc();   <---------------just comment following line } gcc -shared test.o -Wl,--no-whole-archive a.sa b.sa -Wl,--no-whole-archive -o m.so 链接成功,生成的m.so也是可用的,原因是: 当test.c中不使用bfunc时，也就不再加载b.sa(虽然b.sa是在命令行中的), 也就不会出现与a.sa中存在二个同名的samefunc函数了   当改成使用-Wl,--whole-archive后，只有当a.sa与b.sa中没有同名的函数时以下命令才可通过: gcc -shared test.o -Wl,--whole-archive a.sa b.sa -Wl,--no-whole-archive -o m.so此m.so可以使用   总结： 1)当使用--whole-archive时，其会把所有的--whole-archive之后的.sa中的所有函数全部加入到生成的文件中来，这样的情况下，如果有同名函数，则链接就不会通过; 2)当使用--no-whole-archieve时，则此后的所有文件中的所有函数都不会加到生成的文件中,但下面的第3点情况例外; 3)如果命令行中有.o文件，如test.o, 并且.o文件后面有.sa文件，则会把.o文件中用到的函数的.sa文件加入到生成的结果文件中来(即使.sa前有--no-whole-archieve);所以这和.o及.sa的顺序有关系。   注： --whole-archive, --no-whole-archive是ld的命令，gcc并不认识，所以要加-Wl，换成如下命令也是一样的： ld -shared test.o --whole-archive a.sa b.sa --no-whole-archive -o m.so   ld的其它一些用法: 把多个.o加成.a: ar -q result.a s1.o s2.o s3.o 在一个.a中去掉一个.o ar -d result.a s1.o 居然可以在一个.a中加入多个相同的.o ar -q result.a s1.o s1.o s1.o   g++ -v的输出为： Using built-in specs. Target: i486-linux-gnu Configured with:     ../src/configure -v --with-pkgversion='Ubuntu 4.3.3-5ubuntu4'     --with-bugurl=file:///usr/share/doc/gcc-4.3/README.Bugs     --enable-languages=c,c++,fortran,objc,obj-c++     --prefix=/usr --enable-shared --with-system-zlib --libexecdir=/usr/lib     --without-included-gettext --enable-threads=posix --enable-nls     --with-gxx-include-dir=/usr/include/c++/4.3     --program-suffix=-4.3 --enable-clocale=gnu --enable-libstdcxx-debug     --enable-objc-gc --enable-mpfr --enable-targets=all     --with-tune=generic --enable-checking=release --build=i486-linux-gnu     --host=i486-linux-gnu --target=i486-linux-gnu Thread model: posix gcc version 4.3.3 (Ubuntu 4.3.3-5ubuntu4)    当gcc加-ansi参数编译时，有以下限制： 1)文件中不能以//来加注解","title":"把静态库打包成动态库"},{"content":"  说明本人用的是笔记本来搭建VMWare开发环境，在Windows上面装VMWare6.5，在VM6.5上安装linux—ubuntu10.04发行版，ubuntu作为编译环境，并且建立tftpboot文件夹来提供下载的bootImage，安装好VMWare和Ubuntu10.04之后再进行一下设置，建立tftp服务器，如ubuntu10.04下安装tftp的设置，测试成功后进行以下设置，连接开发板： 1、 在”开始”à”程序”à”VM”à” Virtual Network Editor”，在Host Virtual Network Mapping中将VMnet0指定为笔记本的有线物理网卡，修改完毕后“确定”保存。如下图所示：   2、 打开网络连接，将笔记本的有线网卡和无线网卡配置成如下图所示：将VMWare Bridge Protocol无线不选，有线选上，因为我们要用有线RJ45网口通过一根网线直接接到开发板上面的网口上。   开发板通过串口观察Uboot的IP为192.168.1.172，而tftp server的IP为192.168.1.3。这样将有线物理网卡的IP设置成为192.168.1.xxx与以上两个IP在同一个网段里。 3、 打开VM虚拟机启动画面，在networks adapter中将网络选择成custumàVMnet0，界面如下，修改完毕后确认保存。 4、 进入到ubuntu后在/etc/network中的interfaces文件进行编辑加入静态配置的IP地址：192.168.1.3 打开interfaces #vim /etc/network/interfaces 未编辑时显示： auto lo iface lo inet loopback //加入以下语句 auto eth0 iface eth0 inet static address 192.168.1.3 netmask 255.255.255.0 gateway 192.168.1.1 ：wq //保存并退出。 重新启动网络接口 #/etc/init.d/networking restart 此时用#ifconfig观察是否配置成功，确认网络连接正常。连接开发板，开发板Uboot启动。 #ping 192.168.1.172是否有返回包并且在开发板的串口也可以PING tftp服务器网络地址。 5、 tftp的建立及启动如ubuntu10.04下安装tftp所述建立。将需要编译好的文件放入到tftpboot目录下。就可以实现tftp的下载了。 6、 OK ENJOY.","title":"VMware的配置及ubuntu10.04 tftp 与嵌入式开发板的连接设置"},{"content":"安装ubuntu有多种方式，我使用过三种方式。1.硬盘安装，2.刻盘安装，3.U盘安装。 1.下载光盘映像 目前可选12.04LTS（长期支持版本） http://www.ubuntu.org.cn/desktop/get-ubuntu/download/ 2.安装前的准备 如果你想使用双系统，win7 + ubuntu 或者win xp + ubuntu，那你一定要做好安装前的准备，否则安装时分区造成数据丢失就后悔莫及了。 win 7 自带磁盘工具（右击计算机–管理–磁盘管理）将其中一个分区压缩出大于15G的空间，不用格式化，只要记住压缩出空间在磁盘中的位置即可 win xp 貌似没有自带磁盘工具。所以使用分区魔法师分出同上的一块空间。 3.安装过程 3.1硬盘安装 a.Windows下虚拟光驱使用daemon tools,加载刚才下载的光盘镜像。 b.在加载后的虚拟光驱中的下面两个文件夹复制到C盘根目录 .disk casper c.双击虚拟光驱，进入了wubi安装，选择第一项 演示和完全安装 d.此时断开网络，安装过程一定要断开网络，因为有网络会进行自动更新， e.下一步 选择 帮助我从光盘启动 ，然后点 完成。 f.重新启动,系统自动引导进入Ubuntu进行继续安装，包括分区等操作。 3.2 U盘安装 我使用的是1G的TF卡跟4G的金士顿U盘都测试成功，只需要按照步骤来，99%会成功。 下载ultraiso后，点击下图中图标打开刚下载的光盘镜像 选择菜单–启动–写入硬盘镜像…,打开后如下图所示（注意所选的写入方式要写成USB-HDD+）： 点击写入，等待软件写入。软件会自动格式化U盘，所以先备份好U盘数据。 完成之后打开U盘目录下的\\isolinux\\syslinux.cfg， 将default vesamenu.c32注释为 # default vesamenu.c32 4.正式安装 重启之后，将首选启动改为U盘，进入Ubuntu之后按一下F6中的其他设置选项,将下列三项选中（使用空格键选中） 选中后前面会出现小x acpi=off noapic nolapic 确定后选择Install Ubuntu即可。","title":"Ubuntu 12.04硬盘安装与U盘安装（图文）"},{"content":"一：VS（以vs2010为例）      创建txt文档，修改为 xx.bat;      内容如下：      set VS_DEV=\"%VS100COMNTOOLS%..\\IDE\\devenv.com\"     set srcPath=D:\\DTC\\DTr\\trunk\\04code\\     %VS_DEV% %srcPath%/Oprofile.sln /Rebuild \"Debug\"     说明： VS_DEV 为VS的在环境变量中的简称，可以在 系统属性>环境变量>系统变量中查看                       二：Cygwin模式下自动makefile文件脚本        需创建2个脚本：x.cmd, xx.sh        1.  x.cmd 内容如下： @echo offREM 编译输出的文件名称set CYGWIN=D:/cygwinset OP_DB_PATH=D:\\DTCenterCode\\DTCenterV1R2\\04code\\Oprofile\\oprofile_linuxset num=0:StartCompileecho ------------%num%------------REM 如果编译3次仍然没有生成目标程序则退出编译if %num%==3 goto Endecho ====================================================================echo 开始编译oprofile_linux工程......echo ====================================================================REM 跳转到CYGWIN目录chdir /D %CYGWIN%/binbash -li %OP_DB_PATH%/opreport.sh %OP_DB_PATH%echo ====================================================================set /a (num=%num%+1)if not exist %OP_DB_PATH%/opreport.exe goto StartCompile:End@echo on     2. xx.sh 内容如下： #源码路径src_path=$1cd $src_pathmake -f opreport.make cleanmake -j9 -f opreport.make 运行x.cmd将自动运行你所创建的 xx.make 编译工程     有帮助的话，留个脚印也好！","title":"【整理】脚本编译相关（VS、cygwin）"},{"content":"    刚在浏览帖子的时候，看到这个帖子，对内存分配的原理讲得很透彻，看了一遍，还未理解透彻，特收藏下来，以后慢慢回味!   现象 1 压力测试过程中，发现被测对象性能不够理想，具体表现为：  进程的系统态CPU消耗20，用户态CPU消耗10，系统idle大约70  2 用ps -o majflt,minflt -C program命令查看，发现majflt每秒增量为0，而minflt每秒增量大于10000。 初步分析 majflt代表major fault，中文名叫大错误，minflt代表minor fault，中文名叫小错误。 这两个数值表示一个进程自启动以来所发生的缺页中断的次数。 当一个进程发生缺页中断的时候，进程会陷入内核态，执行以下操作：  检查要访问的虚拟地址是否合法  查找/分配一个物理页  填充物理页内容（读取磁盘，或者直接置0，或者啥也不干）  建立映射关系（虚拟地址到物理地址）  重新执行发生缺页中断的那条指令  如果第3步，需要读取磁盘，那么这次缺页中断就是majflt，否则就是minflt。  此进程minflt如此之高，一秒10000多次，不得不怀疑它跟进程内核态cpu消耗大有很大关系。 分析代码 查看代码，发现是这么写的：一个请求来，用malloc分配2M内存，请求结束后free这块内存。看日志，发现分配内存语句耗时10us，平均一条请求处理耗时1000us 。 原因已找到！  虽然分配内存语句的耗时在一条处理请求中耗时比重不大，但是这条语句严重影响了性能。要解释清楚原因，需要先了解一下内存分配的原理。  内存分配的原理 从操作系统角度来看，进程分配内存有两种方式，分别由两个系统调用完成：brk和mmap（不考虑共享内存）。brk是将数据段(.data)的最高地址指针_edata往高地址推，mmap是在进程的虚拟地址空间中（一般是堆和栈中间）找一块空闲的。这两种方式分配的都是虚拟内存，没有分配物理内存。在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。  在标准C库中，提供了malloc/free函数分配释放内存，这两个函数底层是由brk，mmap，munmap这些系统调用实现的。  下面以一个例子来说明内存分配的原理：            1进程启动的时候，其（虚拟）内存空间的初始布局如图1所示。其中，mmap内存映射文件是在堆和栈的中间（例如libc-2.2.93.so，其它数据文件等），为了简单起见，省略了内存映射文件。_edata指针（glibc里面定义）指向数据段的最高地址。  2进程调用A=malloc(30K)以后，内存空间如图2：malloc函数会调用brk系统调用，将_edata指针往高地址推30K，就完成虚拟内存分配。你可能会问：只要把_edata+30K就完成内存分配了？事实是这样的，_edata+30K只是完成虚拟地址的分配，A这块内存现在还是没有物理页与之对应的，等到进程第一次读写A这块内存的时候，发生缺页中断，这个时候，内核才分配A这块内存对应的物理页。也就是说，如果用malloc分配了A这块内容，然后从来不访问它，那么，A对应的物理页是不会被分配的。  3进程调用B=malloc(40K)以后，内存空间如图3.            4进程调用C=malloc(200K)以后，内存空间如图4：默认情况下，malloc函数分配内存，如果请求内存大于128K（可由M_MMAP_THRESHOLD选项调节），那就不是去推_edata指针了，而是利用mmap系统调用，从堆和栈的中间分配一块虚拟内存。这样子做主要是因为brk分配的内存需要等到高地址内存释放以后才能释放（例如，在B释放之前，A是不可能释放的），而mmap分配的内存可以单独释放。当然，还有其它的好处，也有坏处，再具体下去，有兴趣的同学可以去看glibc里面malloc的代码了。  5进程调用D=malloc(100K)以后，内存空间如图5.  6进程调用free(C)以后，C对应的虚拟内存和物理内存一起释放            7进程调用free(B)以后，如图7所示。B对应的虚拟内存和物理内存都没有释放，因为只有一个_edata指针，如果往回推，那么D这块内存怎么办呢？当然，B这块内存，是可以重用的，如果这个时候再来一个40K的请求，那么malloc很可能就把B这块内存返回回去了。  8进程调用free(D)以后，如图8所示。B和D连接起来，变成一块140K的空闲内存。  9默认情况下：当最高地址空间的空闲内存超过128K（可由M_TRIM_THRESHOLD选项调节）时，执行内存紧缩操作（trim）。在上一个步骤free的时候，发现最高地址空闲内存超过128K，于是内存紧缩，变成图9所示。 真相大白 说完内存分配的原理，那么被测模块在内核态cpu消耗高的原因就很清楚了：每次请求来都malloc一块2M的内存，默认情况下，malloc调用mmap分配内存，请求结束的时候，调用munmap释放内存。假设每个请求需要6个物理页，那么每个请求就会产生6个缺页中断，在2000的压力下，每秒就产生了10000多次缺页中断，这些缺页中断不需要读取磁盘解决，所以叫做minflt；缺页中断在内核态执行，因此进程的内核态cpu消耗很大。缺页中断分散在整个请求的处理过程中，所以表现为分配语句耗时（10us）相对于整条请求的处理时间（1000us）比重很小。 解决办法 将动态内存改为静态分配，或者启动的时候，用malloc为每个线程分配，然后保存在threaddata里面。但是，由于这个模块的特殊性，静态分配，或者启动时候分配都不可行。另外，Linux下默认栈的大小限制是10M，如果在栈上分配几M的内存，有风险。  禁止malloc调用mmap分配内存，禁止内存紧缩。 在进程启动时候，加入以下两行代码： mallopt(M_MMAP_MAX, 0);         // 禁止malloc调用mmap分配内存 mallopt(M_TRIM_THRESHOLD, -1);  // 禁止内存紧缩 效果：加入这两行代码以后，用ps命令观察，压力稳定以后，majlt和minflt都为0。进程的系统态cpu从20降到10。 小结 可以用命令ps -o majflt minflt -C program来查看进程的majflt, minflt的值，这两个值都是累加值，从进程启动开始累加。在对高性能要求的程序做压力测试的时候，我们可以多关注一下这两个值。  如果一个进程使用了mmap将很大的数据文件映射到进程的虚拟地址空间，我们需要重点关注majflt的值，因为相比minflt，majflt对于性能的损害是致命的，随机读一次磁盘的耗时数量级在几个毫秒，而minflt只有在大量的时候才会对性能产生影响。","title":"操作系统内存分配原理（帖子中转载）"},{"content":"1、初级阶段 (1) 命令是必须要学的，linux常用的命令大概在80左右，这些常用命令一定要熟练掌握。 (2) 掌握linux软件包的常用安装方法，例如源码安装、RPM方式安装。 (3) 学习添加外部设备，安装设备驱动程序(比如网卡驱动) (4) 熟悉Drub/Lilo引导程序及简单的修复操作 (5) 熟悉linux的文件系统和目录结构以及linux基本运行原理 (6) 掌握vi、gcc、gdb等常用编辑器、编译器和调试器 (7) 理解shell别名、管道、I/O重定向、输入和输出以及shell简单脚本编程 (8) 学习linux环境下的网络基本组建 2.高级阶段 (1) 尝试阅读linux内核代码：这需要具有一定的C、C++语言基础，因为C、C++是linux/UNIX的核心语言，系统代码都是用C写的 (2) 尝试编译安装和调试自己的linux内核：在阅读源码了解了linux底层的运行原理后，完全可以编译一个适合自己的linux系统 (3) 深入学习shell、perl和cgi等脚本语言：这些脚本语言在linux下非常强大，它们能完成用户想做的任何事情，熟练掌握这些语言，可以让用户在linux下游刃有余 (4) 构建企业级linux高可用集群系统：linux下有很多开源的集群软件，利用这些免费的集群软件完全可以构建出与商业UNIX系统相媲美的集群系统","title":"linux学习之路"},{"content":"最近因为项目原因，需要写一个根据路径字符串创建目录的函数，需要支持windows和linux，特贡献出来。 1。首先请加上这些预编译 #ifdef _WIN32 #include <direct.h> #include <io.h> #elif _LINUX #include <stdarg.h> #include <sys/stat.h> #endif #ifdef _WIN32 #define ACCESS _access #define MKDIR(a) _mkdir((a)) #elif _LINUX #define ACCESS access #define MKDIR(a) mkdir((a),0755) #endif   2。函数体 INT CreatDir(char *pszDir) {  INT32 i = 0;  INT32 iRet;  INT32 iLen = strlen(pszDir);  //在末尾加/  if (pszDir[iLen - 1] != '\\\\' && pszDir[iLen - 1] != '/')  {   pszDir[iLen] = '/';   pszDir[iLen + 1] = '\\0';  }  // 创建目录  for (i = 0;i < iLen;i ++)  {   if (pszDir[i] == '\\\\' || pszDir[i] == '/')   {     pszDir[i] = '\\0';    //如果不存在,创建    iRet = ACCESS(pszDir,0);    if (iRet != 0)    {     iRet = MKDIR(pszDir);     if (iRet != 0)     {      return -1;     }     }    //支持linux,将所有\\换成/    pszDir[i] = '/';   }   }  return 0; }","title":"C/C++创建目录函数，支持windows和linux"},{"content":"（一）文件操作篇  1、creat（建立文件） 头文件 1 #include<sys/types.h>2 #include<sys/stat.h>3 #include<fcntl.h> 定义函数 1 int creat(const char * pathname, mode_tmode); 函数说明 参数pathname指向欲建立的文件路径字符串。creat()相当于使用下列的调用方式调用open() 1 open(const char * pathname ,(O_CREAT|O_WRONLY|O_TRUNC)); 错误代码 关于参数mode请参考open（）函数。 返回值 creat()会返回新的文件描述词，若有错误发生则会返回-1，并把错误代码设给errno。 EEXIST 参数pathname所指的文件已存在。 EACCESS 参数pathname 所指定的文件不符合所要求测试的权限 EROFS 欲打开写入权限的文件存在于只读文件系统内 EFAULT 参数pathname 指针超出可存取的内存空间 EINVAL 参数mode 不正确。 ENAMETOOLONG 参数pathname太长。 ENOTDIR 参数pathname为一目录 ENOMEM 核心内存不足 ELOOP 参数pathname有过多符号连接问题。 EMFILE 已达到进程可同时打开的文件数上限 ENFILE 已达到系统可同时打开的文件数上限 附加说明 creat()无法建立特别的装置文件，如果需要请使用mknod()。 2、open（打开文件） 头文件 1 #include<sys/types.h>2 #include<sys/stat.h>3 #include<fcntl.h> 定义函数 1 int open( const char * pathname, int flags);2 int open( const char * pathname,int flags, mode_t mode); 函数说明 参数pathname 指向欲打开的文件路径字符串。下列是参数flags 所能使用的旗标: O_RDONLY 以只读方式打开文件 O_WRONLY 以只写方式打开文件 O_RDWR 以可读写方式打开文件。上述三种旗标是互斥的，也就是不可同时使用，但可与下列的旗标利用OR(|)运算符组合。 O_CREAT 若欲打开的文件不存在则自动建立该文件。 O_EXCL 如果O_CREAT 也被设置，此指令会去检查文件是否存在。文件若不存在则建立该文件，否则将导致打开文件错误。此外，若O_CREAT与O_EXCL同时设置，并且欲打开的文件为符号连接，则会打开文件失败。 O_NOCTTY 如果欲打开的文件为终端机设备时，则不会将该终端机当成进程控制终端机。 O_TRUNC 若文件存在并且以可写的方式打开时，此旗标会令文件长度清为0，而原来存于该文件的资料也会消失。 O_APPEND 当读写文件时会从文件尾开始移动，也就是所写入的数据会以附加的方式加入到文件后面。 O_NONBLOCK 以不可阻断的方式打开文件，也就是无论有无数据读取或等待，都会立即返回进程之中。 O_NDELAY 同O_NONBLOCK。 O_SYNC 以同步的方式打开文件。 O_NOFOLLOW 如果参数pathname 所指的文件为一符号连接，则会令打开文件失败。 O_DIRECTORY 如果参数pathname 所指的文件并非为一目录，则会令打开文件失败。 此为Linux2.2以后特有的旗标，以避免一些系统安全问题。参数mode 则有下列数种组合，只有在建立新文件时才会生效，此外真正建文件时的权限会受到umask值所影响，因此该文件权限应该为（mode-umaks）。 S_IRWXU00700 权限，代表该文件所有者具有可读、可写及可执行的权限。 S_IRUSR 或S_IREAD，00400权限，代表该文件所有者具有可读取的权限。 S_IWUSR 或S_IWRITE，00200 权限，代表该文件所有者具有可写入的权限。 S_IXUSR 或S_IEXEC，00100 权限，代表该文件所有者具有可执行的权限。 S_IRWXG 00070权限，代表该文件用户组具有可读、可写及可执行的权限。 S_IRGRP 00040 权限，代表该文件用户组具有可读的权限。 S_IWGRP 00020权限，代表该文件用户组具有可写入的权限。 S_IXGRP 00010 权限，代表该文件用户组具有可执行的权限。 S_IRWXO 00007权限，代表其他用户具有可读、可写及可执行的权限。 S_IROTH 00004 权限，代表其他用户具有可读的权限 S_IWOTH 00002权限，代表其他用户具有可写入的权限。 S_IXOTH 00001 权限，代表其他用户具有可执行的权限。 返回值 若所有欲核查的权限都通过了检查则返回0 值，表示成功，只要有一个权限被禁止则返回-1。 错误代码 EEXIST 参数pathname 所指的文件已存在，却使用了O_CREAT和O_EXCL旗标。 EACCESS 参数pathname所指的文件不符合所要求测试的权限。 EROFS 欲测试写入权限的文件存在于只读文件系统内。 EFAULT 参数pathname指针超出可存取内存空间。 EINVAL 参数mode 不正确。 ENAMETOOLONG 参数pathname太长。 ENOTDIR 参数pathname不是目录。 ENOMEM 核心内存不足。 ELOOP 参数pathname有过多符号连接问题。 EIO I/O 存取错误  3、close（关闭文件） 头文件 1 #include<unistd.h>  定义函数  1 int close(int fd);  函数说明 当使用完文件后若已不再需要则可使用close()关闭该文件，二close()会让数据写回磁盘，并释放该文件所占用的资源。参数fd为先前由open()或creat()所返回的文件描述词。 返回值 若文件顺利关闭则返回0，发生错误时返回-1。 错误代码 EBADF 参数fd 非有效的文件描述词或该文件已关闭。 附加说明 虽然在进程结束时，系统会自动关闭已打开的文件，但仍建议自行关闭文件，并确实检查返回值。  4、read（由已打开的文件读取数据） 头文件 1 #include<unistd.h>  定义函数  1 ssize_t read(int fd,void * buf ,size_t count);  函数说明 read()会把参数fd 所指的文件传送count个字节到buf指针所指的内存中。若参数count为0，则read()不会有作用并返回0。返回值为实际读取到的字节数，如果返回0，表示已到达文件尾或是无可读取的数据，此外文件读写位置会随读取到的字节移动。 附加说明 如果顺利read()会返回实际读到的字节数，最好能将返回值与参数count 作比较，若返回的字节数比要求读取的字节数少，则有可能读到了文件尾、从管道(pipe)或终端机读取，或者是read()被信号中断了读取动作。当有错误发生时则返回-1，错误代码存入errno中，而文件读写位置则无法预期。 错误代码 EINTR 此调用被信号所中断。 EAGAIN 当使用不可阻断I/O 时（O_NONBLOCK），若无数据可读取则返回此值。 EBADF 参数fd 非有效的文件描述词，或该文件已关闭。  5、write（将数据写入已打开的文件内） 头文件 1 #include<unistd.h>  定义函数  1 ssize_t write (int fd,const void * buf,size_t count);  函数说明 write()会把参数buf所指的内存写入count个字节到参数fd所指的文件内。当然，文件读写位置也会随之移动。 返回值 如果顺利write()会返回实际写入的字节数。当有错误发生时则返回-1，错误代码存入errno中。 错误代码 EINTR 此调用被信号所中断。 EAGAIN 当使用不可阻断I/O 时（O_NONBLOCK），若无数据可读取则返回此值。 EADF 参数fd非有效的文件描述词，或该文件已关闭。  6、flock（锁定文件或解除锁定） 头文件 1 #include<sys/file.h>  定义函数  1 int flock(int fd,int operation);  函数说明 flock()会依参数operation所指定的方式对参数fd所指的文件做各种锁定或解除锁定的动作。此函数只能锁定整个文件，无法锁定文件的某一区域。 参数 operation有下列四种情况: LOCK_SH 建立共享锁定。多个进程可同时对同一个文件作共享锁定。 LOCK_EX 建立互斥锁定。一个文件同时只有一个互斥锁定。 LOCK_UN 解除文件锁定状态。 LOCK_NB 无法建立锁定时，此操作可不被阻断，马上返回进程。通常与LOCK_SH或LOCK_EX 做OR(|)组合。 单一文件无法同时建立共享锁定和互斥锁定，而当使用dup()或fork()时文件描述词不会继承此种锁定。 返回值 返回0表示成功，若有错误则返回-1，错误代码存于errno。  7、lseek（移动文件的读写位置） 头文件 1 #include<sys/types.h>2 #include<unistd.h>  定义函数  1 off_t lseek(int fildes,off_t offset ,int whence);  函数说明 每一个已打开的文件都有一个读写位置，当打开文件时通常其读写位置是指向文件开头，若是以附加的方式打开文件(如O_APPEND)，则读写位置会指向文件尾。当read()或write()时，读写位置会随之增加，lseek()便是用来控制该文件的读写位置。参数fildes 为已打开的文件描述词，参数offset 为根据参数whence来移动读写位置的位移数。 参数 whence为下列其中一种: SEEK_SET 参数offset即为新的读写位置。 SEEK_CUR 以目前的读写位置往后增加offset个位移量。 SEEK_END 将读写位置指向文件尾后再增加offset个位移量。 当whence 值为SEEK_CUR 或SEEK_END时，参数offet允许负值的出现。 下列是教特别的使用方式: 1) 欲将读写位置移到文件开头时:lseek（int fildes,0,SEEK_SET）； 2) 欲将读写位置移到文件尾时:lseek（int fildes，0,SEEK_END）； 3) 想要取得目前文件位置时:lseek（int fildes，0,SEEK_CUR）； 返回值 当调用成功时则返回目前的读写位置，也就是距离文件开头多少个字节。若有错误则返回-1，errno 会存放错误代码。 附加说明 Linux系统不允许lseek（）对tty装置作用，此项动作会令lseek（）返回ESPIPE。  8、fcntl（文件描述词操作） 头文件 1 #include<unistd.h>2 #include<fcntl.h>  定义函数  1 int fcntl(int fd , int cmd);2 int fcntl(int fd,int cmd,long arg);3 int fcntl(int fd,int cmd,struct flock * lock);  函数说明 fcntl()用来操作文件描述词的一些特性。参数fd代表欲设置的文件描述词，参数cmd代表欲操作的指令。 有以下几种情况: F_DUPFD用来查找大于或等于参数arg的最小且仍未使用的文件描述词，并且复制参数fd的文件描述词。执行成功则返回新复制的文件描述词。请参考 dup2()。F_GETFD取得close-on-exec旗标。若此旗标的FD_CLOEXEC位为0，代表在调用exec()相关函数时文件将不会关闭。 F_SETFD 设置close-on-exec 旗标。该旗标以参数arg 的FD_CLOEXEC位决定。 F_GETFL 取得文件描述词状态旗标，此旗标为open（）的参数flags。 F_SETFL 设置文件描述词状态旗标，参数arg为新旗标，但只允许O_APPEND、O_NONBLOCK和O_ASYNC位的改变，其他位的改变将不受影响。 F_GETLK 取得文件锁定的状态。 F_SETLK 设置文件锁定的状态。此时flcok 结构的l_type 值必须是F_RDLCK、F_WRLCK或F_UNLCK。如果无法建立锁定，则返回-1，错误代码为EACCES 或EAGAIN。 F_SETLKW F_SETLK 作用相同，但是无法建立锁定时，此调用会一直等到锁定动作成功为止。若在等待锁定的过程中被信号中断时，会立即返回-1，错误代码为EINTR。参数lock指针为flock 结构指针，定义如下 1 struct flcok2 {3 short int l_type; /* 锁定的状态*/4 short int l_whence;/*决定l_start位置*/5 off_t l_start; /*锁定区域的开头位置*/6 off_t l_len; /*锁定区域的大小*/7 pid_t l_pid; /*锁定动作的进程*/8 };  l_type 有三种状态: F_RDLCK 建立一个供读取用的锁定 F_WRLCK 建立一个供写入用的锁定 F_UNLCK 删除之前建立的锁定 l_whence 也有三种方式: SEEK_SET 以文件开头为锁定的起始位置。 SEEK_CUR 以目前文件读写位置为锁定的起始位置 SEEK_END 以文件结尾为锁定的起始位置。 返回值 成功则返回0，若有错误则返回-1，错误原因存于errno.  9、fgets（由文件中读取一字符串） 头文件 1 include<stdio.h>  定义函数  1 char * fgets(char * s,int size,FILE * stream);  函数说明 fgets()用来从参数stream所指的文件内读入字符并存到参数s所指的内存空间，直到出现换行字符、读到文件尾或是已读了size-1个字符为止，最后会加上NULL作为字符串结束。 返回值 gets()若成功则返回s指针，返回NULL则表示有错误发生。  10、fputs（将一指定的字符串写入文件内） 头文件 1 #include<stdio.h>  定义函数  1 int fputs(const char * s,FILE * stream);  函数说明 fputs()用来将参数s所指的字符串写入到参数stream所指的文件内。 返回值 若成功则返回写出的字符个数，返回EOF则表示有错误发生。    （二）内存控制篇  1、calloc（配置内存空间） 头文件 1 #include <stdlib.h>  定义函数  1 void *calloc(size_t nmemb，size_t size);  函数说明 calloc()用来配置nmemb个相邻的内存单位，每一单位的大小为size，并返回指向第一个元素的指针。这和使用下列的方式效果相同:malloc(nmemb*size);不过，在利用calloc()配置内存时会将内存内容初始化为0。 返回值 若配置成功则返回一指针，失败则返回NULL。  2、free（释放原先配置的内存） 头文件 1 #include<stdlib.h>  定义函数  1 void free(void *ptr);  函数说明 参数ptr为指向先前由malloc()、calloc()或realloc()所返回的内存指针。调用free()后ptr所指的内存空间便会被收回。假若参数ptr所指的内存空间已被收回或是未知的内存地址，则调用free()可能会有无法预期的情况发生。若参数ptr为NULL，则free()不会有任何作用。  3、malloc（配置内存空间） 头文件 1 #include<stdlib.h>  定义函数  1 void * malloc(size_t size);  函数说明 malloc()用来配置内存空间，其大小由指定的size决定。 返回值 若配置成功则返回一指针，失败则返回NULL。 范例 void p = malloc(1024); /*配置1k的内存*/   （三）进程操作篇 1、execl（执行文件） 头文件 1 #include<unistd.h>  定义函数  1 int execl(const char * path,const char * arg,....);  函数说明 execl()用来执行参数path字符串所代表的文件路径，接下来的参数代表执行该文件时传递过去的argv(0)、argv[1]……，最后一个参数必须用空指针(NULL)作结束。 返回值 如果执行成功则函数不会返回，执行失败则直接返回-1，失败原因存于errno中。  2、execlp（从PATH 环境变量中查找文件并执行） 头文件 #include<unistd.h>  定义函数  1 int execlp(const char * file,const char * arg,……)；  函数说明 execlp()会从PATH 环境变量所指的目录中查找符合参数file的文件名，找到后便执行该文件，然后将第二个以后的参数当做该文件的argv[0]、argv[1]……，最后一个参数必须用空指针(NULL)作结束。 返回值 如果执行成功则函数不会返回，执行失败则直接返回-1，失败原因存于errno 中。 错误代码 参考execve()。  3、execv（执行文件） 头文件 1 #include<unistd.h>  定义函数  1 int execv (const char * path, char * const argv[ ]);  函数说明 execv()用来执行参数path字符串所代表的文件路径，与execl()不同的地方在于execve()只需两个参数，第二个参数利用数组指针来传递给执行文件。 返回值 如果执行成功则函数不会返回，执行失败则直接返回-1，失败原因存于errno 中。 错误代码 请参考execve（）。  4、execve（执行文件） 头文件 1 #include<unistd.h>  定义函数  1 int execve(const char * filename,char * const argv[ ],char * const envp[ ]);  函数说明 execve()用来执行参数filename字符串所代表的文件路径，第二个参数系利用数组指针来传递给执行文件，最后一个参数则为传递给执行文件的新环境变量数组。 返回值 如果执行成功则函数不会返回，执行失败则直接返回-1，失败原因存于errno 中。 错误代码 EACCES 1. 欲执行的文件不具有用户可执行的权限。 2. 欲执行的文件所属的文件系统是以noexec 方式挂上。 3.欲执行的文件或script翻译器非一般文件。 EPERM 1.进程处于被追踪模式，执行者并不具有root权限，欲执行的文件具有SUID 或SGID 位。 2.欲执行的文件所属的文件系统是以nosuid方式挂上，欲执行的文件具有SUID 或SGID 位元，但执行者并不具有root权限。 E2BIG 参数数组过大 ENOEXEC 无法判断欲执行文件的执行文件格式，有可能是格式错误或无法在此平台执行。 EFAULT 参数filename所指的字符串地址超出可存取空间范围。 ENAMETOOLONG 参数filename所指的字符串太长。 ENOENT 参数filename字符串所指定的文件不存在。 ENOMEM 核心内存不足 ENOTDIR 参数filename字符串所包含的目录路径并非有效目录 EACCES 参数filename字符串所包含的目录路径无法存取，权限不足 ELOOP 过多的符号连接 ETXTBUSY 欲执行的文件已被其他进程打开而且正把数据写入该文件中 EIO I/O 存取错误 ENFILE 已达到系统所允许的打开文件总数。 EMFILE 已达到系统所允许单一进程所能打开的文件总数。 EINVAL 欲执行文件的ELF执行格式不只一个PT_INTERP节区 EISDIR ELF翻译器为一目录 ELIBBAD ELF翻译器有问题。  5、execvp（执行文件） 头文件 1 #include<unistd.h>  定义函数  1 int execvp(const char *file ,char * const argv []);  函数说明 execvp()会从PATH 环境变量所指的目录中查找符合参数file 的文件名，找到后便执行该文件，然后将第二个参数argv传给该欲执行的文件。 返回值 如果执行成功则函数不会返回，执行失败则直接返回-1，失败原因存于errno中。 错误代码 请参考execve（）。  6、exit（正常结束进程） 头文件 1 #include<stdlib.h>  定义函数  1 void exit(int status);  函数说明 exit()用来正常终结目前进程的执行，并把参数status返回给父进程，而进程所有的缓冲区数据会自动写回并关闭未关闭的文件。  7、_exit（结束进程执行） 头文件 1 #include<unistd.h>  定义函数  1 void _exit(int status);  函数说明 _exit()用来立刻结束目前进程的执行，并把参数status返回给父进程，并关闭未关闭的文件。此函数调用后不会返回，并且会传递SIGCHLD信号给父进程，父进程可以由wait函数取得子进程结束状态。 附加说明 _exit（）不会处理标准I/O 缓冲区，如要更新缓冲区请使用exit（）。    8、vfork（建立一个新的进程） 头文件 1 #include<unistd.h>  定义函数  1 pid_t vfork(void);  函数说明 vfork()会产生一个新的子进程，其子进程会复制父进程的数据与堆栈空间，并继承父进程的用户代码，组代码，环境变量、已打开的文件代码、工作目录和资源限制等。Linux 使用copy-on-write(COW)技术，只有当其中一进程试图修改欲复制的空间时才会做真正的复制动作，由于这些继承的信息是复制而来，并非指相同的内存空间，因此子进程对这些变量的修改和父进程并不会同步。此外，子进程不会继承父进程的文件锁定和未处理的信号。注意，Linux不保证子进程会比父进程先执行或晚执行，因此编写程序时要留意 死锁或竞争条件的发生。 返回值 如果vfork()成功则在父进程会返回新建立的子进程代码(PID)，而在新建立的子进程中则返回0。如果vfork 失败则直接返回-1，失败原因存于errno中。 错误代码 EAGAIN 内存不足。ENOMEM 内存不足，无法配置核心所需的数据结构空间。  9、getpid（取得进程识别码） 头文件 1 #include<unistd.h>  定义函数  1 pid_t getpid(void);  函数说明 getpid（）用来取得目前进程的进程识别码，许多程序利用取到的此值来建立临时文件，以避免临时文件相同带来的问题。 返回值 目前进程的进程识别码  10、getppid（取得父进程的进程识别码） 头文件 1 #include<unistd.h>  定义函数  1 pid_t getppid(void);  函数说明 getppid()用来取得目前进程的父进程识别码。 返回值 目前进程的父进程识别码。  11、wait（等待子进程中断或结束） 头文件 1 #include<sys/types.h>2 #include<sys/wait.h>  定义函数  1 pid_t wait (int * status);  函数说明 wait()会暂时停止目前进程的执行，直到有信号来到或子进程结束。如果在调用wait()时子进程已经结束，则wait()会立即返回子进程结束状态值。子进程的结束状态值会由参数status 返回，而子进程的进程识别码也会一快返回。如果不在意结束状态值，则 参数 status可以设成NULL。子进程的结束状态值请参考waitpid()。 返回值 如果执行成功则返回子进程识别码(PID)，如果有错误发生则返回-1。失败原因存于errno中。  12、waitpid（等待子进程中断或结束） 头文件 1 #include<sys/types.h>2 #include<sys/wait.h>  定义函数  1 pid_t waitpid(pid_t pid,int * status,int options);  函数说明 waitpid()会暂时停止目前进程的执行，直到有信号来到或子进程结束。如果在调用wait()时子进程已经结束，则wait()会立即返回子进程结束状态值。子进程的结束状态值会由参数status返回，而子进程的进程识别码也会一快返回。如果不在意结束状态值，则参数status可以设成 NULL。参数pid为欲等待的子进程识别码，其他数值意义如下: pid<-1 等待进程组识别码为pid绝对值的任何子进程。 pid=-1 等待任何子进程，相当于wait()。 pid=0 等待进程组识别码与目前进程相同的任何子进程。 pid>0 等待任何子进程识别码为pid的子进程。 参数option可以为0 或下面的OR 组合 WNOHANG 如果没有任何已经结束的子进程则马上返回，不予以等待。 WUNTRACED 如果子进程进入暂停执行情况则马上返回，但结束状态不予以理会。 子进程的结束状态返回后存于status，底下有几个宏可判别结束情况 WIFEXITED(status)如果子进程正常结束则为非0值。 WEXITSTATUS(status)取得子进程exit()返回的结束代码，一般会先用WIFEXITED 来判断是否正常结束才能使用此宏。 WIFSIGNALED(status)如果子进程是因为信号而结束则此宏值为真 WTERMSIG(status)取得子进程因信号而中止的信号代码，一般会先用WIFSIGNALED 来判断后才使用此宏。 WIFSTOPPED(status)如果子进程处于暂停执行情况则此宏值为真。一般只有使用WUNTRACED 时才会有此情况。 WSTOPSIG(status)取得引发子进程暂停的信号代码，一般会先用WIFSTOPPED 来判断后才使用此宏。 返回值 如果执行成功则返回子进程识别码(PID)，如果有错误发生则返回-1。失败原因存于errno中。    （四）信号处理篇 1、sigaction（查询或设置信号处理方式） 头文件 1 #include<signal.h>  定义函数  1 int sigaction(int signum,const struct sigaction *act ,struct sigaction *oldact);  函数说明 sigaction()会依参数signum指定的信号编号来设置该信号的处理函数。参数signum可以指定SIGKILL和SIGSTOP以外的所有信号。 如参数结构sigaction定义如下 1 struct sigaction2 {3 void (*sa_handler) (int);4 sigset_t sa_mask;5 int sa_flags;6 void (*sa_restorer) (void);7 }  sa_handler此参数和signal()的参数handler相同，代表新的信号处理函数，其他意义请参考signal()。 sa_mask 用来设置在处理该信号时暂时将sa_mask 指定的信号搁置。 sa_restorer 此参数没有使用。 sa_flags 用来设置信号处理的其他相关操作，下列的数值可用。 OR 运算（|）组合 A_NOCLDSTOP : 如果参数signum为SIGCHLD，则当子进程暂停时并不会通知父进程 SA_ONESHOT/SA_RESETHAND:当调用新的信号处理函数前，将此信号处理方式改为系统预设的方式。 SA_RESTART:被信号中断的系统调用会自行重启 SA_NOMASK/SA_NODEFER:在处理此信号未结束前不理会此信号的再次到来。 如果参数oldact不是NULL指针，则原来的信号处理方式会由此结构sigaction 返回。 返回值 执行成功则返回0，如果有错误则返回-1。 错误代码 EINVAL 参数signum 不合法， 或是企图拦截SIGKILL/SIGSTOPSIGKILL信号 EFAULT 参数act，oldact指针地址无法存取。 EINTR 此调用被中断  2、sigaddset（增加一个信号至信号集） 头文件 1 #include<signal.h>  定义函数  1 int sigaddset(sigset_t *set,int signum);  函数说明 sigaddset()用来将参数signum 代表的信号加入至参数set 信号集里。 返回值 执行成功则返回0，如果有错误则返回-1。 错误代码 EFAULT 参数set指针地址无法存取 EINVAL 参数signum非合法的信号编号  3、sigdelset（从信号集里删除一个信号） 头文件 1 #include<signal.h>  定义函数  1 int sigdelset(sigset_t * set,int signum);  函数说明 sigdelset()用来将参数signum代表的信号从参数set信号集里删除。 返回值 执行成功则返回0，如果有错误则返回-1。 错误代码 EFAULT 参数set指针地址无法存取 EINVAL 参数signum非合法的信号编号  4、sigemptyset（初始化信号集） 头文件 1 #include<signal.h>  定义函数  1 int sigemptyset(sigset_t *set);  函数说明 sigemptyset()用来将参数set信号集初始化并清空。 返回值 执行成功则返回0，如果有错误则返回-1。 错误代码 EFAULT 参数set指针地址无法存取  5、sigfillset（将所有信号加入至信号集） 头文件 1 #include<signal.h>  定义函数  1 int sigfillset(sigset_t * set);  函数说明 sigfillset()用来将参数set信号集初始化，然后把所有的信号加入到此信号集里。 返回值 执行成功则返回0，如果有错误则返回-1。 附加说明 EFAULT 参数set指针地址无法存取  6、sigismember（测试某个信号是否已加入至信号集里） 头文件 1 #include<signal.h>  定义函数  1 int sigismember(const sigset_t *set,int signum);  函数说明 sigismember()用来测试参数signum 代表的信号是否已加入至参数set信号集里。如果信号集里已有该信号则返回1，否则返回0。 返回值 信号集已有该信号则返回1，没有则返回0。如果有错误则返回-1。 错误代码 EFAULT 参数set指针地址无法存取 EINVAL 参数signum 非合法的信号编号  7、signal（设置信号处理方式） 头文件 1 #include<signal.h>  定义函数  1 void (*signal(int signum,void(* handler)(int)))(int);  函数说明 signal()会依参数signum 指定的信号编号来设置该信号的处理函数。当指定的信号到达时就会跳转到参数handler指定的函数执行。如果 参数handler不是函数指针，则必须是下列两个常数之一: SIG_IGN 忽略参数signum指定的信号。 SIG_DFL 将参数signum 指定的信号重设为核心预设的信号处理方式。 关于信号的编号和说明，请参考附录D 返回值 返回先前的信号处理函数指针，如果有错误则返回SIG_ERR(-1)。 附加说明 在信号发生跳转到自定的handler处理函数执行后，系统会自动将此处理函数换回原来系统预设的处理方式，如果要改变此操作请改用 sigaction()。  8、sleep（让进程暂停执行一段时间） 头文件 1 #include<unistd.h>  定义函数  1 unsigned int sleep(unsigned int seconds);  函数说明 sleep()会令目前的进程暂停，直到达到参数seconds 所指定的时间，或是被信号所中断。 返回值 若进程暂停到参数seconds 所指定的时间则返回0，若有信号中断则返回剩余秒数。  9、perror（打印出错误原因信息字符串） 头文件 1 #include<stdio.h>  定义函数  1 void perror(const char *s);  函数说明 perror()用来将上一个函数发生错误的原因输出到标准错误(stderr)。参数s所指的字符串会先打印出，后面再加上错误原因字符串。此 错误原因依照全局变量errno的值来决定要输出的字符串。 返回值  10、mkfifo（建立具名管道） 头文件 1 #include<sys/types.h>2 #include<sys/stat.h>  定义函数  1 int mkfifo(const char * pathname,mode_t mode);  函数说明 mkfifo()会依参数pathname建立特殊的FIFO文件，该文件必须不存在，而参数mode为该文件的权限（mode%~umask），因此 umask值也会 影响到FIFO文件的权限。Mkfifo()建立的FIFO文件其他进程都可以用读写一般文件的方式存取。当使用open()来打开 FIFO文件时， O_NONBLOCK旗标会有影响 1、当使用O_NONBLOCK 旗标时，打开FIFO 文件来读取的操作会立刻返回，但是若还没有其他进程打开FIFO 文件来读取，则写入的操作会 返回ENXIO 错误代码。 2、没有使用O_NONBLOCK 旗标时，打开FIFO 来读取的操作会等到其他进程打开FIFO文件来写入才正常返回。同样地，打开FIFO文件来写 入的操作会等到其他进程打开FIFO 文件来读取后才正常返回。 返回值 若成功则返回0，否则返回-1，错误原因存于errno中。 错误代码 EACCESS 参数pathname所指定的目录路径无可执行的权限 EEXIST 参数pathname所指定的文件已存在。 ENAMETOOLONG 参数pathname的路径名称太长。 ENOENT 参数pathname包含的目录不存在 ENOSPC 文件系统的剩余空间不足 ENOTDIR 参数pathname路径中的目录存在但却非真正的目录。 EROFS 参数pathname指定的文件存在于只读文件系统内。  11、pclose（关闭管道I/O） 头文件 1 #include<stdio.h>  定义函数  1 int pclose(FILE * stream);  函数说明 pclose()用来关闭由popen所建立的管道及文件指针。参数stream为先前由popen()所返回的文件指针。 返回值 返回子进程的结束状态。如果有错误则返回-1，错误原因存于errno中。 错误代码 ECHILD pclose()无法取得子进程的结束状态。  12、pipe（建立管道） 头文件 1 #include<unistd.h>  定义函数  1 int pipe(int filedes[2]);  函数说明 pipe()会建立管道，并将文件描述词由参数filedes数组返回。filedes[0]为管道里的读取端，filedes[1]则为管道的写入端。 返回值 若成功则返回零，否则返回-1，错误原因存于errno中。 错误代码 EMFILE 进程已用完文件描述词最大量。 ENFILE 系统已无文件描述词可用。 EFAULT 参数filedes数组地址不合法。  13、popen（建立管道I/O） 头文件 1 #include<stdio.h>  定义函数  1 FILE * popen( const char * command,const char * type);  函数说明 popen()会调用fork()产生子进程，然后从子进程中调用/bin/sh -c来执行参数command的指令。参数type可使用“r”代表读取，“w”代 表写入。依照此type值，popen()会建立管道连到子进程的标准输出设备或标准输入设备，然后返回一个文件指针。随后进程便可利用此 文件指针来读取子进程的输出设备或是写入到子进程的标准输入设备中。此外，所有使用文件指针(FILE*)操作的函数也都可以使用，除 了fclose()以外。 返回值 若成功则返回文件指针，否则返回NULL，错误原因存于errno中。 错误代码 EINVAL参数type不合法。 注意事项 在编写具SUID/SGID权限的程序时请尽量避免使用popen()，popen()会继承环境变量，通过环境变量可能会造成系统安全的问题。    （五）接口处理篇 1、accept（接受socket连线） 头文件 1 #include<sys/types.h>2 #include<sys/socket.h>  定义函数  1 int accept(int s,struct sockaddr * addr,int * addrlen);  函数说明 accept()用来接受参数s的socket连线。参数s的socket必需先经bind()、listen()函数处理过，当有连线进来时 accept()会返回一个新的 socket处理代码，往后的数据传送与读取就是经由新的socket处理，而原来参数s的socket能继续使用 accept()来接受新的连线要求。连 线成功时，参数addr所指的结构会被系统填入远程主机的地址数据，参数addrlen为scokaddr的结构长度。关于结构sockaddr的定义请参 考bind()。 返回值 成功则返回新的socket处理代码，失败返回-1，错误原因存于errno中。 错误代码 EBADF 参数s 非合法socket处理代码。 EFAULT 参数addr指针指向无法存取的内存空间。 ENOTSOCK 参数s为一文件描述词，非socket。 EOPNOTSUPP 指定的socket并非SOCK_STREAM。 EPERM 防火墙拒绝此连线。 ENOBUFS 系统的缓冲内存不足。 ENOMEM 核心内存不足。  2、bind（对socket定位） 头文件 1 #include<sys/types.h>2 #include<sys/socket.h>  定义函数  1 int bind(int sockfd,struct sockaddr * my_addr,int addrlen);  函数说明 bind()用来设置给参数sockfd的socket一个名称。此名称由参数my_addr指向一sockaddr结构，对于不同的socket domain定义了一个通 用的数据结构 1 struct sockaddr2 {3 unsigned short int sa_family;4 char sa_data[14];5 };  sa_family 为调用socket（）时的domain参数，即AF_xxxx值。 sa_data 最多使用14个字符长度。 此sockaddr结构会因使用不同的socket domain而有不同结构定义，例如使用AF_INET domain，其socketaddr结构定义便为 1 struct socketaddr_in 2 { 3 unsigned short int sin_family; 4 uint16_t sin_port; 5 struct in_addr sin_addr; 6 unsigned char sin_zero[8]; 7 }; 8 struct in_addr 9 {10 uint32_t s_addr;11 };  sin_family 即为sa_family sin_port 为使用的port编号 sin_addr.s_addr 为IP 地址 sin_zero 未使用。 参数 addrlen为sockaddr的结构长度。 返回值 成功则返回0，失败返回-1，错误原因存于errno中。 错误代码 EBADF 参数sockfd 非合法socket处理代码。 EACCESS 权限不足 ENOTSOCK 参数sockfd为一文件描述词，非socket。  3、connect（建立socket连线） 头文件 1 #include<sys/types.h>2 #include<sys/socket.h>  定义函数  1 int connect (int sockfd,struct sockaddr * serv_addr,int addrlen);  函数说明 connect()用来将参数sockfd 的socket 连至参数serv_addr 指定的网络地址。结构sockaddr请参考bind()。参数addrlen为sockaddr的结 构长度。 返回值 成功则返回0，失败返回-1，错误原因存于errno中。 错误代码 EBADF 参数sockfd 非合法socket处理代码 EFAULT 参数serv_addr指针指向无法存取的内存空间 ENOTSOCK 参数sockfd为一文件描述词，非socket。 EISCONN 参数sockfd的socket已是连线状态 ECONNREFUSED 连线要求被server端拒绝。 ETIMEDOUT 企图连线的操作超过限定时间仍未有响应。 ENETUNREACH 无法传送数据包至指定的主机。 EAFNOSUPPORT sockaddr结构的sa_family不正确。 EALREADY socket为不可阻断且先前的连线操作还未完成。  4、htonl（将32位主机字符顺序转换成网络字符顺序） 头文件 1 #include<netinet/in.h>  定义函数  1 unsigned long int htonl(unsigned long int hostlong);  函数说明 htonl（）用来将参数指定的32位hostlong 转换成网络字符顺序。 返回值 返回对应的网络字符顺序。  5、htons（将16位主机字符顺序转换成网络字符顺序） 头文件 1 #include<netinet/in.h>  定义函数  1 unsigned short int htons(unsigned short int hostshort);  函数说明 htons()用来将参数指定的16位hostshort转换成网络字符顺序。 返回值 返回对应的网络字符顺序。  6、inet_addr（将网络地址转成二进制的数字） 头文件 1 #include<sys/socket.h>2 #include<netinet/in.h>3 #include<arpa/inet.h>  定义函数  1 unsigned long int inet_addr(const char *cp);  函数说明 inet_addr()用来将参数cp所指的网络地址字符串转换成网络所使用的二进制数字。网络地址字符串是以数字和点组成的字符串，例 如:“163.13.132.68”。 返回值 成功则返回对应的网络二进制的数字，失败返回-1。  7、inet_aton（将网络地址转成网络二进制的数字） 头文件 1 #include<sys/scoket.h>2 #include<netinet/in.h>3 #include<arpa/inet.h>  定义函数  1 int inet_aton(const char * cp,struct in_addr *inp);  函数说明 inet_aton()用来将参数cp所指的网络地址字符串转换成网络使用的二进制的数字，然后存于参数inp所指的in_addr结构中。 结构in_addr定义如下 struct in_addr{ unsigned long int s_addr;};  返回值 成功则返回非0值，失败则返回0。   8、inet_ntoa（将网络二进制的数字转换成网络地址） 头文件 1 #include<sys/socket.h>2 #include<netinet/in.h>3 #include<arpa/inet.h>  定义函数  1 char * inet_ntoa(struct in_addr in);  函数说明 inet_ntoa()用来将参数in所指的网络二进制的数字转换成网络地址，然后将指向此网络地址字符串的指针返回。 返回值 成功则返回字符串指针，失败则返回NULL。  9、listen（等待连接） 头文件 1 #include<sys/socket.h>  定义函数  1 int listen(int s,int backlog);  函数说明 listen()用来等待参数s 的socket连线。参数backlog指定同时能处理的最大连接要求，如果连接数目达此上限则client端将收到 ECONNREFUSED的错误。 Listen()并未开始接收连线，只是设置socket为listen模式，真正接收client端连线的是accept()。通常listen() 会在socket()，bind()之后调用，接着才调用accept()。 返回值 成功则返回0，失败返回-1，错误原因存于errno 附加说明 listen()只适用SOCK_STREAM或SOCK_SEQPACKET的socket类型。如果socket为AF_INET则参数backlog 最大值可设至128。 错误代码 EBADF 参数sockfd非合法socket处理代码 EACCESS 权限不足 EOPNOTSUPP 指定的socket并未支援listen模式。  10、ntohl（将32位网络字符顺序转换成主机字符顺序） 头文件 1 #include<netinet/in.h>  定义函数  1 unsigned long int ntohl(unsigned long int netlong);  函数说明 ntohl()用来将参数指定的32位netlong转换成主机字符顺序。 返回值 返回对应的主机字符顺序。  11、ntohs（将16位网络字符顺序转换成主机字符顺序） 头文件 1 #include<netinet/in.h>  定义函数  1 unsigned short int ntohs(unsigned short int netshort);  函数说明 ntohs()用来将参数指定的16位netshort转换成主机字符顺序。 返回值 返回对应的主机顺序。  12、recv（经socket接收数据） 头文件 1 #include<sys/types.h>2 #include<sys/socket.h>  定义函数  1 int recv(int s,void *buf,int len,unsigned int flags);  函数说明 recv()用来接收远端主机经指定的socket传来的数据，并把数据存到由参数buf 指向的内存空间，参数len为可接收数据的最大长度。 参数 flags一般设0。其他数值定义如下: MSG_OOB 接收以out-of-band 送出的数据。 MSG_PEEK 返回来的数据并不会在系统内删除，如果再调用recv()会返回相同的数据内容。 MSG_WAITALL强迫接收到len大小的数据后才能返回，除非有错误或信号产生。 MSG_NOSIGNAL此操作不愿被SIGPIPE信号中断返回值成功则返回接收到的字符数，失败返回-1，错误原因存于errno中。 错误代码 EBADF 参数s非合法的socket处理代码 EFAULT 参数中有一指针指向无法存取的内存空间 ENOTSOCK 参数s为一文件描述词，非socket。 EINTR 被信号所中断 EAGAIN 此动作会令进程阻断，但参数s的socket为不可阻断 ENOBUFS 系统的缓冲内存不足。 ENOMEM 核心内存不足 EINVAL 传给系统调用的参数不正确。  13、recvfrom（经socket接收数据） 相关函数 recv，recvmsg，send，sendto，socket 头文件 1 #include<sys/types.h>2 #include<sys/socket.h>  定义函数  1 int recvfrom(int s,void *buf,int len,unsigned int flags ,struct sockaddr *from ,int *fromlen);  函数说明 recv()用来接收远程主机经指定的socket 传来的数据，并把数据存到由参数buf 指向的内存空间，参数len 为可接收数据的最大长度。参 数flags 一般设0，其他数值定义请参考recv()。参数from用来指定欲传送的网络地址，结构sockaddr 请参考bind()。参数fromlen为 sockaddr的结构长度。 返回值 成功则返回接收到的字符数，失败则返回-1，错误原因存于errno中。 错误代码 EBADF 参数s非合法的socket处理代码 EFAULT 参数中有一指针指向无法存取的内存空间。 ENOTSOCK 参数s为一文件描述词，非socket。 EINTR 被信号所中断。 EAGAIN 此动作会令进程阻断，但参数s的socket为不可阻断。 ENOBUFS 系统的缓冲内存不足 ENOMEM 核心内存不足 EINVAL 传给系统调用的参数不正确。  14、recvmsg（经socket接收数据） 头文件 1 #include<sys/types.h>2 #include<sys/socktet.h>  定义函数  1 int recvmsg(int s,struct msghdr *msg,unsigned int flags);  函数说明 recvmsg()用来接收远程主机经指定的socket传来的数据。参数s为已建立好连线的socket，如果利用UDP协议则不需经过连线操作。参 数 msg指向欲连线的数据结构内容，参数flags一般设0，详细描述请参考send()。关于结构msghdr的定义请参考sendmsg()。 返回值 成功则返回接收到的字符数，失败则返回-1，错误原因存于errno中。 错误代码 EBADF 参数s非合法的socket处理代码。 EFAULT 参数中有一指针指向无法存取的内存空间 ENOTSOCK 参数s为一文件描述词，非socket。 EINTR 被信号所中断。 EAGAIN 此操作会令进程阻断，但参数s的socket为不可阻断。 ENOBUFS 系统的缓冲内存不足 ENOMEM 核心内存不足 EINVAL 传给系统调用的参数不正确。  15、send（经socket传送数据） 头文件 1 #include<sys/types.h>2 #include<sys/socket.h>  定义函数  1 int send(int s,const void * msg,int len,unsigned int falgs);  函数说明 send()用来将数据由指定的socket 传给对方主机。参数s为已建立好连接的socket。参数msg指向欲连线的数据内容，参数len则为数据长 度。参数flags一般设0，其他数值定义如下 MSG_OOB 传送的数据以out-of-band 送出。 MSG_DONTROUTE 取消路由表查询 MSG_DONTWAIT 设置为不可阻断运作 MSG_NOSIGNAL 此动作不愿被SIGPIPE 信号中断。 返回值 成功则返回实际传送出去的字符数，失败返回-1。错误原因存于errno 错误代码 EBADF 参数s 非合法的socket处理代码。 EFAULT 参数中有一指针指向无法存取的内存空间 ENOTSOCK 参数s为一文件描述词，非socket。 EINTR 被信号所中断。 EAGAIN 此操作会令进程阻断，但参数s的socket为不可阻断。 ENOBUFS 系统的缓冲内存不足 ENOMEM 核心内存不足 EINVAL 传给系统调用的参数不正确。  16、sendmsg（经socket传送数据） 头文件 1 #include<sys/types.h>2 #include<sys/socket.h>  定义函数  1 int sendmsg(int s,const strcut msghdr *msg,unsigned int flags);  函数说明 sendmsg()用来将数据由指定的socket传给对方主机。参数s为已建立好连线的socket，如果利用UDP协议则不需经过连线操作。参数msg 指向欲连线的数据结构内容，参数flags一般默认为0，详细描述请参考send()。 结构msghdr定义如下 1 struct msghdr 2 { 3 void *msg_name; /*Address to send to /receive from . */ 4 socklen_t msg_namelen; /* Length of addres data */ 5 strcut iovec * msg_iov; /* Vector of data to send/receive into */ 6 size_t msg_iovlen; /* Number of elements in the vector */ 7 void * msg_control; /* Ancillary dat */ 8 size_t msg_controllen; /* Ancillary data buffer length */ 9 int msg_flags; /* Flags on received message */10 };  返回值 成功则返回实际传送出去的字符数，失败返回-1，错误原因存于errno 错误代码 EBADF 参数s 非合法的socket处理代码。 EFAULT 参数中有一指针指向无法存取的内存空间 ENOTSOCK 参数s为一文件描述词，非socket。 EINTR 被信号所中断。 EAGAIN 此操作会令进程阻断，但参数s的socket为不可阻断。 ENOBUFS 系统的缓冲内存不足 ENOMEM 核心内存不足 EINVAL 传给系统调用的参数不正确。  17、sendto（经socket传送数据） 头文件 1 #include < sys/types.h >2 #include < sys/socket.h >  定义函数  1 int sendto ( int s , const void * msg, int len, unsigned int flags, const struct sockaddr * to , int tolen ) ;  函数说明 sendto() 用来将数据由指定的socket传给对方主机。参数s为已建好连线的socket,如果利用UDP协议则不需经过连线操作。参数msg指向 欲连线的数据内容，参数flags 一般设0，详细描述请参考send()。参数to用来指定欲传送的网络地址，结构sockaddr请参考bind()。参数 tolen为sockaddr的结果长度。 返回值 成功则返回实际传送出去的字符数，失败返回－1，错误原因存于errno 中。 错误代码 EBADF 参数s非法的socket处理代码。 EFAULT 参数中有一指针指向无法存取的内存空间。 WNOTSOCK canshu s为一文件描述词，非socket。 EINTR 被信号所中断。 EAGAIN 此动作会令进程阻断，但参数s的soket为补课阻断的。 ENOBUFS 系统的缓冲内存不足。 EINVAL 传给系统调用的参数不正确。  18、socket（建立一个socket通信） 头文件 1 #include<sys/types.h>2 #include<sys/socket.h>  定义函数  1 int socket(int domain,int type,int protocol);  函数说明 socket()用来建立一个新的socket，也就是向系统注册，通知系统建立一通信端口。参数domain 指定使用何种的地址类型，完整的定义 在/usr/include/bits/socket.h 内，底下是常见的协议: PF_UNIX/PF_LOCAL/AF_UNIX/AF_LOCAL UNIX 进程通信协议 PF_INET?AF_INET Ipv4网络协议 PF_INET6/AF_INET6 Ipv6 网络协议 PF_IPX/AF_IPX IPX-Novell协议 PF_NETLINK/AF_NETLINK 核心用户接口装置 PF_X25/AF_X25 ITU-T X.25/ISO-8208 协议 PF_AX25/AF_AX25 业余无线AX.25协议 PF_ATMPVC/AF_ATMPVC 存取原始ATM PVCs PF_APPLETALK/AF_APPLETALK appletalk（DDP）协议 PF_PACKET/AF_PACKET 初级封包接口 参数 type有下列几种数值: SOCK_STREAM 提供双向连续且可信赖的数据流，即TCP。支持 OOB 机制，在所有数据传送前必须使用connect()来建立连线状态。 SOCK_DGRAM 使用不连续不可信赖的数据包连接 SOCK_SEQPACKET 提供连续可信赖的数据包连接 SOCK_RAW 提供原始网络协议存取 SOCK_RDM 提供可信赖的数据包连接 SOCK_PACKET 提供和网络驱动程序直接通信。 protocol用来指定socket所使用的传输协议编号，通常此参考不用管它，设为0即可。 返回值 成功则返回socket处理代码，失败返回-1。 错误代码 EPROTONOSUPPORT 参数domain指定的类型不支持参数type或protocol指定的协议 ENFILE 核心内存不足，无法建立新的socket结构 EMFILE 进程文件表溢出，无法再建立新的socket EACCESS 权限不足，无法建立type或protocol指定的协议 ENOBUFS/ENOMEM 内存不足 EINVAL 参数domain/type/protocol不合法   （六）环境变量篇 1、getenv（取得环境变量内容） 头文件 1 #include<stdlib.h>  定义函数  1 char * getenv(const char *name);  函数说明 getenv()用来取得参数name环境变量的内容。参数name为环境变量的名称，如果该变量存在则会返回指向该内容的指针。环境变量的格 式为name＝value。 返回值 执行成功则返回指向该内容的指针，找不到符合的环境变量名称则返回NULL。  2、putenv（改变或增加环境变量） 头文件 1 #include <stdlib.h>  定义函数  1 int putenv(const char * string);  函数说明 putenv()用来改变或增加环境变量的内容。参数string的格式为name＝value，如果该环境变量原先存在，则变量内容会依参数string改 变，否则此参数内容会成为新的环境变量。 返回值 执行成功则返回0，有错误发生则返回-1。 错误代码 ENOMEM 内存不足，无法配置新的环境变量空间。  3、setenv（改变或增加环境变量） 头文件 1 #include<stdlib.h>  定义函数  1 int setenv(const char *name,const char * value,int overwrite);  函数说明 setenv()用来改变或增加环境变量的内容。参数name为环境变量名称字符串。 参数 value则为变量内容，参数overwrite用来决定是否要改变已存在的环境变量。如果overwrite不为0，而该环境变量原已有内容，则原内 容会被改为参数value所指的变量内容。如果overwrite为0，且该环境变量已有内容，则参数value会被忽略。 返回值 执行成功则返回0，有错误发生时返回-1。 错误代码 ENOMEM 内存不足，无法配置新的环境变量空间   （七）内存及字符串操作篇 1、bcmp（比较内存内容） 头文件 1 #include<string.h>  定义函数  1 int bcmp ( const void *s1,const void * s2,int n);  函数说明 bcmp()用来比较s1和s2所指的内存区间前n个字节，若参数n为0，则返回0。 返回值 若参数s1 和s2 所指的内存内容都完全相同则返回0 值，否则返回非零值。  2、bcopy（拷贝内存内容） 头文件 1 #include <string.h>  定义函数  1 void bcopy ( const void *src,void *dest ,int n);  函数说明 bcopy()与memcpy()一样都是用来拷贝src所指的内存内容前n个字节到dest所指的地址，不过参数src与dest在传给函数时是相反的位置。 返回值  3、bzero（将一段内存内容全清为零） 头文件 1 #include<string.h>  定义函数  1 void bzero(void *s,int n)；  函数说明 bzero()会将参数s所指的内存区域前n个字节，全部设为零值。相当于调用memset((void*)s,0,size_tn);  4、memccpy（拷贝内存内容） 头文件 1 #include<string.h>  定义函数  1 void * memccpy(void *dest, const void * src, int c,size_t n);  函数说明 memccpy()用来拷贝src所指的内存内容前n个字节到dest所指的地址上。与memcpy()不同的是，memccpy()会在复制时检查参数c是否出 现，若是则返回dest中值为c的下一个字节地址。 返回值 返回指向dest中值为c的下一个字节指针。返回值为0表示在src所指内存前n个字节中没有值为c的字节。  5、memcmp（比较内存内容） 头文件 1 #include<string.h>  定义函数  1 int memcmp (const void *s1,const void *s2,size_t n);  函数说明 memcmp()用来比较s1和s2所指的内存区间前n个字符。字符串大小的比较是以ASCII码表上的顺序来决定，次顺序亦为字符的值。memcmp () 首先将s1第一个字符值减去s2第一个字符的值，若差为0则再继续比较下个字符，若差值不为0则将差值返回。例如，字符串\"Ac\"和\"ba\"比 较则会返回字符'A'(65)和'b'(98)的差值(－33)。 返回值 若参数s1和s2所指的内存内容都完全相同则返回0值。s1若大于s2则返回大于0的值。s1若小于s2则返回小于0的值。  6、memcpy（拷贝内存内容） 头文件 1 #include<string.h>  定义函数  1 void * memcpy (void * dest ,const void *src, size_t n);  函数说明 memcpy()用来拷贝src所指的内存内容前n个字节到dest所指的内存地址上。与strcpy()不同的是，memcpy()会完整的复制n个字节，不会因 为遇到字符串结束'\\0'而结束。 返回值 返回指向dest的指针。 附加说明 指针src和dest所指的内存区域不可重叠。  7、memset（将一段内存空间填入某值） 头文件 1 #include<string.h>  定义函数  1 void * memset (void *s ,int c, size_t n);  函数说明 memset()会将参数s所指的内存区域前n个字节以参数c填入，然后返回指向s的指针。在编写程序时，若需要将某一数组作初始化 memset()会相当方便。 返回值 返回指向s的指针。 附加说明 参数c虽声明为int， 但必须是unsigned char ，所以范围在0到255之间。  8、strlen（返回字符串长度） 头文件 1 #include<string.h>  定义函数  1 size_t strlen (const char *s);  函数说明 strlen()用来计算指定的字符串s的长度，不包括结束字符\"\\0\"。 返回值 返回字符串s的字符数。","title":"Linux API函数总结"},{"content":"linux下有些命令可以让我们省不少事情，在开发的过程中，可以利用这些命令，从而省去开发相应功能的时间和精力。 例如system函数就可以满足我们的需求，可是我们经常需要获取命令执行后的返回信息，可以通过以下方法： 以ping命令为例：     #include <stdio.h>#include <sys/types.h>int main(int argc, char *argv[]){        int ret=-1;        char cmd_buf[128]={0};        char buf[128]={0};        FILE *fp;        int pingSize = 56;         \tint pingCount = 7;        char pingAddr[]={\"172.16.158.50\"};        sprintf(cmd_buf,\"ping %s -c %d -s %d\",pingAddr, pingCount, pingSize); // 构造ping命令        fp = popen(cmd_buf,\"r\");  // 打开管道        \twhile(fgets(buf,sizeof(buf),fp)!=NULL) // 获取每行的返回信息\t  \t{                         \t       printf(\"%s\",buf);        }        pclose(fp);        ret = 0;        return ret;}    以上的程序中，使用popen函数来执行命令。 popen函数会调用fork来创建一个子进程，子进程里调用/bin/sh来执行命令。popen函数会创建一个管道连接到子进程的标准输出,返回一个文件指针，随后用该文件指针读取命令执行的返回信息。 popen函数说明请参见man popen。  ","title":"linux下获取命令执行后的返回信息方法"},{"content":"[回顾]清华申请退学博士作品：完全用Linux工作 按: 尽管我们已经不习惯看长篇大论, 但我还是要说, 这是一篇值得你从头读到尾的长篇文章. 2005年9月22日，清华在读博士生王垠在水木社区BLOG上发表了《清华梦的粉碎--写给清华大学的退学申请》明确要求退学, 引起社会各界广泛争论. 他创作的长篇文章《完全用Linux工作》, 洋洋两万多字, 从不同角度居高临下的阐述了他眼中Linux完全优越于Windows的各种理由, 这篇文章并不简单的是一篇论述\"Windows能做的事Linux都能做\"这样的文章, 通篇洋溢着一个彻底批判 Windows 平台基础的计算机哲学, 计算机应用和计算机教育体系的人的万丈豪情, 尽管可能偏激, 也不乏详细的推理论述. 今天我们重温本文, 一方面也是因为CB上喜爱和推广Linux的人士很多, 有时也会爆发小规模论战, 我们希望能通过对本文的研究与讨论, 来窥测国内部分Linux推广者的心态, 同时为大家提供更宽广的讨论空间. 我已经半年没有使用 Windows 的方式工作了。Linux 高效的完成了我所有的工作。 GNU/Linux 不是每个人都想用的。如果你只需要处理一般的事务，打游戏，那么你不需要了解下面这些了。 我不是一个狂热的自由软件份子，虽然我很喜欢自由软件。这篇文章也不是用来推行自由软件运动的，虽然我觉得自由软件运动是非常好的。 这篇文章也不是用来比较 Linux 和 Windows 内核效率，文件系统，网络服务的。我现在是作为一个用户而不是一个开发者来说话的，我们的讨论是基于操作，应用层面的。是为了告诉大学里还不了解，或者不理解 UNIX 的科学工作者和大学生，UNIX 比 Windows 更适合用于科学研究工作，请大家理解 UNIX 的工作方式，不要用 Windows 的标准来要求 Linux，而要用一个科学工作者的标准来要求自己，用UNIX 的思想来武装自己。 我显然是反对在大学，特别是理工科专业推广 Windows 的。我也反对在对\"娃娃\"们的计算机启蒙教育中使用 Windows。因为 Windows 不论从技术上，经济上，思想风格上都是与我们培养高科技人才的目标格格不入的。Windows 的流行属于历史遗留问题，爷爷一级的人当然已经不可救药，但是我们不应该让下一代继续走上歧途。 UNIX 不是计算机专家的专利 当我建议一些非计算机专业的人用 Linux 的时候，很多人说：\"UNIX 是计算机系的人用的，我们不能理解。\" \"UNIX 是男孩用的，我们女孩不用。\" 但是其实世界上的大多数科学家和工程师几乎用的都是 UNIX 作为他们的电脑工具。就因为它简单，可靠，稳定，强大，有趣。甚至很多时候 UNIX 就是唯一的选择。 你说：\"我们都会用 UNIX 的话，你们计算机专业的人还用来干什么？\" 很容幸的告诉你，计算机专业的有一部分人就是专门为你们提供这样强大而方便的计算机工具的。如果他们制造的工具只有自己会用的话，那这个工具还有什么用？ 理解 GNU/Linux 不要用 Windows 的标准来要求 Linux。 由于GNU/Linux这个词太长，下面如果没有特别指明，\"Linux\"就是指GNU/Linux\"。 在这个年代，恐怕没有人需要我来介绍 Linux 是什么了吧？如果你觉得\"Linux 只不过是跟 DOS 差不多的东西\"，那请问问你旁边的 Linux 用户，Linux 到底是什么？ 那为什么我还要写一篇这样的文章？因为，我发现还有很多人不不理解 Linux 和 UNIX，虽然他们也在用它，但是他们有时会问：\"为什么 Linux 不能像 Windows 那样 ……？\"，\"怎么Redhat Linux不能 mount NTFS 分区！\"，\"Linux 下用什么整理硬盘？\"，\"什么时候OpenOffice才能完全兼容Word文件啊？\"，\"现在还有什么Windows能干的事情Linux干不了的？ \"…… 他们有40G的硬盘，却只为 Linux 分配了2G空间，有时还抱怨\"这个东西怎么占这么多硬盘！\" 似乎 Windows 该占用大部分硬盘。他们把重要的数据装在Windows的分区，似乎信不过Linux。他们总是到处寻找新奇的，好看的GUI程序，对命令行的东西一概不屑一顾。他们对Drag&Drop，菜单配置，自动升级非常感兴趣。他们如果找到一个很像 Windows 程序的 Linux 程序，一定会很高兴的说：\"哈哈！Linux 也能……了！\"如果Linux在某种测试中胜过Windows，他们会高兴得跳起来。他们没有办法用Linux 解决问题的时候，甚至用Wine来运行Windows程序。有时实在没办法，只好重起到Windows，或者干脆省得麻烦，在 Windows 下装一个 VMWare 虚拟一个 Linux 玩。 你如果出现了上面的情况，说明你的思想受到了 Windows 的某种潜移默化的影响和误导。你没有能够从本质上理解存在于 Linux 身上的 UNIX 思想。你支持 Linux，你喜欢 Linux，你能从中感觉到快乐，这非常好。你现在只需要明白的是：Linux 从来就不是一个玩具，它是天才UNIX的后代。UNIX 是自晶体管发明以来最伟大的发明，它从诞生那一天开始就比 Windows 的设计出色。 你要体会什么叫做\"设计\"，一个糟糕的设计并不是到后来缝缝补补就可以变好的，而一个出色的设计，不但可以以不变应万变，而且可以影响到后来者。一个出色的设计配上一个出色的实现，那就是非常出色的发明。Linux 就是这样的一个出色的发明。Linux 并不需要追赶 Windows，也不需要打垮微软。它的最终目标是改变整个计算机世界，还人们自由，给人们乐趣和方便。 Unix 是简单的，你不需要成为一个天才也能理解这种简单。 UNIX 的设计者 Dennis Ritchie 说：\"Unix is simple. It just takes a genius to understand its simplicity.\" 但是我不这么认为，因为我不是一个天才，但是我却勇敢的把 Windows 完全删除掉，遇到不明白的事情的时候努力用 UNIX 的方式去解决，而不是寻求 Windows 的帮助。现在我体会到了 UNIX 的思想和好处，我可以用比 Windows 高效几倍的效率工作。因为我相信这样的信念：\"Windows 能办到的事 Linux 一定能办到，而且办的更好。\" 这小节开头的话应该改成：\"Unix 是简单的，你不需要成为一个天才或是计算机专家。但是在这个冲斥着 Windows 错误观念的世界，你需要信念和勇气才能理解它的简单。\" 我下面就告诉你一些我理解到的东西。首先，你要知道的是微软在国际科学领域是根本没有地位的。 微软的地位 微软的名声在欧洲和美国的大学里，特别是在计算机系里之坏，大家可能有所耳闻。我认识的 MIT，Stanford 的教授，贝尔实验室的专家，甚至一个欧洲小国的高中计算机老师都绝口不提微软的名字。在他们眼里，微软只是一个没有真技术，专靠在落后国家商业宣传和垄断经营的小公司。这个\"小\"并不是说它人少，钱少，而是说它先进技术少。 我上次和王益合作写了一个算法演示程序，那个算法是贝尔实验室一位科学家Steven Fortune很天才的发明，为了程序能够被身边大多数人使用，我们选择了 VC+MFC 作为平台。我在分析算法时还得到 Fortune 很热情的鼓励，寄给我一份资料，还多次回信耐心的给我讲解了很多细节。但是程序完成之后，我把样品发给 Fortune，他回信说：\"对不起。我机器上没有 MFC。\" 话说的很客气，但是我已经感觉到了他对 Windows的不屑。然后我把 MFC 静态编译进程序再发给他，他就没有再回信了。他显然不是瞧不起我，而是确实有难处。 你能感觉到这位科学家对微软和 Windows 是什么态度了吧？不是反感，而是他心里根本没有 Windows 这个东西！微软在高科技领域没有发展，那么它怎么生存呢？到发展中国家去发展一下，他们的人民还对电脑一无所知，我说不定甚至可以打入大学的计算机系呢。我送他们软件，我捐钱盖大楼，我出钱找图灵奖获得者来演讲，让他们觉得我们都是科学家！ 好了，现在全国的大学包括清华，几乎所有人机器必装盗版 Win2000，Office XP，学校的选课系统是非IE不能正确浏览，论文用 Word 编辑，演示用ppt做，email 的通知附件是 doc 文件，你不用 Word 打不开，连 863 项目都用 VC 写程序了。我很久以前就看到一份报纸说，\"微软为什么不严厉打击盗版？\" 这篇文章说，微软非但不打击中国的盗版行为，而且有放任之趋势。放长线吊大鱼，\"以后我要你们加倍的来还我！\" 确实如此，它的目的快实现了。 Windows 笼罩下的中国计算机教育 说句丢脸的话，比尔盖茨很久以前是我的偶像…… 在中国，比尔盖茨被很多人奉为神圣，\"少年电脑天才\"，甚至有的人提到他的名字就做出\"抱拳对天\"的姿势。很多人谈到微软的\"新技术\"，\"高科技\" 都是眉飞色舞。各种\"VC编程圣经\"，\"深入了解 Visual C++\"之类的书，在开头几页都会出现非常肉麻的字眼，\"在那团团的混沌中，一个开天辟地的精灵，Windows 1.0，诞生了……\" 微软的软件被这么多人盗用，那么人们是怎样使用这些盗版程序的呢？先看看电脑培训班，教的都是一些 DOS 命令，打字，Windows 基本操作，Word 文档处理，PowerPoint，高级班可能有 Excel，Access…… 参加各种微软认证考试，MCSE，MSDE 的人络绎不绝。考试辅导班都贴出了\"280元，考过为止\"之类的字样。考试参考资料更是昂贵，有些电脑书店整整两书架都是\"Microsoft Press\"的东西。我有个同学参加认证考试，每门考试都要200多元。而且你一次考不过可以再考，又要交钱。他后来还津津乐道跟我说，看我，花了 XXXX(一个四位数)元考过了微软认证，得到一张比尔盖茨亲笔签名的证书和价值6000元的 Windows XP 内部发行版。 \"电脑要从娃娃抓起\"，我们再来看看娃娃们学的是什么。大部分家长给孩子买了电脑之后，他们首先就会装一个盗版的 Windows，然后买来盗版的游戏开始玩。如果哪个孩子会用 Delphi 编程序，那可不得了。报社记者，电视台争相报导，说，某某学校的初中生某某，在别人都还在玩电脑游戏这种\"初级阶段\"的时候就已经用 Delphi 写程序了。镜头还瞄准了他显示器上面的像框中的比尔盖茨头像！ 我刚进入大学计算机系时还不懂得什么是操作系统，因为我以前只用过\"中华学习机\"。看到新入学的同学们各个谈论的都是 \"Windows 95\"，\"VC\"…… 我简直觉得我落后了好几十年一样，整个一土人，根本跟他们答不上话。好不容易找到一个比较熟的同学问了一下：\"你们天天谈论的瘟95是什么啊？\"答： \"win95就是一个操作系统，跟DOS是一类。\"\"朵死是什么？\" \"你连DOS都不知道是什么？别在计算机系混了。\" 学校上课当然不讲VC编程之类的东西，但是上 Pascal 的老师有一次就说：\"嗨，我们学校真是落后。现在别人都用 C, C++，甚至 VC 了，我们还在讲 Pascal。不知道什么时候才能有VC课啊。你们出去也是要用VC的，只好自学了。\" 于是，有些同学很多时候上课都捧着一本很重的\"Windows 编程大全\"之类的书，根本没有听课。吃饭时就念念有词的跟我说，\"代码的优化是无止境的\"，\"匈牙利命名法真是伟大的发明\" …… 这就是中国很多大学计算机系的情况。 感觉到无知了？这不是偶然的，而是微软长久以来埋下的伏笔。它要让无知的大家都把它奉为神圣，它要让支持UNIX，Xwindow的人一旦说 UNIX 好，Xwindow 好的时候，都被一群人围着说教：\"这个 Windows 也能做到\"，\"你对 Windows 有偏见\"，\"微软才是主流啊\"，\"你敢瞧不起 win2k？\"，\".NET 就是世界潮流\"，\"微软的毕竟是新技术\"，\"有钱就是有技术\"…… 甚至在一番论战比较后败下来还是要说：\"Windows 性能差点，但是易用性强\"，\"Windows 是老百姓用的，要求别那么\"，\"微软那么有钱，以后想超过 UNIX 还不容易吗？\"…… 发达国家的计算机教育 我前段时间在 USENET 发文问有关 Scheme 语言的问题时，认识了一位丹麦人。他解决了我所有的问题，并且建议我阅读一些很\"深奥\"的有关程序语言语法，文法的书，他告诉我很多网站可以学习 LISP，Scheme，人工智能，算法。他叫我看 Jonathan Rees 的论文 \"Syntactic Closures\"。他还打包给我寄过来一份 MIT 的 \"How to Design Programs\"。他说他在自己的 PC 机上装的是 Linux，他用 Emacs 编辑，运行Scheme 程序。他对 Emacs 的了解和爱好真是使人惊讶。他大学本科毕业时做的毕业设计是一个 Scheme 解释器。这对于我来说是望尘末及了。 他是那么的不厌其烦，我的每一个问题他都详细的回答。我有时都觉得过于详细了，怎么这么耐心啊？我觉得他似乎是我的高中老师。他是什么样的人呢？我好奇的打听了他的情况。原来，他是丹麦一所普通高中的计算机老师。 他说他在高中里讲授程序设计和算法，计算机语言文法。他说用 Scheme，他的学生不用再为内存泄漏等程序语言本身的问题而烦恼，而专注于问题和算法本身。有利于培养学生解决问题的能力，特别是用计算机解决数学问题的能力。 天哪！为什么欧洲出现那么多数学家，几何学家？你看看别人重视的是什么！我们的计算机教育如果继续这样下去，只会沿着弯路越走越远！ 微软和它的朋友们的如意算盘 下面来看看微软的收入是怎么来的。首先，Windows 98系列操作系统，一个就是 100多美元，每次升级又是几乎同样的价钱。Windows NT 还要贵几倍，而且有用户数目限制，5个用户的，10个用户的…… 以后如果要增加用户数目还要按比例付钱。 花了如此多钱买来的操作系统就能用了吗？它竟然连压缩程序都没有提供！你装上Windows 之后一般第一件事就是去下载一个 WinZip 吧，\"只要 29 美元\"。Windows会中病毒啊，马上花 70 美元买一个 Norton AntiVirus 吧。还有黑客呢？再买一个Norton Internet Security 好了，100 美元。系统需要优化，磁盘需要整理，买一个Norton System Works 是你最佳的解决方案，100美元。 可是你现在还是不能干正事啊！你想要一个 Word, PowerPoint？那就买一套 Office XP 吧，一起买便宜些，$459.90。 那些程序不会用啊！那些菜单怎么设置，到底有什么功能啊？看\"帮助\"也学不会。买本书看看吧，我推荐\"Special Edition Using Microsoft Office XP\"，不贵，$27.99。这本书里面大部分是屏幕抓图，还是买一本旧的比较划算，$17.85。 你如果只是当个秘书，上面的差不多还凑合了。可是你有更高的追求，你想成为 Windows程序员。首先买一个 Visual Studio.NET 吧，要不然怎么编译程序。$494.95。 为了紧跟微软动向，世界潮流，不能不注册个 MSDN 什么的吧？这个贵一点，不过物有所值啊，$2,799。 嗯，你现在已经是上层阶级，白领人士了。你现在可以像这样\"自由\"的，\"安全\"的生活了。 为什么要反对使用 Windows 很多人都说不应该完全否定 Window，Windows 也有它的长处。不应该骂微软。 对。 Windows 容易操作，适合普通用户。如果微软把它自己定位在 P&G，Philips 那样的地位，能够给我们的百姓提供周到的，完善的，价廉物美的服务。那我肯定是很喜欢它的。但是从上面的种种情况说明，微软是一个野心极大的国际垄断组织！它的产品没有一个是不出问题的：Windows 不稳定，容易中病毒，而微软不为大家免费提供杀毒软件。我就是要让你们花钱买我的朋友 Symantec 的杀毒软件，谁叫你们已经上了我的贼船？这叫什么售后服务啊！ 你买来微软的程序，安装的时候一般都有一个协议，说：\" 由于微软的程序造成你的数据损坏或丢失，微软概不负责。\" 我想很多人肯定觉得这个不合理，不想按那个 \"I accept\"。但是你的软件买都买来了，钱都花了，现在一按 \"I decline\"，安装程序马上就会退出。你只好被迫点击了 \"I accept\"！这不是不平等条约吗？ 我已经目睹了好几个朋友的文档被 Microsoft Word 损坏，有的是编辑了十多天的30多页的论文，有的是费了很大工夫做出来的个人简历，那个朋友为此失去了到自己向往的P&G 工作的机会。就在他要投简历的前一个晚上，就在那一瞬间…… 不知道他痛哭的时候有没有想起要投诉微软，可是谁叫我们用的都是盗版呢，况且你还点击了 \"I accept\"。 微软仗势已经占有大部分PC市场，制定不符合国际标准的\"微软的标准\"，以不合理的方式压制其它公司的软件，这个问题已经在美国司法部闹了很久了。他甚至在 Windows系列操作系统中放置能够通过网络泄漏用户信息的代码，以至于 Windows 刚进入澳大利亚时被澳大利亚政府禁止使用。 有些人说：\"微软毕竟开创了一个历史，造就了今天的 IT 行业。\" 但是，如果没有微软，我们今天早就用上非常稳定，非常可靠，非常方便，非常\"傻瓜\"的软件了！微软是阻挡信息技术发展的罪魁祸首。 微软的程序的工作方式(注意，我只是说操作方式，病毒的事情另外算)确实适合于一般家庭，上上网，发发邮件，打打游戏都不错。可是微软却要把自己包装成什么 \"高科技\"企业，要在世界各地设置\"研究院\"，在大学计算机系赠送不适合用于科研的 Windows产品，甚至出钱请图灵奖得主来中国畅谈\"二十一世纪的计算\"，还在大会上宣传自己的 .NET 技术。非要把别人认为自己是科学的，自己是领导世界高科技的。但是呢？它什么高科技也没有。欧洲，美国，哪一个关键部门在用微软的东西？NASA? DOE? CERN?你仔细想一想，微软的程序对人类到底有什么重大作用？ 什么是 Windows 能干而 Linux 干不了的事情？--- \"Windows 能干而 Linux 干不了的事情，那就是不需要干的事情。\" 有个朋友看我半年没有用 Windows，有时就会问我：\"你只用 Linux，有没有发现有些Windows 能处理的事情 Linux 干不了？\"--- 我回答说：\"Windows 能干而 Linux 干不了的事情，那就是不需要干的事情。\" Windows 能做的有益的事情 Linux 都能做--- Windows 下的某些功能确实是我们需要的，那么 Linux 的开发者们和用户也需要这种功能，他们就会去实现这种功能，而且比 Windows 的方式好得多。由于大多数科学家，工程师用的都是 Linux 或者某种商业 UNIX, 所以几乎所有商业的科学工程程序，比如Matlab, Mathematica, AutoCAD, Candence的，Synopsys的，Avant! 的……全都是先有UNIX 的版本(包括Linux)，然后再考虑移植给 Windows，甚至根本不移植给Windows，因为 Windows 的机器一般没有足够的能力运行这样的程序。你不要以为只有 Windows 才有 PSpice, UNIX 的 HSpice 要好得多，而且可以运行在大型主机上。当然它们不是免费的，但是它们值那个价钱。 但是 Windows 下有些东西在 Linux 下没有很相似的，或者你找到很多类似的，但是它们每一个比起 Windows 的那个程序都要差很多，那么原因有两种可能性： 有一个完全类似的程序，但是由于它乍一看不漂亮，被你忽略了。而其它程序虽然看起来很漂亮，但是它们是一些初学编程的人写的。现在由于 Gtk, Qt 的诞生，Linux 下开发图形界面程序极其简单，很多初中生甚至小学生都可以随手编出一些漂亮不中用的程序。如果你整天寻找这样的程序挑来挑去，永远也找不到你满意的。当然也有一流的程序用 Gtk 和 Qt，比如 GVIM 就可以用 Gtk 作为图形界面，我还知道 Synopsys 一些程序用了 Qt。 我曾经也犯过这样的错误，从外表区分一切。结果优秀的 FVWM, lftp, Mutt, wget 都被我忽略过。当我找回它们的时候，我是那么的羞愧不已，它们现在都是我的朋友 我第一次看到 FVWM 觉得它只不过是一个有很厚很难看边框的东西。可是现在，我的同学看到 FVWM 都说：\"哇！真漂亮。\" 有另一种完全不同的方式可以达到相同的目的，甚至更好。 很多人很关心 Open Office, Star Office, AbiWord, ... 他们多么盼望有一天某一个Linux 程序能够完全兼容的打开一个复杂的 doc 文档。但是你永远也不可能有那一天。为什么呢？因为微软为了占有市场，必定不会让其它系统的程序能够完全兼容它的文档格式。它一定会不断变化 doc 文档的内部结构，隐藏一些秘密，让其它公司的程序打开 doc 文档时总是有某种问题，从而你必需购买 Microsoft Office 和 Windows。 你应该想一下，那么多的高智商的大学教授，科学家，学生，他们用的都是 Linux 或者其它类型的 UNIX，他们没有 Word 可用，怎么处理文档呢？这么多年没有一个像Open Office 的程序出现，难道大家没有办法写文档吗？ 显然不是这样。你看看那些高水平的学术杂志，论文，那些大学教授的网页，那些漂亮的幻灯片，它们是什么做的？原来 UNIX 用户早就有非常方便的 troff, LaTeX, SGML等东西可以处理文档，而且它们比起 Word 都要高明的多。Word 显然被这些大拿忽略了，以至于很久以来没有人想在 Linux 下开发一个类似 Word 的程序，除非某些公司想抢微软的饭碗。 很多人留着 Windows 在硬盘上的原因无非是为了用 Word 和 PowerPoint。我见过一个教授，他的 Windows 笔记本电脑上除了 PowerPoint 什么都没有。有一天演示的时候，他指着堆乱字符说：\"对不起，这是一个公式……怎么每次都是这样……\" 其实有比PowerPoint 好几百倍的东西可以制造幻灯片，你可以用最简单的方法制造世界一流效果的论文和幻灯片。你待会儿可以看看我的TeX网页，你就会知道为什么我可以完全离开 Windows。 Windows 能做的那些没用的事情 Linux 永远做不好 电脑游戏 有些人说 Linux 下不能玩 Windows 下所能得到的所有游戏。的确，Linux 下虽然也有少量的游戏，比如 Quake。但是它没有 Counter Strike, 没有 Star Craft, …… 并不是说电脑游戏不该玩，但是应该适可而止。电脑是用来处理事务，帮助你学习，解决问题的工具，而不是一个玩具！整天沉迷于电脑游戏中，而不出去感觉外面的世界，你会变得越来越冷酷，越来越缺乏人情味。你与真实的世界越来越远。 你可以在 CS 里杀人，你可以在 Tomb Raider 里探险，你甚至可以在 Tony Hawk's Pro Skaters 里滑板…… 但是 It's not real！你虽然有很高的\"反恐技巧\"，但是遇到歹徒的时候，你是那么的怯懦；你虽然控制 Laura 伸手敏捷，但是你打篮球的时候怎么总是被人断球？你虽然可以轻易的在 THPS 里作出一个 \"360 kickflip to hangten grind to fakie\"，但是你踩在自己的滑板上的时候还不会 ollie！ 说回来，如果你偶尔玩一下电脑游戏未尝不可。但是世界上有远比 Windows + PC 更好的游戏方式。Sony 的 PlayStation2, SEGA 的 DreamCast, Nintendo 的 N64，Namco的街机……每一个都比 Windows 游戏精彩，每一个都有如此高的3D性能，以至于Pentium4, Itanium + GForce4 都无法与它们比美！ Linux 的用户们都是关心解决世界的关键问题的份子，他们哪里有时间用自己的机器来玩游戏啊？他们每天用Linux高效的做完自己的工作就到阳光下享受自然去了。要玩游戏也是玩一些类似推箱子，贪吃蛇之类的智力小游戏。所以，你知道为什么 Linux 几乎没有游戏了吧？ \"整理硬盘，优化系统\" 这是一个非常有意思的话题，仅次于有关\"病毒\"的话题。相信很多 Windows 用户都有整理硬盘的经历。在很多 Windows 用户眼里，\"硬盘用久了，会出现碎片，速度会减慢，需要一个程序来整理，整理硬盘的时候不要做其它工作\"，这好像是天经地义的事情。 我也曾经津津有味的看着 Norton Defrag 一点一点的把我的硬盘排序，调整，用图形的方式显示出来，然后报告100% 没有碎片。你的硬盘现在已经达到最佳状态。\" 我现在才发觉我那时是多么的幼稚。 Linux 和 UNIX 用户似乎从来没有\"整理硬盘\"这种说法呢？你觉得很奇怪吗？如果你觉得很奇怪，那说明你的思想在某种程度上被微软的垃圾程序禁锢了。你需要明白，UNIX 的大型主机很多必须是一天24小时，一年365又1/4天不停运转的，要是每个星期都要整理一次硬盘，在整理的时候几乎不能干任何事情，那是绝对行不通的！ Linux 机器根本不用整理硬盘，这就是为什么没有看到过 Linux 用户整理硬盘。Linux 的文件系统是比 Windows 的 FAT, FAT32, NTFS 高明得多的文件系统，它们不但可以对文件设置权限，实施完全的保护，而且可以\"越用越整齐\"，\"越用碎片越少\"！你应该把文件大部分放在 Linux 的分区，而不是 Windows 分区，因为它比 Windows分区可靠得多。 还有更滑稽的事情就是有很多\"Norton System Doctor\"，\"Windows 优化大师\"，\"超级兔仔注册表魔法\" 之类的程序存在，而且价格昂贵。似乎一个操作系统本来应该有很多问题，需要别的厂商做程序来\"优化\"它，而且为了得到优化，你需要付钱！这些问题 Linux 根本就没有，所以不需要什么优化。Linux 内核本身就是高度优化的。 IDE 有些人在抱怨为什么 Linux 没有一个良好的 IDE 开发环境。Linux 现在已经有一些IDE 了，但是总是有很多问题。你是不是正在寻找，正在期望 Linux 某一天可以有一个VC那样的开发环境？你有没有发现你正在进入微软给你设下的怪圈？你为什么一定要用 IDE？你说：\"IDE 开发迅速，调试方便，适合大型程序……\" 那说明微软的程序在你脑子里已经比较根深蒂固，你需要好好清醒一下了，看看我来告诉你。 高明的 UNIX 程序员不用 IDE，IDE 从来就是给初级 Windows 程序员用的。 你看看大型的 UNIX 程序，包括 Linux 内核，各种网络服务程序，Xwindow 程序在内，哪一个是 IDE 搞出来的？我们实验室的 EDA 程序也没有一个是 IDE 弄的，我还知道Candence, Synopsys，Mentor 的高性能的图形界面 EDA 程序也都不是 IDE 写的。你信不信，微软的人在写 Windows 本身的时候也根本不用 IDE。微软内部程序员最喜欢的编辑器其实是 VIM，用 VIM 的微软程序员上次向乌干达的可怜儿童捐助了1000多美元，这是值得称赞的。 有一次某杂志采访一些出名的 Linux 内核程序员，包括 Linus 在内，没有一个人用IDE，有的人用 VIM，有的用 Emacs，只有 Linus 说\"GNU Emacs is evil\"，但是其实他用的是一种跟 Emacs 有同样键绑定功能的 MicroEmacs。大家都是用编辑器编辑了程序文件，然后用 make 这样的自动工具调用 gcc 编译器完成编译工作的。甚至高级的 Windows 程序员也不用 IDE，他们可以从命令行调用 cl，nmake 来编译自己的程序。虽然这样的 Windows 程序员很少，但是他们却是最了解 Windows，最高明的Windows 程序员。 为什么 UNIX 程序员不用 IDE？明白了这个道理你就能体会到 UNIX 的设计思想了。首先，一个 IDE 集成了编辑器，编译器，汇编器，调试器，跟踪器…… 这个编辑器功能肯定比不上 VIM 或 Emacs，编译器比不上 GCC，汇编器比不上 as，调试器比不上 gdb，ddd, 跟踪器比不上 strace, ltrace, truss。你得到的是一套整合的低能的程序。如果你对调试器的功能不满意，你只好换用另外一套 IDE，但是这套 IDE 的热键，菜单，编辑器功能，按钮…… 跟原来那个有很大不同。你不得不花很多时间来熟悉新的环境，而不能保持原来的某些东西。 而在 UNIX 下就不一样了。你可以用你最喜欢的 VIM 编辑程序，你在 VIM 里可以调用GNU make，make 可以调用 gcc, ld, ... make 的出错信息可以被 VIM 捕获，VIM 能帮你在源程序里定位。你如果喜欢 icc, 你可以让 make 用 icc 而不是 gcc。你如果觉得 gdb 跟踪变量时比较麻烦，你可以用 ddd 来显示各种数据结构之间的关系。你还可以在 Emacs 里调用 gdb，那样就可以同步显示源代码了。而且 VIM 和 Emacs 还可以编辑很多其它东西，比如信件，LaTeX 文档，HTML，配置文件…… 你不用另外找一个什么编辑器来干这些杂活了。很多程序比如 Mutt, tin 都可以在内部使用 VIM，这样就更方便了。实际上 make 在其它方面还能帮你很多忙，我的每一个比较大型的 LaTeX文档都是用 make 维护的。 Linux 能干的高精尖的事情 Windows 都干不了 当然有很多事情是Linux/UNIX的专利了。因为 Windows 只能装在 PC 机上，好像以前也有 Alpha 可以使用 Windows NT，但是就是没见到有人用。PC 机的能力是很低的，像我们编程序处理 NP-Hard 问题的人，用 Windows 的机器显然速度不够，而且有时一个问题算上几天甚至几个星期，Windows 机器是以\"死机\"著称的，我们怎么能放心？所以几乎所有科学计算程序，EDA 程序，高性能图像处理程序都不是 Windows 的。他们有时也会移植一些给 Windows，但是常常降低那些程序的能力。你比较过 Windows 版本的 Mathematica 和 Linux 的有什么区别吗？ IBM 制造的最大的并行计算机有 8000 多个处理器，Windows 不可能有能力管理这么多处理器，它用的是什么操作系统？答案是 Linux。 《泰坦尼克号》电影里的三维动画，那么细腻逼真，Windows机器能做出来吗？不行。那也是 Linux 机器做的。 民航总局用来训练地情人员的虚拟现实训练设备，Windows 当然无能为力。那都是商业的 IRIX 机器。 UNIX 是最早支持 TCP/IP 网络协议的系统。它上面有很多可以互相协作的网络服务程序，它们经过多年的使用和修订，已经达到比较完善的程度。而就在1997年，微软的比尔盖茨还在扬言：\"Internet 是没有前途的。\" 微软的这个\"远见卓识\"大家应该都已见识，它后来加上的网络服务程序IIS漏洞之多，让公安部都频频发出警报，大家也是见识了的。 其实你知道了，Windows 没有一样有用的事情能比 UNIX 干的更好。 Linux 干不了的有用的事情 Windows 照样干不了 当然 Linux 不是万能的。它也有不能干的事情，电脑也有干不了的事情。但是 Linux干不了的事情，Windows 肯定也干不了。这些事情就是我们需要探索，需要努力的事情了。在你探索的过程中，Linux 必定是你的好伙伴。 不要把Linux和Xwindow掩盖起来！不要把我们的用户当成傻瓜。 什么？你早就知道 Windows 是垃圾？噢！你怎么不早说呢！害我废话这么多。嘿嘿。 \"好了。你知道 Windows 是垃圾，你现在用什么\" \"Linux + Xwindow\" \"那我问你，Xwindow 是什么样的？\" \"不就是跟 Windows 差不多吗？只不过 'Start' 按钮比较方，而且上面不是一个Windows 标志，而是一个脚丫子。点击一下居然还有很漂亮的中文菜单。我喜欢！\" \"你知道什么是'根窗口'吗？\" \"不知道。从来没听说过呢？\" \"根窗口就是遮盖整个屏幕的那个最大的窗口。\" \"哪儿有什么窗口啊！我没有看到呢？\" 你发现了问题吗？这些 Linux 用户说是在用 Linux 和 Xwindow，但是他们对 Linux和 Xwindow 几乎完全不了解。很多人用了那么久 Xwindow 都不知道根窗口是什么东西，不知道其实按钮也是窗口，不知道窗口管理器和其它程序有什么关系，大家都以为窗口上面的按钮是程序自己放上去的，不知道窗口? quot;class name\"，\"resource name\"是什么东西。他们也不知道 .Xdefaults 是用来干什么的。特别是他们很多人都不知道 Xwindow 的字体是如何命名的，什么是 fontset，有了一个新的字体也不知道怎么安装。 他们被遮在 Linux 之上的一层一层的包装迷惑了，他们等待有图形界面的工具来帮助完成一切事情，他们认为 Linux 跟 Windows 一样，只是麻烦一点。他们知道 Linux内核很好，但是他们感觉不到 Linux 和 Xwindow 在操作层面的天生的先进性，随后不久就把 Linux 完全删除掉了。你发现没有，要用户理解 UNIX 和 Xwindow 的操作层面的先进性，才是留住用户的最好办法。如果用户体会不到操作时的方便和高效，内核再好他们也不会理会。 但是用摹仿 Windows 的作法来吸引用户，永远会失败的。因为 Linux 如果摹仿Windows那一套低效率的方式，那么 Linux 的这套\"低效率方式\"永远比不上Windows 的那一套\"低效率方式\"。那么用户就会说：\"这个 Linux，没有一样比的上 Windows。\" Linux 天生就是继承了 UNIX 的高效的工作方式，为什么我们要把它掩盖起来？我们为什么只告诉用户 KDE 的菜单怎么用？我们为什么不能像早期的 Xwindow 书籍那样第一节就告诉用户什么是 X server, 什么是 X client，什么是 Window Manager, 什么是根窗口。第二章就告诉用户窗口有哪些属性，什么是 classname, resource name, hint，怎样使用 .Xdefaults, xrdb …… 在这里我又不得不说一下那些 Linux 的发行公司和写书的人，他们把 Linux 和Xwindow 包装起来，却没有从基本上告诉用户 Xwindow 的工作原理。很多书籍讲授的层次就是在Gnome, KDE 的菜单操作的层次，靠大量抓图来占篇幅，\"繁荣\"Linux 书籍市场。 现在很多人已经把能够利用别人的库写出一个好看的程序作为自己编程水平的象征。在这\"图形化\"，\"可视化\" 的年代，你如果还在用 troff, LaTeX 写文档，你还在用VIM 自己编辑 HTML，用 Mutt 处理邮件，你还在用文本模式的 gdb 调试程序，你还在用Xlib 写程序, 你还在用 tin 上 USENET，你还在自己写 Makefile，写机器代码，你还在玩 Clossal Cave 这样的字符模式冒险游戏，那你就是老古董。 其实这种思想是错误的。虽然你是一个坚决的 Linux 支持者，但是你的思想是 Windows的思想。你认为图形界面，菜单，按钮就可以解决一切问题，就可以给你高效方便。你还是没能摆脱微软给你的潜移默化的东西。你其实离不开 Windows 那样的环境，你迟早会删掉自己的 Linux。 GUI vs. CLI 做一个坚定不移的\"两面派\" 大家看到这个标题是不是热血沸腾？两派大虾都可以围攻我了： GUI派用户：\"哇！我一看你这小子就是 CLI 的。要不然自己写什么 Makefile？用什么Mutt？\" CLI派用户：\"切～ 你还用 X！高手都不用 X。你是 GUI 那边的。\" 可怜的我：\"555～～ 你们都不要我～～ GUI 和 CLI 就那么水火不容吗？\" 计算机界这样的门派之分还很多。很有特点的就是 CLI 和 GUI 了。CLI (Command LIne)的狂热份子声称永远不用 X。我上次在实验室看到一个同学用一个 SecureCRT 登录到Sun 机器，然后用一个 vanilla vi 编辑程序，我建议他启动一个 GVIM 过来显示在Exceed 上可以有语法加亮。但是他坚决反对，说：\"高手不用X。你想想，要是我在一个很慢的网络连接怎么用 X？而且好多服务器没有装 X 程序。\" 但是我们实验室的网速可够快，Windows 机器都有 Exceed 啊，而且 Sun 机器有全套X 客户程序包括 GVIM。他说他是 CLI 的坚决拥护者，但是他却在用 Windows，他后来打开了好几个 SecureCRT，每次从文本框输入地址，用户名和密码，从下拉菜单选择\"SSH2\"，然后点击\"Connnect\"。他还不断的夸SecureCRT 是\"网络管理员投票选出的最受欢迎的登录方式\"。老天，SecureCRT 本身就是个 GUI 啊，他其实没有明白Xwindow 的好处。 你说我是 GUI 的？我虽然很少在 console 下工作。但是我对 bash, VIM 很熟悉，我可以让 bash 按照我的键绑定方式来工作。我可以在 rxvt 里使用 Mutt 来收发 email。我的每个桌面上都常常堆放着一打不同大小的 rxvt。我用 VIM 编辑 LaTeX。我自己写Makefile 来维护 LaTeX 文档。我有时用 mpg321 来放 mp3。我上BBS用的我自己写的expect 脚本。 好了，CLI 派的朋友可以收我做盟友了 你说我是 CLI 的老古董？我的 FVWM 被我配置为可以\"手写操作\"，我只要画一个\"r\"就可以启动 rxvt，我只要画一个 \"U\" 就可以启动 GVIM，…… 我用 GVIM 语法加亮模式编辑程序，我用 Mozilla 浏览网页，…… GUI 派的现在好像认我做朋友了 好了。CLI 派的朋友，虽然我很喜欢命令行，但是我有时在屏幕上左右画一下就可以执行: Module FvwmConsole -terminal rxvt -geometry 45x5-0+0 -bg gold -fg midnightblue -fn \"-adobe-courier-medium-r-*-*-14-*-*-*-*-*-*-*\" 你是不是现在又想把我逐出师门？ GUI 派的朋友，虽然我很喜欢窗口。但是我可以在 FvwmConsole 里输入： All (rxvt) MoveToDesk 把我所有的 rxvt 移动到我现在工作的桌面。\"这家伙，怎么这么快就叛变了！\" 其实何必分什么 GUI 和 CLI，UNIX 和 Xwindow 都是工业标准，它们从设计那天开始就有非常灵活的用法，各个程序，不管是 GUI 还是命令行的都可以互相协作。UNIX 和X 是一家，何必搞的那么偏激，非此即彼？你从我上面的行为可以看出 GUI 和 CLI的模糊界线吗？我就是坚定不移的\"两面派\"。 UNIX 是简单的-- \"我相信简单就是最好，如果太复杂，我是不能理解的。\" -Seymour Cray 很多第一次用 Linux 的人会惊奇的发现，Linux 的程序居然不\"安装\"就可以运行，程序拷贝到随便那个目录都可以用，而不是一定要占用你第一个分区的空间。程序的设置只是一些简简单单的文本文件。你根本不需要什么\"注册表修改器\" 就可以改变系统的设置。这就叫做简单，但是简单就是美。虽然这只是 UNIX 简单性的一个肤浅的认识，你已经体会到了某些东西。 但是简单并不意味着功能弱，并不意味着落后。相反，简单意味着强大，意味着生命力。 我不会再继续阐述我理解到的\"UNIX 的简单\"，因为这个需要自己去体会。 UNIX 是永恒的 有人说：\"Plan9 会取代 UNIX，Mach 会取代 Linux 内核。\" 但是你如果是一个深入体会了 UNIX 的人，你就会知道：UNIX 的思想是永恒的，不管时过境迁，Plan9 是否代替 UNIX，UNIX 的灵魂都会在 Plan9 身上现形！ 我为同一个设备写过 Linux 内核和 Windows VxD 驱动程序。写 Linux 驱动程序时，我对 UNIX 设计的完美的一致性，远见性所折服。UNIX 用同样界面的 read(), write()系统调用就可以对不同的对象：普通文件，设备文件，管道，管道文件，socket，……进行统一的读写操作。我跟本不需要写一个测试用的应用程序就可以对我的设备驱动进行测试，因为 cat, cp, dd, 它们也使用了同样的 read(), write()，设备和普通文件在应用程序眼里没有区别。在那个还没有 Smalltalk, 没有 C++ 的年代，UNIX 的设计者已经使用了所谓的 \"面向对象方法\"。对，C 语言也可以实现面向对象。 UNIX的系统调用几十年都没有很大变化，这非但不是顽固，不进步的象征，反而是UNIX 的远见卓识的体现！这就跟 TeX程序几十年都不变的情况差不多。这些才是真正的永恒的 master piece!你应该改变所有软件都必需从 0.1, 1.0, 1.1, 1.2, 2.0, ..., 3.0, 3.1,95, 98, 2000, XP, ... 不断升级的想法。 Windows 就不同了，它在最开头只是一个 DOS之上的图形包装而已。后来为了兼容以前的糟糕设计，不得不加上很多累赘。我写VxD 驱动程序的时候就深有体会，Windows 95 程序对设备的操作只有用DeviceIoControl，我不得不写了两个应用程序来对设备驱动进行测试。Windows内核的不一致性和隐密性使我非常恼火。不过 Windows WDM驱动程序现在也有了 ReadFile, WriteFile，…… 那说明什么？那说明Windows 在向 UNIX 学习，或者有可能是某个 UNIX设计人员在微软打了几天临工，顺手加了几个UNIX的东西进去。这样做是没有用的，Windows从一开始就是非常糟糕的设计，它的历史的包袱太沉重了，缝缝补补有什么用？它只能永远的被UNIX 甩在身后！ UNIX 是强大的 让聪明人干任何他们想干的事情。 UNIX 的一个特点就是非常高的灵活性，Xwindow也具有这种灵活性。这种灵活性体现在哪里呢？ UNIX 的程序一般都有很多参数，不管你现在用的着用不着，总有人需要某些参数。它们的行为很多都可以用配置文件来改变。比如GNU bash, 通常缺省的命令行输入方式是 Emacs 方式，但是只要我编辑一个.inputrc 文件，就可以把它变成 vi的输入方式，而且我还可以自己绑定键序列到某些操作。我可以用 shopt来设置它的很多特点，比如是否进行通配符扩展，是否可以把一个变量当作一个目录来cd，是否可以自动纠正某些明显的目录名打字错误…… UNIX程序设计的思想是提供给用户“机制”，而不限制用户制定“政策”。这是一个重要的尊重用户的作法。 我们再来看看 Xwindow。Xwindow是一个出色的设计，它把显示服务器和客户程序分开。一个显示上既可以显示本机上的程序，也可以显示别的机器上的X程序，而它们都遵守你的窗口管理器的统一指挥，它们之间可以方便的传送剪贴版数据，各种事件…… 比如有时我的 XFree86 上会出现四个不同机器上的XTerm，两个不同机器上的 GVIM，…… 它们统一受本机上的 FVWM指挥。 Xwindow 程序都具有很多很多命令行参数和 resource参数。你可以随意的在命令行或者 .Xdefaults文件设置所有的颜色，字体，尺寸…… 而且如果你用 xrdb 把 .Xdefaults导入到根窗口，那么其它机器上没有经过配置的同样的程序，显示到你的机器上的时候也会遵守同样的外观规定。 Xwindow 的窗口具有 Property,也就是一些可以自己定义的共享数据(原子)。正是因为这些 Property的存在，使得 Xwindow 具有无比强大的生命力。X的窗口管理器和其它客户程序之间并没有统一的协议，但是后来出现了ICCCM(客户程序间通信规范)，这个规范就是通过 property定义的。现在又有人定义了一套“扩展的窗口协议(EWM Hints)”，使得Xwindow 可以具有某些 Windows 的特征，比如一个工具条程序可以告 诉窗口管理器：“这个屏幕下面被我占据了24个像素的空间，你最大化程序的时候不要越过这个界线。” 一个强大的窗口管理程序比如FVWM，它收到这样的提示时，可以答应工具条程序的这个要求，也可以不答应。一切选择的权力在于谁？当然是用户了！ 你想想，是不是有些 Windows 程序常常弹出一个窗口要你选择 \"Yes orNo\"？你不点击它它就不下去。你觉不觉得你的程序在侵犯你的尊严？你是一个人，一个智慧的生物，怎能受到一个程序如此的待遇？ 还有就是很多 Windows程序把人当成傻瓜，而它是“智能程序”。比如，有一个程序就是喜欢把你的每句话第一个字母都变成大写，我不说它是谁了，你遇到的时候就知道了。 如果连“一句话开头一个字母要大写”这么明显的问题都需要程序帮你纠正的话，人脑还用来干什么？况且如果你故意想要不大写的话，那就更麻烦了，我楞是没有从它那一大堆菜单里找到怎么关闭这个愚蠢的选项。 只有符号才能完全操纵计算机 我们来说说很多初学 Linux 的用户。虽然他们在用 Linux，但是他们打心眼儿里是觉得 Windows 的工作方式好，他们希望 Linux 有一天能\"像Windows那样\"。你说：\"我鼠标一点，我菜单一拉，...... 就可以完成我的操作。\" 但是我要告诉你：\"Linux 从来没有摹仿 Windows，将来也不会。Linux 从诞生之日起，它的工作方式就比 Windows 的先进。Linux 属于能勇敢面对符号的人。只有符号才能完全操纵计算机。\" 看看优秀的 UNIX 程序，XFree86, FVWM, VIM, Emacs, proftpd, Mutt, wget,tin, ... 没有一个不是用配置文件来设置选项的。为什么这些程序没有方便的菜单可以用来配置?难道它们的设计者就那么低能，连个图形配置界面也写不出来? 当然不是。因为图形界面配置方式的能力是极其有限的，而配置文件和程序语言的表达能力却是无限的。用图形界面配置这些程序的话，如果你想达到配 置文件的效果，你需要成百上千的菜单，checkbox, radio button, ... 到时候你根本没办法找到你需要修改的地方了!而各个程序的配置文件的语法都有很多相似之处，一般就是一些命令，设置一些变量，参数，...... 一旦用会了一个，其它的也就容易理解了。如果你用惯了 awk, sed, Perl，你会觉得那才是真正的自动化啊。 鼠标虽然是很好的工具，但是它的表达能力是有限的。你不可能光用鼠标就让电脑完全明白你的意思，它毕竟只有3个按钮。看看我的MetaPost页你就能体会到鼠标的这一弱点。所以我们虽然很喜欢鼠标，但是却不能完全依赖它。 各个小程序的完美配合 这就是UNIX最重要的特点了，它就是UNIX设计的思想。让每个程序只具有一项专门的能力，然后让它们合作。Xwindow也继承了这种好传统。 这恐怕就是Windows和其它操作系统望尘莫及的地方了。UNIX 程序设计之统一，配合之完美，真使我难以置信!shell, grep, find, awk, sed, make, Perl,Emacs, vi, tin, Mutt, ... 它们是那么的具有一致性!你一旦学会了 sed 的正则表达式，其它程序基本上都能用了。你一旦学会了 vi 和 VIM, 你会发现它的操作是那么的有规律性，似乎vi的设计者在几十年前就已经设计好了 VIM 在今天的完美而统一的操作方式!而且vi的操作还体现在 Mutt, tin 等很多程序中。你甚至可以把 bash 设置为 vi 的输入方式来输入命令行，我就是这么做的。一个程序可以调用另外一个程序来得到数据，可以把数据交给它处理后返回来，可以在自己的窗口里\"嵌入\"另外一个程序。 在 Windows 和其它非 UNIX 操作系统中，这种合作是非常困难的。我曾经在Windows 下使用 Perl来进行一些自动工作。但是 Windows 的文件操作，管道是如此的不稳定，程序之间基本不能合作。你别想在 Visual Studio 窗口里面嵌入UltraEdit 编辑器，你别想用一个 expect 脚本来控制 telnet 到水木清华BBS，这就是为什么 helloooo 诞生在 Linux 而不是 Windows。我曾经试图从Windows + Exceed + SecureCRT ssh 登录到 Sun 机器，然后通过 ssh 的隧道(X11 tunnel)把 X 程序传到 Exceed 上运行，但是搞了两天都没有成功!而在Linux 下这个事情根本就是不用怎么配置的，OpenSSH 和 XFree86 本来就是完美结合，只要打开 ssh 的 \"forward X11\" 选项就什么都搞定了。 Windows 的程序都是大而全，大而杂，所有的电子邮件程序都需要自己提供编辑器，自己发送和收取邮件，自己显示邮件的附件。每一个BBS程序都提供自己的 Virtual Terminal, 自己的通讯代码。每一个 IDE 都自己提供编辑器，编译器，汇编器，调试器。人们为了使用一种新的程序，需要适应所有这些它提供的界面，而不能使用自己喜欢的编辑器的键绑定，菜单组织...... 不能 DIY! 你要知道，最高级的电脑是定做的，自己想要什么什么CPU，什么主板，多少内存，什么硬盘，键盘，鼠标，显示器都是自己选择的。最高级的滑板，自己想要什么牌子的版面，什么牌子的沙，什么桥，什么轮子，什么轴承，也都是自己选的。最高级的乒乓球拍，木板，胶皮，海绵，胶水都是可以自己选择...... 而用Windows 程序，你得到的是大杂烩，就像你去买\"品牌机\"，只有那么几种配置，而且附带很多你不需要的软件和服务;就像你去买组装好的滑板，你想要大一点的轮子和窄一点的板子，但是你没有这种选择余地!Windo ws 程序就相当于最廉价，最次的滑板。但是它却会花你更多的钱，因为一旦一个部件坏了，或者你不喜欢了，你不能另外找一个好的换掉它，你必需重新买全套配件! 而 UNIX 和 Xwindow 就是高档的\"组装货\"。比如我用 Mutt 的时候，我可以用VIM 也可以用 pico 来编辑邮件，我可以用 ImageMagick 也可以用 xv 来显示附件里的图片，我可以用 lynx 把 HTML 附件转成文本嵌入窗口中，我也可以把HTML 附件交给 Mozilla 图形显示。我可以让 GnuPG 帮我把邮件进行数字签名和加密，我也可以用其它 PGP 程序。我想让 Postfix 而不是 sendmail 帮我发出邮件，我想让 fetchmail 帮我收邮件，转发给 postfix，然后被我自己写的Perl过滤器处理...... 这一切我都可以办到!我可以选择我最喜欢的专门的程序来完成专门的工作，然后把它们结合在一起，我也可以分别得到它们的好处。 结论 我写这么多的目的是什么?我希望喜欢 Linux 的朋友，完全清除微软和Windows 灌输在你脑子里的谬论，别再相信它们所谓的\"新技术\"，别再追赶Windows，因为追赶 Windows =倒退。马克思有一个思想很重要，\"新生事物并不一定是在最近出现的。\" UNIX，Xwindow, TeX 虽然都比 Windows 先出现，但是它们才是先进生产力的代表。我们要清楚的认识到什么才是真正的现代化，什么才是真正的自动化。 勇敢的拿起像 bash, FVWM, VIM, Emacs, Mutt, lftp ...... 这样强大的程序，不要再埋怨\"Linux 为什么不能像 Windows 那样\"，不要再浪费时间试用这样那样的程序，不要再忙着升级。是你需要改变而不是 Linux 和 UNIX，Linux 现在就可以成为你的好朋友。你需要认识它，了解它，信任它，才能完全的靠它来高效的工作，省出时间来处理世界上更加值得处理的事情。 转自：http://www.cnbeta.com/articles/76147.htm","title":"[回顾]清华申请退学博士作品：完全用Linux工作"},{"content":"mkdosfs 引导扇区 结构体分析 ///mkdosfs #define BOOTCODE_SIZE  448 #define BOOTCODE_FAT32_SIZE 420 /* __attribute__ ((packed)) is used on all structures to make gcc ignore any  * alignments */ struct msdos_volume_info {     __u8 drive_number;  /* BIOS drive number */     __u8 RESERVED;  /* Unused */     __u8 ext_boot_sign;  /* 0x29 if fields below exist (DOS 3.3+) */     __u8 volume_id[4];  /* Volume ID number */     __u8 volume_label[11]; /* Volume label */     __u8 fs_type[8];  /* Typically FAT12 or FAT16 */ } __attribute__ ((packed));    //26bytes struct msdos_boot_sector {     __u8 boot_jump[3];  /* Boot strap short or near jump */              //union之前36bytes     __u8 system_id[8];  /* Name - can be used to special case        partition manager volumes */     __u8 sector_size[2]; /* bytes per logical sector */     __u8 cluster_size;  /* sectors/cluster */     __u16 reserved;  /* reserved sectors */     __u8 fats;   /* number of FATs */     __u8 dir_entries[2]; /* root directory entries */     __u8 sectors[2];  /* number of sectors */     __u8 media;   /* media code (unused) */     __u16 fat_length;  /* sectors/FAT */     __u16 secs_track;  /* sectors per track */     __u16 heads;  /* number of heads */     __u32 hidden;  /* hidden sectors (unused) */     __u32 total_sect;  /* number of sectors (if sectors == 0) */     union {  struct {      struct msdos_volume_info vi;    //26bytes      __u8 boot_code[BOOTCODE_SIZE];       //36 + 26 + 448 = 510  } __attribute__ ((packed)) _oldfat;  struct {      __u32 fat32_length; /* sectors/FAT */          //msdos_volume_info之前28bytes      __u16 flags; /* bit 8: fat mirroring, low 4: active fat */      __u8 version[2]; /* major, minor filesystem version */      __u32 root_cluster; /* first cluster in root directory */      __u16 info_sector; /* filesystem info sector */      __u16 backup_boot; /* backup boot sector */      __u16 reserved2[6]; /* Unused */      struct msdos_volume_info vi;        //26bytes      __u8 boot_code[BOOTCODE_FAT32_SIZE];   //36 + 28 + 26 + 420 = 510  } __attribute__ ((packed)) _fat32;     } __attribute__ ((packed)) fstype;    //fstype分_oldfat和_fat32,旧的文件系统和新格式化的fat32     __u16 boot_sign;                    //2bytes   //0xAA55  小端 } __attribute__ ((packed));   如图：","title":"mkdosfs 引导扇区 结构体分析"},{"content":"第一步：安装gsl 按照官网给出方式安装gsl到默认目录（./configure ; make ; sudo make install; ） 第二步：配置eclipse 右键单击项目(project)，选择properties。 C/C++ Build -> settings           GCC C++ Linker -> Libraries -> Libraries(-l)                                添加两项：1、gsl  ； 2、gslcblas 清理并重建项目 如下图：","title":"linux(ubuntu) eclipse 中 gsl 的配置"},{"content":"位于：/usr/src/linux/include/linux/ip.h struct iphdr { #if defined(__LITTLE_ENDIAN_BITFIELD) __u8    ihl:4, version:4; #elif defined (__BIG_ENDIAN_BITFIELD) __u8    version:4, ihl:4; #else #error “Please fix <asm/byteorder.h>” #endif __u8    tos; __be16 -tot_len; __be16 -id; __be16 -frag_off; __u8    ttl; __u8    protocol; __be16 -check; __be32 -saddr; __be32 -daddr; };  IPv4 (Internel协议)头部 Loosky LOOSKY iphdr->version 版本(4位)，目前的协议版本号是4,因此IP有时也称作IPv4。 http://loosky.net iphdr->ihl 首部长度(4位):首部长度指的是IP层头部占32 bit字的数目(也就是IP层头部包含多少个4字节 — 32位),包括任何选项。由于它是一个4比特字段,因此首部最长为60个字节。普通IP数据报(没有任何选择项)字段的值是5 <==> 5 * 32 / 8 = 5 * 4 = 20 Bytes http://loosky.net iphdr->tos 服务类型字段(8位): 服务类型(TOS)字段包括一个3 bit的优先权子字段(现在已被忽略)，4 bit的TOS子字段和1 bit未用位但必须置0。4 bit的TOS子字段分别代表:最小时延、最大吞吐量、最高可靠性和最 小费用。4 bit中只能设置其中1 bit。如果所有4 bit均为0,那么就意味着是一般服务。 LOOSKY iphdr->tot_len 总长度字段(16位)是指整个IP数据报的长度,以字节为单位。利用首部长度字段和总长度字段,就可以知道 IP数据报中数据内容的起始位置和长度。由于该字段长16比特,所以IP数据报最长可达65535字节 总长度字段是IP首部中必要的内容,因为一些数据链路(如以太网)需要填充一些数据以达到最小长度。尽管以太网的最小帧长为46字节,但是IP数据可能会更短。如果没有总长度字段,那么IP层就不知道46字节中有多少是IP数据报的内容。 LOOSKY iphdr->id 标识字段(16位)唯一地标识主机发送的每一份数据报。通常每发送一份报文它的值就会加1。 From HTTP://LOOSKY.NET iphdr->frag_off (16位) frag_off域的低13位 — 分段偏移(Fragment offset)域指明了该分段在当前数据报中的什么位置上。除了一个数据报的最后一个分段以外，其他所有的分段(分片)必须是8字节的倍数。这是8字节是基本分段单位。由于该域有13个位，所以，每个数据报最多有8192个分段。因此，最大的数据报长度为65,536字节，比iphdr->tot_len域还要大1。 From HTTP://LOOSKY.NET iphdr->frag_off的高3位 (1) 比特0是保留的，必须为0； (2) 比特1是“更多分片”(MF — More Fragment)标志。除了最后一片外，其他每个组成数据报的片都要把该比特置1。 (3) 比特2是“不分片”(DF — Don’t Fragment)标志,如果将这一比特置1，IP将不对数据报进行分片,这时如果有需要进行分片的数据报到来，会丢弃此数据报并发送一个ICMP差错报文给起始端。  iphdr->ttl TTL(time-to-live) — 8位，生存时间字段设置了数据报可以经过的最多路由器数。它指定了数据报的生存时间。TTL的初始值由源主机设置(通常为32或64),一旦经过一个处理它的路由器,它的值就减去1。当该字段的值为0时,数据报就被丢弃,并发送ICMP报文通知源主机。 TTL(Time to live)域是一个用于限制分组生存期的计数器。这里的计数时间单位为秒，因此最大的生存期为255秒。在每一跳上该计数器必须被递减，而且，当数据报在一台路由器上排队时间较长时，该计数器必须被多倍递减。在实践中，它只是跳计数器，当它递减到0的时候，分组被丢弃，路由器给源主机发送一个警告分组。此项特性可以避免数据报长时间地逗留在网络中，有时候当路由表被破坏之后，这种事情是有可能发生的。 http://loosky.net iphdr->protocol 协议字段(8位): 根据它可以识别是哪个协议向IP传送数据。 当网络层组装完成一个完整的数据报之后，它需要知道该如何对它进行处理。协议(Protocol)域指明了该将它交给哪个传输进程。TCP是一种可能，但是UDP或者其他的协议也是可能的。 http://loosky.net iphdr->check 首部检验和字段(16位)是根据IP首部计算的检验和码。它不对首部后面的数据进行计算。 ICMP、IGMP、UDP和TCP在它们各自的首部中均含有同时覆盖首部和数据检验和码。 为了计算一份数据报的IP检验和,首先把检验和字段置为0。然后,对首部中每个16 bit进行二进制反码求和(整个首部看成是由一串16 bit的字组成),结果存在检验和字段中。当收到一份IP数据报后,同样对首部中每个16 bit进行二进制反码的求和。由于接收方在计算过程中包含了发送方存在首部中的检验和,因此,如果首部在传输过程中没有发生任何差错,那么接收方计算的结果应该为全1。如果结果不是全1(即检验和错误),那么IP就丢弃收到的数据报。但是不生成差错报文,由上层去发现丢失的数据报并进行重传。 http://loosky.com iphdr->saddr 32位源IP地址 iphdr->daddr 32位目的IP地址 FROM 自由的风 网络字节序 4个字节的32 bit值以下面的次序传输:首先是0~7bit,其次8~15bit,然后16~23bit,最后是24~31 bit。这种传输次序称作big endian字节序。由于TCP/IP首部中所有的二进制整数在网络中传输时都要求以这种次序,因此它又称作网络字节序。","title":"iphdr结构"},{"content":"浏览目录类： 1、pwd：显示当前所在目录 2、cd：进入相应的目录   cd  ==== cd ~ 进入主文件夹  cd /  进入根文件  cd /var/tmp 进入指定文件  cd ..    向上 3、ls ：显示文件或目录的信息 语法格式：ls [参数] [文件或目录]  参数：  -a:显示所有文件或文件夹  -A:显示指定目录下所有子文件夹及文件，但是路径中不显示‘.’和‘..’  -c:按照文件的修改时间排列显示  -C:将显示结果分为多列显示  -l:按照长格式显示文件（详细信息）等价于ll命令   浏览文件类： 1、cat 浏览文件内容 格式：cat [参数] 文件名 参数：  -b:只对非空行进行行号的标注  -n:对所有行进行行号的标注 2、more 分页显示文件内容 格式：more [参数]  文件名   （注意：按q结束浏览） 参数：  -num:num为一个整数，表示每页显示的行数  +num:num为一个整数，从哪行开始显示 3、less 分页显示文件（方便对显示文件进行查找） 格式：less 文件名   目录操作类： 1、mkdir 创建文件夹 格式：mkdir [参数] 文件夹的名称 参数：-p:在父目录不存在的情况下，创建父目录及子目录（创建了一个文件夹的树形结构） 2、rmdir 删除目录(注意删除时目录必须为空) 格式：rmdir [参数] 文件夹的名称 参数：-p:在删除当前目录时，如果父目录为空，将父目录一起删除。   文件操作类 1.cp命令 复制文件 格式:cp [参数] 源文件 目的文件 参数:  -f:如果目标文件已经存在，直接覆盖目标文件，没有提示  -i:如果目标文件已经存在，给出提示（y代表yes，n代表no）  -R:复制目录结构 2.mv 移动万文件或文件夹 格式：mv [参数] 源文件或目录 目的文件或目录 3.rm  删除文件或目录 格式:rm [参数] 文件或目录  参数:  -i:给出提示  -f:不给提示，直接删除  -R:删除文件及目录 4.touch 创建一个空文件 格式：touch [参数] 文件名（目录结构） 参数: -d: 同时修改创建时间  -a: 将文件存取的时间改为当前时间  -m: 将文件的修改时间改为当前时间 5.ln 创建文件链接 硬链接：相当于两个文件，这两个文件指向同一存储空间，当修改一个文件时，另一个跟着变，当删除一个文件时，另一个文件不会被删除 软链接：类似windows中的快捷方式 格式：ln [参数] 源文件或目录 链接文件名 参数：-s:代表软链接 6.gzip和gunzip  压缩和解压缩(压缩后文件的扩展明为.gz) 格式: gzip [参数] 文件名  gunzip [参数] 压缩文件名 参数:-v 显示压缩和解压时的信息 7.tar 用于文件的打包（类似于winrar） 格式：tar [参数] 档案cd文件(打包生成的文件) 源文件的列表 参数: -c:创建压缩文件  -v:显示打包的详细信息  -f:指定档案文件的名称  -z:以zip格式压缩或解压文件  -j:以bzip的格式压缩或解压文件  -r:将文件追加到档案文件的末尾  -x:解压文件 8.rpm 进行软件包的管理（安装，卸载，升级，查找） 格式：rpm [参数] 软件包 参数: -q:查询指定的软件在系统中是否被安装  -qa:查询系统中安装的所有软件  -qi:显示系统中安装的软件的详细信息  -qf:显示系统中指定的文件所属的软件包  -i:指定要安装的rpm包  -v:显示安装时的详细信息  -h:以“＃”显示安装进度  -e:卸载以安装的RPM  -U:升级软件包 9.whereis 获取软件路径 格式：whereis 命令名称 10.whatis 获取命令的信息 格式：whatis 命令名称 11.find 文件查找   格式：find [路径] ［匹配表达式］ 几种情况： (1). 查找指定名称的文件：-name  文件名称 (2). 查找指定类型的文件：-type 文件类型（f:普通文件  b:快设备文件 c:字符设备文件 d:目录 p:管道 l:链接文件） (3).按照大小查找文件：-size n:n为一个整数。代表查找的文件大小不大于n块（一块是512B） (4).按照最后访问时间来查找：-atime n:n为一个整数。＋n表示超过n天访问的内容；－n表示为超过n天访问的文件  (5).将查找到的文件执行相应的命令：    -exec 命令 {} \\;将查找到的文件直接执行命令   -ok   命令 {} \\;先提示用户是否要执行，然后再执行（给提示） 12.grep 用于查找文本中包含指定字符串的行。 格式：grep [参数] 要查找的字符串 文件名 参数： -v:列出不匹配的信息  -c:对匹配的行进行计数  -i:不去分大小写  -n:显示行号","title":"linux虚拟机指令（文件、目录操作类）"},{"content":"waitpid系统调用在Linux函数库中的原型是： #include <sys/types.h> #include <sys/wait.h> pid_t waitpid(pid_t pid,int *status,int options) 从本质上讲，系统调用waitpid和wait的作用是完全相同的，但waitpid多出了两个可由用户控制的参数pid和options，从而为我们编程提供了另一种更灵活的方式。下面我们就来详细介绍一下这两个参数： pid 从参数的名字pid和类型pid_t中就可以看出，这里需要的是一个进程ID。但当pid取不同的值时，在这里有不同的意义。 pid>0时，只等待进程ID等于pid的子进程，不管其它已经有多少子进程运行结束退出了，只要指定的子进程还没有结束，waitpid就会一直等下去。 pid=-1时，等待任何一个子进程退出，没有任何限制，此时waitpid和wait的作用一模一样。 pid=0时，等待同一个进程组中的任何子进程，如果子进程已经加入了别的进程组，waitpid不会对它做任何理睬。 pid<-1时，等待一个指定进程组中的任何子进程，这个进程组的ID等于pid的绝对值。 options options提供了一些额外的选项来控制waitpid，目前在Linux中只支持WNOHANG和WUNTRACED两个选项，这是两个常数，可以用\"|\"运算符把它们连接起来使用，比如： ret=waitpid(-1,NULL,WNOHANG | WUNTRACED); 如果我们不想使用它们，也可以把options设为0，如： ret=waitpid(-1,NULL,0); 如果使用了WNOHANG(wait no hung)参数调用waitpid，即使没有子进程退出，它也会立即返回，不会像wait那样永远等下去。 而WUNTRACED参数，由于涉及到一些跟踪调试方面的知识，加之极少用到，这里就不多费笔墨了，有兴趣的读者可以自行查阅相关材料。 wait不就是经过包装的waitpid吗？没错，察看<内核源码目录>/include/unistd.h文件349-352行就会发现以下程序段： static inline pid_t wait(int * wait_stat) { return waitpid(-1,wait_stat,0); } 1.9.2 返回值和错误 waitpid的返回值比wait稍微复杂一些，一共有3种情况： 当正常返回的时候，waitpid返回收集到的子进程的进程ID； 如果设置了选项WNOHANG，而调用中waitpid发现没有已退出的子进程可收集，则返回0； 如果调用中出错，则返回-1，这时errno会被设置成相应的值以指示错误所在； 当pid所指示的子进程不存在，或此进程存在，但不是调用进程的子进程，waitpid就会出错返回，这时errno被设置为ECHILD； #include <sys/types.h> #include <sys/wait.h> #include <unistd.h> main() {     pid_t pc, pr;     pc=fork();     if(pc<0)      printf(\"Error occured on forking.\\n\");     else if(pc==0)     {      sleep(4);     exit(0);     }     do     {     pr=waitpid(pc, NULL, WNOHANG);      if(pr==0)      {         printf(\"No child exited\\n\");       sleep(1);      }     }while(pr==0);        if(pr==pc)      printf(\"successfully release child %d\\n\", pr);     else      printf(\"some error occured\\n\"); } 编译并运行： $ cc waitpid.c -o waitpid $ ./waitpid No child exited No child exited No child exited No child exited successfully release child 1526 父进程经过4次失败的尝试之后，终于收集到了退出的子进程。 因为这只是一个例子程序，不便写得太复杂，所以我们就让父进程和子进程分别睡眠了4秒钟和1秒钟，代表它们分别作了4秒钟和1秒钟的工作。父子进程都有工作要做，父进程利用工作的简短间歇察看子进程的是否退出，如退出就收集它.这样的话,既不影响父进程的工作,也可以消除僵尸进程. 最后 不管是 wait 还是waitpid函数都有个参数来反映子进程的结束状态,底下有几个宏可判别结束情况,参数当然是指针指向的那个： WIFEXITED（status）如果子进程正常结束则为非0 值。 WEXITSTATUS（status）取得子进程exit（）返回的结束代码，一般会先用WIFEXITED 来判断是否正常结束才能使用此宏。 WIFSIGNALED（status）如果子进程是因为信号而结束则此宏值为真 WTERMSIG（status）取得子进程因信号而中止的信号代码，一般会先用WIFSIGNALED 来判断后才使用此宏。 WIFSTOPPED（status）如果子进程处于暂停执行情况则此宏值为真。一般只有使用WUNTRACED 时才会有此情况。 WSTOPSIG（status） 取得引发子进程暂停的信号代码，一般会先用WIFSTOPPED 来判断后才使用此宏。 返回值 如果执行成功则返回子进程识别码（PID），如果有错误发生则返回 -1。失败原因存于errno 中。","title":"waitpid()的使用"},{"content":"转自：http://topic.csdn.net/u/20101001/01/2280b2dd-1446-439d-b1f8-cdd9db1fd615.html #include <stdio.h>  #include <stdlib.h>  #include <curses.h>  #include <signal.h>  #include <sys/time.h>  #define NUM 60    struct direct                //用来表示方向的  {      int cx;      int cy;  };  typedef struct node            //链表的结点  {      int cx;      int cy;      struct node *back;      struct node *next;  }node;    void initGame();            //初始化游戏  int setTicker(int);            //设置计时器  void show();                //显示整个画面  void showInformation();        //显示游戏信息（前两行）  void showSnake();            //显示蛇的身体  void getOrder();            //从键盘中获取命令  void over(int i);            //完成游戏结束后的提示信息    void creatLink();                //（带头尾结点）双向链表以及它的操作  void insertNode(int x, int y);     void deleteNode();  void deleteLink();    int ch;                                //输入的命令  int hour, minute, second;            //时分秒  int length, tTime, level;            //（蛇的）长度，计时器，（游戏）等级  struct direct dir, food;            //蛇的前进方向，食物的位置  node *head, *tail;                    //链表的头尾结点    int main()  {      initscr();      initGame();      signal(SIGALRM, show);      getOrder();      endwin();      return 0;  }    void initGame()  {      cbreak();                    //把终端的CBREAK模式打开      noecho();                    //关闭回显      curs_set(0);                //把光标置为不可见      keypad(stdscr, true);        //使用用户终端的键盘上的小键盘      srand(time(0));                //设置随机数种子      //初始化各项数据      hour = minute = second = tTime = 0;      length = 1;      dir.cx = 1;      dir.cy = 0;      ch = 'A';      food.cx = rand() % COLS;      food.cy = rand() % (LINES-2) + 2;      creatLink();      setTicker(20);  }    //设置计时器（这个函数是书本上的例子，有改动）  int setTicker(int n_msecs)  {      struct itimerval new_timeset;      long    n_sec, n_usecs;        n_sec = n_msecs / 1000 ;      n_usecs = ( n_msecs % 1000 ) * 1000L ;      new_timeset.it_interval.tv_sec  = n_sec;              new_timeset.it_interval.tv_usec = n_usecs;            n_msecs = 1;      n_sec = n_msecs / 1000 ;      n_usecs = ( n_msecs % 1000 ) * 1000L ;      new_timeset.it_value.tv_sec     = n_sec  ;            new_timeset.it_value.tv_usec    = n_usecs ;           return setitimer(ITIMER_REAL, &new_timeset, NULL);  }    void showInformation()  {      tTime++;      if(tTime >= 1000000)                //          tTime = 0;      if(1 != tTime % 50)          return;      move(0, 3);         //显示时间      printw(\"time: %d:%d:%d %c\", hour, minute, second);      second++;      if(second > NUM)      {          second = 0;          minute++;      }      if(minute > NUM)      {          minute = 0;          hour++;      }      //显示长度，等级      move(1, 0);      int i;      for(i=0;i<COLS;i++)          addstr(\"-\");      move(0, COLS/2-5);      printw(\"length: %d\", length);      move(0, COLS-10);      level = length / 3 + 1;      printw(\"level: %d\", level);  }    //蛇的表示是用一个带头尾结点的双向链表来表示的，  //蛇的每一次前进，都是在链表的头部增加一个节点，在尾部删除一个节点  //如果蛇吃了一个食物，那就不用删除节点了  void showSnake()  {      if(1 != tTime % (30-level))          return;      //判断蛇的长度有没有改变      bool lenChange = false;      //显示食物      move(food.cy, food.cx);      printw(\"@\");      //如果蛇碰到墙，则游戏结束      if((COLS-1==head->next->cx && 1==dir.cx)          || (0==head->next->cx && -1==dir.cx)          || (LINES-1==head->next->cy && 1==dir.cy)          || (2==head->next->cy && -1==dir.cy))      {          over(1);          return;      }      //如果蛇头砬到自己的身体，则游戏结束      if('*' == mvinch(head->next->cy+dir.cy, head->next->cx+dir.cx) )      {          over(2);          return;      }      insertNode(head->next->cx+dir.cx, head->next->cy+dir.cy);      //蛇吃了一个“食物”      if(head->next->cx==food.cx && head->next->cy==food.cy)      {          lenChange = true;          length++;          //恭喜你，通关了          if(length >= 50)          {              over(3);              return;          }          //重新设置食物的位置          food.cx = rand() % COLS;          food.cy = rand() % (LINES-2) + 2;      }      if(!lenChange)      {          move(tail->back->cy, tail->back->cx);          printw(\" \");          deleteNode();      }      move(head->next->cy, head->next->cx);      printw(\"*\");  }    void show()  {      signal(SIGALRM, show);        //设置中断信号      showInformation();      showSnake();      refresh();                    //刷新真实屏幕  }    void getOrder()  {      //建立一个死循环，来读取来自键盘的命令      while(1)      {          ch = getch();          if(KEY_LEFT == ch)          {              dir.cx = -1;              dir.cy = 0;          }          else if(KEY_UP == ch)          {              dir.cx = 0;              dir.cy = -1;          }          else if(KEY_RIGHT == ch)          {              dir.cx = 1;              dir.cy = 0;          }          else if(KEY_DOWN == ch)          {              dir.cx = 0;              dir.cy = 1;          }          setTicker(20);      }  }    void over(int i)  {      //显示结束原因      move(0, 0);      int j;      for(j=0;j<COLS;j++)          addstr(\" \");      move(0, 2);      if(1 == i)          addstr(\"Crash the wall. Game over\");      else if(2 == i)          addstr(\"Crash itself. Game over\");      else if(3 == i)          addstr(\"Mission Complete\");      setTicker(0);                //关闭计时器      deleteLink();                //释放链表的空间  }    //创建一个双向链表  void creatLink()  {      node *temp = (node *)malloc( sizeof(node) );      head = (node *)malloc( sizeof(node) );      tail = (node *)malloc( sizeof(node) );      temp->cx = 5;      temp->cy = 10;      head->back = tail->next = NULL;      head->next = temp;      temp->next = tail;      tail->back = temp;      temp->back = head;  }    //在链表的头部（非头结点）插入一个结点  void insertNode(int x, int y)  {      node *temp = (node *)malloc( sizeof(node) );      temp->cx = x;      temp->cy = y;      temp->next = head->next;      head->next = temp;      temp->back = head;      temp->next->back = temp;  }    //删除链表的（非尾结点的）最后一个结点  void deleteNode()  {      node *temp = tail->back;      node *bTemp = temp->back;      bTemp->next = tail;      tail->back = bTemp;      temp->next = temp->back = NULL;      free(temp);      temp = NULL;  }    //删除整个链表  void deleteLink()  {      while(head->next != tail)          deleteNode();      head->next = tail->back = NULL;      free(head);      free(tail);  }  xiongyao@xiongyao-Lenovo:~$ gedit snake.c xiongyao@xiongyao-Lenovo:~$ gcc snake.c -lcurses -o snake   xiongyao@xiongyao-Lenovo:~$ ./snake","title":"Linux环境下C语言实现贪吃蛇游戏"},{"content":"Linux驱动程序工作原理简介 一、linux驱动程序的数据结构     二、设备节点如何产生？     三、应用程序是如何访问设备驱动程序的？     四、为什么要有设备文件系统？     五、设备文件系统如何实现？     六、如何使用设备文件系统？     七、具体设备驱动程序分析     1、    驱动程序初始化时，要注册设备节点，创建子设备文件     2、    驱动程序卸载时要注销设备节点，删除设备文件     参考书目     一、linux驱动程序的数据结构 设备驱动程序实质上是提供一组供应用程序操作设备的接口函数。 各种设备由于功能不同，驱动程序提高的函数接口也不相同，但linux为了能够统一管理，规定了linux下设备驱动程序必须使用统一的接口函数file_operations 。 所以，一种设备的驱动程序主要内容就是提高这样的一组file_operations接口函数。 那么，linux是如何管理种类繁多的设备驱动程序呢？ linux下设备大体分为块设备和字符设备两类。 内核中用2个全局数组存放这2类驱动程序。 #define MAX_CHRDEV    255 #define MAX_BLKDEV     255 struct device_struct {     const char * name;     struct file_operations * fops; }; static struct device_structchrdevs[MAX_CHRDEV]; static struct {     const char *name;     struct block_device_operations*bdops; } blkdevs[MAX_BLKDEV]; //此处说明一下，struct block_device_operations是块设备驱动程序内部的接口函数，上层文件系统还是通过struct file_operations访问的。 哈哈，现在明白了吧？你的驱动程序调用int register_chrdev(unsigned int major, const char* name, struct file_operations *fops) 就是将你提供的接口函数fops存放到chrdevs[MAX_CHRDEV]这个数组中，数组下标就是你的驱动的主设备号，数组内容包括驱动名称和驱动接口函数，这样，内核就能看到你的驱动程序了。BTW，如果你将major设为0，系统会自动给你分配一个空闲的主设备号。 那么？次设备号呢？别急，马上就出现了：） 二、设备节点如何产生？    驱动程序运行在内核空间，应用程序访问驱动程序通常是通过系统调用文件系统接口函数的，也就是说，在linux下，和磁盘文件一样，设备也是文件，只是他们的文件属性不同而已，应用程序只能通过文件名来访问设备的驱动程序。 所以，文件系统中必须要有一个代表你的设备的文件，应用程序才能访问你的设备驱动程序。    为了便于理解，我们可以将设备文件换个名字，叫做设备节点。    设备节点在哪里？设备节点存在于你的文件系统中，通常在/dev目录下，当然，你也可以在其它地方创建。一般说来，我们在制作文件系统映像时就已经将可能用到的设备节点都创建好了。    你可以打开/dev目录看一下，它下面的设备节点的数量会让你吃惊的：）    如何创建设备节点？。 你可以用mknod命令。如使用以下命令可以创建一个mtd4的字符设备节点。 Mknod /dev/ mtd4 cMTD_CHAR_MAJOR 4 我们创建一个普通的磁盘文件，它的内容是我们写入的数据。 那么设备节点的内容是什么？设备节点文件没有数据，它的文件大小为0，它只有文件属性，包括设备类型、主设备号、次设备号。 没有别的了？对，就这些，没别的了。 那设备节点和设备驱动程序是怎么联系起来的啊？ 别着急，休息，休息一会儿：）   三、应用程序是如何访问设备驱动程序的？ 举个例子：我们要向nor flash的第四个分区的起始位置偏移512字节写入100字节的数据。 我们是如何做的？主要程序片断如下：     fd = open(“/dev/mtd4”,O_RDWR);     lseek (fd,512, SEEK_SET);     write (fd , write_buffer, 100);     close(fd); 上面的代码比较简单，但是似乎没有看到我们的应用程序是如何调用到驱动程序的。 没关系，接下来我将带领你们走通这条道路。 应用程序调用Open函数，这是个系统调用函数，程序会进入内核空间调用sys_open函数。 在sys_open，首先会根据文件路径“/dev/mtd4”找到这个文件节点，这部分工作是属于VFS（虚拟文件系统）的。 “/dev/mtd4”的文件属性是字符设备，于是sys_open会调用函数chrdev_open()，在这个函数里有一句话： filp->f_op =get_chrfops(MAJOR(inode->i_rdev), MINOR(inode->i_rdev)); 哈！看到了眉目吧！猜也能猜到啊，get_chrfops()里面一定会返回chrdevs[major].fops的。 我们终于从文件系统走到驱动程序了，那么，接下来的事情就是可以理解的了。 Write()最终一定会调用到chrdevs[major].fops->write()； Read()最终一定会调用到chrdevs[major].fops->read()； 各种驱动程序比较特殊的功能函数都可以通过ioctl()来得到调用。 而次设备号也会作为参数传递给你。   四、为什么要有设备文件系统？ 从前面的章节，我们可以看到以主次设备号的形式管理设备驱动程序存在很大的缺点。 首先，设备节点的创建是独立于内核的，是在建立文件系统时就把所有要用到的设备节点都创建好了的，通常我们不会去刻意删除哪些节点，因为我们不知道系统将来会不会用到它们。由于每个设备节点代表唯一的主次设备号，所以每个可能存在的子设备都对应一个设备节点，可见，这样的设备节点数量是很大的，这些数量庞大的设备节点都（文件）存在于存储介质中，对文件系统的效率也是个影响。 其次，文件系统中存在哪些设备节点，并不代表内核中就有这种设备的驱动程序，也不代表系统中有这种设备，因为设备节点不是动态创建的，它是制作文件系统时建立的。因此，/dev目录下的信息大多对我们是无用的，而且那么多的设备节点都平铺在/dev目录下，阅读起来也不直观。 最后，目前主次设备号都是用8位整数表示的，也就是说内核最多管理256种字符设备和256种块设备。现在计算机外设种类越来越多，这样的限制已经不够了。 由于目前的主次设备号的管理形式有以上几个缺点，linux内核小组在2.4版本以后加入了设备文件系统来改进这些缺点。 设备文件系统的思想就是想让设备节点可以动态创建、删除，这样系统中有哪些设备驱动程序就可以一目了然；还要能够把设备节点组织成一棵目录树，方便阅读；最后，希望能够扩大主次设备号的限制，不再限制在256种设备以内。 五、设备文件系统如何实现？    要想在内核中方便的做到动态创建、删除设备文件（在这里，我们把设备节点称为设备文件会更恰当些），最自然的做法就是在RAM中创建一个文件系统，内核启动时这个文件系统是空的，以后每加载一种设备驱动程序，就在这个文件系统中创建一个对应的设备文件；卸载设备驱动程序时，再删除这个设备文件。而且，我们可以在这个文件系统中创建目录，一类设备文件放在同一个目录中，甚至把一种设备的多个子设备文件放在同一个目录下，方便阅读。    在设备文件系统中，我们在注册设备文件时可以把设备驱动程序的ops直接挂到设备文件的inode中，以后访问驱动程序就可以摆脱主次设备号的限制了，不需要再访问chrdev[]数组，这样就突破了256种设备的限制。    我们把设备文件系统mount到/dev目录下，这样，看起来跟以前的方案就很相似了，也方便老的应用程序的移植。   六、如何使用设备文件系统？    以前我们写驱动程序时要调用int register_chrdev(unsigned int major, const char* name, struct file_operations *fops)将你提供的接口函数fops存放到chrdevs[MAX_CHRDEV]这个数组中，然后在文件系统中用mknod创建有相同主设备号的设备节点就可以了。    那么现在有了设备文件系统，我们的驱动程序该如何写呢？    很简单，follow me! 1、调用devfs_handle_t devfs_mk_dir (devfs_handle_t dir,const char *name, void *info)创建设备文件所在的目录。Dir是要创建目录的父目录句柄，如为NULL，就是设备文件系统的根目录（/dev）；最后一个参数info通常为NULL。 2、调用devfs_handle_t devfs_register (devfs_handle_t dir,const char *name,                   unsigned int flags,                    unsignedint major, unsigned int minor,                    umode_tmode, void *ops, void *info) 注册具体的设备，并在指定目录下创建子设备节点。 这里的dir目录名是要创建的设备文件所在的目录名，目录名一般不能为NULL，因为子设备文件名name通常是以0、1、2、3等数字命名的，会和其它设备文件冲突。    3、卸载驱动程序时调用void devfs_unregister (devfs_handle_tde)删除创建的目录和子设备文件。 七、具体设备驱动程序分析    这节以mtdchar设备驱动程序来具体分析驱动程序的写法。    Mtdchar字符设备是管理flash驱动程序的，是各种flash驱动程序的抽象层。    Mtdchar的主程序是driver/mtd/mtdchar.c； 1、    驱动程序初始化时，要注册设备节点，创建子设备文件 驱动程序为了兼容以前的方案，通常会既注册设备节点，又创建子设备文件，这样不管内核支持不支持设备文件系统，驱动程序都可以工作。 static int __initinit_mtdchar(void) {     //为了兼容以前的方案，要注册mtdchar的主设备号、设备名以及fops     if(register_chrdev(MTD_CHAR_MAJOR, \"mtd\",&mtd_fops)) {          printk(KERN_NOTICE \"Can't allocate major number%d for Memory Technology Devices.\\n\",              MTD_CHAR_MAJOR);          return -EAGAIN;     }     //如果内核支持设备文件系统，在这个函数里会创建子设备文件。    mtdchar_devfs_init();     return 0; } static inline voidmtdchar_devfs_init(void) {     //创建设备节点的父目录，/dev/mtd/     devfs_dir_handle =devfs_mk_dir(NULL, \"mtd\", NULL);     //在这个函数里会调用devfs_register()创建子设备    register_mtd_user(¬ifier); } notifier定义如下，主要是提高创建和删除子设备文件的接口函数 static structmtd_notifier notifier = {     .add     = mtd_notify_add,              //创建一个子设备     .remove     = mtd_notify_remove,    //删除一个子设备 }; static void mtd_notify_add(structmtd_info* mtd) {     char name[8];     if (!mtd)          return;     // mtd是一个子设备，代表flash上的一个逻辑分区     sprintf(name, \"%d\",mtd->index);     //这里调用devfs_register创建子设备文件，如/dev/mtd/0    devfs_rw_handle[mtd->index] =devfs_register(devfs_dir_handle, name,               DEVFS_FL_DEFAULT, MTD_CHAR_MAJOR,mtd->index*2,               S_IFCHR | S_IRUGO | S_IWUGO,               &mtd_fops, NULL);     //下面注册的是只读子设备，无关紧要。     sprintf(name, \"%dro\",mtd->index);     //创建只读子设备，如    /dev/mtd/0ro    devfs_ro_handle[mtd->index] =devfs_register(devfs_dir_handle, name,               DEVFS_FL_DEFAULT, MTD_CHAR_MAJOR,mtd->index*2+1,               S_IFCHR | S_IRUGO,               &mtd_fops, NULL); } static void mtd_notify_remove(structmtd_info* mtd) {     if (!mtd)          return;     //删除mtdchar子设备文件和mtdchar子设备文件    devfs_unregister(devfs_rw_handle[mtd->index]);     devfs_unregister(devfs_ro_handle[mtd->index]); } mtd驱动程序中会将一片flash划分为多个逻辑分区，这样的每个逻辑分区也可以被看做是一个子设备，具体flash驱动程序添加逻辑分区时会在数组mtd_table[]中记录分区的位置和大小。 voidregister_mtd_user (struct mtd_notifier *new) {     int i;     down(&mtd_table_mutex);     list_add(&new->list,&mtd_notifiers);     __module_get(THIS_MODULE);          // mtd_table[]是个全局数组，每个元素都是一个逻辑分区，记录着分区的起始位置和大小，我们将每个逻辑分区创建为一个单独的mtd子设备文件     for (i=0; i<MAX_MTD_DEVICES; i++)          if (mtd_table)              new->add(mtd_table);     up(&mtd_table_mutex); } 2、    驱动程序卸载时要注销设备节点，删除设备文件 static void __exitcleanup_mtdchar(void) {     mtdchar_devfs_exit();     //注销chrdevs[major]    unregister_chrdev(MTD_CHAR_MAJOR,\"mtd\"); } static inline voidmtdchar_devfs_exit(void) {     //在这个函数里会调用devfs_unregister()删除子设备    unregister_mtd_user(¬ifier);     //删除父目录    devfs_unregister(devfs_dir_handle); } int unregister_mtd_user (structmtd_notifier *old) {     int i;     down(&mtd_table_mutex);     module_put(THIS_MODULE);     for (i=0; i< MAX_MTD_DEVICES;i++)          if (mtd_table)               old->remove(mtd_table);                    list_del(&old->list);     up(&mtd_table_mutex);     return 0; }","title":"Linux驱动程序工作原理简介"},{"content":"学习linux，必会命令行；学习命令，必会shell；shell是什么？解开它的面纱，看它的庐山真面目 1. Scripting languange shell首先是一种支持编写脚本的程序设计语言，那脚本又什么？脚本是软件环境中可以使任务自动化执行的文件，这些任务也可以人为选择执行，主要的软件环境包括应用程序、浏览器中的网页，操作系统的外壳等等。office中网址和邮箱的自动连接，shell脚本的任务是进程控制，控制系统程序的行为。其他的脚本语言还有javascript、python、Ruby等 不同的脚本语言适用于不同的软件环境。如javascript广泛应用于网页中，shell主要应用于系统进程管理中。 2. interface software shell的本意是壳，操作系统的壳，在内核与用户之间，完成用户与内核之间的交互。shell包括命令行shell和图像界面shell，linux和UNIX中的未命令行shell，window中是图像界面shell。linux shell 将用户的命令解释后发给内核，内核完成相应的操作。用户在操作系统上完成的所有任务都是通过shell与内核交互实现。如shutdown命令是由shell编写的程序，命令解释shell解释shutdown命令，然后提交给内核处理，告诉内核完成关机操作，关机任务具体由内核实现。 为了加快命令的执行，同时更有效的制定shell程序，shell中定义了一些内置的命令，如cd 、exit。这些内置命令在用户登录系统后，就被载入内存，并一直运行，直到用户退出系统。除了shell的内置命令，linux系统上还有很多可执行文件，类似window中的.exe文件，例如ls命令就是一个可执行文件，存放在/bin/ls中。这些命令和内置命令不同，只有在被调用时，才由系统装入内存执行。  ","title":"what is shell"},{"content":"你的linux没有在红帽网络上注册，所以无法下载上面的软件包，替代方案可以使用centos 1.卸载rhel的默认安装的yum包 查看yum包 rpm -qa|grep yum 卸载之 rpm -qa|grep yum|xargs rpm -e –-nodeps 2.下载新的yum包 wget http://centos.ustc.edu.cn/centos/5/os/i386/CentOS/yum-3.2.22-26.el5.centos.noarch.rpm wget http://centos.ustc.edu.cn/centos/5/os/i386/CentOS/yum-fastestmirror-1.1.16-14.el5.centos.1.noarch.rpm wget http://centos.ustc.edu.cn/centos/5/os/i386/CentOS/yum-metadata-parser-1.1.2-3.el5.centos.i386.rpm 并且安装之 rpm -ivh yum-* 注意：yum和yum-fastestmirror相互依赖，所以同时安装即可。 3.下载yum的配置源 wget http://docs.linuxtone.org/soft/lemp/CentOS-Base.repo 下载到 /etc/yum.repos.d/ 目录下面 4.运行yum makecache生成缓存","title":"ReInstall yum in rht"},{"content":"KBuild MakeFile介绍 从Linux内核2.6开始，Linux内核的编译采用Kbuild系统，这同过去的编译系统有很大的不同，尤其对于Linux内核模块的编译。在新的系统下，Linux编译系统会两次扫描Linux的Makefile：首先编译系统会读取Linux内核顶层的Makefile，然后根据读到的内容第二次读取Kbuild的Makefile来编译Linux内核。 Linux内核Makefile分类 · Kernel Makefile Kernel Makefile位于Linux内核源代码的顶层目录，也叫 Top Makefile。它主要用于指定编译Linux Kernel目标文件（vmlinux）和模块（module）。这编译内核或模块是，这个文件会被首先读取，并根据读到的内容配置编译环境变量。对于内核或驱动开发人员来说，这个文件几乎不用任何修改。 · Kbuild Makefile Kbuild系统使用Kbuild Makefile来编译内核或模块。当Kernel Makefile被解析完成后，Kbuild会读取相关的Kbuild Makefile进行内核或模块的编译。Kbuild Makefile有特定的语法指定哪些编译进内核中、哪些编译为模块、及对应的源文件是什么等。内核及驱动开发人员需要编写这个Kbuild Makefile文件。 · ARCH Makefile ARCH Makefile位于ARCH/$(ARCH)/Makefile，是系统对应平台的Makefile。Kernel Top Makefile会包含这个文件来指定平台相关信息。只有平台开发人员会关心这个文件。 Kbuild Makefile Kbuild Makefile的文件名不一定是Makefile，尽管推荐使用Makefile这个名字。大多的Kbuild文件的名字都是Makefile。为了与其他Makefile文件相区别，你也可以指定Kbuild Makefile的名字为Kbuild。而且如果“Makefile”和“Kbuild”文件同时存在，则Kbuild系统会使用“Kbuild”文件。 · 目标定义 Kbuild Makefile的一个最主要功能就是指定编译什么，这个功能是通过下面两个对象指定的obj-?和xxx-objs： · obj-? obj-?指定编译什么，怎么编译？其中的“?”可能是“y”或“m”，“y”指定把对象编译进内核中，“m”指定把对象编译为模块。语法如下; obj-? = $(target).o target为编译对象的名字。如果没有指定xxx-objs，这编译这个对象需要的源文件就是$(target).c或$(target).s。如果指定了$(target)-objs，则编译这个对象需要的源文件由$(target)-objs指定，并且不能有$(target).c或$(target).s文件。 · xxx-objs xxx-objs指定了编译对象需要的文件，一般只有在源文件是多个时才需要它。 只要包含了这两行，Kbuild Makefile就应该可以工作了。 · 嵌套编译 有时一个对象可能嵌入到另一个对象的目录下，那么如何编译子目录下的对象呢?其实很简单，只要指定obj_?的对象为子目录的名字就可以了： obj-? = $(sub_target)/ 其中“?”可以是“y”或“m”，$(sub_target)是子目录名字。 · 编译器选项 尽管在大多数情况下不需要指定编译器选项，有时我们还是需要指定一些编译选项的。 · ccflags-y, asflags-y and ldflags-y 这些编译选项用于指定cc、as和ld的编译选项 编译外部模块 有时候我们需要在内核源代码数的外面编译内核模块，编译的基本命令是： make -C $(KERNEL_DIR) M=`pwd` modules 我们可以把这个命令集成到Makefile里，这样我们只输入“make”命令就可以了。 ##Makefile ifneq ($(KERNELRELEASE),) include \"Kbuild\" else KERNEL_DIR = /lib/modules/`uname -r`/build MODULEDIR := $(shell pwd) .PHONY: modules default: modules modules: make -C $(KERNEL_DIR) M=$(MODULEDIR) modules clean distclean: rm -f *.o *.mod.c .*.*.cmd *.ko rm -rf .tmp_versions endif ## Kbuild MODULE_NAME = helloworld $(MODULE_NAME)-objs := hello.o obj-m := $(MODULE_NAME).o 一般不需要在Makefile里包含如下代码,这样写完全是为了兼容老版本的Kbuild系统。KERNELRELEASE变量在Kernel Makefile里定义的，因此只有在第二次由Kbuild读取这个Makefile文件时才会解析到Kbuild的内容。 ifneq ($(KERNELRELEASE),) include \"Kbuild\" else ... endif 外部头文件 有时需要连接内核源代码外部的系统头文件，但Kbuild系统默认的系统头文件都在内核源代码内部，如何使用外部的头文件呢？这个可以借助于Kbuild系统的特殊规则: · EXTRA_CFLAGS EXTRA_CFLAGS可以给Kbuild系统添加外部系统头文件， EXTRA_CFLAGS += $(ext_include_path) 一般外部头文件可能位于外部模块源文件的目录内，如何指定呢？这可以借助$(src)或$(obj) · $(src)/$(obj) $(src)是一个相对路径，它就是Makefile/Kbuild文件所在的路径。同样$(obj)就是编译目标保存的路径，默认就是源代码所在路径。 因此，我们修改Kbuild文件添加 EXTRA_CFLAGS 来包含外部头文件，尽管在这个驱动里没有引用外部系统头文件： ## Kbuild MODULE_NAME = helloworld $(MODULE_NAME)-objs := hello.o EXTRA_CFLAGS := -I$(src)/include obj-m := $(MODULE_NAME).o Goal definitions Example: obj-y += foo.o 告诉kbuild，在文件夹中有一个叫做foo.o的object。foo.o将会被从foo.c或者foo.S被构建。 如果foo.o被构建成一个模块，则将使用变量obj-m。Example: obj-$(CONFIG_FOO) += foo.o $(CONFIG_FOO)要么是y(built-in)，要么是m(module)。如果CONFIG_FOO既不是y也不是m，那么文件将不会被编译也不会被连接。 · Built-in object goals - obj-y kbuild Makefiles在$(obj-y)列表中为vmlinux指明object文件。这个列表依靠内核的配置。 在$(obj-y)中的文件的顺序是非常重要的。列表中允许两个相同的文件：第一个实体将被连接到built-in.o，后面的实体将会被忽略。 连接的顺序也很重要，因为在boot过程中某些函数(module_init()/_initcall)将会按顺序出现。因此，如果改变了连接顺序，将会改变你的SCSI控制器的检测顺序，你的磁盘也同时被重新编号了。 Example: #drivers/isdn/i4l/Makefile # Makefile for the kernel ISDN subsystem and device drivers. # Each configuration option enables a list of files. obj-$(CONFIG_ISDN) += isdn.o obj-$(CONFIG_ISDN_PPP_BSDCOMP) += isdn_bsdcomp.o · Loadable module goals - obj-m $(obj-m)指明object文件作为可装载的内核模块被构建。一个模块可能从一个或者多个源文件被构建。kbuild Makefile只是简单的将源文件加到%(obj-m) Example: #drivers/isdn/i4l/Makefile obj-$(CONFIG_ISDN_PPP_BSDCOMP) += isdn_bsdcomp.o 注意这里$(CONFIG_ISDN_PPP_BSDCOMP)是m. Note: In this example $(CONFIG_ISDN_PPP_BSDCOMP) evaluates to 'm'。 如果一个内核模块从多个源文件构建，KBuild就必须要知道你想从哪些部分构建模块。因此，你不得不设置$(<module_name>-objs)变量来告诉KBuild。 Example: #drivers/isdn/i4l/Makefile obj-$(CONFIG_ISDN) += isdn.o isdn-objs := isdn_net_lib.o isdn_v110.o isdn_common.o 在这个例子中，模块名是isdn.o,Kbuild将会编译列在$(isdn-objs)的object文件，然后在这些文件的列表中调用\"$(LD) -r\"来产生isdn.o。 Kbuild使用后缀-objs,-y来识别混合的object文件。这允许Makefiles使用变量CONFIG_sambol来决定一个object是否是混合object的的一部分。 Example: #fs/ext2/Makefile obj-$(CONFIG_EXT2_FS) += ext2.o ext2-y := balloc.o bitmap.o ext2-$(CONFIG_EXT2_FS_XATTR) += xattr.o 在这个例子中，如果$(CONFIG_EXT2_FS_XATTR)是y，则xattr.o只是混合object文件ext2.o的一部分。 注意，当你构造一个objects到内核中时，上面的语法当然也能够工作。因此，如果你让CONFIG_EXT2=Y,KBuild将会为你构建一个独立的ext2.o文件，并且连接到built-in.o。 · Library file goals - lib-y 用obj-*连接的Objects在指明的文件夹中被用作模块或者综合进built-in.o。也又可能被列出的objects将会被包含进一个库,lib.a。所有用lib-y列出的objects在那个文件夹中被综合进单独的一个库。列在obj-y和附加列在lib-y中的Objects将不会被包含在库中，因为他们将会被任意的存取。对于被连接在lib-m中，连续的objects将会被包含在lib.a中。值得注意的是kbuild makefile可能列出文件用作built-in，并且作为库的一部分。因此，同一个文件夹可能包含一个built-in.o和lib.a文件。 Example: #arch/i386/lib/Makefile lib-y := checksum.o delay.o 这里将会创建一个基于checksum.o和delay.o的库文件。对于kbuild，识别一个lib.a正在被构建，这个文件夹应该被列在libs-y中。lib-y的使用方法通常被限制在lib/和arc/*/lib中。 · Descending down in directories 一个Makefile只负责在他自己的文件夹中构建objects。 在子文件夹中的文件应该由子文件夹中的Makefiles来照顾。如果你知道他们，build系统将会自动递归地用在子文件夹中的make。 在这种情况下obj-y和obj-m就被使用了。ext2存在于不同的文件夹中，Makefile出现在fs/，则告诉kbuild从后面的参数下来。 Example: #fs/Makefile obj-$(CONFIG_EXT2_FS) += ext2/ 如果CONFIG_EXT2_FS被设置成y(built-in)或者m(modular)，相应的obj-变量将会被设置，并且kbuild将会从ext2文件夹继承下来。Kbuild只会使用这些信息来决定它需要访问这些文件夹，而在子文件夹中的Makefile来指明哪些是modules哪些是built-in。 当赋值文件夹名字的时候，使用CONFIG_variable是很好的选择。这允许kbuild完全的跳过文件夹，而不管CONFIG_option是否是y或者m。 · Compilation flags EXTRA_CFLAGS, EXTRA_AFLAGS, EXTRA_LDFLAGS, EXTRA_ARFLAGS。 所有的EXTRA_ variables只应用在kbuild中，他们被赋值的地方。EXTRA_variables应用在kbuild makefile中所有的可执行的命令。$(EXTRA_CFLAGS) 指明用$(CC)编译C文件的时候的选项。 Example: # drivers/sound/emu10k1/Makefile EXTRA_CFLAGS += -I$(obj) ifdef DEBUG EXTRA_CFLAGS += -DEMU10K1_DEBUG endif 这里的变量是必须的，因为顶层的Makefile拥有变量$(CFLAGS)并且用它来作为整个树的编译标志当编译汇编源文件的时候$(EXTRA_AFLAGS)，和每个文件夹的选项是相似的。 Example: #arch/x86_64/kernel/Makefile EXTRA_AFLAGS := -traditional $(EXTRA_LDFLAGS)和$(EXTRA_ARFLAGS) 对于每个文件夹的$(LD)和$(AR)选项是类似的。 Example: #arch/m68k/fpsp040/Makefile EXTRA_LDFLAGS := -x CFLAGS_$@, AFLAGS_$@ CFLAGS_$@和AFLAGS_$@只应用到当前kbuild makefile的命令。 $(CFLAGS_$@) 为每个文件的$(CC)指明选项。$@ 部分有一个字面上的值，指明它是为那个文件。 Example: # drivers/scsi/Makefile CFLAGS_aha152x.o = -DAHA152X_STAT -DAUTOCONF CFLAGS_gdth.o = # -DDEBUG_GDTH=2 -D__SERIAL__ -D__COM2__ \\ -DGDTH_STATISTICS CFLAGS_seagate.o = -DARBITRATE -DPARITY -DSEAGATE_USE_ASM These three lines specify compilation flags for aha152x.o, gdth.o, and seagate.o $(AFLAGS_$@) is a similar feature for source files in assembly languages. Example: # arch/arm/kernel/Makefile AFLAGS_head-armv.o := -DTEXTADDR=$(TEXTADDR) -traditional AFLAGS_head-armo.o := -DTEXTADDR=$(TEXTADDR) -traditional","title":"Kbuild Makefile介绍"},{"content":"struct sk_buff可能是linux网络代码中最重要的数据结构，它表示接收或发送数据包的包头信息，并包含很多成员变量供网络代码中的各子系统使用。  这个结构被网络的不同层(MAC或者其他二层链路协议，三层的IP，四层的TCP或UDP等)使用，并且其中的成员变量在结构从一层向另一层传递时改变。 L4向L3传递前会添加一个L4的头部，同样，L3向L2传递前，会添加一个L3的头部。添加头部比在不同层之间拷贝数据的效率更高。由于在缓冲区的头部 添加数据意味着要修改指向缓冲区的指针，这是个复杂的操作，所以内核提供了一个函数skb_reserve来完成这个功能。协议栈中的每一层在往下一层传 递缓冲区前，第一件事就是调用skb_reserve在缓冲区的头部给协议头预留一定的空间。     skb_reserve同样被设备驱动使用来对齐接收到包的包头。如果缓冲区向上层协议传递，旧的协议层的头部信息就没什么用了。例如，L2的头部只有在 网络驱动处理L2的协议时有用，L3是不会关心它的信息的。但是，内核并没有把L2的头部从缓冲区中删除，而是把有效荷载的指针指向L3的头部，这样做， 可以节省CPU时间。      有些sk_buff成员变量的作用是方便查找或者是连接数据结构本身。内核可以把sk_buff组织成一个双向链表。当然，这个链表的结构要比常见的双向 链表的结构复杂一点。就像任何一个双向链表一样，sk_buff中有两个指针next和prev，其中，next指向下一个节点，而prev指向上一个节 点。在第一个节点前面会插入另一个结构sk_buff_head，这是一个辅助节点(作为sk_buff双向链表的头)，它的定义如下: struct sk_buff_head {     struct sk_buff -*next;     struct sk_buff -*prev;     __u32           qlen;     spinlock_t      lock; };     qlen代表链表元素的个数     lock用于防止对链表的并发访问     sk_buff和sk_buff_head的前两个元素是一样的：next和prev指针。这使得它们可以放到同一个链表中，尽管 sk_buff_head要比sk_buff小得多。另外，相同的函数可以同样应用于sk_buff和sk_buff_head。 sk_buff->sk     这是一个指向拥有这个sk_buff的sock结构的指针。这个指针在网络包由本机发出或者由本机进程接收时有效，因为插口相关的信息被L4(TCP或 UDP)或者用户空间程序使用。如果sk_buff只在转发中使用(这意味着，源地址和目的地址都不是本机地址)，这个指针是NULL sk_buff->len     表示当前协议数据包的长度。它包括主缓冲区中的数据长度(data指针指向它)和分片中的数据长度。 sk_buff->data_len     和len不同，data_len只计算分片中数据的长度 sk_buff->mac_len     这是mac头的长度 sk_buff->users     这是一个引用计数，用于计算有多少实体引用了这个sk_buff缓冲区。它的主要用途是防止释放sk_buff后，还有其他实体引用这个sk_buff。 因此，每个引用这个缓冲区的实体都必须在适当的时候增加或减小这个变量。这个计数器只保护sk_buff结构本身，而缓冲区的数据部分由类似的计数器 (dataref)来保护.有时可以用atomic_inc和atomic_dec函数来直接增加或减小users，但是，通常还是使用函数 skb_get和kfree_skb来操作这个变量。 sk_buff->truesize     这是缓冲区的总长度，包括sk_buff结构和数据部分。如果申请一个len字节的缓冲区，alloc_skb函数会把它初始化成len+sizeof(sk_buff)。当skb->len变化时，这个变量也会变化。  sk_buff->head sk_buff->data sk_buff->tail sk_buff->end     它们表示缓冲区和数据部分的边界。在每一层申请缓冲区时，它会分配比协议头或协议数据大的空间。head和end指向缓冲区的头部和尾部，而data和 tail指向实际数据的头部和尾部。每一层会在head和data之间填充协议头，或者在tail和end之间添加新的协议数据。数据部分会在尾部包含一 个附加的头部。    void (*destructor)(struct sk_buff *skb)     这个函数指针可以初始化成一个在缓冲区释放时完成某些动作的函数。如果缓冲区不属于一个socket，这个函数指针通常是不会被赋值的。如果缓冲区属于一 个socket，这个函数指针会被赋值为sock_rfree或sock_wfree(分别由skb_set_owner_r或 skb_set_owner_w函数初始化)。这两个sock_xxx函数用于更新socket的队列中的内存容量。 sk_buff->tstamp     这个变量只对接收到的包有意义。它代表包接收时的时间戳，或者有时代表包准备发出时的时间戳。它在netif_rx里面由函数net_timestamp设置，而netif_rx是设备驱动收到一个包后调用的函数。      sk_buff->dev     这个变量的类型是net_device，net_device它代表一个网络设备。dev的作用与这个包是准备发出的包还是刚接收的包有关。当收到一个包 时，设备驱动会把sk_buff的dev指针指向收到这个包的网络设备；当一个包被发送时，这个变量代表将要发送这个包的设备。在发送网络包时设置这个值 的代码要比接收网络包时设置这个值的代码复杂。有些网络功能可以把多个网 络设备组成一个虚拟的网络设备(也就是说，这些设备没有和物理设备直接关联)，并由一个虚拟网络设备驱动管理。当虚拟设备被使用时，dev指针指向虚拟设 备的net_device结构。而虚拟设备驱动会在一组设备中选择一个设备并把dev指针修改为这个设备的net_device结构。因此，在某些情况 下，指向传输设备的指针会在包处理过程中被改变。 sk_buff->input_dev     这是收到包的网络设备的指针。如果包是本地生成的，这个值为NULL。对以太网设备来说，这个值由eth_type_trans初始化,它主要被流量控制代码使用。 sk_buff->h sk_buff->nh sk_buff->mac     这些是指向TCP/IP各层协议头的指针：h指向L4(传输层)，nh指向L3(网络层)，mac指向L2(数据链路层)。每个指针的类型都是一个联合， 包含多个数据结构，每一个数据结构都表示内核在这一层可以解析的协议。例如，h是一个包含内核所能解析的L4协议的数据结构的联合。每一个联合都有一个 raw变量用于初始化，后续的访问都是通过协议相关的变量进行的。     当接收一个包时，处理n层协议头的函数从其下层(n-1层)收到一个缓冲区，它的skb->data指向n层协议的头。处理n层协议的函数把本层的 指针(例如，L3对应的是skb->nh指针)初始化为skb->data，因为这个指针(data指针)的值会在处理下一层协议时改变 (skb->data将被初始化成缓冲区里的其他地址)。在处理n层协议的函数结束时，在把包传递给n+1层的处理函数前，它会把skb-> data指针指向n层协议头的末尾，这正好是n+1层协议的协议头。     当网卡驱动程序收到一个UDP数据报后，它创建一个结构体struct sk_buff，确保sk_buff->data成员指向的空间足够存放收到的数据(对于数据报分片的情况，因为比较复杂，我们暂时忽略，我们假设 一次收到的是一个完整的UDP数据报)。把收到的数据全部拷贝到sk_buff->data指向的空间，然后，把skb->mac.raw指 向data，此时，数据报的开始位置是一个以太网头，所以skb->mac.raw指向链路层的以太网头。然后通过调用skb_pull剥掉以太网 头，所谓剥掉以太网头，只是把data加上sizeof(struct ethhdr)，同时len减去这个值，这样，在逻辑上,skb已经不包含以太网头了，但通过skb->mac.raw还能找到它。这就是我们通常 所说的，IP数据报被收到后，在链路层被剥去以太网头。 sk_buff->dst     这个变量在路由子系统中使用 sk_buff->sp     这个变量被IPSec协议用于跟踪传输的信息 sk_buff->cb[48]     这是一个“control buffer”，或者说是一个私有信息的存储空间，由每一层自己维护并使用。它在分配sk_buff结构时分配(它目前的大小是48字节，已经足够为每一 层存储必要的私有信息了)。在每一层中，访问这个变量的代码通常用宏实现以增强代码的可读性。例如，TCP用这个变量存储tcp_skb_cb结构。     下面这个宏被TCP代码用来访问cb变量。在这个宏里面，有一个简单的类型转换:     #define TCP_SKB_CB(__skb)     ((struct tcp_skb_cb *)&((__skb)->cb[0]))     下面的例子是TCP子系统在收到一个分段时填充相关数据结构的代码: int tcp_v4_rcv(struct sk_buff *skb) {     ...     th = skb->h.th;     TCP_SKB_CB(skb)->seq = ntohl(th->seq);     TCP_SKB_CB(skb)->end_seq = (TCP_SKB_CB(skb)->seq + th->syn + th->fin +                  skb->len - th->doff * 4);     TCP_SKB_CB(skb)->ack_seq = ntohl(th->ack_seq);     TCP_SKB_CB(skb)->when = 0;     TCP_SKB_CB(skb)->flags = skb->nh.iph->tos;     TCP_SKB_CB(skb)->sacked = 0;     ... }     如果想要了解cb中的参数是如何被取出的，可以查看net/ipv4/tcp_output.c中的tcp_transmit_skb函数。这个函数被TCP用于向IP层发送一个分段。 sk_buff->csum sk_buff->ip_summed     表示校验和以及相关状态标记 sk_buff->cloned     一个布尔标记，当被设置时，表示这个结构是另一个sk_buff的克隆 sk_buff->pkt_type     这个变量表示帧的类型，分类是由L2的目的地址来决定的。这个值在网卡驱动程序中由函数eth_type_trans通过判断目的以太网地址来确定。如果 目的地址是FF:FF:FF:FF:FF:FF，则为广播地址，pkt_type = PACKET_BROADCAST；如果最高位为1,则为组播地址，pkt_type = PACKET_MULTICAST；如果目的mac地址跟本机mac地址不相等，则不是发给本机的数据报，pkt_type = PACKET_OTHERHOST；否则就是缺省值PACKET_HOST。 /* Packet types */ #define PACKET_HOST         0       /* To us        */ #define PACKET_BROADCAST    1       /* To all       */ #define PACKET_MULTICAST    2       /* To group     */ #define PACKET_OTHERHOST    3       /* To someone else      */ #define PACKET_OUTGOING     4       /* Outgoing of any type */ sk_buff->priority     这个变量描述发送或转发包的QoS类别。如果包是本地生成的，socket层会设置priority变量。如果包是将要被转发的， rt_tos2priority函数会根据ip头中的Tos域来计算赋给这个变量的值。这个变量的值与DSCP(DiffServ CodePoint)没有任何关系。 sk_buff->protocol     这个变量是高层协议从二层设备的角度所看到的协议。典型的协议包括IP，IPV6和ARP。完整的列表在 include/linux/if_ether.h中。由于每个协议都有自己的协议处理函数来处理接收到的包，因此，这个域被设备驱动用于通知上层调用哪 个协议处理函数。每个网络驱动都调用netif_rx来通知上层网络协议的协议处理函数，因此protocol变量必须在这些协议处理函数调用之前初始 化。","title":"sk_buff结构体"},{"content":"RCS是在SCCS源代码控制系统之后开发的。SCCS是由AT&T在系统V版本的Unix中引入的最初的源代码控制系统，现在它已经是X/Open标准的一部分了。RCS的功能与SCCS非常类似，但是它有着更加直观的接口和一些其他的选项，所以SCCS基本上已经被RCS所取代。 RCS只保存版本之间的不同之处，因此它非常节省存储空间。 RCS对个人的开发项目来说非常容易使用，因此在这里进行介绍。 下面介绍一下RCS的基本用法。 假设我们进行版本控制的文件是important.c，其内容是一个简单的Hello World C程序。 首先需要用rcs命令来初始化该文件的RCS控制： 命令rcs -i的作用是初始化RCS控制文件。 我们可以使用多行注释，在结束输入的时候需要在一行中单独使用一个英文句号或输入文件结束字符（通常是组合键CTRL+D）。 执行完这条语句之后，rcs将创建一个新的只读文件，其后缀是,v。如图所示： 我们开头创建了一个文件夹RCS，就是用来存放RCS文件的。这个系统会自动进行。 接下来用ci命令将源文件的当前版本签入（check in）到RCS中。 这时候发现源文件important.c已经被删除了： 文件内容及其控制信息都已经被保存到RCS文件important.c,v中了。 要对文件进行修改，需要首先签出（check out）该文件。 如果只是想阅读该文件，可以用co命令重建当前版本的该文件并将其权限设置为只读。 如果想对其进行修改，必须使用命令co -l锁定该文件。 现在可以对其进行修改，我们简单的添加一条打印语句： 然后保存，再次用ci命令保存改动。 如果想在签入该文件的时候仍然保留该文件的锁定状态，使得可以继续对该文件进行修改，就需要在调用ci命令的时候加上-l选项，这样在签入该文件的同时它会被自动签出来供同一用户使用。 查看一个文件的改动，使用rlog命令： 输出结果的第一行给出了对该文件的描述以及rcs使用的选项。接着列出了对该文件的修改情况和签入该文件时输入的注释内容，最近修改的在最前面。 如果现在要取出该文件的第一个版本，可以在调用co命令是指定所需要的版本号： ci命令也有一个-r选项，其作用是强制指定版本号。 RCS和SCCS默认都用数字1作为第一个次版本号。 如果只是想了解两个版本之间的区别，使用命令rcsdiff：","title":"【Linux学习】linux源代码版本控制RCS"},{"content":"top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。下面详细介绍它的使用方法。top是一个动态显示过程,即可以通过用户按键来不断刷新当前状态.如果在前台执行该命令,它将独占前台,直到用户终止该程序为止.比较准确的说,top命令提供了实时的对系统处理器的状态监视.它将显示系统中CPU最“敏感”的任务列表.该命令可以按CPU使用.内存使用和执行时间对任务进行排序；而且该命令的很多特性都可以通过交互式命令或者在个人定制文件中进行设定. 1．命令格式： top [参数] 2．命令功能： 显示当前系统正在执行的进程的相关信息，包括进程ID、内存占用率、CPU占用率等 3．命令参数： -b 批处理 -c 显示完整的治命令 -I 忽略失效过程 -s 保密模式 -S 累积模式 -i<时间> 设置间隔时间 -u<用户名> 指定用户名 -p<进程号> 指定进程 -n<次数> 循环显示的次数 4．使用实例： 实例1：显示进程信息 命令： top 输出： [root@TG1704 log]# top top - 14:06:23 up 70 days, 16:44,  2 users,  load average: 1.25, 1.32, 1.35 Tasks: 206 total,   1 running, 205 sleeping,   0 stopped,   0 zombie Cpu(s):  5.9%us,  3.4%sy,  0.0%ni, 90.4%id,  0.0%wa,  0.0%hi,  0.2%si,  0.0%st Mem:  32949016k total, 14411180k used, 18537836k free,   169884k buffers Swap: 32764556k total,        0k used, 32764556k free,  3612636k cached   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                 28894 root      22   0 1501m 405m  10m S 52.2  1.3   2534:16 java                                                                    18249 root      18   0 3201m 1.9g  11m S 35.9  6.0 569:39.41 java                                                                     2808 root      25   0 3333m 1.0g  11m S 24.3  3.1 526:51.85 java                                                                    25668 root      23   0 3180m 704m  11m S 14.0  2.2 360:44.53 java                                                                      574 root      25   0 3168m 611m  10m S 12.6  1.9 556:59.63 java                                                                     1599 root      20   0 3237m 1.9g  11m S 12.3  6.2 262:01.14 java                                                                     1008 root      21   0 3147m 842m  10m S  0.3  2.6   4:31.08 java                                                                    13823 root      23   0 3031m 2.1g  10m S  0.3  6.8 176:57.34 java                                                                    28218 root      15   0 12760 1168  808 R  0.3  0.0   0:01.43 top                                                                     29062 root      20   0 1241m 227m  10m S  0.3  0.7   2:07.32 java                                                                        1 root      15   0 10368  684  572 S  0.0  0.0   1:30.85 init                                                                        2 root      RT  -5     0    0    0 S  0.0  0.0   0:01.01 migration/0                                                                 3 root      34  19     0    0    0 S  0.0  0.0   0:00.00 ksoftirqd/0                                                                 4 root      RT  -5     0    0    0 S  0.0  0.0   0:00.00 watchdog/0                                                                  5 root      RT  -5     0    0    0 S  0.0  0.0   0:00.80 migration/1                                                                 6 root      34  19     0    0    0 S  0.0  0.0   0:00.00 ksoftirqd/1                                                                 7 root      RT  -5     0    0    0 S  0.0  0.0   0:00.00 watchdog/1                                                                  8 root      RT  -5     0    0    0 S  0.0  0.0   0:20.59 migration/2                                                                 9 root      34  19     0    0    0 S  0.0  0.0   0:00.09 ksoftirqd/2                                                                10 root      RT  -5     0    0    0 S  0.0  0.0   0:00.00 watchdog/2                                                                 11 root      RT  -5     0    0    0 S  0.0  0.0   0:23.66 migration/3                                                                12 root      34  19     0    0    0 S  0.0  0.0   0:00.03 ksoftirqd/3                                                                13 root      RT  -5     0    0    0 S  0.0  0.0   0:00.00 watchdog/3                                                                 14 root      RT  -5     0    0    0 S  0.0  0.0   0:20.29 migration/4                                                                15 root      34  19     0    0    0 S  0.0  0.0   0:00.07 ksoftirqd/4                                                                16 root      RT  -5     0    0    0 S  0.0  0.0   0:00.00 watchdog/4                                                                 17 root      RT  -5     0    0    0 S  0.0  0.0   0:23.07 migration/5                                                                18 root      34  19     0    0    0 S  0.0  0.0   0:00.07 ksoftirqd/5                                                                19 root      RT  -5     0    0    0 S  0.0  0.0   0:00.00 watchdog/5                                                                 20 root      RT  -5     0    0    0 S  0.0  0.0   0:17.16 migration/6                                                                21 root      34  19     0    0    0 S  0.0  0.0   0:00.05 ksoftirqd/6                                                                22 root      RT  -5     0    0    0 S  0.0  0.0   0:00.00 watchdog/6                                                                 23 root      RT  -5     0    0    0 S  0.0  0.0   0:58.28 migration/7 说明： 统计信息区： 前五行是当前系统情况整体的统计信息区。下面我们看每一行信息的具体意义。 第一行，任务队列信息，同 uptime 命令的执行结果，具体参数说明情况如下： 14:06:23 — 当前系统时间 up 70 days, 16:44 — 系统已经运行了70天16小时44分钟（在这期间系统没有重启过的吆！） 2 users — 当前有2个用户登录系统 load average: 1.15, 1.42, 1.44 — load average后面的三个数分别是1分钟、5分钟、15分钟的负载情况。 load average数据是每隔5秒钟检查一次活跃的进程数，然后按特定算法计算出的数值。如果这个数除以逻辑CPU的数量，结果高于5的时候就表明系统在超负荷运转了。 第二行，Tasks — 任务（进程），具体信息说明如下： 系统现在共有206个进程，其中处于运行中的有1个，205个在休眠（sleep），stoped状态的有0个，zombie状态（僵尸）的有0个。 第三行，cpu状态信息，具体属性说明如下： 5.9%us — 用户空间占用CPU的百分比。 3.4% sy — 内核空间占用CPU的百分比。 0.0% ni — 改变过优先级的进程占用CPU的百分比 90.4% id — 空闲CPU百分比 0.0% wa — IO等待占用CPU的百分比 0.0% hi — 硬中断（Hardware IRQ）占用CPU的百分比 0.2% si — 软中断（Software Interrupts）占用CPU的百分比 备注：在这里CPU的使用比率和windows概念不同，需要理解linux系统用户空间和内核空间的相关知识！ 第四行,内存状态，具体信息如下： 32949016k total — 物理内存总量（32GB） 14411180k used — 使用中的内存总量（14GB） 18537836k free — 空闲内存总量（18GB） 169884k buffers — 缓存的内存量 （169M） 第五行，swap交换分区信息，具体信息说明如下： 32764556k total — 交换区总量（32GB） 0k used — 使用的交换区总量（0K） 32764556k free — 空闲交换区总量（32GB） 3612636k cached — 缓冲的交换区总量（3.6GB） 备注： 第四行中使用中的内存总量（used）指的是现在系统内核控制的内存数，空闲内存总量（free）是内核还未纳入其管控范围的数量。纳入内核管理的内存不见得都在使用中，还包括过去使用过的现在可以被重复利用的内存，内核并不把这些可被重新使用的内存交还到free中去，因此在linux上free内存会越来越少，但不用为此担心。 如果出于习惯去计算可用内存数，这里有个近似的计算公式：第四行的free + 第四行的buffers + 第五行的cached，按这个公式此台服务器的可用内存：18537836k +169884k +3612636k = 22GB左右。 对于内存监控，在top里我们要时刻监控第五行swap交换分区的used，如果这个数值在不断的变化，说明内核在不断进行内存和swap的数据交换，这是真正的内存不够用了。 第六行，空行。 第七行以下：各进程（任务）的状态监控，项目列信息说明如下： PID — 进程id USER — 进程所有者 PR — 进程优先级 NI — nice值。负值表示高优先级，正值表示低优先级 VIRT — 进程使用的虚拟内存总量，单位kb。VIRT=SWAP+RES RES — 进程使用的、未被换出的物理内存大小，单位kb。RES=CODE+DATA SHR — 共享内存大小，单位kb S — 进程状态。D=不可中断的睡眠状态 R=运行 S=睡眠 T=跟踪/停止 Z=僵尸进程 %CPU — 上次更新到现在的CPU时间占用百分比 %MEM — 进程使用的物理内存百分比 TIME+ — 进程使用的CPU时间总计，单位1/100秒 COMMAND — 进程名称（命令名/命令行） 其他使用技巧： 1.多U多核CPU监控 在top基本视图中，按键盘数字“1”，可监控每个逻辑CPU的状况：   观察上图，服务器有16个逻辑CPU，实际上是4个物理CPU。再按数字键1，就会返回到top基本视图界面。 2.高亮显示当前运行进程 敲击键盘“b”（打开/关闭加亮效果），top的视图变化如下：       我们发现进程id为2570的“top”进程被加亮了，top进程就是视图第二行显示的唯一的运行态（runing）的那个进程，可以通过敲击“y”键关闭或打开运行态进程的加亮效果。 3.进程字段排序 默认进入top时，各进程是按照CPU的占用量来排序的，在下图中进程ID为28894的java进程排在第一（cpu占用142%），进程ID为574的java进程排在第二（cpu占用16%）。            敲击键盘“x”（打开/关闭排序列的加亮效果），top的视图变化如下：         可以看到，top默认的排序列是“%CPU”。 4. 通过”shift + >”或”shift + <”可以向右或左改变排序列 下图是按一次”shift + >”的效果图,视图现在已经按照%MEM来排序。           实例2：显示 完整命令 命令： top -c 输出：        说明： 实例3：以批处理模式显示程序信息 命令： top -b 输出： 说明： 实例4：以累积模式显示程序信息 命令： top -S 输出： 说明： 实例5：设置信息更新次数 命令：   top -n 2 输出： 说明： 表示更新两次后终止更新显示 实例6：设置信息更新时间 命令： top -d 3 输出： 说明： 表示更新周期为3秒 实例7：显示指定的进程信息 命令： top -p 574 输出： 说明：      5.top交互命令 在top 命令执行过程中可以使用的一些交互命令。这些命令都是单字母的，如果在命令行中使用了s 选项， 其中一些命令可能会被屏蔽。 h 显示帮助画面，给出一些简短的命令总结说明 k 终止一个进程。 i 忽略闲置和僵死进程。这是一个开关式命令。 q 退出程序 r 重新安排一个进程的优先级别 S 切换到累计模式 s 改变两次刷新之间的延迟时间（单位为s），如果有小数，就换算成m s。输入0值则系统将不断刷新，默认值是5 s f或者F 从当前显示中添加或者删除项目 o或者O 改变显示项目的顺序 l 切换显示平均负载和启动时间信息 m 切换显示内存信息 t 切换显示进程和CPU状态信息 c 切换显示命令名称和完整命令行 M 根据驻留内存大小进行排序 P 根据CPU使用百分比大小进行排序 T 根据时间/累计时间进行排序 W 将当前设置写入~/.toprc文件中","title":"每天一个命令 top命令"},{"content":"ubuntu 9.10默认的是UFW防火墙，已经支持界面操作了。在命令行运行ufw命令就可以看到提示的一系列可进行的操作。 最简单的一个操作：sudo ufw status可检查防火墙的状态，我的返回的是：不活动 sudo ufw version防火墙版本： ufw 0.29-4ubuntu1 Copyright 2008-2009 Canonical Ltd. ubuntu 系统默认已安装ufw. 1.安装 sudo apt-get install ufw 2.启用 sudo ufw enable sudo ufw default deny 运行以上两条命令后，开启了防火墙，并在系统启动时自动开启。关闭所有外部对本机的访问，但本机访问外部正常。 3.开启/禁用 sudo ufw allow|deny [service] 打开或关闭某个端口，例如： sudo ufw allow smtp　允许所有的外部IP访问本机的25/tcp (smtp)端口 sudo ufw allow 22/tcp 允许所有的外部IP访问本机的22/tcp (ssh)端口 sudo ufw allow 53 允许外部访问53端口(tcp/udp) sudo ufw allow from 192.168.1.100 允许此IP访问所有的本机端口 sudo ufw allow proto udp 192.168.0.1 port 53 to 192.168.0.2 port 53 sudo ufw deny smtp 禁止外部访问smtp服务 sudo ufw delete allow smtp 删除上面建立的某条规则 4.查看防火墙状态 sudo ufw status 一般用户，只需如下设置： sudo apt-get install ufw sudo ufw enable sudo ufw default deny 以上三条命令已经足够安全了，如果你需要开放某些服务，再使用sudo ufw allow开启。 开启/关闭防火墙 (默认设置是’disable’) sudo  ufw enable|disable 转换日志状态 sudo  ufw logging on|off 设置默认策略 (比如 “mostly open” vs “mostly closed”) sudo  ufw default allow|deny 许 可或者屏蔽端口 (可以在“status” 中查看到服务列表)。可以用“协议：端口”的方式指定一个存在于/etc/services中的服务名称，也可以通过包的meta-data。 ‘allow’ 参数将把条目加入 /etc/ufw/maps ，而 ‘deny’ 则相反。基本语法如下： sudo  ufw allow|deny [service] 显示防火墙和端口的侦听状态，参见 /var/lib/ufw/maps。括号中的数字将不会被显示出来。 sudo  ufw status UFW 使用范例： 允许 53 端口 $ sudo ufw allow 53 禁用 53 端口 $ sudo ufw delete allow 53 允许 80 端口 $ sudo ufw allow 80/tcp 禁用 80 端口 $ sudo ufw delete allow 80/tcp 允许 smtp 端口 $ sudo ufw allow smtp 删除 smtp 端口的许可 $ sudo ufw delete allow smtp 允许某特定 IP $ sudo ufw allow from 192.168.254.254 删除上面的规则 $ sudo ufw delete allow from 192.168.254.254 linux 2.4内核以后提供了一个非常优秀的防火墙工具：netfilter/iptables,他免费且功能强大，可以对流入、流出的信息进行细化控制，它可以 实现防火墙、NAT（网络地址翻译）和数据包的分割等功能。netfilter工作在内核内部，而iptables则是让用户定义规则集的表结构。 但是iptables的规则稍微有些“复杂”，因此ubuntu提供了ufw这个设定工具，以简化iptables的某些设定，其后台仍然是 iptables。ufw 即uncomplicated firewall的简称，一些复杂的设定还是要去iptables。 ufw相关的文件和文件夹有： /etc /ufw/：里面是一些ufw的环境设定文件，如 before.rules、after.rules、sysctl.conf、ufw.conf，及 for ip6 的 before6.rule 及 after6.rules。这些文件一般按照默认的设置进行就ok。 若开启ufw之 后，/etc/ufw/sysctl.conf会覆盖默认的/etc/sysctl.conf文件，若你原来的/etc/sysctl.conf做了修 改，启动ufw后，若/etc/ufw/sysctl.conf中有新赋值，则会覆盖/etc/sysctl.conf的，否则还以/etc /sysctl.conf为准。当然你可以通过修改/etc/default/ufw中的“IPT_SYSCTL=”条目来设置使用哪个 sysctrl.conf. /var/lib/ufw/user.rules 这个文件中是我们设置的一些防火墙规则，打开大概就能看明白，有时我们可以直接修改这个文件，不用使用命令来设定。修改后记得ufw reload重启ufw使得新规则生效。 下面是ufw命令行的一些示例： ufw enable/disable:打开/关闭ufw ufw status：查看已经定义的ufw规则 ufw default allow/deny:外来访问默认允许/拒绝 ufw allow/deny 20：允许/拒绝 访问20端口,20后可跟/tcp或/udp，表示tcp或udp封包。 ufw allow/deny servicename:ufw从/etc/services中找到对应service的端口，进行过滤。 ufw allow proto tcp from 10.0.1.0/10 to 本机ip port 25:允许自10.0.1.0/10的tcp封包访问本机的25端口。 ufw delete allow/deny 20:删除以前定义的\"允许/拒绝访问20端口\"的规则","title":"ubuntu下防火墙的配置"},{"content":"1.动态库路径的设置 Linux下调用动态库和windows不一样.linux 可执行程序是靠配置文件去读取路径的,因此有些时候需要设置路径 具体操作如下 export LD_LIBRARY_PATH=/home/.....(动态库的目录) 不过这种设置方法只是在当前的session中有效 你可以修改配置文件实现任何session都有效   2.环境变量的设置 一般来说，配置交叉编译工具链的时候需要指定编译工具的路径，此时就需要设置环境变量。例如我的mips-linux-gcc编译器在“/opt/au1200_rm/build_tools/bin”目录下，build_tools就是我的编译工具，则有如下三种方法来设置环境变量： 1、直接用export命令： #export PATH=$PATH:/opt/au1200_rm/build_tools/bin 查看是否已经设好，可用命令export查看： [root@localhost bin]# export declare -x BASH_ENV=\"/root/.bashrc\" declare -x G_BROKEN_FILENAMES=\"1\" declare -x HISTSIZE=\"1000\" declare -x HOME=\"/root\" declare -x HOSTNAME=\"localhost.localdomain\" declare -x INPUTRC=\"/etc/inputrc\" declare -x LANG=\"zh_CN.GB18030\" declare -x LANGUAGE=\"zh_CN.GB18030:zh_CN.GB2312:zh_CN\" declare -x LESSOPEN=\"|/usr/bin/lesspipe.sh %s\" declare -x LOGNAME=\"root\" declare -x LS_COLORS=\"no=00:fi=00:di=01;34:ln=01;36:pi=40;33:so=01;35:bd=40;33;01:cd=40;33;01:or=01;05;37;41:mi=01;05;37;41:ex=01;32:*.cmd=01;32:*.exe=01;32:*.com=01;32:*.btm=01;32:*.bat=01;32:*.sh=01;32:*.csh=01;32:*.tar=01;31:*.tgz=01;31:*.arj=01;31:*.taz=01;31:*.lzh=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.gz=01;31:*.bz2=01;31:*.bz=01;31:*.tz=01;31:*.rpm=01;31:*.cpio=01;31:*.jpg=01;35:*.gif=01;35:*.bmp=01;35:*.xbm=01;35:*.xpm=01;35:*.png=01;35:*.tif=01;35:\" declare -x MAIL=\"/var/spool/mail/root\" declare -x OLDPWD=\"/opt/au1200_rm/build_tools\" declare -x PATH=\"/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/usr/X11R6/bin:/root/bin:/opt/au1200_rm/build_tools/bin\" declare -x PWD=\"/opt/au1200_rm/build_tools/bin\" declare -x SHELL=\"/bin/bash\" declare -x SHLVL=\"1\" declare -x SSH_ASKPASS=\"/usr/libexec/openssh/gnome-ssh-askpass\" declare -x SSH_AUTH_SOCK=\"/tmp/ssh-XX3LKWhz/agent.4242\" declare -x SSH_CLIENT=\"10.3.37.152 2236 22\" declare -x SSH_CONNECTION=\"10.3.37.152 2236 10.3.37.186 22\" declare -x SSH_TTY=\"/dev/pts/2\" declare -x TERM=\"linux\" declare -x USER=\"root\" declare -x USERNAME=\"root\" 可以看到，环境变量已经设好，PATH里面已经有了我要加的编译器的路径。 2、修改profile文件： #vi /etc/profile 在里面加入: export PATH=\"$PATH:/opt/au1200_rm/build_tools/bin\" 3. 修改.bashrc文件： # vi /root/.bashrc 在里面加入： export PATH=\"$PATH:/opt/au1200_rm/build_tools/bin\" 后两种方法一般需要重新注销系统才能生效，最后可以通过echo命令测试一下： # echo $PATH 看看输出里面是不是已经有了/my_new_path这个路径了。 ----------------------------------------------------------------------------------- 　“/bin”、“/sbin”、“/usr/bin”、“/usr/sbin”、“/usr/local/bin”等路径已经在系统环境变量中了，如果可执行文件在这几个标准位置，在终端命令行输入该软件可执行文件的文件名和参数(如果需要参数)，回车即可。 　　如果不在标准位置，文件名前面需要加上完整的路径。不过每次都这样跑就太麻烦了，一个“一劳永逸”的办法是把这个路径加入环境变量。命令 “PATH=$PATH:路径”可以把这个路径加入环境变量，但是退出这个命令行就失效了。要想永久生效，需要把这行添加到环境变量文件里。有两个文件可选：“/etc/profile”和用户主目录下的“.bash_profile”，“/etc/profile”对系统里所有用户都有效，用户主目录下的“.bash_profile”只对这个用户有效。 　　“PATH=$PATH:路径1:路径2:...:路径n”，意思是可执行文件的路径包括原先设定的路径，也包括从“路径1”到“路径n”的所有路径。当用户输入一个一串字符并按回车后，shell会依次在这些路径里找对应的可执行文件并交给系统核心执行。那个“$PATH”表示原先设定的路径仍然有效，注意不要漏掉。某些软件可能还有“PATH”以外类型的环境变量需要添加，但方法与此相同，并且也需要注意“$”。 　　注意，与DOS/Window不同，UNIX类系统环境变量中路径名用冒号分隔，不是分号。另外，软件越装越多，环境变量越添越多，为了避免造成混乱，建议所有语句都添加在文件结尾，按软件的安装顺序添加。 　　格式如下()： 　　# 软件名-版本号 　　PATH=$PATH:路径1:路径2:...:路径n 　　其他环境变量=$其他环境变量:... 　　在“profile”和“.bash_profile”中，“#”是注释符号，写在这里除了视觉分隔外没有任何效果。 　　设置完毕，注销并重新登录，设置就生效了。如果不注销，直接在shell里执行这些语句，也能生效，但是作用范围只限于执行了这些语句的shell。 　　相关的环境变量生效后，就不必老跑到软件的可执行文件目录里去操作了。 from:http://blog.csdn.net/kpgood/archive/2009/03/07/3965446.aspx 使用linux的朋友越来越多了，在linux下做开发首先就是需要配置环境变量，下面以配置java环境变量为例介绍三种配置环境变量的方法。   1.修改/etc/profile文件 如果你的计算机仅仅作为开发使用时推荐使用这种方法，因为所有用户的shell都有权使用这些环境变量，可能会给系统带来安全性问题。   (1)用文本编辑器打开/etc/profile   (2)在profile文件末尾加入： JAVA_HOME=/usr/share/jdk1.5.0_05 PATH=$JAVA_HOME/bin:$PATH CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export JAVA_HOME export PATH export CLASSPATH   (3)重新登录   注解： a. 你要将 /usr/share/jdk1.5.0_05jdk 改为你的jdk安装目录   b. linux下用冒号“:”来分隔路径   c. $PATH / $CLASSPATH / $JAVA_HOME 是用来引用原来的环境变量的值,在设置环境变量时特别要注意不能把原来的值给覆盖掉了，这是一种常见的错误。   d. CLASSPATH中当前目录“.”不能丢,把当前目录丢掉也是常见的错误。   e. export是把这三个变量导出为全局变量。   f. 大小写必须严格区分。   2. 修改.bashrc文件　　 这种方法更为安全，它可以把使用这些环境变量的权限控制到用户级别，如果你需要给某个用户权限使用这些环境变量，你只需要修改其个人用户主目录下的.bashrc文件就可以了。   (1)用文本编辑器打开用户目录下的.bashrc文件   (2)在.bashrc文件末尾加入：　　 set JAVA_HOME=/usr/share/jdk1.5.0_05 export JAVA_HOME set PATH=$JAVA_HOME/bin:$PATH export PATH set CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export CLASSPATH   (3)重新登录   3. 直接在shell下设置变量 不赞成使用这种方法，因为换个shell，你的设置就无效了，因此这种方法仅仅是临时使用，以后要使用的时候又要重新设置，比较麻烦。   只需在shell终端执行下列命令： export JAVA_HOME=/usr/share/jdk1.5.0_05 export PATH=$JAVA_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar          ","title":"Linux里设置环境变量的方法（export PATH）"},{"content":"一、 Web界面探索Openshift 打开：https://openshift.Red Hat.com/，这就是OpenShift的主站。     经过短暂的注册和Email激活之后，登录到系统的后台。首先系统会让你先设定个二级域名，然后就可以添加你的第一个应用了。     Openshift的后台支持各种开发环境。除了比较常见的Java、PHP、Python、Ruby、Perl，还有Node.js等比较新兴的语言。而部署环境，除了红帽自己的JBoss之外，还有Tomcat和Ruby on rails、Zend Server 5.6等第三方平台。当然，如果你需求比较特别，OpenShit也支持“Do-It-Yourself”。 如果现在后台还没有支持你所用的开发语言，框架，中间件什么的，你可以自行创建和编译相关的内容。     当然，让人比较高兴的是，OpenShift在2012年开始，支持经典开源Web程序的一键安装了。比如Drupal、Wordpress、phpbb等等，还有新的程序在不断加入。    ","title":"openshift学习笔记"},{"content":"原文地址：http://wenku.baidu.com/view/7105e6c15fbfc77da269b1f4 http://bbs.csdn.net/topics/350052487十三楼尝试一下 摄像头移植 一、环境 主机环境 ：ubuntu 10.10         目标板 ：FS-S5PC100  主机工具链 ：gcc-4.4.5        交叉工具链 ：arm-unknown-linux-gnueabi-gcc   摄像头 ：ZC301 注意事项： 自己制作文件系时，需要将交叉编译工具链中的库文件拷贝到文件系统中。 2  调试时使用nfs挂载，调试完成后，将zImage和yaffs文件系统（yaffs可读写）烧入开发板。 二、移植过程 1、配置内核使内核支持芯片为ZC301的摄像头    Make menuconfig    DeviceDrivers --->           <*>Multimedia support --->                    <*>Video For Linux                    [*]Enable Video For Linux API 1 (DEPRECATED) (NEW)                     [*]Video capture adapters (NEW) --->                               [*]V4L USB devices (NEW) --->                                        <*>USB Video Class (UVC)                                        [*]UVC input events device support (NEW)                                 <*>USB ZC0301[P] webcam support (DEPRECATED) 2、重新编译内核 makezImage 3、mjpg-streamer的移植 关于mjpg-streamer的资料可以在下面这个网址查看：http://sourceforge.net/apps/mediawiki/mjpg-streamer/index.php?title=Main_Page mjpg-streamer的移植需要jpeg的库，所以我们先移植jpeg的库 (1)jpeg库的移植  1)jpeg源码包通过下面这个网址下载          http://www.ijg.org/files/jpegsrc.v8b.tar.gz  2)解压源码包在/home/linux/ 目录下解压:            tarxvf jpegsrc.v8b.tar.gz  3)配置源码,在/home/linux/目录下创建jpeg目录mkdirjpeg                 cd jpeg-8b            执行    ./configure --prefix=/home/linux/jpeg  --host=arm-unknwn-linux-gnueabi   4)编译               make   5)安装               makeinstall   6)拷贝库到文件系统中        cp /home/linux/jpeg/lib/libjpeg.so.8   /source/rootfs/lib (2)mjpg-streamer的移植         1)mjpg-stream源码包通过下面这个网址下载  http://sourceforge.net/projects/mjpg-streamer/         2)解压源码                tarxvf mjpg-streamer-r63.tar.gz          3)修改源码                cdmjpg-streamer-r63                 修改顶层makefile及plugins目录中的各级makefile，将所有                 CC=gcc                 修改为               CC=arm-unknown-linux-gnueabi-gcc         修改plugins/input_uvc/Makfile                 修改                CFLAGS+= -O2 -DLINUX -D_GNU_SOURCE -Wall -shared –fPIC                 为                CFLAGS+= -O2 -DLINUX -D_GNU_SOURCE -Wall -shared -fPIC -I/home/linux//jpeg/include                 修改                 $(CC)$(CFLAGS) -ljpeg -o $@ input_uvc.c v4l2uvc.lojpeg_utils.lo dynctrl.lo                 为                 $(CC)$(CFLAGS) -ljpeg -L/home/linux/jpeg/lib -o $@ input_uvc.c v4l2uvc.lo jpeg_utils.lo dynctrl.lo        4)编译                make        5)将mjpeg可执行文件拷贝到文件系统的/bin目录下   cpmjpg-streamer  /source/rootfs/bin 在文件系统中创建mjpg目录，将所有的动态库拷贝到该目录下               mkdir/source/rootfs/mjpg                 cp*.so /source/rootfs/mjpg  {6个so文件} 将mjpeg_streamer-r63目录下的/www目录拷贝到文件系统中 cp  /www/ -a   /source/rootfs/  -rf -rf 4 运行        在WINDOWS下 运行viewer.exe或运行解压文件中的www目录下的所有文件复制到你当前的BOA服务器指定的目录下。 同时要将www目录下的cambozla.jarbodybg.gif ,favicon.ico, favicon.png,  sidebarbg.gif拷贝到你的BOA服务器下。 打开开开发板将boa服务器运行起来     ./etc/boa/boa& 输入下面一行命令： ./bin/mjpg_streamer  -i  \"/mjpg/input_uvc.so-d /dev/video0\"  -o  \"/mjpg/output_http.so -w  /www/  \"  在linux系统的浏览器中，输入如下地址：    http://192.168.1.200:8080 显示界面如下图所示：                 5 拍照功能的实现 由于mjpg_stream中output-file.so能实现连续拍照的功能，不能实现单拍或连拍几张的功能所以需要对output_file原码进行修改。 #  cd mjpg-streamer-rc63/plugins/output_file #  vim output_file.c 在96行 函数 void*worker_thread(void *arg) 体中加入以下代码： charbuf[10];   // intflags = 0;   //拍照标志，1：表示11张照片，2：表示1张照片 intfd_com = 0; //打开管道的文件描述符      stop_num = 0; //拍照计数   if ( access(“/tmp/webcom”,F_OK) < 0 )    //创建有名管道用于接收拍照命令 {    if ( mkfifo(“/tmp/webcom”,0666 ) < 0)    {        Printf(“ photo fifo create failed\\n”); } }   fd_com = open (“/tmp/webcom”,O_RDONLY,0666);   if (fd < 0) {        perror (“open the file webcom error”); }   在while( ok >= 0 && !pglobal->stop){ 后加入   if (flags == 0) {        while(1)  {        reade(fd_com,buf,sizeof(buf)); if(strncmp(buf,”danger”,6) == 0)    //拍11张照片 {        flags = 1;     bzero(buf,sizeof(buf));     break; } if(strncmp(buf,”one”,3) == 0)   //拍1张照片 {        flags = 2;     bzero(buf,sizeof(buf));     break; }   } }   在if (delay > 0){    usleep(1000*delay); }后加入 stop_num++ if(flags == 1)        //判断拍照的数量 {        if ( stop_num > 9)    { stop_num= 0; flsgs= 0; } } elseif (flags == 2) { stop_num= 0; flags= 0; } 所以只要向有名管道/tmp/webcom写入danger就能连拍11张照片，写入one就拍一张照片。   注:拍照功能实现： ./bin/mjpg_streamer  –i  “/mjpeg/input_uvc.so –d  /dev/video0” -o “/mjpeg/output_file.so   –f  /pice -d  15000 ”  &  echo  danger >  /dev/video0","title":"Mjpg-Streamer 拍照功能移植"},{"content":"//vprintf和vsprintf函数的使用   1 #include <stdio.h>   2 #include <stdlib.h>   3 #include <stdarg.h>   4   5 #define BUFF_MAX_SIZE 128   6 char *buff;   7   8 int my_vprintf(const char *format, ...){   9 >--->---va_list ap;  10 >--->---int retval;  11 >--->---  12 >--->---va_start(ap, format);  13 >--->---retval = vprintf(format, ap);  14 >--->---va_end(ap);  15  16 >--->---return retval;  17 }  18  19 int my_vsprintf(const char *format, ...){  20 >--->---va_list ap;  21 >--->---int retval;  22 >--->---buff = (char *)malloc(BUFF_MAX_SIZE);  23  24 >--->---va_start(ap, format);  25 >--->---retval = vsprintf(buff, format, ap);//按着一定格式将字符串存放在申请的地址空间  26 >--->---va_end(ap);  27  28 >--->---return retval;  29 }  30  31 int main(void){  32 >--->---int var1 = 100;  33 >--->---int var2 = -100;  34 >--->---double tmp = 3.14159;  35  36 >--->---my_vprintf(\"%d %f %x\\n\", var2, tmp, var1);  37 >--->---my_vsprintf(\"%f : %d : %x\\n\", tmp, var2, var1);  38 >--->---printf(\"buff: %s\", buff);  39  40 >--->---free(buff);  41 >--->---return 0;  42 } //sscanf格式化取出字符串   1 #include <stdio.h>   2 #include <stdlib.h>   3 #define BUFF_MAX_SIZE 20   4   5 int main(void){   6 >--->---char *time_now = \"2012-12-19 15:06:30\";   7 >--->---int year, month, day, hour, minute, seconds;   8 >--->---char *user_name = \"1234567890321\";   9 >--->---char buff[BUFF_MAX_SIZE];  10  11 >--->---sscanf(time_now, \"%d-%d-%d %d:%d:%d\", &year, &month, &day, &hour, &minute, &seconds);  12 >--->---printf(\"%04d-%02d-%02d %02d:%02d:%02d\\n\", year, month, day, hour, minute, seconds);  13  14 >--->---sscanf(user_name, \"%3s\", buff);  15 >--->---printf(\"buff:  %s\\n\", buff);  16  17 >--->---return 0;  18 }","title":"vprintf,vsprintf,sscanf函数的使用"},{"content":"由于记忆力有限,把平时常用的Linux命令整理出来,以便随时查阅:  linux 基本命令  ls     (list 显示当前目录下文件和目录 ls -l 详细显示 =ll )   [root@linux ~]# ls [-aAdfFhilRS] 目录名称  [root@linux ~]# ls [--color={none,auto,always}] 目录名称  [root@linux ~]# ls [--full-time] 目录名称  参数：  -a ：全部的档案，连同隐藏档( 开头为 . 的档案) 一起列出来～  -A ：全部的档案，连同隐藏档，但不包括 . 与 .. 这两个目录，一起列出来～  -d ：仅列出目录本身，而不是列出目录内的档案数据  -f ：直接列出结果，而不进行排序 (ls 预设会以档名排序！)  -F ：根据档案、目录等信息，给予附加数据结构，例如：  *：代表可执行档； /：代表目录； =：代表 socket 档案； |：代表 FIFO 档案；  -h ：将档案容量以人类较易读的方式(例如 GB, KB 等等)列出来；  -i ：列出 inode 位置，而非列出档案属性；  -l ：长数据串行出，包含档案的属性等等数据；  -n ：列出 UID 与 GID 而非使用者与群组的名称 (UID与GID会在账号管理提到！)  -r ：将排序结果反向输出，例如：原本档名由小到大，反向则为由大到小；  -R ：连同子目录内容一起列出来；  -S ：以档案容量大小排序！  -t ：依时间排序  --color=never ：不要依据档案特性给予颜色显示；  --color=always ：显示颜色  --color=auto ：让系统自行依据设定来判断是否给予颜色  --full-time ：以完整时间模式 (包含年、月、日、时、分) 输出  --time={atime,ctime} ：输出 access 时间或 改变权限属性时间 (ctime)  而非内容变更时间 (modification time)       cat 由第一行开始显示档案内容    [root@linux ~]# cat [-AEnTv]  参数：  -A ：相当于 -vET 的整合参数，可列出一些特殊字符～  -E ：将结尾的断行字符 $ 显示出来；  -n ：打印出行号；  -T ：将 [tab] 按键以 ^I 显示出来；  -v ：列出一些看不出来的特殊字符       tac 从最后一行开始显示，可以看出 tac 是 cat 的倒着写！ nl 显示的时候，顺道输出行号！    [root@linux ~]# nl [-bnw] 档案  参数：  -b ：指定行号指定的方式，主要有两种：  -b a ：表示不论是否为空行，也同样列出行号；  -b t ：如果有空行，空的那一行不要列出行号；  -n ：列出行号表示的方法，主要有三种：  -n ln ：行号在屏幕的最左方显示；  -n rn ：行号在自己字段的最右方显示，且不加 0 ；  -n rz ：行号在自己字段的最右方显示，且加 0 ；  -w ：行号字段的占用的位数。       more 一页一页的显示档案内容    空格键 (space)：代表向下翻一页；  Enter ：代表向下翻『一行』；  /字符串 ：代表在这个显示的内容当中，向下搜寻『字符串』；  :f ：立刻显示出文件名以及目前显示的行数；  q ：代表立刻离开 more ，不再显示该档案内容。  less 与 more 类似，但是比 more 更好的是，他可以往前翻页！ 空格键 ：向下翻动一页；  [pagedown]：向下翻动一页；  [pageup] ：向上翻动一页；  /字符串 ：向下搜寻『字符串』的功能；  ?字符串 ：向上搜寻『字符串』的功能；  n ：重复前一个搜寻 (与 / 或 ? 有关！)  N ：反向的重复前一个搜寻 (与 / 或 ? 有关！)  q ：离开 less 这个程序；  head 只看头几行    [root@linux ~]# head [-n number] 档案  参数：  -n ：后面接数字，代表显示几行的意思       tail 只看尾巴几行   tail -200f logfile2 ( 显示日志最后 200 行 ) od 以二进制的方式读取档案内容！    [root@linux ~]# od [-t TYPE] 档案  参数：  -t ：后面可以接各种『类型 (TYPE)』的输出，例如：  a ：利用预设的字符来输出；  c ：使用 ASCII 字符来输出  d[size] ：利用十进制(decimal)来输出数据，每个整数占用 size bytes ；  f[size] ：利用浮点数值(floating)来输出数据，每个数占用 size bytes ；  o[size] ：利用八进位(octal)来输出数据，每个整数占用 size bytes ；  x[size] ：利用十六进制(hexadecimal)来输出数据，每个整数占用 size bytes ；        chmod  ( chmod +R filename增加文件读写执行权限,+R 可读,+W 可写,+X 可执行         ( chmod 777 filename 增加文件读写执行权限的另一种方式,                              7=> 对应8进制的 111 可读可写可执行)           chown  ( chown -R haowen .将当前目录下所有文件和目录权限赋给 haowen            ,-R 包括子目录)  chgrp -R mysql . (把当前文件夹变更到mysql群组,mysql是已经有的群组)变更文件或目录的所属群组。  umask 档案预设权限：  umask 指定的是『该默认值需要减掉的权限 ！』 chattr (设定档案隐藏属性)  lsattr (显示档案隐藏属性)     find   ( find ./ -name file1 -print ,从当前目录向下查找名为 file1 的文件)  mkdir  ( mkdir  dir1 ,新建目录 dir1 )    mkdir [-mp] 目录名称  参数：  -m ：设定档案的权限喔！直接设定，不需要看预设权限 (umask) 的脸色～  -p ：帮助你直接将所需要的目录递归建立起来！          [root@linux ~]# rmdir [-p] 目录名称  参数：  -p ：连同上层『空的』目录也一起删除        pwd   Print Working Directory  ( pwd  ,显示当前路径 ) pwd -P 显示出确实的路径,而非使用连接(link)路径  cd     ( cd /usr/local/   进入目录 /usr/local/ , cd ../ 返回到上一级目录                              ./ 当前目录 ../父目录 - 代表前一个工作目录 ~代表[目前使用者身份]所在的家目录  ~account代表account这个使用者的家目录)针对 cd 的使用方法，如果仅输入 cd 时，代表的就是『 cd           ~ 』    mv     ( mv file1  /home/haowen/ ,将文件移动到目录 /home/haowen/下                                    ,相当于 window 剪切 )         ( mv file1 filenew1 ,将文件名改为 filenew1 )   [root@linux ~]# mv [-fiu] source destination  [root@linux ~]# mv [options] source1 source2 source3 .... directory  参数：  -f ：force 强制的意思，强制直接移动而不询问；  -i ：若目标档案 (destination) 已经存在时，就会询问是否覆盖！  -u ：若目标档案已经存在，且 source 比较新，才会更新 (update)        cp     ( cp file1 /home/haowen/  ,将文件复制copy到目录 /home/haowen/下             cp -r dir1 /home/haowen/            cp file1 ./file2 复制文件并改名)   [root@linux ~]# cp [-adfilprsu] 来源档(source) 目的檔(destination)  [root@linux ~]# cp [options] source1 source2 source3 .... directory  参数：  -a ：相当于 -pdr 的意思；  -d ：若来源文件为连结文件的属性(link file)，则复制连结文件属性而非档案本身；  -f ：为强制 (force) 的意思，若有重复或其它疑问时，不会询问使用者，而强制复制；  -i ：若目的檔(destination)已经存在时，在覆盖时会先询问是否真的动作！  -l ：进行硬式连结 (hard link) 的连结档建立，而非复制档案本身；  -p ：连同档案的属性一起复制过去，而非使用预设属性；  -r ：递归持续复制，用于目录的复制行为；  -s ：复制成为符号连结文件 (symbolic link)，亦即『快捷方式』档案；  -u ：若 destination 比 source 旧才更新 destination ！        rm     ( rm file1 ,rm -r dir1,rm -rf dir2 删除文件或目录, f不提示输入y    [root@linux ~]# rm [-fir] 档案或目录  参数：  -f ：就是 force 的意思，强制移除；  -i ：互动模式，在删除前会询问使用者是否动作  -r ：递归删除啊！最常用在目录的删除了       touch 建立一个空的档案,将某个档案日期修订为目前 (mtime 与 atime)    [root@linux ~]# touch [-acdmt] 档案  参数：  -a ：仅修订 access time；  -c ：仅修改时间，而不建立档案； -d ：后面可以接日期，也可以使用 --date=\"日期或时间\"  -m ：仅修改 mtime ；  -t ：后面可以接时间，格式为[YYMMDDhhmm]            file 如果你想要知道某个档案的基本数据，例如是属于 ASCII 或者是 data 档案，或者是 binary ， 且其中有没有使用到动态函式库 (share library) 等等的信息，就可以利用 file 这个指令来检阅喔！  which (寻找『执行档』) 这个指令是根据『PATH』这个环境变量所规范的路径，去搜寻『执行档』的档名   [root@linux ~]# which [-a] command  参数：  -a ：将所有可以找到的指令均列出，而不止第一个被找到的指令名称       whereis (从数据库寻找特定档案)   [root@linux ~]# whereis [-bmsu] 档案或目录名  参数：  -b :只找 binary 的档案  -m :只找在说明文件 manual 路径下的档案  -s :只找 source 来源档案  -u :没有说明档的档案！       功能说明：计算字数。 语 　 法：wc [-clw][--help][--version][文件名] 补充说明：利用wc指令我们可以计算文件的Byte数、字数、或是列数，若不指定任何文件名称，或是所给予的文件名为\"-\"，则wc指令会从标准输入设备读取数据。假设不给予其参数，wc指令会一并显示列数、字数和Byte数 参 　 数： -c 只显示Byte数，亦即字符数； -l 只显示列数； -w 只显示字数； -m 同样显示字符数 --help 在线帮助； --version 显示此软件的版本信息。 locate 从数据库列出某个档案的完整档名 find ./ -name index.jsp 查找当前目录下名称为index.jsp的文件  grep   ( grep \"mobile=13712345678\"  logfile1 ,在logfile1中            搜索查找内容 \"mobile=13712345678\" )    ping   ( ping 61.129.78.9 ,ping www.163.com ,测试网络连接是否正常 )  ifconfig  ( ifconfig ,查看本机 IP地址，子网掩码等 )    ps    ( ps aux 查看系统中已经启动的进程, ps aux | grep programe1 ,          查看程序1是否正在运行  kill  ( kill -9  2325 ,杀死进程号为 2325的进程,           killall  programe1 ,杀死programe1进程 )  reboot ( 重启系统 )  init 0 ( 关机 ,仅 root 用户有权操作 )  init 6 ( 重启系统 ,仅 root 用户有权操作 )    gzip   ( gzip file1 ,压缩文件 file1 )  gunzip ( gunzip file1.gz  解压缩文件 file1.gz )    tar -zcvf ( tar -zcvf  dir1.tar.gz ./dir1  ,将当前目录下 dir1目录所有内容            压缩打包,包名dir1.tar.gz )  tar -zxvf ( tar -zxvf  dir1.tar.gz ,解开压缩包 )     echo \"hello!\" >> file1  ( 将 \"hello\" 添加到文件 file1后面,                             当 file1 不存在就创建 file1    vi file2       ( vi 编即器新建文件 file2)                 ...输入内容 welcome..                 ( 按 i 进入 insert 状态 即插入模式 ,按 Esc 退出插入模式                   在非插入模式下按 dd 删除光标当前行,按 x 删除当前字,                   按 j,n,l移动光标 )  :wq  ( 保存退出 ) :q! (不保存退出)    增加环境变量   [root@linux ~]# echo $PATH         [root@linux ~]# PATH=\"$PATH\":/root         env  显示系统的一些环境变量  set  显示系统的所有变量   chmod:  Linux/Unix 的档案调用权限分为三级 : 档案拥有者、群组、其他。  利用 chmod 可以藉以控制档案如何被他人所调用。     + 表示增加权限、- 表示取消权限、= 表示唯一设定权限。  　 r 表示可读取，w 表示可写入，x 表示可执行，    1. 将档案 file1.txt 设为所有人皆可读取 :  　　 chmod ugo+r file1.txt   或  chmod 444 file1.txt    2. 将文件 file2 设为属主可读写执行,Group,other ,只能读    chmod 744 file2   ( 7=> \"111\" ,4=>\"100\" 二进制 )      3. 将文件 file3 设为属主可读写执行,Group,other ,无权限操作不能读写执行)    chmod 700 file3   ( 7=> \"111\" ,0=>\"000\"  )        其中a,b,c各为一个数字，分别表示User、Group、及Other的权限。  　  　 r=4，w=2，x=1 若要rwx属性则4+2+1=7； 若要rw-属性则4+2=6；                   若要r-x属性则4+1=5 　 　   tar:   tar 调用gzip 　　gzip是GNU组织开发的一个压缩程序，.gz结尾的文件就是gzip压缩的结果。     与gzip相对的解压程序是gunzip。tar中使用-z这个参数来调用gzip。 　　# tar -czf all.tar.gz *.jpg      　　这条命令是将所有.jpg的文件打成一个tar包，并且将其用gzip压缩，生成一个     gzip压缩过的包，包名为all.tar.gz      　　# tar -xzf all.tar.gz   这条命令是将上面产生的包解开。 　　 date 显示日期的指令：  cal 显示日历的指令：  bc 简单好用的计算器：  [Tab] 按键   (按两次) 命令补全:  [Ctrl]-c 按键 中断目前程序:  [Ctrl]-d 按键  (相当于输入 exit) 键盘输入结束:  info 在线求助  :        who 要看目前有谁在在线:        finger 显示关于系统用户的信息 netstat -a     看网络的联机状态:  ntsysv 设置服务随系统启动时同时启动      shutdown  ,shutdown -h now  惯用的关机指令：  reboot, halt, poweroff 重新开机，关机：  --- 系统相关的命令:---  dmesg : 例如 dmesg | more  显示系统的诊断信息,操作系统版本号,物理内及其它信息  df : 例如 df -h 显示硬盘空间  du :   查看目录中各级子目录使用的硬盘空间  free:  查看系统内存,虚拟内存(交换空间)的大小占用情况  top: 动态实时查看系统内存,CPU,进程  hostname 查看主机名:    hostname 新主机名 修改主机名(临时的,重启就没了): man 命令:查看该命令的基础用法  info 命令:查看该命令的基础用法 ls -l /lib/modules/`uname -r`/kernel/fs 查看Linux 支持的档案系统有哪些 cat /proc/filesystems  查看Linux目前已启用的档案系统 type 查询某个指令是来自于外部指令(指的是其它非 bash 套件所提供的指令) 或是内建在 bash 当中的指令   [root@linux ~]# type [-tpa] name  参数：  ：不加任何参数时，则 type 会显示出那个 name 是外部指令还是 bash 内建的指令！  -t ：当加入 -t 参数时，type 会将 name 以底下这些字眼显示出他的意义：  file ：表示为外部指令；  alias ：表示该指令为命令别名所设定的名称；  builtin ：表示该指令为 bash 内建的指令功能；  -p ：如果后面接的 name 为指令时，会显示完整文件名(外部指令)或显示为内建指令；  -a ：会将由 PATH 变量定义的路径中，将所有含有 name 的指令都列出来，包含 alias       myname=pqb 变量的设定 PATH=\"$PATH\":/home/dmtsai/bin  变量的累加 echo $myname 变量的查看 unset myname 变量的取消 在来看看关机，关闭系统使用Shutdown命令，确保用户和系统的资料完整。只有root用户才能使用这个命令。 一般的用户是不允许执行这个命令的。 我们先看看showdown语法： shutdown [options] when [message] options:　-r 表示重启，-h表示系统服务停滞(halt)后，立刻关机，-f表示快速重启 when：　为shutdown指定时间。hh:mm：绝对时间，hh指小时，mm指分钟；如08:30，+m:m分钟后执行， now=+0，也就是立刻执行 message：表示系统的广播信息，一般提示各个用户系统关机或重启，要求用户保存资料后退出。 我们来看看几个例子： shutdown -h now 立刻关机 shutdown -h 21:30 今天21：30关机 shutdown -h +10 十分钟后关机 shutdown -r now 立刻重启 shutdown -r +10 ‘the system will reboot’ 10分钟后重启，管理员提示用户系统要重启了，便于用户保存工 作中的资料。只有root用户才能使用这个命令。 创建文件 创建文件是指创建一个一般的普通文件，并且这个文件为空，我们可以使 用touch命令来建立一般文件，如下操作： [root@Linux two]# touch 111.txt 搜索文件 我们先来学习一下如何搜索文件，特别是刚开始学习Linux的时候，自己建立的文件不知道放在哪里了，常有发 生。如果知道文件名，却不知道文件在那个目录下面了，我们就可以使用locate命令来搜索文件。看如下操作 ： [root@Linux one]# locate install.log /root/install.log /root/install.log.syslog 看一下，我们一下就搜索了两个与install.log相关的文件，他们都在/root目录下，同时我们感觉到，使用这个命 令搜索文件的速度比较快，其实要使用这个命令，必须配合数据库来使用，因为这个命令是从数据库中来搜索 文件，这个数据库的更新速度是7天更新一次。如下操作： [root@Linux one]# touch 001.txt [root@Linux one]# locate 001.txt 发现这个命令找不到新建立的文件，所以我们要使用这个命令搜索文件之前，必须自己更新一下数据库(更新数据库需要root权限)，如下 操作： [root@Linux one]# updatedb [root@Linux one]# locate 001.txt /root/one/001.txt 看看，如果执行updatedb这个命令更新数据库之后，我们就可以找到我们所需要的数据。不过更新数据库的时 间需要一段时间。 locale能看语言环境 保存语言信息的文件在/etc/sysconfig/i18n中。 /sbin/service xinetd restart|start|stop 启动后台服务，  /sbin/chkconfig --list |more 显示系统服务启动情况，显示了运行级别0到运行级别6的情况. 这些服务都是靠系统脚本init启动的。还有一些不是靠系统脚本启动的而下面会看到一些特殊服务，他们不是 靠init 启动的。是靠xinetd启动的，是一个独立的互联网服务器的服务器是一个超级服务其，可以启动很多的子服 务器。 大家看到 xinetd这个服务只要他是开启的，就可以运行他下面的服务器，它下面的大部分都是关闭的，只 有一个是开启的，如果我们想开启一个服务可以使用chkconfig命令，例如我们想开启 rsync服务，我们可以使 用chkconfig rsync on|off 命令。 mount 在mount命令不使用任何选项和参数的时候将显示当前linux系统中以挂载的文件系统信息。 mount Cttype dev dir 光盘文件系统类型是：iso9660；dev表示需要挂载文件系统的设备名称，光盘驱动器的设备名称是/dev/cdrom; dir表示挂载点，即挂载到的文件目录路径。 首先介绍光盘的挂载方法： mount -t iso9660 /dev/cdrom /media/cdrom 列出系统中所有存储设备 fdisk -l命令 使用“vfat”文件系统类型表示所有的fat文件系统类型，包括fat16和fat32，ntfs还是使用ntfs表示。 u盘的挂载方法 mount -t vfat /dev/sdb1 /mnt/ mount -t ntfs /dev/sdb1 /mnt/ umount命令用于卸载已经挂载的文件系统，基本格式如：umount dir device 对于光盘文件系统的卸载可以使用，以下两条命令中的任意一条 umount /dev/cdrom umount /media/cdrom u盘的卸载 umount /dev/sdb1 eject命令 eject 弹出光盘命令 eject -t 光盘驱动器自动回收 cut  使用权限：所有使用者  用法：cut -cnum1-num2 filename  说明：显示每行从开头算起 num1 到 num2 的文字。  范例：  shell>> cat example  test2  this is test1  shell>> cut -c0-6 example 开头算起前 6 个字元  test2  this i  指令名称:ln  　　使用权限:所有使用者  　　使用方式:ln [options] source dist,其中 option 的格式为: 　　[-bdfinsvF] [-S backup-suffix] [-V {numbered,existing,simple}]  　　[--help] [--version] [--]  　　说明:Linux/Unix 档案系统中,有所谓的连结(link),我们可以将其视为档案的别名,而连结又可分为两种:硬连结(hard link)与软连结(symbolic link),硬连结的意思是一个档案可以有多个名称,而软连结的方式则是产生一个特殊的档案,该档案的内容是指向另一个档案的位置。硬连结是存在同一个档案系统中,而软连结却可以跨越不同的档案系统。  　　ln source dist 是产生一个连结(dist)到 source,至于使用硬连结或软链结则由参数决定。  　　不论是硬连结或软链结都不会将原本的档案复制一份,只会占用非常少量的磁碟空间。 　　-f:链结时先将与 dist 同档名的档案删除-d:允许系统管理者硬链结自己的目录-i:在删除与 dist 同档名的档案时先进行询问-n:在进行软连结时,将 dist 视为一般的档案-s:进行软链结(symbolic link)-v:在连结之前显示其档名-b:将在链结时会被覆写或删除的档案进行备份-S SUFFIX:将备份的档案都加上 SUFFIX 的字尾-V METHOD:指定备份的方式--help:显示辅助说明--version:显示版本  　　范例: 　　将档案 yy 产生一个 symbolic link:zz  　　ln -s yy zz  　　将档案 yy 产生一个 hard link:zz  　　ln yy xx  名称:at  　　使用权限:所有使用者  　　使用方式:at -V [-q queue] [-f file] [-mldbv] TIME  　　说明:at 可以让使用者指定在 TIME 这个特定时刻执行某个程式或指令,TIME 的格式是 HH:MM其中的 HH 为小时,MM 为分钟,甚至你也可以指定 am, pm, midnight, noon, teatime(就是下午 4 点锺)等口语词。  　　如果想要指定超过一天内的时间,则可以用 MMDDYY 或者 MM/DD/YY 的格式,其中 MM 是分钟,DD 是第几日,YY 是指年份。另外,使用者甚至也可以使用像是 now + 时间间隔来弹性指定时间,其中的时间间隔可以是 minutes, hours, days, weeks  　　另外,使用者也可指定 today 或 tomorrow 来表示今天或明天。当指定了时间并按下 enter 之后,at 会进入交谈模式并要求输入指令或程式,当你输入完后按下 ctrl+D 即可完成所有动作,至于执行的结果将会寄回你的帐号中。 　　把计: 　　-V:印出版本编号  　　-q:使用指定的伫列(Queue)来储存,at 的资料是存放在所谓的 queue 中,使用者可以同时使用多个 queue,而 queue 的编号为 a, b, c... z 以及 A, B, ... Z 共 52 个  　　-m:即使程式/指令执行完成后没有输出结果, 也要寄封信给使用者  　　-f file:读入预先写好的命令档。使用者不一定要使用交谈模式来输入,可以先将所有的指定先写入档案后再一次读入  　　-l:列出所有的指定 (使用者也可以直接使用 atq 而不用 at -l)  　　-d:删除指定 (使用者也可以直接使用 atrm 而不用 at -d)  　　-v:列出所有已经完成但尚未删除的指定  　　例子: 　　三天后的下午 5 点锺执行 /bin/ls: 　　at 5pm + 3 days /bin/ls  　　三个星期后的下午 5 点锺执行 /bin/ls: 　　at 5pm + 2 weeks /bin/ls  　　明天的 17:20 执行 /bin/date: 　　at 17:20 tomorrow /bin/date  　　1999 年的最后一天的最后一分钟印出 the end of world !  　　at 23:59 12/31/1999 echo the end of world !  名称：cal  　　使用权限：所有使用者  　　使用方式：cal [-mjy] [month [year]]  　　说明：  　　显示日历。若只有一个参数,则代表年份(1-9999),显示该年的年历。年份必须全部写出：``cal 89\\ 将不会是显示 1989 年的年历。使用两个参数,则表示月份及年份。若没有参数则显示这个月的月历。  　　1752 年 9 月第 3 日起改用西洋新历,因这时大部份的国家都采用新历,有 10 天被去除,所以该月份的月历有些不同。在此之前为西洋旧历。  　　匡兜:  　　-m:以星期一为每周的第一天方式显示。  　　-j:以凯撒历显示,即以一月一日起的天数显示。  　　-y:显示今年年历。  　　范例：  　　cal:显示本月的月历。 　　[root@mylinux /root]# date  　　Tue Aug 15 08:00:18 CST 2000  　　[root@mylinux /root]# cal  　　... 　　cal 2001:显示公元 2001 年年历。 　　[root@mylinux /root]# cal 2001  　　...     cal 5 2001:显示公元 2001 年 5 月月历。 　　[root@mylinux /root]# cal 5 2001  名称:crontab  　　使用权限:所有使用者  　　使用方式: 　　crontab [ -u user ] filecrontab [ -u user ] { -l | -r | -e }  　　说明: 　　crontab 是用来让使用者在固定时间或固定间隔执行程式之用,换句话说,也就是类似使用者的时程表。-u user 是指设定指定 user 的时程表,这个前提是你必须要有其权限(比如说是 root)才能够指定他人的时程表。如果不使用 -u user 的话,就是表示设定自己的时程表。  　　参数: 　　-e:执行文字编辑器来设定时程表,内定的文字编辑器是 VI,如果你想用别的文字编辑器,则请先设定 VISUAL 环境变数来指定使用那个文字编辑器(比如说 setenv VISUAL joe)  　　-r:删除目前的时程表  　　-l:列出目前的时程表  　　时程表的格式如下: 　　f1 f2 f3 f4 f5 program  　　其中 f1 是表示分钟,f2 表示小时,f3 表示一个月份中的第几日,f4 表示月份,f5 表示一个星期中的第几天。program 表示要执行的程式。  　　当 f1 为 * 时表示每分钟都要执行 program,f2 为 * 时表示每小时都要执行程式,其余类推  　　当 f1 为 a-b 时表示从第 a 分钟到第 b 分钟这段时间内要执行,f2 为 a-b 时表示从第 a 到第 b 小时都要执行,其余类推  　　当 f1 为 */n 时表示每 n 分钟个时间间隔执行一次,f2 为 */n 表示每 n 小时个时间间隔执行一次,其余类推  　　当 f1 为 a, b, c,... 时表示第 a, b, c,... 分钟要执行,f2 为 a, b, c,... 时表示第 a, b, c...个小时要执行,其余类推  　　使用者也可以将所有的设定先存放在档案 file 中,用 crontab file 的方式来设定时程表。  　　例子: 　　每月每天每小时的第 0 分钟执行一次 /bin/ls: 　　0 7 * * * /bin/ls  　　在 12 月内, 每天的早上 6 点到 12 点中,每隔 20 分钟执行一次 /usr/bin/backup: 　　0 6-12/3 * 12 * /usr/bin/backup  　　周一到周五每天下午 5:00 寄一封信给 alex@domain.name: 　　0 17 * * 1-5 mail -s \"hi\" alex@domain.name < /tmp/maildata  　　每月每天的午夜 0 点 20 分, 2 点 20 分, 4 点 20 分....执行 echo \"haha\"  　　20 0-23/2 * * * echo \"haha\"  　　注意: 　　当程式在你所指定的时间执行后,系统会寄一封信给你,显示该程式执行的内容,若是你不希望收到这样的信,请在每一行空一格之后加上 > /dev/null 2>&1 即可。 名称:sleep  　　使用权限:所有使用者  　　使用方式:sleep [--help] [--version] number[smhd]  　　说明:sleep 可以用来将目前动作延迟一段时间  　　参数说明: 　　--help:显示辅助讯息  　　--version:显示版本编号  　　number:时间长度,后面可接 s,m,h 或 d  　　其中 s 为秒,m 为 分钟,h 为小时,d 为日数  　　例子: 　　显示目前时间后延迟 1 分钟,之后再次显示时间: 　　date;sleep 1m;date  　　名称： finger  　　使用权限： 所有使用者  　　使用方式： finger [options] user[@address]  　　说明：finger 可以让使用者查询一些其他使用者的资料。     范例：下列指令可以查询本机管理员的资料：  　　finger root  名称：last  　　使用权限：所有使用者  　　使用方式：shell>> last [options]  　　说明：显示系统开机以来获是从每月初登入者的讯息  　　把计:  　　-R 省略 hostname 的栏位  　　-num 展示前 num 个  　　username 展示 username 的登入讯息  　　tty 限制登入讯息包含终端机代号  　　范例：  　　shell>> last -R -2  　名称:write  　　使用权限:所有使用者  　　使用方式: 　　write user [ttyname]  　　说明:传讯息给其他使用者  　　把计: 　　user:预备传讯息的使用者帐号  　　ttyname:如果使用者同时有两个以上的 tty 连线,可以自行选择合适的 tty 传讯息  　　例子.1: 　　传讯息给 Rollaend,此时 Rollaend 只有一个连线: 　　write Rollaend      接下来就是将讯息打上去,结束请按 ctrl+c  　　例子.2 :传讯息给 Rollaend,Rollaend 的连线有 pts/2,pts/3: 　　write Rollaend pts/2 　　接下来就是将讯息打上去,结束请按 ctrl+c  　　注意:若对方设定 mesg n,则此时讯席将无法传给对方  名称：expr  　　使用权限：所有使用者  　　### 字串长度  　　shell>> expr length \"this is a test\"  　　14  　　### 数字商数  　　shell>> expr 14 % 9  　　5  　　### 从位置处抓取字串  　　shell>> expr substr \"this is a test\" 3 5  　　is is  　　### 数字串 only the first character  　　shell>> expr index \"testforthegame\" e  　　2  　　### 字串真实重现  　　shell>> expr quote thisisatestformela  　　thisisatestformela  指令：clear  　　用途：清除萤幕用。  　　使用方法：在 console 上输入 clear。 ","title":"linux常用的命令大全总结"},{"content":"linux下sqlplus不能使用上下键来调用以前输入过的命令，如果想使用这个功能，须要安装个rlwrap，设置如下： 安装rlwrap： #tar -zxvf rlwrap-0.37.tar.gz #cd rlwrap-0.37 #./configure #make install   #su - oracle [oracle@db ~]$vi ./.bash_profile 添加alias sqlplus='rlwrap sqlplus' 这样就可以在linux上可以使用rlwrap来为sqlplus增加历史回显功能。 rlwrap下载地址http://download.csdn.net/detail/waterxcfg304/4922640","title":"Linux下增加sqlplus上下键翻动功能"},{"content":"其实，查看的方法有很多种，多数是借助于第三方工具实现的小工具，本质上是一样的。 windows 下命令行方法： 比如要查看8080端口被哪个程序占用了，windows命令行窗口下执行：运行--cmd netstat -aon|findstr \"8080\" 输出：TCP 127.0.0.1:80 0.0.0.0:0 LISTENING 2448 端口被进程号为2448的进程占用，继续执行下面命令： tasklist|findstr \"2448\" 输出：thread.exe 2016 Console 0 16,064 K 表示thread.exe程序占用了端口8080 linux 下命令行方法： netstat -nlptu |awk '{print $4,$7}' | grep 80 转载请注明来自Master.R（石硕）的CSDN博客：blog.csdn.net/shishuo365  如有疑问请发邮件shishuo365#126.com（将#更换为@）","title":"如何查看一个指定端口被哪个程序使用"},{"content":"  shell字符串的截取的问题： 一、Linux shell 截取字符变量的前8位，有方法如下： 　　1.expr substr “$a” 1 8 　　2.echo $a|awk ‘{print substr(,1,8)}’ 　　3.echo $a|cut -c1-8 　　4.expr $a : ‘\\(.\\\\).*’ 　　5.echo $a|dd bs=1 count=8 2>/dev/null 二、按指定的字符串截取 　　1、第一种方法: ${varible##*string} 从左向右截取最后一个string后的字符串 ${varible#*string}从左向右截取第一个string后的字符串 ${varible%%string*}从右向左截取最后一个string后的字符串 ${varible%string*}从右向左截取第一个string后的字符串 “*”只是一个通配符可以不要 例子： $ MYVAR=foodforthought.jpg $ echo ${MYVAR##*fo} rthought.jpg $ echo ${MYVAR#*fo} odforthought.jpg 　　2、第二种方法：${varible:n1:n2}:截取变量varible从n1到n2之间的字符串。 可以根据特定字符偏移和长度，使用另一种形式的变量扩展，来选择特定子字符串。试着在 bash 中输入以下行： $ EXCLAIM=cowabunga $ echo ${EXCLAIM:0:3} cow $ echo ${EXCLAIM:3:7} abunga 这种形式的字符串截断非常简便，只需用冒号分开来指定起始字符和子字符串长度。 三、按照指定要求分割： 比如获取后缀名 ls -al | cut -d “.” -f2  一、构造字符串 直接构造 STR_ZERO=hello STR_FIRST=\"i am a string\" STR_SECOND='success' 重复多次 #repeat the first parm($1) by $2 times strRepeat() { local x=$2 if [ \"$x\" == \"\" ]; then x=0 fi local STR_TEMP=\"\" while [ $x -ge 1 ]; do STR_TEMP=`printf \"%s%s\" \"$STR_TEMP\" \"$1\"` x=`expr $x - 1` done echo $STR_TEMP } 举例： STR_REPEAT=`strRepeat \"$USER_NAME\" 3` echo \"repeat = $STR_REPEAT\" 二、赋值与拷贝 直接赋值 与构造字符串一样 USER_NAME=terry 从变量赋值 ALIASE_NAME=$USER_NAME 三、联接 直接联接两个字符串 STR_TEMP=`printf \"%s%s\" \"$STR_ZERO\" \"$USER_NAME\"` 使用printf可以进行更复杂的联接 四、求长 求字符数(char) COUNT_CHAR=`echo \"$STR_FIRST\" | wc -m` echo $COUNT_CHAR 求字节数(byte) COUNT_BYTE=`echo \"$STR_FIRST\" | wc -c` echo $COUNT_BYTE 求字数(word) COUNT_WORD=`echo \"$STR_FIRST\" | wc -w` echo $COUNT_WORD 五、比较 相等比较 str1 = str2 不等比较 str1 != str2 举例： if [ \"$USER_NAME\" = \"terry\" ]; then echo \"I am terry\" fi 小于比较 #return 0 if the two string is equal, return 1 if $1 < $2, else 2strCompare() { local x=0 if [ \"$1\" != \"$2\" ]; then x=2 localTEMP=`printf \"%s\\n%s\" \"$1\" \"$2\"` local TEMP2=`(echo \"$1\"; echo \"$2\") |sort` if [ \"$TEMP\" = \"$TEMP2\" ]; then x=1 fi fi echo $x } 六、测试 判空 -z str 判非空 -n str 是否为数字 # return 0 if the string is num, otherwise 1 strIsNum() { local RET=1 if [ -n \"$1\" ]; then local STR_TEMP=`echo \"$1\" | sed 's/[0-9]//g'` if [ -z \"$STR_TEMP\" ]; then RET=0 fi fi echo $RET } 举例： if [ -n \"$USER_NAME\" ]; then echo \"my name is NOT empty\" fi echo `strIsNum \"9980\"` 七、分割 以符号＋为准，将字符分割为左右两部分 使用sed 举例： 命令 date --rfc-3339 seconds 的输出为 2007-04-14 15:09:47+08:00 取其＋左边的部分 date --rfc-3339 seconds | sed 's/+[0-9][0-9]:[0-9][0-9]//g' 输出为 2007-04-14 15:09:47 取+右边的部分 date --rfc-3339 seconds | sed 's/.*+//g' 输出为 08:00 以空格为分割符的字符串分割 使用awk 举例： STR_FRUIT=\"Banana 0.89 100\" 取第3字段 echo $STR_FRUIT | awk '{ print $3; }' 八、子字符串 字符串1是否为字符串2的子字符串 # return 0 is $1 is substring of $2, otherwise 1 strIsSubstring() { local x=1 case \"$2\" in *$1*) x=0;; esac echo $x }   在做shell批处理程序时候，经常会涉及到字符串相关操作。有很多命令语句，如：awk,sed都可以做字符串各种操作。 其实shell内置一系列操作符号，可以达到类似效果，大家知道，使用内部操作符会省略启动外部程序等时间，因此速度会非常的快。   一、判断读取字符串值 表达式 含义 ${var} 变量var的值, 与$var相同     ${var-DEFAULT} 如果var没有被声明, 那么就以$DEFAULT作为其值 * ${var:-DEFAULT} 如果var没有被声明, 或者其值为空, 那么就以$DEFAULT作为其值 *     ${var=DEFAULT} 如果var没有被声明, 那么就以$DEFAULT作为其值 * ${var:=DEFAULT} 如果var没有被声明, 或者其值为空, 那么就以$DEFAULT作为其值 *     ${var+OTHER} 如果var声明了, 那么其值就是$OTHER, 否则就为null字符串 ${var:+OTHER} 如果var被设置了, 那么其值就是$OTHER, 否则就为null字符串     ${var?ERR_MSG} 如果var没被声明, 那么就打印$ERR_MSG * ${var:?ERR_MSG} 如果var没被设置, 那么就打印$ERR_MSG *     ${!varprefix*} 匹配之前所有以varprefix开头进行声明的变量 ${!varprefix@} 匹配之前所有以varprefix开头进行声明的变量 加入了“*”  不是意思是： 当然, 如果变量var已经被设置的话, 那么其值就是$var. [chengmo@localhost ~]$ echo ${abc-'ok'} ok [chengmo@localhost ~]$ echo $abc [chengmo@localhost ~]$ echo ${abc='ok'} ok [chengmo@localhost ~]$ echo $abc ok   如果abc 没有声明“=\" 还会给abc赋值。 [chengmo@localhost ~]$ var1=11;var2=12;var3= [chengmo@localhost ~]$ echo ${!v@}            var1 var2 var3 [chengmo@localhost ~]$ echo ${!v*} var1 var2 var3   ${!varprefix*}与${!varprefix@}相似，可以通过变量名前缀字符，搜索已经定义的变量,无论是否为空值。   二、字符串操作（长度，读取，替换） 表达式 含义 ${#string} $string的长度     ${string:position} 在$string中, 从位置$position开始提取子串 ${string:position:length} 在$string中, 从位置$position开始提取长度为$length的子串     ${string#substring} 从变量$string的开头, 删除最短匹配$substring的子串 ${string##substring} 从变量$string的开头, 删除最长匹配$substring的子串 ${string%substring} 从变量$string的结尾, 删除最短匹配$substring的子串 ${string%%substring} 从变量$string的结尾, 删除最长匹配$substring的子串     ${string/substring/replacement} 使用$replacement, 来代替第一个匹配的$substring ${string//substring/replacement} 使用$replacement, 代替所有匹配的$substring ${string/#substring/replacement} 如果$string的前缀匹配$substring, 那么就用$replacement来代替匹配到的$substring ${string/%substring/replacement} 如果$string的后缀匹配$substring, 那么就用$replacement来代替匹配到的$substring     说明：\"* $substring”可以是一个正则表达式.   1.长度 [web97@salewell97 ~]$ test='I love china' [web97@salewell97 ~]$ echo ${#test} 12 ${#变量名}得到字符串长度   2.截取字串 [chengmo@localhost ~]$ test='I love china' [chengmo@localhost ~]$ echo ${test:5}     e china [chengmo@localhost ~]$ echo ${test:5:10} e china ${变量名:起始:长度}得到子字符串   3.字符串删除 [chengmo@localhost ~]$ test='c:/windows/boot.ini' [chengmo@localhost ~]$ echo ${test#/} c:/windows/boot.ini [chengmo@localhost ~]$ echo ${test#*/} windows/boot.ini [chengmo@localhost ~]$ echo ${test##*/} boot.ini [chengmo@localhost ~]$ echo ${test%/*} c:/windows [chengmo@localhost ~]$ echo ${test%%/*} ${变量名#substring正则表达式}从字符串开头开始配备substring,删除匹配上的表达式。 ${变量名%substring正则表达式}从字符串结尾开始配备substring,删除匹配上的表达式。 注意：${test##*/},${test%/*} 分别是得到文件名，或者目录地址最简单方法。 4.字符串替换 [chengmo@localhost ~]$ test='c:/windows/boot.ini' [chengmo@localhost ~]$ echo ${test/\\//\\\\} c:\\windows/boot.ini [chengmo@localhost ~]$ echo ${test//\\//\\\\} c:\\windows\\boot.ini   ${变量/查找/替换值} 一个“/”表示替换第一个，”//”表示替换所有,当查找中出现了：”/”请加转义符”\\/”表示。 三、性能比较 在shell中，通过awk,sed,expr 等都可以实现，字符串上述操作。下面我们进行性能比较。 [chengmo@localhost ~]$ test='c:/windows/boot.ini'                       [chengmo@localhost ~]$ time for i in $(seq 10000);do a=${#test};done;            real    0m0.173s user    0m0.139s sys     0m0.004s [chengmo@localhost ~]$ time for i in $(seq 10000);do a=$(expr length $test);done;       real    0m9.734s user    0m1.628s 速度相差上百倍，调用外部命令处理，与内置操作符性能相差非常大。在shell编程中，尽量用内置操作符或者函数完成。使用awk,sed类似会出现这样结果。","title":"shell字符串的截取"},{"content":"  前言：使用eclipse开发嵌入式linux程序和pc linux程序几乎没有区别，并且使用eclipse图形界面的集成开发环境上手简单，方便学习，这里就教大家开发第一个嵌入式linux程序，程序功能就是测试上次写好的LED驱动程序。 1.新建工程 输入工程名称，选择可执行程序，选择cross GCC,下一步，选择填写arm-linux-gcc的路径，这一步按照自己的实际情况进行填写 点击完成即可 2.输入代码并编译 代码很简单的，只是一个实例 /*****************************************************************************************************************文件名\t\t:\tmain.c*主要功能\t\t:\tLED测试*作者       \t:\t异灵元（cp1300@139.com）*创建时间\t\t:\t2012下午11:52:59*最后修改时间\t:\t2012下午11:52:59*说明\t\t:\t使用OK6410开发板，测试自己写的LED驱动****************************************************************************************************************/#include <stdio.h>#include <stdlib.h>#include <unistd.h>#include <fcntl.h>#include <sys/ioctl.h>#include <unistd.h>int main(void){\tint fd;\tint retval;\tunsigned char led;\t//LED测试\tprintf(\"LED test...\\n\");\tfd = open(\"/dev/OK6410_LED\",O_RDWR);\t\t//open led,注意：是驱动模块名，不是驱动文件名\tif(fd == -1)\t{\t\tprintf(\"open led error!\\n\");\t\texit(-1);\t}\telse\t{\t\tprintf(\"open led ok!\\n\");\t}\twhile(1)\t{\t\tfor(retval = 0;retval < 4;retval ++)\t\t{\t\t\tled = 1 << retval;\t\t\tled = ~led;\t\t\twrite(fd,&led,sizeof((unsigned char)1));\t\t\t//read(fd,&led,sizeof((unsigned char)1));\t\t\t//printf(\"LED = 0x%X\\n\",led);\t\t\tusleep(1000 * 100);\t//100MS\t\t}\t\tfor(retval = 2;retval > 0;retval --)\t\t{\t\t\tled = 1 << retval;\t\t\tled = ~led;\t\t\twrite(fd,&led,sizeof((unsigned char)1));\t\t\t//read(fd,&led,sizeof((unsigned char)1));\t\t\t//printf(\"LED = 0x%X\\n\",led);\t\t\tusleep(1000 * 100);\t//100MS\t\t}\t}\tclose(fd);\texit(0);} 编写完代码后编译，一般先保存，设置了编译前自动保存只要按下 Ctrl + B 即可，编译完成后会生成相关的可执行程序，但是这个程序只能在ARM LINUX上执行，不能在PC上面执行。 3.执行程序 将程序复制到开发板执行，如果挂载了NFS就可以直接运行了，运行结果如下，当然还可以看到开发板的灯在来回跑动。。。 有的时候程序无法运行，需要添加可执行属性  执行：chmod +x xxxx      xxxx即为编译好的可执行程序名称。","title":"【嵌入式linux】（第六步）：使用eclipse集成开发环境开发第一个嵌入式Linux程序，并测试LED驱动"},{"content":"       SDA，SCL都为高时，设备处于空闲状态。        SDA由高变低时，是开始。        SCL为高时，SDA由低变高，是结束。        仅当SCL为高时，SDA上的数据才有效。就是说当主设备准备写数据时，先令SCL为低（由第一句话可知这时SDA无效），然后把要写的数据，高或低（1或0）放到SDA上，这时令SCL为高（由第一句话可知这时SDA有效），数据就这样从主设备写进了从设备（从设备因为检测到SCL的上升沿，从而马上读取SDA上的数据）。当主设备要读数据时，先令SCL为低（由第一句话可知这时SDA无效），然后令SCL为高（由第一句话可知这时SDA有效），这时主设备可读取SDA上的数据，1或0（从设备因为检测到SCL的上升沿，从而马上在SDA上输出数据）。一般读写完一位（bit）后，都应该令SCL为低，以使SDA无效，以免发生错误的读写。                接收完8位（bit）后，要发送应答位，0为应答，1为无应答。        弄清iic的时序后，iic通信就不再是难点了。至于iic的其它知识点就不在此多说了。","title":"千言万语IIC时序就五句话"},{"content":"1. FORTIFY_SOURCE（buffer over-flow 防御） 参考：http://fedoraproject.org/wiki/Security/Features#Compile_Time_Buffer_Checks_.28FORTIFY_SOURCE.29 http://gcc.gnu.org/ml/gcc-patches/2004-09/msg02055.html 此选项用于 gcc 在编译阶段检查是否存在缓冲区溢出问题。相关的原理及说明见上面的两个网址。此处仅举几个简单的例子说明其作用。 示例程序如下：   1 #include <stdio.h>   2 #include <string.h>   3    4 int main()   5 {   6         char str[3];   7    8         strcpy(str, \"abcde\");   //这里有问题   9   10         return 0;  11 } 首先看看不带 FORTIFY_SOURCE 选项的结果： [tom@localhost code]$ gcc -O2 -o test test.c [tom@localhost code]$ ll 可见，不带 FORTIFY_SOURCE 选项的情况下，编译器无法检测到这类问题； 在看看带 FORTIFY_SOURCE 选项的编译结果（注意该选项只能和 -O 选项一起使用，且优化级别大于 0）： [tom@localhost code]$ gcc -O2 -D_FORTIFY_SOURCE=2（1 或者 2） -o test test.c In file included from /usr/include/string.h:642:0,                  from test.c:2: In function 'strcpy',     inlined from 'main' at test.c:8:8: /usr/include/bits/string3.h:105:3: warning: call to __builtin___memcpy_chk will always overflow destination buffer [enabled by default] [tom@localhost code]$  可以看到，已经报出来在源码的第 8 行存在溢出问题。 需要注意的是这个选项只能辅助检测出一部分缓冲区溢出的问题，而不是所有的。 2. gcc的pie和fpie选项 （转自：http://blog.sina.com.cn/s/blog_ae4e800401014pcg.html） Position-Independent-Executable是Binutils,glibc和gcc的一个功能，能用来创建介于共享库和通常可执行代码之间的代码�能像共享库一样可重分配地址的程序，这种程序必须连接到Scrt1.o。标准的可执行程序需要固定的地址，并且只有被装载到这个地址时，程序才能正确执行。PIE能使程序像共享库一样在主存任何位置装载，这需要将程序编译成位置无关，并链接为ELF共享对象。 引入PIE的原因是让程序能装载在随机的地址，通常情况下，内核都在固定的地址运行，如果能改用位置无关，那攻击者就很难借助系统中的可执行码实施攻击了。类似缓冲区溢出之类的攻击将无法实施。而且这种安全提升的代价很小 谈到PIE就不得不说说Pax和Grsec内核。这两个东西都是为了构建坚不可摧到安全系统而准备的。PaX是Linux内核安全增强补丁，它能在两方面保证安全性，一是ASLR(Address Space Layout Randomization,地址空间分布随机化)，这是一种将所有数据装载到内存时都随机化地址的方式，当使用PIE选项编译应用时，PaX能将应用的地址做随机加法；二是能提供不可执行的内存空间，这样就能使得攻击者放入内存中的恶意代码不可执行。不过PaX官网上能支持的最新内核是2.6.27，已经是一年前的更新了。Grsec也时类似的内核补丁，更新较为频繁能支持最新的2.6.32内核。这两种方式都能将内核完全位置无关，除了Grub和Glibc中无法位置无关的汇编码。 PIE最早由RedHat的人实现，他在连接起上增加了-pie选项，这样使用-fPIE编译的对象就能通过连接器得到位置无关可执行程序。fPIE和fPIC有些不同。可以参考Gcc和Open64中的-fPIC选项. gcc中的-fpic选项，使用于在目标机支持时，编译共享库时使用。编译出的代码将通过全局偏移表(Global Offset Table)中的常数地址访存，动态装载器将在程序开始执行时解析GOT表项(注意，动态装载器操作系统的一部分，连接器是GCC的一部分).而gcc中的-fPIC选项则是针对某些特殊机型做了特殊处理，比如适合动态链接并能避免超出GOT大小限制之类的错误。而Open64仅仅支持不会导致GOT表溢出的PIC编译。 gcc中的-fpie和-fPIE选项和fpic及fPIC很相似，但不同的是，除了生成为位置无关代码外，还能假定代码是属于本程序。通常这些选项会和GCC链接时的-pie选项一起使用。fPIE选项仅能在编译可执行码时用，不能用于编译库。所以，如果想要PIE的程序，需要你除了在gcc增加-fPIE选项外，还需要在ld时增加-pie选项才能产生这种代码。即gcc -fpie -pie来编译程序。单独使用哪一个都无法达到效果。 你可以使用file命令来查看当前的可执行文件是不是PIE的。 下面是本博编译helloword的显示。可以看出，可执行文件属性从executable变成了shared object. $ gcc  helloworld.c $ file a.out a.out: ELF 32-bit LSB executable, Intel 80386, version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 2.6.9, not stripped $ gcc -fpie -pie helloworld.c $ file a.out a.out: ELF 32-bit LSB shared object, Intel 80386, version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 2.6.9, not stripped 接下来，我们就能实验了，使用strace命令来查看这两个a.out执行情况了。关于strace命令，可以参考strace命令介绍 在博主电脑上，有PIE时，执行第一个brk(0)系统调用时，返回的地址一直是变化的。而无PIE时，brk(O)系统调用返回地址一直不变（红色部分）。 [tom@localhost code]$ strace helloworld strace: Can't stat 'helloworld': No such file or directory [tom@localhost code]$ strace ./helloworld  execve(\"./helloworld\", [\"./helloworld\"], [/* 25 vars */]) = 0 brk(0)                                  = 0x7f98a5278000 [tom@localhost code]$ strace ./helloworld  execve(\"./helloworld\", [\"./helloworld\"], [/* 25 vars */]) = 0 brk(0)                                  = 0x7f9b4cebb000 注： linux系统调用brk()： linux系统内部分配内存的系统调用，malloc()其实也是调用的brk().直接修改堆的大小，返回新内存区域的结束地址。","title":"gcc 若干安全相关选项"},{"content":"Installing OpenShift Client Tools The OpenShift Client tools known as rhc are built and packaged using the Ruby programming language. OpenShift integrates with the Git version control system to provide powerful, decentralized version control for your application source code. OpenShift rhc can be run on any operating system with Ruby 1.8.7 or higher if you have the requisite user permissions to install programs.  Instructions for specific operating systems are provided below. It is assumed that you are running the commands from a command line window, such as Command Prompt, or Terminal.  If you are usingRuby Version Manager (rvm) see the instructions below. Windows RubyInstaller 1.9 provides the best experience for installing Ruby on Windows XP, Vista, and Windows 7.  Download the newest version fromthe download page and launch the installer. Important: During the installation you can accept all of the defaults, but it is mandatory that you select the \"Add Ruby executables to your PATH\" check box in order to run Ruby from the command line. After the installation is completed, to verify that the installation is working run: C:\\Program Files\\> ruby -e 'puts \"Welcome to Ruby\"'Welcome to Ruby If the 'Welcome to Ruby' message does not display, the Ruby executable may not have been added to the path.  Restart the installation process and ensure the \"Add Ruby executables to your PATH\" check box is selected. Installing Git The next step is to install Git for Windows so that you can synchronise your local application source and your OpenShift application.  Git for Windows offers the easiest Git experience on the Windows operating system and is the recommended default - if you use another version of Git please ensure it can be executed from the command line and continue to the next section. Download and install the latest version of Git for Windows.  Ensure that Git is added to your PATH so that it can be run from the command line.  After the installation is completed, to verify that Git is correctly configured run: C:\\Program Files\\> git --versiongit version 1.7.11.msysgit.1 Installing the OpenShift gem After Ruby and Git are correctly installed, use the RubyGems package manager (included in Ruby) to install the OpenShift client tools. Run: C:\\Program Files\\> gem install rhc RubyGems downloads and installs the rhc gem from www.rubygems.org/gems/rhc.  The installation typically proceeds without errors.  After installation is complete, run: C:\\Program Files\\> rhc The OpenShift interactive setup wizard displays and prompts you to complete the rest of the process.  If you cannot run OpenShift client tools at this point, please contact us onIRC or post inour forums for more assistance.   2. Setup your environment Using your OpenShift login and password, run rhc setup to connect to OpenShift and create a unique namespace for your applications. $ rhc setupStarting Interactive Setup for OpenShift's command line interfaceWe'll help get you setup with just a couple of questions.To connect to openshift.redhat.com enter your OpenShift login (email or Red Hat login id): The wizard will help you upload your SSH keys so you can communicate with Git, check to see if you are missing any required configuration, and then help you create a domain name. On OpenShift, domain names make up part of your app's url. They are also unique across all OpenShift users so choose wisely and be creative! When the wizard runs it creates a configuration file in <your home directory>/.openshift/express.conf which includes your login id. If you ever need to set your machine up a second time, just run rhc setup again. 3. Create your first application Now you can create an application. $ rhc app create -a myapp -t php-5.3Password: (Enter your account password) This will create a remote git repository for your application, and clone it locally in your current directory. OpenShift offers many application stacks. Run rhc app create -h to see all of your options. Your application's domain name will be <your app name>-<your domain name>.rhcloud.com. So, the application created by the example commands would be located at myapp-mydomain.rhcloud.com Creating an application video walkthrough 4. Make a change, publish Getting an application running is only the first step. Now you are on the road to making it your own. Here's an example for the php framework. $ cd myapp$ vim php/index.php(Make a change...  :wq)$ git commit -a -m \"My first change\"$ git push Use whichever IDE or editor works best for you. Chances are, it'll have git support. Even if it doesn't, you're just two simple commands away from glory! Now, check your URL - your change will be live. Check out these great guides for deploying popular frameworks 5. Next steps While this has gotten you started, there is a lot more information out there to really get you going. Check out the following pages for videos, blogs, and tutorials: Videos Developer Center OpenShift on StackOverflow Forums Pricing        ","title":"openshift安装client工具，创建第一个app"},{"content":"Install and Setup PuTTY SSH Client for Windows Introduction PuTTY is a popular free SSH client for Windows.  This document will help you get putty installed and configured so that you can connect to your application with a click of a button. Download the PuTTY Installer The installer can be downloaded from the PuTTY download page Make sure you grab the latest stable release under the headers Binaries/A Windows installer for everything except PuTTYtel and will be named similar to putty-0.62-installer.exe. Running the Installer After you have installer downloaded open up the folder you downloaded it to in the File Explorer and double click on the icon to run the installer. Step 1: You will be greeted by the Welcome dialog.  You may click the Next > button to continue Step 2: The wizard will ask you to select a directory to install PuTTY to.  You should use the default and click the Next > button to continue. Step 3: The wizard will ask which folder you wish to put PuTTY into on the Start Menu.  You should use the default and click the Next > button to continue. Step 4: You will be asked addtional questions.  You can choose to have an icon placed on your desktop or on the Panel as a quick start button for easier access to PuTTY if you wish.  It is recommended that you keep the option for associating .ppk files checked.  You may click the Next > button to continue. Step 5: PuTTY is now ready to install.  You may click the Install button to start the installation process. Step 6: You are now down and may click the Finish button to exit the installer.  It is recommended that you read the README file for further information about PuTTY. Importing Your SSH Key It is assumed that you have already gone through the steps to create an SSH key to be used with OpenShift.  You may now import that key for use with PuTTY. Step 1: Launch PuTTYgen You need to launch PuTTYgen, the PuTTY key manager.  From the Start Menu type in putty in the search box.  A list of putty applications will show up.  Click on PuTTYgen.  On older versions of Windows navigate to the PuTTY folder and launch it from there. Step 2: Import the SSH Key Once PuTTYgen is started go to the Conversions menu and select the Import key item. Step 3: Select the SSH Key for Import A file dialog should pop up.  Navigate to the .ssh directory in your user folder C:\\Users\\<user name>\\.ssh and select the id_rsa key that was generated for you by rhc setup. Step 4: Save the Private Key as a .PPK File PuTTYgen will load your key and display it.  In this dialog press the Save private key button. Step 5: Select a Key Name Another file dialog will pop up for you to select where to save the key.  Again navigate to the .ssh directory in your user folder C:\\Users\\<user name>\\.ssh.  Name the key whatever you wish but make sure you do not overwrite any files in this directory.  Good names to use are default.ppk or id_rsa.ppk. You are now done with importing your SSH key and may close the PuTTYgen application. Configuring a Session to Connect to Your Application It is assumed that you have already created an application on OpenShift at this point and want to configure PuTTY so you can easily ssh to it. Step 1: Launch PuTTY If you selected the option to put an icon on the desktop or a button the start menu you may launch PuTTY from there.  Otherwise, click on the start menu and in the search box type in putty.  Select the PuTTY application to run.  On older versions of windows you may need to navigate to the PuTTY directory in the Start Menu and launch it from there. Step 2: Get the SSH Address You need to get the ssh address to enter into PuTTY.  The easiest way to find the SSH address is to go to the applications list page in the web console and click on your application to go to the details page.  Once on the details page you can click on the Want to log in to your application? link to expand the text.  This text includes the ssh command and the address.  In the next step you will want to copy this text but remove the ssh command from the front of the string. Step 3:  Enter the Address into PuTTY In the Session category, under the Host Name form past the text you copied from the previous step, remembering to remove the ssh command from the begining of the string. Step 4:  Associate Your SSH  Key with the Session In the Category tree, expand the Connection and then SSH categories and select Auth.  Here click on the Browse button and when the file dialog pops up, again navigate to the .ssh directory in your user folder C:\\Users\\<user name>\\.ssh and select the .ppk file you saved there. Step 5:  Save Your Session In the Category tree go back to the Session category.  In the Saved Sessions form name your session.  We recommend using the name of your application.  Click the save button and you should see it pop up in the list. Click the Open button to connect to your application. Now whenever you wish to connect to your app you can simply select your session in the list.  Click on the Load button and then click on the Open button. Go back to the SSH page for more information on the commands you can use inside of an SSH session.","title":"openshift安装PUTTY"},{"content":"1：Shuffle Error: Exceeded MAX_FAILED_UNIQUE_FETCHES; bailing-out Answer： 程序 里面需要打开多个文件 ，进行分析，系统一般默认数量是1024，（用ulimit -a可以看到）对于正常使用是够了，但是对于程序来讲，就太少了。 修改办法： 修改2个文件。         /etc/security/limits.conf vi /etc/security/limits.conf 加上： * soft nofile 102400 * hard nofile 409600     $cd /etc/pam.d/     $sudo vi login         添加        session    required     /lib/security/pam_limits.so 针对第一个问题 我纠正下答案： 这是reduce 预处理阶段shuffle时获取 已完成的map的输出失败次数超过上限造成的，上限默认为5。引起此问题的方式可能会有很多种，比如网络连接不正常，连接超时，带宽较差以及端口阻塞等。。。通常框架内网络情况较好是不会出现此错误的。  2：Too many fetch-failures  Answer: 出现这个问题主要是结点间的连通不够全面。 1) 检查 、/etc/hosts    要求本机ip 对应 服务 器名    要求要包含所有的服务器ip + 服务器名 2) 检查 .ssh/authorized_keys    要求包含所有服务器（包括其自身）的public key 3：处理速度特别的慢 出现map很快 但是reduce很慢 而且反复出现 reduce=0%  Answer: 结合第二点，然后 修改 conf/hadoop-env.sh 中的export HADOOP_HEAPSIZE=4000  4：能够启动 datanode ，但无法访问，也无法结束的错误 在重新格式化一个新的分布式 文件时，需要将你NameNode上所配置的dfs.name.dir这一namenode用来存放NameNode 持久存储名字空间及事务日志的本地 文件系统路径 删除，同时将各DataNode上的dfs.data .dir的路径 DataNode 存放块数据 的本地文件系统路径的目录也删除。如本此配置就是在NameNode上删除/home/hadoop/NameData，在DataNode上删除/home/hadoop/DataNode1和/home/hadoop/DataNode2。这是因为Hadoop 在 格式化一个新的分布式文件系统时，每个存储的名字空间都对应了建立时间的那个版本（可以查看/home/hadoop /NameData/current目录下的VERSION文件，上面记录了版本信息），在重新格式化新的分布式系统文件时，最好先删除NameData 目录。必须删除各DataNode的dfs.data.dir。这样才可以使namedode和datanode记录的信息版本对应。 注意：删除是个很危险的动作，不能确认的情况下不能删除！！做好删除的文件等通通备份！！ 5：java.io.IO Exception : Could not obtain block: blk_194219614024901469_1100 file=/user/hive/warehouse/src_20090724_log/src_20090724_log 出现这种情况大多是结点断了，没有连接上。 6：java.lang.OutOfMemoryError: Java heap space 出现这种异常，明显是jvm内存不够得原因，要修改所有的datanode的jvm内存大小。 Java -Xms1024m -Xmx4096m 一般jvm的最大内存使用应该为总内存大小的一半，我们使用的8G内存，所以设置为4096m，这一值可能依旧不是最优的值。 7：Hadoop添加节点的方法  自己实际添加节点过程： 1. 先在slave上配置好环境，包括ssh，jdk，相关config，lib，bin等的拷贝； 2. 将新的datanode的host加到集群namenode及其他datanode中去； 3. 将新的datanode的ip加到master的conf/slaves中； 4. 重启cluster,在cluster中看到新的datanode节点； 5. 运行bin/start-balancer.sh，这个会很耗时间 备注： 1. 如果不balance，那么cluster会把新的数据都存放在新的node上，这样会降低mr的工作效率； 2. 也可调用bin/start-balancer.sh 命令执行，也可加参数 -threshold 5    threshold 是平衡阈值，默认是10%，值越低各节点越平衡，但消耗时间也更长。 3. balancer也可以在有mr job的cluster上运行，默认dfs.balance.bandwidthPerSec很低，为1M/s。在没有mr job时，可以提高该设置加快负载均衡时间。 其他备注：  1. 必须确保slave的firewall已关闭; 2. 确保新的slave的ip已经添加到master及其他slaves的/etc/hosts中，反之也要将master及其他slave的ip添加到新的slave的/etc/hosts中 mapper及reducer个数  url地址： http://wiki.apache.org/hadoop/HowManyMapsAndReduces 较好的建议： The right number of reduces seems to be 0.95 or 1.75 multiplied by (<no. of nodes> * mapred.tasktracker.reduce.tasks.maximum).increasing the number of reduces increases the framework overhead, but increases load balancing and lowers the cost of failures.  <property>   <name>mapred.tasktracker.reduce.tasks.maximum<\/name>   <value>2<\/value>   <description>The maximum number of reduce tasks that will be run   simultaneously by a task tracker.   <\/description> <\/property> 8：单个node新加硬盘  1.修改需要新加硬盘的node的dfs.data.dir，用逗号分隔新、旧文件目录 2.重启dfs 9：同步hadoop 代码  hadoop-env.sh # host:path where hadoop code should be rsync'd from.  Unset by default. # export HADOOP_MASTER=master:/home/$USER/src/hadoop 10：用命令合并HDFS小文件  hadoop fs -getmerge <src> <dest> 11：重启reduce job方法  Introduced recovery of jobs when JobTracker restarts. This facility is off by default. Introduced config parameters \"mapred.jobtracker.restart.recover\", \"mapred.jobtracker.job.history.block.size\", and \"mapred.jobtracker.job.history.buffer.size\". 还未验证过。 12：IO写操作出现问题  0-1246359584298, infoPort=50075, ipcPort=50020):Got exception while serving blk_-5911099437886836280_1292 to /172.16.100.165: java.net.SocketTimeoutException: 480000 millis timeout while waiting for channel to be ready for write. ch : java.nio.channels.SocketChannel[connected local=/ 172.16.100.165:50010 remote=/172.16.100.165:50930]         at org.apache.hadoop.net.SocketIOWithTimeout.waitForIO(SocketIOWithTimeout.java:185)         at org.apache.hadoop.net.SocketOutputStream.waitForWritable(SocketOutputStream.java:159)         at org.apache.hadoop.net.SocketOutputStream.transferToFully(SocketOutputStream.java:198)         at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendChunks(BlockSender.java:293)         at org.apache.hadoop.hdfs.server.datanode.BlockSender.sendBlock(BlockSender.java:387)         at org.apache.hadoop.hdfs.server.datanode.DataXceiver.readBlock(DataXceiver.java:179)         at org.apache.hadoop.hdfs.server.datanode.DataXceiver.run(DataXceiver.java:94)         at java.lang.Thread.run(Thread.java:619) It seems there are many reasons that it can timeout, the example given in  HADOOP-3831 is a slow reading client. 解决办法：在hadoop-site.xml中设置dfs.datanode.socket.write.timeout=0试试；  My understanding is that this issue should be fixed in Hadoop 0.19.1 so that we should leave the standard timeout. However until then this can help resolve issues like the one you're seeing. 13：HDFS退服节点的方法  目前版本的dfsadmin的帮助信息是没写清楚的，已经file了一个bug了，正确的方法如下： 1. 将 dfs.hosts 置为当前的 slaves，文件名用完整路径，注意，列表中的节点主机名要用大名，即 uname -n 可以得到的那个。 2. 将 slaves 中要被退服的节点的全名列表放在另一个文件里，如 slaves.ex，使用 dfs.host.exclude 参数指向这个文件的完整路径 3. 运行命令 bin/hadoop dfsadmin -refreshNodes 4. web界面或 bin/hadoop dfsadmin -report 可以看到退服节点的状态是 Decomission in progress，直到需要复制的数据复制完成为止 5. 完成之后，从 slaves 里（指 dfs.hosts 指向的文件）去掉已经退服的节点 附带说一下 -refreshNodes 命令的另外三种用途：  2. 添加允许的节点到列表中（添加主机名到 dfs.hosts 里来） 3. 直接去掉节点，不做数据副本备份（在 dfs.hosts 里去掉主机名） 4. 退服的逆操作——停止 exclude 里面和 dfs.hosts 里面都有的，正在进行 decomission 的节点的退服，也就是把 Decomission in progress 的节点重新变为 Normal （在 web 界面叫 in service) 14：Hadoop添加节点的方法  自己实际添加节点过程： 1. 先在slave上配置好环境，包括ssh，jdk，相关config，lib，bin等的拷贝； 2. 将新的datanode的host加到集群namenode及其他datanode中去； 3. 将新的datanode的ip加到master的conf/slaves中； 4. 重启cluster,在cluster中看到新的datanode节点； 5. 运行bin/start-balancer.sh，这个会很耗时间 备注： 1. 如果不balance，那么cluster会把新的数据都存放在新的node上，这样会降低mr的工作效率； 2. 也可调用bin/start-balancer.sh 命令执行，也可加参数 -threshold 5    threshold 是平衡阈值，默认是10%，值越低各节点越平衡，但消耗时间也更长。 3. balancer也可以在有mr job的cluster上运行，默认dfs.balance.bandwidthPerSec很低，为1M/s。在没有mr job时，可以提高该设置加快负载均衡时间。 其他备注：  1. 必须确保slave的firewall已关闭; 2. 确保新的slave的ip已经添加到master及其他slaves的/etc/hosts中，反之也要将master及其他slave的ip添加到新的slave的/etc/hosts中 hadoop 学习借鉴  1. 解决hadoop OutOfMemoryError问题： <property>    <name>mapred.child.java.opts<\/name>    <value>-Xmx800M -server<\/value> <\/property> With the right JVM size in your hadoop-site.xml , you will have to copy this to all mapred nodes and restart the cluster. 或者：hadoop jar jarfile [main class] -D mapred.child.java.opts=-Xmx800M  2. Hadoop java.io.IOException: Job failed! at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1232) while indexing.  when i use nutch1.0,get this error: Hadoop java.io.IOException: Job failed! at org.apache.hadoop.mapred.JobClient.runJob(JobClient.java:1232) while indexing. 这个也很好解决： 可以删除conf/log4j.properties，然后可以看到详细的错误报告 我这儿出现的是out of memory 解决办法是在给运行主类org.apache.nutch.crawl.Crawl加上参数：-Xms64m -Xmx512m 你的或许不是这个问题，但是能看到详细的错误报告问题就好解决了 15：distribute cache使用  类似一个全局变量，但是由于这个变量较大，所以不能设置在config文件中，转而使用distribute cache 具体使用方法：(详见《the definitive guide》,P240) 1. 在命令行调用时：调用-files，引入需要查询的文件(可以是local file, HDFS file(使用hdfs://xxx?)), 或者 -archives (JAR,ZIP, tar等) % hadoop jar job.jar MaxTemperatureByStationNameUsingDistributedCacheFile \\   -files input/ncdc/metadata/stations-fixed-width.txt input/ncdc/all output 2. 程序中调用：    public void configure(JobConf conf) {       metadata = new NcdcStationMetadata();       try {         metadata.initialize(new File(\"stations-fixed-width.txt\"));       } catch (IOException e) {         throw new RuntimeException(e);       }    } 另外一种间接的使用方法：在hadoop-0.19.0中好像没有 调用addCacheFile()或者addCacheArchive()添加文件， 使用getLocalCacheFiles() 或 getLocalCacheArchives() 获得文件 hadoop的job显示web  There are web-based interfaces to both the JobTracker (MapReduce master) and NameNode (HDFS master) which display status pages about the state of the entire system. By default, these are located at [WWW] http://job.tracker.addr:50030/and [WWW] http://name.node.addr:50070/ .  16：hadoop监控  OnlyXP(52388483) 131702 用nagios作告警，ganglia作监控图表即可 17:status of 255 error  错误类型： java.io.IOException: Task process exit with nonzero status of 255.         at org.apache.hadoop.mapred.TaskRunner.run(TaskRunner.java:424) 错误原因：  Set mapred.jobtracker.retirejob.interval and mapred.userlog.retain.hours to higher value. By default, their values are 24 hours. These might be the reason for failure, though I'm not sure split size  FileInputFormat input splits: (详见 《the definitive guide》P190) mapred.min.split.size: default=1, the smallest valide size in bytes for a file split. mapred.max.split.size: default=Long.MAX_VALUE, the largest valid size. dfs.block.size: default = 64M, 系统中设置为128M。 如果设置 minimum split size > block size, 会增加块的数量。(猜想从其他节点拿去数据的时候，会合并block，导致block数量增多)  如果设置maximum split size < block size, 会进一步拆分block。 split size = max(minimumSize, min(maximumSize, blockSize));  其中 minimumSize < blockSize < maximumSize. 18：sort by value  hadoop 不提供直接的sort by value方法，因为这样会降低mapreduce性能。 但可以用组合的办法来实现，具体实现方法见《the definitive guide》, P250 基本思想： 1. 组合key/value作为新的key； 2. 重载partitioner，根据old key来分割； conf.setPartitionerClass(FirstPartitioner.class); 3. 自定义keyComparator：先根据old key排序，再根据old value排序； conf.setOutputKeyComparatorClass(KeyComparator.class); 4. 重载GroupComparator, 也根据old key 来组合；  conf.setOutputValueGroupingComparator(GroupComparator.class); 19:small input files的处理  对于一系列的small files作为input file，会降低hadoop效率。 有3种方法可以将small file合并处理： 1. 将一系列的small files合并成一个sequneceFile，加快mapreduce速度。 详见WholeFileInputFormat及SmallFilesToSequenceFileConverter,《the definitive guide》, P194 2. 使用CombineFileInputFormat集成FileinputFormat，但是未实现过； 3. 使用hadoop archives(类似打包)，减少小文件在namenode中的metadata内存消耗。(这个方法不一定可行，所以不建议使用)    方法：    将/my/files目录及其子目录归档成files.har，然后放在/my目录下    bin/hadoop archive -archiveName files.har /my/files /my        查看files in the archive:    bin/hadoop fs -lsr har://my/files.har 20：skip bad records  JobConf conf = new JobConf(ProductMR.class); conf.setJobName(\"ProductMR\"); conf.setOutputKeyClass(Text.class); conf.setOutputValueClass(Product.class); conf.setMapperClass(Map.class); conf.setReducerClass(Reduce.class); conf.setMapOutputCompressorClass(DefaultCodec.class); conf.setInputFormat(SequenceFileInputFormat.class); conf.setOutputFormat(SequenceFileOutputFormat.class); String objpath = \"abc1\"; SequenceFileInputFormat.addInputPath(conf, new Path(objpath)); SkipBadRecords.setMapperMaxSkipRecords(conf, Long.MAX_VALUE); SkipBadRecords.setAttemptsToStartSkipping(conf, 0); SkipBadRecords.setSkipOutputPath(conf, new Path(\"data/product/skip/\")); String output = \"abc\"; SequenceFileOutputFormat.setOutputPath(conf, new Path(output)); JobClient.runJob(conf); For skipping failed tasks try : mapred.max.map.failures.percent  21:restart 单个datanode  如果一个datanode 出现问题，解决之后需要重新加入cluster而不重启cluster，方法如下： bin/hadoop-daemon.sh start datanode bin/hadoop-daemon.sh start jobtracker 22：reduce exceed 100%  \"Reduce Task Progress shows > 100% when the total size of map outputs (for a single reducer) is high \" 造成原因： 在reduce的merge过程中，check progress有误差，导致status > 100%，在统计过程中就会出现以下错误：java.lang.ArrayIndexOutOfBoundsException: 3         at org.apache.hadoop.mapred.StatusHttpServer$TaskGraphServlet.getReduceAvarageProgresses(StatusHttpServer.java:228)         at org.apache.hadoop.mapred.StatusHttpServer$TaskGraphServlet.doGet(StatusHttpServer.java:159)         at javax.servlet.http.HttpServlet.service(HttpServlet.java:689)         at javax.servlet.http.HttpServlet.service(HttpServlet.java:802)         at org.mortbay.jetty.servlet.ServletHolder.handle(ServletHolder.java:427)         at org.mortbay.jetty.servlet.WebApplicationHandler.dispatch(WebApplicationHandler.java:475)         at org.mortbay.jetty.servlet.ServletHandler.handle(ServletHandler.java:567)         at org.mortbay.http.HttpContext.handle(HttpContext.java:1565)         at org.mortbay.jetty.servlet.WebApplicationContext.handle(WebApplicationContext.java:635)         at org.mortbay.http.HttpContext.handle(HttpContext.java:1517)         at org.mortbay.http.HttpServer.service(HttpServer.java:954) jira地址： https://issues.apache.org/jira/browse/HADOOP-5210  23:counters  3中counters： 1. built-in counters: Map input bytes, Map output records... 2. enum counters    调用方式：   enum Temperature {     MISSING,     MALFORMED   } reporter.incrCounter(Temperature.MISSING, 1)     结果显示： 09/04/20 06:33:36 INFO mapred.JobClient:   Air Temperature Recor 09/04/20 06:33:36 INFO mapred.JobClient:     Malformed=3 09/04/20 06:33:36 INFO mapred.JobClient:     Missing=66136856 3. dynamic countes:    调用方式：    reporter.incrCounter(\"TemperatureQuality\", parser.getQuality(),1);        结果显示： 09/04/20 06:33:36 INFO mapred.JobClient:   TemperatureQuality 09/04/20 06:33:36 INFO mapred.JobClient:     2=1246032 09/04/20 06:33:36 INFO mapred.JobClient:     1=973422173 09/04/20 06:33:36 INFO mapred.JobClient:     0=1 24: Namenode in safe mode  解决方法 bin/hadoop dfsadmin -safemode leave 25:java.net.NoRouteToHostException: No route to host  j解决方法： sudo /etc/init.d/iptables stop 26：更改namenode后，在hive中运行select 依旧指向之前的namenode地址  这是因为：When youcreate a table, hive actually stores the location of the table (e.g. hdfs://ip:port/user/root/...) in the SDS and DBS tables in the metastore . So when I bring up a new cluster the master has a new IP, but hive's metastore is still pointing to the locations within the old cluster. I could modify the metastore to update with the new IP everytime I bring up a cluster. But the easier and simpler solution was to just use an elastic IP for the master 所以要将metastore中的之前出现的namenode地址全部更换为现有的namenode地址","title":"Hadoop使用常见问题以及解决方法"},{"content":"一.linux的安装 注意：安装linux前，需要从windows中删除一部分硬盘，必须至少有两个分区： 根分区（主分区 '/'）和swap（交换分区） swap的作用：swap分区一般情况下大小设置为内存的2倍。相当于一块虚拟内存,当内存出现不足时，有这个分区临时充当内存的角色。 二、关于linux的用户 分3类： 1.root（超级管理员）：拥有修给linux系统任何文件的权限，甚至可以将根目录删除。（UID：0） 2.普通用户（用户自定义的用户）：权限有限，需要root权限时可以切换用户（su 用户名） （UID：500---） 3.不用于登陆的用户（伪用户）：管理linux的服务（UID:1-499） 三、linux各个目录的作用 /boot :  存放linux的内核文件（不要动） /bin  : 存放普通用户的命令 /sbin : 超级管理员的命令 /usr/bin   /usr/sbin   (whereis lvs) /dev  : 外部设备 /home : 存放用户信息（当创建一个用户之后,默认的在home中创建指定用户的文件夹，桌面上的主文件夹） lost+found:存储异常信息（断电后的日志／数据文件） /misc :杂物箱 /net :网络信息 /root :root用户的主目录 /sys :系统信息 /usr :存放用户的应用数据 /etc :存放配置文件和文件目录（不要动） /lib :存放linux动态链接库文件(相当于win中的*.dll文件) /media和/mnt :挂载目录(挂载：mount) /opt  :软件默认的安装目录（C:\\Program Files） /proc :存放获取的系统信息 /srv :存放原数据 /tmp :存放系统产生的临时文件 /var :存放系统的可变文件（日志文件／数据文件） 三 、linux的引导流程及grub的配置 1.linux的启动流程 步骤1：加载固件（固件：引导程序，固化到主板上的一段程序） （类似于：BIOS／CMOS）对于linux：（firmware） 作用： 主要：识别硬件（硬件加电）体现在windows中，新的硬件添加后需要重启，用固件程序去加电 其他： 设置时间固件时间（hwclock） 与之对应的系统的时间date   密码：设置固件密码 步骤2：根据选择启动相应的操作系统（为了解决linux本身的多系统（一个linux可以有选择的启动）） 在linux下引导程序分两类 LILO：Last IN Last OUT（后进的服务，最后运行） GRUB：（GRand Unified Bootloader） linux如何写入计算机  先烧写：bootloader  在Bootloader中区选择kenal文件 通过设置/etc/grub.conf或/boot/grub/grub.conf去更改GRUB的启动信息 grub.conf文件内容： # grub.conf generated by anaconda # # Note that you do not have to rerun grub after making changes to this file # NOTICE:  You have a /boot partition.  This means that #          all kernel and initrd paths are relative to /boot/, eg. #          root (hd0,0) #          kernel /vmlinuz-version ro root=/dev/sda2 #          initrd /initrd-version.img #boot=/dev/sda  （说明引导程序是在硬盘上：sd代表SATA DISK ） GRUB的全局变量：（从grub.conf开始的到第一个title结束） default=0   （默认启动的操作系统：win：1  linux：0） timeout=5 （选择操作系统延迟的时间，单位为秒） splashimage=(hd0,0)/grub/splash.xpm.gz （选择操作系统时的图片背景） hd(0,0)代表：hd（hard disk）除了用hda／hdb...表示之外还可以用数字表示， 如：hd(0,0)表示：第0快硬盘的第0个分区，前面的数字表示第几块硬盘，后面的数字表示第几分区。 passwd＝.... hiddenmenu 局部变量： title Red Hat Enterprise Linux Server (2.6.18-164.el5)（title设置启动显示的标题）版本号：主版本号.次版本号.具体的内核版本（根据次版本号来选择，当次版本号为奇数，表示测试版，如果是偶数表示为正式版）  root (hd0,0)      (/root)  kernel /vmlinuz-2.6.18-164.el5 ro root=LABEL=/ rhgb quiet  initrd /initrd-2.6.18-164.el5.img  passwd kernel是什么？里面存放的是系统有关的硬件驱动，文件系统 用户自己可以根据平台的不同对kernel进行裁减（u盘    pad  手机）   内核服务（进程）管理 通过修改/etc/initab文件对内核服务进行修改 # # inittab       This file describes how the INIT process should set up #               the system in a certain run-level. # # Author:       Miquel van Smoorenburg, <miquels@drinkel.nl.mugnet.org> #               Modified for RHS Linux by Marc Ewing and Donnie Barnes # # Default runlevel. The runlevels used by RHS（Red Hat SERVICE（红帽的服务等级runlevel）） are: #   0 - halt (Do NOT set initdefault to this) #   1 - Single user mode（单用户模式） #   2 - Multiuser, without NFS (The same as 3, if you do not have networking) #   3 - Full multiuser mode（2，3都是多用户的文本模式（text）） #   4 - unused （4保留） #   5 - X11 （图形模式） #   6 - reboot (Do NOT set initdefault to this)（重启） # id:5:initdefault: inittab中文件的语法格式： 优先顺序:操作类型:脚本名称 # System initialization.（修改启动项） si::sysinit:/etc/rc.d/rc.sysinit l0:0:wait:/etc/rc.d/rc 0 l1:1:wait:/etc/rc.d/rc 1 l2:2:wait:/etc/rc.d/rc 2 l3:3:wait:/etc/rc.d/rc 3 l4:4:wait:/etc/rc.d/rc 4 l5:5:wait:/etc/rc.d/rc 5 l6:6:wait:/etc/rc.d/rc 6 # Trap CTRL-ALT-DELETE ca::ctrlaltdel:/sbin/shutdown -t3 -r now # When our UPS tells us power has failed, assume we have a few minutes # of power left.  Schedule a shutdown for 2 minutes from now. # This does, of course, assume you have powerd installed and your # UPS connected and working correctly.  pf::powerfail:/sbin/shutdown -f -h +2 \"Power Failure; System Shutting Down\" # If power was restored before the shutdown kicked in, cancel it. pr:12345:powerokwait:/sbin/shutdown -c \"Power Restored; Shutdown Cancelled\" # Run gettys in standard runlevels 1:2345:respawn:/sbin/mingetty tty1 2:2345:respawn:/sbin/mingetty tty2 3:2345:respawn:/sbin/mingetty tty3 4:2345:respawn:/sbin/mingetty tty4 5:2345:respawn:/sbin/mingetty tty5 6:2345:respawn:/sbin/mingetty tty6 # Run xdm in runlevel 5 x:5:respawn:/etc/X11/prefdm -nodaemon                              ","title":"LINUX知识点"},{"content":"一、简介 　　nali，名字取自中文“哪里”的拼音。nali包含一组命令行程序，其主要功能就是把一些网络工具的输出的IP字符串，附加上地理位置信息(使用纯真数据库QQWry.Dat)。例如74.125.128.104会变成74.125.128.104[美国 加利福尼亚州山景市谷歌公司]。查询是在本地进行，并不会进行联网查询，所以效率方面不会对原始命令产生什么影响。 　　目前包含以下几个命令： nali nali-dig nali-nslookup nali-traceroute nali-tracepath nali-ping 　　使用这些命令的前提是，他们对应的命令必须存在。例如你要用nali-dig，必须保证dig是存在的。他们的用法和原始命令是一样的。例如nali-dig，用法就和dig一样。（nali-dig等同于dig |nali） 二、下载 # wget --no-check-certificate http://qqwry.googlecode.com/files/nali-0.2.tar.gz 三、安装 # tar zxvf nali-0.2.tar.gz # cd nali-0.2 # ./configure # make && make install 四、更新IP数据库 可以用nali-update命令来更新IP数据库 /usr/local/share/QQWry.Dat 这个文件需要经常更新，否则误差会比较大。 五、使用 5.1. nali # nali 74.125.128.106 # nali 61.135.169.105 5.2. nali-dig # nali-dig www.google.com 5.3. nali-nslookup # nali-nslookup www.google.com 5.4. nali-traceroute # nali-traceroute www.google.com 5.5. nali-tracepath # nali-tracepath www.baidu.com 5.6. nali-ping # nali-ping www.163.com 5.7. 其它程序调用nali显示IP物理位置可使用重定向方式，如： # mtr www.google.com|nali 也就是说，nali这个命令，可以对标准输出的ip，附加上地理信息。同理，如果你不喜欢用nali-dig，那么也可以用dig ip|nali这样的命令。 六、alias 如果你觉得输入nali-xxx麻烦，那么可以做一些alias，例如： # alias traceroute='nali-traceroute' # alias dig='nali-dig' 七、参考","title":"Linux下显示IP地理位置信息的小工具—nali（很强大）"},{"content":"逛博客  找到一个牛人的博客  很犀利  里面正好有关于C语言的  我就根据练习练习  正愁没参考的程序 把程序练习后  保存一份在自己的博客里  这属于转载了吧   他的博客地址：http://blog.chinaunix.net/uid/24219701/frmd/15655/page/1.html    C部分的  大家可以去看看 下面是两个递归的练习： #include <stdlib.h>#include <stdio.h>void fun(int);                    /* 函数声明 */int main(){  int x = 1;  fun(x);                     /* 函数调用 */  return 0;}void fun(int i)                     /* 函数定义 */{  if(i > 5)  {    printf(\"Done!\\n\");    return;                    /* 如果没有该语句，程序将进入死循环 */  }  printf(\"%d\\n\", i);  fun(++i);                     /* 函数递归 */  return;} #include <stdlib.h>#include <stdio.h>int func(int);                    /* 函数声明 */int main(){  int n,y;  printf(\"Input n (>0) : \");  scanf(\"%d\", &n);                 /* 输入正整数n */  if(n <= 0)  {    printf(\"Error!\\n\");  }  else  {    y = fun(n);                 /* 函数调用 */    printf(\"%d! = %d \\n\", n, y);        /* 输出运算结果 */  }  return 0;}int fun(int n)                     /* 函数定义 */{  int t;  if(1 == n)                    /* 递归结束条件 */  {    return 1;  }  else  {    t = n*fun(n-1);                /* 函数递归调用 */    return t;  }}","title":"C 递归"},{"content":"RPM是RedHat Package Manager（RedHat软件包管理工具）类似Windows里面的“添加/删除程序” rpm 执行安装包 二进制包（Binary）以及源代码包（Source）两种。二进制包可以直接安装在计算机中，而源代码包将会由RPM自动编译、安装。源代码包经常以src.rpm作为后缀名。 常用命令组合：   －ivh：安装显示安装进度--install--verbose--hash －Uvh：升级软件包--Update； －qpl：列出RPM软件包内的文件信息[Query Package list]； －qpi：列出RPM软件包的描述信息[Query Package install package(s)]； －qf：查找指定文件属于哪个RPM软件包[Query File]； －Va：校验所有的RPM软件包，查找丢失的文件[View Lost]； －e：删除包     rpm -q samba //查询程序是否安装 rpm -ivh  /media/cdrom/RedHat/RPMS/samba-3.0.10-1.4E.i386.rpm //按路径安装并显示进度 rpm -ivh --relocate /=/opt/gaim gaim-1.3.0-1.fc4.i386.rpm    //指定安装目录 rpm -ivh --test gaim-1.3.0-1.fc4.i386.rpm　　　 //用来检查依赖关系；并不是真正的安装； rpm -Uvh --oldpackage gaim-1.3.0-1.fc4.i386.rpm //新版本降级为旧版本 rpm -qa | grep httpd　　　　　 ＃[搜索指定rpm包是否安装]--all搜索*httpd* rpm -ql httpd　　　　　　　　　＃[搜索rpm包]--list所有文件安装目录 rpm -qpi Linux-1.4-6.i368.rpm　＃[查看rpm包]--query--package--install package信息 rpm -qpf Linux-1.4-6.i368.rpm　＃[查看rpm包]--file rpm -qpR file.rpm　　　　　　　＃[查看包]依赖关系 rpm2cpio file.rpm |cpio -div    ＃[抽出文件] rpm -ivh file.rpm 　＃[安装新的rpm]--install--verbose--hash rpm -ivh rpm -Uvh file.rpm    ＃[升级一个rpm]--upgrade rpm -e file.rpm      ＃[删除一个rpm包]--erase 常用参数： Install/Upgrade/Erase options: -i, --install                     install package(s) -v, --verbose                     provide more detailed output -h, --hash                        print hash marks as package installs (good with -v) -e, --erase                       erase (uninstall) package -U, --upgrade=<packagefile>+      upgrade package(s) －-replacepkge                    无论软件包是否已被安装，都强行安装软件包 --test                            安装测试，并不实际安装 --nodeps                          忽略软件包的依赖关系强行安装 --force                           忽略软件包及文件的冲突 Query options (with -q or --query): -a, --all                         query/verify all packages -p, --package                     query/verify a package file -l, --list                        list files in package -d, --docfiles                    list all documentation files -f, --file                        query/verify package(s) owning file RPM源代码包装安装 .src.rpm结尾的文件，这些文件是由软件的源代码包装而成的，用户要安装这类RPM软件包，必须使用命令：   rpm　--recompile　vim-4.6-4.src.rpm   ＃这个命令会把源代码解包并编译、安装它，如果用户使用命令： rpm　--rebuild　vim-4.6-4.src.rpm　　＃在安装完成后，还会把编译生成的可执行文件重新包装成i386.rpm的RPM软件包。   偶不喜欢写比较复杂的东东，麻烦的话`不过做为参考`偶还素转了一位哒人的`写的真很全面` 作者：北南南北 来自：LinuxSir.Org 提要：RPM 是 Red Hat Package Manager 的缩写，原意是Red Hat 软件包管理；本文介绍RPM，并结合实例来解说RPM手工安装、查询等应用； ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 正文： ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ RPM 是 Red Hat Package Manager 的缩写，本意是Red Hat 软件包管理，顾名思义是Red Hat 贡献出来的软件包管理；在Fedora 、Redhat、Mandriva、SuSE、YellowDog等主流发行版本，以及在这些版本基础上二次开发出来的发行版采用； RPM包里面都包含什么？里面包含可执行的二进制程序，这个程序和Windows的软件包中的.exe文件类似是可执行的；RPM包中还包括程序运行时所需要的文件，这也和Windows的软件包类似，Windows的程序的运行，除了.exe文件以外，也有其它的文件； 一个RPM 包中的应用程序，有时除了自身所带的附加文件保证其正常以外，还需要其它特定版本文件，这就是软件包的依赖关系；依赖关系并不是Linux特有的， Windows操作系统中也是同样存在的；比如我们在Windows系统中运行3D游戏，在安装的时候，他可能会提示，要安装Direct 9 ；Linux和Windows原理是差不多的； 软件安装流程图：   本文使用范围： 1、本文是对RPM管理的软件的说明，对通过file.tar.gz 或file.tar.bz2源码包用 make ;make install 安装的软件无效； 2、安装软件时，最好用各自发行版所提供的系统软件包管理工具，对于Fedora/Redhat 您可以参考如下文章； 1）Fedora 系统管理软件包工具 system-config-packages，方便的添加和移除系统安装盘提供的软件包，详情请看 《Fedora 软件包管理器system-config-packages》 2）Redhat 系统管理软件包工具,新一点的系统应该是 redhat-config-packages ，用法和 《Fedora 软件包管理器system-config-packages》 一样； 3）apt + synaptic 软件包在线安装、移除、升级工具； 用法：《用apt+synaptic 在线安装或升级Fedora core 4.0 软件包》 4）yum 软件包在线安装、升级、移除工具；用法：《Fedora/Redhat 在线安装更新软件包，yum 篇》 5）所有的yum和apt 教程 《apt and yum》 目前 apt和yum 已经极为成熟了，建议我们安装软件时，采用 apt或者yum ；如果安装系统盘提供的软件包，可以用 system-config-packages 或redhat-config-packages ； 一、RPM包管理的用途； 1、可以安装、删除、升级和管理软件；当然也支持在线安装和升级软件； 2、通过RPM包管理能知道软件包包含哪些文件，也能知道系统中的某个文件属于哪个软件包； 3、可以在查询系统中的软件包是否安装以及其版本； 4、作为开发者可以把自己的程序打包为RPM 包发布； 5、软件包签名GPG和MD5的导入、验证和签名发布 6、依赖性的检查，查看是否有软件包由于不兼容而扰乱了系统； 二、RPM 的使用权限； RPM软件的安装、删除、更新只有root权限才能使用；对于查询功能任何用户都可以操作；如果普通用户拥有安装目录的权限，也可以进行安装； 三、rpm 的一点简单用法； 我们除了软件包管理器以外，还能通过rpm 命令来安装；是不是所有的软件包都能通过rpm 命令来安装呢？不是的，文件以.rpm 后缀结尾的才行；有时我们在一些网站上找到file.rpm ，都要用 rpm 来安装； 一）初始化rpm 数据库； 通过rpm 命令查询一个rpm 包是否安装了，也是要通过rpm 数据库来完成的；所以我们要经常用下面的两个命令来初始化rpm 数据库； [root@localhost beinan]# rpm --initdb [root@localhost beinan]# rpm --rebuilddb 注：这个要花好长时间； 注：这两个参数是极为有用，有时rpm 系统出了问题，不能安装和查询，大多是这里出了问题； 二）RPM软件包管理的查询功能： 命令格式 rpm {-q|--query} [select-options] [query-options] RPM的查询功能是极为强大，是极为重要的功能之一；举几个常用的例子，更为详细的具体的，请参考#man rpm 1、对系统中已安装软件的查询； 1）查询系统已安装的软件；   语法：rpm -q 软件名 举例：   [root@localhost beinan]# rpm -q gaim gaim-1.3.0-1.fc4 -q就是 --query ，中文意思是“问”，此命令表示的是，是不是系统安装了gaim ；如果已安装会有信息输出；如果没有安装，会输出gaim 没有安装的信息； 查看系统中所有已经安装的包，要加 -a 参数 ； [root@localhost RPMS]# rpm -qa 如果分页查看，再加一个管道 |和more命令； [root@localhost RPMS]# rpm -qa |more 在所有已经安装的软件包中查找某个软件，比如说 gaim ；可以用 grep 抽取出来；   [root@localhost RPMS]# rpm -qa |grep gaim 上面这条的功能和 rpm -q gaim 输出的结果是一样的； 2）查询一个已经安装的文件属于哪个软件包；   语法 rpm -qf 文件名 注：文件名所在的绝对路径要指出   举例： [root@localhost RPMS]# rpm -qf /usr/lib/libacl.la libacl-devel-2.2.23-8 3）查询已安装软件包都安装到何处；   语法：rpm -ql 软件名 或 rpm rpmquery -ql 软件名 举例：   [root@localhost RPMS]# rpm -ql lynx [root@localhost RPMS]# rpmquery -ql lynx 4）查询一个已安装软件包的信息   语法格式： rpm -qi 软件名 举例： [root@localhost RPMS]# rpm -qi lynx 5）查看一下已安装软件的配置文件；   语法格式：rpm -qc 软件名 举例： RPM是RedHat Package Manager（RedHat软件包管理工具）类似Windows里面的“添加/删除程序” rpm 执行安装包 二进制包（Binary）以及源代码包（Source）两种。二进制包可以直接安装在计算机中，而源代码包将会由RPM自动编译、安装。源代码包经常以src.rpm作为后缀名。 常用命令组合：   －ivh：安装显示安装进度--install--verbose--hash －Uvh：升级软件包--Update； －qpl：列出RPM软件包内的文件信息[Query Package list]； －qpi：列出RPM软件包的描述信息[Query Package install package(s)]； －qf：查找指定文件属于哪个RPM软件包[Query File]； －Va：校验所有的RPM软件包，查找丢失的文件[View Lost]； －e：删除包     rpm -q samba //查询程序是否安装 rpm -ivh  /media/cdrom/RedHat/RPMS/samba-3.0.10-1.4E.i386.rpm //按路径安装并显示进度 rpm -ivh --relocate /=/opt/gaim gaim-1.3.0-1.fc4.i386.rpm    //指定安装目录 rpm -ivh --test gaim-1.3.0-1.fc4.i386.rpm　　　 //用来检查依赖关系；并不是真正的安装； rpm -Uvh --oldpackage gaim-1.3.0-1.fc4.i386.rpm //新版本降级为旧版本 rpm -qa | grep httpd　　　　　 ＃[搜索指定rpm包是否安装]--all搜索*httpd* rpm -ql httpd　　　　　　　　　＃[搜索rpm包]--list所有文件安装目录 rpm -qpi Linux-1.4-6.i368.rpm　＃[查看rpm包]--query--package--install package信息 rpm -qpf Linux-1.4-6.i368.rpm　＃[查看rpm包]--file rpm -qpR file.rpm　　　　　　　＃[查看包]依赖关系 rpm2cpio file.rpm |cpio -div    ＃[抽出文件] rpm -ivh file.rpm 　＃[安装新的rpm]--install--verbose--hash rpm -ivh rpm -Uvh file.rpm    ＃[升级一个rpm]--upgrade rpm -e file.rpm      ＃[删除一个rpm包]--erase 常用参数： Install/Upgrade/Erase options: -i, --install                     install package(s) -v, --verbose                     provide more detailed output -h, --hash                        print hash marks as package installs (good with -v) -e, --erase                       erase (uninstall) package -U, --upgrade=<packagefile>+      upgrade package(s) －-replacepkge                    无论软件包是否已被安装，都强行安装软件包 --test                            安装测试，并不实际安装 --nodeps                          忽略软件包的依赖关系强行安装 --force                           忽略软件包及文件的冲突 Query options (with -q or --query): -a, --all                         query/verify all packages -p, --package                     query/verify a package file -l, --list                        list files in package -d, --docfiles                    list all documentation files -f, --file                        query/verify package(s) owning file RPM源代码包装安装 .src.rpm结尾的文件，这些文件是由软件的源代码包装而成的，用户要安装这类RPM软件包，必须使用命令：   rpm　--recompile　vim-4.6-4.src.rpm   ＃这个命令会把源代码解包并编译、安装它，如果用户使用命令： rpm　--rebuild　vim-4.6-4.src.rpm　　＃在安装完成后，还会把编译生成的可执行文件重新包装成i386.rpm的RPM软件包。   偶不喜欢写比较复杂的东东，麻烦的话`不过做为参考`偶还素转了一位哒人的`写的真很全面` 作者：北南南北 来自：LinuxSir.Org 提要：RPM 是 Red Hat Package Manager 的缩写，原意是Red Hat 软件包管理；本文介绍RPM，并结合实例来解说RPM手工安装、查询等应用； ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 正文： ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ RPM 是 Red Hat Package Manager 的缩写，本意是Red Hat 软件包管理，顾名思义是Red Hat 贡献出来的软件包管理；在Fedora 、Redhat、Mandriva、SuSE、YellowDog等主流发行版本，以及在这些版本基础上二次开发出来的发行版采用； RPM包里面都包含什么？里面包含可执行的二进制程序，这个程序和Windows的软件包中的.exe文件类似是可执行的；RPM包中还包括程序运行时所需要的文件，这也和Windows的软件包类似，Windows的程序的运行，除了.exe文件以外，也有其它的文件； 一个RPM 包中的应用程序，有时除了自身所带的附加文件保证其正常以外，还需要其它特定版本文件，这就是软件包的依赖关系；依赖关系并不是Linux特有的， Windows操作系统中也是同样存在的；比如我们在Windows系统中运行3D游戏，在安装的时候，他可能会提示，要安装Direct 9 ；Linux和Windows原理是差不多的； 软件安装流程图：   本文使用范围： 1、本文是对RPM管理的软件的说明，对通过file.tar.gz 或file.tar.bz2源码包用 make ;make install 安装的软件无效； 2、安装软件时，最好用各自发行版所提供的系统软件包管理工具，对于Fedora/Redhat 您可以参考如下文章； 1）Fedora 系统管理软件包工具 system-config-packages，方便的添加和移除系统安装盘提供的软件包，详情请看 《Fedora 软件包管理器system-config-packages》 2）Redhat 系统管理软件包工具,新一点的系统应该是 redhat-config-packages ，用法和 《Fedora 软件包管理器system-config-packages》 一样； 3）apt + synaptic 软件包在线安装、移除、升级工具； 用法：《用apt+synaptic 在线安装或升级Fedora core 4.0 软件包》 4）yum 软件包在线安装、升级、移除工具；用法：《Fedora/Redhat 在线安装更新软件包，yum 篇》 5）所有的yum和apt 教程 《apt and yum》 目前 apt和yum 已经极为成熟了，建议我们安装软件时，采用 apt或者yum ；如果安装系统盘提供的软件包，可以用 system-config-packages 或redhat-config-packages ； 一、RPM包管理的用途； 1、可以安装、删除、升级和管理软件；当然也支持在线安装和升级软件； 2、通过RPM包管理能知道软件包包含哪些文件，也能知道系统中的某个文件属于哪个软件包； 3、可以在查询系统中的软件包是否安装以及其版本； 4、作为开发者可以把自己的程序打包为RPM 包发布； 5、软件包签名GPG和MD5的导入、验证和签名发布 6、依赖性的检查，查看是否有软件包由于不兼容而扰乱了系统； 二、RPM 的使用权限； RPM软件的安装、删除、更新只有root权限才能使用；对于查询功能任何用户都可以操作；如果普通用户拥有安装目录的权限，也可以进行安装； 三、rpm 的一点简单用法； 我们除了软件包管理器以外，还能通过rpm 命令来安装；是不是所有的软件包都能通过rpm 命令来安装呢？不是的，文件以.rpm 后缀结尾的才行；有时我们在一些网站上找到file.rpm ，都要用 rpm 来安装； 一）初始化rpm 数据库； 通过rpm 命令查询一个rpm 包是否安装了，也是要通过rpm 数据库来完成的；所以我们要经常用下面的两个命令来初始化rpm 数据库； [root@localhost beinan]# rpm --initdb [root@localhost beinan]# rpm --rebuilddb 注：这个要花好长时间； 注：这两个参数是极为有用，有时rpm 系统出了问题，不能安装和查询，大多是这里出了问题； 二）RPM软件包管理的查询功能： 命令格式 rpm {-q|--query} [select-options] [query-options] RPM的查询功能是极为强大，是极为重要的功能之一；举几个常用的例子，更为详细的具体的，请参考#man rpm 1、对系统中已安装软件的查询； 1）查询系统已安装的软件；   语法：rpm -q 软件名 举例：   [root@localhost beinan]# rpm -q gaim gaim-1.3.0-1.fc4 -q就是 --query ，中文意思是“问”，此命令表示的是，是不是系统安装了gaim ；如果已安装会有信息输出；如果没有安装，会输出gaim 没有安装的信息； 查看系统中所有已经安装的包，要加 -a 参数 ； [root@localhost RPMS]# rpm -qa 如果分页查看，再加一个管道 |和more命令； [root@localhost RPMS]# rpm -qa |more 在所有已经安装的软件包中查找某个软件，比如说 gaim ；可以用 grep 抽取出来；   [root@localhost RPMS]# rpm -qa |grep gaim 上面这条的功能和 rpm -q gaim 输出的结果是一样的； 2）查询一个已经安装的文件属于哪个软件包；   语法 rpm -qf 文件名 注：文件名所在的绝对路径要指出   举例： [root@localhost RPMS]# rpm -qf /usr/lib/libacl.la libacl-devel-2.2.23-8 3）查询已安装软件包都安装到何处；   语法：rpm -ql 软件名 或 rpm rpmquery -ql 软件名 举例：   [root@localhost RPMS]# rpm -ql lynx [root@localhost RPMS]# rpmquery -ql lynx 4）查询一个已安装软件包的信息   语法格式： rpm -qi 软件名 举例： [root@localhost RPMS]# rpm -qi lynx 5）查看一下已安装软件的配置文件；   语法格式：rpm -qc 软件名 举例： RPM是RedHat Package Manager（RedHat软件包管理工具）类似Windows里面的“添加/删除程序” rpm 执行安装包 二进制包（Binary）以及源代码包（Source）两种。二进制包可以直接安装在计算机中，而源代码包将会由RPM自动编译、安装。源代码包经常以src.rpm作为后缀名。 常用命令组合：   －ivh：安装显示安装进度--install--verbose--hash －Uvh：升级软件包--Update； －qpl：列出RPM软件包内的文件信息[Query Package list]； －qpi：列出RPM软件包的描述信息[Query Package install package(s)]； －qf：查找指定文件属于哪个RPM软件包[Query File]； －Va：校验所有的RPM软件包，查找丢失的文件[View Lost]； －e：删除包     rpm -q samba //查询程序是否安装 rpm -ivh  /media/cdrom/RedHat/RPMS/samba-3.0.10-1.4E.i386.rpm //按路径安装并显示进度 rpm -ivh --relocate /=/opt/gaim gaim-1.3.0-1.fc4.i386.rpm    //指定安装目录 rpm -ivh --test gaim-1.3.0-1.fc4.i386.rpm　　　 //用来检查依赖关系；并不是真正的安装； rpm -Uvh --oldpackage gaim-1.3.0-1.fc4.i386.rpm //新版本降级为旧版本 rpm -qa | grep httpd　　　　　 ＃[搜索指定rpm包是否安装]--all搜索*httpd* rpm -ql httpd　　　　　　　　　＃[搜索rpm包]--list所有文件安装目录 rpm -qpi Linux-1.4-6.i368.rpm　＃[查看rpm包]--query--package--install package信息 rpm -qpf Linux-1.4-6.i368.rpm　＃[查看rpm包]--file rpm -qpR file.rpm　　　　　　　＃[查看包]依赖关系 rpm2cpio file.rpm |cpio -div    ＃[抽出文件] rpm -ivh file.rpm 　＃[安装新的rpm]--install--verbose--hash rpm -ivh rpm -Uvh file.rpm    ＃[升级一个rpm]--upgrade rpm -e file.rpm      ＃[删除一个rpm包]--erase 常用参数： Install/Upgrade/Erase options: -i, --install                     install package(s) -v, --verbose                     provide more detailed output -h, --hash                        print hash marks as package installs (good with -v) -e, --erase                       erase (uninstall) package -U, --upgrade=<packagefile>+      upgrade package(s) －-replacepkge                    无论软件包是否已被安装，都强行安装软件包 --test                            安装测试，并不实际安装 --nodeps                          忽略软件包的依赖关系强行安装 --force                           忽略软件包及文件的冲突 Query options (with -q or --query): -a, --all                         query/verify all packages -p, --package                     query/verify a package file -l, --list                        list files in package -d, --docfiles                    list all documentation files -f, --file                        query/verify package(s) owning file RPM源代码包装安装 .src.rpm结尾的文件，这些文件是由软件的源代码包装而成的，用户要安装这类RPM软件包，必须使用命令：   rpm　--recompile　vim-4.6-4.src.rpm   ＃这个命令会把源代码解包并编译、安装它，如果用户使用命令： rpm　--rebuild　vim-4.6-4.src.rpm　　＃在安装完成后，还会把编译生成的可执行文件重新包装成i386.rpm的RPM软件包。   偶不喜欢写比较复杂的东东，麻烦的话`不过做为参考`偶还素转了一位哒人的`写的真很全面` 作者：北南南北 来自：LinuxSir.Org 提要：RPM 是 Red Hat Package Manager 的缩写，原意是Red Hat 软件包管理；本文介绍RPM，并结合实例来解说RPM手工安装、查询等应用； ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 正文： ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ RPM 是 Red Hat Package Manager 的缩写，本意是Red Hat 软件包管理，顾名思义是Red Hat 贡献出来的软件包管理；在Fedora 、Redhat、Mandriva、SuSE、YellowDog等主流发行版本，以及在这些版本基础上二次开发出来的发行版采用； RPM包里面都包含什么？里面包含可执行的二进制程序，这个程序和Windows的软件包中的.exe文件类似是可执行的；RPM包中还包括程序运行时所需要的文件，这也和Windows的软件包类似，Windows的程序的运行，除了.exe文件以外，也有其它的文件； 一个RPM 包中的应用程序，有时除了自身所带的附加文件保证其正常以外，还需要其它特定版本文件，这就是软件包的依赖关系；依赖关系并不是Linux特有的， Windows操作系统中也是同样存在的；比如我们在Windows系统中运行3D游戏，在安装的时候，他可能会提示，要安装Direct 9 ；Linux和Windows原理是差不多的； 软件安装流程图：   本文使用范围： 1、本文是对RPM管理的软件的说明，对通过file.tar.gz 或file.tar.bz2源码包用 make ;make install 安装的软件无效； 2、安装软件时，最好用各自发行版所提供的系统软件包管理工具，对于Fedora/Redhat 您可以参考如下文章； 1）Fedora 系统管理软件包工具 system-config-packages，方便的添加和移除系统安装盘提供的软件包，详情请看 《Fedora 软件包管理器system-config-packages》 2）Redhat 系统管理软件包工具,新一点的系统应该是 redhat-config-packages ，用法和 《Fedora 软件包管理器system-config-packages》 一样； 3）apt + synaptic 软件包在线安装、移除、升级工具； 用法：《用apt+synaptic 在线安装或升级Fedora core 4.0 软件包》 4）yum 软件包在线安装、升级、移除工具；用法：《Fedora/Redhat 在线安装更新软件包，yum 篇》 5）所有的yum和apt 教程 《apt and yum》 目前 apt和yum 已经极为成熟了，建议我们安装软件时，采用 apt或者yum ；如果安装系统盘提供的软件包，可以用 system-config-packages 或redhat-config-packages ； 一、RPM包管理的用途； 1、可以安装、删除、升级和管理软件；当然也支持在线安装和升级软件； 2、通过RPM包管理能知道软件包包含哪些文件，也能知道系统中的某个文件属于哪个软件包； 3、可以在查询系统中的软件包是否安装以及其版本； 4、作为开发者可以把自己的程序打包为RPM 包发布； 5、软件包签名GPG和MD5的导入、验证和签名发布 6、依赖性的检查，查看是否有软件包由于不兼容而扰乱了系统； 二、RPM 的使用权限； RPM软件的安装、删除、更新只有root权限才能使用；对于查询功能任何用户都可以操作；如果普通用户拥有安装目录的权限，也可以进行安装； 三、rpm 的一点简单用法； 我们除了软件包管理器以外，还能通过rpm 命令来安装；是不是所有的软件包都能通过rpm 命令来安装呢？不是的，文件以.rpm 后缀结尾的才行；有时我们在一些网站上找到file.rpm ，都要用 rpm 来安装； 一）初始化rpm 数据库； 通过rpm 命令查询一个rpm 包是否安装了，也是要通过rpm 数据库来完成的；所以我们要经常用下面的两个命令来初始化rpm 数据库； [root@localhost beinan]# rpm --initdb [root@localhost beinan]# rpm --rebuilddb 注：这个要花好长时间； 注：这两个参数是极为有用，有时rpm 系统出了问题，不能安装和查询，大多是这里出了问题； 二）RPM软件包管理的查询功能： 命令格式 rpm {-q|--query} [select-options] [query-options] RPM的查询功能是极为强大，是极为重要的功能之一；举几个常用的例子，更为详细的具体的，请参考#man rpm 1、对系统中已安装软件的查询； 1）查询系统已安装的软件；   语法：rpm -q 软件名 举例：   [root@localhost beinan]# rpm -q gaim gaim-1.3.0-1.fc4 -q就是 --query ，中文意思是“问”，此命令表示的是，是不是系统安装了gaim ；如果已安装会有信息输出；如果没有安装，会输出gaim 没有安装的信息； 查看系统中所有已经安装的包，要加 -a 参数 ； [root@localhost RPMS]# rpm -qa 如果分页查看，再加一个管道 |和more命令； [root@localhost RPMS]# rpm -qa |more 在所有已经安装的软件包中查找某个软件，比如说 gaim ；可以用 grep 抽取出来；   [root@localhost RPMS]# rpm -qa |grep gaim 上面这条的功能和 rpm -q gaim 输出的结果是一样的； 2）查询一个已经安装的文件属于哪个软件包；   语法 rpm -qf 文件名 注：文件名所在的绝对路径要指出   举例： [root@localhost RPMS]# rpm -qf /usr/lib/libacl.la libacl-devel-2.2.23-8 3）查询已安装软件包都安装到何处；   语法：rpm -ql 软件名 或 rpm rpmquery -ql 软件名 举例：   [root@localhost RPMS]# rpm -ql lynx [root@localhost RPMS]# rpmquery -ql lynx 4）查询一个已安装软件包的信息   语法格式： rpm -qi 软件名 举例： [root@localhost RPMS]# rpm -qi lynx 5）查看一下已安装软件的配置文件；   语法格式：rpm -qc 软件名  ","title":"Linux rpm 命令参数使用详解［介绍和应用］"},{"content":"IDE是一款简化和加快源代码书写的软件应用程序。它能够有效的提高开发人员的工作效率，它一般能够实现的功能是书写、修改、编译调试软件。 下面为Windows，Mac和Linux用户提供10款非常有用的IDE。 1：NetBeans netBeans能够使你快速轻松的开发java桌面、移动和web应用程序，同时也为c/c++和php开发人员提供了很好的工具。netbeans是开源和免费的，有很大的用户群体。 2：Zend Studio Zend Studio 是专业开发人员在使用PHP整个开发周期中唯一的集成开发环境 (IDE)，它包括了PHP所有必须的开发部件。通过一整套编辑、调试、分析、优化和数据库工具，Zend Studio 加速开发周期，并简化复杂的应用方案。 3：komodo ide komodo是一个功能全面的ide，无论您是开发在Windows，Mac，Linux或者是三个都有，他都能够胜任。komodo IDE具有全面的功能来帮助您更快的开发、调试、部署。它具有直观的用户界面，让你一见倾心。 4：nvu Nvu（发音N-view）是个所见即所得的万维网页处理系统，它是自由软件，建基于Mozilla的Composer Mode。它的目标是能与商业的网站开发工具如Microsoft FrontPage和Macromedia Dreamweaver争一日之长短，及成为Linux上最重要的所见即所得(WYSWYG: What you see, what you get)编辑器。Nvu的设计是极为适合非专业的电脑使用者。并不强调需要html或CSS的知识。 5：Aptana Aptana是世界上最强大的开源Web开发IDE。 6：Eclipse Eclipse 是一个开放源代码的、基于Java的可扩展开发平台。就其本身而言，它只是一个框架和一组服务，用于通过插件组件构建开发环境。它的项目主要集中在建立一个开放的开发平台，用于构建，部署和管理软件的整个生命周期。 7：Intellij IntelliJ IDEA是一个相对较新的Java IDE，它是一个以代码为中心的IDE专注于开发人员的工作效率，它包括了很多辅助的功能，并且与Java结合得相当好。不同的工具窗口围绕在主编程窗口周围，当鼠标点到时即可打开，无用时也可轻松关闭，使用户得到了最大化的有效屏幕范围。 8：Spket 一个RIA的开发工具。支持javascript, XUL/XBL, Laszlo, SVG and Yahoo! Widget 等新产品，他可以以一个独立的桌面应用程序运行或者以Eclipse的一个插件运行。 本文转自：http://www.itlanguageexpress.info/559.html 如果要查看更多文章请移驾到我的个人博客：http://www.itlanguageexpress.info","title":"Windows，Mac和Linux用户的8个集成开发环境（IDE）"},{"content":"1 Linux 的日志文件 一般情况下，Linux 的软件包大多将它们的日志信息记录到 /var/log 目录下的文件里，在有些发行版本上，个别日志也保存在 /var/adm 里。 现如今，大多数程序将它们的日志项发到一个称为 rsyslogd (如果你在其他旧的资料中看到 syslog 的关键词，请根据您所使用的发行版系统作相应的调整，因为在我的 Ubuntu 10.10 和 Fedora 17 系统上默认安装的都是 rsyslogd 并且我在系统的包管理器上再也找不到 syslog 的踪影了)的中央清理系统。默认的 rsyslogd 配置一般将这些信息的大部分转储到 /var/log 中的某个地方。下表是一份主要发行系统中较为常见的日志文件的有关信息。除非特别说明，否则文件名都相对于 /var/log 目录而言的。 文件 程序 发行版本 内容 auth.log su 等 DU 授权 apache2/* apache2 SDU Apache2 http server log boot.log rc 脚本 所有 系统启动脚本的输出 cron cron RF(DU要手动修改) cron 的执行情况和出错信息 cups/* CUPS 所有 与打印有关的信息（CUPS） daemon.log 许多 DU 所有守护进程功能的消息 debug 许多 DU 调试输出 dmesg 内核 DU 内核消息缓冲的转储 dpkg.log dpkg DU 软件包管理日志 failog login SDU 不成功的登录企图 httpd/log/* httpd RF Apache http server log kern.log 内核 DU 所有 kern 功能的消息 lastlog login 所有 每个用户上次登录的时间（二进制） mail. mail 相关 所有 所有 mail 功能的消息 message 许多 所有 经常是主要的系统日志文件 rpmpkgs cron.daily/rpm RF 已安装的 RPM 软件包清单 samba/* smbd 等 - Samba（Windows/CIFS 文件夹共享） secure sshd, sudo 等 RF 保密的授权信息 syslog 许多 DU 经常是主要的系统日志文件 warn 许多 S 所有的警告、出错级的信息 wtmp login 所有 登录记录（二进制） Xorg.n.log Xorg 所有 X window server 的出错信息 yum.log yum RF 软件包管理日志 发行版本： R = Red Hat Enterprise Linux F = Fedora D = Debian U = Ubuntu S = SUSE 1.1 特殊的日志文件 /var/log/wtmp 中包含用户登录系统和退出系统的记录，也包含了表明系统何时重启或者关机的记录项。不过 wtmp 文件是以二进制形式保存的。只有使用 last 命令来解读这些信息： $ last /var/log/lastlog 包含信息类似于 /var/log/wtmp 中的信息，但是它只记录每个用户上次登录的时间。它也是一个二进制文件，使用 lastlog 命令来读取： $ lastlog 2 logrotate: 管理日志文件 Erik Troan 提供了一种优秀的工具 logrotate，它实现了多种多样的日志管理策略，而且在大多数的发行版本都是标准应用。当你查看你的 /var/log 目录下发现好多以类似 “.log.1”，“.log.2.gz” 形式结尾的项的时候，那么很多都是 logrotate 干的好事了。 logrotate 的配置文件由一系列规范组成，它们说明了要管理的日志文件组。默认情况下，配置文件处在 /etc/logrotate.conf 的位置，我们先来看下 Ubuntu 10.10 下默认情况下这个文件是长啥样的： weeklyrotate 4createinclude /etc/logrotate.d/var/log/wtmp {    missingok    monthly    create 0664 root utmp    rotate 1}/var/log/btmp {    missingok    monthly    create 0660 root utmp    rotate 1} 这一配置每周转换一次，包含 /etc/logrotate.d 目录下的所有配置文件。并且指定每月轮换一次 /var/log/wtmp 文件，它保持这个文件的 1 个转换版本，新建文件的属主为 root 属组为 utmp，权限设为 0664。 下表列出 logrotate.conf 最有用的选项，同样适用于 /etc/logrotate.d 下的配置文件 选项 含义 compress 压缩日志文件的所有非当前版本 daily 每日轮换日志文件 weekly 每周轮换日志文件 monthly 每月轮换日志文件 delaycompress 压缩除了当前和最近之外的所有其他版本 endscript 标记 prerotate 或者 postrotate 脚本结束 errors emailaddr 向指定的 emailaddr 发送出错通知邮件 missingok 如果日志不存在，不会发出报怨 notifempty 如果日志为空，则不轮换它 olddir dir 指定要放入 dir 里的日志文件老版本 postrotate 引入在轮换过日志之后要运行的脚本 prerotate 引入在进行任何发动之前运行的脚本 rotate n 在轮换方案中包括 n 个版本的日志 sharedscripts 只为整个日志组运行一次的脚本 size=logsize 如果日志文件大于 logsize（例如 100k, 4M）才轮换 logrotate 一般每天由 cron 运行一次，而在膝上机或者并非总是开着机的环境中则由 anacron 来运行。关于 cron 和 anacron 的介绍可以参考前面的学习笔记（八）周期性进程或者阅读关于该两款工具的权威文章，man 是一个不错的选择，当然如果您手头上也有一本《Linux 系统管理技术手册》的书的话那样最好。 3 rsyslogd: 系统事件的日志程序 如果您正在使用的是比较旧的发行版本，那么可能您需要将 rsyslog 替换成 syslog 来看待，比如在文章中看到 rsyslogd 那么在您的头脑中就将它翻译成 syslogd 这样。不过很幸运地，在 Ubuntu 10.10 和 Fedora 17 这两款具有代表性的发行版本上所使用的均是 rsyslogd 系统日志程序。 我查阅了一下资料，在 RHEL 5.5 的发行版本上使用的似乎就是 syslogd，所以在阅读以下文字的时候需要根据系统所使用的相应的程序来进行阅读。 古人言：尽信书不如无书。 3.1 syslog 的体系结构 （这里的 syslog 是一个概念，并非对应一个具体的程序，除非字体被加粗，否则只是一个系统日志(syslog)的概念） syslog 包括 3 个部分： rsyslogd 日志守护进程（及其配置文件 /etc/rsyslog.conf） logger 一条从 shell 提交日志记录项的用户级命令。 库例程 openlog, syslog, closelog 用于在程序中使用 syslog 3.2 配置 rsyslogd 配置文件 /etc/rsyslog.conf 控制着 rsyslogd 的行为。在文件的开头部分指明了您可以参考的文档的路径，在 Ubuntu 10.10 里是 /usr/share/doc/rsyslog-doc/html/rsyslog_conf.html，不过 Ubuntu 10.10 默认情况下并没有安装该文档的，所以你在查阅之前可能需要先安装 $ sudo apt-get install rsyslog-doc 而在 Fedora 17 系统很幸运地默认已经安装好了，路径为 /usr/share/doc/rsyslog-5.8.10/rsyslog_conf.html。具体路径根据不同系统会有些少差别，需要根据自身使用系统的特点进行查阅。 /etc/rsyslog.conf 是一个格式相当简单的文本文件。# 为注释符。基本格式为： selector    action 例如，下面的一行： mail.*                          /var/log/mail.log 将把来自电子邮件系统的信息保存在文件 /var/log/mail.log 中。 selector 用语法 [facility.level] 指明正在发送日志消息的程序和消息的严重级别。 selector 可以包含特殊的关键字 * 和 none，其含义分别为“所有的”和“什么都没有”。selector 可以包括多个用逗号分开的设备。多个 selector 可以用分号组合起来。 一般而言，selector 相互之间为“or”的关系，和某个 selector 匹配的消息将由同一行的 action 处理。但是，不管同一行中其他的 selector 是如何定义的，只要有一个带有 none 级别的，selector 就会排除列出的设备。比如下面这句 *.*;auth,authpriv.none          -/var/log/syslog 意思就是将所有的系统信息记录到 /var/log/syslog 中但除了 auth 和 authpriv 的信息。 下表列出了有效的设备名。 设备（facility） 使用该设备的程序 * 除了“mark”以外的所有设备 auth 与安全和授权有关的命令 authpriv 敏感、保密的授权信息 cron 守护进程 cron daemon 系统守护进程 ftp FTP 守护进程，*ftpd* kern 内核 local0-7 本地消息的 8 种类型 lpr 行式打印机的假脱机系统 mail mail 相关软件 mark 定期产生的时间戳 news Usernet 新闻系统 syslog rsyslogd 内部消息 user 用户进程 uucp 为 UUCP 保留，并未使用 syslog 的严重性级别按照重要性递减的顺序排列如下表： 级别 大致含义 emerg 恐慌状态 alert 紧急状态 crit 临界状态 err 错误情况 warning 警告消息 notice 需要调查的事项 info 提供信息的消息 debug 仅供调试 Linux 版的 syslog 对基本语法做了改进，它也允许在优先级前面加上字符 = 和 !，分别表示“仅此优先级”和“除此优先级及其以上级别”的意思。下表给出了一些例子： 选择符 含义 mail.info 选择与邮件相关的优先级为 info 或者更高的消息 mail.=info 只选择优先级为 info 的消息 mail.info;mail.!err 只选择优先级为 info 以上，err 以下的消息 mail.debug;mail.!=warning 选择除 warning 之外的所有优先级 action 字段说明如何处理一则消息。下表列出可以选择的处理方法： 动作（Action） 含义 filename 把消息写入本地机器上的一个文件里 @hostname 把消息转发给主机 hostname 上的 rsyslogd @ipaddress 把消息转发给 IP 地址为 ipaddress 的主机 fifoname 把消息写入有名管道 fifoname user1,user2 如果用户登录到了系统上，那么就把消息写在用户的屏幕上 * 把消息写给目前已经登录的所有用户 您可以在 filename 动作之前加一个短划线“-”，表示在写完每条日志记录项后，不应该对文件系统执行 sync 操作，执行 sync 有助于在发生崩溃的时候尽可能多地保留日志信息，但是从磁盘吞吐上来看，代价又太大了。 3.3 调试 syslog logger 命令用于从 shell 脚本提交日志项。用户也可以用它来检测 rsyslogd 的配置文件的变化。例如，如果已经添加了一行： local5.warning          /tmp/evi.log 而且想看看它是否正常工作，则运行： $ logger -p local5.warning \"test message\" 含有“test message”的一行记录项应该写到 /tmp/evi.log 文件中，如果没有写入，那么可能是忘记了给 rsyslogd 发送挂起信号。 3.4 在程序中使用 syslog 库例程 openlog，syslog 和 closelog 能够让程序使用 syslog 系统。这些库例程有 C、Perl、Python 和 PHP 版本，我在这里以 python 做个示例： #! /usr/bin/python# -*- coding: utf-8 -*-import syslogsyslog.openlog('logdemo', syslog.LOG_PID | syslog.LOG_CONS, syslog.LOG_USER)syslog.syslog(syslog.LOG_INFO, \"This is a logdemo test for syslog\")syslog.closelog() 选择你喜爱的编辑器，emacs 或者 vi，将上面的代码添加上去，然后将文件保存成 logdemo 并修改它的执行权限 $ chmod +x logdemo 运行之后就应该在 /var/log/messages 或者 /var/log/syslog（Ubuntu）文件中看到产生的日志记录： Dec 22 22:23:34 bluebird-system logdemo[8109]: This is a logdemo test for syslog Enjoy & Have fun.","title":"Linux 学习笔记（十）系统日志"},{"content":"下载mahout包 解压到对应的文件 配置环境变量 vi ~/.bashrc 最后添加下面四行 export HADOOP_HOME=/usr/local/hadoop-0.20.205.0 export HADOOP_CONF_DIR=/usr/local/hadoop-0.20.205.0/conf export MAHOUT_HOME=/usr/local/mahout-distribution-0.5 export PATH=$HADOOP_HOME/bin:$MAHOUT_HOME/bin:$PATH 输入 source ~/.bashrc 输入 mahout 输出mahout包含的算法","title":"mahout安装 （ubuntu 12.0.4LTS）"},{"content":"错误：  error: conflicting types for ‘SetMaxNum’ 个人原因： 类型定义出错，头文件中定义为int    而在源文件中（即.C文件）中 却定义为Void型  其他原因 原因一： 原来是因为没有先做函数声明，而函数位于main()之后。 在main函数前声明了函数原型后，一切ok.   原因二： 头文件的被循环引用，在引用时考虑清楚包含顺序   原因三： 头文件声明和定义参数稍有不同 例：  头文件中声明 void Hanlder(constchar * buf);  在定义时写作 void Hanlder(char *buf); 这是就会发生conflictingtypes for 错误问题","title":"error: conflicting types"},{"content":"步骤如下： 1. 下载SDL_draw（SDL_draw-1.2.13.tar.gz）开源包（http://sdl-draw.sourceforge.net/） 2. 编译，安装开源包 sudo ./configure loading cache ./config.cache checking for a BSD compatible install... (cached) /usr/bin/install -c checking whether build environment is sane... yes checking whether make sets ${MAKE}... (cached) yes checking for working aclocal-1.4... missing checking for working autoconf... found checking for working automake-1.4... missing checking for working autoheader... found checking for working makeinfo... missing checking host system type... i686-pc-linux-gnu checking build system type... i686-pc-linux-gnu checking for ranlib... (cached) ranlib checking for gcc... (cached) gcc checking whether the C compiler (gcc  ) works... yes checking whether the C compiler (gcc  ) is a cross-compiler... no checking whether we are using GNU C... (cached) yes checking whether gcc accepts -g... (cached) yes checking for ld used by GCC... (cached) /usr/bin/ld checking if the linker (/usr/bin/ld) is GNU ld... (cached) yes checking for BSD-compatible nm... (cached) /usr/bin/nm -B checking whether ln -s works... (cached) yes loading cache ./config.cache within ltconfig checking for object suffix... o checking for executable suffix... (cached) no checking for gcc option to produce PIC... -fPIC checking if gcc PIC flag -fPIC works... yes checking if gcc supports -c -o file.o... yes checking if gcc supports -c -o file.lo... yes checking if gcc supports -fno-rtti -fno-exceptions ... no checking if gcc static flag -static works... -static checking if the linker (/usr/bin/ld) is GNU ld... yes checking whether the linker (/usr/bin/ld) supports shared libraries... yes checking command to parse /usr/bin/nm -B output... ok checking how to hardcode library paths into programs... immediate checking for /usr/bin/ld option to reload object files... -r checking dynamic linker characteristics... Linux ld.so checking if libtool supports shared libraries... yes checking whether to build shared libraries... yes checking whether to build static libraries... yes checking for objdir... .libs creating libtool loading cache ./config.cache checking for gcc... (cached) gcc checking whether the C compiler (gcc -g -O2 ) works... yes checking whether the C compiler (gcc -g -O2 ) is a cross-compiler... no checking whether we are using GNU C... (cached) yes checking whether gcc accepts -g... (cached) yes checking for ranlib... (cached) ranlib checking target system type... i686-pc-linux-gnu checking for sdl-config... (cached) /usr/bin/sdl-config checking for SDL - version >= 1.2.0... yes creating ./config.status creating Makefile creating src/Makefile sudo make Making all in src make[1]: Entering directory `/home/fangl/SDL_draw-1.2.13/src' /bin/sh ../libtool --mode=compile gcc -DPACKAGE=\\\"SDL_draw\\\" -DVERSION=\\\"1.2.1\\\"  -I. -I.  `sdl-config --cflags` -I../include     -g -O2 -I/usr/include/SDL -D_GNU_SOURCE=1 -D_REENTRANT -c SDL_draw.c rm -f .libs/SDL_draw.lo gcc -DPACKAGE=\\\"SDL_draw\\\" -DVERSION=\\\"1.2.1\\\" -I. -I. -I/usr/include/SDL -D_GNU_SOURCE=1 -D_REENTRANT -I../include -g -O2 -I/usr/include/SDL -D_GNU_SOURCE=1 -D_REENTRANT -Wp,-MD,.deps/SDL_draw.pp -c SDL_draw.c  -fPIC -DPIC -o .libs/SDL_draw.lo gcc -DPACKAGE=\\\"SDL_draw\\\" -DVERSION=\\\"1.2.1\\\" -I. -I. -I/usr/include/SDL -D_GNU_SOURCE=1 -D_REENTRANT -I../include -g -O2 -I/usr/include/SDL -D_GNU_SOURCE=1 -D_REENTRANT -Wp,-MD,.deps/SDL_draw.pp -c SDL_draw.c -o SDL_draw.o >/dev/null 2>&1 mv -f .libs/SDL_draw.lo SDL_draw.lo /bin/sh ../libtool --mode=link gcc  -g -O2 -I/usr/include/SDL -D_GNU_SOURCE=1 -D_REENTRANT  -o libSDL_draw.la -rpath /usr/local/lib -release 1.2    -version-info 0:1:0                              SDL_draw.lo  -L/usr/lib -lSDL rm -fr .libs/libSDL_draw.la .libs/libSDL_draw.* .libs/libSDL_draw-1.2.* gcc -shared  SDL_draw.lo  -L/usr/lib -lSDL -lc  -Wl,-soname -Wl,libSDL_draw-1.2.so.0 -o .libs/libSDL_draw-1.2.so.0.0.1 (cd .libs && rm -f libSDL_draw-1.2.so.0 && ln -s libSDL_draw-1.2.so.0.0.1 libSDL_draw-1.2.so.0) (cd .libs && rm -f libSDL_draw.so && ln -s libSDL_draw-1.2.so.0.0.1 libSDL_draw.so) ar cru .libs/libSDL_draw.a  SDL_draw.o ranlib .libs/libSDL_draw.a creating libSDL_draw.la (cd .libs && rm -f libSDL_draw.la && ln -s ../libSDL_draw.la libSDL_draw.la) make[1]: Leaving directory `/home/fangl/SDL_draw-1.2.13/src' make[1]: Entering directory `/home/fangl/SDL_draw-1.2.13' make[1]: Nothing to be done for `all-am'. make[1]: Leaving directory `/home/fangl/SDL_draw-1.2.13' sudo make install Making install in src make[1]: Entering directory `/home/fangl/SDL_draw-1.2.13/src' make[2]: Entering directory `/home/fangl/SDL_draw-1.2.13/src' /bin/sh ../mkinstalldirs /usr/local/lib /bin/sh ../libtool  --mode=install /usr/bin/install -c libSDL_draw.la /usr/local/lib/libSDL_draw.la /usr/bin/install -c .libs/libSDL_draw-1.2.so.0.0.1 /usr/local/lib/libSDL_draw-1.2.so.0.0.1 (cd /usr/local/lib && rm -f libSDL_draw-1.2.so.0 && ln -s libSDL_draw-1.2.so.0.0.1 libSDL_draw-1.2.so.0) (cd /usr/local/lib && rm -f libSDL_draw.so && ln -s libSDL_draw-1.2.so.0.0.1 libSDL_draw.so) /usr/bin/install -c .libs/libSDL_draw.lai /usr/local/lib/libSDL_draw.la /usr/bin/install -c .libs/libSDL_draw.a /usr/local/lib/libSDL_draw.a ranlib /usr/local/lib/libSDL_draw.a chmod 644 /usr/local/lib/libSDL_draw.a PATH=\"$PATH:/sbin\" ldconfig -n /usr/local/lib ---------------------------------------------------------------------- Libraries have been installed in:    /usr/local/lib If you ever happen to want to link against installed libraries in a given directory, LIBDIR, you must either use libtool, and specify the full pathname of the library, or use `-LLIBDIR' flag during linking and do at least one of the following:    - add LIBDIR to the `LD_LIBRARY_PATH' environment variable      during execution    - add LIBDIR to the `LD_RUN_PATH' environment variable      during linking    - use the `-Wl,--rpath -Wl,LIBDIR' linker flag    - have your system administrator add LIBDIR to `/etc/ld.so.conf' See any operating system documentation about shared libraries for more information, such as the ld(1) and ld.so(8) manual pages. ---------------------------------------------------------------------- make[2]: Nothing to be done for `install-data-am'. make[2]: Leaving directory `/home/fangl/SDL_draw-1.2.13/src' make[1]: Leaving directory `/home/fangl/SDL_draw-1.2.13/src' make[1]: Entering directory `/home/fangl/SDL_draw-1.2.13' make[2]: Entering directory `/home/fangl/SDL_draw-1.2.13' make[2]: Nothing to be done for `install-exec-am'. make[2]: Nothing to be done for `install-data-am'. make[2]: Leaving directory `/home/fangl/SDL_draw-1.2.13' make[1]: Leaving directory `/home/fangl/SDL_draw-1.2.13' 这样SDL_draw开源包就安装成功了。 注意：按照如上进行编译安装之后的文件存放在默认目录：／usr/local/lib 安装文件： libSDL_draw-1.2.so.0      libSDL_draw.a   libSDL_draw.so libSDL_draw-1.2.so.0.0.1  libSDL_draw.la  3. 环境配置 在这里，我将以上5个文件libSDL_draw*拷贝到／usr/lib下。（why？因为sdl的libSDL_image，libSDL_gfx等都在这个目录下，不用编译时和sdl的路径不一样） 注意：网上export添加路径为临时路径，而且还要把此路径加入到如上编译命令中去，麻烦。 4. 最后不要忘记添加SDL_draw.h 如上编译安置，配置之后，还缺少一个文件——SDL_draw.h，此文件网上去找。最后将SDL_draw.h拷贝到/usr/include/SDL目录里。 编译运行：g++ -o temp temp.cpp `sdl-config --cflags --libs` -lSDL_draw","title":"ubuntu下安装SDL_draw"},{"content":"1 、单链表在页帧管理的应用        在一些支持虚拟内存的系统中有关链表的运用，虚拟内存是一种地址空间的映射机制，它允许进程不必完全加载到物理内存中也可以得到运行。这种方式的一个突出优点就是进程可以使用比熊实际所允许的物理内存大得多的地址空间。另外一个优点是多个进程能够共享的内存以并发的方式运行。     先简单的介绍Linux操作系统存储管理方式，Linux系统采用请求式分页虚拟内存管理的方式，系统为每个进程提供了4GB的虚拟内存空间。各个进程的虚拟内存彼此独立。     那么这样运行在虚拟内存机制下的进程需要处理虚拟地址。这些地址对于虚拟内存来说就行物理内存地址一样，但是使用前必须要有操作系统做转换，由专门的硬件所支持的页表来快速执行地址的转换工作。每个进程都有自己的页表，将它的虚拟地址空间中的页映射到物理内存中的页帧上。当某个进程引用一个虚拟地址时，页表中的某项需要见车并决定页关联到那个物理的页帧上（见下图）。   页帧管理的函数的是实现 这里只介绍页帧管理中的2个重要的函数 alloc_frame  free_frame。使用链表来维护可供分配的页帧，函数alloc_frame从空闲的页帧链表中货物空闲的页帧好。给定某个特定的页。将页帧号放在特定的页表中来检查该页面应对应哪个物理的页帧。当页面从物理内存中移除的时候，函数free_frame接受一个页帧号并将其放回到空闲页帧链表中。使用链表来管理页帧是一个非常好的办法，因为页帧的分配涉及到频繁的插入和删除操作，这些操作都定义在链表的头。下面为具体函数的实现，涉及到前面所定义的单链表的函数。 /*frames.c */#include <stdlib.h>#include \"frames.h\"#include \"../include/list.h\"/*alloc_frame */int alloc_frame(List *frames,int frame_number){   int *data;   /* Allocate storage for the frame number */   if ((data = (int *)malloc(sizeof(int))) == NULL){        return -1;    }   *data  = frame_number;   if(list_ins_next(frames, NULL, data) != 0){        return -1;    }   return 0;}int free_frame(list *frames){    int frame_number,*data;    if (list_size(frames) == 0)        return -1;    else {        if (list_rem_next(frames, NULL, (void **)& data) != 0){            return -1;            } else {            frame_number = *data;            free(data);            }    }    return frame_number;} 2、循环链表在页面置换的用法    在上面介绍了单链表在管理页帧的分配，但还有一个问题没有搞清楚，那就是当空闲页面链表为空时，系统将如何分配新的页帧？为了解决这个问题操作系统从物理内存中取出一个页面将其放大称为交换磁盘的磁盘空间中，以这种当时来释放页帧。操作系统采用页面置换算法来决定置换在哪一个页帧在当前时刻最适合释放。页面置换算法中的一个例子是第二次机会置换法，也成为时钟算法。   第二次机会置换法是实现LRU（Least Recently Used）页面置换法的一种方式。它的工作方式是：维护一个当前存在于物理内存中的页面循环链表。假设链表中的每个元素只存储一个页码和一个引用值，引用值要么为1要么为0.在实践中，每个元素还会包含其他的信息。所有的页面初始的引用值都为0，每当系统访问页面时。该页面的应用值就设置为1.当需要某个页帧时操作系统就使用它维护的循环链表以及引用值来判断哪些页面应该释放其页帧。为了确定这一点开始遍历链表知道找到一个引用值为0的元素。当遍历每一个页面时，操作系统将页面的引用值从1重设回0.一旦它遇到的引用为0的元素，就是找到了一个上次便利链表以来都没有被系统访问的页面。就是最近很少使用的页面。   第二次页面置换算法的实现 /* page.h*/#ifndef PAGE_H#define PAGE_H#include \"../include/clist.h\"/*define a structuue for information about pages */typedef struct Page_{    int number;    int reference;}Page;/* public Interface */int replace_page(CListElmt **current);#endif   /*page.c*/#include \"../include/clist.h\"#include \"../include/page.h\"/*relace_page */int replace_page(CListElmt * * current){    while (((Page *)(* current) ->data)->reference != 0){        ((Page *)(* current) ->data)->reference = 0;        *current = clist_next(*current);    }    return ((Page *)(*current)->data->number;}    ","title":"C 算法 -----链表在页帧和页面转换的应用"},{"content":"一、I/O设备的类型 按照设备的所属关系，将I/O设备分为以下两种： 1.系统设备 系统生成时登记于系统中的标准设备，属于系统的基本配置 2.用户设备 系统生成时未登记在系统中的非标准设备 按照设备信息交换的数据单位分类： 1.字符设备 以字符为单位进行输入和输出的设备 2.块设备 块设备的输入和输出是以数据块为单位进行的。 按照设备的共享属性分类： 1.独占设备 字符设备都是独占设备，在一段时间内只允许一个用户访问的设备 2.共享设备 块设备都是共享设备，允许多个进程同时访问 3.虚拟设备 通过虚拟技术实现一台独占设备分为若干个逻辑设备，共多个用户使用，提高设备的利用率。 设备管理的任务和功能 设备管理是对计算机的输入/输出系统的管理，它是操作系统最具有多样性和复杂性的部分，主要任务如下： 1.选择和分配I/O设备，以便对数据进行传输操作。 2.控制I/O设备和CPU或者内存进行数据交换。 3.为用户和用户设备提供接口。 4.提高设备与设备之间，CPU与设备之间，进程与进程之间的的并行操作程度。 为了完成上述任务，设备管理程序需要提供下述功能： 1）提供和进程管理系统的接口 2）进行设备分配 3）实现设备和设备、设备和CPU等之间的并行操作 4）进行缓冲管理 5）设备控制与驱动 设备控制器 设备控制器是CPU与I/O设备之间的接口，它接收从CPU发出的命令并去控制相应的I/O设备工作。设备控制器是一个可编址设备，当它仅控制一个设备时，它只有一个唯一的设备地址；当它控制多个设备时，则具有多个设备地址，每个设备地址控制一个设备。","title":"Linux设备管理"},{"content":"Segmentation fault 标签： segmentation fault linux it 分类： linux Segment fault 之所以能够流行于世，是与Glibc库中基本所有的函数都默认型参指针为非空有着密切关系的。 背景     最近一段时间在linux下用C做一些学习和开发，但是由于经验不足，问题多多。而段错误就是让我非常头痛的一个问题。不过，目前写一个一千行左右的代码，也很少出现段错误，或者是即使出现了，也很容易找出来，并且处理掉。     那什么是段错误？段错误为什么是个麻烦事？以及怎么发现程序中的段错误以及如何避免发生段错误呢？     一方面为了给自己的学习做个总结，另一方面由于至今没有找到一个比较全面介绍这个虽然是“FREQUENTLY ASKED QUESTIONS”的问题，所以我来做个抛砖引玉吧。下面就从上面的几个问题出发来探讨一下“Segmentation faults\"吧。 目录 1。什么是段错误？ 2。为什么段错误这么“麻烦”？ 3。编程中通常碰到段错误的地方有哪些？ 4。如何发现程序中的段错误并处理掉？ 正文 1。什么是段错误？ 下面是来自Answers.com的定义： A segmentation fault (often shortened to segfault) is a particular error condition that can occur during the operation of computer software. In short, a segmentation fault occurs when a program attempts to access a memory location that it is not allowed to access, or attempts to access a memory location in a way that is not allowed (e.g., attempts to write to a read-only location, or to overwrite part of the operating system). Systems based on processors like the Motorola 68000 tend to refer to these events as Address or Bus errors. Segmentation is one approach to memory management and protection in the operating system. It has been superseded by paging for most purposes, but much of the terminology of segmentation is still used, \"segmentation fault\" being an example. Some operating systems still have segmentation at some logical level although paging is used as the main memory management policy. On Unix-like operating systems, a process that accesses invalid memory receives the SIGSEGV signal. On Microsoft Windows, a process that accesses invalid memory receives the STATUS_ACCESS_VIOLATION exception. 另外，这里有个基本上对照的中文解释，来自http://www.linux999.org/html_sql/3/132559.htm 所谓的段错误就是指访问的内存超出了系统所给这个程序的内存空间，通常这个值是由gdtr来保存的，他是一个48位的寄存器，其中的32位是保存由它指向的gdt表，后13位保存相应于gdt的下标，最后3位包括了程序是否在内存中以及程序的在cpu中的运行级别,指向的gdt是由以64位为一个单位的表，在这张表中就保存着程序运行的代码段以及数据段的起始地址以及与此相应的段限和页面交换还有程序运行级别还有内存粒度等等的信息。一旦一个程序发生了越界访问，cpu就会产生相应的异常保护，于是segmentation fault就出现了 通过上面的解释，段错误应该就是访问了不可访问的内存，这个内存区要么是不存在的，要么是受到系统保护的。 2。为什么段错误这么麻烦？ 中国linux论坛有一篇精华帖子《Segment fault 之永远的痛》(http://www.linuxforum.net/forum/gshowflat.php?Cat=&Board=program&Number=193239&page=2&view=collapsed&sb=5&o=all&fpart=1&vc=1) 在主题帖子里头，作者这么写道： 写程序好多年了，Segment fault 是许多C程序员头疼的提示。指针是好东西，但是随着指针的使用却诞生了这个同样威力巨大的恶魔。 Segment fault 之所以能够流行于世，是与Glibc库中基本所有的函数都默认型参指针为非空有着密切关系的。 不知道什么时候才可以有能够处理NULL的glibc库诞生啊！ 不得已，我现在为好多的函数做了衣服，避免glibc的函数被NULL给感染，导致我的Mem访问错误，而我还不知道NULL这个病毒已经在侵蚀我的身体了。 Segment fault 永远的痛......     后面有好多网友都跟帖了，讨论了Segmentation faults为什么这么“痛”，尤其是对于服务器程序来说，是非常头痛的，为了提高效率，要尽量减少一些不必要的段错误的“判断和处理”，但是不检查又可能会存在段错误的隐患。     那么如何处理这个“麻烦”呢？     就像人不可能“完美”一样，由人创造的“计算机语言“同样没有“完美”的解决办法。     我们更好的解决办法也许是：     通过学习前人的经验和开发的工具，不断的尝试和研究，找出更恰当的方法来避免、发现并处理它。对于一些常见的地方，我们可以避免，对于一些“隐藏”的地方，我们要发现它，发现以后就要及时处理，避免留下隐患。     下面我们可以通过具体的实验来举出一些经常出现段错误的地方，然后再举例子来发现和找出这类错误藏身之处，最后处理掉。 3。编程中通常碰到段错误的地方有哪些？ 为了进行下面的实验，我们需要准备两个工具，一个是gcc，一个是gdb 我是在ubuntu下做的实验，安装这两个东西是比较简单的 sudo apt-get install gcc-4.0 libc6-dev sudo apt-get install gdb 好了，开始进入我们的实验，我们粗略的分一下类 1）往受到系统保护的内存地址写数据     有些内存是内核占用的或者是其他程序正在使用，为了保证系统正常工作，所以会受到系统的保护，而不能任意访问。 例子1： Code: ＃i nclude <stdio.h> int main() {  <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> int i = 0;  <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> scanf (\"%d\", i); <wbr>  <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> printf (\"%d\\n\", i);  <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> return 0; } [Ctrl+A Select All]     编译和执行一下 $ gcc -o segerr segerr.c $ ./segerr 10 段错误     咋一看，好像没有问题哦，不就是读取一个数据然后给输出来吗？ 下面我们来调试一下，看看是什么原因？ $ gcc -g -o segerr segerr.c        --加-g选项查看调试信息 $ gdb ./segerr (gdb) l                    --用l(list)显示我们的源代码 1       ＃i nclude <stdio.h> 2 3       int 4       main() 5       { 6               int i = 0; 7 8               scanf (\"%d\", i);  9               printf (\"%d\\n\", i); 10              return 0; (gdb) b 8                --用b(break)设置断点 Breakpoint 1 at 0x80483b7: file segerr.c, line 8. (gdb) p i                --用p(print)打印变量i的值[看到没，这里i的值是0哦] $1 = 0 (gdb) r                    --用r(run)运行，直到断点处 Starting program: /home/falcon/temp/segerr Breakpoint 1, main () at segerr.c:8 8               scanf (\"%d\", i);  --[试图往地址0处写进一个值] (gdb) n                    --用n(next)执行下一步 10 Program received signal SIGSEGV, Segmentation fault. 0xb7e9a1ca in _IO_vfscanf () from /lib/tls/i686/cmov/libc.so.6 (gdb) c            --在上面我们接收到了SIGSEGV,然后用c(continue)继续执行 Continuing. Program terminated with signal SIGSEGV, Segmentation fault. The program no longer exists. (gdb) quit        --退出gdb 果然 我们“不小心”把&i写成了i 而我们刚开始初始化了i为0,这样我们不是试图向内存地址0存放一个值吗？实际上很多情况下，你即使没有初始化为零，默认也可能是0，所以要特别注意。 补充： 可以通过man 7 signal查看SIGSEGV的信息。 $ man 7 signal | grep SEGV Reformatting signal(7), please wait...        SIGSEGV      11       Core    Invalid memory reference 例子2： Code: ＃i nclude <stdio.h> int main() {  <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> char *p;  <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> p = NULL;  <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> *p = 'x';  <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> printf(\"%c\", *p);  <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> return 0; } [Ctrl+A Select All] 很容易发现，这个例子也是试图往内存地址0处写东西。 这里我们通过gdb来查看段错误所在的行 $ gcc -g -o segerr segerr.c $ gdb ./segerr (gdb) r        --直接运行，我们看到抛出段错误以后，自动显示出了出现段错误的行，这就是一个找出段错误的方法 Starting program: /home/falcon/temp/segerr Program received signal SIGSEGV, Segmentation fault. 0x08048516 in main () at segerr.c:10 10              *p = 'x'; (gdb) 2）内存越界(数组越界，变量类型不一致等) 例子3： Code: ＃i nclude <stdio.h> int main() {  <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> char test[1];  <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> printf(\"%c\", test[1000000000]);  <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> return 0; } [Ctrl+A Select All] 这里是比较极端的例子，但是有时候可能是会出现的，是个明显的数组越界的问题 或者是这个地址是根本就不存在的 例子4： Code: ＃i nclude <stdio.h> int main() {  <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> int b = 10;  <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> printf(\"%s\\n\", b);  <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> <wbr> return 0; } [Ctrl+A Select All] 我们试图把一个整数按照字符串的方式输出出去，这是什么问题呢？ 由于还不熟悉调试动态链接库，所以 我只是找到了printf的源代码的这里 声明部分：     int pos =0 ,cnt_printed_chars =0 ,i ; 　　unsigned char *chptr ; 　　va_list ap ; %s格式控制部分： case 's': 　　    chptr =va_arg (ap ,unsigned char *); 　　    i =0 ; 　　    while (chptr [i ]) 　　    {... 　　        cnt_printed_chars ++; 　　        putchar (chptr [i ++]); 　　} 仔细看看，发现了这样一个问题，在打印字符串的时候，实际上是打印某个地址开始的所有字符，但是当你想把整数当字符串打印的时候，这个整数被当成了一个地址，然后printf从这个地址开始去打印字符，直到某个位置上的值为\\0。所以，如果这个整数代表的地址不存在或者不可访问，自然也是访问了不该访问的内存——segmentation fault。 类似的，还有诸如：sprintf等的格式控制问题 比如，试图把char型或者是int的按照%s输出或存放起来，如： Code: ＃i nclude <stdio.h> ＃i nclude <string.h> char c='c'; int i=10; char buf[100]; printf(\"%s\", c); <wbr> <wbr>  <wbr> <wbr> <wbr>  <wbr>//试图把char型按照字符串格式输出，这里的字符会解释成整数，再解释成地址，所以原因同上面那个例子 printf(\"%s\", i); <wbr> <wbr>  <wbr> <wbr> <wbr>  <wbr> <wbr> <wbr>  <wbr>//试图把int型按照字符串输出 memset(buf, 0, 100); sprintf(buf, \"%s\", c); <wbr> <wbr>  <wbr>//试图把char型按照字符串格式转换 memset(buf, 0, 100); sprintf(buf, \"%s\", i); <wbr> <wbr> //试图把int型按照字符串转换 [Ctrl+A Select All] 3）其他 其实大概的原因都是一样的，就是段错误的定义。但是更多的容易出错的地方就要自己不断积累，不段发现，或者吸纳前人已经积累的经验，并且注意避免再次发生。 例如： <1>定义了指针后记得初始化，在使用的时候记得判断是否为NULL <2>在使用数组的时候是否被初始化，数组下标是否越界，数组元素是否存在等 <3>在变量处理的时候变量的格式控制是否合理等 再举一个比较不错的例子： 我在进行一个多线程编程的例子里头，定义了一个线程数组 #define THREAD_MAX_NUM pthread_t thread[THREAD_MAX_NUM]; 用pthread_create创建了各个线程，然后用pthread_join来等待线程的结束 刚开始我就直接等待，在创建线程都成功的时候，pthread_join能够顺利等待各个线程结束，但是一旦创建线程失败，那用pthread_join来等待那个本不存在的线程时自然会存在访问不能访问的内存的情况，从而导致段错误的发生，后来，通过不断调试和思考，并且得到网络上资料的帮助，找到了上面的原因和解决办法： 在创建线程之前，先初始化我们的线程数组，在等待线程的结束的时候，判断线程是否为我们的初始值 如果是的话，说明我们的线程并没有创建成功，所以就不能等拉。否则就会存在释放那些并不存在或者不可访问的内存空间。 上面给出了很常见的几种出现段错误的地方，这样在遇到它们的时候就容易避免拉。但是人有时候肯定也会有疏忽的，甚至可能还是会经常出现上面的问题或者其他常见的问题，所以对于一些大型一点的程序，如何跟踪并找到程序中的段错误位置就是需要掌握的一门技巧拉。 4。如何发现程序中的段错误？ 有个网友对这个做了比较全面的总结，除了感谢他外，我把地址弄了过来。文章名字叫《段错误bug的调试》(http://www.cublog.cn/u/5251/showart.php?id=173718),应该说是很全面的。 而我常用的调试方法有： 1）在程序内部的关键部位输出(printf)信息，那样可以跟踪 段错误 在代码中可能的位置 为了方便使用这种调试方法，可以用条件编译指令#ifdef DEBUG和#endif把printf函数给包含起来，编译的时候加上-DDEBUG参数就可以查看调试信息。反之，不加上该参数进行调试就可以。 2）用gdb来调试，在运行到段错误的地方，会自动停下来并显示出错的行和行号 这个应该是很常用的，如果需要用gdb调试，记得在编译的时候加上-g参数，用来显示调试信息,对于这个，网友在《段错误bug的调试》文章里创造性的使用这样的方法，使得我们在执行程序的时候就可以动态扑获段错误可能出现的位置：通过扑获SIGSEGV信号来触发系统调用gdb来输出调试信息。如果加上上面提到的条件编译，那我们就可以非常方便的进行段错误的调试拉。 3）还有一个catchsegv命令 通过查看帮助信息，可以看到 Catch segmentation faults in programs 这个东西就是用来扑获段错误的，它通过动态加载器（ld-linux.so）的预加载机制（PRELOAD）把一个事先写好的库（/lib/libSegFault.so）加载上，用于捕捉断错误的出错信息。 到这里，“初级总结篇”算是差不多完成拉。欢迎指出其中表达不当甚至错误的地方，先谢过! 参考资料[具体地址在上面的文章中都已经给出拉]： 1。段错误的定义 Ansers.com http://www.answers.com Definition of \"Segmentation fault\" http://www.faqs.org/qa/qa-673.html 2。《什么是段错误》 http://www.linux999.org/html_sql/3/132559.htm 3。《Segment fault 之永远的痛》 http://www.linuxforum.net/forum/gshowflat.php?Cat=&Board=program&Number=193239&page=2&view=collapsed&sb=5&o=all&fpart= 4。《段错误bug的调试》 http://www.cublog.cn/u/5251/showart.php?id=173718 后记 虽然感觉没有写什么东西,但是包括查找资料和打字，也花了好些几个小时，不过总结一下也是值得的，欢迎和我一起交流和讨论，也欢迎对文章中表达不当甚至是错误的地方指正一下。","title":"Segmentation fault"},{"content":"线程是指进程内的一个执行单元,也是进程内的可调度实体. 与进程的区别: (1)地址空间:进程内的一个执行单元;进程至少有一个线程;它们共享进程的地址空间;而进程有自己独立的地址空间; (2)资源拥有:进程是资源分配和拥有的单位,同一个进程内的线程共享进程的资源 (3)线程是处理器调度的基本单位,但进程不是. 4)二者均可并发执行. 进程和线程都是由操作系统所体会的程序运行的基本单元，系统利用该基本单元实现系统对应用的并发性。进程和线程的区别在于： 简而言之,一个程序至少有一个进程,一个进程至少有一个线程.  线程的划分尺度小于进程，使得多线程程序的并发性高。  另外，进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率。  线程在执行过程中与进程还是有区别的。每个独立的线程有一个程序运行的入口、顺序执行序列和程序的出口。但是线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。  从逻辑角度来看，多线程的意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配。这就是进程和线程的重要区别。 进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位.  线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源.  一个线程可以创建和撤销另一个线程;同一个进程中的多个线程之间可以并发执行.","title":"进程与线程的区别"},{"content":"主要内容来自 http://gamblis.com/2010/02/12/how-to-install-virtualbox-guest-addition-in-fedora-12/ 1.升级kernel,运行 sudo yum -y update kernel 2.安装kernel-devel, kernel-headers, dkms, gcc serta gcc-c++ sudo yum -y install kernel-devel kernel-headers dkms gcc gcc-c++ 3.reboot 4.点虚拟机上方devices，里面install guest addition  找到，Vbox根目录下面的VboxGuestAddition.iso 然后一般就会自动运行安装。 未自动运行安装程序的就运行光盘下的 VBoxLinuxAdditions.run","title":"在fedora 17下安装VirtualBox Guest Addition"},{"content":"1.插入新硬盘，启动Linux服务器，使用fdisk -l  查看硬盘 #fdisk -l Disk /dev/sda: 1000.2 GB, 1000204886016 bytes 2.格式化硬盘 #mkfs -t ext4 /dev/sda 3.挂载硬盘 #mount 硬盘地址  要挂载的地址 #mount /dev/sda /media/imgs 4.实现系统重启后自动挂载该分区 #vi  /etc/fstab 在最后一行添加 /dev/sda  /media/imgs                  ext4    defaults        1   2  ","title":"Linux 添加新硬盘 自动挂载硬盘"},{"content":"频繁重启apache 后可能会启动失败，错误日志如下： No space left on device: Couldn't create accept lock 运行命令 ipcs -s 会发现 semaphore 占用来很多， 使用命令清理 semaphore 后就可以正常启动apache 了 for i in `ipcs -s | awk ‘$3==\"root\" {print $2}’`; do ipcrm -s $i; done 当然，以上命令判断条件不一定是 $3==\"root\" ， 得视情况而定。 如若你的apache 是以 apache 用户运行的话那句好办了 如若 apache 是以 root 用户运行的话？ 我X ...  谁让你用root的？","title":"apache 启动问题"},{"content":"1. ramdisk.img文件gzip压缩文件, 所以要用gunzip命令解压缩. 但是gunzip需要默认后缀名.gz才可以正常解压, 不然会被忽略对待. (源文件类型) ramdisk.img: gzip compressed data, from Unix 2. 解压后名字会自动去掉.gz后缀,并重命名为ramdisk.img, 这时候文件类型为 ramdisk.img: ASCII cpio archive (SVR4 with no CRC) 3. 这时候就可以用cpio命令从ramdisk.img里面解压出跟文件系统的文件了, 所以建议新建一个目录来做 mkdir aaa 进入到目录里面 cpio -i -F ../ramdisk.img OK, 成功解压, 可以随便更改定制自己的跟文件系统了, init.rc随便你改吧 4. 定制好了之后开始重新打包了 cpio -i -t -F ../ramdisk.img > list cpio -o -H newc -O new.img < list 好了,打包好新的ramdisk.img了, 名字为new.img, 但是这时候还不能直接跑起来, 为什么呢?  看看文件类型吧 new.img: ASCII cpio archive (SVR4 with no CRC) 跟上面解压后的ramdisk.img一样, 所以这时候还差一步,就是重新用gzip 压缩 gzip new.img 搞定. 文件类型为 new.img.gz: gzip compressed data, was \"new.img\", from Unix, last modified: Mon Dec 24 10:59:51 2012 然后重新命名为ramdisk.img mv new.img.gz ramdisk.img 5. 好了, 有板子的就重新烧录ramdisk.img文件, 没板子的也可以运行模拟器了. emulator -ramdisk ./ramdisk.img -system ./system.img -data ./userdata.img -sdcard (可选) 整理一下命令吧 cp ramdisk.img ramdisk.img.gz gunzip ramdisk.img.gz mkdir aaa cd aaa cpio -i -F ../ramdisk.img (解压完毕, 定制自己的根文件系统) cpio -i -t -F ../ramdisk.img > list cpio -o -H newc -O new.img < list gzip new.img mv new.img.gz ramdisk.img cp ramdisk.img ../ramdisk.img (覆盖原来的ramdisk, 可选) emulator -ramdisk ./ramdisk.img -system ./system.img -data ./userdata.img","title":"重新解压打包android 根文件系统 ramdisk.img"},{"content":"1。在ndk-build的时候如果出现non-numeric second argument to `wordlist'function: ''.  这个error是由于jni上层的Android.xml问题导致的。所以在生成so的时候，先把这个文件删除编译即可。 在ndk-gdb的时候如果出现non-numericsecond argument to `wordlist' function: ''. 这个error，需要修改 __gmsl文件的第512行 把nt_encode= $(__gmsl_tr1)$(wordlist 1,$1,$(__gmsl_input_int)) 改成: int_encode = $(__gmsl_tr1)$(wordlist 1,$(words$1),$(__gmsl_input_int))即可。 2。如果出现 /arm-linux-androideabi-gcc: Command not found的编译问题，直接在ndk预编译的目录下查找，将arm-linux-androideabi-gcc-4.6改为需要的名字。 3。 如果出现 *** multiple target patterns. stop, 直接删除Lib, Obj两个文件夹重新编译。 4。","title":"android平台工程移植问题"},{"content":"欢迎到gripleaf.ys168.com 下Download文件夹下下载《鸟哥Linux私房菜——基础篇》学习笔记文档。 现已进入更新末期，预计未来不会再有更多改动了。将于不久之后开始整理《鸟哥Linux私房菜——服务器架设篇》学习笔记的整理。 希望能有在学Linux 的和我一起交流进步~ ——2012年12月25日","title":"《鸟哥Linux私房菜——基础篇》学习笔记持续整理中"},{"content":"    为了提高自己，不知不觉踏上了linux源码分析之路了！     我选择linux源码版本是linux 0.11，为什么选择它？因为它代码量少且资料多。     针对它的分析是建立于网上资料之上（快捷、效果好）。     项目如图：   该项目是网上某某已经编译好了，并且对它进行了分析。笔者只是学习他的皮毛。   首先进入项目的是bootsect：这个程序是linuxkernel的第一个程序，包括了linux自己的bootstrap程序，但是在 说明这个程序前，必须先说明一般IBMPC开机时的动作(此处的开机是指\"打开PC的电源\" )。它是第一个被读入内存中并执行的程序，现在，我们可以开始来看看到底它做了什么。  第一步 ：bootsect将它\"自己\"从被ROMBIOS载入的绝对地址0x7C00处搬到0x90000处， 然后利用一个jmpi(jumpindirectly)的指令，跳到新位置的jmpi的下一行去执行… 表示将跳到CS为0x9000，IP为offset\"go\"的位置(CS:IP=0x9000:offsetgo)，其中I NITSEC=0x9000定义于程序开头的部份，而go这个label则恰好是下一行指令所在的位置。 第二步：接着，将其它segmentregisters包括DS，ES，SS都指向0x9000这个位置，与CS看齐 。 第叁步：接着利用BIOS中断服务int13h的第0号功能，重置磁盘控制器，使得刚才的设定发挥功能。  第四步：完成重置磁盘控制器之后，bootsect就从磁盘上读入紧邻着bootsect的setup程序， 也就是以后将会介绍的setup.S，此读入动作是利用BIOS中断服务int13h的第2号功能。 第五步：再来，就要读入真正linux的kernel了，也就是你可以在linux的根目录下看到的\"v mlinuz\"。 第六步：接下来做的事是检查root device，之后就仿照一开始的方法，利用indirect jump跳到刚刚已读入的setup部份。  ;//bootsec.s文件说明如下:磁盘的引导块程序，驻留在磁盘的第一扇区。 ;//在PC机加电rom bios自检之后，引导扇区由bios加载到内存0x7c00处，然后将自己移动到内存0x90000处。 ;//该程序的主要作用是首先将setup模块从磁盘加载到内存中，紧接着bootsect的后面位置(0x90200),然后利用bios中断0x13中断去磁盘参数表中当前引导盘的参数， ;//然后在屏幕上显示\"Loading system...\"字符串。再者将system模块从磁盘上加载到内存0x10000开始的地方。随后确定根文件系统的设备号，如果没有指定， ;//则根据所保存的引导盘的每类型和种类，并保存设备号与boot_dev,最后长跳转到 setup程序开始处0x90200执行setup程序。   .model tiny .386p;// SYSSIZE是要加载的节数（16字节为1节）。3000h共为30000h字节＝192kB;// 对当前的版本空间已足够了。 SYSSIZE = 3000h\t\t;// 指编译连接后system模块的大小。\t\t\t\t\t\t;// 这里给出了一个最大默认值。 SETUPLEN = 4\t\t\t;// setup程序的扇区数（setup－sectors）值 BOOTSEG  = 07c0h\t\t;// bootsect的原始地址（是段地址，以下同） INITSEG  = 9000h\t\t;// 将bootsect移到这里 SETUPSEG = 9020h\t\t;// setup程序从这里开始 SYSSEG   = 1000h\t\t;// system模块加载到10000(64kB)处. ENDSEG   = SYSSEG + SYSSIZE\t\t;// 停止加载的段地址;// DEF_ROOT_DEV:\t000h - 根文件系统设备使用与引导时同样的软驱设备.;//\t\t301 - 根文件系统设备在第一个硬盘的第一个分区上，等等ROOT_DEV = 301h;//指定根文件系统设备是第1个硬盘的第1个分区。这是Linux老式的硬盘命名\t\t\t\t\t\t;//方式，具体值的含义如下：\t\t\t\t\t\t;//设备号 ＝ 主设备号*256 ＋ 次设备号 \t\t\t\t\t\t;//          (也即 dev_no = (major<<8 + minor)\t\t\t\t\t\t;//(主设备号：1－内存，2－磁盘，3－硬盘，4－ttyx，5－tty，6－并行口，7－非命名管道)\t\t\t\t\t\t;//300 - /dev/hd0 － 代表整个第1个硬盘\t\t\t\t\t\t;//301 - /dev/hd1 － 第1个盘的第1个分区\t\t\t\t\t\t;//... ...\t\t\t\t\t\t;//304 - /dev/hd4 － 第1个盘的第4个分区\t\t\t\t\t\t;//305 - /dev/hd5 － 代表整个第2个硬盘\t\t\t\t\t\t;//306 - /dev/hd6 － 第2个盘的第1个分区\t\t\t\t\t\t;//... ...\t\t\t\t\t\t;//309 - /dev/hd9 － 第1个盘的第4个分区 ;/* ************************************************************************;\tboot被bios－启动子程序加载至7c00h（31k）处，并将自己移动到了;\t地址90000h（576k）处，并跳转至那里。;\t它然后使用BIOS中断将'setup'直接加载到自己的后面（90200h）（576.5k），;\t并将system加载到地址10000h处。;;\t注意：目前的内核系统最大长度限制为（8*65536）（512kB）字节，即使是在;\t将来这也应该没有问题的。我想让它保持简单明了。这样512k的最大内核长度应该;\t足够了，尤其是这里没有象minix中一样包含缓冲区高速缓冲。;;\t加载程序已经做的够简单了，所以持续的读出错将导致死循环。只能手工重启。;\t只要可能，通过一次取取所有的扇区，加载过程可以做的很快的。;************************************************************************ */code segment\t\t;// 程序从_main标号开始执行。\tassume cs:codestart:\t\t\t\t\t;// 以下10行作用是将自身(bootsect)从目前段位置07c0h(31k)\t\t\t\t\t\t;// 移动到9000h(576k)处，共256字(512字节)，然后跳转到\t\t\t\t\t\t;// 移动后代码的 go 标号处，也即本程序的下一语句处。 \tmov\tax,BYTE PTR BOOTSEG\t\t;// 将ds段寄存器置为7C0h\tmov\tds,ax\tmov\tax,BYTE PTR INITSEG\t\t;// 将es段寄存器置为9000h\tmov\tes,ax\tmov\tcx,256\t\t\t;// 移动计数值 ＝ 256字 = 512 字节\tsub\tsi,si\t\t\t;// 源地址   ds:si = 07C0h:0000h\tsub\tdi,di\t\t\t;// 目的地址 es:di = 9000h:0000h\trep movsw\t\t\t;// 重复执行，直到cx = 0;移动1个字;\tjmp INITSEG:[go] \t;// 间接跳转。这里INITSEG指出跳转到的段地址。    db 0eah\t\t\t\t;// 间接跳转指令码\tdw go\tdw INITSEGgo:\tmov\tax,cs\t\t\t;// 将ds、es和ss都置成移动后代码所在的段处（9000h）。\tmov\tds,ax\t\t\t;// 由于程序中有堆栈操作（push，pop，call），因此必须设置堆栈。\tmov\tes,ax;// put stack at 9ff00.  将堆栈指针sp指向9ff00h（即9000h:0ff00h）处\tmov\tss,ax\tmov\tsp,0FF00h\t\t;/* 由于代码段移动过了，所以要重新设置堆栈段的位置。\t\t\t\t\t\t;   sp只要指向远大于512偏移（即地址90200h）处\t\t\t\t\t\t;   都可以。因为从90200h地址开始处还要放置setup程序，\t\t\t\t\t\t;   而此时setup程序大约为4个扇区，因此sp要指向大\t\t\t\t\t\t;   于（200h + 200h*4 + 堆栈大小）处。 */;// 在bootsect程序块后紧跟着加载setup模块的代码数据。;// 注意es已经设置好了。（在移动代码时es已经指向目的段地址处9000h）。load_setup:\t;// 以下10行的用途是利用BIOS中断INT 13h将setup模块从磁盘第2个扇区\t;// 开始读到90200h开始处，共读4个扇区。如果读出错，则复位驱动器，并\t;// 重试，没有退路。\t;// INT 13h 的使用方法如下：\t;// ah = 02h - 读磁盘扇区到内存；al = 需要读出的扇区数量；\t;// ch = 磁道（柱面）号的低8位；  cl = 开始扇区（0－5位），磁道号高2位（6－7）；\t;// dh = 磁头号；\t\t\t\t  dl = 驱动器号（如果是硬盘则要置为7）；\t;// es:bx ->指向数据缓冲区；  如果出错则CF标志置位。 \tmov\tdx,0000h\t\t\t\t;// drive 0, head 0\tmov\tcx,0002h\t\t\t\t;// sector 2, track 0\tmov\tbx,0200h\t\t\t\t;// address = 512, in INITSEG\tmov\tax,0200h+SETUPLEN\t\t;// service 2, nr of sectors\tint\t13h\t\t\t\t\t;// read it\tjnc\tok_load_setup\t\t\t;// ok - continue\tmov\tdx,0000h\tmov\tax,0000h\t\t\t\t;// reset the diskette\tint\t13h\tjmp\tload_setupok_load_setup:;/* 取磁盘驱动器的参数，特别是每道的扇区数量。;   取磁盘驱动器参数INT 13h调用格式和返回信息如下：;   ah = 08h\tdl = 驱动器号（如果是硬盘则要置位7为1）。;   返回信息：;   如果出错则CF置位，并且ah = 状态码。;   ah = 0, al = 0,         bl = 驱动器类型（AT/PS2）;   ch = 最大磁道号的低8位，cl = 每磁道最大扇区数（位0-5），最大磁道号高2位（位6-7）;   dh = 最大磁头数，       电力＝ 驱动器数量，;   es:di -> 软驱磁盘参数表。 */\tmov\tdl,00h\tmov\tax,0800h\t\t;// AH=8 is get drive parameters\tint\t13h\tmov\tch,00h;//\tseg cs\t\t\t\t;// 表示下一条语句的操作数在cs段寄存器所指的段中。\tmov\tcs:sectors,cx\t\t;// 保存每磁道扇区数。\tmov\tax,INITSEG\tmov\tes,ax\t\t\t;// 因为上面取磁盘参数中断改掉了es的值，这里重新改回。;// Print some inane message   在显示一些信息（'Loading system ... '回车换行，共24个字符）。\tmov\tah,03h\t\t;// read cursor pos\txor\tbh,bh\t\t\t;// 读光标位置。\tint\t10h\t\tmov\tcx,27\t\t\t;// 共24个字符。\tmov\tbx,0007h\t\t;// page 0, attribute 7 (normal)\tmov\tbp,offset msg1\t\t;// 指向要显示的字符串。\tmov\tax,1301h\t\t;// write string, move cursor\tint\t10h\t\t\t;// 写字符串并移动光标。;// ok, we've written the message, now;// we want to load the system (at 10000h)  现在开始将system 模块加载到10000h(64k)处。\tmov\tax,SYSSEG\tmov\tes,ax\t\t;// segment of 010000h  es = 存放system的段地址。\tcall read_it\t\t\t;// 读磁盘上system模块，es为输入参数。\tcall kill_motor\t\t;// 关闭驱动器马达，这样就可以知道驱动器的状态了。;// 此后，我们检查要使用哪个根文件系统设备（简称根设备）。如果已经指定了设备（!=0）;// 就直接使用给定的设备。否则就需要根据BIOS报告的每磁道扇区数来;// 确定到底使用/dev/PS0(2,28)还是/dev/at0(2,8)。;//\t\t上面一行中两个设备文件的含义：;//\t\t在Linux中软驱的主设备号是2（参加第43行注释），次设备号 = type*4 + nr, 其中;//\t\tnr为0－3分别对应软驱A、B、C或D；type是软驱的类型（2->1.2M或7->1.44M等）。;//\t\t因为7*4 + 0 = 28，所以/dev/PS0(2,28)指的是1.44M A驱动器，其设备号是021c;//\t\t同理 /dev/at0(2,8)指的是1.2M A驱动器，其设备号是0208。;//\tseg cs\tmov\tax,cs:root_dev\tcmp\tax,0\tjne\troot_defined\t;// 如果 ax != 0, 转到root_defined;//\tseg cs\tmov\tbx,cs:sectors\t\t;// 取上面保存的每磁道扇区数。如果sectors=15\t\t\t\t\t\t;// 则说明是1.2Mb的驱动器；如果sectors=18，则说明是\t\t\t\t\t\t;// 1.44Mb软驱。因为是可引导的驱动器，所以肯定是A驱。\tmov\tax,0208h\t\t\t;// /dev/ps0 - 1.2Mb\tcmp\tbx,15\t\t\t;// 判断每磁道扇区数是否=15\tje\troot_defined\t;// 如果等于，则ax中就是引导驱动器的设备号。\tmov\tax,021ch\t\t\t;// /dev/PS0 - 1.44Mb\tcmp\tbx,18\tje\troot_definedundef_root:\t\t\t\t;// 如果都不一样，则死循环（死机）。\tjmp undef_rootroot_defined:;//\tseg cs\tmov\tcs:root_dev,ax\t\t;// 将检查过的设备号保存起来。;// 到此，所有程序都加载完毕，我们就跳转到被;// 加载在bootsect后面的setup程序去。;\tjmp\tSETUPSEG:[0]\t\t;// 跳转到9020:0000（setup程序的开始处）。\tdb 0eah\tdw 0\tdw SETUPSEG;//－－－－－－－－－－－－ 本程序到此就结束了。－－－－－－－－－－－－－;// ******下面是两个子程序。*******;// 该子程序将系统模块加载到内存地址10000h处，并确定没有跨越64kB的内存边界。;// 我们试图尽快地进行加载，只要可能，就每次加载整条磁道的数据;// ;// 输入：es － 开始内存地址段值（通常是1000h）;//sread\tdw 1+SETUPLEN\t;// 当前磁道中已读的扇区数。开始时已经读进1扇区的引导扇区head\tdw 0\t\t\t\t;// 当前磁头号track\tdw 0\t\t\t\t;// 当前磁道号read_it:\t\t;// 测试输入的段值。必须位于内存地址64KB边界处，否则进入死循环。\tmov ax,es\t;// 清bx寄存器，用于表示当前段内存放数据的开始位置。\ttest ax,0fffhdie:\tjne die\t\t\t;// es值必须位于64KB地址边界！\txor bx,bx\t\t;// bx为段内偏移位置。rp_read:;// 判断是否已经读入全部数据。比较当前所读段是否就是系统数据末端所处的段（#ENDSEG），如果;// 不是就跳转至下面ok1_read标号处继续读数据。否则退出子程序返回。\tmov ax,es\tcmp ax,ENDSEG\t\t;// have we loaded all yet? 是否已经加载了全部数据？\tjb ok1_read\tretok1_read:;// 计算和验证当前磁道需要读取的扇区数，放在ax寄存器中。;// 根据当前磁道还未读取的扇区数以及段内数据字节开始偏移位置，计算如果全部读取这些;// 未读扇区，所读总字节数是否会超过64KB段长度的限制。若会超过，则根据此次最多能读;// 入的字节数（64KB - 段内偏移位置），反算出此次需要读取的扇区数。;//\tseg cs\tmov ax,cs:sectors\t\t;// 取每磁道扇区数。\tsub ax,sread\t\t;// 减去当前磁道已读扇区数。\tmov dx,ax\t\t\t;// ax = 当前磁道未读扇区数。\tmov cl,9\tshl dx,cl\t\t\t;// dx = ax * 512 字节。\tadd dx,bx\t\t\t;// cx = cx + 段内当前偏移值（bx）\t\t\t\t\t\t;//    = 此次读操作后，段内共读入的字节数。\tjnc ok2_read\t\t;// 若没有超过64KB字节，则跳转至ok2_read处执行。\tje ok2_read\txor ax,ax\t\t\t;// 若加上此次将读磁道上所有未读扇区时会超过64KB，则计算\tsub ax,bx\t\t\t;// 此时最多能读入的字节数（64KB － 段内读偏移位置），再转换\tshr ax,cl\t\t\t;// 成需要读取的扇区数。ok2_read:\tcall read_track\tmov dx,ax\t\t\t;// dx = 该此操作已读取的扇区数。\tadd ax,sread\t\t;// 当前磁道上已经读取的扇区数。;//\tseg cs\tcmp ax,cs:sectors\t\t;// 如果当前磁道上的还有扇区未读，则跳转到ok3_read处。\tjne ok3_read;// 读该磁道的下一磁头面（1号磁头）上的数据。如果已经完成，则去读下一磁道。\tmov ax,1\tsub ax,head\t\t\t;// 判断当前磁头号。\tjne ok4_read\t\t;// 如果是0磁头，则再去读1磁头面上的扇区数据\tinc track\t\t\t;// 否则去读下一磁道。ok4_read:\tmov head,ax\t\t\t;// 保存当前磁头号。\txor ax,ax\t\t\t;// 清当前磁道已读扇区数。ok3_read:\tmov sread,ax\t\t;// 保存当前磁道已读扇区数。\tshl dx,cl\t\t\t;// 上次已读扇区数*512字节。\tadd bx,dx\t\t\t;// 调整当前段内数据开始位置。\tjnc rp_read\t\t\t;// 若小于64KB边界值，则跳转到rp_read处，继续读数据。\t\t\t\t\t\t;// 否则调整当前段，为读下一段数据作准备。\tmov ax,es\tadd ax,1000h\t\t;// 将段基址调整为指向下一个64KB段内存。\tmov es,ax\txor bx,bx\tjmp rp_read;// 读当前磁道上指定开始扇区和需读扇区数的数据到es:bx开始处。;// al － 需读扇区数； es:bx － 缓冲区开始位置。read_track:\tpush ax\tpush bx\tpush cx\tpush dx\tmov dx,track\t\t;// 取当前磁道号。\tmov cx,sread\t\t;// 取当前磁道上已读扇区数。\tinc cx\t\t\t\t;// cl = 开始读扇区。\tmov ch,dl\t\t\t;// ch = 当前磁道号。\tmov dx,head\t\t\t;// 取当前磁头号。\tmov dh,dl\t\t\t;// dh = 磁头号。\tmov dl,0\t\t\t;// dl = 驱动器号（为0表示当前驱动器）。\tand dx,0100h\t\t;// 磁头号不大于1\tmov ah,2\t\t\t;// ah = 2, 读磁盘扇区功能号。\tint 13h\tjc bad_rt\t\t\t;// 若出错，则跳转至bad_rt。\tpop dx\tpop cx\tpop bx\tpop ax\tret;// 执行驱动器复位操作（磁盘中断功能号0），再跳转到read_track处重试。bad_rt:\t\tmov ax,0\tmov dx,0\tint 13h\tpop dx\tpop cx\tpop bx\tpop ax\tjmp read_track;///*;//* 这个子程序用于关闭软驱的马达，这样我们进入内核;//* 后它处于已知状态，以后也就无须担心它了。;//*/kill_motor:\tpush dx\tmov dx,3f2h\t\t;// 软驱控制卡的驱动端口，只写。\tmov al,0\t\t\t;// A驱动器，关闭FDC，禁止DMA和中断请求，关闭马达。\tout dx,al\t\t\t;// 将al中的内容输出到dx指定的端口去。\tpop dx\tretsectors dw 0\t\t\t\t;// 存放当前启动软盘每磁道的扇区数。msg1 db 13,10\t\t\t;// 回车、换行的ASCII码。\t db \"Loading my system ...\"\t;// 我加了my，共有27个字符了\t db 13,10,13,10\t;// 共24个ASCII码字符。org 508\t\t;// 表示下面语句从地址508(1FC)开始，所以root_dev\t\t\t;// 在启动扇区的第508开始的2个字节中。root_dev dw ROOT_DEV\t;// 这里存放根文件系统所在的设备号（init/main.c中会用）。boot_flag dw 0AA55h\t\t;// 硬盘有效标识。code endsend 第二个项目是build，他是在windows下分析Linux编译好的文件pe结构信息。该项目就一个目标文件，源码如下： #include <stdio.h>#include <windows.h>#include <stdlib.h>DWORD g_dwFileHeader[1024] = {0};    //PE文件的标题将读入该缓冲区。typedef struct __tagFILE_HEADER{\tunsigned char ucNop[4];\tDWORD         dwJmpAddr;}__FILL_HEADER;__FILL_HEADER g_FillHeader = {0x90,0x90,0x90,0xe9,0x00000000};    //这种结构将被写入到目标文件。char* g_lpszTargetPath = \"E:\\\\book\\\\Temp\\\\linux011VC\\\\VC\\\\Release\\\\system\";  //目标文件的路径和名称。void main(int argc,char argv[]){\tIMAGE_DOS_HEADER*       ImageDosHeader = NULL;\tIMAGE_NT_HEADERS*       ImageNtHeader = NULL;\tIMAGE_OPTIONAL_HEADER*  ImageOptionalHeader = NULL;\tHANDLE                  hFile = INVALID_HANDLE_VALUE;\tDWORD                   dwReadBytes = 0L;\tBOOL                    bResult = FALSE;\tDWORD                   dwActualBytes = 0L;\tDWORD                   dwOffset = 0L;\tUCHAR*                  lpucSource = NULL;\tUCHAR*                  lpucDes    = NULL;\tDWORD                   dwLoop     = 0;\thFile = CreateFile(                //打开目标文件\t\tg_lpszTargetPath,\t\tGENERIC_READ | GENERIC_WRITE,\t\t0L,\t\tNULL,\t\tOPEN_ALWAYS,\t\t0L,\t\tNULL);\tif(INVALID_HANDLE_VALUE == hFile)\t{\t\tprintf(\"Can not open the target file to read.\");\t\tgoto __TERMINAL;\t}\tdwReadBytes = 4096;               //4k字节的目标文件。\tbResult = ReadFile(hFile,g_dwFileHeader,dwReadBytes,&dwActualBytes,NULL);\tif(!bResult)\t\tgoto __TERMINAL;\tCloseHandle(hFile);\thFile = INVALID_HANDLE_VALUE;\t//\t//PE文件的入口点，并修改它。\t//\tImageDosHeader = (IMAGE_DOS_HEADER*)&g_dwFileHeader[0];\tdwOffset = ImageDosHeader->e_lfanew;\tImageNtHeader = (IMAGE_NT_HEADERS*)((UCHAR*)&g_dwFileHeader[0] + dwOffset);\tImageOptionalHeader = &(ImageNtHeader->OptionalHeader);\tg_FillHeader.dwJmpAddr = ImageOptionalHeader->AddressOfEntryPoint;\tprintf(\"    Entry Point : %d\\r\\n\",ImageOptionalHeader->AddressOfEntryPoint);\tg_FillHeader.dwJmpAddr -= sizeof(__FILL_HEADER);    //计算的目标地址将跳转.我们在前面的目标文件已经添加了一些nop指令，所以我们必须调整它。\tlpucSource = (UCHAR*)&g_FillHeader.ucNop[0];\tlpucDes    = (UCHAR*)&g_dwFileHeader[0];\tfor(dwLoop = 0;dwLoop < sizeof(__FILL_HEADER);dwLoop ++)  //修改目标文件的头信息\t{\t\t*lpucDes = *lpucSource;\t\tlpucDes ++;\t\tlpucSource ++;\t}\thFile = CreateFile(                //打开目标文件 并写入信息\t\tg_lpszTargetPath,\t\tGENERIC_READ | GENERIC_WRITE,\t\t0L,\t\tNULL,\t\tOPEN_ALWAYS,\t\t0L,\t\tNULL);\tif(INVALID_HANDLE_VALUE == hFile)\t{\t\tprintf(\"Can not open the target file to write.\");\t\tgoto __TERMINAL;\t}\tWriteFile(hFile,(LPVOID)&g_dwFileHeader[0],sizeof(__FILL_HEADER),&dwActualBytes,\t\tNULL);\tprintf(\"SectionAligment : %d\\r\\n\",ImageOptionalHeader->SectionAlignment);\tprintf(\"   FileAligment : %d\\r\\n\",ImageOptionalHeader->FileAlignment);__TERMINAL:\tif(INVALID_HANDLE_VALUE != hFile)\t\tCloseHandle(hFile);} 第三个项目是Documents，其实是一些文档，具体如下： 附：PC I/O地址分配　　PC只用了10位地址线(A0-A9)进行译码，其寻址的范围为0H-3FFH，共有1024个I/O地址。这1024个地址中前半段(A9=0，范围为0H-1FFH)是属于主机板I/O译码，后半段(A9=1，范围为200H-3FFH)则是用来扩展插槽上的I/O译码用。　　　　　　　　　I/O端口功能表———————————————————————————I/O地址　功能、用途———————————————————————————0　　　　DMA通道0，内存地址寄存器（DMA控制器1(8237)）1　　　　DMA通道0, 传输计数寄存器2　　　　DMA通道1，内存地址寄存器3　　　　DMA通道1, 传输计数寄存器4　　　　DMA通道2，内存地址寄存器5　　　　DMA通道2, 传输计数寄存器6　　　　DMA通道3，内存地址寄存器7　　　　DMA通道3, 传输计数寄存器8　　　　DMA通道0-3的状态寄存器0AH　　　 DMA通道0-3的屏蔽寄存器0BH　　　 DMA通道0-3的方式寄存器0CH　　　 DMA清除字节指针0DH　　　 DMA主清除字节0EH　　　 DMA通道0-3的清屏蔽寄存器0FH　　　 DMA通道0-3的写屏蔽寄存器19H　　　DMA起始寄存器20H-3FH　可编程中断控制器1(8259)使用40H　　　可编程中断计时器(8253)使用，读/写计数器041H　　　可编程中断计时器寄存器42H　　　可编程中断计时器杂项寄存器43H　　　可编程中断计时器,控制字寄存器44H　　　可编程中断计时器,杂项寄存器（AT）47H　　　可编程中断计时器,计数器0的控制字寄存器48H-5FH　可编程中断计时器使用60H-61H　键盘输入数据缓冲区61H　　　AT:8042键盘控制寄存器/XT:8255输出寄存器62H　　　8255输入寄存器63H　　　8255命令方式寄存器64H　　　8042键盘输入缓冲区/8042状态65H-6FH　8255/8042专用70H　　　CMOS RAM地址寄存器71H　　　CMOS RAM数据寄存器80H　　　生产测试端口81H　　　DMA通道2,页表地址寄存器82H　　　DMA通道3,页表地址寄存器83H　　　DMA通道1,页表地址寄存器87H　　　DMA通道0,页表地址寄存器89H　　　DMA通道6,页表地址寄存器8AH　　　DMA通道7,页表地址寄存器8BH　　　DMA通道5,页表地址寄存器8FH　　　DMA通道4,页表地址寄存器93H-9FH　DMA控制器专用0A0H　　　NM1屏蔽寄存器/可编程中断控制器20A1H　　　可编程中断控制器2屏蔽0C0H　　　DMA通道0，内存地址寄存器（DMA控制器2(8237)）0C2H　　　DMA通道0, 传输计数寄存器0C4H　　　DMA通道1，内存地址寄存器0C6H　　　DMA通道1, 传输计数寄存器0C8H　　　DMA通道2，内存地址寄存器0CAH　　　DMA通道2, 传输计数寄存器0CCH　　　DMA通道3，内存地址寄存器0CEH　　　DMA通道3, 传输计数寄存器0D0H　　　DMA状态寄存器0D2H　　　DMA写请求寄存器0D4H　　　DMA屏蔽寄存器0D6H　　　DMA方式寄存器0D8H　　　DMA清除字节指针0DAH　　　DMA主清0DCH　　　DMA清屏蔽寄存器0DEH　　　DMA写屏蔽寄存器0DFH-0EFH　保留0F0H-0FFH　协处理器使用100H-16FH保留170H　　 1号硬盘数据寄存器171H　　 1号硬盘错误寄存器172H　　 1号硬盘数据扇区计数173H　　 1号硬盘扇区数174H　　 1号硬盘柱面（低字节）175H　　 1号硬盘柱面（高字节）176H　　 1号硬盘驱动器/磁头寄存器177H　　 1号硬盘状态寄存器1F0H　　 0号硬盘数据寄存器1F1H　　 0号硬盘错误寄存器1F2H　　 0号硬盘数据扇区计数1F3H　　 0号硬盘扇区数1F4H　　 0号硬盘柱面（低字节）1F5H　　 0号硬盘柱面（高字节）1F6H　　 0号硬盘驱动器/磁头寄存器1F7H　　 0号硬盘状态寄存器1F9H-1FFH保留200H-20FH游戏控制端口210H-21FH扩展单元278H　　 3号并行口，数据端口279H　　 3号并行口，状态端口27AH　　 3号并行口，控制端口2B0H-2DFH保留2E0H　　 EGA/VGA使用2E1H　　 GPIP(0号适配器)2E2H　　 数据获取(0号适配器)2E3H　　 数据获取(1号适配器)2E4H-2F7H保留2F8H　　 2号串行口，发送/保持寄存器(RS232接口卡2)2F9H　　 2号串行口，中断有效寄存器2FAH　　 2号串行口，中断ID寄存器2FBH　　 2号串行口，线控制寄存器2FCH　　 2号串行口，调制解调控制寄存器2FDH　　 2号串行口，线状态寄存器2FEH　　 2号串行口，调制解调状态寄存器2FFH　　 保留300H-31FH原形卡320H　　 硬盘适配器寄存器322H　　 硬盘适配器控制/状态寄存器324H　　 硬盘适配器提示/中断状态寄存器325H-347H保留348H-357H　DCA3278366H-36FH　PC网络372H　　　 软盘适配器数据输出/状态寄存器375H-376H　软盘适配器数据寄存器377H　　　 软盘适配器数据输入寄存器378H　　　 2号并行口，数据端口379H　　　 2号并行口，状态端口37AH　　　 2号并行口，控制端口380H-38FH　SDLC及BSC通讯390H-393H　Cluster适配器03A0H-3AFH　BSC通讯3B0H-3B H　MDA视频寄存器3BCH　　　 1号并行口，数据端口3BDH　　　 1号并行口，状态端口3BEH　　　 1号并行口，控制端口3C0H-3CFH　EGA/VGA视频寄存器3D0H-3D7H　CGA视频寄存器3F0H-3F7H　软盘控制器寄存器3F8H　　　 1号串行口，发送/保持寄存器(RS232接口卡1)3F9H　　　 1号串行口，中断有效寄存器3FAH　　　 1号串行口，中断ID寄存器3FBH　　　 1号串行口，线控制寄存器3FCH　　　 1号串行口，调制解调控制寄存器3FDH　　　 1号串行口，线状态寄存器3FEH　　　 1号串行口，调制解调状态寄存器3FFH　　　 保留 // 微机中断的资料如下：// IRQ0系统时钟（系统保留）　// IRQ1键盘（系统保留）// IRQ2系统的第二个中断请示控制器（IRQ8－15）// IRQ3串行口2（可用）　// IRQ4串行口1（可用）// IRQ5并行口2（可用）（一般用来设置声卡）// IRQ6软盘（系统保留）　// IRQ7并行口1（一般用作打印机）// IRQ8实时时钟（系统保留） // IRQ9可用　// IRQ10可用// IRQ11常用于显示卡　// IRQ12 PS/2　mouse（可用）// IRQ13数学协处理器// IRQ14 IDE1控制器通道　// IRQ15 IDE2控制器通道（可用）// 此外还有NMI非正常中断（不可屏蔽中断），如校验错。 第四个项目是setup.s。 setup负责从BIOS获取系统数据，并存储在适当的内存位置。主要步骤如下： 1、利用ROM BIOS 中断读取机器系统数据，并将这些数据保存到0x90000 开始的位置（覆盖掉了bootsect 程序所在的地方），所取得的参数和保留的内存位置见下表3.1 所示。这些参数将被内核中相关程序使用，例如字符设备驱动程序集中的ttyio.c 程序等。 2、然后setup程序将system模块从0x10000-0x8ffff(512K) (当时认为内核系统模块system的长度不会超过此值：512KB）整块向下移动到内存绝对地址0x00000 处。 3、接下来加载中断描述符表寄存器(idtr)和全局描述符表寄存器(gdtr)。 4、开启A20 地址线，重新设置两个中断控制芯片8259A，将硬件中断号重新设置为0x20 - 0x2f。 5、最后设置CPU 的控制寄存器CR0（也称机器状态字），从而进入32 位保护模式运行，并跳转到位于system模块最前面部分的head.s 程序继续运行。 源码如下：  .model tiny .386p;// setup.s负责从BIOS 中获取系统数据，并将这些数据放到系统内存的适当地方。;// 此时setup.s 和system 已经由bootsect 引导块加载到内存中。;// 这段代码询问bios 有关内存/磁盘/其它参数，并将这些参数放到一个;// “安全的”地方：90000-901FF，也即原来bootsect 代码块曾经在;// 的地方，然后在被缓冲块覆盖掉之前由保护模式的system 读取。;// 以下这些参数最好和bootsect.s 中的相同！ INITSEG  = 9000h\t;// 原来bootsect 所处的段 SYSSEG   = 1000h\t;// system 在10000(64k)处。 SETUPSEG = 9020h\t;// 本程序所在的段地址。code segmentstart:;// ok, 整个读磁盘过程都正常，现在将光标位置保存以备今后使用。\tmov\tax,INITSEG\t\t;// 将ds 置成INITSEG(9000)。这已经在bootsect 程序中\tmov\tds,ax\t\t\t;// 设置过，但是现在是setup 程序，Linus 觉得需要再重新\t\t\t\t\t\t;// 设置一下。\tmov\tah,03h\t\t;// BIOS 中断10 的读光标功能号ah = 03\txor\tbh,bh\t\t;// 输入：bh = 页号\tint\t10h\t\t\t;// 返回：ch = 扫描开始线，cl = 扫描结束线，\tmov\tds:[0],dx\t\t;// dh = 行号(00 是顶端)，dl = 列号(00 是左边)。\t\t\t\t\t;// 将光标位置信息存放在90000 处，控制台初始化时会来取。\tmov\tah,88h\t\t;// 这3句取扩展内存的大小值（KB）。\tint\t15h\t\t\t;// 是调用中断15，功能号ah = 88\tmov\tds:[2],ax\t\t;// 返回：ax = 从100000（1M）处开始的扩展内存大小(KB)。\t\t\t\t\t;// 若出错则CF 置位，ax = 出错码。;// 下面这段用于取显示卡当前显示模式。;// 调用BIOS 中断10，功能号ah = 0f;// 返回：ah = 字符列数，al = 显示模式，bh = 当前显示页。;// 90004(1 字)存放当前页，90006 显示模式，90007 字符列数。\tmov\tah,0fh\tint\t10h\tmov\tds:[4],bx\t\t;// bh = display page\tmov\tds:[6],ax\t\t;// al = video mode, ah = window width;// 检查显示方式（EGA/VGA）并取参数。;// 调用BIOS 中断10，附加功能选择-取方式信息;// 功能号：ah = 12，bl = 10;// 返回：bh = 显示状态;// (00 - 彩色模式，I/O 端口=3dX);// (01 - 单色模式，I/O 端口=3bX);// bl = 安装的显示内存;// (00 - 64k, 01 - 128k, 02 - 192k, 03 = 256k);// cx = 显示卡特性参数(参见程序后的说明)。\tmov\tah,12h\tmov\tbl,10h\tint\t10h\tmov\tds:[8],ax\t\t;// 90008 = ??\tmov\tds:[10],bx\t\t;// 9000A = 安装的显示内存，9000B = 显示状态(彩色/单色)\tmov\tds:[12],cx\t\t;// 9000C = 显示卡特性参数。;// 取第一个硬盘的信息（复制硬盘参数表）。;// 第1 个硬盘参数表的首地址竟然是中断向量41 的向量值！而第2 个硬盘;// 参数表紧接第1 个表的后面，中断向量46 的向量值也指向这第2 个硬盘;// 的参数表首址。表的长度是16 个字节(10)。;// 下面两段程序分别复制BIOS 有关两个硬盘的参数表，90080 处存放第1 个;// 硬盘的表，90090 处存放第2 个硬盘的表。\tmov\tax,0000h\tmov\tds,ax\tlds\tsi,ds:[4*41h]\t\t;// 取中断向量41 的值，也即hd0 参数表的地址 ds:si\tmov\tax,INITSEG\tmov\tes,ax\tmov\tdi,0080h\t\t;// 传输的目的地址: 9000:0080 -> es:di\tmov\tcx,10h\t\t\t;// 共传输10 字节。\trep movsb;// Get hd1 data\tmov\tax,0000h\tmov\tds,ax\tlds\tsi,ds:[4*46h]\t\t;// 取中断向量46 的值，也即hd1 参数表的地址 -> ds:si\tmov\tax,INITSEG\tmov\tes,ax\tmov\tdi,0090h\t\t;// 传输的目的地址: 9000:0090 -> es:di\tmov\tcx,10h\trep movsb\t;// 检查系统是否存在第2 个硬盘，如果不存在则第2 个表清零。;// 利用BIOS 中断调用13 的取盘类型功能。;// 功能号ah = 15；;// 输入：dl = 驱动器号（8X 是硬盘：80 指第1 个硬盘，81 第2 个硬盘）;// 输出：ah = 类型码；00 --没有这个盘，CF 置位； 01 --是软驱，没有change-line 支持；;//  02--是软驱(或其它可移动设备)，有change-line 支持； 03 --是硬盘。\tmov\tax,1500h\tmov\tdl,81h\tint\t13h\tjc\tno_disk1\tcmp\tah,3\t\t\t;// 是硬盘吗？(类型= 3 ？)。\tje\tis_disk1no_disk1:\tmov\tax,INITSEG\t\t;// 第2个硬盘不存在，则对第2个硬盘表清零。\tmov\tes,ax\tmov\tdi,0090h\tmov\tcx,10h\tmov\tax,00h\trep stosb\tis_disk1:;// 从这里开始我们要保护模式方面的工作了。\tcli\t\t\t;// 此时不允许中断。 ;//;// 首先我们将system 模块移到正确的位置。;// bootsect 引导程序是将system 模块读入到从10000（64k）开始的位置。由于当时假设;// system 模块最大长度不会超过80000（512k），也即其末端不会超过内存地址90000，;// 所以bootsect 会将自己移动到90000 开始的地方，并把setup 加载到它的后面。;// 下面这段程序的用途是再把整个system 模块移动到00000 位置，即把从10000 到8ffff;// 的内存数据块(512k)，整块地向内存低端移动了10000（64k）的位置。\tmov\tax,0000h\tcld\t\t\t;// 'direction'=0, movs moves forwarddo_move:\tmov\tes,ax\t\t;// es:di -> 目的地址(初始为0000:0)\tadd\tax,1000h\tcmp\tax,9000h\t;// 已经把从8000 段开始的64k 代码移动完？\tjz\tend_move\tmov\tds,ax\t\t;// ds:si -> 源地址(初始为1000:0)\tsub\tdi,di\tsub\tsi,si\tmov cx,8000h\t;// 移动8000 字（64k 字节）。\trep movsw\tjmp\tdo_move;// 此后，我们加载段描述符。;// 从这里开始会遇到32 位保护模式的操作，因此需要Intel 32 位保护模式编程方面的知识了,;// 有关这方面的信息请查阅列表后的简单介绍或附录中的详细说明。这里仅作概要说明。;//;// lidt 指令用于加载中断描述符表(idt)寄存器，它的操作数是6 个字节，0-1 字节是描述符表的;// 长度值(字节)；2-5 字节是描述符表的32 位线性基地址（首地址），其形式参见下面;// 219-220 行和223-224 行的说明。中断描述符表中的每一个表项（8 字节）指出发生中断时;// 需要调用的代码的信息，与中断向量有些相似，但要包含更多的信息。;//;// lgdt 指令用于加载全局描述符表(gdt)寄存器，其操作数格式与lidt 指令的相同。全局描述符;// 表中的每个描述符项(8 字节)描述了保护模式下数据和代码段（块）的信息。其中包括段的;// 最大长度限制(16 位)、段的线性基址（32 位）、段的特权级、段是否在内存、读写许可以及;// 其它一些保护模式运行的标志。参见后面205-216 行。;//end_move:\tmov\tax,SETUPSEG\t\t;// right, forgot this at first. didn't work :-)\tmov\tds,ax\t\t\t;// ds 指向本程序(setup)段。因为上面操作改变了ds的值。\tlidt fword ptr idt_48\t\t\t;// 加载中断描述符表(idt)寄存器，idt_48 是6 字节操作数的位置\t\t\t\t\t\t;// 前2 字节表示idt 表的限长，后4 字节表示idt 表所处的基地址。\tlgdt fword ptr gdt_48\t\t\t;// 加载全局描述符表(gdt)寄存器，gdt_48 是6 字节操作数的位置;// 以上的操作很简单，现在我们开启A20 地址线。\tcall empty_8042\t\t;// 等待输入缓冲器空。\t\t\t\t\t\t;// 只有当输入缓冲器为空时才可以对其进行写命令。\tmov\tal,0D1h\t\t\t;// D1 命令码-表示要写数据到8042 的P2 端口。P2 端\tout\t64h,al\t\t\t;// 口的位1 用于A20 线的选通。数据要写到60 口。\tcall empty_8042\t\t;// 等待输入缓冲器空，看命令是否被接受。\tmov\tal,0DFh\t\t\t;// A20 on 选通A20 地址线的参数。\tout\t60h,al\tcall empty_8042\t\t;// 输入缓冲器为空，则表示A20 线已经选通。;// 希望以上一切正常。现在我们必须重新对中断进行编程 ;// 我们将它们放在正好处于intel 保留的硬件中断后面，在int 20-2F。;// 在那里它们不会引起冲突。不幸的是IBM 在原PC 机中搞糟了，以后也没有纠正过来。;// PC 机的bios 将中断放在了08-0f，这些中断也被用于内部硬件中断。;// 所以我们就必须重新对8259 中断控制器进行编程，这一点都没劲。\tmov\tal,11h\t\t;// 11 表示初始化命令开始，是ICW1 命令字，表示边\t\t\t\t\t;// 沿触发、多片8259 级连、最后要发送ICW4 命令字。\tout\t20h,al\t\t;// 发送到8259A 主芯片。\tdw\t00ebh,00ebh\t\t;// jmp $+2, jmp $+2  $ 表示当前指令的地址，\t\t\t\t\t\t\t\t;// 两条跳转指令，跳到下一条指令，起延时作用。\tout\t0A0h,al\t\t;// and to 8259A-2 ;// 再发送到8259A 从芯片。\tdw\t00ebh,00ebh\tmov\tal,20h\t\t;// start of hardware int's (20)\tout\t21h,al\t\t;// 送主芯片ICW2 命令字，起始中断号，要送奇地址。\tdw\t00ebh,00ebh\tmov\tal,28h\t\t;// start of hardware int's 2 (28)\tout\t0A1h,al\t\t;// 送从芯片ICW2 命令字，从芯片的起始中断号。\tdw\t00ebh,00ebh\tmov\tal,04h\t\t;// 8259-1 is master\tout\t21h,al\t\t;// 送主芯片ICW3 命令字，主芯片的IR2 连从芯片INT。\tdw\t00ebh,00ebh\t;// 参见代码列表后的说明。\tmov\tal,02h\t\t;// 8259-2 is slave\tout\t0A1h,al\t\t;// 送从芯片ICW3 命令字，表示从芯片的INT 连到主芯\t\t\t\t\t\t;// 片的IR2 引脚上。\tdw\t00ebh,00ebh\tmov\tal,01h\t\t;// 8086 mode for both\tout\t21h,al\t\t;// 送主芯片ICW4 命令字。8086 模式；普通EOI 方式，\t\t\t\t\t\t;// 需发送指令来复位。初始化结束，芯片就绪。\tdw\t00ebh,00ebh\tout\t0A1h,al\t\t;// 送从芯片ICW4 命令字，内容同上。\tdw\t00ebh,00ebh\tmov\tal,0FFh\t\t;// mask off all interrupts for now\tout\t21h,al\t\t;// 屏蔽主芯片所有中断请求。\tdw\t00ebh,00ebh\tout\t0A1h,al\t\t;// 屏蔽从芯片所有中断请求。;// 哼，上面这段当然没劲 ，希望这样能工作，而且我们也不再需要乏味的BIOS 了（除了;// 初始的加载.。BIOS 子程序要求很多不必要的数据，而且它一点都没趣。那是“真正”的;// 程序员所做的事。;// 这里设置进入32 位保护模式运行。首先加载机器状态字(lmsw - Load Machine Status Word)，;// 也称控制寄存器CR0，其比特位0 置1 将导致CPU 工作在保护模式。\tmov\tax,0001h\t;// 保护模式比特位(PE)。\tlmsw ax\t\t\t;// 就这样加载机器状态字;\tjmp 8:0  \t\t;// 跳转至cs 段8，偏移0 处。执行system 中的代码\tdb 0eah\tdw 0\tdw 8;// 我们已经将system 模块移动到00000 开始的地方，所以这里的偏移地址是0。这里的段值;// 的8 已经是保护模式下的段选择符了，用于选择描述符表和描述符表项以及所要求的特权级。;// 段选择符长度为16 位（2 字节）；位0-1 表示请求的特权级0-3，linux 操作系统只用;// 到两级：0 级（系统级）和3 级（用户级）；位2 用于选择全局描述符表(0)还是局部描;// 述符表(1)；位3-15 是描述符表项的索引，指出选择第几项描述符。所以段选择符;// 8(00000,0000,0000,1000)表示请求特权级0、使用全局描述符表中的第1 项，该项指出;// 代码的基地址是0，因此这里的跳转指令就会去执行system 中的代码。;// 下面这个子程序检查键盘命令队列是否为空。这里不使用超时方法- 如果这里死机，;// 则说明PC 机有问题，我们就没有办法再处理下去了。;// 只有当输入缓冲器为空时（状态寄存器位2 = 0）才可以对其进行写命令。empty_8042:\tdw 00ebh,00ebh\t;// jmp $+2, jmp $+2 $ 表示当前指令的地址\t\t\t\t\t\t;// 这是两个跳转指令的机器码(跳转到下一句)，相当于延时空操作。\tin\tal,64h\t\t\t;// 读AT 键盘控制器状态寄存器。\ttest al,2\t\t\t;// 测试位2，输入缓冲器满？\tjnz\tempty_8042\t\t;// yes - loop\tret;// 全局描述符表开始处。描述符表由多个8 字节长的描述符项组成。;// 这里给出了3 个描述符项。第1 项无用，但须存在。第2 项是系统代码段;// 描述符（208-211 行），第3 项是系统数据段描述符(213-216 行)。每个描述符的具体;// 含义参见列表后说明。gdt:\tdw\t0,0,0,0\t\t;// 第1 个描述符，不用。;// 这里在gdt 表中的偏移量为08，当加载代码段寄存器(段选择符)时，使用的是这个偏移值。\tdw\t07FFh\t\t;// 8Mb - limit=2047 (2048*4096=8Mb)\tdw\t0000h\t\t;// base address=0\tdw\t9A00h\t\t;// code read/exec\tdw\t00C0h\t\t;// granularity=4096, 386;// 这里在gdt 表中的偏移量是10，当加载数据段寄存器(如ds 等)时，使用的是这个偏移值。\tdw\t07FFh\t\t;// 8Mb - limit=2047 (2048*4096=8Mb)\tdw\t0000h\t\t;// base address=0\tdw\t9200h\t\t;// data read/write\tdw\t00C0h\t\t;// granularity=4096, 386idt_48:\tdw\t0\t\t\t;// idt limit=0\tdw\t0,0\t\t\t;// idt base=0Lgdt_48:\tdw\t800h\t\t;// 全局表长度为2k 字节，因为每8 字节组成一个段描述符项\t\t\t\t\t\t;// 所以表中共可有256 项。\tdw\t512+gdt,9h\t;// 4 个字节构成的内存线性地址：0009<<16 + 0200+gdt\t\t\t\t\t\t;// 也即90200 + gdt(即在本程序段中的偏移地址，205 行)。\tcode endsend 最后一个项目是system，关键核心源码。由于其的重要性，笔者认真总结每个文件。 boot/head.s   源码如下： ;/* ; *总体linux启动过程如下:; *当PC得电源打开之后，80x86结构的CPU将自动进入实时模式，并且从0xFFFF0开始自动执行程序代码，这个地址通常是ROM-BIOS的地址。PC机的BIOS将执行系统的; *检测，并且在物理地址的0处开始初始化中断向量。此后，它将可启动设备的第一扇区(512字节)读入内存的绝对地址0x7c00处，并且跳转到这个地方。; *启动设备通常是软盘或者是硬盘。这里的叙述是很简单的，但是这已经足够理解内核的初始化的工作过程。; *linux的0x9000由BIOS读入到内存的绝对地址0x7c00(31k)处，当它被执行时就会把自己移动到绝对地址0x90000处，并把启动设备中后2kb字节代码; *(boot/setup.s)读入到内存0x90200处，而内核的其他部分则被读入到从地址0x10000的开始处。; *在系统的加载期间显示信息?Loading...\",然后将控制权传递给boot/setup.s中的代码.这是另一个实时模式汇编程序。; *系统启动部分识别主机的某些特性以及vga卡的类型。; *如果需要，它会要求用户为控制台选择显示模式。; *然后整个系统从地址0x10000移至0x0000处，进入保护模式病跳转至系统的余下部分。; *此时所有的32位运行方式的设置启动被完成:idt,gdt,ldt被加载，处理器和协处理器也确认，分页的工作也设置好了。; *最终将调用init/main.c中的main程序。; *上述的操作的源代码是在boot/head.s中的。; *这可能是整个内核中最有诀窍的代码了。; *注意如果在上述任何一步中出现了一步错误。; *计算机就会死锁。; *在操作系统还没有完全运转之前是处理不了错误的。; */.586p.model flat;/*; *   head.s 含有32 位启动代码。; *; * 注意!!! 32 位启动代码是从绝对地址0x00000000 开始的，这里也同样; * 是页目录将存在的地方，因此这里的启动代码将被页目录覆盖掉。; * ; */extrn _stack_start:far ptr,_main_rename:proc,_printk:procpublic _idt,_gdt,_pg_dir,_tmp_floppy_area.code_pg_dir:\t\t;// 页目录将会存放在这里。_startup_32:\t\t\t;// 以下5行设置各个数据段寄存器。指向gdt数据段描述符项\tmov eax,10h;// 再次注意!!! 这里已经处于32 位运行模式，因此这里的$0x10 并不是把地址0x10 装入各;// 个段寄存器，它现在其实是全局段描述符表中的偏移值，或者更正确地说是一个描述符表;// 项的选择符。有关选择符的说明请参见setup.s 中的说明。这里$0x10 的含义是请求特权;// 级0(位0-1=0)、选择全局描述符表(位2=0)、选择表中第2 项(位3-15=2)。它正好指向表中;// 的数据段描述符项。（描述符的具体数值参见前面setup.s ）。下面代码的含义是：;// 置ds,es,fs,gs 中的选择符为setup.s 中构造的数据段（全局段描述符表的第2 项）=0x10，;// 并将堆栈放置在数据段中的_stack_start 数组内，然后使用新的中断描述符表和全局段;// 描述表.新的全局段描述表中初始内容与setup.s 中的完全一样。\tmov ds,ax\tmov es,ax\tmov fs,ax\tmov gs,ax\tlss esp,_stack_start\t;// 表示_stack_start -> ss:esp，设置系统堆栈。\t\t\t\t\t\t\t;// stack_start 定义在kernel/sched.c，69 行。\tcall setup_idt\t\t;// 调用设置中断描述符表子程序。\tcall setup_gdt\t\t;// 调用设置全局描述符表子程序。\tmov eax,10h\t\t\t;// reload all the segment registers\tmov ds,ax\t\t\t;// after changing gdt. CS was already\tmov es,ax\t\t\t;// reloaded in 'setup_gdt'\tmov fs,ax\t\t\t;// 因为修改了gdt，所以需要重新装载所有的段寄存器。\tmov gs,ax\t\t\t;// CS 代码段寄存器已经在setup_gdt 中重新加载过了。\tlss esp,_stack_start;// 以下5行用于测试A20 地址线是否已经开启。采用的方法是向内存地址0x000000 处写入任意;// 一个数值，然后看内存地址0x100000(1M)处是否也是这个数值。如果一直相同的话，就一直;// 比较下去，也即死循环、死机。表示地址A20 线没有选通，结果内核就不能使用1M 以上内存。\txor eax,eaxl1:\tinc eax\t\t\t\t;// check that A20 really IS enabled\tmov ds:[0],eax\t;// loop forever if it isn't\tcmp ds:[100000h],eax\tje l1\t\t\t\t;// '1b'表示向后(backward)跳转到标号1 去。\t\t\t\t\t\t;// 若是'5f'则表示向前(forward)跳转到标号5 去。;/*;* 注意! 在下面这段程序中，486 应该将位16 置位，以检查在超级用户模式下的写保护,;* 此后\"verify_area()\"调用中就不需要了。486 的用户通常也会想将NE(;//5)置位，以便;* 对数学协处理器的出错使用int 16。;*/;// 下面这段程序用于检查数学协处理器芯片是否存在。方法是修改控制寄存器CR0，在假设;// 存在协处理器的情况下执行一个协处理器指令，如果出错的话则说明协处理器芯片不存;// 在，需要设置CR0 中的协处理器仿真位EM（位2），并复位协处理器存在标志MP（位1）。\tmov eax,cr0\t\t\t\t;// check math chip\tand eax,80000011h\t\t;// Save PG,PE,ET;/* \"orl $0x10020,%eax\" here for 486 might be good */\tor\t eax,2\t\t\t\t;// set MP\tmov cr0,eax\tcall check_x87\tjmp after_page_tables;/*;* 我们依赖于ET 标志的正确性来检测287/387 存在与否。;*/check_x87:\tfninit\tfstsw ax\tcmp al,0\tje l2\t\t\t\t;/* no coprocessor: have to set bits */\tmov eax,cr0\t\t\t;// 如果存在的则向前跳转到标号1 处，否则改写cr0。\txor eax,6\t\t;/* reset MP, set EM */\tmov cr0,eax\tretalign 2\t;// 这里\".align 2\"的含义是指存储边界对齐调整。l2:\t\t\t;// 即按4 字节方式对齐内存地址。\t db 0DBh,0E4h\t\t;/* 287 协处理器码。 */\t ret;/*; * 下面这段是设置中断描述符表子程序setup_idt; *; * 将中断描述符表idt 设置成具有256 个项，并都指向ignore_int 中断门。然后加载; * 中断描述符表寄存器(用lidt 指令)。真正实用的中断门以后再安装。当我们在其它; * 地方认为一切都正常时再开启中断。该子程序将会被页表覆盖掉。; */setup_idt:\tlea edx,ignore_int\t\t;// 将ignore_int 的有效地址（偏移值）值 edx 寄存器\tmov eax,00080000h\t\t;// 将选择符0x0008 置入eax 的高16 位中。\tmov ax,dx\t\t\t\t;/* selector = 0x0008 = cs */\t\t\t\t\t\t\t;// 偏移值的低16 位置入eax 的低16 位中。此时eax 含\t\t\t\t\t\t\t;// 有门描述符低4 字节的值。\tmov dx,8E00h\t\t;/* interrupt gate - dpl=0, present */\t\t\t\t\t\t\t;// 此时edx 含有门描述符高4 字节的值。\tlea edi,_idt\tmov ecx,256rp_sidt:\tmov [edi],eax\t\t;// 将哑中断门描述符存入表中。\tmov [edi+4],edx\tadd edi,8\t\t\t;// edi 指向表中下一项。\tdec ecx\tjne rp_sidt\tlidt fword ptr idt_descr\t\t;// 加载中断描述符表寄存器值。\tret;/*; * 下面这段是设置全局描述符表项setup_gdt; *; * 这个子程序设置一个新的全局描述符表gdt，并加载。此时仅创建了两个表项，与前; * 面的一样。该子程序只有两行，“非常的”复杂，所以当然需要这么长的注释了:)。; */setup_gdt:\tlgdt fword ptr gdt_descr\t\t;// 加载全局描述符表寄存器(内容已设置好，见232-238 行)。\tret;/*; * Linus 将内核的内存页表直接放在页目录之后，使用了4 个表来寻址16 Mb 的物理内存。; * 如果你有多于16 Mb 的内存，就需要在这里进行扩充修改。; */;// 每个页表长为4 Kb 字节，而每个页表项需要4 个字节，因此一个页表共可以存放1000 个，;// 表项如果一个表项寻址4 Kb 的地址空间，则一个页表就可以寻址4 Mb 的物理内存。页表项;// 的格式为：项的前0-11 位存放一些标志，如是否在内存中(P 位0)、读写许可(R/W 位1)、;// 普通用户还是超级用户使用(U/S 位2)、是否修改过(是否脏了)(D 位6)等；表项的位12-31 ;// 是页框地址，用于指出一页内存的物理起始地址。org 1000h\t\t;// 从偏移0x1000 处开始是第1 个页表（偏移0 开始处将存放页表目录）。pg0:org 2000hpg1:org 3000hpg2:org 4000hpg3:org 5000h\t\t;// 定义下面的内存数据块从偏移0x5000 处开始。;/*; * 当DMA（直接存储器访问）不能访问缓冲块时，下面的tmp_floppy_area 内存块; * 就可供软盘驱动程序使用。其地址需要对齐调整，这样就不会跨越64kB 边界。; */_tmp_floppy_area:\tdb 1024 dup(0)\t\t;// 共保留1024 项，每项1 字节，填充数值0 。;// 下面这几个入栈操作(pushl)用于为调用/init/main.c 程序和返回作准备。;// 前面3 个入栈指令不知道作什么用的，也许是Linus 用于在调试时能看清机器码用的.。;// 139 行的入栈操作是模拟调用main.c 程序时首先将返回地址入栈的操作，所以如果;// main.c 程序真的退出时，就会返回到这里的标号L6 处继续执行下去，也即死循环。;// 140 行将main.c 的地址压入堆栈，这样，在设置分页处理（setup_paging）结束后;// 执行'ret'返回指令时就会将main.c 程序的地址弹出堆栈，并去执行main.c 程序去了。after_page_tables:\tpush 0\t\t\t;// These are the parameters to main :-)\tpush 0\t\t\t;// 这些是调用main 程序的参数（指init/main.c）。\tpush 0\tpush L6\t\t\t;// return address for main, if it decides to.\tpush _main_rename\t\t;// '_main'是编译程序对main 的内部表示方法。\tjmp setup_pagingL6:\tjmp L6\t\t\t;// main should never return here, but\t\t\t\t;// just in case, we know what happens.;/* 下面是默认的中断“向量句柄” :-) */int_msg:\tdb \"Unknown interrupt\\n\\r\"\t\t;// 定义字符串“未知中断(回车换行)”。align 2\t\t\t\t;// 按4 字节方式对齐内存地址。ignore_int:\tpush eax\tpush ecx\tpush edx\tpush ds\t\t\t;// 这里请注意！！ds,es,fs,gs 等虽然是16 位的寄存器，但入栈后\tpush es\t\t\t;// 仍然会以32 位的形式入栈，也即需要占用4 个字节的堆栈空间。\tpush fs\tmov eax,10h\t\t\t;// 置段选择符（使ds,es,fs 指向gdt 表中的数据段）。\tmov ds,ax\tmov es,ax\tmov fs,ax\tpush int_msg\t\t;// 把调用printk 函数的参数指针（地址）入栈。\tcall _printk\t\t;// 该函数在/kernel/printk.c 中。\t\t\t\t\t\t;// '_printk'是printk 编译后模块中的内部表示法。\tpop eax\tpop fs\tpop es\tpop ds\tpop edx\tpop ecx\tpop eax\tiretd\t\t;// 中断返回（把中断调用时压入栈的CPU 标志寄存器（32 位）值也弹出）。;/*; * Setup_paging; *; * 这个子程序通过设置控制寄存器cr0 的标志（PG 位31）来启动对内存的分页处理; * 功能，并设置各个页表项的内容，以恒等映射前16 MB 的物理内存。分页器假定; * 不会产生非法的地址映射（也即在只有4Mb 的机器上设置出大于4Mb 的内存地址）。; *; * 注意！尽管所有的物理地址都应该由这个子程序进行恒等映射，但只有内核页面管; * 理函数能直接使用>1Mb 的地址。所有“一般”函数仅使用低于1Mb 的地址空间，或; * 者是使用局部数据空间，地址空间将被映射到其它一些地方去-- mm(内存管理程序); * 会管理这些事的。; *; * 对于那些有多于16Mb 内存的家伙- 太幸运了，我还没有，为什么你会有:-)。代码就; * 在这里，对它进行修改吧。（实际上，这并不太困难的。通常只需修改一些常数等。; * 我把它设置为16Mb，因为我的机器再怎么扩充甚至不能超过这个界限（当然，我的机 ; * 器很便宜的:-)）。我已经通过设置某类标志来给出需要改动的地方（搜索“16Mb”），; * 但我不能保证作这些改动就行了 :-( ); */align 2\t\t;// 按4 字节方式对齐内存地址边界。setup_paging:\t;// 首先对5 页内存（1 页目录+ 4 页页表）清零\tmov ecx,1024*5\t\t;/* 5 pages - pg_dir+4 page tables */\txor eax,eax\txor edi,edi\t\t\t;/* pg_dir is at 0x000 */\t\t\t\t\t\t\t;// 页目录从0x000 地址开始。\tpushf\t\t;// VC内汇编使用cld和std后，需要自己恢复DF的值\tcld\trep stosd;// 下面4 句设置页目录中的项，我们共有4 个页表所以只需设置4 项。;// 页目录项的结构与页表中项的结构一样，4 个字节为1 项。参见上面的说明。;// \"$pg0+7\"表示：0x00001007，是页目录表中的第1 项。;// 则第1 个页表所在的地址= 0x00001007 & 0xfffff000 = 0x1000；第1 个页表;// 的属性标志= 0x00001007 & 0x00000fff = 0x07，表示该页存在、用户可读写。\tmov eax,_pg_dir\tmov [eax],pg0+7\t\t;/* set present bit/user r/w */\tmov [eax+4],pg1+7\t\t;/*  --------- \" \" --------- */\tmov [eax+8],pg2+7\t\t;/*  --------- \" \" --------- */\tmov [eax+12],pg3+7\t\t;/*  --------- \" \" --------- */;// 下面6 行填写4 个页表中所有项的内容，共有：4(页表)*1024(项/页表)=4096 项(0 - 0xfff)，;// 也即能映射物理内存4096*4Kb = 16Mb。;// 每项的内容是：当前项所映射的物理内存地址+ 该页的标志（这里均为7）。;// 使用的方法是从最后一个页表的最后一项开始按倒退顺序填写。一个页表的最后一项;// 在页表中的位置是1023*4 = 4092。因此最后一页的最后一项的位置就是$pg3+4092。\tmov edi,pg3+4092\t\t;// edi -> 最后一页的最后一项。\tmov eax,00fff007h\t\t;/*  16Mb - 4096 + 7 (r/w user,p) */\t\t\t\t\t\t\t;// 最后1 项对应物理内存页面的地址是0xfff000，\t\t\t\t\t\t\t;// 加上属性标志7，即为0xfff007.\tstd\t\t\t\t\t;// 方向位置位，edi 值递减(4 字节)。L3:\tstosd\t\t\t\t;/* fill pages backwards - more efficient :-) */\tsub eax,00001000h\t;// 每填写好一项，物理地址值减0x1000。\tjge L3\t\t\t\t;// 如果小于0 则说明全添写好了。\tpopf;// 设置页目录基址寄存器cr3 的值，指向页目录表。\txor eax,eax\t\t;/* 页目录表(pg_dir)在0x0000 处。 */\tmov cr3,eax\t\t;/* cr3 - page directory start */;// 设置启动使用分页处理（cr0 的PG 标志，位31）\tmov eax,cr0\tor  eax,80000000h\t;// 添上PG 标志。\tmov cr0,eax\t\t\t;/* set paging (PG) bit */\tret\t\t\t\t\t\t;/* this also flushes prefetch-queue */;// 在改变分页处理标志后要求使用转移指令刷新预取指令队列，这里用的是返回指令ret。;// 该返回指令的另一个作用是将堆栈中的main 程序的地址弹出，并开始运行/init/main.c ;// 程序。本程序到此真正结束了。align 2\t\t\t;// 按4 字节方式对齐内存地址边界。\tdw 0;//下面两行是lidt 指令的6 字节操作数：长度，基址。idt_descr:\tdw 256*8-1\tdd _idt\t\t\t;// idt contains 256 entriesalign 2\tdw 0;// 下面两行是lgdt 指令的6 字节操作数：长度，基址。gdt_descr:\tdw 256*8-1\t\t;// so does gdt (not that that's any\tdd _gdt\t\t\t;// magic number, but it works for me :^)align 4\t\t\t;// 按8 字节方式对齐内存地址边界。_idt:\tDQ 256 dup(0)\t;// idt is uninitialized // 256 项，每项8 字节，填0。;// 全局表。前4 项分别是空项（不用）、代码段描述符、数据段描述符、系统段描述符，;// 其中系统段描述符linux 没有派用处。后面还预留了252 项的空间，用于放置所创建;// 任务的局部描述符(LDT)和对应的任务状态段TSS 的描述符。;// (0-nul, 1-cs, 2-ds, 3-sys, 4-TSS0, 5-LDT0, 6-TSS1, 7-LDT1, 8-TSS2 etc...)_gdt:\tDQ 0000000000000000h\t;/* NULL descriptor */\tDQ 00c09a0000000fffh\t;/* 16Mb */  // 代码段最大长度16M。\tDQ 00c0920000000fffh\t;/* 16Mb */\t// 数据段最大长度16M。\tDQ 0000000000000000h\t;/* TEMPORARY - don't use */\tDQ 252 dup(0)\t\t\t\t;/* space for LDT's and TSS's etc */end fs/bitmap.c /*\t本程序的功能和作用即简单又清晰，主要用于对i 节点位图和逻辑块位图进行释放和占用处理。操作i 节点位图的函数是free_inode()和new_inode()，操作逻辑块位图的函数是free_block()和new_block()。\t函数free_block()用于释放指定设备dev 上数据区中的逻辑块block。具体操作是复位指定逻辑块block对应逻辑块位图中的比特位。它首先取指定设备dev 的超级块，并根据超级块上给出的设备数据逻辑块的范围，判断逻辑块号block 的有效性。然后在高速缓冲区中进行查找，看看指定的逻辑块现在是否正在高速缓冲区中，若是，则将对应的缓冲块释放掉。接着计算block 从数据区开始算起的数据逻辑块号（从1开始计数），并对逻辑块(区段)位图进行操作，复位对应的比特位。最后根据逻辑块号设置相应逻辑块位图在缓冲区中对应的缓冲块的已修改标志。\t函数new_block()用于向设备dev 申请一个逻辑块，返回逻辑块号。并置位指定逻辑块block 对应的逻辑块位图比特位。它首先取指定设备dev 的超级块。然后对整个逻辑块位图进行搜索，寻找首个是0 的比特位。若没有找到，则说明盘设备空间已用完，返回0。否则将该比特位置为1，表示占用对应的数据逻辑块。并将该比特位所在缓冲块的已修改标志置位。接着计算出数据逻辑块的盘块号，并在高速缓冲区中申请相应的缓冲块，并把该缓冲块清零。然后设置该缓冲块的已更新和已修改标志。最后释放该缓冲块，以便其它程序使用，并返回盘块号（逻辑块号）。\t函数free_inode()用于释放指定的i 节点，并复位对应的i 节点位图比特位；new_inode()用于为设备dev建立一个新i 节点。返回该新i 节点的指针。主要操作过程是在内存i 节点表中获取一个空闲i 节点表项，并从i 节点位图中找一个空闲i 节点。这两个函数的处理过程与上述两个函数类似，因此这里就不用再赘述。*/ //// 将指定地址(addr)处的一块内存清零。嵌入汇编程序宏。// 输入：eax = 0，ecx = 数据块大小BLOCK_SIZE/4，edi = addr。extern _inline void clear_block(char *addr){_asm{\tpushf\tmov edi,addr\tmov ecx,BLOCK_SIZE/4\txor eax,eax\tcld\trep stosd\tpopf}}//#define clear_block(addr) \\//__asm__(\"cld\\n\\t\" \\  /*清方向位。*///\t\"rep\\n\\t\" \\  /*重复执行存储数据（0）。*///\t\"stosl\" \\//\t::\"a\" (0),\"c\" (BLOCK_SIZE/4),\"D\" ((long) (addr)):\"cx\",\"di\")//// 置位指定地址开始的第nr 个位偏移处的比特位(nr 可以大于32！)。返回原比特位（0 或1）。// 输入：%0 - eax（返回值)，%1 - eax(0)；%2 - nr，位偏移值；%3 - (addr)，addr 的内容。extern _inline int set_bit(unsigned long nr,char* addr){//\tvolatile register int __res;\t_asm{\t\txor eax,eax\t\tmov ebx,nr\t\tmov edx,addr\t\tbts [edx],ebx\t\tsetb al//\t\tmov __res,eax\t}//\treturn __res;}//#define set_bit(nr,addr) ({\\//register int res __asm__(\"ax\"); \\//__asm__ __volatile__(\"btsl %2,%3\\n\\tsetb %%al\": \\//\"=a\" (res):\"0\" (0),\"r\" (nr),\"m\" (*(addr))); \\//res;})//// 复位指定地址开始的第nr 位偏移处的比特位。返回原比特位的反码（1 或0）。// 输入：%0 - eax（返回值)，%1 - eax(0)；%2 - nr，位偏移值；%3 - (addr)，addr 的内容。extern _inline int clear_bit(unsigned long nr,char* addr){//\tvolatile register int __res;\t_asm{\t\txor eax,eax\t\tmov ebx,nr\t\tmov edx,addr\t\tbtr [edx],ebx\t\tsetnb al//\t\tmov __res,eax\t}//\treturn __res;}//#define clear_bit(nr,addr) ({\\//register int res __asm__(\"ax\"); \\//__asm__ __volatile__(\"btrl %2,%3\\n\\tsetnb %%al\": \\//\"=a\" (res):\"0\" (0),\"r\" (nr),\"m\" (*(addr))); \\//res;})//// 从addr 开始寻找第1 个0 值比特位。// 输入：%0 - ecx(返回值)；%1 - ecx(0)；%2 - esi(addr)。// 在addr 指定地址开始的位图中寻找第1 个是0 的比特位，并将其距离addr 的比特位偏移值返回。extern _inline int find_first_zero(char *addr){//\tint __res;\t_asm{\t\tpushf\t\txor ecx,ecx\t\tmov esi,addr\t\tcld   /*清方向位。*/\tl1: lodsd   /*取[esi] -> eax。*/\t\tnot eax   /*eax 中每位取反。*/\t\tbsf edx,eax   /*从位0 扫描eax 中是1 的第1 个位，其偏移值 -> edx。*/\t\tje l2   /*如果eax 中全是0，则向前跳转到标号2 处(40 行)。*/\t\tadd ecx,edx   /*偏移值加入ecx(ecx 中是位图中首个是0 的比特位的偏移值)*/\t\tjmp l3   /*向前跳转到标号3 处（结束）。*/\tl2: add ecx,32   /*没有找到0 比特位，则将ecx 加上1 个长字的位偏移量32。*/\t\tcmp ecx,8192   /*已经扫描了8192 位（1024 字节）了吗？*/\t\tjl l1  /*若还没有扫描完1 块数据，则向前跳转到标号1 处，继续。*///\tl3: mov __res,ecx  /*结束。此时ecx 中是位偏移量。*/\tl3: mov eax,ecx\t\tpopf\t}//\treturn __res;} //// 释放设备dev 上数据区中的逻辑块block。// 复位指定逻辑块block 的逻辑块位图比特位。// 参数：dev 是设备号，block 是逻辑块号（盘块号）。void free_block(int dev, int block) ////向设备dev 申请一个逻辑块（盘块，区块）。返回逻辑块号（盘块号）。// 置位指定逻辑块block 的逻辑块位图比特位。int new_block(int dev) //// 释放指定的i 节点。// 复位对应i 节点位图比特位。void free_inode(struct m_inode * inode) //// 为设备dev 建立一个新i 节点。返回该新i 节点的指针。// 在内存i 节点表中获取一个空闲i 节点表项，并从i 节点位图中找一个空闲i 节点。struct m_inode * new_inode(int dev) fs/block_dev.c  block_dev.c 程序属于块设备文件数据访问操作类程序。该文件包括block_read()和block_write()两个块设备读写函数。这两个函数是供系统调用函数read()和write()调用的，其它地方没有引用。 //// 数据块写函数- 向指定设备从给定偏移处写入指定长度字节数据。// 参数：dev - 设备号；pos - 设备文件中偏移量指针；buf - 用户地址空间中缓冲区地址；//       count - 要传送的字节数。// 对于内核来说，写操作是向高速缓冲区中写入数据，什么时候数据最终写入设备是由高速缓冲管理// 程序决定并处理的。另外，因为设备是以块为单位进行读写的，因此对于写开始位置不处于块起始// 处时，需要先将开始字节所在的整个块读出，然后将需要写的数据从写开始处填写满该块，再将完// 整的一块数据写盘（即交由高速缓冲程序去处理）。int block_write(int dev, long * pos, char * buf, int count) //// 数据块读函数- 从指定设备和位置读入指定字节数的数据到高速缓冲中。int block_read(int dev, unsigned long * pos, char * buf, int count) fs/buffer.c 用于实现缓冲区高速缓存功能。通过不让中断过程改变缓冲区，而是让调用者来执行，避免了竞争条件（当然除改变数据以外）。注意！由于中断可以唤醒一个调用者，因此就需要开关中断指令（cli-sti）序列来检测等待调用返回。但需要非常地快(希望是这样)。 //// 等待指定缓冲区解锁。static _inline void wait_on_buffer(struct buffer_head * bh) //// 系统调用。同步设备和内存高速缓冲中数据。int sys_sync(void)//passed //// 对指定设备进行高速缓冲数据与设备上数据的同步操作。int sync_dev(int dev) //// 使指定设备在高速缓冲区中的数据无效。// 扫描高速缓冲中的所有缓冲块，对于指定设备的缓冲区，复位其有效(更新)标志和已修改标志。void _inline invalidate_buffers(int dev) /* * 该子程序检查一个软盘是否已经被更换，如果已经更换就使高速缓冲中与该软驱 * 对应的所有缓冲区无效。该子程序相对来说较慢，所以我们要尽量少使用它。 * 所以仅在执行'mount'或'open'时才调用它。我想这是将速度和实用性相结合的 * 最好方法。若在操作过程当中更换软盘，会导致数据的丢失，这是咎由自取 :-) * * 注意！尽管目前该子程序仅用于软盘，以后任何可移动介质的块设备都将使用该 * 程序，mount/open 操作是不需要知道是否是软盘或其它什么特殊介质的。 *///// 检查磁盘是否更换，如果已更换就使对应高速缓冲区无效。void check_disk_change(int dev) //// 从hash 队列和空闲缓冲队列中移走指定的缓冲块。static _inline void remove_from_queues(struct buffer_head * bh) //// 将指定缓冲区插入空闲链表尾并放入hash 队列中。static _inline void insert_into_queues(struct buffer_head * bh) //// 在高速缓冲中寻找给定设备和指定块的缓冲区块。// 如果找到则返回缓冲区块的指针，否则返回NULL。static struct buffer_head * find_buffer(int dev, int block) /* * 代码为什么会是这样子的？我听见你问... 原因是竞争条件。由于我们没有对 * 缓冲区上锁（除非我们正在读取它们中的数据），那么当我们（进程）睡眠时 * 缓冲区可能会发生一些问题（例如一个读错误将导致该缓冲区出错）。目前 * 这种情况实际上是不会发生的，但处理的代码已经准备好了。 */struct buffer_head * get_hash_table(int dev, int block) //// 取高速缓冲中指定的缓冲区。// 检查所指定的缓冲区是否已经在高速缓冲中，如果不在，就需要在高速缓冲中建立一个对应的新项。// 返回相应缓冲区头指针。struct buffer_head * getblk(int dev,int block) //// 释放指定的缓冲区。// 等待该缓冲区解锁。引用计数递减1。唤醒等待空闲缓冲区的进程。void brelse(struct buffer_head * buf) /* * 从设备上读取指定的数据块并返回含有数据的缓冲区。如果指定的块不存在 * 则返回NULL。 *///// 从指定设备上读取指定的数据块。struct buffer_head * bread(int dev,int block) //// 复制内存块。// 从from 地址复制一块数据到to 位置。extern __inline void COPYBLK(char* from, char* to) /* * bread_page 一次读四个缓冲块内容读到内存指定的地址。它是一个完整的函数， * 因为同时读取四块可以获得速度上的好处，不用等着读一块，再读一块了。 *///// 读设备上一个页面（4 个缓冲块）的内容到内存指定的地址。void bread_page(unsigned long address,int dev,int b[4]) /* * OK，breada 可以象bread 一样使用，但会另外预读一些块。该函数参数列表 * 需要使用一个负数来表明参数列表的结束。 *///// 从指定设备读取指定的一些块。// 成功时返回第1 块的缓冲区头指针，否则返回NULL。struct buffer_head * breada(int dev,int first, ...) //// 缓冲区初始化函数。// 参数buffer_end 是指定的缓冲区内存的末端。对于系统有16MB 内存，则缓冲区末端设置为4MB。// 对于系统有8MB 内存，缓冲区末端设置为2MB。void buffer_init(long buffer_end) fs/char_dev.c // 定义字符设备读写函数指针类型。typedef (*crw_ptr)(int rw,unsigned minor,char * buf,int count,off_t * pos); //// 串口终端读写操作函数。// 参数：rw - 读写命令；minor - 终端子设备号；buf - 缓冲区；cout - 读写字节数；//       pos - 读写操作当前指针，对于终端操作，该指针无用。// 返回：实际读写的字节数。static int rw_ttyx(int rw,unsigned minor,char * buf,int count,off_t * pos) //// 终端读写操作函数。// 同上rw_ttyx()，只是增加了对进程是否有控制终端的检测。static int rw_tty(int rw,unsigned minor,char * buf,int count, off_t * pos) //// 内存数据读写。未实现。static int rw_ram(int rw,char * buf, int count, off_t *pos) //// 内存数据读写操作函数。未实现。static int rw_mem(int rw,char * buf, int count, off_t * pos) //// 内核数据区读写函数。未实现。static int rw_kmem(int rw,char * buf, int count, off_t * pos) // 端口读写操作函数。// 参数：rw - 读写命令；buf - 缓冲区；cout - 读写字节数；pos - 端口地址。// 返回：实际读写的字节数。static int rw_port(int rw,char * buf, int count, off_t * pos) //// 内存读写操作函数。static int rw_memory(int rw, unsigned minor, char * buf, int count, off_t * pos) //// 字符设备读写操作函数。// 参数：rw - 读写命令；dev - 设备号；buf - 缓冲区；count - 读写字节数；pos -读写指针。// 返回：实际读/写字节数。int rw_char(int rw,int dev, char * buf, int count, off_t * pos) fs/exec.c /* * create_tables()函数在新用户内存中解析环境变量和参数字符串，由此 * 创建指针表，并将它们的地址放到\"堆栈\"上，然后返回新栈的指针值。 *///// 在新用户堆栈中创建环境和参数变量指针表。// 参数：p - 以数据段为起点的参数和环境信息偏移指针；argc - 参数个数；envc -环境变量数。// 返回：堆栈指针。static unsigned long * create_tables(char * p,int argc,int envc) /* * count()函数计算命令行参数/环境变量的个数。 *///// 计算参数个数。// 参数：argv - 参数指针数组，最后一个指针项是NULL。// 返回：参数个数。static int count(char ** argv) //// 复制指定个数的参数字符串到参数和环境空间。// 参数：argc - 欲添加的参数个数；argv - 参数指针数组；page - 参数和环境空间页面指针数组。//       p -在参数表空间中的偏移指针，始终指向已复制串的头部；from_kmem - 字符串来源标志。// 在do_execve()函数中，p 初始化为指向参数表(128kB)空间的最后一个长字处，参数字符串// 是以堆栈操作方式逆向往其中复制存放的，因此p 指针会始终指向参数字符串的头部。// 返回：参数和环境空间当前头部指针。static unsigned long copy_strings(int argc,char ** argv,unsigned long *page,\t\tunsigned long p, int from_kmem) //// 修改局部描述符表中的描述符基址和段限长，并将参数和环境空间页面放置在数据段末端。// 参数：text_size - 执行文件头部中a_text 字段给出的代码段长度值；//       page - 参数和环境空间页面指针数组。// 返回：数据段限长值(64MB)。static unsigned long change_ldt(unsigned long text_size,unsigned long * page) /* * 'do_execve()'函数执行一个新程序。 *///// execve()系统中断调用函数。加载并执行子进程（其它程序）。// 该函数系统中断调用(int 0x80)功能号__NR_execve 调用的函数。// 参数：eip - 指向堆栈中调用系统中断的程序代码指针eip 处，参见kernel/system_call.s 程序// 开始部分的说明；tmp - 系统中断调用本函数时的返回地址，无用；//                 filename - 被执行程序文件名；argv - 命令行参数指针数组；//                 envp - 环境变量指针数组。// 返回：如果调用成功，则不返回；否则设置出错号，并返回-1。int do_execve(unsigned long * eip,long tmp,char * filename,\tchar ** argv, char ** envp) fs/fcntl.c //// 复制文件句柄(描述符)。// 参数fd 是欲复制的文件句柄，arg 指定新文件句柄的最小数值。// 返回新文件句柄或出错码。static int dupfd(unsigned int fd, unsigned int arg) //// 复制文件句柄系统调用函数。// 复制指定文件句柄oldfd，新句柄值等于newfd。如果newfd 已经打开，则首先关闭之。int sys_dup2(unsigned int oldfd, unsigned int newfd) //// 复制文件句柄系统调用函数。// 复制指定文件句柄oldfd，新句柄的值是当前最小的未用句柄。int sys_dup(unsigned int fildes) //// 文件控制系统调用函数。// 参数fd 是文件句柄，cmd 是操作命令(参见include/fcntl.h，23-30 行)。int sys_fcntl(unsigned int fd, unsigned int cmd, unsigned long arg) fs/file_dev.c //// 文件读函数- 根据i 节点和文件结构，读设备数据。// 由i 节点可以知道设备号，由filp 结构可以知道文件中当前读写指针位置。buf 指定用户态中// 缓冲区的位置，count 为需要读取的字节数。返回值是实际读取的字节数，或出错号(小于0)。int file_read(struct m_inode * inode, struct file * filp, char * buf, int count) //// 文件写函数- 根据i 节点和文件结构信息，将用户数据写入指定设备。// 由i 节点可以知道设备号，由filp 结构可以知道文件中当前读写指针位置。buf 指定用户态中// 缓冲区的位置，count 为需要写入的字节数。返回值是实际写入的字节数，或出错号(小于0)。int file_write(struct m_inode * inode, struct file * filp, char * buf, int count) fs/inode.c //// 等待指定的i 节点可用。// 如果i 节点已被锁定，则将当前任务置为不可中断的等待状态。直到该i 节点解锁。static _inline void wait_on_inode(struct m_inode * inode) //// 对指定的i 节点上锁（锁定指定的i 节点）。// 如果i 节点已被锁定，则将当前任务置为不可中断的等待状态。// 直到该i 节点解锁，然后对其上锁。static _inline void lock_inode(struct m_inode * inode) //// 对指定的i 节点解锁。// 复位i 节点的锁定标志，并明确地唤醒等待此i 节点的进程。static _inline void unlock_inode(struct m_inode * inode) //// 释放内存中设备dev 的所有i 节点。// 扫描内存中的i 节点表数组，如果是指定设备使用的i 节点就释放之。void invalidate_inodes(int dev) //// 同步所有i 节点。// 同步内存与设备上的所有i 节点信息。void sync_inodes(void) //// 文件数据块映射到盘块的处理操作。(block 位图处理函数，bmap - block map)// 参数：inode – 文件的i 节点；block – 文件中的数据块号；create - 创建标志。// 如果创建标志置位，则在对应逻辑块不存在时就申请新磁盘块。// 返回block 数据块对应在设备上的逻辑块号（盘块号）。static int _bmap(struct m_inode * inode,int block,int create) //// 根据i 节点信息取文件数据块block 在设备上对应的逻辑块号。int bmap(struct m_inode * inode,int block) //// 创建文件数据块block 在设备上对应的逻辑块，并返回设备上对应的逻辑块号。int create_block(struct m_inode * inode, int block) //// 释放一个i 节点(回写入设备)。void iput(struct m_inode * inode) //// 从i 节点表(inode_table)中获取一个空闲i 节点项。// 寻找引用计数count 为0 的i 节点，并将其写盘后清零，返回其指针。struct m_inode * get_empty_inode(void) //// 获取管道节点。返回为i 节点指针（如果是NULL 则失败）。// 首先扫描i 节点表，寻找一个空闲i 节点项，然后取得一页空闲内存供管道使用。// 然后将得到的i 节点的引用计数置为2(读者和写者)，初始化管道头和尾，置i 节点的管道类型表示。struct m_inode * get_pipe_inode(void) //// 从设备上读取指定节点号的i 节点。// nr - i 节点号。struct m_inode * iget(int dev,int nr) //// 从设备上读取指定i 节点的信息到内存中（缓冲区中）。static void read_inode(struct m_inode * inode) //// 将指定i 节点信息写入设备（写入缓冲区相应的缓冲块中，待缓冲区刷新时会写入盘中）。static void write_inode(struct m_inode * inode) fs/ioctl.c //// 系统调用函数- 输入输出控制函数。// 参数：fd - 文件描述符；cmd - 命令码；arg - 参数。// 返回：成功则返回0，否则返回出错码。int sys_ioctl(unsigned int fd, unsigned int cmd, unsigned long arg) fs/ioctl.c /* *\tpermission() * * 该函数用于检测一个文件的读/写/执行权限。我不知道是否只需检查euid，还是 * 需要检查euid 和uid 两者，不过这很容易修改。 *///// 检测文件访问许可权限。// 参数：inode - 文件对应的i 节点；mask - 访问属性屏蔽码。// 返回：访问许可返回1，否则返回0。static int permission(struct m_inode * inode,int mask) /* * ok，我们不能使用strncmp 字符串比较函数，因为名称不在我们的数据空间(不在内核空间)。 * 因而我们只能使用match()。问题不大。match()同样也处理一些完整的测试。 * * 注意！与strncmp 不同的是match()成功时返回1，失败时返回0。 *///// 指定长度字符串比较函数。// 参数：len - 比较的字符串长度；name - 文件名指针；de - 目录项结构。// 返回：相同返回1，不同返回0。static int match(int len,const char * name,struct dir_entry * de) /* *\tfind_entry() * * 在指定的目录中寻找一个与名字匹配的目录项。返回一个含有找到目录项的高速 * 缓冲区以及目录项本身(作为一个参数- res_dir)。并不读目录项的i 节点- 如 * 果需要的话需自己操作。 * * '..'目录项，操作期间也会对几种特殊情况分别处理- 比如横越一个伪根目录以 * 及安装点。 *///// 查找指定目录和文件名的目录项。// 参数：dir - 指定目录i 节点的指针；name - 文件名；namelen - 文件名长度；// 返回：高速缓冲区指针；res_dir - 返回的目录项结构指针；static struct buffer_head * find_entry(struct m_inode ** dir,\tconst char * name, int namelen, struct dir_entry ** res_dir) /* *\tadd_entry() * * 使用与find_entry()同样的方法，往指定目录中添加一文件目录项。 * 如果失败则返回NULL。 * * 注意！！'de'(指定目录项结构指针)的i 节点部分被设置为0 - 这表示 * 在调用该函数和往目录项中添加信息之间不能睡眠，因为若睡眠那么其它 * 人(进程)可能会已经使用了该目录项。 *///// 根据指定的目录和文件名添加目录项。// 参数：dir - 指定目录的i 节点；name - 文件名；namelen - 文件名长度；// 返回：高速缓冲区指针；res_dir - 返回的目录项结构指针；static struct buffer_head * add_entry(struct m_inode * dir,\tconst char * name, int namelen, struct dir_entry ** res_dir) /* *\tget_dir() * * 该函数根据给出的路径名进行搜索，直到达到最顶端的目录。 * 如果失败则返回NULL。 *///// 搜寻指定路径名的目录。// 参数：pathname - 路径名。// 返回：目录的i 节点指针。失败时返回NULL。static struct m_inode * get_dir(const char * pathname) /* *\tdir_namei() * * dir_namei()函数返回指定目录名的i 节点指针，以及在最顶层目录的名称。 */// 参数：pathname - 目录路径名；namelen - 路径名长度。// 返回：指定目录名最顶层目录的i 节点指针和最顶层目录名及其长度。static struct m_inode * dir_namei(const char * pathname,\tint * namelen, const char ** name) /* *\tnamei() * * 该函数被许多简单的命令用于取得指定路径名称的i 节点。open、link 等则使用它们 * 自己的相应函数，但对于象修改模式'chmod'等这样的命令，该函数已足够用了。 *///// 取指定路径名的i 节点。// 参数：pathname - 路径名。// 返回：对应的i 节点。struct m_inode * namei(const char * pathname) /* *\topen_namei() * * open()所使用的namei 函数- 这其实几乎是完整的打开文件程序。 *///// 文件打开namei 函数。// 参数：pathname - 文件路径名；flag - 文件打开标志；mode - 文件访问许可属性；// 返回：成功返回0，否则返回出错码；res_inode - 返回的对应文件路径名的的i 节点指针。int open_namei(const char * pathname, int flag, int mode,\tstruct m_inode ** res_inode) //// 系统调用函数- 创建一个特殊文件或普通文件节点(node)。// 创建名称为filename，由mode 和dev 指定的文件系统节点(普通文件、设备特殊文件或命名管道)。// 参数：filename - 路径名；mode - 指定使用许可以及所创建节点的类型；dev - 设备号。// 返回：成功则返回0，否则返回出错码。int sys_mknod(const char * filename, int mode, int dev) //// 系统调用函数- 创建目录。// 参数：pathname - 路径名；mode - 目录使用的权限属性。// 返回：成功则返回0，否则返回出错码。int sys_mkdir(const char * pathname, int mode) /* * 用于检查指定的目录是否为空的子程序(用于rmdir 系统调用函数)。 *///// 检查指定目录是否是空的。// 参数：inode - 指定目录的i 节点指针。// 返回：0 - 是空的；1 - 不空。static int empty_dir(struct m_inode * inode) //// 系统调用函数- 删除指定名称的目录。// 参数： name - 目录名(路径名)。// 返回：返回0 表示成功，否则返回出错号。int sys_rmdir(const char * name) //// 系统调用函数- 删除文件名以及可能也删除其相关的文件。// 从文件系统删除一个名字。如果是一个文件的最后一个连接，并且没有进程正打开该文件，则该文件// 也将被删除，并释放所占用的设备空间。// 参数：name - 文件名。// 返回：成功则返回0，否则返回出错号。int sys_unlink(const char * name) //// 系统调用函数- 为文件建立一个文件名。// 为一个已经存在的文件创建一个新连接(也称为硬连接- hard link)。// 参数：oldname - 原路径名；newname - 新的路径名。// 返回：若成功则返回0，否则返回出错号。int sys_link(const char * oldname, const char * newname) fs/open.c // 取文件系统信息系统调用函数。int sys_ustat(int dev, struct ustat * ubuf) //// 设置文件访问和修改时间。// 参数filename 是文件名，times 是访问和修改时间结构指针。// 如果times 指针不为NULL，则取utimbuf 结构中的时间信息来设置文件的访问和修改时间。如果// times 指针是NULL，则取系统当前时间来设置指定文件的访问和修改时间域。int sys_utime(char * filename, struct utimbuf * times) /* * 文件属性XXX，我们该用真实用户id 还是有效用户id？BSD 系统使用了真实用户id， * 以使该调用可以供setuid 程序使用。（注：POSIX 标准建议使用真实用户ID） *///// 检查对文件的访问权限。// 参数filename 是文件名，mode 是屏蔽码，由R_OK(4)、W_OK(2)、X_OK(1)和F_OK(0)组成。// 如果请求访问允许的话，则返回0，否则返回出错码。int sys_access(const char * filename,int mode) //// 改变当前工作目录系统调用函数。// 参数filename 是目录名。// 操作成功则返回0，否则返回出错码。int sys_chdir(const char * filename) //// 改变根目录系统调用函数。// 将指定的路径名改为根目录'/'。// 如果操作成功则返回0，否则返回出错码。int sys_chroot(const char * filename) //// 修改文件属性系统调用函数。// 参数filename 是文件名，mode 是新的文件属性。// 若操作成功则返回0，否则返回出错码。int sys_chmod(const char * filename,int mode) //// 修改文件宿主系统调用函数。// 参数filename 是文件名，uid 是用户标识符(用户id)，gid 是组id。// 若操作成功则返回0，否则返回出错码。int sys_chown(const char * filename,int uid,int gid) //// 打开（或创建）文件系统调用函数。// 参数filename 是文件名，flag 是打开文件标志：只读O_RDONLY、只写O_WRONLY 或读写O_RDWR，// 以及O_CREAT、O_EXCL、O_APPEND 等其它一些标志的组合，若本函数创建了一个新文件，则mode// 用于指定使用文件的许可属性，这些属性有S_IRWXU(文件宿主具有读、写和执行权限)、S_IRUSR// (用户具有读文件权限)、S_IRWXG(组成员具有读、写和执行权限)等等。对于新创建的文件，这些// 属性只应用于将来对文件的访问，创建了只读文件的打开调用也将返回一个可读写的文件句柄。// 若操作成功则返回文件句柄(文件描述符)，否则返回出错码。(参见sys/stat.h, fcntl.h)int sys_open(const char * filename,int flag,int mode) //// 创建文件系统调用函数。// 参数pathname 是路径名，mode 与上面的sys_open()函数相同。// 成功则返回文件句柄，否则返回出错码。int sys_creat(const char * pathname, int mode) // 关闭文件系统调用函数。// 参数fd 是文件句柄。// 成功则返回0，否则返回出错码。int sys_close(unsigned int fd) fs/pipe.c //// 管道读操作函数。// 参数inode 是管道对应的i 节点，buf 是数据缓冲区指针，count 是读取的字节数。int read_pipe(struct m_inode * inode, char * buf, int count) //// 管道写操作函数。// 参数inode 是管道对应的i 节点，buf 是数据缓冲区指针，count 是将写入管道的字节数。int write_pipe(struct m_inode * inode, char * buf, int count) //// 创建管道系统调用函数。// 在fildes 所指的数组中创建一对文件句柄(描述符)。这对文件句柄指向一管道i 节点。fildes[0]// 用于读管道中数据，fildes[1]用于向管道中写入数据。// 成功时返回0，出错时返回-1。int sys_pipe(unsigned long * fildes) fs/read_write.c //// 重定位文件读写指针系统调用函数。// 参数fd 是文件句柄，offset 是新的文件读写指针偏移值，origin 是偏移的起始位置，是SEEK_SET// (0，从文件开始处)、SEEK_CUR(1，从当前读写位置)、SEEK_END(2，从文件尾处)三者之一。int sys_lseek (unsigned int fd, off_t offset, int origin) //// 读文件系统调用函数。// 参数fd 是文件句柄，buf 是缓冲区，count 是欲读字节数。int sys_read (unsigned int fd, char *buf, int count) fs/stat.c //// 复制文件状态信息。// 参数inode 是文件对应的i 节点，statbuf 是stat 文件状态结构指针，用于存放取得的状态信息。static voidcp_stat (struct m_inode *inode, struct stat *statbuf) //// 文件状态系统调用函数 - 根据文件名获取文件状态信息。// 参数filename 是指定的文件名，statbuf 是存放状态信息的缓冲区指针。// 返回0，若出错则返回出错码。intsys_stat (char *filename, struct stat *statbuf) //// 文件状态系统调用 - 根据文件句柄获取文件状态信息。// 参数fd 是指定文件的句柄(描述符)，statbuf 是存放状态信息的缓冲区指针。// 返回0，若出错则返回出错码。intsys_fstat (unsigned int fd, struct stat *statbuf) fs/super.c /* set_bit()使用了setb 指令，因为汇编编译器gas 不能识别指令setc *///// 测试指定位偏移处比特位的值(0 或1)，并返回该比特位值。(应该取名为test_bit()更妥帖)// 嵌入式汇编宏。参数bitnr 是比特位偏移值，addr 是测试比特位操作的起始地址。// %0 - ax(__res)，%1 - 0，%2 - bitnr，%3 - addr/*#define set_bit(bitnr,addr) ({ \\register int __res __asm__( \"ax\"); \\__asm__( \"bt %2,%3;setb %%al\": \"=a\" (__res): \"a\" (0), \"r\" (bitnr), \"m\" (*(addr))); \\__res; })*/extern _inline int set_bit(int bitnr,char* addr) //// 锁定指定的超级块。static voidlock_super (struct super_block *sb) //// 对指定超级块解锁。（如果使用ulock_super 这个名称则更妥帖）。static voidfree_super (struct super_block *sb) //// 睡眠等待超级块解锁。static voidwait_on_super (struct super_block *sb) //// 取指定设备的超级块。返回该超级块结构指针。struct super_block *get_super (int dev) //// 释放指定设备的超级块。// 释放设备所使用的超级块数组项（置s_dev=0），并释放该设备i 节点位图和逻辑块位图所占用// 的高速缓冲块。如果超级块对应的文件系统是根文件系统，或者其i 节点上已经安装有其它的文件// 系统，则不能释放该超级块。voidput_super (int dev) //// 从设备上读取超级块到缓冲区中。// 如果该设备的超级块已经在高速缓冲中并且有效，则直接返回该超级块的指针。static struct super_block *read_super (int dev) //// 卸载文件系统的系统调用函数。// 参数dev_name 是设备文件名。intsys_umount (char *dev_name) //// 安装文件系统调用函数。// 参数dev_name 是设备文件名，dir_name 是安装到的目录名，rw_flag 被安装文件的读写标志。// 将被加载的地方必须是一个目录名，并且对应的i 节点没有被其它程序占用。intsys_mount (char *dev_name, char *dir_name, int rw_flag) //// 安装根文件系统。// 该函数是在系统开机初始化设置时(sys_setup())调用的。( kernel/blk_drv/hd.c, 157 )voidmount_root (void) fs/truncate.c //// 释放一次间接块。static void free_ind (int dev, int block) //// 释放二次间接块。static voidfree_dind (int dev, int block) //// 将节点对应的文件长度截为0，并释放占用的设备空间。voidtruncate (struct m_inode *inode) lib/_exit.c //// 内核使用的程序(退出)终止函数。// 直接调用系统中断int 0x80，功能号__NR_exit。// 参数：exit_code - 退出码。//volatile void _exit(int exit_code) lib/close.c // 关闭文件函数。// 下面该调用宏函数对应：int close(int fd)。直接调用了系统中断int 0x80，参数是__NR_close。// 其中fd 是文件描述符。_syscall1(int,close,int,fd) lib/dup.c //// 复制文件描述符函数。// 下面该调用宏函数对应：int dup(int fd)。直接调用了系统中断int 0x80，参数是__NR_dup。// 其中fd 是文件描述符。_syscall1(int,dup,int,fd) lib/execve.c //// 加载并执行子进程(其它程序)函数。// 下面该调用宏函数对应：int execve(const char * file, char ** argv, char ** envp)。// 参数：file - 被执行程序文件名；argv - 命令行参数指针数组；envp - 环境变量指针数组。// 直接调用了系统中断int 0x80，参数是__NR_execve。参见include/unistd.h 和fs/exec.c 程序。_syscall3(int,execve,const char *,file,char **,argv,char **,envp) lib/malloc.c /* * 下面的子程序用于初始化一页桶描述符页面。 *///// 初始化桶描述符。// 建立空闲桶描述符链表，并让free_bucket_desc 指向第一个空闲桶描述符。static _inline void init_bucket_desc() //// 分配动态内存函数。// 参数：len - 请求的内存块长度。// 返回：指向被分配内存的指针。如果失败则返回NULL。void *malloc(unsigned int len) /* * 下面是释放子程序。如果你知道释放对象的大小，则free_s()将使用该信息加速 * 搜寻对应桶描述符的速度。 *  * 我们将定义一个宏，使得\"free(x)\"成为\"free_s(x, 0)\"。 *///// 释放存储桶对象。// 参数：obj - 对应对象指针；size - 大小。void free_s(void *obj, int size) lib/open.c //// 打开文件函数。// 打开并有可能创建一个文件。// 参数：filename - 文件名；flag - 文件打开标志；...// 返回：文件描述符，若出错则置出错码，并返回-1。int open(const char * filename, int flag, ...) lib/setsid.c //// 创建一个会话并设置进程组号。// 下面系统调用宏对应于函数：pid_t setsid()。// 返回：调用进程的会话标识符(session ID)。_syscall0(pid_t,setsid) lib/wait.c //// 等待进程终止系统调用函数。// 该下面宏结构对应于函数：pid_t waitpid(pid_t pid, int * wait_stat, int options)//// 参数：pid - 等待被终止进程的进程id，或者是用于指定特殊情况的其它特定数值；//       wait_stat - 用于存放状态信息；options - WNOHANG 或WUNTRACED 或是0。_syscall3(pid_t,waitpid,pid_t,pid,int *,wait_stat,int,options)//// wait()系统调用。直接调用waitpid()函数。pid_t wait(int * wait_stat) lib/write.c //// 写文件系统调用函数。// 该宏结构对应于函数：int write(int fd, const char * buf, off_t count)// 参数：fd - 文件描述符；buf - 写缓冲区指针；count - 写字节数。// 返回：成功时返回写入的字节数(0 表示写入0 字节)；出错时将返回-1，并且设置了出错号。_syscall3(int,write,int,fd,const char *,buf,off_t,count) mm/memory.c void do_exit(long code);// 进程退出处理函数，在kernel/exit.c。//// 显示内存已用完出错信息，并退出。static _inline void oom(void) // 复制1 页内存（4K 字节）。//#define copy_page(from,to) \\//__asm__(\"cld ; rep ; movsl\"::\"S\" (from),\"D\" (to),\"c\" (1024):\"cx\",\"di\",\"si\")#define copy_page(from,to) _copy_page((void *)(from),(void *)(to))_inline void _copy_page(void *from, void *to) /* * 获取首个(实际上是最后1 个:-)物理空闲页面，并标记为已使用。如果没有空闲页面， * 就返回0。 *///// 取物理空闲页面。如果已经没有可用内存了，则返回0。// 输入：%1(ax=0) - 0；%2(LOW_MEM)；%3(cx=PAGING PAGES)；%4(edi=mem_map+PAGING_PAGES-1)。// 输出：返回%0(ax=页面起始地址)。// 上面%4 寄存器实际指向mem_map[]内存字节图的最后一个字节。本函数从字节图末端开始向前扫描// 所有页面标志（页面总数为PAGING_PAGES），若有页面空闲（其内存映像字节为0）则返回页面地址。// 注意！本函数只是指出在主内存区的一页空闲页面，但并没有映射到某个进程的线性地址去。后面// 的put_page()函数就是用来作映射的。unsigned long get_free_page(void) /* * 释放物理地址'addr'开始的一页内存。用于函数'free_page_tables()'。 *///// 释放物理地址addr 开始的一页面内存。// 1MB 以下的内存空间用于内核程序和缓冲，不作为分配页面的内存空间。void free_page(unsigned long addr) /* * 下面函数释放页表连续的内存块，'exit()'需要该函数。与copy_page_tables() * 类似，该函数仅处理4Mb 的内存块。 *///// 根据指定的线性地址和限长（页表个数），释放对应内存页表所指定的内存块并置表项空闲。// 页目录位于物理地址0 开始处，共1024 项，占4K 字节。每个目录项指定一个页表。// 页表从物理地址0x1000 处开始（紧接着目录空间），每个页表有1024 项，也占4K 内存。// 每个页表项对应一页物理内存（4K）。目录项和页表项的大小均为4 个字节。// 参数：from - 起始基地址；size - 释放的长度。int free_page_tables(unsigned long from,unsigned long size) /* * 好了，下面是内存管理mm 中最为复杂的程序之一。它通过只复制内存页面 * 来拷贝一定范围内线性地址中的内容。希望代码中没有错误，因为我不想 * 再调试这块代码了 :-) * * 注意！我们并不是仅复制任何内存块- 内存块的地址需要是4Mb 的倍数（正好 * 一个页目录项对应的内存大小），因为这样处理可使函数很简单。不管怎样， * 它仅被fork()使用（fork.c） * * 注意!!当from==0 时，是在为第一次fork()调用复制内核空间。此时我们 * 不想复制整个页目录项对应的内存，因为这样做会导致内存严重的浪费- 我们 * 只复制头160 个页面- 对应640kB。即使是复制这些页面也已经超出我们的需求， * 但这不会占用更多的内存- 在低1Mb 内存范围内我们不执行写时复制操作，所以 * 这些页面可以与内核共享。因此这是nr=xxxx 的特殊情况（nr 在程序中指页面数）。 *///// 复制指定线性地址和长度（页表个数）内存对应的页目录项和页表，从而被复制的页目录和//// 页表对应的原物理内存区被共享使用。// 复制指定地址和长度的内存对应的页目录项和页表项。需申请页面来存放新页表，原内存区被共享；// 此后两个进程将共享内存区，直到有一个进程执行写操作时，才分配新的内存页（写时复制机制）。int copy_page_tables(unsigned long from,unsigned long to,long size) /* * 下面函数将一内存页面放置在指定地址处。它返回页面的物理地址，如果 * 内存不够(在访问页表或页面时)，则返回0。 *///// 把一物理内存页面映射到指定的线性地址处。// 主要工作是在页目录和页表中设置指定页面的信息。若成功则返回页面地址。unsigned long put_page(unsigned long page,unsigned long address) //// 取消写保护页面函数。用于页异常中断过程中写保护异常的处理（写时复制）。// 输入参数为页表项指针。// [ un_wp_page 意思是取消页面的写保护：Un-Write Protected。]void un_wp_page(unsigned long * table_entry) /* * 当用户试图往一个共享页面上写时，该函数处理已存在的内存页面，（写时复制） * 它是通过将页面复制到一个新地址上并递减原页面的共享页面计数值实现的。 * * 如果它在代码空间，我们就以段错误信息退出。 *///// 页异常中断处理调用的C 函数。写共享页面处理函数。在page.s 程序中被调用。// 参数error_code 是由CPU 自动产生，address 是页面线性地址。// 写共享页面时，需复制页面（写时复制）。void do_wp_page(unsigned long error_code,unsigned long address) //// 写页面验证。// 若页面不可写，则复制页面。在fork.c 第34 行被调用。void write_verify(unsigned long address) //// 取得一页空闲内存并映射到指定线性地址处。// 与get_free_page()不同。get_free_page()仅是申请取得了主内存区的一页物理内存。而该函数// 不仅是获取到一页物理内存页面，还进一步调用put_page()，将物理页面映射到指定的线性地址// 处。void get_empty_page(unsigned long address) /* * try_to_share()在任务\"p\"中检查位于地址\"address\"处的页面，看页面是否存在，是否干净。 * 如果是干净的话，就与当前任务共享。 * * 注意！这里我们已假定p !=当前任务，并且它们共享同一个执行程序。 *///// 尝试对进程指定地址处的页面进行共享操作。// 同时还验证指定的地址处是否已经申请了页面，若是则出错，死机。// 返回1-成功，0-失败。static int try_to_share(unsigned long address, struct task_struct * p) /* * share_page()试图找到一个进程，它可以与当前进程共享页面。参数address 是 * 当前数据空间中期望共享的某页面地址。 * * 首先我们通过检测executable->i_count 来查证是否可行。如果有其它任务已共享 * 该inode，则它应该大于1。 *///// 共享页面。在缺页处理时看看能否共享页面// 返回1 - 成功，0 - 失败。。static int share_page(unsigned long address) //// 页异常中断处理调用的函数。处理缺页异常情况。在page.s 程序中被调用。// 参数error_code 是由CPU 自动产生，address 是页面线性地址。void do_no_page(unsigned long error_code,unsigned long address) //// 物理内存初始化。// 参数：start_mem - 可用作分页处理的物理内存起始位置（已去除RAMDISK 所占内存空间等）。// end_mem - 实际物理内存最大地址。// 在该版的linux 内核中，最多能使用16Mb 的内存，大于16Mb 的内存将不于考虑，弃置不用。// 0 - 1Mb 内存空间用于内核系统（其实是0-640Kb）。void mem_init(long start_mem, long end_mem) // 计算内存空闲页面数并显示。void calc_mem(void) mm/page.s ;/* passed; *  该文件包括页异常中断处理程序（中断14），主要分两种情况处理。; * 一是由于缺页引起的页异常中断，通过调用do_no_page(error_code, address)来处理；; * 二是由页写保护引起的页异常，此时调用页写保护处理函数do_wp_page(error_code, address); * 进行处理。其中的出错码(error_code)是由CPU 自动产生并压入堆栈的，出现异常时访问的; * 线性地址是从控制寄存器CR2 中取得的。CR2 是专门用来存放页出错时的线性地址。; */.586p.model flat;/*; * page.s 程序包含底层页异常处理代码。实际的工作在memory.c 中完成。; */extrn _do_no_page:proc,_do_wp_page:procpublic _page_fault.code_page_fault:\txchg ss:[esp],eax\t;// 取出错码到eax。\tpush ecx\tpush edx\tpush ds\tpush es\tpush fs\tmov edx,10h\t\t;// 置内核数据段选择符。\tmov ds,dx\tmov es,dx\tmov fs,dx\tmov edx,cr2\t\t\t;// 取引起页面异常的线性地址\tpush edx\t\t\t;// 将该线性地址和出错码压入堆栈，作为调用函数的参数。\tpush eax\ttest eax,1\t\t\t;// 测试标志P，如果不是缺页引起的异常则跳转。\tjne l1\tcall _do_no_page\t;// 调用缺页处理函数（mm/memory.c,365 行）。\tjmp l2\t\t\tl1:\tcall _do_wp_page\t;// 调用写保护处理函数（mm/memory.c,247 行）。l2:\tadd esp,8\t\t;// 丢弃压入栈的两个参数。\tpop fs\tpop es\tpop ds\tpop edx\tpop ecx\tpop eax\tiretdend;/*; * 当处理器在转换线性地址到物理地址的过程中检测到以下两种条件时，; * 就会发生页异常中断，中断14。; *   o 当CPU 发现对应页目录项或页表项的存在位（Present）标志为0。; *   o 当前进程没有访问指定页面的权限。; * 对于页异常处理中断，CPU 提供了两项信息用来诊断页异常和从中恢复运行。; * (1) 放在堆栈上的出错码。该出错码指出了异常是由于页不存在引起的还是违反了访问权限引起的；; * \t\t在发生异常时CPU 的当前特权层；以及是读操作还是写操作。出错码的格式是一个32 位的长; * \t\t字。但只用了最后的3 个比特位。分别说明导致异常发生时的原因：; * \t\t位2(U/S) - 0 表示在超级用户模式下执行，1 表示在用户模式下执行；; * \t\t位1(W/R) - 0 表示读操作，1 表示写操作；; * \t\t位0(P) - 0 表示页不存在，1 表示页级保护。; * (2) CR2(控制寄存器2)。CPU 将造成异常的用于访问的线性地址存放在CR2 中。异常处理程序可以; * \t\t使用这个地址来定位相应的页目录和页表项。如果在页异常处理程序执行期间允许发生另一; * \t\t个页异常，那么处理程序应该将CR2 压入堆栈中。; */ kernel/asm.s ;/*;* asm.s contains the low-level code for most hardware faults.;* page_exception is handled by the mm, so that isn't here. This;* file also handles (hopefully) fpu-exceptions due to TS-bit, as;* the fpu must be properly saved/resored. This hasn't been tested.;* eax = -1;* 系统中断调用(eax=调用号);* ebx,ecx,edx 中放有调用参数;* 调用号超范围?;* 中断返回;* 寄存器入栈;* ds,es 指向内核代码段;* fs 指向局部数据段(用户数据);* 调用对应的C 处理函数;* 任务状态?;* 调用schedule() 时间片=0？;* 初始任务？;* 弹出入栈的寄存器;* 超级用户程序?;* 用户堆栈?;* 根据进程信号位图取进程的最;* 小信号量，调用do signal();*/;/*;* asm.s 程序中包括大部分的硬件故障（或出错）处理的底层次代码。页异常是由内存管理程序;* mm 处理的，所以不在这里。此程序还处理（希望是这样）由于TS-位而造成的fpu 异常，;* 因为fpu 必须正确地进行保存/恢复处理，这些还没有测试过。;*/;// 本代码文件主要涉及对Intel 保留的中断int0--int16 的处理（int17-int31 留作今后使用）。;// 以下是一些全局函数名的声明，其原形在traps.c 中说明。extrn _do_divide_error:far, _do_int3:far, _do_nmi:far, _do_overflow:farextrn _do_bounds:far, _do_invalid_op:far, _do_coprocessor_segment_overrun:farextrn _do_reserved:far, _coprocessor_error:far ptr, _do_double_fault:farextrn _do_invalid_TSS:far, _do_segment_not_present:farextrn _do_stack_segment:far, _do_general_protection:farpublic _divide_error,_debug,_nmi,_int3,_overflow,_bounds,_invalid_oppublic _double_fault,_coprocessor_segment_overrunpublic _invalid_TSS,_segment_not_present,_stack_segmentpublic _general_protection,_irq13,_reserved;// int0 -- （下面这段代码的含义参见图4.1(a)）。;// 下面是被零除出错(divide_error)处理代码。标号'_divide_error'实际上是C 语言函;// 数divide_error()编译后所生成模块中对应的名称。'_do_divide_error'函数在traps.c 中。.code_divide_error:\tpush dword ptr _do_divide_error ;// 首先把将要调用的函数地址入栈。这段程序的出错号为0。no_error_code: ;// 这里是无出错号处理的入口处，见下面第55 行等。\txchg [esp],eax ;// _do_divide_error 的地址 -> eax，eax 被交换入栈。\tpush ebx\tpush ecx\tpush edx\tpush edi\tpush esi\tpush ebp\tpush ds ;// ！！16 位的段寄存器入栈后也要占用4 个字节。\tpush es\tpush fs\tpush 0 ;// \"error code\" ;// 将出错码入栈。\tlea edx,[esp+44] ;// 取原调用返回地址处堆栈指针位置，并压入堆栈。\tpush edx\tmov edx,10h ;// 内核代码数据段选择符。\tmov ds,dx\tmov es,dx\tmov fs,dx\tcall eax ;// 调用C 函数do_divide_error()。\tadd esp,8 ;// 让堆栈指针重新指向寄存器fs 入栈处。\tpop fs\tpop es\tpop ds\tpop ebp\tpop esi\tpop edi\tpop edx\tpop ecx\tpop ebx\tpop eax ;// 弹出原来eax 中的内容。\tiretd;// int1 -- debug 调试中断入口点。处理过程同上。_debug:\tpush _do_int3 ;// _do_debug C 函数指针入栈。以下同。\tjmp no_error_code;// int2 -- 非屏蔽中断调用入口点。_nmi:\tpush _do_nmi\tjmp no_error_code;// int3 -- 同_debug。_int3:\tpush _do_int3\tjmp no_error_code;// int4 -- 溢出出错处理中断入口点。_overflow:\tpush _do_overflow\tjmp no_error_code;// int5 -- 边界检查出错中断入口点。_bounds:\tpush _do_bounds\tjmp no_error_code;// int6 -- 无效操作指令出错中断入口点。_invalid_op:\tpush _do_invalid_op\tjmp no_error_code;// int9 -- 协处理器段超出出错中断入口点。_coprocessor_segment_overrun:\tpush _do_coprocessor_segment_overrun\tjmp no_error_code;// int15 – 保留。_reserved:\tpush _do_reserved\tjmp no_error_code;// int45 -- ( = 0x20 + 13 ) 数学协处理器（Coprocessor）发出的中断。;// 当协处理器执行完一个操作时就会发出IRQ13 中断信号，以通知CPU 操作完成。_irq13:\tpush eax\txor al,al ;// 80387 在执行计算时，CPU 会等待其操作的完成。\tout 0F0h,al ;// 通过写0xF0 端口，本中断将消除CPU 的BUSY 延续信号，并重新;// 激活80387 的处理器扩展请求引脚PEREQ。该操作主要是为了确保;// 在继续执行80387 的任何指令之前，响应本中断。\tmov al,20h\tout 20h,al ;// 向8259 主中断控制芯片发送EOI（中断结束）信号。\tjmp l1 ;// 这两个跳转指令起延时作用。l1: jmp l2l2: out 0A0h,al ;// 再向8259 从中断控制芯片发送EOI（中断结束）信号。\tpop eax\tjmp _coprocessor_error ;// _coprocessor_error 原来在本文件中，现在已经放到\t\t\t\t\t\t\t;// （kernel/system_call.s, 131）;// 以下中断在调用时会在中断返回地址之后将出错号压入堆栈，因此返回时也需要将出错号弹出。;// int8 -- 双出错故障。（下面这段代码的含义参见图4.1(b)）。_double_fault:\tpush _do_double_fault ;// C 函数地址入栈。error_code:\txchg [esp+4],eax ;// error code <-> %eax，eax 原来的值被保存在堆栈上。\txchg [esp],ebx ;// &function <-> %ebx，ebx 原来的值被保存在堆栈上。\tpush ecx\tpush edx\tpush edi\tpush esi\tpush ebp\tpush ds\tpush es\tpush fs\tpush eax ;// error code ;// 出错号入栈。\tlea eax,[esp+44] ;// offset ;// 程序返回地址处堆栈指针位置值入栈。\tpush eax\tmov eax,10h ;// 置内核数据段选择符。\tmov ds,ax\tmov es,ax\tmov fs,ax\tcall ebx ;// 调用相应的C 函数，其参数已入栈。\tadd esp,8 ;// 堆栈指针重新指向栈中放置fs 内容的位置。\tpop fs\tpop es\tpop ds\tpop ebp\tpop esi\tpop edi\tpop edx\tpop ecx\tpop ebx\tpop eax\tiretd;// int10 -- 无效的任务状态段(TSS)。_invalid_TSS:\tpush _do_invalid_TSS\tjmp error_code;// int11 -- 段不存在。_segment_not_present:\tpush _do_segment_not_present\tjmp error_code;// int12 -- 堆栈段错误。_stack_segment:\tpush _do_stack_segment\tjmp error_code;// int13 -- 一般保护性出错。_general_protection:\tpush _do_general_protection\tjmp error_code;// int7 -- 设备不存在(_device_not_available)在(kernel/system_call.s,148);// int14 -- 页错误(_page_fault)在(mm/page.s,14);// int16 -- 协处理器错误(_coprocessor_error)在(kernel/system_call.s,131);// 时钟中断int 0x20 (_timer_interrupt)在(kernel/system_call.s,176);// 系统调用int 0x80 (_system_call)在（kernel/system_call.s,80）end kernel/exit.c //// 释放指定进程(任务)。void release (struct task_struct *p) //// 向指定任务(*p)发送信号(sig)，权限为priv。static _inline intsend_sig (long sig, struct task_struct *p, int priv) //// 终止会话(session)。static void kill_session (void) /** 为了向进程组等发送信号，XXX 需要检查许可。kill()的许可机制非常巧妙!*///// kill()系统调用可用于向任何进程或进程组发送任何信号。// 如果pid 值>0，则信号被发送给pid。// 如果pid=0，那么信号就会被发送给当前进程的进程组中的所有进程。// 如果pid=-1，则信号sig 就会发送给除第一个进程外的所有进程。// 如果pid < -1，则信号sig 将发送给进程组-pid 的所有进程。// 如果信号sig 为0，则不发送信号，但仍会进行错误检查。如果成功则返回0。int sys_kill (int pid, int sig) //// 通知父进程 -- 向进程pid 发送信号SIGCHLD：子进程将停止或终止。// 如果没有找到父进程，则自己释放。static void tell_father (int pid) //// 程序退出处理程序。在系统调用的中断处理程序中被调用。int do_exit (long code)\t\t// code 是错误码。 //// 系统调用exit()。终止进程。int sys_exit (int error_code) //// 系统调用waitpid()。挂起当前进程，直到pid 指定的子进程退出（终止）或者收到要求终止// 该进程的信号，或者是需要调用一个信号句柄（信号处理程序）。如果pid 所指的子进程早已// 退出（已成所谓的僵死进程），则本调用将立刻返回。子进程使用的所有资源将释放。// 如果pid > 0, 表示等待进程号等于pid 的子进程。// 如果pid = 0, 表示等待进程组号等于当前进程的任何子进程。// 如果pid < -1, 表示等待进程组号等于pid 绝对值的任何子进程。// [ 如果pid = -1, 表示等待任何子进程。]// 若options = WUNTRACED，表示如果子进程是停止的，也马上返回。// 若options = WNOHANG，表示如果没有子进程退出或终止就马上返回。// 如果stat_addr 不为空，则就将状态信息保存到那里。int sys_waitpid (pid_t pid, unsigned long *stat_addr, int options) kernel/fork.c //// 进程空间区域写前验证函数。// 对当前进程的地址addr 到addr+size 这一段进程空间以页为单位执行写操作前的检测操作。// 若页面是只读的，则执行共享检验和复制页面操作（写时复制）。void verify_area (void *addr, int size) // 设置新任务的代码和数据段基址、限长并复制页表。// nr 为新任务号；p 是新任务数据结构的指针。int copy_mem (int nr, struct task_struct *p) /** OK，下面是主要的fork 子程序。它复制系统进程信息(task[n])并且设置必要的寄存器。* 它还整个地复制数据段。*/// 复制进程。int copy_process (int nr, long ebp, long edi, long esi, long gs, long none,\t\t\t\t  long ebx, long ecx, long edx,\t\t\t\t  long fs, long es, long ds,\t\t\t\t  long eip, long cs, long eflags, long esp, long ss) // 为新进程取得不重复的进程号last_pid，并返回在任务数组中的任务号(数组index)。int find_empty_process (void) kernel/mktime.c // 该函数计算从1970 年1 月1 日0 时起到开机当日经过的秒数，作为开机时间。longkernel_mktime (struct tm *tm) kernel/panic.c // 该函数用来显示内核中出现的重大错误信息，并运行文件系统同步函数，然后进入死循环 -- 死机。// 如果当前进程是任务0 的话，还说明是交换任务出错，并且还没有运行文件系统同步函数。void panic (const char *s) kernel/printk.c // 内核使用的显示函数。int printk (const char *fmt, ...) kernel/sched.c // 显示任务号nr 的进程号、进程状态和内核堆栈空闲字节数（大约）。void show_task (int nr, struct task_struct *p) // 显示所有任务的任务号、进程号、进程状态和内核堆栈空闲字节数（大约）。void show_stat (void) /* * 将当前协处理器内容保存到老协处理器状态数组中，并将当前任务的协处理器 * 内容加载进协处理器。 */// 当任务被调度交换过以后，该函数用以保存原任务的协处理器状态（上下文）并恢复新调度进来的// 当前任务的协处理器执行状态。void math_state_restore () /* * 'schedule()'是调度函数。这是个很好的代码！没有任何理由对它进行修改，因为它可以在所有的 * 环境下工作（比如能够对IO-边界处理很好的响应等）。只有一件事值得留意，那就是这里的信号 * 处理代码。 * 注意！！任务0 是个闲置('idle')任务，只有当没有其它任务可以运行时才调用它。它不能被杀 * 死，也不能睡眠。任务0 中的状态信息'state'是从来不用的。 */void schedule (void) //// pause()系统调用。转换当前任务的状态为可中断的等待状态，并重新调度。// 该系统调用将导致进程进入睡眠状态，直到收到一个信号。该信号用于终止进程或者使进程调用// 一个信号捕获函数。只有当捕获了一个信号，并且信号捕获处理函数返回，pause()才会返回。// 此时pause()返回值应该是-1，并且errno 被置为EINTR。这里还没有完全实现（直到0.95 版）。int sys_pause (void) // 把当前任务置为不可中断的等待状态，并让睡眠队列头的指针指向当前任务。// 只有明确地唤醒时才会返回。该函数提供了进程与中断处理程序之间的同步机制。// 函数参数*p 是放置等待任务的队列头指针。（参见列表后的说明）。void sleep_on (struct task_struct **p) // 将当前任务置为可中断的等待状态，并放入*p 指定的等待队列中。参见列表后对sleep_on()的说明。void interruptible_sleep_on (struct task_struct **p) // 唤醒指定任务*p。void wake_up (struct task_struct **p) // 指定软盘到正常运转状态所需延迟滴答数（时间）。// nr -- 软驱号(0-3)，返回值为滴答数。int ticks_to_floppy_on (unsigned int nr) // 等待指定软驱马达启动所需时间。void floppy_on (unsigned int nr) // 置关闭相应软驱马达停转定时器（3 秒）。void floppy_off (unsigned int nr) // 软盘定时处理子程序。更新马达启动定时值和马达关闭停转计时值。该子程序是在时钟定时// 中断中被调用，因此每一个滴答(10ms)被调用一次，更新马达开启或停转定时器的值。如果某// 一个马达停转定时到，则将数字输出寄存器马达启动位复位。void do_floppy_timer (void) // 添加定时器。输入参数为指定的定时值(滴答数)和相应的处理程序指针。// jiffies – 以10 毫秒计的滴答数；*fn()- 定时时间到时执行的函数。void add_timer (long jiffies, void (*fn) ()) //// 时钟中断C 函数处理程序，在kernel/system_call.s 中的_timer_interrupt（176 行）被调用。// 参数cpl 是当前特权级0 或3，0 表示内核代码在执行。// 对于一个进程由于执行时间片用完时，则进行任务切换。并执行一个计时更新工作。void do_timer (long cpl) // 系统调用功能 - 设置报警定时时间值(秒)。// 如果已经设置过alarm 值，则返回旧值，否则返回0。int sys_alarm (long seconds) // 系统调用功能 -- 降低对CPU 的使用优先权（有人会用吗？?）。// 应该限制increment 大于0，否则的话,可使优先权增大！！int sys_nice (long increment) // 调度程序的初始化子程序。void sched_init (void) kernel/signal.c volatile void do_exit (int error_code);\t// 前面的限定符volatile 要求编译器不要对其进行优化。// 获取当前任务信号屏蔽位图（屏蔽码）。int sys_sgetmask () // 设置新的信号屏蔽位图。SIGKILL 不能被屏蔽。返回值是原信号屏蔽位图。int sys_ssetmask (int newmask) // 复制sigaction 数据到fs 数据段to 处。。static _inline void save_old (char *from, char *to) // 把sigaction 数据从fs 数据段from 位置复制到to 处。static _inline void get_new (char *from, char *to) // signal()系统调用。类似于sigaction()。为指定的信号安装新的信号句柄(信号处理程序)。// 信号句柄可以是用户指定的函数，也可以是SIG_DFL（默认句柄）或SIG_IGN（忽略）。// 参数signum --指定的信号；handler -- 指定的句柄；restorer –原程序当前执行的地址位置。// 函数返回原信号句柄。int sys_signal (int signum, long handler, long restorer) // sigaction()系统调用。改变进程在收到一个信号时的操作。signum 是除了SIGKILL 以外的任何// 信号。[如果新操作(action)不为空]则新操作被安装。如果oldaction 指针不为空，则原操作// 被保留到oldaction。成功则返回0，否则为-1。int sys_sigaction (int signum, const struct sigaction *action,\t\t\t\t\tstruct sigaction *oldaction) // 系统调用中断处理程序中真正的信号处理程序（在kernel/system_call.s,119 行）。// 该段代码的主要作用是将信号的处理句柄插入到用户程序堆栈中，并在本系统调用结束// 返回后立刻执行信号句柄程序，然后继续执行用户的程序。void do_signal (long signr, long eax, long ebx, long ecx, long edx,\t\t\tlong fs, long es, long ds,\t\t\tlong eip, long cs, long eflags, unsigned long *esp, long ss) kernel/sys.c // 返回日期和时间。int sys_ftime () // 用于当前进程对子进程进行调试(degugging)。int sys_ptrace () // 改变并打印终端行设置。int sys_stty () // 取终端行设置信息。int sys_gtty () // 设置当前任务的实际以及/或者有效组ID（gid）。如果任务没有超级用户特权，// 那么只能互换其实际组ID 和有效组ID。如果任务具有超级用户特权，就能任意设置有效的和实际// 的组ID。保留的gid（saved gid）被设置成与有效gid 同值。int sys_setregid (int rgid, int egid) // 设置进程组号(gid)。如果任务没有超级用户特权，它可以使用setgid()将其有效gid// （effective gid）设置为成其保留gid(saved gid)或其实际gid(real gid)。如果任务有// 超级用户特权，则实际gid、有效gid 和保留gid 都被设置成参数指定的gid。int sys_setgid (int gid) // 返回从1970 年1 月1 日00:00:00 GMT 开始计时的时间值（秒）。如果tloc 不为null，则时间值// 也存储在那里。int sys_time (long *tloc) /** 无特权的用户可以见实际用户标识符(real uid)改成有效用户标识符(effective uid)，反之也然。*/// 设置任务的实际以及/或者有效用户ID（uid）。如果任务没有超级用户特权，那么只能互换其// 实际用户ID 和有效用户ID。如果任务具有超级用户特权，就能任意设置有效的和实际的用户ID。// 保留的uid（saved uid）被设置成与有效uid 同值。int sys_setreuid (int ruid, int euid) // 设置任务用户号(uid)。如果任务没有超级用户特权，它可以使用setuid()将其有效uid// （effective uid）设置成其保留uid(saved uid)或其实际uid(real uid)。如果任务有// 超级用户特权，则实际uid、有效uid 和保留uid 都被设置成参数指定的uid。int sys_setuid (int uid) // 设置系统时间和日期。参数tptr 是从1970 年1 月1 日00:00:00 GMT 开始计时的时间值（秒）。// 调用进程必须具有超级用户权限。int sys_stime (long *tptr) // 当参数end_data_seg 数值合理，并且系统确实有足够的内存，而且进程没有超越其最大数据段大小// 时，该函数设置数据段末尾为end_data_seg 指定的值。该值必须大于代码结尾并且要小于堆栈// 结尾16KB。返回值是数据段的新结尾值（如果返回值与要求值不同，则表明有错发生）。// 该函数并不被用户直接调用，而由libc 库函数进行包装，并且返回值也不一样。int sys_brk (unsigned long end_data_seg) /** 下面代码需要某些严格的检查…* 我只是没有胃口来做这些。我也不完全明白sessions/pgrp 等。还是让了解它们的人来做吧。*/// 将参数pid 指定进程的进程组ID 设置成pgid。如果参数pid=0，则使用当前进程号。如果// pgid 为0，则使用参数pid 指定的进程的组ID 作为pgid。如果该函数用于将进程从一个// 进程组移到另一个进程组，则这两个进程组必须属于同一个会话(session)。在这种情况下，// 参数pgid 指定了要加入的现有进程组ID，此时该组的会话ID 必须与将要加入进程的相同(193 行)。int sys_setpgid (int pid, int pgid) // 获取系统信息。其中utsname 结构包含5 个字段，分别是：本版本操作系统的名称、网络节点名称、// 当前发行级别、版本级别和硬件类型名称。int sys_uname (struct utsname *name) // 设置当前进程创建文件属性屏蔽码为mask & 0777。并返回原屏蔽码。int sys_umask (int mask) kernel/system_call.s ;/*;* system_call.s 文件包含系统调用(system-call)底层处理子程序。由于有些代码比较类似，所以;* 同时也包括时钟中断处理(timer-interrupt)句柄。硬盘和软盘的中断处理程序也在这里。;*;* 注意：这段代码处理信号(signal)识别，在每次时钟中断和系统调用之后都会进行识别。一般;* 中断信号并不处理信号识别，因为会给系统造成混乱。;*;* 从系统调用返回（'ret_from_system_call'）时堆栈的内容见上面19-30 行。;*/SIG_CHLD = 17 ;// 定义SIG_CHLD 信号（子进程停止或结束）。R_EAX = 00h ;// 堆栈中各个寄存器的偏移位置。R_EBX = 04hR_ECX = 08hR_EDX = 0ChR_FS = 10hR_ES = 14hR_DS = 18hR_EIP = 1ChR_CS = 20hEFLAGS = 24hOLDR_ESP = 28h ;// 当有特权级变化时。OLR_DSS = 2Ch;// 以下这些是任务结构(task_struct)中变量的偏移值，参见include/linux/sched.h，77 行开始。state = 0 ;// these are offsets into the task-struct. ;// 进程状态码counter = 4 ;// 任务运行时间计数(递减)（滴答数），运行时间片。priority = 8 ;// 运行优先数。任务开始运行时counter=priority，越大则运行时间越长。signal = 12 ;// 是信号位图，每个比特位代表一种信号，信号值=位偏移值+1。sigaction = 16 ;// MUST be 16 (=len of sigaction) // sigaction 结构长度必须是16 字节。;// 信号执行属性结构数组的偏移值，对应信号将要执行的操作和标志信息。blocked = (33*16) ;// 受阻塞信号位图的偏移量。;// 以下定义在sigaction 结构中的偏移量，参见include/signal.h，第48 行开始。;// offsets within sigactionsa_handler = 0 ;// 信号处理过程的句柄（描述符）。sa_mask = 4 ;// 信号量屏蔽码sa_flags = 8 ;// 信号集。sa_restorer = 12 ;// 返回恢复执行的地址位置。nr_system_calls = 72 ;// Linux 0.11 版内核中的系统调用总数。;/*;* Ok, I get parallel printer interrupts while using the floppy for some;* strange reason. Urgel. Now I just ignore them.;*/;/*;* 好了，在使用软驱时我收到了并行打印机中断，很奇怪。呵，现在不管它。;*/;// 定义入口点。extrn _schedule:proc,_do_signal:proc,_math_error:procextrn _math_state_restore:proc,_math_emulate:proc,_jiffies:procextrn _do_timer:proc,_do_execve:procextrn _find_empty_process:proc,_copy_process:procextrn _do_floppy:proc,_unexpected_floppy_interrupt:procextrn _do_hd:proc,_unexpected_hd_interrupt:procextrn _current:dword,_task:dword,_sys_call_table:dwordpublic _system_call,_sys_fork,_timer_interrupt,_sys_execvepublic _hd_interrupt,_floppy_interrupt,_parallel_interruptpublic _device_not_available, _coprocessor_error.code;// 错误的系统调用号。align 4 ;// 内存4 字节对齐。bad_sys_call:\tmov eax,-1 ;// eax 中置-1，退出中断。\tiretd;// 重新执行调度程序入口。调度程序schedule 在(kernel/sched.c,104)。align 4reschedule:\tpush ret_from_sys_call ;// 将ret_from_sys_call 的地址入栈（101 行）。\tjmp _schedule;//// int 0x80 --linux 系统调用入口点(调用中断int 0x80，eax 中是调用号)。align 4_system_call:\tcmp eax,nr_system_calls-1 ;// 调用号如果超出范围的话就在eax 中置-1 并退出。\tja bad_sys_call\tpush ds ;// 保存原段寄存器值。\tpush es\tpush fs\tpush edx ;// ebx,ecx,edx 中放着系统调用相应的C 语言函数的调用参数。\tpush ecx ;// push %ebx,%ecx,%edx as parameters\tpush ebx ;// to the system call\tmov edx,10h ;// set up ds,es to kernel space\tmov ds,dx ;// ds,es 指向内核数据段(全局描述符表中数据段描述符)。\tmov es,dx\tmov edx,17h ;// fs points to local data space\tmov fs,dx ;// fs 指向局部数据段(局部描述符表中数据段描述符)。;// 下面这句操作数的含义是：调用地址 = _sys_call_table + %eax * 4。参见列表后的说明。;// 对应的C 程序中的sys_call_table 在include/linux/sys.h 中，其中定义了一个包括72 个;// 系统调用C 处理函数的地址数组表。\tcall [_sys_call_table+eax*4]\tpush eax ;// 把系统调用号入栈。\tmov eax,_current ;// 取当前任务（进程）数据结构地址??eax。;// 下面97-100 行查看当前任务的运行状态。如果不在就绪状态(state 不等于0)就去执行调度程序。;// 如果该任务在就绪状态但counter[??]值等于0，则也去执行调度程序。\tcmp dword ptr [state+eax],0 ;// state\tjne reschedule\tcmp dword ptr [counter+eax],0 ;// counter\tje reschedule;// 以下这段代码执行从系统调用C 函数返回后，对信号量进行识别处理。ret_from_sys_call:;// 首先判别当前任务是否是初始任务task0，如果是则不必对其进行信号量方面的处理，直接返回。;// 103 行上的_task 对应C 程序中的task[]数组，直接引用task 相当于引用task[0]。\tmov eax,_current ;// task[0] cannot have signals\tcmp eax,_task\tje l1 ;// 向前(forward)跳转到标号l1。;// 通过对原调用程序代码选择符的检查来判断调用程序是否是超级用户。如果是超级用户就直接;// 退出中断，否则需进行信号量的处理。这里比较选择符是否为普通用户代码段的选择符0x000f;// (RPL=3，局部表，第1 个段(代码段))，如果不是则跳转退出中断程序。\tcmp word ptr [R_CS+esp],0fh ;// was old code segment supervisor ?\tjne l1;// 如果原堆栈段选择符不为0x17（也即原堆栈不在用户数据段中），则也退出。\tcmp word ptr [OLR_DSS+esp],17h ;// was stack segment = 0x17 ?\tjne l1;// 下面这段代码（109-120）的用途是首先取当前任务结构中的信号位图(32 位，每位代表1 种信号)，;// 然后用任务结构中的信号阻塞（屏蔽）码，阻塞不允许的信号位，取得数值最小的信号值，再把;// 原信号位图中该信号对应的位复位（置0），最后将该信号值作为参数之一调用do_signal()。;// do_signal()在（kernel/signal.c,82）中，其参数包括13 个入栈的信息。\tmov ebx,[signal+eax] ;// 取信号位图??ebx，每1 位代表1 种信号，共32 个信号。\tmov ecx,[blocked+eax] ;// 取阻塞（屏蔽）信号位图??ecx。\tnot ecx ;// 每位取反。\tand ecx,ebx ;// 获得许可的信号位图。\tbsf ecx,ecx ;// 从低位（位0）开始扫描位图，看是否有1 的位，;// 若有，则ecx 保留该位的偏移值（即第几位0-31）。\tje l1 ;// 如果没有信号则向前跳转退出。\tbtr ebx,ecx ;// 复位该信号（ebx 含有原signal 位图）。\tmov dword ptr [signal+eax],ebx ;// 重新保存signal 位图信息??current->signal。\tinc ecx ;// 将信号调整为从1 开始的数(1-32)。\tpush ecx ;// 信号值入栈作为调用do_signal 的参数之一。\tcall _do_signal ;// 调用C 函数信号处理程序(kernel/signal.c,82)\tpop eax ;// 弹出信号值。l1: pop eax\tpop ebx\tpop ecx\tpop edx\tpop fs\tpop es\tpop ds\tiretd;//// int16 -- 下面这段代码处理协处理器发出的出错信号。跳转执行C 函数math_error();// (kernel/math/math_emulate.c,82)，返回后将跳转到ret_from_sys_call 处继续执行。align 4_coprocessor_error:\tpush ds\tpush es\tpush fs\tpush edx\tpush ecx\tpush ebx\tpush eax\tmov eax,10h ;// ds,es 置为指向内核数据段。\tmov ds,ax\tmov es,ax\tmov eax,17h ;// fs 置为指向局部数据段（出错程序的数据段）。\tmov fs,ax\tpush ret_from_sys_call ;// 把下面调用返回的地址入栈。\tjmp _math_error ;// 执行C 函数math_error()(kernel/math/math_emulate.c,37);//// int7 -- 设备不存在或协处理器不存在(Coprocessor not available)。;// 如果控制寄存器CR0 的EM 标志置位，则当CPU 执行一个R_ESC 转义指令时就会引发该中断，这样就;// 可以有机会让这个中断处理程序模拟R_ESC 转义指令（169 行）。;// CR0 的TS 标志是在CPU 执行任务转换时设置的。TS 可以用来确定什么时候协处理器中的内容（上下文）;// 与CPU 正在执行的任务不匹配了。当CPU 在运行一个转义指令时发现TS 置位了，就会引发该中断。;// 此时就应该恢复新任务的协处理器执行状态（165 行）。参见(kernel/sched.c,77)中的说明。;// 该中断最后将转移到标号ret_from_sys_call 处执行下去（检测并处理信号）。align 4_device_not_available:\tpush ds\tpush es\tpush fs\tpush edx\tpush ecx\tpush ebx\tpush eax\tmov eax,10h ;// ds,es 置为指向内核数据段。\tmov ds,ax\tmov es,ax\tmov eax,17h ;// fs 置为指向局部数据段（出错程序的数据段）。\tmov fs,ax\tpush ret_from_sys_call ;// 把下面跳转或调用的返回地址入栈。\tclts ;// clear TS so that we can use math\tmov eax,cr0\ttest eax,4h ;// EM (math emulation bit);// 如果不是EM 引起的中断，则恢复新任务协处理器状态，\tje  goto_math_state_restore;// 执行C 函数math_state_restore()(kernel/sched.c,77)。\tpush ebp\tpush esi\tpush edi\tcall _math_emulate ;// 调用C 函数math_emulate(kernel/math/math_emulate.c,18)。\tpop edi\tpop esi\tpop ebp\tret ;// 这里的ret 将跳转到ret_from_sys_call(101 行)。goto_math_state_restore:\tjmp _math_state_restore;//// int32 -- (int 0x20) 时钟中断处理程序。中断频率被设置为100Hz(include/linux/sched.h,5)，;// 定时芯片8253/8254 是在(kernel/sched.c,406)处初始化的。因此这里jiffies 每10 毫秒加1。;// 这段代码将jiffies 增1，发送结束中断指令给8259 控制器，然后用当前特权级作为参数调用;// C 函数do_timer(long CPL)。当调用返回时转去检测并处理信号。align 4_timer_interrupt:\tpush ds ;// save ds,es and put kernel data space\tpush es ;// into them. %fs is used by _system_call\tpush fs\tpush edx ;// we save %eax,%ecx,%edx as gcc doesn't\tpush ecx ;// save those across function calls. %ebx\tpush ebx ;// is saved as we use that in ret_sys_call\tpush eax\tmov eax,10h ;// ds,es 置为指向内核数据段。\tmov ds,ax\tmov es,ax\tmov eax,17h ;// fs 置为指向局部数据段（出错程序的数据段）。\tmov fs,ax\tinc dword ptr _jiffies;// 由于初始化中断控制芯片时没有采用自动EOI，所以这里需要发指令结束该硬件中断。\tmov al,20h ;// EOI to interrupt controller ;//1\tout 20h,al ;// 操作命令字OCW2 送0x20 端口。;// 下面3 句从选择符中取出当前特权级别(0 或3)并压入堆栈，作为do_timer 的参数。\tmov eax,dword ptr [R_CS+esp]\tand eax,3 ;// %eax is CPL (0 or 3, 0=supervisor)\tpush eax;// do_timer(CPL)执行任务切换、计时等工作，在kernel/shched.c,305 行实现。\tcall _do_timer ;// 'do_timer(long CPL)' does everything from\tadd esp,4 ;// task switching to accounting ...\tjmp ret_from_sys_call;//// 这是sys_execve()系统调用。取中断调用程序的代码指针作为参数调用C 函数do_execve()。;// do_execve()在(fs/exec.c,182)。align 4_sys_execve:\tlea eax,[R_EIP+esp]\tpush eax\tcall _do_execve\tadd esp,4 ;// 丢弃调用时压入栈的R_EIP 值。\tret;//// sys_fork()调用，用于创建子进程，是system_call 功能2。原形在include/linux/sys.h 中。;// 首先调用C 函数find_empty_process()，取得一个进程号pid。若返回负数则说明目前任务数组;// 已满。然后调用copy_process()复制进程。align 4_sys_fork:\tcall _find_empty_process ;// 调用find_empty_process()(kernel/fork.c,135)。\ttest eax,eax\tjs l2\tpush gs\tpush esi\tpush edi\tpush ebp\tpush eax\tcall _copy_process ;// 调用C 函数copy_process()(kernel/fork.c,68)。\tadd esp,20 ;// 丢弃这里所有压栈内容。l2: ret;//// int 46 -- (int 0x2E) 硬盘中断处理程序，响应硬件中断请求IRQ14。;// 当硬盘操作完成或出错就会发出此中断信号。(参见kernel/blk_drv/hd.c)。;// 首先向8259A 中断控制从芯片发送结束硬件中断指令(EOI)，然后取变量do_hd 中的函数指针放入edx;// 寄存器中，并置do_hd 为NULL，接着判断edx 函数指针是否为空。如果为空，则给edx 赋值指向;// unexpected_hd_interrupt()，用于显示出错信息。随后向8259A 主芯片送EOI 指令，并调用edx 中;// 指针指向的函数: read_intr()、write_intr()或unexpected_hd_interrupt()。_hd_interrupt:\tpush eax\tpush ecx\tpush edx\tpush ds\tpush es\tpush fs\tmov eax,10h ;// ds,es 置为内核数据段。\tmov ds,ax\tmov es,ax\tmov eax,17h ;// fs 置为调用程序的局部数据段。\tmov fs,ax;// 由于初始化中断控制芯片时没有采用自动EOI，所以这里需要发指令结束该硬件中断。\tmov al,20h\tout 0A0h,al ;// EOI to interrupt controller ;//1 ;// 送从8259A。\tjmp l3 ;// give port chance to breathel3: jmp l4 ;// 延时作用。l4: xor edx,edx\txchg edx,dword ptr _do_hd ;// do_hd 定义为一个函数指针，将被赋值read_intr()或;// write_intr()函数地址。(kernel/blk_drv/hd.c);// 放到edx 寄存器后就将do_hd 指针变量置为NULL。\ttest edx,edx ;// 测试函数指针是否为Null。\tjne l5 ;// 若空，则使指针指向C 函数unexpected_hd_interrupt()。\tmov edx,dword ptr _unexpected_hd_interrupt ;// (kernel/blk_drv/hdc,237)。l5: out 20h,al ;// 送主8259A 中断控制器EOI 指令（结束硬件中断）。\tcall edx ;// \"interesting\" way of handling intr.\tpop fs ;// 上句调用do_hd 指向的C 函数。\tpop es\tpop ds\tpop edx\tpop ecx\tpop eax\tiretd;//// int38 -- (int 0x26) 软盘驱动器中断处理程序，响应硬件中断请求IRQ6。;// 其处理过程与上面对硬盘的处理基本一样。(kernel/blk_drv/floppy.c)。;// 首先向8259A 中断控制器主芯片发送EOI 指令，然后取变量do_floppy 中的函数指针放入eax;// 寄存器中，并置do_floppy 为NULL，接着判断eax 函数指针是否为空。如为空，则给eax 赋值指向;// unexpected_floppy_interrupt ()，用于显示出错信息。随后调用eax 指向的函数: rw_interrupt,;// seek_interrupt,recal_interrupt,reset_interrupt 或unexpected_floppy_interrupt。_floppy_interrupt:\tpush eax\tpush ecx\tpush edx\tpush ds\tpush es\tpush fs\tmov eax,10h ;// ds,es 置为内核数据段。\tmov ds,ax\tmov es,ax\tmov eax,17h ;// fs 置为调用程序的局部数据段。\tmov fs,ax\tmov al,20h ;// 送主8259A 中断控制器EOI 指令（结束硬件中断）。\tout 20h,al ;// EOI to interrupt controller ;//1\txor eax,eax\txchg eax,dword ptr _do_floppy ;// do_floppy 为一函数指针，将被赋值实际处理C 函数程序，;// 放到eax 寄存器后就将do_floppy 指针变量置空。\ttest eax,eax ;// 测试函数指针是否=NULL?\tjne l6 ;// 若空，则使指针指向C 函数unexpected_floppy_interrupt()。\tmov eax,dword ptr _unexpected_floppy_interruptl6: call eax ;// \"interesting\" way of handling intr.\tpop fs ;// 上句调用do_floppy 指向的函数。\tpop es\tpop ds\tpop edx\tpop ecx\tpop eax\tiretd;//// int 39 -- (int 0x27) 并行口中断处理程序，对应硬件中断请求信号IRQ7。;// 本版本内核还未实现。这里只是发送EOI 指令。_parallel_interrupt:\tpush eax\tmov al,20h\tout 20h,al\tpop eax\tiretdend kernel/traps.c // 以下语句定义了三个嵌入式汇编宏语句函数。有关嵌入式汇编的基本语法见列表后或参见附录。// 取段seg 中地址addr 处的一个字节。//#define get_seg_byte(seg,addr) ({ \\//register char __res; \\//__asm__(\"push %%fs;mov %%ax,%%fs;movb %%fs:%2,%%al;pop %%fs\" \\//\t:\"=a\" (__res):\"0\" (seg),\"m\" (*(addr))); \\//__res;})_inline char get_seg_byte(unsigned short segm, void *addr) // 取段seg 中地址addr 处的一个长字（4 字节）。_inline long get_seg_long(unsigned short segm,long *addr) // 取fs 段寄存器的值（选择符）。_inline unsigned short _fs() // 该子程序用来打印出错中断的名称、出错号、调用程序的EIP、EFLAGS、ESP、fs 段寄存器值、// 段的基址、段的长度、进程号pid、任务号、10 字节指令码。如果堆栈在用户数据段，则还// 打印16 字节的堆栈内容。static void die(char * str,long esp_ptr,long nr) // 以下这些以do_开头的函数是对应名称中断处理程序调用的C 函数。void do_double_fault(long esp, long error_code) // 下面是异常（陷阱）中断程序初始化子程序。设置它们的中断调用门（中断向量）。// set_trap_gate()与set_system_gate()的主要区别在于前者设置的特权级为0，后者是3。因此// 断点陷阱中断int3、溢出中断overflow 和边界出错中断bounds 可以由任何程序产生。// 这两个函数均是嵌入式汇编宏程序(include/asm/system.h,第36 行、39 行)。void trap_init(void) kernel/vsprintf.c // 该函数将字符数字串转换成整数。输入是数字串指针的指针，返回是结果数值。另外指针将前移。static int skip_atoi (const char **s) // 除操作。输入：n 为被除数，base 为除数；结果：n 为商，函数返回值为余数。// 参见4.5.3 节有关嵌入汇编的信息。#define do_div(n,base) _do_div(&(n),base)extern _inline int _do_div(int *n,int base) // 将整数转换为指定进制的字符串。// 输入：num-整数；base-进制；size-字符串长度；precision-数字长度(精度)；type-类型选项。// 输出：str 字符串指针。static char *number (char *str, int num, int base, int size, int precision, int type) // 下面函数是送格式化输出到字符串中。// 为了能在内核中使用格式化的输出，Linus 在内核实现了该C 标准函数。// 其中参数fmt 是格式字符串；args 是个数变化的值；buf 是输出字符串缓冲区。// 请参见本代码列表后的有关格式转换字符的介绍。intvsprintf (char *buf, const char *fmt, va_list args) kernel/blk_drv/floppy.c // 字节直接输出（嵌入汇编语言宏）。//#define immoutb_p(val,port) \\//__asm__ (\"outb %0,%1\\n\\tjmp 1f\\n1:\\tjmp 1f\\n1:\"::\"a\" ((char) (val)),\"i\" (port))void _inline immoutb_p(unsigned char val,unsigned short port) //// 释放（取消选定的）软盘（软驱）。// 数字输出寄存器(DOR)的低2 位用于指定选择的软驱（0-3 对应A-D）。voidfloppy_deselect (unsigned int nr) /** floppy-change()不是从中断程序中调用的，所以这里我们可以轻松一下，睡觉等。* 注意floppy-on()会尝试设置current_DOR 指向所需的驱动器，但当同时使用几个* 软盘时不能睡眠：因此此时只能使用循环方式。*///// 检测指定软驱中软盘更换情况。如果软盘更换了则返回1，否则返回0。intfloppy_change (unsigned int nr) //// 复制内存块。//#define copy_buffer(from,to) \\// __asm__( \"cld ; rep ; movsl\" \\// :: \"c\" (BLOCK_SIZE/4), \"S\" ((long)(from)), \"D\" ((long)(to)) \\// : \"cx\", \"di\", \"si\")void _inline copy_buffer(void* from, void* to) //// 设置（初始化）软盘DMA 通道。static voidsetup_DMA (void) //// 向软盘控制器输出一个字节数据（命令或参数）。static voidoutput_byte (char byte) //// 读取FDC 执行的结果信息。// 结果信息最多7 个字节，存放在reply_buffer[]中。返回读入的结果字节数，若返回值=-1// 表示出错。static intresult (void) //// 软盘操作出错中断调用函数。由软驱中断处理程序调用。static voidbad_flp_intr (void) /** OK，下面该中断处理函数是在DMA 读/写成功后调用的，这样我们就可以检查执行结果，* 并复制缓冲区中的数据。*///// 软盘读写操作成功中断调用函数。。static voidrw_interrupt (void) //// 设置DMA 并输出软盘操作命令和参数（输出1 字节命令+ 0~7 字节参数）。_inline voidsetup_rw_floppy (void) /** 该子程序是在每次软盘控制器寻道（或重新校正）中断后被调用的。注意* \"unexpected interrupt\"(意外中断)子程序也会执行重新校正操作，但不在此地。*///// 寻道处理中断调用函数。// 首先发送检测中断状态命令，获得状态信息ST0 和磁头所在磁道信息。若出错则执行错误计数// 检测处理或取消本次软盘操作请求项。否则根据状态信息设置当前磁道变量，然后调用函数// setup_rw_floppy()设置DMA 并输出软盘读写命令和参数。static voidseek_interrupt (void) /** 该函数是在传输操作的所有信息都正确设置好后被调用的（也即软驱马达已开启* 并且已选择了正确的软盘（软驱）。*///// 读写数据传输函数。static voidtransfer (void) /** 特殊情况 - 用于意外中断（或复位）处理后。*///// 软驱重新校正中断调用函数。// 首先发送检测中断状态命令（无参数），如果返回结果表明出错，则置复位标志，否则复位重新// 校正标志。然后再次执行软盘请求。static voidrecal_interrupt (void) //// 意外软盘中断请求中断调用函数。// 首先发送检测中断状态命令（无参数），如果返回结果表明出错，则置复位标志，否则置重新// 校正标志。voidunexpected_floppy_interrupt (void) //// 软盘重新校正处理函数。// 向软盘控制器FDC 发送重新校正命令和参数，并复位重新校正标志。static voidrecalibrate_floppy (void) //// 软盘控制器FDC 复位中断调用函数。在软盘中断处理程序中调用。// 首先发送检测中断状态命令（无参数），然后读出返回的结果字节。接着发送设定软驱参数命令// 和相关参数，最后再次调用执行软盘请求。static voidreset_interrupt (void) /* FDC 复位是通过将数字输出寄存器(DOR)位2 置0 一会儿实现的 *///// 复位软盘控制器。static voidreset_floppy (void) //// 软驱启动定时中断调用函数。// 首先检查数字输出寄存器(DOR)，使其选择当前指定的驱动器。然后调用执行软盘读写传输// 函数transfer()。static voidfloppy_on_interrupt (void) //// 软盘读写请求项处理函数。voiddo_fd_request (void) //// 软盘系统初始化。// 设置软盘块设备的请求处理函数(do_fd_request())，并设置软盘中断门(int 0x26，对应硬件// 中断请求信号IRQ6），然后取消对该中断信号的屏蔽，允许软盘控制器FDC 发送中断请求信号。voidfloppy_init (void) kernel/blk_drv/hd.c // 读端口port，共读nr 字，保存在buf 中。//#define port_read(port,buf,nr) \\//__asm__( \"cld;rep;insw\":: \"d\" (port), \"D\" (buf), \"c\" (nr): \"cx\", \"di\")_inline void port_read(unsigned short port, void* buf,unsigned long nr) // 写端口port，共写nr 字，从buf 中取数据。//#define port_write(port,buf,nr) \\//__asm__( \"cld;rep;outsw\":: \"d\" (port), \"S\" (buf), \"c\" (nr): \"cx\", \"si\")_inline void port_write(unsigned short port, void* buf,unsigned long nr) /* 下面该函数只在初始化时被调用一次。用静态变量callable 作为可调用标志。*/// 该函数的参数由初始化程序init/main.c 的init 子程序设置为指向0x90080 处，此处存放着setup.s// 程序从BIOS 取得的2 个硬盘的基本参数表(32 字节)。硬盘参数表信息参见下面列表后的说明。// 本函数主要功能是读取CMOS 和硬盘参数表信息，用于设置硬盘分区结构hd，并加载RAM 虚拟盘和// 根文件系统。int sys_setup (unsigned char *BIOS) //// 判断并循环等待驱动器就绪。// 读硬盘控制器状态寄存器端口HD_STATUS(0x1f7)，并循环检测驱动器就绪比特位和控制器忙位。static int controller_ready (void) //// 检测硬盘执行命令后的状态。(win_表示温切斯特硬盘的缩写)// 读取状态寄存器中的命令执行结果状态。返回0 表示正常，1 出错。如果执行命令错，// 则再读错误寄存器HD_ERROR(0x1f1)。static int win_result (void) //// 向硬盘控制器发送命令块（参见列表后的说明）。// 调用参数：drive - 硬盘号(0-1)； nsect - 读写扇区数；// sect - 起始扇区； head - 磁头号；// cyl - 柱面号； cmd - 命令码；// *intr_addr() - 硬盘中断处理程序中将调用的C 处理函数。static void hd_out (unsigned int drive, unsigned int nsect, unsigned int sect,\t\t    unsigned int head, unsigned int cyl, unsigned int cmd,\t\t    void (*intr_addr) (void)) //// 等待硬盘就绪。也即循环等待主状态控制器忙标志位复位。若仅有就绪或寻道结束标志// 置位，则成功，返回0。若经过一段时间仍为忙，则返回1。static int drive_busy (void) //// 诊断复位（重新校正）硬盘控制器。static void reset_controller (void) //// 复位硬盘nr。首先复位（重新校正）硬盘控制器。然后发送硬盘控制器命令“建立驱动器参数”，// 其中recal_intr()是在硬盘中断处理程序中调用的重新校正处理函数。static void reset_hd (int nr) //// 意外硬盘中断调用函数。// 发生意外硬盘中断时，硬盘中断处理程序中调用的默认C 处理函数。在被调用函数指针为空时// 调用该函数。参见(kernel/system_call.s,241 行)。void unexpected_hd_interrupt (void) //// 读写硬盘失败处理调用函数。static void bad_rw_intr (void) //// 读操作中断调用函数。将在执行硬盘中断处理程序中被调用。static void read_intr (void) //// 写扇区中断调用函数。在硬盘中断处理程序中被调用。// 在写命令执行后，会产生硬盘中断信号，执行硬盘中断处理程序，此时在硬盘中断处理程序中调用的// C 函数指针do_hd()已经指向write_intr()，因此会在写操作完成（或出错）后，执行该函数。static void write_intr (void) //// 硬盘重新校正（复位）中断调用函数。在硬盘中断处理程序中被调用。// 如果硬盘控制器返回错误信息，则首先进行硬盘读写失败处理，然后请求硬盘作相应(复位)处理。static void recal_intr (void) // 执行硬盘读写请求操作。void do_hd_request (void) // 硬盘系统初始化。void hd_init (void) kernel/blk_drv/ll_rw_blk.c // 锁定指定的缓冲区bh。如果指定的缓冲区已经被其它任务锁定，则使自己睡眠（不可中断地等待），// 直到被执行解锁缓冲区的任务明确地唤醒。static _inline voidlock_buffer (struct buffer_head *bh) // 释放（解锁）锁定的缓冲区。static _inline voidunlock_buffer (struct buffer_head *bh) /** add-request()向连表中加入一项请求。它关闭中断，* 这样就能安全地处理请求连表了 *///// 向链表中加入请求项。参数dev 指定块设备，req 是请求的结构信息。  static voidadd_request (struct blk_dev_struct *dev, struct request *req) //// 创建请求项并插入请求队列。参数是：主设备号major，命令rw，存放数据的缓冲区头指针bh。static voidmake_request (int major, int rw, struct buffer_head *bh) //// 低层读写数据块函数。// 该函数主要是在fs/buffer.c 中被调用。实际的读写操作是由设备的request_fn()函数完成。// 对于硬盘操作，该函数是do_hd_request()。（kernel/blk_drv/hd.c,294）void ll_rw_block (int rw, struct buffer_head *bh) //// 块设备初始化函数，由初始化程序main.c 调用（init/main.c,128）。// 初始化请求数组，将所有请求项置为空闲项(dev = -1)。有32 项(NR_REQUEST = 32)。void blk_dev_init (void) kernel/blk_drv/ramdisk.c // 执行虚拟盘(ramdisk)读写操作。程序结构与do_hd_request()类似(kernel/blk_drv/hd.c,294)。voiddo_rd_request (void) /* 返回内存虚拟盘ramdisk 所需的内存量 */// 虚拟盘初始化函数。确定虚拟盘在内存中的起始地址，长度。并对整个虚拟盘区清零。longrd_init (long mem_start, int length) /** 如果根文件系统设备(root device)是ramdisk 的话，则尝试加载它。root device 原先是指向* 软盘的，我们将它改成指向ramdisk。*///// 加载根文件系统到ramdisk。voidrd_load (void) kernel/blk_drv/math_emulate.c //// 协处理器仿真函数。// 中断处理程序调用的C 函数，参见(kernel/math/system_call.s，169 行)。voidmath_emulate (long edi, long esi, long ebp, long sys_call_ret,\t      long eax, long ebx, long ecx, long edx,\t      unsigned short fs, unsigned short es, unsigned short ds,\t      unsigned long eip, unsigned short cs, unsigned long eflags,\t      unsigned short ss, unsigned long esp) //// 协处理器出错处理函数。// 中断处理程序调用的C 函数，参见(kernel/math/system_call.s，145 行)。voidmath_error (void) 学习的目标是成熟！~~","title":"linux 简单分析"},{"content":"http://www.cnblogs.com/blankqdb/archive/2012/08/30/2663859.html 1 #include <sys/socket.h>2 ssize_t recv(int sockfd, void *buff, size_t nbytes, int flags);3 ssize_t send(int sockfd, const void *buff, size_t nbytes, int flags); recv 和send的前3个参数等同于read和write。 flags参数值为0或：   flags 说明 recv send  MSG_DONTROUTE 绕过路由表查找      •  MSG_DONTWAIT 仅本操作非阻塞    •       •  MSG_OOB　　　　 发送或接收带外数据   •   •  MSG_PEEK　　 窥看外来消息   •    MSG_WAITALL　　 等待所有数据    •    1. send解析  sockfd：指定发送端套接字描述符。  buff：    存放要发送数据的缓冲区  nbytes:  实际要改善的数据的字节数  flags：   一般设置为0  1) send先比较发送数据的长度nbytes和套接字sockfd的发送缓冲区的长度，如果nbytes > 套接字sockfd的发送缓冲区的长度, 该函数返回SOCKET_ERROR;  2) 如果nbtyes <= 套接字sockfd的发送缓冲区的长度，那么send先检查协议是否正在发送sockfd的发送缓冲区中的数据，如果是就等待协议把数据发送完，如果协议还没有开始发送sockfd的发送缓冲区中的数据或者sockfd的发送缓冲区中没有数据，那么send就比较sockfd的发送缓冲区的剩余空间和nbytes  3) 如果 nbytes > 套接字sockfd的发送缓冲区剩余空间的长度，send就一起等待协议把套接字sockfd的发送缓冲区中的数据发送完  4) 如果 nbytes < 套接字sockfd的发送缓冲区剩余空间大小，send就仅仅把buf中的数据copy到剩余空间里(注意并不是send把套接字sockfd的发送缓冲区中的数据传到连接的另一端的，而是协议传送的，send仅仅是把buf中的数据copy到套接字sockfd的发送缓冲区的剩余空间里)。  5) 如果send函数copy成功，就返回实际copy的字节数，如果send在copy数据时出现错误，那么send就返回SOCKET_ERROR; 如果在等待协议传送数据时网络断开，send函数也返回SOCKET_ERROR。  6) send函数把buff中的数据成功copy到sockfd的改善缓冲区的剩余空间后它就返回了，但是此时这些数据并不一定马上被传到连接的另一端。如果协议在后续的传送过程中出现网络错误的话，那么下一个socket函数就会返回SOCKET_ERROR。（每一个除send的socket函数在执行的最开始总要先等待套接字的发送缓冲区中的数据被协议传递完毕才能继续，如果在等待时出现网络错误那么该socket函数就返回SOCKET_ERROR）  7) 在unix系统下，如果send在等待协议传送数据时网络断开，调用send的进程会接收到一个SIGPIPE信号，进程对该信号的处理是进程终止。 2.recv函数 sockfd: 接收端套接字描述符 buff：   用来存放recv函数接收到的数据的缓冲区 nbytes: 指明buff的长度 flags:   一般置为0  1) recv先等待s的发送缓冲区的数据被协议传送完毕，如果协议在传送sock的发送缓冲区中的数据时出现网络错误，那么recv函数返回SOCKET_ERROR  2) 如果套接字sockfd的发送缓冲区中没有数据或者数据被协议成功发送完毕后，recv先检查套接字sockfd的接收缓冲区，如果sockfd的接收缓冲区中没有数据或者协议正在接收数据，那么recv就一起等待，直到把数据接收完毕。当协议把数据接收完毕，recv函数就把s的接收缓冲区中的数据copy到buff中（注意协议接收到的数据可能大于buff的长度，所以在这种情况下要调用几次recv函数才能把sockfd的接收缓冲区中的数据copy完。recv函数仅仅是copy数据，真正的接收数据是协议来完成的）  3) recv函数返回其实际copy的字节数，如果recv在copy时出错，那么它返回SOCKET_ERROR。如果recv函数在等待协议接收数据时网络中断了，那么它返回0。  4) 在unix系统下，如果recv函数在等待协议接收数据时网络断开了，那么调用 recv的进程会接收到一个SIGPIPE信号，进程对该信号的默认处理是进程终止。","title":"linux send与recv函数详解"},{"content":"kill -9  `pgrep  进程名称` kill -9 `ps aux |grep 进程名称 |awk '{print $2}' |sed -n '2p'`","title":"根据名称 杀进程 单个进程"},{"content":"最近有很多应届毕业的同学打听数码视讯的情况，而一般从网上搜出来的消息往往过于骇人听闻。回想起自己当年加入数码视讯前的彷徨，就把前几日，与一位同学的对话，摘抄如下，希望能解决一些人的疑惑吧！ =============================================================================================   问： 我是今年刚毕业的研究生，签约签了数码视讯，想了解下内部的具体情况，希望寻求你的帮助，不知道是否唐突，我的QQ是xxxxxxxx，如果可以的话，希望您加我qq，希望能够想您咨询一些事情，谢谢 ******************************************************************************************************************************* 回答： 没事，你直接在这里问就好了。我很少用QQ的。 =============================================================================================   问： 非常感谢您。数码视讯校招的时候有2个岗位，岗位介绍如下所示 一、嵌入式/C工程师（硕、博为主） 本科及以上学历，理工科相关专业； 具有ARM、DSP等嵌入式软件开发经验，具有良好的C语言基础； 熟悉常用ARM、DSP系统的硬件结构和软件开发方法； 熟悉嵌入式操作系统（如ucos、vxworks、linux），有实际项目开发经验的优先考虑。 二、C++/VC工程师（硕士） 硕士及以上学历，理工科相关专业； 熟悉Windows或Linux开发平台； 熟悉网络和数据库编程，熟悉常用通信协议； 具有 Visual C++ / Win32 SDK / MFC / ATL 实际编程经验者优先。 我想请教您一下，是不是第二个职位主要是从事window是客户端编程的，如果我对linux内核方面比较感兴趣是不是该选择第一个岗位? 还有就是网上对数码视讯的评价好像不太好，对此你怎么看。 如果我是真心想学技术，数码视讯是否是一个好的去处？ 非常感谢 ********************************************************************************************************************************************** 回答： 你好！ 1、第一个职位接触linux的机会肯定大一些，嵌入式系统一般都采用linux，不过第二个职位，将来也有可能，我们这边的服务器也大部分正在转linux操作系统 2、网上的评价不好？呵呵，现在好像比我四年前来时的评价好一些了。我觉得公司制度和环境方面还算正常吧！可能福利会比别的地方差一些，毕竟是私企嘛！ 3、学技术，应该是个好地方。首先这里的老人很愿意帮助新人，你强了，他的负担就轻了；其次，你估计也看了我的博客，一个人要干五六个人的活，活干的多了，提高自然快了（这个我有些夸张了，但是我公司有句名言，什么样的员工是好员工？一个顶三的员工就是好员工，工作强度可见一斑） 我的回答就这些，希望能帮助你！ ============================================================================================================= 问： 非常感谢您的细心指点，让我受益匪浅， 我现在还有点顾虑，如果进入了数码视讯，会不会因为行业比较局限，以后跳槽比较难。 另外您对数字电视行业发展怎么看？ 您觉得贵公司的核心技术是在哪方面？上述2个职位相对来说哪个更核心一点？ 非常感谢您 O(∩_∩)O 年轻人的问题可能比较幼稚，希望您包容 ********************************************************************************************************************************************** 回答： 1、不会，做嵌入式系统，或者linux的，别的行业应该也有较大需求吧！ 2、数字电视行业的发展？你太抬举我了，未来我也说不好，但是数码视讯不止做这一个行业，别的行业也有拓展，我做的就是与广电行业无关。 3、核心技术，我感觉还在广电行业内部吧！我用的很多东西也都是从那边借鉴过来的。 4、我感觉第一个职位吧！呵呵，但我做的就是这个，可能主观因素比较大。你自己考虑吧！ =============================================================================================================    ","title":"数码视讯 答后来者问"},{"content":"一、 前言       每个Linux使用者在安装Linux时都会遇到这样的困境：在为系统分区时，如何精确评估和分配各个硬盘分区的容量，因为系统管理员不但要考虑到当前某个分区需要的容量，还要预见该分区以后可能需要的容量的最大值。因为如果估计不准确，当遇到某个分区不够用时管理员可能甚至要备份整个系统、清除硬盘、重新对硬盘分区，然后恢复数据到新分区。     虽然现在有很多动态调整磁盘的工具可以使用，例如Partation Magic等等，但是它并不能完全解决问题，因为某个分区可能会再次被耗尽；另外一个方面这需要重新引导系统才能实现，对于很多关键的服务器，停机是不可接受的，而且对于添加新硬盘，希望一个能跨越多个硬盘驱动器的文件系统时，分区调整程序就不能解决问题。     因此完美的解决方法应该是在零停机前提下可以自如对文件系统的大小进行调整，可以方便实现文件系统跨越不同磁盘和分区。幸运的是Linux提供的逻辑盘卷管理（LVM，Logical Volume Manager）机制就是一个完美的解决方案。     LVM是逻辑盘卷管理（Logical Volume Manager）的简称，它是Linux环境下对磁盘分区进行管理的一种机制，LVM是建立在硬盘和分区之上的一个逻辑层，来提高磁盘分区管理的灵活性。通过LVM系统管理员可以轻松管理磁盘分区，如：将若干个磁盘分区连接为一个整块的卷组（volume group），形成一个存储池。管理员可以在卷组上随意创建逻辑卷组（logical volumes），并进一步在逻辑卷组上创建文件系统。管理员通过LVM可以方便的调整存储卷组的大小，并且可以对磁盘存储按照组的方式进行命名、管理和分配，例如按照使用用途进行定义：“development”和“sales”，而不是使用物理磁盘名“sda”和“sdb”。而且当系统添加了新的磁盘，通过LVM管理员就不必将磁盘的文件移动到新的磁盘上以充分利用新的存储空间，而是直接扩展文件系统跨越磁盘即可。 二、 LVM基本术语       前面谈到，LVM是在磁盘分区和文件系统之间添加的一个逻辑层，来为文件系统屏蔽下层磁盘分区布局，提供一个抽象的盘卷，在盘卷上建立文件系统。首先我们讨论以下几个LVM术语： 物理存储介质（The physical media） 这里指系统的存储设备：硬盘，如：/dev/hda1、/dev/sda等等，是存储系统最低层的存储单元。 物理卷（physical volume） 物理卷就是指硬盘分区或从逻辑上与磁盘分区具有同样功能的设备(如RAID)，是LVM的基本存储逻辑块，但和基本的物理存储介质（如分区、磁盘等）比较，却包含有与LVM相关的管理参数。 卷组（Volume Group） LVM卷组类似于非LVM系统中的物理硬盘，其由物理卷组成。可以在卷组上创建一个或多个“LVM分区”（逻辑卷），LVM卷组由一个或多个物理卷组成。 逻辑卷（logical volume） LVM的逻辑卷类似于非LVM系统中的硬盘分区，在逻辑卷之上可以建立文件系统(比如/home或者/usr等)。 PE（physical extent） 每一个物理卷被划分为称为PE(Physical Extents)的基本单元，具有唯一编号的PE是可以被LVM寻址的最小单元。PE的大小是可配置的，默认为4MB。 LE（logical extent） 逻辑卷也被划分为被称为LE(Logical Extents) 的可被寻址的基本单位。在同一个卷组中，LE的大小和PE是相同的，并且一一对应。       首先可以看到，物理卷（PV）被由大小等同的基本单元PE组成。     一个卷组由一个或多个物理卷组成，     从上图可以看到，PE和LE有着一一对应的关系。逻辑卷建立在卷组上。逻辑卷就相当于非LVM系统的磁盘分区，可以在其上创建文件系统。     下图是磁盘分区、卷组、逻辑卷和文件系统之间的逻辑关系的示意图：     和非LVM系统将包含分区信息的元数据保存在位于分区的起始位置的分区表中一样，逻辑卷以及卷组相关的元数据也是保存在位于物理卷起始处的VGDA(卷组描述符区域)中。VGDA包括以下内容： PV描述符、VG描述符、LV描述符、和一些PE描述符 。     系统启动LVM时激活VG，并将VGDA加载至内存，来识别LV的实际物理存储位置。当系统进行I/O操作时，就会根据VGDA建立的映射机制来访问实际的物理位置。 三、 安装LVM       首先确定系统中是否安装了lvm工具：     [root@www root]# rpm –qa|grep lvm     lvm-1.0.3-4     如果命令结果输入类似于上例，那么说明系统已经安装了LVM管理工具；如果命令没有输出则说明没有安装LVM管理工具，则需要从网络下载或者从光盘装LVM rpm工具包。     安装了LVM的RPM软件包以后，要使用LVM还需要配置内核支持LVM。RedHat默认内核是支持LVM的，如果需要重新编译内核，则需要在配置内核时，进入Multi-device Support (RAID and LVM)子菜单，选中以下两个选项：   Multiple devices driver support (RAID and LVM) 　　<*> Logical volume manager (LVM) Support     然后重新编译内核，即可将LVM的支持添加到新内核中。     为了使用LVM，要确保在系统启动时激活LVM，幸运的是在RedHat7.0以后的版本，系统启动脚本已经具有对激活LVM的支持，在/etc/rc.d/rc.sysinit中有以下内容： # LVM initialization if [ -e /proc/lvm -a -x /sbin/vgchange -a -f /etc/lvmtab ]; then action  $\"Setting up Logical Volume Management:\" /sbin/vgscan && /sbin/vgchange -a y fi     其中关键是两个命令，vgscan命令实现扫描所有磁盘得到卷组信息，并创建文件卷组数据文件/etc/lvmtab和/etc/lvmtab.d/*；vgchange -a y命令激活系统所有卷组。 四、 创建和管理LVM 要创建一个LVM系统，一般需要经过以下步骤： 1、 创建分区     使用分区工具（如：fdisk等）创建LVM分区，方法和创建其他一般分区的方式是一样的，区别仅仅是LVM的分区类型为8e。 2、 创建物理卷     创建物理卷的命令为pvcreate，利用该命令将希望添加到卷组的所有分区或者磁盘创建为物理卷。将整个磁盘创建为物理卷的命令为： # pvcreate /dev/hdb     将单个分区创建为物理卷的命令为：         # pvcreate /dev/hda5 3、 创建卷组     创建卷组的命令为vgcreate，将使用pvcreate建立的物理卷创建为一个完整的卷组：         # vgcreate web_document /dev/hda5 /dev/hdb     vgcreate命令第一个参数是指定该卷组的逻辑名：web_document。后面参数是指定希望添加到该卷组的所有分区和磁盘。vgcreate在创建卷组 web_document 以外，还设置使用大小为4 MB的PE（默认为4MB），这表示卷组上创建的所有逻辑卷都以 4 MB 为增量单位来进行扩充或缩减。由于内核原因，PE大小决定了逻辑卷的最大大小，4 MB 的PE决定了单个逻辑卷最大容量为 256 GB，若希望使用大于256G的逻辑卷则创建卷组时指定更大的PE。PE大小范围为8 KB 到 512 MB，并且必须总是 2 的倍数（使用-s指定，具体请参考man vgcreate）。 4、 激活卷组     为了立即使用卷组而不是重新启动系统，可以使用vgchange来激活卷组：         # vgchange -a y web_document 5、 添加新的物理卷到卷组中     当系统安装了新的磁盘并创建了新的物理卷，而要将其添加到已有卷组时，就需要使用vgextend命令：         # vgextend web_document /dev/hdc1     这里/dev/hdc1是新的物理卷。 6、 从卷组中删除一个物理卷     要从一个卷组中删除一个物理卷，首先要确认要删除的物理卷没有被任何逻辑卷正在使用，就要使用pvdisplay命令察看一个该物理卷信息：     如果某个物理卷正在被逻辑卷所使用，就需要将该物理卷的数据备份到其他地方，然后再删除。删除物理卷的命令为vgreduce：         # vgreduce web_document /dev/hda1 7、 创建逻辑卷     创建逻辑卷的命令为lvcreate：         # lvcreate -L1500 –nwww1 web_document     该命令就在卷组web_document上创建名字为www1，大小为1500M的逻辑卷，并且设备入口为/dev/web_document/www1 （web_document为卷组名，www1为逻辑卷名）。如果希望创建一个使用全部卷组的逻辑卷，则需要首先察看该卷组的PE数，然后在创建逻辑卷时指定： # vgdisplay web_document| grep \"Total PE\" Total PE 45230 # lvcreate -l 45230 web_document -n www1 8、 创建文件系统     笔者推荐使用reiserfs文件系统，来替代ext2和ext3：     创建了文件系统以后，就可以加载并使用它： # mkdir /data/wwwroot # mount /dev/web_document/www1 /data/wwwroot 如果希望系统启动时自动加载文件系统，则还需要在/etc/fstab中添加内容： /dev/web_document/www1 /data/wwwroot reiserfs defaults 1 2 9、 删除一个逻辑卷 删除逻辑卷以前首先需要将其卸载，然后删除： # umount /dev/web_document/www1 # lvremove /dev/web_document/www1 lvremove -- do you really want to remove \"/dev/web_document/www1\"? [y/n]: y lvremove -- doing automatic backup of volume group \"web_document\" lvremove -- logical volume \"/dev/web_document/www1\" successfully removed 10、 扩展逻辑卷大小 LVM提供了方便调整逻辑卷大小的能力，扩展逻辑卷大小的命令是lvcreate： # lvextend -L12G /dev/web_document/www1 lvextend -- extending logical volume \"/dev/web_document/www1\" to 12 GB lvextend -- doing automatic backup of volume group \"web_document \" lvextend -- logical volume \"/dev/web_document/www1\" successfully extended 上面的命令就实现将逻辑卷www1的大小扩招为12G。 # lvextend -L+1G /dev/web_document/www1 lvextend -- extending logical volume \"/dev/web_document/www1\" to 13 GB lvextend -- doing automatic backup of volume group \"web_document \" lvextend -- logical volume \"/dev/web_document/www1\" successfully extended 上面的命令就实现将逻辑卷www1的大小增加1G。     增加了逻辑卷的容量以后，就需要修改文件系统大小以实现利用扩充的空间。笔者推荐使用reiserfs文件系统来替代ext2或者ext3。因此这里仅仅讨论reiserfs的情况。Reiserfs文件工具提供了文件系统大小调整工具：resize_reiserfs。对于希望调整被加载的文件系统大小：     # resize_reiserfs -f /dev/web_document/www1     一般建议最好将文件系统卸载，调整大小，然后再加载： # umount /dev/web_document/www1 # resize_reiserfs /dev/web_document/www1 # mount -treiserfs /dev/web_document/www1 /data/wwwroot 对于使用ext2或ext3文件系统的用户可以考虑使用工具      ext2resize。http://sourceforge.net/projects/ext2resize 11、 减少逻辑卷大小 使用lvreduce即可实现对逻辑卷的容量，同样需要首先将文件系统卸载： # umount /data/wwwroot # resize_reiserfs -s-2G /dev/web_document/www1 # lvreduce -L-2G /dev/web_document/www1 # mount -treiserfs /dev/web_document/www1 /data/wwwroot 五、 总结     根据上面的讨论可以看到，LVM具有很好的可伸缩性，使用起来非常方便。可以方便地对卷组、逻辑卷的大小进行调整，更进一步调整文件系统的大小。如果希望了解更多信息，请参考LVM-HOWTO。","title":"Linux逻辑盘卷管理LVM详解"},{"content":"嵌入式qq讨论区 为linux内核添加新的系统调用 开发平台：x86 ubuntu 目标平台：S3C6410      linux3.4.4 一、    打开内核源码目录下arch/arm/kernel/calls.S文件，在389行添加：     /* 378 */       CALL(sys_my_syscall) 378是新添加的系统调用的系统调用号，sys_my_syscall是该系调用的名字 二、打开内核源码目录下arch/arm/include/asm/unistd.h文件，在407行添加：     #define __NR_my_syscall           (__NR_SYSCALL_BASE+378) my_syscall是新系统调用的名字，378是系统调用号 三、打开内核源码目录下arch/arm/kernel/sys_arm.c文件，在最后添加：     asmlinkage long sys_my_syscall(int a, int b)    {         return a + b;    } 这个就是系统调用的实现，在这里简单的写一个加法为例 四、重新编译内核，启动内核并挂在网络文件系统，挂在成功后：     [lzy@uplooking]# 五、在用户态测试新添加的系统调用my_syscall     #include <stdio.h> int main(int argc, char *argv[]) {         int add;         add = syscall(378, 1, 2);         printf(\"add = %d\\n\", add);         return 0; } 其中387是新添加的系统调用的系统调用号 编译并把可执行文件拷贝到/nfsroot，/nfsroot是开发板的根目录 lizhiyong@ThinkPad:/home/test$ arm-linux-gcc my_syscall.c -o my_syscall lizhiyong@ThinkPad:/home/test$ cp my_syscall /nfsroot 在开发板上执行my_syscall，运行结果如下：     [lzy@uplooking]# ./my_syscall     add=3","title":"为arm linux内核添加新的系统调用"},{"content":"版权声明：此文档为个人原创文档，转载请注明出处，请勿摘抄。 2012年已经接近尾声了，公司也得要交年终总结了，发现自己好久没有更新自己的博客，借此机会发表一下2012年的工作总结，此总结只是个人对于2012年度的工作心得。         一年的工作下来，我从事的嵌入式软件方面的工作也过了有1年半了，期间虽然换过工作，但是我的工作方向一直未变，希望在此行业的大牛们，牛嫂们能给些建议，让我在以后的工作中多多收益。        首先，我谈谈我对工作的认识：        工作是为自己实现最初目标和提升人生阅历以及为企业创造利润和商业价格，有人把合同称为“卖身契”，其实想想工作是双方受益的，不仅仅是公司，个人也可以从工作中得到很多阅历和长进。所以我觉得工作是人生中不可或缺的一段历程，可以让我们为这个社会贡献出一份力量（说得有些过了，小时候应该说得多），其实啊，真正做贡献最多的还是普通的老百姓，如果没有我们这些人，那些当官的有那么多表吗？有那么多干女儿吗？有那么多艳照吗？（这个也说过了，政治在技术论坛是个忌讳）。        再谈谈嵌入式软件方面的心得：       嵌入式软件，定义我就不说了，太广泛了，我又不是写书的，没必要去背书，来点项目中最实际的。        说说嵌入式的前景,当你还在沉溺于强大windows的开发时，还是在做目前程序员最多的JAVA开发时，那么就别看这个了，因为术业有专攻，每个行业做到顶尖了都是专家级别了。我针对的是目前还在徘徊选择的人，嵌入式行业是目前来说，培训机构的主打项目，为什么了？因为高校基本上很少有学校开这个专业，我算走运，专业是这个方向。市场需求激增，就业形势和待遇当然是很可观的，记得我上半年在深圳的时候，那边可是很多公司都缺这样的人。所以啊，前景我非常看好，而且现在市面上基本上的电子产品可以说都是嵌入式的。       说了前景就得说说准备工作了。       C语言很重要，为什么呢？我做的项目中都是基于C语言开发的，特别是底层，全是C代码，不过这个C是嵌入式C，51单片机，在学校的时候最多，目前市面上也有很多公司采用这个单片机做项目。目前嵌入式里面我做过51开发，stm32开发，arm+linux开发（海思的DVR项目），感觉C语言很重要，汇编其实也要会，但是现在的开发基本上都是基于C，u-boot有一段是必须用汇编的，因为啊，那个是bootloader,得为C的运行提供环境。C语言的学习远远不只在学校里面学的皮毛，自己得好好学习，特别学习指针的操作。推荐的书有《C和指针》，《C专家编程》，《C陷阱和缺陷》等。这三本书也是我今年好好的看了的，之前在学校完全没用心看。感谢经理买的这三本书。       arm架构的认识，在学校的时候开了一个《嵌入式系统原理及应用》的课程，我也是花了心思的学了，那本书主要是以ARM7平台讲了ARM的架构的软件设计和其硬件的相关知识，虽然《微机原理》和《51单片机设计》对处理器的架构有所介绍，但是我觉得还是有很多地方是不同的。上半年做了stm32的开发，基于驱动的开发，得对芯片的内部结构要了解，不过啊，一般都会有datasheet给你，你要是没有认识，估计看都难看懂。       linux要熟悉，现在很多的产品都上了操作系统，虽然之前有玩过stm32的uc/os，但是和linux比较起来还是不是一回事的。linux C必须得会，我8月份开始就开发华为海思的DVR方案，做视频监控的开发，开发板为hi3515，运行的是linux操作系统，就是基于linux平台的应用开发（目前嵌入式里面此类项目开发较多）。到现在产品才基本成型，我一个人做这个视频监控的项目确实也是摸着石头过河，尽管我在梦网的时候从事过视频监控终端机的研发，和从事过mips的视频监控客户端的研发，但是都是基于团队的，这次是一个人做。不过得感谢我的经理，人家的知识确实很扎实，很多问题都问过他。       wince平台，现在嵌入式系统军工和一些可靠性非常强强的都是采用PowerPC+VxWorks，一般工业和民用级的基本上是采用ARM+LINUX,ARM+WINCE，不过也不一定是ARM，我上半年就接触过MIPS+LINUX的。不过一般芯片厂商都会把相关的底层驱动给你，一般公司节约开发成本和时间都是采用做应用开发。wince平台我的项目还没做完，目前只是用C#实现了前期的搭建。       好了，相关嵌入式软件方面的心得就像是抛砖引玉一样，很多都得自己去体会。      今年的年终总结感觉就是浮躁过，学习过，成长过，收获过。现在我正准备考一个嵌入式系统设计师的软考证，之前在学校没有去考，现在准备把补上，虽然都是些原理性的考试（上午题），但是下午题确实还是项目中遇到的，看了下，希望自己能过。        最后，祝大家完胜2012，冀望2013。      ","title":"年终总结"},{"content":"Linux提供了内存映射函数mmap, 它把文件内容映射到一段内存上(准确说是虚拟内存上), 通过对这段内存的读取和修改, 实现对文件的读取和修改, 先来看一下mmap的函数声明: 一、头文件:  #include <unistd.h>  #include <sys/mman.h> 二、原型: void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offsize); 三、返回值: 成功则返回映射区起始地址, 失败则返回MAP_FAILED(-1). 四、参数:  addr: 指定映射的起始地址, 通常设为NULL, 由系统指定.  length: 将文件的多大长度映射到内存.  prot: 映射区的保护方式, 可以是:   PROT_EXEC: 映射区可被执行.   PROT_READ: 映射区可被读取.   PROT_WRITE: 映射区可被写入.   PROT_NONE: 映射区不能存取.  flags: 映射区的特性, 可以是:   MAP_SHARED: 对映射区域的写入数据会复制回文件, 且允许其他映射该文件的进程共享.   MAP_PRIVATE: 对映射区域的写入操作会产生一个映射的复制(copy-on-write), 对此区域所做的修改不会写回原文件.   此外还有其他几个flags不很常用, 具体查看linux C函数说明.  fd: 由open返回的文件描述符, 代表要映射的文件.  offset: 以文件开始处的偏移量, 必须是分页大小的整数倍, 通常为0, 表示从文件头开始映射. 五、下面说一下内存映射的步骤:  用open系统调用打开文件, 并返回描述符fd.  用mmap建立内存映射, 并返回映射首地址指针start.  对映射(文件)进行各种操作, 显示(printf), 修改(sprintf).  用munmap(void *start, size_t lenght)关闭内存映射.  用close系统调用关闭文件fd. 六、注意事项: 在修改映射的文件时, 只能在原长度上修改, 不能增加文件长度, 因为内存是已经分配好的. 七、简单例子(没有对文件进行操作)   1 #include <fcntl.h>   2 #include <sys/mman.h>   3 #include <errno.h>   4   5 #define MAP_LENGTH      (10*1024*1024)   6   7 int main(void){   8 >--->---int fd;   9 >--->---void * addr;  10  11 >--->---/* create a file in hugetlb fs */  12 >--->---fd = open(\"/home/shell/aa.txt\", O_CREAT | O_RDWR);  13 >--->---if(fd < 0){  14 >--->--->--->---perror(\"Err: \");  15 >--->--->--->---return -1;  16 >--->---}  17  18 >--->---/* map the file into address space of current application process */  19 >--->---addr = mmap(0, MAP_LENGTH, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);  20 >--->---if(addr == MAP_FAILED){  21 >--->--->--->---perror(\"Err: \");  22 >--->--->--->---close(fd);  23 >--->--->--->---unlink(\"/home/shell/aa.txt\");  24 >--->--->--->---return -1;  25 >--->---}  26  27 >--->---/* from now on, you can store application data on huage pages via addr */  28  29 >--->---munmap(addr, MAP_LENGTH);  30 >--->---close(fd);  31 >--->---unlink(\"/home/shell/aa.txt\");  32 >--->---return 0;  33 }","title":"linux内存映射函数 mmap"},{"content":"Linux的函数库提供有两种消息队列，一种是POSIX消息队列，另一种是SYS V消息队列。这里介绍POSIX消息队列。 涉及到的函数主要有： mq_open() - 创建消息队列 mq_close() - 关闭消息队列 mq_send() - 往消息队列里发送消息 mq_receive() - 从消息队列里接受消息 消息队列实际上是一个文件，因此需要消息队列虚拟文件系统的支持。通常系统启动时，在/dev目录下，会有一个/mqueue目录来暂存所有的消息队列。如果没有这个目录，就需要先挂载。 # mkdir /dev/mqueue# mount -t mqueue none /dev/mqueue 打开和关闭消息队列的操作和打开关闭普通文件的操作几乎一样。而发送接收也和普通文件的读写操作十分相似。 mqd_t mq_open(const char *name, int oflag);mqd_t mq_open(const char *name, int oflag, mode_t mode,                     struct mq_attr *attr);打开操作有两个形式，通常使用第二种形式的打开函数。因为它有更多的可选参数，可以控制文件的打开方式和读写权限。参数中，name是文件的路径，根据mq_overview的man page所说，它的形式必须是/somename（以斜线开头），这里的somename也是最终在/dev/mqueue中可以看见的消息队列的文件名。第二个参数oflag是打开方式，只读、只写、读写等方式，与open的参数相同。第三个是mode是文件的权限（755、777等），也是和open相同的。最后一个参数attr是消息队列的参数。执行成功，返回已打开的消息队列的描述符。 int mq_send(mqd_t mqdes, const char *msg_ptr,                     size_t msg_len, unsigned msg_prio);mq_send()用于写一条消息到消息队列。第一个参数mqdes是消息队列的描述符，也就是mq_open()函数的返回值。第二个msg_ptr是要发送的消息的指针。第三个msg_len是要发送的消息的长度。第四个msg_prio是消息的优先级，优先级按降序排列，数字越大优先级越高。 ssize_t mq_receive(mqd_t mqdes, char *msg_ptr,                          size_t msg_len, unsigned *msg_prio);mq_receive()用于从消息队列读取一条消息。第一个参数mqdes是消息队列的描述符。第二个msg_ptr是接收消息的缓冲区。第三个msg_len是要接收的消息的长度。第四个msg_prio是消息的优先级。 发送端： /× server.c */#include <stdio.h>#include <fcntl.h>           /* For O_* constants */#include <sys/stat.h>        /* For mode constants */#include <mqueue.h>#include <string.h>#include <errno.h>#define PATHNAME \"/msg_test\"#define PRIOLOW 1#define PRIOHIGH 2int main(){\tmqd_t mqd;\tchar name[24] = \"/msg_test\";\tchar data[24] = \"Hello World!\";\tchar data_new[32] = \"Hello World, again!\";\tstruct mq_attr attr;\tattr.mq_msgsize = strlen(data);\tmqd = mq_open(name, O_RDWR | O_CREAT, \t\t\tS_IRUSR | S_IWUSR | S_IRGRP | S_IROTH, NULL);\tif (mqd == -1) {\t\tprintf(\"errno: %d\\n\", errno);\t\tperror(\"open failed!!!: \");\t\treturn 0;\t}\tmq_send(mqd, name, strlen(name), PRIOLOW);\tmq_send(mqd, data, strlen(data), PRIOHIGH);\tmq_send(mqd, data_new, strlen(data_new), PRIOHIGH);\tmq_close(mqd);\treturn 0;} 接收端： /* client.c */#include <stdio.h>#include <fcntl.h>           /* For O_* constants */#include <sys/stat.h>        /* For mode constants */#include <mqueue.h>#include <string.h>#define PATHNAME \"/msg_test\"#define PRIO 1int main(){\tmqd_t mqd;\tchar name[24] = \"/msg_test\";\tstruct mq_attr attr;\tchar data[32];\tint prio;\tint len;\tmqd = mq_open(name, O_RDONLY, \t\t\tS_IRUSR | S_IWUSR | S_IRGRP | S_IROTH, NULL);\tmq_getattr(mqd, &attr);\tif (mqd == -1) {\t\tprintf(\"open failed!!!\\n\");\t\treturn 0;\t}\tlen = mq_receive(mqd, data, attr.mq_msgsize, &prio);\tdata[len] = '\\0';\tmq_close(mqd);\tprintf(\"msg: %s, msg_len: %d, prio: %d\\n\", data, attr.mq_msgsize, prio);\treturn 0;} 执行结果： $ gcc -g -o server server.c -lrt$ gcc -g -o client client.c -lrt$ ./server$ cat /dev/mqueue/msg_testQSIZE:112        NOTIFY:0     SIGNO:0     NOTIFY_PID:0$ ./clientmsg: Hello World!, msg_len: 8192, prio: 2$ ./clientmsg: Hello World, again!, msg_len: 8192, prio: 2$ ./clientmsg: /msg_test, msg_len: 8192, prio: 1$ cat /dev/mqueue/msg_testQSIZE:24         NOTIFY:0     SIGNO:0     NOTIFY_PID:0","title":"POSIX消息队列 发送接收简单子"},{"content":"前两天有个同事问起怎么递归删除目录下所有指定的文件？执行下列命令即可： find -name '.svn' | xargs -i rm -rf {}'.svn' 换成你要删除的文件即可，很简单。","title":"清理 svn 文件"},{"content":"tr用来从标准输入中通过替换或删除操作，进行字符转换。tr主要用于删除文件中控制字符或进行字符转换。使用tr时要转换两个字符串：字符串1用于查询，字符串2用于处理各种转换tr刚执行时，字符串1中的字符被映射到字符串2中的字符，然后转换操作开始。 1、用法和选项 用法： tr [选项]... SET1 [SET2] 说明： tr命令用于从标准输入中替换、缩减或删除字符，并将结果写到标准输出。 选项：  -c, -C, --complement          用SET1的补集 -d, --delete                    删除匹配SET1 的内容，并不作替换 -s, --squeeze-repeats   如果匹配于SET1 的字符在输入序列中存在连续的重复，在替换时会被统一缩为一个字符的长度 -t, --truncate-set1       先将SET1 的长度截为和SET2 相等 --help                            显示此帮助信息并退出 --version                       显示版本信息并退出 2、SET字符串 SET 是一组字符串，一般都可按照字面含义理解。解析序列如下： \\NNN          #八进制值为NNN 的字符(1 至3 个数位)   \\\\            #反斜杠    \\a            #终端鸣响    \\b            #退格    \\f            #换页    \\n            #换行    \\r            #回车    \\t            #水平制表符    \\v            #垂直制表符    字符1-字符2    #从字符1 到字符2 的升序递增过程中经历的所有字符    [字符*]       #在SET2 中适用，指定字符会被连续复制直到吻合设置1 的长度   [字符*次数]    #对字符执行指定次数的复制，若次数以 0 开头则被视为八进制数   [:alnum:]     #所有的字母和数字    [:alpha:]     #所有的字母    [:blank:]     #所有呈水平排列的空白字符    [:cntrl:]     #所有的控制字符    [:digit:]     #所有的数字    [:graph:]     #所有的可打印字符，不包括空格    [:lower:]     #所有的小写字母    [:print:]     #所有的可打印字符，包括空格   [:punct:]     #所有的标点字符    [:space:]     #所有呈水平或垂直排列的空白字符    [:upper:]     #所有的大写字母    [:xdigit:]    #所有的十六进制数    [=字符=]       #所有和指定字符相等的字符   注意： 1、仅在SET1 和SET2 都给出，同时没有-d 选项的时候才会进行替换。 2、仅在替换时才可能用到-t 选项。如果需要SET2 将被通过在末尾添加原来的末字符的方式补充到同SET1 等长。SET2 中多余的字符将被省略。 3、只有[:lower:] 和[:upper:]以升序展开字符；在用于替换时的SET2 中以成对表示大小写转换。 4、-s 作用于SET1，既不替换也不删除，否则在替换或展开后使用SET2 缩减。 3、示例 （1）删除空行 [root@RHEL6 ~]# tr -s \"[\\012]\" < plan.txt 或 tr -s [\"\\n\"] < plan.txt （2）去除test.txt里面的重复的小写字符 [root@RHEL6 ~]# tr -s \"[a-z]\"<test.txt >result.txt （3）有时需要删除文件中的^M，并代之以换行 [root@RHEL6 ~]# tr -s \"[\\015]\" \"[\\n]\" < file 或 [root@RHEL6 ~]# tr -s \"[\\r]\" \"[\\n]\" < file （4）大写到小写 [root@RHEL6 ~]# cat a.txt |tr \"[a-z]\" \"[A-Z]\" >b.txt （5）删除指定字符 一个星期的日程表任务是从其中删除所有数字，只保留日期日期有大写，也有小写格式因此需指定两个字符范围[a-z]和[A-Z]，命令tr -cs \"[a-z][A-Z]\" \"[\\012*]\" 将文件每行所有不包含在[a-z]或[A-Z]（所有希腊字母）的字符串放在字符串1中并转换为一新行-s选项表明压缩所有新行， -c表明保留所有字母不动原文件如下，后跟tr命令： [root@RHEL6 ~]# tr -cs \"[a-z][A-Z]\" \"[\\012*]\" <diary.txt （6）替换passwd文件中所有冒号，代之以tab键，可以增加可读性 [root@RHEL6 ~]# tr -s \"[:]\" \"[\\011]\" < /etc/passwd 或 [root@RHEL6 ~]# tr -s \"[:]\" \"[\\t]\" < /etc/passwd （7）使路径具有可读性 如果用 echo $PATH 或者 echo $LD_LIBRARY_PATH 等类似的命令来显示路径信息的话，我们看到的将会是一大堆用冒号连接在一起的路径， tr命令可以把这些冒号转换为回车，这样，这些路径就具有很好的可读性了 [root@RHEL6 ~]# echo $PATH | tr \":\" \"\\n\" （8）可以在vim内使用所有这些命令！在tr命令前要加上您希望处理的行范围和感叹号 （！），如 $!tr -d '\\t'（美元符号表示最后一行） （9）转换控制字符 tr的第一个功能就是转换控制字符，特别是从dos向UNIX下载文件时，忘记设置ftp关于回车换行转换的选项时更是如此cat -v filename 显示控制字符 [root@RHEL6 ~]# cat -v Lstat.txtbox aa^^^^^12^Mapple bbas^^^^23^M^Z 猜想^ ^ ^ ^ ^ ^是tab键每一行以Ctrl-M结尾，文件结尾Ctrl-Z，以下是改动方法 使用-s选项，查看ASCII表^的八进制代码是136，^M是015，tab键是011，^Z是032 ,下面将按步骤完成最终功能 用tab键替换^ ^ ^ ^ ^ ^，命令为\"\\136\" \"[\\011*]\"将结果重定向到临时工作文件Lstat.tmp [root@RHEL6 ~]# tr -s \"[\\136]\" \"[\\011*]\" <stat.txt >Lstat.tmp 用新行替换每行末尾的^M，并用\\n去除^Z，输入要来自于临时工作文件Lstat.tmp [root@RHEL6 ~]# tr -s \"[\\015][\\032]\" \"\\n\" <Lstat.tmp 要删除所有的tab键，代之以空格，使用命令 [root@RHEL6 ~]# tr -s \"[\\011]\" \"[\\040*]\" <input.txt   以上的示例都可以通过sed 来完成。 来自：http://www.lampbo.org/linux-xuexi/linux-base/linux-shell-tr-command-replace-string.html","title":"Linux shell: tr"},{"content":"转载出处：http://www.cnblogs.com/51linux/archive/2012/05/23/2515299.html linux sort 命令详解 sort是在Linux里非常常用的一个命令，管排序的，集中精力，五分钟搞定sort，现在开始！ 1 sort的工作原理   sort将文件的每一行作为一个单位，相互比较，比较原则是从首字符向后，依次按ASCII码值进行比较，最后将他们按升序输出。 [rocrocket@rocrocket programming]$ cat seq.txt banana apple pear orange [rocrocket@rocrocket programming]$ sort seq.txt apple banana orange pear 2 sort的-u选项 它的作用很简单，就是在输出行中去除重复行。 [rocrocket@rocrocket programming]$ cat seq.txt banana apple pear orange pear [rocrocket@rocrocket programming]$ sort seq.txt apple banana orange pear pear [rocrocket@rocrocket programming]$ sort -u seq.txt apple banana orange pear pear由于重复被-u选项无情的删除了。 3 sort的-r选项 sort默认的排序方式是升序，如果想改成降序，就加个-r就搞定了。 [rocrocket@rocrocket programming]$ cat number.txt 1 3 5 2 4 [rocrocket@rocrocket programming]$ sort number.txt 1 2 3 4 5 [rocrocket@rocrocket programming]$ sort -r number.txt 5 4 3 2 1 4 sort的-o选项 由于sort默认是把结果输出到标准输出，所以需要用重定向才能将结果写入文件，形如sort filename > newfile。 但是，如果你想把排序结果输出到原文件中，用重定向可就不行了。 [rocrocket@rocrocket programming]$ sort -r number.txt > number.txt [rocrocket@rocrocket programming]$ cat number.txt [rocrocket@rocrocket programming]$ 看，竟然将number清空了。 就在这个时候，-o选项出现了，它成功的解决了这个问题，让你放心的将结果写入原文件。这或许也是-o比重定向的唯一优势所在。 [rocrocket@rocrocket programming]$ cat number.txt 1 3 5 2 4 [rocrocket@rocrocket programming]$ sort -r number.txt -o number.txt [rocrocket@rocrocket programming]$ cat number.txt 5 4 3 2 1 5 sort的-n选项 你有没有遇到过10比2小的情况。我反正遇到过。出现这种情况是由于排序程序将这些数字按字符来排序了，排序程序会先比较1和2，显然1小，所以就将10放在2前面喽。这也是sort的一贯作风。 我们如果想改变这种现状，就要使用-n选项，来告诉sort，“要以数值来排序”！ [rocrocket@rocrocket programming]$ cat number.txt 1 10 19 11 2 5 [rocrocket@rocrocket programming]$ sort number.txt 1 10 11 19 2 5 [rocrocket@rocrocket programming]$ sort -n number.txt 1 2 5 10 11 19 6 sort的-t选项和-k选项 如果有一个文件的内容是这样： [rocrocket@rocrocket programming]$ cat facebook.txt banana:30:5.5 apple:10:2.5 pear:90:2.3 orange:20:3.4 这个文件有三列，列与列之间用冒号隔开了，第一列表示水果类型，第二列表示水果数量，第三列表示水果价格。 那么我想以水果数量来排序，也就是以第二列来排序，如何利用sort实现？ 幸好，sort提供了-t选项，后面可以设定间隔符。（是不是想起了cut和paste的-d选项，共鸣～～） 指定了间隔符之后，就可以用-k来指定列数了。 [rocrocket@rocrocket programming]$ sort -n -k 2 -t : facebook.txt apple:10:2.5 orange:20:3.4 banana:30:5.5 pear:90:2.3 我们使用冒号作为间隔符，并针对第二列来进行数值升序排序，结果很令人满意。 7 其他的sort常用选项 -f会将小写字母都转换为大写字母来进行比较，亦即忽略大小写 -c会检查文件是否已排好序，如果乱序，则输出第一个乱序的行的相关信息，最后返回1 -C会检查文件是否已排好序，如果乱序，不输出内容，仅返回1 -M会以月份来排序，比如JAN小于FEB等等 -b会忽略每一行前面的所有空白部分，从第一个可见字符开始比较。 有时候学习脚本，你会发现sort命令后面跟了一堆类似-k1,2，或者-k1.2 -k3.4的东东，有些匪夷所思。今天，我们就来搞定它—-k选项！ 1 准备素材 $ cat facebook.txt google 110 5000 baidu 100 5000 guge 50 3000 sohu 100 4500   第一个域是公司名称，第二个域是公司人数，第三个域是员工平均工资。（除了公司名称，其他的别信，都瞎写的^_^） 2 我想让这个文件按公司的字母顺序排序，也就是按第一个域进行排序：（这个facebook.txt文件有三个域） $ sort -t ‘ ‘ -k 1 facebook.txt baidu 100 5000 google 110 5000 guge 50 3000 sohu 100 4500 看到了吧，就直接用-k 1设定就可以了。（其实此处并不严格，稍后你就会知道） 3 我想让facebook.txt按照公司人数排序 $ sort -n -t ‘ ‘ -k 2 facebook.txt guge 50 3000 baidu 100 5000 sohu 100 4500 google 110 5000 不用解释，我相信你能懂。 但是，此处出现了问题，那就是baidu和sohu的公司人数相同，都是100人，这个时候怎么办呢？按照默认规矩，是从第一个域开始进行升序排序，因此baidu排在了sohu前面。 4  我想让facebook.txt按照公司人数排序 ，人数相同的按照员工平均工资升序排序： $ sort -n -t ‘ ‘ -k 2 -k 3 facebook.txt guge 50 3000 sohu 100 4500 baidu 100 5000 google 110 5000 看，我们加了一个-k2 -k3就解决了问题。对滴，sort支持这种设定，就是说设定域排序的优先级，先以第2个域进行排序，如果相同，再以第3个域进行排序。（如果你愿意，可以一直这么写下去，设定很多个排序优先级） 5 我想让facebook.txt按照员工工资降序排序，如果员工人数相同的，则按照公司人数升序排序：（这个有点难度喽） $ sort -n -t ‘ ‘ -k 3r -k 2 facebook.txt baidu 100 5000 google 110 5000 sohu 100 4500 guge 50 3000 此处有使用了一些小技巧，你仔细看看，在-k 3后面偷偷加上了一个小写字母r。你想想，再结合我们上一篇文章，能得到答案么？揭晓：r和-r选项的作用是一样的，就是表示逆序。因为sort默认是按照升序排序的，所以此处需要加上r表示第三个域（员工平均工资）是按照降序排序。此处你还可以加上n，就表示对这个域进行排序时，要按照数值大小进行排序，举个例子吧： $ sort -t ‘ ‘ -k 3nr -k 2n facebook.txt baidu 100 5000 google 110 5000 sohu 100 4500 guge 50 3000 看，我们去掉了最前面的-n选项，而是将它加入到了每一个-k选项中了。 6 -k选项的具体语法格式 要继续往下深入的话，就不得不来点理论知识。你需要了解-k选项的语法格式，如下： [ FStart [ .CStart ] ] [ Modifier ] [ , [ FEnd [ .CEnd ] ][ Modifier ] ] 这个语法格式可以被其中的逗号（“，”）分为两大部分，Start部分和End部分。 先给你灌输一个思想，那就是“如果不设定End部分，那么就认为End被设定为行尾”。这个概念很重要的，但往往你不会重视它。 Start部分也由三部分组成，其中的Modifier部分就是我们之前说过的类似n和r的选项部分。我们重点说说Start部分的FStart和C.Start。 C.Start也是可以省略的，省略的话就表示从本域的开头部分开始。之前例子中的-k 2和-k 3就是省略了C.Start的例子喽。 FStart.CStart，其中FStart就是表示使用的域，而CStart则表示在FStart域中从第几个字符开始算“排序首字符”。 同理，在End部分中，你可以设定FEnd.CEnd，如果你省略.CEnd，则表示结尾到“域尾”，即本域的最后一个字符。或者，如果你将CEnd设定为0(零)，也是表示结尾到“域尾”。 7 突发奇想，从公司英文名称的第二个字母开始进行排序： $ sort -t ‘ ‘ -k 1.2 facebook.txt baidu 100 5000 sohu 100 4500 google 110 5000 guge 50 3000 看，我们使用了-k 1.2，这就表示对第一个域的第二个字符开始到本域的最后一个字符为止的字符串进行排序。你会发现baidu因为第二个字母是a而名列榜首。sohu和 google第二个字符都是o，但sohu的h在google的o前面，所以两者分别排在第二和第三。guge只能屈居第四了。 8 又突发奇想，，只针对公司英文名称的第二个字母进行排序，如果相同的按照员工工资进行降序排序： $ sort -t ‘ ‘ -k 1.2,1.2 -k 3,3nr facebook.txt baidu 100 5000 google 110 5000 sohu 100 4500 guge 50 3000 由于只对第二个字母进行排序，所以我们使用了-k 1.2,1.2的表示方式，表示我们“只”对第二个字母进行排序。（如果你问“我使用-k 1.2怎么不行？”，当然不行，因为你省略了End部分，这就意味着你将对从第二个字母起到本域最后一个字符为止的字符串进行排序）。对于员工工资进行排 序，我们也使用了-k 3,3，这是最准确的表述，表示我们“只”对本域进行排序，因为如果你省略了后面的3，就变成了我们“对第3个域开始到最后一个域位置的内容进行排序” 了。 9 在modifier部分还可以用到哪些选项？ 可以用到b、d、f、i、n 或 r。 其中n和r你肯定已经很熟悉了。 b表示忽略本域的签到空白符号。 d表示对本域按照字典顺序排序（即，只考虑空白和字母）。 f表示对本域忽略大小写进行排序。 i表示忽略“不可打印字符”，只针对可打印字符进行排序。（有些ASCII就是不可打印字符，比如\\a是报警，\\b是退格，\\n是换行，\\r是回车等等） 10 思考思考关于-k和-u联合使用的例子： $ cat facebook.txt google 110 5000 baidu 100 5000 guge 50 3000 sohu 100 4500 这是最原始的facebook.txt文件。 $ sort -n -k 2 facebook.txt guge 50 3000 baidu 100 5000 sohu 100 4500 google 110 5000 $ sort -n -k 2 -u facebook.txt guge 50 3000 baidu 100 5000 google 110 5000 当设定以公司员工域进行数值排序，然后加-u后，sohu一行就被删除了！原来-u只识别用-k设定的域，发现相同，就将后续相同的行都删除。 $ sort  -k 1 -u facebook.txt baidu 100 5000 google 110 5000 guge 50 3000 sohu 100 4500 $ sort  -k 1.1,1.1 -u facebook.txt baidu 100 5000 google 110 5000 sohu 100 4500 这个例子也同理，开头字符是g的guge就没有幸免于难。 $ sort -n -k 2 -k 3 -u facebook.txt guge 50 3000 sohu 100 4500 baidu 100 5000 google 110 5000 咦！这里设置了两层排序优先级的情况下，使用-u就没有删除任何行。原来-u是会权衡所有-k选项，将都相同的才会删除，只要其中有一级不同都不会轻易删除的:)（不信，你可以自己加一行sina 100 4500试试看） 11 最诡异的排序： $ sort -n -k 2.2,3.1 facebook.txt guge 50 3000 baidu 100 5000 sohu 100 4500 google 110 5000 以第二个域的第二个字符开始到第三个域的第一个字符结束的部分进行排序。 第一行，会提取0 3，第二行提取00 5，第三行提取00 4，第四行提取10 5。 又因为sort认为0小于00小于000小于0000…. 因此0 3肯定是在第一个。10 5肯定是在最后一个。但为什么00 5却在00 4前面呢？（你可以自己做实验思考一下。） 答案揭晓：原来“跨域的设定是个假象”，sort只会比较第二个域的第二个字符到第二个域的最后一个字符的部分，而不会把第三个域的开头字符纳入比较范围。当发现00和00相同时，sort就会自动比较第一个域去了。当然baidu在sohu前面了。用一个范例即可证实： $ sort -n -k 2.2,3.1 -k 1,1r facebook.txt guge 50 3000 sohu 100 4500 baidu 100 5000 google 110 5000 12 有时候在sort命令后会看到+1 -2这些符号，这是什么东东？ 关于这种语法，最新的sort是这么进行解释的： On older systems, `sort’ supports an obsolete origin-zero syntax `+POS1 [-POS2]‘ for specifying sort keys.  POSIX 1003.1-2001 (*note Standards conformance::) does not allow this; use `-k’ instead. 原来，这种古老的表示方式已经被淘汰了，以后可以理直气壮的鄙视使用这种表示方法的脚本喽！ （为了防止古老脚本的存在，在这再说一下这种表示方法，加号表示Start部分，减号表示End部分。最最重要的一点是，这种方式方法是从0开始计数的，以前所说的第一个域，在此被表示为第0个域。以前的第2个字符，在此表示为第1个字符。明白？） 绿色通道： 好文要顶 关注我 收藏该文与","title":"linux sort 命令详解"},{"content":"1 用 dump 建立增量备份机制 dump 和 restore 都是用来创建备份以及从备份恢复的最常用的方法。这两个程序已经存在很长时间了，在大多数站点中，dump 和 restore 都是支撑自动备份软件使用的命令。但这里有些情况是要说明下的，实际上，在 Linux 环境下，没有说非要选择 dump 来做备份的理由，遗憾的是，大多数主流 UNIX 发行版本所附带的 tar 版本缺乏 GNU 的 tar 所具备的许多功能。如果您必须对 UNIX 和 Linux 都提供备份支持，那么 dump 是最好的选择。它是唯一能够在不同平台上（相当）一致地处理好这些问题的命令，这样一来，您只要是一条命令的专家就够了，不必熟悉两条命令。如果您很幸运，处在一个纯 Linux 环境里，那么就可以选用自己最喜欢的工具啦，dump 的功能不足，而 tar 就好用多了！ 根据所选择的发行版本的不同，您可能不得不在 Linux 系统上明确安装 dump 和 restore 命令。默认情况下，Ubuntu 系统是没有安装 dump 的，所以您需要使用命令： $ sudo apt-get install dump 来进行安装。 2 转储文件系统 dump 命令的第一个参数必须是增量转储级别（0~9），dump 使用 /etc/dumpdates (Ubuntu 系统 /var/lib/dumpdates ) 文件来决定增量转储必须倒回去多远。-u 标志可以使 dump 命令在转储完成之后自动更新 /etc/dumpdates 文件，将日期、转储级别和文件系统的名称都记录下来。如果您从来没有使用过 -u 标志，那么所有转储都会变为级别 0，因为那样的话，将不会有先前备份过当前文件系统的记录。 dump 命令会把它的输出发送到某个默认设备上，通常情况下是主磁带机。如果想使用不同的设备，可以使用 -f 标志来通知 dump 将其输出发送到别处。-f 所使用的可以是设备文件例如 /dev/st0 (磁带机)，/dev/rsd1c (软盘驱动器)，/dev/sda1 (硬盘驱动器)，普通文件（可以使用 touch file 来创建）或者是 - (标准输出)。当需要转储数据到一个远程系统时，必须把远程磁带驱动器指定为 host:file 或者 user@host:file 的形式，例如： $ sudo dump -0u -f username@hostname:/dev/sdb1 /boot 访问远程磁带机的权限由 ssh 通道控制。 下面我们来看一些具体的备份策略： $ touch /tmp/dump.file $ sudo dump -0 -f /tmp/dump.file ~angel/music 通知 dump 将 angel 用户的 music 目录备份到 /tmp/dump.file 文件中。当备份的并非是整个文件系统时，dump 限定了备份的选项：-u 选项是不可用的，并且只支持 0 级转储级别。如上面的命令选项所示。 $ sudo dump -1u -f /dev/nst0 /boot 这里的 /boot 假定的是一个单独的文件系统，并非仅仅只是一个文件目录，因此可以使用 -u 选项并支持任意的增量转储级别。所用的是非倒带设备，Linux 通常用 /dev/st0 代表倒带设备，而用 /dev/nst0 代表非倒带设备。如果是使用 dump 来做备份操作的话，都应该使用非倒带设备 /dev/nst0，如果您不小心选择了自动倒带设备，那么最终只能保存最后转储的那个文件系统。因为 dump 命令并不知道磁带定位在哪里，这个失误当时并不会造成出错，这种情况只有在试图恢复文件的时候才会显现出来。 正常情况下，当磁带驱动器到达末尾时 dump 会自动倒带并弹出当前磁带，然后要求换入一卷新磁带。 $ sudo dump -5u -f /dev/sda1 /usr 以上这条命令顺利执行的条件要求： /usr 是一个独立的文件系统 /dev/sda1 的空间要比 /usr 大，能够完全装入 /usr 文件系统。 3 用 restore 从转储中恢复 restore -i 从磁带中读取备份目录，然后让您通过使用 ls，cd 和 pwd 这样的命令像一个普通的目录树那样遍历转储目录。使用 add 命令来标记那些需要恢复的文件。选好后，键入 extract 命令将文件从磁带中提取出来。 例如，用户 angel 不小心删除了 music 目录下他最心爱的 lonly.mp3 这首歌曲，需要从 /tmp/dump.file 备份中取回这曲歌曲，这时候系统管理员要做的就是： $ sudo mkdir /var/restore $ cd /var/restore $ restore -i -f /tmp/dump.file restore> ls.:music/restore> cd musicrestore> lsa.mp3 b.mp3 lonly.mp3restore> add lonly.mp3         使用 add 命令标记需要恢复的文件restore> lsa.mp3 b.mp3 *lonly.mp3         lonly.mp3 前面的星号表示标记 restore> extractYou have not read any volumes yet.Unless you know which volume your file(s) are on you should startwith the last volume and work towards the first.Specify next volume # (none if no more volumes): 1oset owner/mode for '.'? [yn] n 卷（磁带）是从 1 而不是从 0 开始记数的，所以对于在单独一卷磁带上进行的转储而言，可以指定 1。当 restore 命令询问是否需要为“.”设置属主和模式时，它是在询问是否应该设置当前目录去匹配磁带的根。除非您是在恢复整个文件系统，否则可能不需要这么做。 restore 完成之后，在 /var/restore 目录下就会有相应的文件夹出现，这时只要将里面的歌曲拷贝到 angel 的 music 目录下并设置属主和属组既可。 4 使用其他存档程序 dump 命令不是用于把文件存档到磁带、磁盘中的唯一程序，不过通常情况下，它是备份整个系统的最有效的方法。tar, cpio 和 dd 命令都能够把文件从一个介质转移到另外一个介质中去。 4.1 tar: 给文件打包 tar 命令读取多个文件或者目录，并把它们打包成一个文件，通常情况下是一个磁带文件。可以直接使用 -cf 选项创建一个存档文件： $ tar -cf file.tar fromdir 也可以在创建存档文件时加上压缩选项，我们很多时候都是这么干的，可以使用 -z (gzip), -j (bzip2) 或者 -J (xz) 等压缩算法，其中 xz 是目前最高效的压缩算法，压缩后的存档文件比 gzip 和 bzip2 压缩后的存档文件都要小得多。我们可以使用以下任意一条命令来创建压缩存档文件： gzip $ tar -czvf file.tar.gz fromdir bzip2 $ tar -cjvf file.tar.bz2 fromdir xz $ tar -cJvf file.tar.xz fromdir 默认情况下，tar 命令不会对符号链接所指向的真正文件做备份，但可以提示它去这么做。也可以指定 tar 只包含自给定日期以来修改过的文件，这对于创建您自己的增量备份方案来说很有帮助。具体详情请参考 tar 手册页，了解这项功能以及别的好功能。 4.2 cpio: 古老的存档工具 cpio 在功能上和 tar 相似。它可以追溯到 UNIX 的最初时期，但现在很少使用了。不过所有的系统中都包含它。和 tar 一样，cpio 命令能够用于移动目录树。如下命令： $ find fromdir -depth -print | cpio -pdm todir 4.3 dd: 处理位流 dd 是文件复制和转换程序。除非告诉 dd 命令去进行某种转换操作，否则它只进行从输入文件到输出文件的复制工作。如果用户给您一卷在某些非 Linux 系统上写入的磁带，那么 dd 命令可能是读取它的唯一方法。 dd 命令在历史上的一种应用就是创建一个完整文件系统的副本。但现在更好的选择是使用 mkfs.ext4 命令创建目标文件系统，然后运行 dump 命令导出给 restore 命令。如果使用不正确的话，dd 命令有时候能够破坏分区信息。它只能在大小完全相同的两个分区之间复制文件系统。","title":"Linux 学习笔记（九）备份"},{"content":"一、安装MySQL 目前web服务器已经很少有跑静态页面的，如果要跑动态网站那当然就离不开数据库，虽然在以前文章中有写MySQL是怎么安装的，但是感觉好久没装MySQL，现在只把步骤贴出来，就不做过多的讲解了 #useradd mysql #tar zxvf mysql-5.0.40.tar.gz #cd mysql-5.0.40 #./configure --prefix=/usr/local/mysql #make && make install #/usr/local/mysql/bin/mysql_install_db --user=mysql //初始化MySQL数据库 #chown -R mysql /usr/local/mysql/var #/usr/local/mysql/bin/mysqld_safe & //启动MySQL #/usr/local/mysql/bin/mysqladmin -u root password 123456 //设置MySQL密码 #cp support-files/my-medium.cnf /etc/my.cnf #echo \"/usr/local/mysql/bin/mysqld_safe &\" >>/etc/rc.local 二、安装PCRE PCRE是perl所用到的正则表达式，目的是让所装的软件支持正则表达式。默认情况下，Nginx只处理静态的网页请求，也就是html.如果是来自动态的网页请求，比如*.php，那么Nginx就要根据正则表达式查询路径，然后把*.PHP交给PHP去处理 #rpm -qa | grep pcre //查询系统中有没有安装PCRE，一般装系统是默认装有，所以我们要删掉系统自带的 #cp /lib/libpcre.so.0 / //在删除系统自带的PCRE之前，要先备份一下libpcre.so.0这个文件，因为RPM包的关联性太强，在删除后没libpcre.so.0这个文件时我们装PCRE是装不上的 #rpm -e --nodeps pcre-6.6-1.1 //删除系统自带的PCRE # tar zxvf pcre-8.00.tar.gz #cd pcre-8.00 #cp /libpcre.so.0 /lib/ //把我们删除系统自带的PCRE之前备份的libpcre.so.0拷贝到/lib 目录下 #./configure //配置PCRE，因为PCRE是一个库，而不是像pache、php、postfix等这样的程序，所以我们安装时选择默认路径即可，这样会在后面安装其它东西时避免一些不必要的麻烦，执行完这部后会显示出下图，上面显示了我们对PCRE的配置 #make && make install 三、安装Nginx 在网上，看到不少人装Nginx 时非常麻烦，配置时用了一大堆选项，请问你们真实现那么多功能么？害的我越看越郁闷。此次安装Nginx如果是按着上面笔者的步骤一步步走下来，安装Nginx时只需指定Nginx的安装路径即可 #tar zxvf nginx-0.8.24.tar.gz #cd nginx-0.8.24 #./configure --prefix=/usr/local/nginx //此处在本环节只需指定一个路径 #make && make install #/usr/local/nginx/sbin/nginx //启Nginx #echo \"/usr/local/nginx/sbin/nginx\" >>/etc/rc.local Nginx启动后有两个进程，master为主进程，worker为工作进程，如下图 在启动完NGINX后，我们可以在浏览器中输入http://localhost查看，如下图 四、安装PHP 既然安装PHP，那GD便是不可少的，在此GD的安装不再进行描述 1、安装libpng #tar xvf libpng-1.2.10.tar.tar #cd libpng-1.2.10 #./configure --prefix=/usr/local/png #make;make install #ln -s /usr/local/png/lib/* /usr/lib/ 2、安装jpeg #mkdir /usr/local/jpeg #mkdir /usr/local/jpeg/bin #mkdir /usr/local/jpeg/lib #mkdir /usr/local/jpeg/include #mkdir /usr/local/jpeg/man #mkdir /usr/local/jpeg/man/man1 #tar xvf jpegsrc.v7.tar.tar #cd jpeg-7 #./configure --prefix=/usr/local/jpeg --enable-shared --enable-static #make;make install #ln -s /usr/local/jpeg/lib/* /usr/lib/ 3、安装 freetype #tar xvf freetype-2.3.9.tar.tar #cd freetype-2.3.9 #./configure --prefix=/usr/local/freetype #make;make install 4、安装fontconfig #tar zxvf fontconfig-2.4.2.tar.gz #cd fontconfig-2.4.2 #./configure --prefix=/usr/local/fontconfig --with-freetype-config=/usr/local/freetype/bin/freetype-config #make;make install 5、安装GD #tar zxvf gd-2.0.32.tar.gz #cd gd-2.0.32 #./configure --prefix=/usr/local/gd --with-png=/usr/local/png --with-jpeg=/usr/local/jpeg --with- freetype=/usr/local/freetype --with-fontconfig=/usr/local/fontconfig #cp /usr/local/png/include/png.h ./ #cp /usr/local/png/include/pngconf.h ./ #make;make install 6、安装PHP 这个地方是最重要的地方，因为默认情况下Nginx和PHP他俩之间是一点感觉没有的。在之前，很多朋友都搭建过Apache+PHP，Apache+PHP编译后生成的是模块文件，而Nginx+PHP需要PHP生成可执行文件才可以，所以要利用fastcgi技术来实现N ginx与PHP的整合，这个只要我们安装是启用FastCGI即可。此次我们安装PHP不仅使用了FastCGI，而且还使用了PHP-FPM这么一个东东，PHP-FPM说白了是一个管理FastCGI的一个管理器，它作为PHP的插件纯在，在安装PHP要想使用PHP-FPM时就需要把PHP-FPM以补丁的形式安装到PHP中，而且PHP要与PHP-FPM版本一致，这是必须的，切记！ 首先我们把PHP和PHP-FPM下载到同一目录下，此次用的为php-5.3.0.tar.bz2和php-5.3.0-fpm-0.5.12.diff.gz，下载到了同一目录下 #tar xvf php-5.3.0.tar.bz2 #gzip -cd php-5.3.0-fpm-0.5.12.diff.gz | patch -d php-5.3.0 -p1 //将php-5.3.0-fpm-0.5.12.diff.gz以补丁形式加到php-5.3.0里面 #cd php-5.3.0 #./configure --prefix=/usr/local/php --with-gd=/usr/local/gd --with-jpeg-dir=/usr/local/jpeg --with-png-dir=/usr/local/png --with-freetype-dir=/usr/local/freetype --with-mysql=/usr/local/mysql --enable-fastcgi --enable-fpm 注：Nginx+PHP整合，在安装时必须启用--enable-fastcgi和 --enable-fpm，这两个选项是做什么的上面已经描述。执行完后系统会提示--enable-fastcgi是一个未知选项，我们不必理会 #make #make install #cp php.ini-dist /usr/local/php/etc/php.ini 下面我们就要启动PHP-FPM #/usr/local/php/sbin/php-fpm start 在启动PHP-FPM时会报上面这个错误，原因是PHP-FPM自己不知道以那个用户和组运行PHP，所以我们要修改一个文件，把文件中的注释去掉即可（打开文件把红色部分删除），然后PHP-FPM会以nobody用户和组去运行PHP。 #vi /usr/local/php/etc/php-fpm.conf #/usr/local/php/sbin/php-fpm start #ps -aux | grep php #echo \"/usr/local/php/sbin/php-fpm start\" >>/etc/rc.local 五、整合Nginx与PHP 上面已经讲过，Nginx自己并不处理动态网页的请求，而且Nginx将得到的动态请求转交给PHP，下面我们打开Nginx的配置文件看一下 #vi /usr/local/nginx/conf/nginx.conf //标的部分是我们后面要修改的 看上图，Nginx已经知道怎么把得到的请求传达给PHP，Nginx在得到*.php请求时，会把请求通过9000端口传给PHP。下面我们把这些注释给去掉即可，如下图 注：上面的/usr/local/nginx/html 是我们PHP网站放置的路径 那么只有Nginx自己知道咋找PHP了还不行，还需要PHP知道咋找Nginx，PS：你见过大街上的JJMM约会时有不是相互认识对方，或者是不知道用啥方法和对方接头的？这点我们不需要担心，PHP-FPM已经在配置文件中定义了从哪接受PHP请求，我们可以打开配置文件看一下 #vi /usr/local/php/etc/php-fpm.conf 如上图所示，我们在前面已经看到过Nginx是通过本机的9000端口将PHP请求转发给PHP的，而上图我们可以看到PHP自己是从本机的9000端口侦听数据 ，Nginx与PHP通过本机的9000端口完成了数据请求。 六、测试 我们在nginx的配置文件里面已经定义了PHP网站的存放路径，路径问/usr/local/nginx/html 下面我们在这个目录下新建一个PHP页面测试网页，文件名为test.php，内容如下 重启PHP与nginx后(可以用杀死进程的方式关闭，然后在启动)我们在浏览器中输入http://localhost/test.php，出现如下界面算成功","title":"CentOS+Nginx+PHP+MySQL详细配置(图解)"},{"content":"当需要在linux环境下编写大型的c/c++程序时，如果我们要一个一个源文件手动调用gcc命令编译那不知猴年马月才能做完，所以make出现了，自动化编译。这篇文章记录了学习前辈程皓<跟我一起写Makefile>的笔记。 跟我一些Makefile系列 跟我一起写 Makefile（一） 跟我一起写 Makefile（二） 跟我一起写 Makefile（三） 跟我一起写 Makefile（四） 跟我一起写 Makefile（五） 跟我一起写 Makefile（六） 跟我一起写 Makefile（七） 跟我一起写 Makefile（八） 跟我一起写 Makefile（九） 跟我一起写 Makefile（十） 跟我一起写 Makefile（十一） 跟我一起写 Makefile（十二） 跟我一起写 Makefile（十三） 跟我一起写 Makefile（十四）","title":"make学习"},{"content":"先发布一个获取url的 函数，后面还会发布获取host的函数 http_host，尽请期待 更多内容： http://bugkill.01safe.com/thread-220-1-1.html const char* geturl(const char* buf,const u_int16 buflen, char ** url,u_int16* urllen){int i = 0;char c ;int left;c = buf[0];switch(c){case 'P':i +=5;left = 5;break;case 'G':i+=4;left = 4;break;default:return NULL;}*url =(char*)( buf+i); while(i<buflen){if(buf[i] !=' '){i++;}else break;}*urllen = i-left;return *url;}","title":"获取linux ip mac 主机名有啥好玩的！来个更高级的获取 url host"},{"content":"    我这边是用的是eclipse3.2 + Myeclipse5.1。     下载必要的软件：      eclipse-SDK-3.2.2-linux-gtk.tar.gz：     http://dl.lupaworld.com/download/eclipse-SDK-3.2.2-43.html      MyEclipse_5_1_1GA_Installer.bin：     http://www.myeclipseide.com/index.php?name=Downloads&req=viewsdownload&sid=15          安装Eclipse：      其实安装Eclipse还是蛮简单的，我这边将其解压到/usr/java目录下      tar -zxvf /PATH/eclipse-SDK-3.2.2-linux-gtk.tar.gz      这里PATH是你存放eclipse-SDK-3.2.2-linux-gtk.tar.gz的目录，解压后，在/usr/java目录下就有了eclipse这个目录          接下来，我来为eclipse创建一个图形界面快速启动项（类似于windows下的桌面快捷方式），右击图形界面——〉选择\\\"新建启动器(New     Launcher)\\\"——〉名称（Name）输入Eclipse——〉命令（Command）选择Eclipse解压目录     /usr/java/eclipse——〉图标（Icon）可以选择Eclipse的图标——〉点击确定完成，然后你就可以双击图形界面中的快速启动来启     动你的eclipse了，当然也可以在shell下执行eclipse根目录下的执行文件来启动eclipse！      eclipse启动后还需要一些必要的配置，这里就不讲了     安装Myeclipse：      下面来安装Myeclipse，Myeclipse的安装跟windows下的安装并无多大区别      shell下执行MyEclipse_5_1_1GA_Installer.bin文件：      ./PATH/MyEclipse_5_1_1GA_Installer.bin     （必要时要改变权限：sudo chmod 777 MyEclipse_5_1_1GA_Installer.bin）          按回车后它会先检测你系统中的环境，待检测完毕，正常的话会出现Myeclipse安装画面，这下来的操作跟windows下的操作是一样的，这里面会先     让你选择eclipse的安装目录，我这里就是/usr/java/eclipse，然后再选择安装目录，输入/usr/java/myeclipse，     然后一路next就行了 ^_^      安装完成后，启动eclipse，点击菜单项Help——〉Software Updates——〉Manager Configuration      在打开的窗口中可以看到已经有myeclipse在那里了.     接下来是注册，可使用下面的帐号和密码：      Subscriber: www.1cn.biz     Subscriber Code: jLR8ZC-444-55-4467865481680090          注册成功后会发现：          Subscriber: www.1cn.biz     Product ID: E3MP (MyEclipse Professional Subscription)     License version: 9.99     Full Maintenance Included     Subscription expiration date (YYYYMMDD): 20991231     Number of licenses: Unlimited     配置Tomcat：      eclipse中选择window——〉preferences，在弹出的窗口选择Myeclipse——〉Application Servers——〉Tomcat5     接着在Tomcat server这里选择\\\"Enable\\\",下面Tomcat Home Directory选择你tomcat安装的目录，然后右下角的Apply应用，确定退出！                         本文来自ChinaUnix博客，如果查看原文请点：http://blog.chinaunix.net/u1/40572/showart_411539.html","title":"Linux下Eclipse，Myeclipse安装"},{"content":"TTl=time to live 这应当从网络的层次讲起：  首先，PING命令是属于ICMP协议规定的，而ICMP是内嵌于IP层的，因此，可以说，PING是网络层的命令。 PING的实现过程很简单，命令将引发IP层发送一个简单的IP包，而目的方收到这个包之后，将源和目的地址做一下交换，重新发出这个包即可，当然还要加一些超时的机制。 简单来说,为了避免数据包在网路上的传送路径造成死循环或者无休止的投递下去，每个ip数据包都包含乐一个寿命计数器，这个就是数据包的的生存时间TTL，也叫hop count,只要一个路由器处理过这个数据包，它就递减这个数据包的寿命计数，当寿命计数递减到0的时候，路由器就丢弃该包. TTL在一定程度上反应了一个IP数据包经过的路由器的多少，但是也不完全是这样，因为数据包在网络上传播的时候，其传播时间和带宽有一定关系，有时候协议会把传播时间的长短折合在TTL里，能比较客观的反应网络的状况。   简单来说，TTL全程Time to Live，意思就是生存周期。首先要说明ping命令是使用的网络层协议ICMP，所以TTL指的是一个网络层的网络数据包（package）的生存周期，这句话不懂的先回去复习OSI7层协议去。 第一个问题，为什么要有生存周期这个概念。 很显然，一个package从一台机器到另一台机器中间需要经过很长的路径，显然这个路径不是单一的，是很复杂的，并且很可能存在环路。如果一个数据包在传输过程中进入了环路，如果不终止它的话，它会一直循环下去，如果很多个数据包都这样循环的话，那对于网络来说这就是灾难了。所以需要在包中设置这样一个值，包在每经过一个节点，将这个值减1，反复这样操作，最终可能造成2个结果：包在这个值还为正数的时候到达了目的地，或者是在经过一定数量的节点后，这个值减为了0。前者代表完成了一次正常的传输，后者代表包可能选择了一条非常长的路径甚至是进入了环路，这显然不是我们期望的，所以在这个值为0的时候，网络设备将不会再传递这个包而是直接将他抛弃，并发送一个通知给包的源地址，说这个包已死。 第二个问题，通过TTL值我们能得到什么 其实TTL值这个东西本身并代表不了什么，对于使用者来说，关心的问题应该是包是否到达了目的地而不是经过了几个节点后到达。但是TTL值 还是可以得到有意思的信息的。每个操作系统对TTL值得定义都不同，这个值甚至可以通过修改某些系统的网络参数来修改，例如Win2000默认为128，通过注册表也可以修改。而Linux大多定义为64。不过一般来说，很少有人会去修改自己机器的这个值的，这就给了我们机会可以通过ping的回显TTL来大体判断一台机器是什么操作系统。 以我公司2台机器为例  看如下命令  D:/Documents and Settings/hx>ping 61.152.93.131 Pinging 61.152.93.131 with 32 bytes of data: Reply from 61.152.93.131: bytes=32 time=21ms TTL=118  Reply from 61.152.93.131: bytes=32 time=19ms TTL=118  Reply from 61.152.93.131: bytes=32 time=18ms TTL=118  Reply from 61.152.93.131: bytes=32 time=22ms TTL=118 Ping statistics for 61.152.93.131:  Packets: Sent = 4, Received = 4, Lost = 0 (0% loss  Approximate round trip times in milli-seconds:  Minimum = 18ms, Maximum = 22ms, Average = 20ms D:/Documents and Settings/hx>ping 61.152.104.40 Pinging 61.152.104.40 with 32 bytes of data: Reply from 61.152.104.40: bytes=32 time=28ms TTL=54  Reply from 61.152.104.40: bytes=32 time=18ms TTL=54  Reply from 61.152.104.40: bytes=32 time=18ms TTL=54  Reply from 61.152.104.40: bytes=32 time=13ms TTL=54 Ping statistics for 61.152.104.40:  Packets: Sent = 4, Received = 4, Lost = 0 (0% loss  Approximate round trip times in milli-seconds:  Minimum = 13ms, Maximum = 28ms, Average = 19ms  第一台TTL为118，则基本可以判断这是一台Windows机器，从我的机器到这台机器经过了10个节点，因为128-118=10。而第二台应该是台Linux ，理由一样64-54=10。 了解了上面的东西，可能有人会有一些疑问，例如以下： 1，不是说包可能走很多路径吗，为什么我看到的4个包TTL都是一样的，没有出现不同？ 这是由于包经过的路径是经过了一些最优选择算法来定下来的，在网络拓扑稳定一段时间后，包的路由路径也会相对稳定在一个最短路径上。 具体怎么算出来的要去研究路由算法了，不在讨论之列。 2，对于上面例子第二台机器，为什么不认为它是经过了74个节点的Windows机器？因为128-74=54。 对于这个问题，我们要引入另外一个很好的ICMP协议工具。不过首先要声明的是，一个包经过74个节点这个有些恐怖，这样的路径还是不用为 好。 要介绍的这个工具是tracert（*nix下为traceroute），让我们来看对上面的第二台机器用这个命令的结果  D:/Documents and Settings/hx>tracert 61.152.104.40 Tracing route to 61.152.104.40 over a maximum of 30 hops 1 13 ms 16 ms 9 ms 10.120.32.1  2 9 ms 9 ms 11 ms 219.233.244.105  3 12 ms 10 ms 10 ms 219.233.238.173  4 15 ms 15 ms 17 ms 219.233.238.13  5 14 ms 19 ms 19 ms 202.96.222.73  6 14 ms 17 ms 13 ms 202.96.222.121  7 14 ms 15 ms 14 ms 61.152.81.86  8 15 ms 14 ms 13 ms 61.152.87.162  9 16 ms 16 ms 28 ms 61.152.99.26  10 12 ms 13 ms 18 ms 61.152.99.94  11 14 ms 18 ms 16 ms 61.152.104.40 Trace complete. 从这个命令的结果能够看到从我的机器到服务器所走的路由，确实是11个节点（上面说10个好像是我犯了忘了算0的错误了，应该是64-54+1， 嘿嘿），而不是128的TTL经过了70多个节点。 既然已经说到这里了，不妨顺便说说关于这两个ICMP命令的高级一点的东西。 首先是ping命令，其实ping有这样一个参数，可以无视操作系统默认TTL值而使用自己定义的值来发送ICMP Request包。  例如还是用那台Linux机器，用以下命令：  D:/Documents and Settings/hx>ping 61.152.104.40 -i 11 Pinging 61.152.104.40 with 32 bytes of data: Reply from 61.152.104.40: bytes=32 time=10ms TTL=54  Reply from 61.152.104.40: bytes=32 time=13ms TTL=54  Reply from 61.152.104.40: bytes=32 time=10ms TTL=54  Reply from 61.152.104.40: bytes=32 time=13ms TTL=54 Ping statistics for 61.152.104.40:  Packets: Sent = 4, Received = 4, Lost = 0 (0% loss),  Approximate round trip times in milli-seconds:  Minimum = 10ms, Maximum = 13ms, Average = 11ms D:/Documents and Settings/hx>  这个命令我们定义了发包的TTL为11，而前面我们知道，我到这台服务器是要经过11个节点的，所以这个输出和以前没什么不同。现在再用这个 试试看：  D:/Documents and Settings/hx>ping 61.152.104.40 -i 10 Pinging 61.152.104.40 with 32 bytes of data: Reply from 61.152.99.94: TTL expired in transit.  Reply from 61.152.99.94: TTL expired in transit.  Reply from 61.152.99.94: TTL expired in transit.  Reply from 61.152.99.94: TTL expired in transit. Ping statistics for 61.152.104.40:  Packets: Sent = 4, Received = 4, Lost = 0 (0% loss),  Approximate round trip times in milli-seconds:  Minimum = 0ms, Maximum = 0ms, Average = 0ms D:/Documents and Settings/hx> 可以看到，结果不一样了，我定义了TTL为10来发包，结果是TTL expired in transit.就是说在到达服务器之前这个包的生命周期就结束了。 注意看这句话前面的ip，这个ip恰好是我们前面tracert结果到服务器之前的最后1个ip，包的TTL就是在这里减少到0了，根据我们前面的讨论 ，当TTL减为0时设备会丢弃包并发送一个TTL过期的ICMP反馈给源地址，这里的结果就是最好的证明。 通过这里再次又证明了从我机器到服务器是经过了11个节点而不是70多个，呵呵。  最后再巩固一下知识，有人可能觉得tracer这个命令很神奇，可以发现一个包所经过的路由路径。其实这个命令的原理就在我们上面的讨论中 。 想象一下，如果我给目的服务器发送一个TTL为1的包，结果会怎样？  根据前面的讨论，在包港出发的第一个节点，TTL就会减少为0，这时这个节点就会回应TTL失效的反馈，这个回应包含了设备本身的ip地址，这样我们就得到了路由路径的第一个节点的地址。因此，我们继续发送TTL=2的包，也就受到第二个节点的TTL失效回应.依次类推，我们一个一个的发现，当最终返回的结果不是TTL失效而是ICMP Response的时候，我们的tracert也就结束了，就是这么简单。 顺便补一句ping命令还有个-n的参数指定要发包的数量，指定了这个数字就会按照你的要求来发包了而不是默认的4个包。如果使用-t参数的话，命令会一直发包直到你强行中止它。","title":"什么是TTL"},{"content":".tar  解包：tar xvf FileName.tar 打包：tar cvf FileName.tar DirName （注：tar是打包，不是压缩！） ——————————————— .gz 解压1：gunzip FileName.gz 解压2：gzip -d FileName.gz 压缩：gzip FileName .tar.gz 和 .tgz 解压：tar zxvf FileName.tar.gz 压缩：tar zcvf FileName.tar.gz DirName ——————————————— .bz2 解压1：bzip2 -d FileName.bz2 解压2：bunzip2 FileName.bz2 压缩： bzip2 -z FileName .tar.bz2 解压：tar jxvf FileName.tar.bz2 压缩：tar jcvf FileName.tar.bz2 DirName ——————————————— .bz 解压1：bzip2 -d FileName.bz 解压2：bunzip2 FileName.bz 压缩：未知 .tar.bz 解压：tar jxvf FileName.tar.bz 压缩：未知 ——————————————— .Z 解压：uncompress FileName.Z 压缩：compress FileName .tar.Z 解压：tar Zxvf FileName.tar.Z 压缩：tar Zcvf FileName.tar.Z DirName ——————————————— .zip 解压：unzip FileName.zip 压缩：zip FileName.zip DirName ——————————————— .rar 解压：rar x FileName.rar 压缩：rar a FileName.rar DirName ——————————————— .lha 解压：lha -e FileName.lha 压缩：lha -a FileName.lha FileName ——————————————— .rpm 解包：rpm2cpio FileName.rpm | cpio -div ——————————————— .deb 解包：ar p FileName.deb data.tar.gz | tar zxf - ——————————————— .tar .tgz .tar.gz .tar.Z .tar.bz .tar.bz2 .zip .cpio .rpm .deb .slp .arj .rar .ace .lha .lzh .lzx .lzs .arc .sda .sfx .lnx .zoo .cab .kar .cpt .pit .sit .sea 解压：sEx x FileName.* 压缩：sEx a FileName.* FileName sEx只是调用相关程序，本身并无压缩、解压功能，请注意！ gzip 命令  减少文件大小有两个明显的好处，一是可以减少存储空间，二是通过网络传输文件时，可以减少传输的时间。gzip 是在 Linux 系统中经常使用的一个对文件进行压缩和解压缩的命令，既方便又好用。 语法：gzip [选项] 压缩（解压缩）的文件名该命令的各选项含义如下： -c 将输出写到标准输出上，并保留原有文件。-d 将压缩文件解压。-l 对每个压缩文件，显示下列字段：     压缩文件的大小；未压缩文件的大小；压缩比；未压缩文件的名字-r 递归式地查找指定目录并压缩其中的所有文件或者是解压缩。-t 测试，检查压缩文件是否完整。-v 对每一个压缩和解压的文件，显示文件名和压缩比。-num 用指定的数字 num 调整压缩的速度，-1 或 --fast 表示最快压缩方法（低压缩比），-9 或--best表示最慢压缩方法（高压缩比）。系统缺省值为 6。指令实例： gzip *% 把当前目录下的每个文件压缩成 .gz 文件。gzip -dv *% 把当前目录下每个压缩的文件解压，并列出详细的信息。gzip -l *% 详细显示例1中每个压缩的文件的信息，并不解压。gzip usr.tar% 压缩 tar 备份文件 usr.tar，此时压缩文件的扩展名为.tar.gz。","title":"ubuntu下解压缩包命令"},{"content":"  Qt 学习中, Ha Ha - _ -................   #ifndef FINDDIALOG_H#define FINDDIALOG_H#include <QDialog>class QLabel;class QPushButton;class QCheckBox;class QLineEdit;class FindDialog : public QDialog{    Q_OBJECTpublic:    FindDialog(QWidget * parent = 0);private:    void findNext(const QString &str, Qt::CaseSensitivity cs);    void findPrevious(const QString &str, Qt::CaseSensitivity cs);private slots:    void findClicked();    void enableFindButton(const QString &text);private:    QLabel *label;    QLineEdit *lineEdit;    QCheckBox *machCase;    QCheckBox *searchBackward;    QPushButton *okButton;    QPushButton *cancelButton;};#endif // FINDDIALOG_H   #include <QtGui>#include <finddialog.h>FindDialog::FindDialog(QWidget *parent)    :QDialog(parent){    label = new QLabel(tr(\"&Find what\"));    lineEdit = new QLineEdit;    label->setBuddy(lineEdit);    machCase = new QCheckBox(tr(\"&Mach case\"));    searchBackward = new QCheckBox(tr(\"&Search Backward\"));    okButton = new QPushButton(tr(\"&Find\"));    okButton->setDefault(true);     // Enter key is    okButton->setEnabled(false);    cancelButton = new QPushButton(tr(\"Cancel\"));    QObject::connect(lineEdit, SIGNAL(textChanged(QString)), this, SLOT(enableFindButton(QString))); //is not textEdited(QString)?    QObject::connect(okButton, SIGNAL(clicked()), this, SLOT(findClicked()));    QObject::connect(cancelButton, SIGNAL(clicked()), this, SLOT(close()));    QHBoxLayout *topLeftLayout = new QHBoxLayout;    topLeftLayout->addWidget(label);    topLeftLayout->addWidget(lineEdit);    QVBoxLayout *leftLayout = new QVBoxLayout;    leftLayout->addLayout(topLeftLayout);   //addLayout相当于布局好了的容器，而addWidget相当于要加入这个容器中的东西    leftLayout->addWidget(machCase);    leftLayout->addWidget(searchBackward);    QVBoxLayout *rightLayout = new QVBoxLayout;    rightLayout->addWidget(okButton);    rightLayout->addWidget(cancelButton);    rightLayout->addStretch();    QHBoxLayout *windowLayout = new QHBoxLayout;    windowLayout->addLayout(leftLayout);    windowLayout->addLayout(rightLayout);    setLayout(windowLayout);    setWindowTitle(tr(\"Find\"));    setFixedHeight(sizeHint().height());}void FindDialog::findNext(const QString &str, Qt::CaseSensitivity cs){    QString tr1 = str;    int cs1 = cs;    cs1 += cs1    //now none thing to do    ;}void FindDialog::enableFindButton(const QString &text){    okButton->setEnabled(!text.isEmpty());}void FindDialog::findPrevious(const QString &str, Qt::CaseSensitivity cs){    QString str1 = str;    int cs1 = cs;    cs1 += cs1    // NOW none thing to do    ;}void FindDialog::findClicked(){    QString str = lineEdit->text();    Qt::CaseSensitivity cs = machCase->isChecked() ? Qt::CaseSensitive : Qt::CaseInsensitive;    if (searchBackward->isChecked())    {        emit this->findPrevious(str, cs);   //send signal    }    else    {        emit this->findNext(str, cs);    }}   #include <QApplication>#include <finddialog.h>int main(int argc, char *argv[]){    QApplication app(argc, argv);    FindDialog *findDialog = new FindDialog;    findDialog->show();    return app.exec();}    #include <QApplication>#include <finddialog.h>int main(int argc, char *argv[]){    QApplication app(argc, argv);    FindDialog *findDialog = new FindDialog;    findDialog->show();    return app.exec();}      ","title":"[置顶] qdilog"},{"content":"最近在看代码的时候看到了很多关于shell重定向的使用，所以特地学习了官方Bash手册，并结合一个网友的博客，在此将内容总结整理一下。 一、shell指令执行的顺序 bash启动的时候会默认打开3个文件描述符，当它运行一条指令的时候，会先fork一个子进程，子进程会继承这3个文件描述符，然后设定好重定向之后，再执行指令。严格按照这个顺序会很容易理解重定向。 需要注意的几点是： 如果指令中有多个重定向，重定向的顺序是很关键的，因为重定向是按照从左向右解析的。 如果只有一个重定向的话，那么它在指令的位置可以任意，因为bash是先解析重定向，然后将重定向从指令中去除以后再执行指令。 重定向符号如果以‘<’开头，是指对标准输入（fd= 0）进行重定向；如果是以'>'开头，则是对标准输出（fd= 1）重定向，这点后面还会继续强调。 下面所有列举的重定向格式中的 word 除特意指明以外，都是指各种扩展之后的效果，本文只针对重定向，这些扩展具体可以查看bash的参考手册，在这里我们就使用不带任何扩展、最简单的文件名来说明。 重定向就是针对文件描述符的操作，理解到这一点，重定向也就不难了。 二、输入重定向（Redirecting Input） 格式：[n]<word 说明：将文件描述符n重定向到word指代的文件（以读的方式打开），如果n省略（第3个注意项），则是将标准输入重定向。 举例： $ cat < file\t # 等价于cat 0<file 子进程的shell在继承3个文件描述符以后，解析到重定向符号‘<'，然后将标准输入重定向到file，之后执行cat指令，cat指令从标准输入读取数据，标准输入由于已定向到file，所以就转而从file中读取输入内容。 三、输出重定向（Redirecting Output） 格式：[n]>[|]word 说明：将文件描述符n重定向到word指代的文件（以写的方式打开），如果n省略（第3个注意项），则是将标准输出重定向。bash有一个内建选项noclobber，是用来防止文件被覆盖写入，默认是关闭的，可以通过指令 set -o noclobber开启该功能（o代表open，关闭使用set +o noclobber），开启以后输出重定向会执行失败。'|' 字符是用于在开启该功能的情况下强制执行重定向。 举例： $ set -o noclobber$ touch file$ ls > file\t # 等价于ls 1>filebash: file: cannot overwrite existing file$ ls >| file$ cat filefile 首先开启noclobber功能，创建一个空文件file，然后在执行ls > file的时候，标准输出首先重定向到file，执行ls时打印到标准输出的结果会写入到file，但是noclobber使文件不能被写入。在使用>|以后，就可以强制写入file了。 注意：建议将noclobber功能追加到.bashrc文件中， echo 'set -o noclobber' >> .bashrc\t # 注意是“>>” 这样会防止平时误操作导致文件被覆盖，需要强制的时候只需要加上‘|’符号即可。 四、附加输出重定向（Appending Redirected Output） 格式：[n]>>word 说明：与输出重定向类似，只是word代表的文件是以附加方式打开，所以不受noclobber的影响。 五、标准输出与标准错误输出重定向（Redirecting Standard Output and Standard Error） 格式：&>word 或 >&word 说明：将标准输出与标准错误输出都定向到word代表的文件（以写的方式打开），两种格式意义完全相同，不过更推荐使用前者（手册上没有说明为什么，个人认为是为了与下面要提到的附加标准输出与标准错误输出重定向格式相对应），格式等价于>word2>&1（2>&1是将标准错误输出文件描述符复制到标准输出，后面还会说明） 举例： $ ls &> file$ cat filefile$ mkdir &>file\t # 开启noclobber功能重定向会失效$ cat filemkdir: missing operandTry `mkdir --help' for more information. 从ls &> file中可以看出ls到标准输出的内容写入到了file中，说明标准输出重定向。然后执行了一条错误的mkdir指令，终端上没有显示出任何错误信息，而打印file的内容，可以看到错误信息被写入到了file中去，说明标准错误输出重定向。 六、附加标准输出与标准错误输出重定向（Appending Standard Output and Standard Error） 格式：&>>word 说明：与标准输出与标准错误输出重定向类似，只是word代表的文件是以附加方式打开，所以不受noclobber的影响。格式等价于>>word 2>&1。 七、复制文件描述符（Duplicating File Descriptors） 格式：(1)[n]<&word (2) [n]>&word 说明：word是用数字表示的文件描述符（注意不是文件名了），表示将文件描述符n复制到word，前者是以读的方式打开，后者是以写的方式打开。这里不用digit而是依然用word来指代文件描述符的原因可以由第五点来说明，如果n省略，那么(2)就变成了>&word的形式，而这里的word还是代表文件名。 为了更清晰解释这部分内容，我们用图来说明cmd &>file的等价形式cmd >file 2>&1执行的过程（图中的/dev/tty0代表终端）。 第一步，创建shell子进程，子进程继承3个文件描述符 第二步，从左到右解析重定向符号，>file是将标准输出重定向到file。 然后2>&1将标准错误输出复制到标准输出。 第三步，去除所有重定向，执行cmd指令，标准错误输出和标准输入都会重定向到file中。 注意在这里重定向的顺序很重要，如果执行的指令是cmd 2>&1 >file，那么重定向会先将标准错误输出复制到标准输出，再将标准输出定向到file。像下面这两张图 举例： $ set +o noclobber$ mkdir >file 2>&1$ cat filemkdir: missing operandTry `mkdir --help' for more information.$ mkdir 2>&1 >filemkdir: missing operandTry `mkdir --help' for more information.$ cat file$ 首先关闭noclobber功能，由运行结果可以看到，先定向再复制的话，标准错误输出会写入到file中，而先复制后定后的话，由于标准输出没有任何结果，所以标准错误输出打印到了终端上，而file文件则为空。 八、移动文件描述符（Moving File Descriptors） 格式：[n]<&digit- 或 [n]>&digit- 说明：类似于复制，只是在复制完成之后，文件描述符n会关闭。注意这里的文件描述符是用digit来指代的，因为不会有其他意义。 九、读写打开文件描述符（Opening File Descriptors for Reading and Writing） 格式：[n]<>word 说明：以读写方式打开word指代的文件，并将n重定向到该文件。如果n不指定的话，默认为标准输入。 举例： $ exec 3<>file$ ls >&3$ cat filefile$ cat <&3$ exec 3<>file$ cat <&3file 将文件描述符3定向到file，然后把标准输出定向到3以后，标准输出的内容就写入到file中。同样从标准输入读的时候，将标准输入定向到3，会打印出file的内容。由上面的结果还能看到exec3<>file只针对一条指令有效。 十、Here文件（Here Documents） 格式： <<[-]word here-document delimiter 说明：指定shell从当前输入源中读入行直至遇到仅包含word的一行（word后面也不能有空白符），然后所有读入的内容（不包括最后一行）作为标准输入传递给指令。'-'的作用是将每一行前面的tab去除后再读入。需要注意的是这个word不会进行任何扩展，但是如果word中没有字符没引号扩起来，那么here-document中的内容可以进行参数扩展、指令替换以及算术扩展（parameterexpansion, command substitution, and arithmeticexpansion）；只要有任一字符被引号扩起来，delimiter仍是将去除引号的word，但是输入行不会进行任何扩展。 举例： $ cat <<EOF> $(pwd)     # 指令替换> `pwd`      # 指令替换的第2种形式> $HOME      # 参数扩展> $((4+5))   # 算数扩展> EOF/home/leo/home/leo/home/leo9$ cat <<\"EOF\"> $(ls)> `pwd`> $HOME> $((4+5))> EOF$(ls)`pwd`$HOME$((4+5)) 第一次没有将EOF用引号扩起来，三种扩展都能正常展开，而第二次用引号扩起来以后，原样输出。 十一、Here字符串（Here Strings） 格式：<<<word 说明：将扩展后的word作为标准输入传递给指令。 举例：使用这个功能可以将指令 echo 'something' |command 通过下面这种方式来实现 command <<<'something'。 参考资料： 1. Bash Reference Manual: http://www.gnu.org/software/bash/manual/bashref.html#Redirections 2. Bash One-Liners Explained, Part III: All about redirections: http://www.catonmat.net/blog/bash-one-liners-explained-part-three/","title":"Bash shell 重定向"},{"content":"linux命令行（十五） linux常用软件安装方式 1.rpm方式安装软件 命名规则 一般使用如下格式 packagename-version-arch.rpm packagename-version-arch.src.rpm packagename软件包名称 version带有主次和修订号的软件包版本 arch是指软件包要求的硬件平台 noarch指这样的软件一般不需要特定的软件平台 2.校验rpm包 命令rpm -Va 显示目前系统上面所有可能被更改过的文件 命令rpm -V 已安装的rpm包 显示指定软件包在安装后被改动大的情况 命令rpm -Vf 系统中的文件显示指定的文件在安装后是否被更改过 命令rpm -Vp rpm文件 显示指定软件包文件中被改动的文件 在使用rpm命令进行校验时会输出相关的信息 输出格式为SM5DLUGT c文件名 SM5DLUGT c文件名 中记录的信息含义如下 S:表示文件大小变化 M:表示权限发生变化 5：表示md5值发生变化 D：表示主从设备号发生变化 L：表示符号连接发生变化 U：表示所有者发生变化 G：表示所有组发生变化 missing：某些文件丢失、 . 文件没有发生变化 3.安装rpm包 使用rpm -i 命令安装rpm包，在安装时一般结合 -v查看详细安装信息 -h 显示安装进度   4.查询rpm包 rpm -q <软件名称> 查询指定的软件包是否安装 rpm -qa 显示系统中所有已安装的软件包 rpm -qa --last 会根据软件包安装到系统的时候显示 rpm -qi <软件名称> 显示详细信息 rpm -ql <软件名称> 显示已安装软件包的所有文件和目录 rpm -qR <软件名称> 显示已安装文件包的依赖关系 5.升级rpm包 -U 表示对已安装指定的软件包进行升级 -F 表示对已安装指定的软件包进行升级 如未安装 则不做任何处理 6.rpm包 -e 参考文献 《linux从入门到精通》 电子工业出版社","title":"linux命令行（十五）"},{"content":"gcc 提供了大量的警告选项，对代码中可能存在的问题提出警 告，通常可以使用-Wall来开启以下警告:             -Waddress -Warray-bounds (only with -O2) -Wc++0x-compat             -Wchar-subscripts -Wimplicit-int -Wimplicit-function-declaration             -Wcomment -Wformat -Wmain (only for C/ObjC and unless             -ffreestanding) -Wmissing-braces -Wnonnull -Wparentheses             -Wpointer-sign -Wreorder -Wreturn-type -Wsequence-point             -Wsign-compare (only in C++) -Wstrict-aliasing -Wstrict-overflow=1             -Wswitch -Wtrigraphs -Wuninitialized (only with -O1 and above)             -Wunknown-pragmas -Wunused-function -Wunused-label -Wunused-value             -Wunused-variable  unused-function:警告声明但是没有定义的static函数;  unused- label:声明但是未使用的标签;  unused-parameter:警告未使用的函数参数;  unused-variable:声明但 是未使用的本地变量;  unused-value:计算了但是未使用的值;  format:printf和scanf这样的函数中的格式字符 串的使用不当;  implicit-int:未指定类型;  implicit-function:函数在声明前使用;  char- subscripts:使用char类作为数组下标(因为char可能是有符号数);  missingbraces:大括号不匹配;  parentheses: 圆括号不匹配;  return-type:函数有无返回值以及返回值类型不匹配;  sequence-point:违反顺序点的代码,比如 a[i] = c[i++];  switch:switch语句缺少default或者switch使用枚举变量为索引时缺少某个变量的case;  strict- aliasing=n:使用n设置对指针变量指向的对象类型产生警告的限制程度,默认n=3;只有在-fstrict-aliasing设置的情况下有 效;  unknow-pragmas:使用未知的#pragma指令;  uninitialized:使用的变量为初始化,只在-O2时有 效;  以下是在-Wall中不会激活的警告选项:  cast-align:当指针进行类型转换后有内存对齐要求更严格时发出警告;  sign- compare:当使用signed和unsigned类型比较时;  missing-prototypes:当函数在使用前没有函数原型时;  packed:packed 是gcc的一个扩展,是使结构体各成员之间不留内存对齐所需的空 间 ,有时候会造成内存对齐的问题;  padded:也是gcc的扩展,使结构体成员之间进行内存对齐的填充,会 造成结构体体积增大.  unreachable-code:有不会执行的代码时.  inline:当inline函数不再保持inline时 (比如对inline函数取地址);  disable-optimization:当不能执行指定的优化时.(需要太多时间或系统 资源).  可以使用 -Werror时所有的警告都变成错误,使出现警告时也停止编译.需要和指定警告的参数一起使用.  优化:  gcc默认提供了5级优 化选项的集合:  -O0:无优化(默认)  -O和-O1:使用能减少目标文 件 大小以及执行时间并且不会使编译时间明显增加的优化.在编译大型程序的时候会显著增加编译时内存的使用.  -O2: 包含-O1的优化并增加了不需要在目标文件大小和执行速度上进行折衷的优化.编译器不执行循环展开以及函数内联.此选项将增加编译时间和目标文件的执行性 能.  -Os:专门优化目标文件大小,执行所有的不增加目标文件大小的-O2优化选项.并且执行专门减小目标文件大小的优化选项.  -O3: 打开所有-O2的优化选项并且增加 -finline-functions, -funswitch-loops,-fpredictive-commoning, -fgcse-after-reload and -ftree-vectorize优化选项.  -O1包含的选项-O1通常可以安全的和调试的选项一起使用:             -fauto-inc-dec -fcprop-registers -fdce -fdefer-pop -fdelayed-branch             -fdse -fguess-branch-probability -fif-conversion2 -fif-conversion             -finline-small-functions -fipa-pure-const -fipa-reference             -fmerge-constants -fsplit-wide-types -ftree-ccp -ftree-ch             -ftree-copyrename -ftree-dce -ftree-dominator-opts -ftree-dse             -ftree-fre -ftree-sra -ftree-ter -funit-at-a-time  以下所有的优化选项需要在名字 前加上-f,如果不需要此选项可以使用-fno-前缀  defer-pop:延迟到只在必要时从函数参数栈中pop参数;  thread- jumps:使用跳转线程优化,避免跳转到另一个跳转;  branch-probabilities:分支优化;  cprop- registers:使用寄存器之间copy-propagation传值;  guess-branch-probability:分支预测;  omit- frame-pointer:可能的情况下不产生栈帧;  -O2:以下是-O2在-O1基础上增加的优化选项:             -falign-functions  -falign-jumps -falign-loops  -falign-labels             -fcaller-saves -fcrossjumping -fcse-follow-jumps  -fcse-skip-blocks             -fdelete-null-pointer-checks -fexpensive-optimizations -fgcse             -fgcse-lm -foptimize-sibling-calls -fpeephole2 -fregmove             -freorder-blocks  -freorder-functions -frerun-cse-after-loop             -fsched-interblock  -fsched-spec -fschedule-insns             -fschedule-insns2 -fstrict-aliasing -fstrict-overflow -ftree-pre             -ftree-vrp  cpu架构的优化选项,通常是-mcpu(将被取消);-march,-mtune  Debug选项:  在 gcc编译源代码时指定-g选项可以产生带有调试信息的目标代码,gcc可以为多个不同平台上帝不同调试器提供调试信息,默认gcc产生的调试信息是为 gdb使用的,可以使用-gformat 指定要生成的调试信息的格式以提供给其他平台的其他调试器使用.常用的格式有  -ggdb:生成gdb专 用的调试信息,使用最适合的格式(DWARF 2,stabs等)会有一些gdb专用的扩展,可能造成其他调试器无法运行.  -gstabs:使用 stabs格式,不包含gdb扩展,stabs常用于BSD系统的DBX调试器.  -gcoff:产生COFF格式的调试信息,常用于System V下的SDB调试器;  -gxcoff:产生XCOFF格式的调试信息,用于IBM的RS/6000下的DBX调试器;  -gdwarf- 2:产生DWARF version2 的格式的调试信息,常用于IRIXX6上的DBX调试器.GCC会使用DWARF version3的一些特性.  可 以指定调试信息的等级:在指定的调试格式后面加上等级:  如: -ggdb2 等,0代表不产生调试信息.在使用-gdwarf-2时因为最早的格式为-gdwarf2会造成混乱,所以要额外使用一个-glevel来指定调试信息的 等级,其他格式选项也可以另外指定等级.  gcc可以使用-p选项指定生成信息以供porf使用. GCC常用选项 选项  含义 --help  --target-help  显示 gcc 帮助说明。‘target-help’是显示目标机器特定的命令行选项。 --version  显示 gcc 版本号和版权信息 。 -o outfile  输出到指定的文件。 -x language  指明使用的编程语言。允许的语言包括：c c++ assembler none 。 ‘none’意味着恢复默认行为，即根据文件的扩展名猜测源文件的语言。 -v  打印较多信息，显示编译器调用的程序。 -###  与 -v 类似，但选项被引号括住，并且不执行命令。 -E  仅作预处理，不进行编译、汇编和链接。如上图所示。 -S  仅编译到汇编语言，不进行汇编和链接。如上图所示。 -c  编译、汇编到目标代码，不进行链接。如上图所示。 -pipe  使用管道代替临时文件。 -combine  将多个源文件一次性传递给汇编器。 3 其他GCC选项 更多有用的GCC选项： 命令  描述 -l library  -llibrary  进行链接时搜索名为library的库。  例子： $ gcc test.c -lm -o test -Idir  把dir 加入到搜索头文件的路径列表中。  例子： $ gcc test.c -I../inc -o test -Ldir  把dir 加入到搜索库文件的路径列表中。  例子： $ gcc -I/home/foo -L/home/foo -ltest test.c -o test -Dname  预定义一个名为name 的宏，值为1。  例子： $ gcc -DTEST_CONFIG test.c -o test -Dname =definition  预定义名为name ，值为definition 的宏。 -ggdb  -ggdblevel  为调试器 gdb 生成调试信息。level 可以为1，2，3，默认值为2。 -g  -glevel  生成操作系统本地格式的调试信息。-g 和 -ggdb 并不太相同， -g 会生成 gdb 之外的信息。level 取值同上。 -s  去除可执行文件中的符号表和重定位信息。用于减小可执行文件的大小。 -M  告诉预处理器输出一个适合make的规则，用于描述各目标文件的依赖关系。对于每个 源文件，预处理器输出 一个make规则，该规则的目标项(target)是源文件对应的目标文件名，依赖项(dependency)是源文件中 `#include引用的所有文件。生成的规则可 以是单行，但如果太长，就用`\\'-换行符续成多行。规则 显示在标准输出，不产生预处理过的C程序。 -C  告诉预处理器不要丢弃注释。配合`-E'选项使用。 -P  告诉预处理器不要产生`#line'命令。配合`-E'选项使用。 -static  在支持动态链接的系统上，阻止连接共享库。该选项在其它系统上 无效。 -nostdlib  不连接系统标准启动文件和标准库文件，只把指定的文件传递给连接器。 Warnings -Wall  会打开一些很有用的警告选项，建议编译时加此选项。 -W  -Wextra  打印一些额外的警告信息。 -w  禁止显示所有警告信息。 -Wshadow  当一个局部变量遮盖住了另一个局部变量，或者全局变量时，给出警告。很有用的选项，建议打开。 -Wall 并不会打开此项。 -Wpointer-arith  对函数指针或者void *类型的指针进行算术操作时给出警告。也很有用。 -Wall 并不会打开此项。 -Wcast-qual  当强制转化丢掉了类型修饰符时给出警告。 -Wall 并不会打开此项。 -Waggregate-return  如果定义或调用了返回结构体或联合体的函数，编译器就发出警告。 -Winline  无论是声明为 inline 或者是指定了-finline-functions 选项，如果某函数不能内联，编译器都将发出警告。如果你的代码含有很多 inline 函数的话，这是很有用的选项。 -Werror  把警告当作错误。出现任何警告就放弃编译。 -Wunreachable-code  如果编译器探测到永远不会执行到的代码，就给出警告。也是比较有用的选项。 -Wcast-align  一旦某个指针类型强制转换导致目标所需的地址对齐增加时，编译器就发出警告。 -Wundef  当一个没有定义的符号出现在 #if 中时，给出警告。 -Wredundant-decls  如果在同一个可见域内某定义多次声明，编译器就发出警告，即使这些重复声明有效并且毫无差别。 Optimization -O0  禁止编译器进行优化。默认为此项。 -O  -O1  尝试优化编译时间和可执行文件大小。 -O2  更多的优化，会尝试几乎全部的优化功能，但不会进行“空间换时间”的优化方法。 -O3  在 -O2 的基础上再打开一些优化选项：-finline-functions， -funswitch-loops 和 -fgcse-after-reload 。 -Os  对生成文件大小进行优化。它会打开 -O2 开的全部选项，除了会那些增加文件大小的。 -finline-functions  把所有简单的函数内联进调用者。编译器会探索式地决定哪些函数足够简单，值得做这种内联。 -fstrict-aliasing  施加最强的别名规则（aliasing rules）。 Standard -ansi  支持符合ANSI标准的C程序。这样就会关闭GNU C中某些不兼容ANSI C的特性。 -std=c89  -iso9899:1990  指明使用标准 ISO C90 作为标准来编译程序。 -std=c99  -std=iso9899:1999  指明使用标准 ISO C99 作为标准来编译程序。 -std=c++98  指明使用标准 C++98 作为标准来编译程序。 -std=gnu9x  -std=gnu99  使用 ISO C99 再加上 GNU 的一些扩展。 -fno-asm  不把asm, inline或typeof当作关键字，因此这些词可以用做标识符。用 __asm__， __inline__和__typeof__能够替代它们。 `-ansi' 隐含声明了`-fno-asm'。 -fgnu89-inline  告诉编译器在 C99 模式下看到 inline 函数时使用传统的 GNU 句法。 C options -fsigned-char  -funsigned-char  把char定义为有/无符号类型，如同signed char/unsigned char。 -traditional  尝试支持传统C编译器的某些方面。详见GNU C手册。 -fno-builtin  -fno-builtin-function  不接受没有 __builtin_ 前缀的函数作为内建函数。 -trigraphs  支持ANSI C的三联符（ trigraphs）。`-ansi'选项隐含声明了此选项。 -fsigned-bitfields  -funsigned-bitfields  如果没有明确声明`signed'或`unsigned'修饰符，这些选项用来定义有符号位域或无符号位域。缺省情况下，位域是有符号的，因为它们继承的基本整数类型，如int，是有符号数。 -Wstrict-prototypes  如果函数的声明或定义没有指出参数类型，编译器就发出警告。很有用的警告。 -Wmissing-prototypes  如果没有预先声明就定义了全局函数，编译器就发出警告。即使函数定义自身提供了函数原形也会产生这个警告。这个选项 的目的是检查没有在头文件中声明的全局函数。 -Wnested-externs  如果某extern声明出现在函数内部，编译器就发出警告。 C++ options -ffor-scope  从头开始执行程序，也允许进行重定向。 -fno-rtti  关闭对 dynamic_cast 和 typeid 的支持。如果你不需要这些功能，关闭它会节省一些空间。 -Wctor-dtor-privacy  当一个类没有用时给出警告。因为构造函数和析构函数会被当作私有的。 -Wnon-virtual-dtor  当一个类有多态性，而又没有虚析构函数时，发出警告。-Wall会开启这个选项。 -Wreorder  如果代码中的成员变量的初始化顺序和它们实际执行时初始化顺序不一致，给出警告。 -Wno-deprecated  使用过时的特性时不要给出警告。 -Woverloaded-virtual  如果函数的声明隐藏住了基类的虚函数，就给出警告。 Machine Dependent Options (Intel) -mtune=cpu-type  为指定类型的 CPU 生成代码。cpu-type 可以是：i386，i486，i586，pentium，i686，pentium4 等等。 -msse  -msse2  -mmmx  -mno-sse  -mno-sse2  -mno-mmx  使用或者不使用MMX，SSE，SSE2指令。 -m32  -m64  生成32位/64位机器上的代码。 -mpush-args  -mno-push-args  （不）使用 push 指令来进行存储参数。默认是使用。 -mregparm=num  当传递整数参数时，控制所使用寄存器的个数。","title":"gcc命令"},{"content":"（据说windows自己也有不错的shell，叫做powershell， http://www.microsoft.com/en-us/download/confirmation.aspx?id=16818） 假如你用惯了linux，那你很有可能跟我一样，是被一堆个头不大，却是精明能干的小工具所吸引的：im, ssh, perl, grep, agrep, fgrep, sed, wget, agrep, unzip, cp, mv, rm （我常用的，也就这些）……这些工具在windows不是不存在，只是有的工具加上了gui界面，个头太大；有的改成了彻头彻尾的windows版。这一切，让人感觉，不爽。 可是，你值得安装一整套cygwin么？你有必要安装虚拟机么？当然没必要。本文要介绍的，是一组小巧的实现方案：UnxUtils。自14-04-2003年4月14日之后，它有了升级版本，但是仍然都是03年、04年的作品。只要你需要，就不妨拿来用，不要因为它陈旧而轻视它的实用性。 下载UnxUtils以及UnxUpdates之后，解压到自己中意的文件夹，把/usr/local/wbin文件夹的绝对地址加到 我的电脑(右键)->属性->高级->环境变量->系统变量->path值 注意，在所加的地址之前，应该有个分号“;”以示区分。这样，你随时随地就能打开一个”cmd”console，使用如下工具： agrep.exe ansi2knr.exe basename.exe bc.exe bison.exe bunzip2.exe bzip2.exe bzip2recover.exe cat.exe chgrp.exe chmod.exe chown.exe cksum.exe cmp.exe comm.exe compress.exe cp.exe csplit.exe cut.exe date.exe dc.exe dd.exe df.exe diff.exe diff3.exe dircolors.exe dirname.exe du.exe echo.exe egrep.exe env.exe expand.exe expr.exe factor.exe fgrep.exe find.exe flex.exe fmt.exe fold.exe fsplit.exe gawk.exe gclip.exe gplay.exe grep.exe gsar.exe gunzip.exe gzip.exe head.exe id.exe indent.exe install.exe join.exe jwhois.exe less.exe lesskey.exe ln.exe logname.exe ls.exe m4.exe make.exe makedepend.exe makemsg.exe man.exe md5sum.exe mkdir.exe mkfifo.exe mknod.exe mv.exe mvdir.exe nl.exe od.exe paste.exe patch.exe pathchk.exe pclip.exe pr.exe printenv.exe printf.exe ptx.exe pwd.exe recode.exe rm.exe rman.exe rmdir.exe sdiff.exe sed.exe seq.exe sh.exe sha1sum.exe shar.exe sleep.exe sort.exe split.exe stego.exe su.exe sum.exe sync.exe tac.exe tail.exe tar.exe tee.exe test.exe touch.exe tr.exe tsort.exe type.exe uname.exe unexpand.exe uniq.exe unrar.exe unshar.exe unzip.exe uudecode.exe uuencode.exe wc.exe wget.exe which.exe whoami.exe xargs.exe yes.exe zcat.exe zip.exe zsh.exe http://en.wikipedia.org/wiki/UnxUtils","title":"windows下的unix工具集：UnxUtils"},{"content":"学校给我的既定方向是电子商务！但是我不断尝试，我以后要做的是软硬件整合！最终我决定学拥抱嵌入式，拥抱Linux。但是我这个文科出生，高数基础差，物理电路基础几乎没有，并且我的老师告知我：不可以换方向。看样子，我得狠下功夫自学了。但我有不知道从何入手。上网查了下，众说纷纭，目前正在请教学长。请CSDN中做嵌入式的前辈能够在百忙之中抽空给些建议（对于嵌入式我是毫无基础的！并且我的数学和物理功底也差，恐怕我有的只是颗真心学习嵌入式 的心）！","title":"决定拥抱嵌入式"},{"content":"centos使用本地光盘或iso直接做源 分类： linux应用2012-10-01 09:47 128人阅读 评论(0) 收藏 举报 本地yum源设置，将yum源设置成本地RHEL镜像里面的Server，这样使用yum的时候就可以直接调用这里面的rpm， 1、挂载DVD镜像，并将命令写入/etc/rc.d/rc.local自启动 mkdir /media/RHELDVD mount -t iso9660 /dev/hdc /media/RHELDVD 2、修改yum源 cd /etc/repos.d vi rhel-debuginfo.repo 将baseurl修改为file:///media/RHELDVD/Server [rhel-debuginfo] name=Red Hat Enterprise Linux baseurl=file:///media/RHELDVD/Server enabled=1 gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release 保存之后，运行yum clean all，之后就可以使用本地yum源来进行更新了 本地yum源设置，将yum源设置成本地RHEL镜像里面的Server，这样使用yum的时候就可以直接调用这里面的rpm， 1、挂载DVD镜像，并将命令写入/etc/rc.d/rc.local自启动 mkdir /media/RHELDVD mount -t iso9660 /dev/hdc /media/RHELDVD 2、修改yum源 cd /etc/repos.d vi rhel-debuginfo.repo 将baseurl修改为file:///media/RHELDVD/Server [rhel-debuginfo] name=Red Hat Enterprise Linux baseurl=file:///media/RHELDVD/Server enabled=1 gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-redhat-release 保存之后，运行yum clean all，之后就可以使用本地yum源来进行更新了","title":"centos使用本地光盘或iso直接做源 centos使用本地光盘或iso直接做源"},{"content":"原文链接：http://blog.csdn.net/huyiyang2010/article/details/7815491 在Linux命令行中执行top命令，可以查询到所有进程使用的VIRT虚拟内存、RES常驻内存和共享内存SHR。 那么，什么是VIRT虚拟内存、RES常驻内存和共享内存SHR？我们编写的Linux C++程序如何影响它们呢？ 查阅资料后，归纳一下。 VIRT： 1、进程“需要的”虚拟内存大小，包括进程使用的库、代码、数据，以及malloc、new分配的堆空间和分配的栈空间等； 2、假如进程新申请10MB的内存，但实际只使用了1MB，那么它会增长10MB，而不是实际的1MB使用量。 3、VIRT = SWAP + RES RES： 1、进程当前使用的内存大小，包括使用中的malloc、new分配的堆空间和分配的栈空间，但不包括swap out量； 2、包含其他进程的共享； 3、如果申请10MB的内存，实际使用1MB，它只增长1MB，与VIRT相反； 4、关于库占用内存的情况，它只统计加载的库文件所占内存大小。 5、RES = CODE + DATA SHR： 1、除了自身进程的共享内存，也包括其他进程的共享内存； 2、虽然进程只使用了几个共享库的函数，但它包含了整个共享库的大小； 3、计算某个进程所占的物理内存大小公式：RES – SHR； 4、swap out后，它将会降下来。 测试如下： 一） [cpp] view plaincopy #include <iostream>      int main()   {       char * p = new char [1024*1024*512];       getchar();       return 0;   }   top结果如下：   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND 401 huyiyang  17   0  523m  916  792 S  0.0  0.0   0:00.00 ./main VIRT包含了new出来的512MB空间，但是RES不包含该空间。即刚new出来的空间，如果没有使用，会放入SWAP中，并不在内容中真实的分配物理内存。 二） [cpp] view plaincopy #include <iostream>      int main()   {       char * p = new char [1024*1024*512];       memset(p, 0, 1024*1024*512);       getchar();       return 0;   }   top结果如下： PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                                                               32604 huyiyang  17   0  523m 512m  792 S  0.0 26.2   0:00.33 ./main VIRT包含new出来的512MB空间，RES包含目前使用的memset的512M空间。即new出来的空间被使用后，会真实分配物理内存。 三） [cpp] view plaincopy #include <iostream>      int main()   {       char * p = new char [1024*1024*512];       memset(p + 1024*1024*128, 0, 1024*1024*128);       getchar();       return 0;   }   top结果如下： PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND  456 huyiyang  17   0  523m 128m  792 S  0.0  6.6   0:00.07 ./main VIRT包含new出来的512MB空间，RES包含目前使用的memset的128M空间。即new出来的空间，如果只使用部分，则只分配部分物理内存。 四） [cpp] view plaincopy #include <iostream>      int main()   {       char p[1024*1024*10];       getchar();       return 0;   }   top结果如下： PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND 544 huyiyang  17   0 21568  884  760 S  0.0  0.0   0:00.00 ./main 没有使用的栈空间，VIRT会包含（没有使用的栈空间会在SWAP中）。 五） [cpp] view plaincopy #include <iostream>      int main()   {       char p[1024*1024*10];       memset(p, 0, 1024*1024*10);       getchar();       return 0;   }   top结果如下： PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND   561 huyiyang  17   0 21568  10m  760 S  0.0  0.6   0:00.00 ./main 已经使用的栈空间，VIRT和RES都会包含。 六） [cpp] view plaincopy #include <iostream>      int main()   {       char ** pp = new char * [1024];       for(int i=0;i<1024;i++)       {           pp[i] = new char [1024*1024*512];           memset(pp[i], 0, 1024*1024*512);           printf(\"p%d\\n\", i);           getchar();       }       return 0;   }   第一个循环时：   PID USER       PR  NI  VIRT    RES   SHR S %CPU %MEM    TIME+  SWAP COMMAND  3627 huyiyang  18   0  523m 512m  836   S       0.0        26.2    0:00.34  10m ./main 第二个循环时：   PID USER       PR  NI  VIRT    RES   SHR S %CPU %MEM    TIME+  SWAP COMMAND  3627 huyiyang  18   0 1035m 1.0g  836    S     0.0      52.4      0:00.69  10m     ./main 第三个循环时：   PID   USER      PR  NI  VIRT   RES  SHR S %CPU %MEM    TIME+  SWAP COMMAND                                                                                                           3627 huyiyang  18   0 1547m 1.5g    836 S     0.0       78.5   0:01.03    10m     ./main 在我的服务器上，当执行到第四个循环时，并且有其他程序占用较大内存的情况下，top结果如下：   PID USER       PR  NI  VIRT    RES   SHR S %CPU %MEM    TIME+  SWAP COMMAND   3427 huyiyang  16   0 2059m 711m  836 S  0.0        36.4       0:01.45 1.3g     ./main 出现了swap out的情况。","title":"编写Linux C++程序如何影响VIRT（虚存）和RES（实存/常驻内存）"},{"content":"Android初始化语言由四大类声明组成:行为类(Actions),命令类(Commands)，服务类(Services),选项类(Options).   * 初始化语言以行为单位，由以空格间隔的语言符号组成。C风格的反斜杠转义符可以用来插入空白到语言符号。双引号也可以用来防止文本被空格分成多个语言符号。当反斜杠在行末时，作为折行符。   * 以#开始(前面允许有空格)的行为注释行。   * Actions和Services隐含声明一个新的段落。所有该段落下Commands或Options的声明属于该段落。第一段落前的Commands或Options被忽略。   * Actions和Services拥有独一无二的命名。在它们之后声明相同命名的类将被当作错误并忽略。 Actions ------- Actions是一系列命令的命名。Actions拥有一个触发器(trigger)用来决定action何时执行。当一个action在符合触发条件被执行时，如果它还没被加入到待执行队列中的话，则加入到队列最后。 队列中的action依次执行，action中的命令也依次执行。Init在执行命令的中间处理其它活动(设备创建/销毁,property设置，进程重启)。 Actions表现形式为： on <trigger>    <command>    <command>    <command>   Services -------- Services是由init启动，在它们退出时重启(可选)。Service表现形式为: service <name> <pathname> [ <argument> ]*    <option>    <option>    ...    Options ------- Options是Services的修饰，它们影响init何时、如何运行service.   critical      这是一个设备关键服务(device-critical service) .如果它在4分钟内退出超过4次，设备将重启并进入恢复模式。   disabled      这个服务的级别将不会自动启动，它必须被依照服务名指定启动才可以启动。   setenv <name> <value>      设置已启动的进程的环境变量<name>的值<value>   socket <name> <type> <perm> [ <user> [ <group> ] ]      创建一个名为/dev/socket/<name>的unix domin socket，并传送它的fd到已启动的进程。<type>必须为\"dgram\"或\"stream\".用户和组默认为0.   user <username>      在执行服务前改变用户名。当前默认为root.如果你的进程需要linux能力，你不能使用这个命令。你必须在还是root时请求能力，并下降到你需要的uid.   group <groupname> [ <groupname> ]*      在执行服务前改变组。在第一个组后的组将设为进程附加组(通过setgroups()).当前默认为root.   oneshot      在服务退出后不重启。   class <name>      为service指定一个类别名。同样类名的所有的服务可以一起启动或停止。如果没有指定类别的服务默认为\"default\"类。   onrestart        当服务重启时执行一个命令。   Triggers --------      Triggers(触发器)是一个字符串，可以用来匹配某种类型的事件并执行一个action。   boot      这是当init开始后执行的第一个触发器(当/init.conf被加载)   <name>=<value>      当property <name>被设为指定的值<value>时触发。   device-added-<path> device-removed-<path>      当设备节点被添加或移除时触发。   service-exited-<name>      当指定的服务存在时触发     Commands --------   exec <path> [ <argument> ]*      Fork并执行一个程序(<path>).这将被block直到程序执行完毕。最好避免执行例如内建命令以外的程序，它可能会导致init被阻塞不动。   export <name> <value>      设定全局环境变量<name>的值<value>，当这个命令执行后所有的进程都可以取得。   ifup <interface>      使网络接口<interface>联机。   import <filename>      解析一个init配置文件，扩展当前配置文件。   hostname <name>      设置主机名   chmod <octal-mode> <path>      改变文件访问权限   chown <owner> <group> <path>      改变文件所属和组   class_start <serviceclass>      当指定类别的服务没有运行，启动该类别所有的服务。   class_stop <serviceclass>      当指定类别的服务正在运行，停止该类别所有的服务。   domainname <name>      设置域名。   insmod <path>      加载该路径<path>的模块   mkdir <path> [mode] [owner] [group]      在<path>创建一个目录,可选选项:mod,owner,group.如果没有指定，目录以755权限，owner为root,group为root创建.   mount <type> <device> <dir> [ <mountoption> ]*      尝试mount <device>到目录<dir>. <device>可以用mtd@name格式以命名指定一个mtd块设备。<mountoption>包含\"ro\",\"rw\",\"remount\",\"noatime\".   setkey      暂时没有   setprop <name> <value>      设置系统property <name>的值<value>.   setrlimit <resource> <cur> <max>      设置resource的rlimit.   start <service>      启动一个没有运行的服务。   stop <service>      停止一个正在运行的服务。   symlink <target> <path>      创建一个<path>的符号链接到<target>   sysclktz <mins_west_of_gmt>      设置系统时区(GMT为0)   trigger <event>      触发一个事件。用于调用其它action。   write <path> <string> [ <string> ]*      打开<path>的文件并写入一个或多个字符串。     Properties ---------- Init会更新一些系统property以提供查看它正在干嘛。 init.action      当前正在执行的action,如果没有则为\"\"   init.command      被执行的命令，如果没有则为\"\"   init.svc.<name>      命名为<name>的服务的状态(\"stopped\", \"running\", \"restarting\")     init.rc 示例: -----------------   # not complete -- just providing some examples of usage # on boot    export PATH /sbin:/system/sbin:/system/bin    export LD_LIBRARY_PATH /system/lib      mkdir /dev    mkdir /proc    mkdir /sys      mount tmpfs tmpfs /dev    mkdir /dev/pts    mkdir /dev/socket    mount devpts devpts /dev/pts    mount proc proc /proc    mount sysfs sysfs /sys      write /proc/cpu/alignment 4      ifup lo      hostname localhost    domainname localhost      mount yaffs2 mtd@system /system    mount yaffs2 mtd@userdata /data      import /system/etc/init.conf      class_start default   service adbd /sbin/adbd    user adb    group adb   service usbd /system/bin/usbd -r    user usbd    group usbd    socket usbd 666   service zygote /system/bin/app_process -Xzygote /system/bin --zygote    socket zygote 666   service runtime /system/bin/runtime    user system    group system   on device-added-/dev/compass    start akmd   on device-removed-/dev/compass    stop akmd   service akmd /sbin/akmd    disabled    user akmd    group akmd   调试 --------------- 默认情况下，init执行的程序输出的信息和错误到/dev/null.为了debug，你可以通过Android程序logwrapper执行你的程序。这将复位向输出/错误输出到Android logging系统(通过logcat访问)。 例如 service akmd /system/bin/logwrapper /sbin/akmd","title":"Android init.rc解析"},{"content":"FLCK、HCLK和PCLK的关系 S3C2440有三个时钟FLCK、HCLK和PCLK s3c2440官方手册上说P7-8写到： FCLK is used by ARM920T，内核时钟，主频。 HCLK is used for AHB bus, which is used by the ARM920T, the memory controller, the interrupt controller, the LCD controller, the DMA and USB host block. 也就是总线时钟，包括USB时钟。 PCLK is used for APB bus, which is used by the peripherals such as WDT, IIS, I2C, PWM timer, MMC interface,ADC, UART, GPIO, RTC and SPI.即IO接口时钟，例如串口的时钟设置就是从PCLK来的； 那么这三个时钟是什么关系呢？ 这三个时钟通常设置为1:4:8，1:3:6的分频关系，也就说如果主频FLCK是400MHz，按照1:4:8的设置，那么HLCK是100MHz，PLCK是50MHz 寄存器CLKDIVN表明并设置了这三个时钟的关系     如果CLKDIVN设置为0x5,那么比例即为1:4:8，前提是CAMDIVN[9]为0. 2）输入时钟FIN与主频FCLK的关系 现代的CPU基本上都使用了比主频低的多的时钟输入，在CPU内部使用锁相环进行倍频。对于S3C2440，常用的输入时钟FIN有两种：12MHz和16.9344MHz，那么CPU是如何将FIN倍频为FCLK的呢？ S3C2440使用了三个倍频因子MDIV、PDIV和SDIV来设置将FIN倍频为MPLL，也就是FCLK MPLL=(2*m*FIN)/(p*2^s) where m=(MDIV+8), p=(PDIV+2), s=SDIV 寄存器MPLLCON就是用来设置倍频因子的     理论上，你可以通过设置该寄存器来实现不同的频率，然而，由于实际存在的各种约束关系，设置一个适当的频率并不容易，手册上列出了一些常用频率的表格，   例如，假设输入时钟FIN=16.9344M，MDIV=110, PDIV=3, SDIV=1， 利用上面的公式，FCLK=2*16.9344*(110+8)/((2+3)*2)=399.65","title":"ARM9 S3C2440 FCLK,HCLK,PCLK时钟的关系"},{"content":"linux下安装apache有两种方式：1.yum安装方式  2.源码编译的方式 yum安装apache服务 yum -y install httpd* service httpd start #启动apache服务 service httpd stop #关闭apache服务 service httpd restart #重启apache服务 service httpd reload #重新加载 service httpd status #查看状态 chkconfig httpd on #设置开机启动 chkconfig httpd on #设置开机不启动 chkconfig httpd --level 35 on #设置在3、5上开机启动 修改selinux的状态 vi /etc/selinux/config SELINUX=disabled","title":"linux下安装apache"},{"content":"1、总体介绍 　　该DM9000是一款完全集成的和符合成本效益单芯片快速以太网MAC控制器与一般处理接口，一个10/100M自适应的PHY和4K DWORD值的SRAM 。它的目的是在低功耗和高性能进程的3.3V与5V的支持宽容。 　　DM9000还提供了介质无关的接口，来连接所有提供支持介质无关接口功能的家用电话线网络设备或其他收发器。该DM9000支持8位， 16位和32 -位接口访问内部存储器，以支持不同的处理器。DM9000物理协议层接口完全支持使用10MBps下3类、4类、5类非屏蔽双绞线和100MBps下5类非屏蔽双绞线。这是完全符合IEEE 802.3u规格。它的自动协调功能将自动完成配置以最大限度地适合其线路带宽。还支持IEEE 802.3x全双工流量控制。这个工作里面DM9000是非常简单的，所以用户可以容易的移植任何系统下的端口驱动程序。 2、特点 　　支持处理器读写内部存储器的数据操作命令以 字节/ 字/ 双字的长度进行 　　集成10/100M自适应收发器 　　支持介质无关接口 　　支持背压模式半双工流量控制模式 　　IEEE802.3x流量控制的全双工模式 　　支持唤醒帧，链路状态改变和远程的唤醒 　　4K双字SRAM 　　支持自动加载EEPROM里面生产商ID和产品ID 　　支持4个通用输入输出口 　　超低功耗模式 　　功率降低模式 　　电源故障模式 　　可选择1：1或5：4变压比例的变压器降低格外功率 　　兼容3.3v和5.0v输入输出电压 　　100脚CMOS LQFP封装工艺 3、引脚描述 　　I=输入 O=输出 I/O=输入/输出 O/D=漏极开路 P=电源 LI=复位锁存输入 #=普遍低电位 　　介质无关接口引脚 引脚号 引脚名 I/O 功能描述 37 LINK_I I 外部介质无关接口器件连接状态 38、39、40、41 RXD [3:0] I 外部介质无关接口接收数据 　　4位 半字节输入（同步于接收时钟） 43 CRS I/O 外部介质无关接口的载波检测 44 COL I/O 外部介质无关接口的冲突检测，输出到外部设备 45 RX_DV I 外部介质无关接口数据有效信号 46 RX_ER I 外部介质无关接口接收错误 47 RX_CLK I 外部介质无关接口接收时钟 49 TX_CLK I/O 外部介质无关接口发送时钟 50～53 TXD[3:0] O 外部介质无关接口发送数据低4位输出 　　TXD[2:0]决定内部存储空间基址：TXD [2:0]) * 10H + 300H 54 MDIO I/O 外部介质无关接口串行数据通信 57 MDC O 外部介质无关串行数据通信口时钟，且与中断引脚有关 　　该引脚高电平时候，中断引脚低电平有效；否则高有效 注意：以上介质无关端口都内部自带60K 欧姆的下拉电阻 　　处理器接口引脚 1 IOR# I 处理器读命令 　　低电平有效，极性能够被EEPROM修改，详细请参考对EEPROM内容的描述 2 IOW# I 处理器写命令 　　低电平有效，同样能修改极性 3 AEN# I 芯片选择，低电平有效 4 IOWAIT O 处理器命令就绪 　　当上一指令没有结束，该引脚电平拉低表示当前指令需要等待 14 RST I 硬件复位信号，高电平有效复位 1~6 82~89 SD0~15 I/O 0~15位的数据地址复用总线,由CMD引脚决定当期访问类型 93~98 SA4~9 I 地址线4~9；仅作芯片选择信号 　　(SA4~9：TXD0~2 ，011)被选中 92 CMD I 访问类型 　　高电平是访问数据端口；低电平是访问地址端口 91 IO16 O 字命令标志，默认低电平有效 　　当访问外部数据存储器是字或双字宽度时，被置位 100 INT O 中断请求信号 　　高电平有效，极性能修改 37~53 56 SD31~16 I/O 双字模式，高16位数据引脚 57 IO32 O 双字命令标志，默认低电平有效 注意：以上引脚除去SD8,SD9和IO16，都内部自带60K 欧姆的下拉电阻 　　EEPROM引脚 64 EEDI I 数据输入引脚 65 EEDO I/O EEPROM数据引脚 　　与WAKEUP引脚一起定义访问数据存储器的总线宽度 　　WAKEUP EEDO 总线宽度 　　0 0 16位 　　0 1 32位 　　1 0 8位 　　1 1 未定义 66 EECK I 时钟信号 67 EECS I/O 片选 　　也做LED模式选择引脚 　　高电平时，LED模式1，否则模式0 注意：EECS EECK EEDO引脚都内部自带60K欧姆下拉电阻 　　时钟引脚 21 X2_25M O 25M晶振输出 22 X1_25M I 25M晶振输入 59 CLK20MO O 20M晶振再生输出给外部介质无关设备，自带60K欧姆下拉电阻   　　LED引脚 60 SPEED100# O 低电平指示100M带宽指示，高电平指示10M带宽 61 DUP# O 全双工指示LED 　　LED模式0时，低电平显示工作在10M带宽，或在100M带宽浮动 62 LINK&ACT# O 连接LED，在模式0时，只作物理层的载波监听检测连接状态   　　10/100 物理层与光纤接口 24 SD I 光纤信号检测 　　PECL电平信号，显示光纤接收是否有效 25 DGGND P 带隙地信号线 26 BGRES I/O 带隙引脚 27 AVDD P 带隙与电源保护环 28 AVDD P 接收端口电源 29 RXI+ I 物理层接收端的正极 30 RXI- I 物理层接收端的负极 31 AGND P 接收端口地 32 AGND P 发送端口地 33 TXO+ O 物理层发送端口正极 34 TXO- O 发送端口负极 35 AVDD P 物理层发送端口负极   　　各种其他功能引脚 16~19 TEST1~4 I 工作模式 　　Test1~4(1,1,0,0)正常工作状态 48 TEST5 I 必须接地 68~69 GPIO0~3 I/O 通用I/O端口 　　通用端口控制寄存器和通用端口寄存器能编程该系列引脚 　　GPIO0默认输出为高来关闭物理层和其他外部介质无关器件 　　GPIO1~3默认为输入引脚 78 LINK_O O 电缆连接状态显示输出，高电平有效 79 WAKEUP O 流出一个唤醒信号当唤醒事件发生 　　内置60K欧姆的下拉电阻 80 PW_RST# I 上电复位 　　低电平激活DM9000的重新初始化，5us后初始化当该引脚测试到电平变化 74，75，77 NC   无用   　　电源引脚 5,20,36,55, 　　72,90,73 DVDD P 数字电源 15,23,42,58 　　63,81,99,76 DGND P 数字地   　　内部寄存器 　　DM9000（A）包含一系列可被访问的控制状态寄存器，这些寄存器是字节对齐的，他们在硬件或软件复位时被设置成初始值。 　　以下为DM9000的寄存器功能详解： 　　NCR （00H）：网络控制寄存器（Network Control Register ） 　　7：EXT_PHY：1选择外部PHY，0选择内部PHY，不受软件复位影响。 　　6：WAKEEN：事件唤醒使能，1使能，0禁止并清除事件唤醒状态，不受软件复位影响。 　　5：保留。 　　4：FCOL：1强制冲突模式，用于用户测试。 　　3：FDX：全双工模式。内部PHY模式下只读，外部PHY下可读写。 　　2-1：LBK：回环模式（Loopback）00通常，01MAC内部回环，10内部PHY 100M模式数字回环，11保留。 　　0：RST：1软件复位，10us后自动清零。 　　NSR （01H）：网络状态寄存器（Network Status Register ） 　　7：SPEED：媒介速度，在内部PHY模式下，0为100Mbps，1为10Mbps。当LINKST=0时，此位不用。 　　6：LINKST：连接状态，在内部PHY模式下，0为连接失败，1为已连接。 　　5：WAKEST：唤醒事件状态。读取或写1将清零该位。不受软件复位影响。 　　4：保留。 　　3：TX2END：TX（发送）数据包2完成标志，读取或写1将清零该位。数据包指针2传输完成。 　　2：TX2END：TX（发送）数据包1完成标志，读取或写1将清零该位。数据包指针1传输完成。 　　1：RXOV：RX（接收）FIFO（先进先出缓存）溢出标志。 　　0：保留。 　　TCR（02H）：发送控制寄存器（TX Control Register） 　　7：保留。 　　6：TJDIS：Jabber传输使能。1使能Jabber传输定时器（2048字节），0禁止。 　　注释：Jabber是一个有CRC错误的长帧（大于1518byte而小于6000byte）或是数据包重组错误。原因：它可能导致网络丢包。多是由于作站有硬件或软件错误。 　　5：EXCECM：额外冲突模式控制。0当额外的冲突计数多于15则终止本次数据包，1始终尝试发发送本次数据包。 　　4：PAD_DIS2：禁止为数据包指针2添加PAD。 　　3：CRC_DIS2：禁止为数据包指针2添加CRC校验。 　　2：PAD_DIS2：禁止为数据包指针1添加PAD。 　　1：CRC_DIS2：禁止为数据包指针1添加CRC校验。 　　0：TXREQ：TX（发送）请求。发送完成后自动清零该位。 　　TSR_I（03H）：数据包指针1的发送状态寄存器1（TX Status Register I） 　　7：TJTO：Jabber传输超时。该位置位表示由于多于2048字节数据被传输而导致数据帧被截掉。 　　6：LC：载波信号丢失。该位置位表示在帧传输时发生红载波信号丢失。在内部回环模式下该位无效。 　　5：NC：无载波信号。该位置位表示在帧传输时无载波信号。在内部回环模式下该位无效。 　　4：LC：冲突延迟。该位置位表示在64字节的冲突窗口后又发生冲突。 　　3：COL：数据包冲突。该位置位表示传输过程中发生冲突。 　　2：EC：额外冲突。该位置位表示由于发生了第16次冲突（即额外冲突）后，传送被终止。 　　1-0：保留。 　　TSR_II（04H）：数据包指针2的发送状态寄存器2（TX Status Register II） 　　同TSR_I 　　略。 　　RCR（05H）：接收控制寄存器（RX Control Register ） 　　7：保留。 　　6：WTDIS：看门狗定时器禁止。1禁止，0使能。 　　5：DIS_LONG：丢弃长数据包。1为丢弃数据包长度超过1522字节的数据包。 　　4：DIS_CRC：丢弃CRC校验错误的数据包。 　　3：ALL：忽略所有多点传送。 　　2：RUNT：忽略不完整的数据包。 　　1：PRMSC：混杂模式（Promiscuous Mode） 　　0：RXEN：接收使能。 　　RSR（06H）：接收状态寄存器（RX Status Register ） 　　7：RF：不完整数据帧。该位置位表示接收到小于64字节的帧。 　　6：MF：多点传送帧。该位置位表示接收到帧包含多点传送地址。 　　5：LCS：冲突延迟。该位置位表示在帧接收过程中发生冲突延迟。 　　4：RWTO：接收看门狗定时溢出。该位置位表示接收到大于2048字节数据帧。 　　3：PLE：物理层错误。该位置位表示在帧接收过程中发生物理层错误。 　　2：AE：对齐错误（Alignment）。该位置位表示接收到的帧结尾处不是字节对齐，即不是以字节为边界对齐。 　　1：CE：CRC校验错误。该位置位表示接收到的帧CRC校验错误。 　　0：FOE：接收FIFO缓存溢出。该位置位表示在帧接收时发生FIFO溢出。 　　ROCR（07H）：接收溢出计数寄存器（Receive Overflow Counter Register） 　　7：RXFU：接收溢出计数器溢出。该位置位表示ROC（接收溢出计数器）发生溢出。 　　6-0：ROC：接收溢出计数器。该计数器为静态计数器，指示FIFO溢出后，当前接收溢出包的个数。 　　BPTR（08H）：背压门限寄存器（Back Pressure Threshold Register） 　　7-4：BPHW：背压门限最高值。当接收SRAM空闲空间低于该门限值，则MAC将产生一个拥挤状态。1=1K字节。默认值为3H，即3K字节空闲空间。不要超过SRAM大小。 　　3-0：JPT：拥挤状态时间。默认为200us。0000 为5us，0001为10us，0010为15us，0011为25us，0100为50us，0101为100us，0110为150us，0111为 200us，1000为250us，1001为300us，1010为350us，1011为400us，1100为450us，1101为500us， 1110为550us，1111为600us。 　　FCTR（09H）：溢出控制门限寄存器（Flow Control Threshold Register）  　　7-4：HWOT：接收FIFO缓存溢出门限最高值。当接收SRAM空闲空间小于该门限值，则发送一个暂停时间（pause_time）为FFFFH的暂停包。若该值为0，则无接收空闲空间。1=1K字节。默认值为3H，即3K字节空闲空间。不要超过SRAM大小。 　　3-0：LWOT：接收FIFO缓存溢出门限最低值。当接收SRAM空闲空间大于该门限值，则 发送一个暂停时间（pause_time）为0000H的暂停包。当溢出门限最高值的暂停包发送之后，溢出门限最低值的暂停包才有效。默认值为8K字节。 不要超过SRAM大小。 　　RTFCR（0AH）：接收/发送溢出控制寄存器（RX/TX Flow Control Register） 　　7：TXP0：1发送暂停包。发送完成后自动清零，并设置TX暂停包时间为0000H。 　　6：TXPF：1发送暂停包。发送完成后自动清零，并设置TX暂停包时间为FFFFH。 　　5：TXPEN：强制发送暂停包使能。按溢出门限最高值使能发送暂停包。 　　4：BKPA：背压模式。该模式仅在半双工模式下有效。当接收SRAM超过BPHW并且接收新数据包时，产生一个拥挤状态。 　　3：BKPM：背压模式。该模式仅在半双工模式下有效。当接收SRAM超过BPHW并数据包DA匹配时，产生一个拥挤状态。 　　2：RXPS：接收暂停包状态。只读清零允许。 　　1：RXPCS：接收暂停包当前状态。 　　0：FLCE：溢出控制使能。1设置使能溢出控制模式。 　　EPCR/PHY_CR（0BH）：EEPROM和PHY控制寄存器（EEPROM & PHY Control Register） 　　7-6：保留。 　　5：REEP：重新加载EEPROM。驱动程序需要在该操作完成后清零该位。 　　4：WEP：EEPROM写使能。 　　3：EPOS：EEPROM或PHY操作选择位。0选择EEPROM，1选择PHY。 　　2：ERPRR：EEPROM读，或PHY寄存器读命令。驱动程序需要在该操作完成后清零该位。 　　1：ERPRW：EEPROM写，或PHY寄存器写命令。驱动程序需要在该操作完成后清零该位。 　　0：ERRE：EEPROM或PHY的访问状态。1表示EEPROM或PHY正在被访问。 　　EPAR/PHY_AR（0CH）：EEPROM或PHY地址寄存器（EEPROM & PHY Address Register） 　　7-6：PHY_ADR：PHY地址的低两位（bit1，bit0），而PHY地址的bit[4:2]强制为000。如果要选择内部PHY，那么此2位强制为01，实际应用中要强制为01。 　　5-0：EROA：EEPROM字地址或PHY寄存器地址。 　　EPDRL/PHY_DRL（0DH）：EEPROM或PHY数据寄存器低半字节（EEPROM & PHY Low Byte Data Register） 　　7-0：EE_PHY_L 　　EPDRL/PHY_DRH（0EH）：EEPROM或PHY数据寄存器高半字节（EEPROM & PHY High Byte Data Register） 　　7-0：EE_PHY_H 　　WUCR（0FH）：唤醒控制寄存器（Wake Up Control Register） 　　7-6：保留。 　　5：LINKEN：1使能“连接状态改变”唤醒事件。该位不受软件复位影响。 　　4：SAMPLEEN：1使能“Sample帧”唤醒事件。该位不受软件复位影响。 　　3：MAGICEN：1使能“Magic Packet”唤醒事件。该位不受软件复位影响。 　　2：LINKST：1表示发生了连接改变事件和连接状态改变事件。该位不受软件复位影响。 　　1：SAMPLEST：1表示接收到“Sample帧”和发生了“Sample帧”事件。该位不受软件复位影响。 　　0：MAGICST：1表示接收到“Magic Packet”和发生了“Magic Packet”事件。该位不受软件复位影响。 　　PAR（10H -- 15H）：物理地址（MAC）寄存器（Physical Address Register） 　　7-0：PAD0 -- PAD5：物理地址字节0 -- 字节5（10H -- 15H）。用来保存6个字节的MAC地址。 　　MAR（16H -- 1DH）：多点发送地址寄存器（Multicast Address Register ） 　　7-0：MAB0 -- MAB7：多点发送地址字节0 -- 字节7（16H --1DH）。 　　GPCR（1FH）：GPIO控制寄存器（General Purpose Control Register） 　　7-4：保留。 　　3-0：GEP_CNTL：GPIO控制。定义GPIO的输入输出方向。1为输出，0为输入。GPIO0默认为输出做POWER_DOWN功能。其它默认为输入。因此默认值为0001。 　　GPR（1FH）：GPIO寄存器（General Purpose Register） 　　7-4：保留。 　　3-1：GEPIO3-1：GPIO为输出时，相关位控制对应GPIO端口状态，GPIO为输入时，相关位反映对应GPIO端口状态。（类似于单片机对IO端口的控制）。 　　0：GEPIO0：功能同上。该位默认为输出1到POWER_DEWN内部PHY。若希望启用PHY，则驱动程序需要通过写“0”将PWER_DOWN信号清零。该位默认值可通过EEPROM编程得到。参考EEPROM相关描述。 　　TRPAL（22H）：发送SRAM读指针地址低半字节（TX SRAM Read Pointer Address Low Byte） 　　7-0：TRPAL 　　TRPAH（23H）：发送SRAM读指针地址高半字节（TX SRAM Read Pointer Address High Byte ） 　　7-0：TRPAH 　　RWPAL（24H）：接收SRAM指针地址低半字节（RX SRAM Write Pointer Address Low Byte） 　　7-0：RWPAL 　　RWPAH（25H）：接收SRAM指针地址高半字节（RX SRAM Write Pointer Address High Byte） 　　7-0:RWPAH 　　VID（28H -- 29H）：生产厂家序列号（Vendor ID） 　　7-0：VIDL：低半字节（28H），只读，默认46H。 　　7-0：VIDH：高半字节（29H），只读，默认0AH。 　　PID（2AH --2BH）：产品序列号（Product ID） 　　7-0：PIDL：低半字节（2AH），只读，默认00H。 　　7-0：PIDH：高半字节（2BH），只读，默认90H。 　　CHIPR（2CH）：芯片修订版本（CHIP Revision） 　　7-0：PIDH：只读，默认00H。 　　TCR2（2DH）：传输控制寄存器2（TX Control Register 2） 　　7：LED：LED模式。1设置LED引脚为模式1，0设置LED引脚为模式0或根据EEPROM的设定。 　　6：RLCP：1重新发送有冲突延迟的数据包。 　　5：DTU：1禁止重新发送“underruned”数据包。 　　4：ONEPM：单包模式。1发送完成前发送一个数据包的命令能被执行，0发送完成前发送两个以上数据包的命令能被执行。 　　3-0：IFGS：帧间间隔设置。0XXX为96bit，1000为64bit，1001为72bit，1010为80bit，1011为88bit，1100为96bit，1101为104bit，1110为112bit，1111为120bit。 　　OCR（2EH）：操作测试控制寄存器（Operation Control Register） 　　7-6：SCC：设置内部系统时钟。00为50MHz，01为20MHz，10为100MHz，11保留。 　　5：保留。 　　4：SOE：内部SRAM输出使能始终开启。 　　3：SCS：内部SRAM片选始终开启。 　　2-0：PHYOP：为测试用内部PHY操作模式。 　　SMCR（2FH）：特殊模式控制寄存器（Special Mode Control Register） 　　7：SM_EN：特殊模式使能。 　　6-3：保留。 　　2：FLC：强制冲突延迟。 　　1：FB1：强制最长“Back-off”时间。 　　0：FB0：强制最短“Back-off”时间。 　　ETXCSR（30H）：传输前（Early）控制、状态寄存器（Early Transmit Control/Status Register） 　　7：ETE：传输前使能。 　　6：ETS2：传输前状态2。 　　5：ETS1：传输前状态1。 　　4-2：保留。 　　1-0：ETT：传输前门限。当写到发送FIFO缓存里的数据字节数达到该门限，则开始传输。00为12.5%，01为25%，10为50%，11为75%。 　　TCSCR（31H）：传输校验和控制寄存器（Transmit Check Sum Control Register） 　　7-3：保留。 　　2：UDPCSE：UDP校验和产生使能。 　　1：TCPCSE：TCP检验和产生使能。 　　0：IPCSE：IP校验和产生使能。 　　RCSCSR（32H）：接收校验和控制状态寄存器（Receive Check Sum Control Status Register ） 　　7：UDPS：UDP校验和状态。1表示UDP数据包校验失败。 　　6：TCPS：TCP校验和状态。1表示TCP数据包校验失败。 　　5：IPS：IP校验和状态。1表示IP数据包校验失败。 　　4：UDPP：1表示UDP数据包。 　　3：TCPP：1表示TCP数据包。 　　2：IPP：1表示IP数据包。 　　1：RCSEN：接收检验和检验使能。1使能校验和校验，将校验和状态位（bit7-2）存储到数据包的各自的报文头的第一个字节。 　　0：DCSE：丢弃校验和错误的数据包。1使能丢弃校验和错误的数据包，若IP/TCP/UDP的校验和域错误，则丢弃该数据包。 　　MRCMDX（F0H）：存储器地址不变的读数据命令（Memory Data Pre-Fetch Read Command Without Address Increment Register） 　　7-0：MRCMDX：从接收SRAM中读数据，读取之后，指向内部SRAM的读指针不变。 　　MRCMDX1（F1H）：存储器读地址不变的读数据命令（Memory Data Read Command With Address Increment Register 　　同上。 　　MRCMD（F2H）：存储器读地址自动增加的读数据命令（Memory Data Read Command With Address Increment Register） 　　7-0：MRCMD：从接收SRAM中读数据，读取之后，指向内部SRAM的读指针自动增加1、2或4，根据处理器的操作模式而定（8位、16位或32位）。 　　MRRL（F4H）：存储器读地址寄存器低半字节（Memory Data Read_ address Register Low Byte） 　　7-0：MDRAL 　　MRRH（F5H）：存储器读地址寄存器高半字节Memory Data Read_ address Register High Byte 　　7-0：MDRAH：若IMR的bit7=1，则该寄存器设置为0CH。 　　MWCMDX（F6H）：存储器读地址不变的读数据命令（Memory Data Write Command Without Address Increment Register） 　　7-0：MWCMDX：写数据到发送SRAM中，之后指向内部SRAM的写地址指针不变。 　　MWCMD（F8H）：存储器读地址自动增加的读数据命令（Memory Data Write Command With Address Increment Register） 　　7-0：MWCMD：写数据到发送SRAM中，之后指向内部SRAM的读指针自动增加1、2或4，根据处理器的操作模式而定（8位、16位或32位）。 　　MWRL（FAH）：存储器写地址寄存器低半字节（Memory Data Write_ address Register Low Byte） 　　7-0：MDRAL 　　MWRH（FBH）：存储器写地址寄存器高半字节（Memory Data Write _ address Register High Byte） 　　7-0:MDRAH 　　TXPLL（FCH）：发送数据包长度寄存器低半字节（TX Packet Length Low Byte Register） 　　7-0：TXPLL 　　TXPLH（FDH）：发送数据包长度寄存器高半字节（TX Packet Length High Byte Register） 　　7-0：TXPLH 　　ISR（FEH）：终端状态寄存器（Interrupt Status Register） 　　7-6：IOMODE：处理器模式。00为16位模式，01为32位模式，10为8位模式，00保留。 　　5：LNKCHG：连接状态改变。 　　4：UDRUN：传输“Underrun” 　　3：ROOS：接收溢出计数器溢出。 　　2：ROS：接收溢出。 　　1：PTS：数据包传输。 　　0：PRS：数据包接收。 　　ISR寄存器各状态写1清除 　　IMR（FFH）：终端屏蔽寄存器（Interrupt Mask Register） 　　7：PAR：1使能指针自动跳回。当SRAM的读、写指针超过SRAM的大小时，指针自动跳回起始位置。需要驱动程序设置该位，若设置则REG_F5（MDRAH）将自动位0CH。 　　6：保留。 　　5：LNKCHGI：1使能连接状态改变中断。 　　4：UDRUNI：1使能传输“Underrun”中断。 　　3：ROOI：1使能接收溢出计数器溢出中断。 　　2：ROI：1使能接收溢出中断。 　　1：PTI：1使能数据包传输终端。 　　0：PRI：1使能数据包接收中断。 　　注释：表示在DM9000初始化中要用到的寄存器。 　　访问以上寄存器的方法是通过总线驱动的方式，即通过对IOR、IOW、AEN、CMD以及SD0--SD15等相关引脚的操作来实现。其中CMD引脚为高 电平时为写寄存器地址，为低电平时为写数据到指定地址的寄存器中。详细过程请参考数据手册中“读写时序”部分。 　　在DM9000（A）中，还有一些PHY寄存器，也称之为介质无关接口MII寄存器，需要我们去访问。这些寄存器是字对齐的，即16位宽。下面列出三个常用的PHY寄存器。 　　BMCR（00H）：基本模式控制寄存器（Basic Mode Control Register) 　　15：reset：1PHY软件复位，0正常操作。复位操作使PHY寄存器的值为默认值。复位操作完成后，该位自动清零。 　　14：loopback：1Loop-back使能，0正常操作。 　　13：speed selection：1为100Mbps，0为10Mbps。连接速度即可以根据该位选择，也可以根据第12位，即自动协商选择。当自动协商使能时，即第12位为1，该位将会返回自动协商后的速度值。 　　12：auto-negotiation enable：1自动协商使能。使得第13位和第8位的值反应自动协商后的状态。 　　11：power down：POWER_DOWN模式。1为POWER_DOWN，0为正常操作。在POWER_DOWN状态下，PHY应当响应操作处理。在转变到 POWER_DOWN状态或已经运行在POWER_DOWN状态下时，PHY不会在MII上产生虚假信号。 　　10：isolate：1除了一些操作外，PHY将从MII中隔离，0为正常操作。当该位置 位，PHY不会响应TXD[3:0]，TX_EN和TX_ER输入，并且在TX_CLK，RX_CLK，RX_DV，RX_ER，RXD[3:0]， COL和CRS输出上为高阻态。当PHY被隔离，则它将响应操作处理。 　　9：restart auto-aegotiation：1重新初始化自动协商协议，0为正常操作。当第12位禁止该功能，则该位无效。初始化后该位自动清零。 　　8：duplex mode：1为全双工操作，0为正常操作。当第12位被禁止（置0）时该位被置位，若第12位被置位，则该位反应自动协商后的状态。 　　7：collision test：1为冲突测试使能，0为正常操作。若该位置位，声明TX_EN将引起COL信号被声明。 　　6-0：保留。 　　ANAR（04H）：自动协商广告寄存器（Auto-negotiation Advertisement Register） 　　15：NP：0表示无有效的下一页，1表示下一页有效。PHY没有下一页，所以该位始终为0。 　　14：ACK：1表示连接对象数据接收认证，0表示无认证。PHY的自动协商状态机会自动控制该位。 　　13：RF：1表示本地设备处于错误状态，0为无错误检验。 　　12-11：保留。 　　10：FCS：1表示处理器支持溢出控制能力，0表示不支持。 　　9：T4：1表示本地设备支持100BASE-T4，0表示不支持。PHY不支持100BASE-T4，所以该位永远是0。 　　8：TX_FDX：1为本地设备支持100BASE-TX全双工模式，0为不支持。 　　7：TX_HDX：1为本地设备支持100BASE-TX，0为不支持。 　　6：10_FDX：1为本地设备支持100BASE-T全双工模式，0为不支持。 　　5：10_HDX：1为本地设备支持100BASE-T，0为不支持。 　　4-0：selecter：协议选择位，00001为默认值，表示设备支持IEEE802.3CSMA/CD，不用修改。 　　DSCR（16H）：DAVICOM详细配置寄存器（DAVICOM Specified Configuration Register） 　　15：BP_4B5B：1为绕过4B5B编码和5B4B解码功能，0为正草4B5B和5B4B功能。 　　14：BP_SCR：1为绕过扰频和解扰功能，0为正常操作。 　　13：BP_ALIGN：1为绕过接收时的解扰、符号队列、解码功能和发送时的符号编码、扰频功能，0正常操作。 　　12：BP_ADPOK：1为强制信号探测功能使能，0为正常操作。该位仅为调试使用 　　11：保留。 　　10：TX：1表示100BASE-TX操作，0保留。 　　9-8：保留。 　　7：F_LINK_100：0为正常100Mbps，1为强制100Mbps良好连接状态。 　　6-5：保留，强制为0. 　　4：RPDCTR-EN：1为使能自动简化POWER_DOWN，0为禁止。 　　3：SMRST：1为重新初始化PHY的状态机，初始化后该位自动清零。 　　2：MFPSC：1表示MII帧引导抑制开启，0表示关闭。 　　1：SLEEP：睡眠模式。该位置位将导致PHY进入睡眠模式，通过将该位清零唤醒睡眠模式，其中配置将还原为睡眠模式之前的状态，但状态机将重新初始化。 　　0：RLOUT：该位置位将使接收到的数据放入发送通道中。 　　访问PHY寄存器的方法是： 　　（1）寄存器地址写到EPAR/PHY_AR（0CH）寄存器中，注意将寄存器地址的第6位置1（地址与0x40或运算即可），以表明写的是PHY地址，而不是EEPROM地址。 　　（2）将数据高字节写到PHY_DRH（0EH）寄存器中。 　　（3）将数据低字节写到PHY_DRL（0DH）寄存器中。 　　（4）发送PHY命令(0x0a）到EPCR/PHY_CR（0BH）寄存器中。 　　（5）延时5us，发送命令0x08到EPCR/PHY_CR（0BH）寄存器中，清除PHY写操作。 　　以上为DM9000（A）常用寄存器功能的详细介绍，通过对这些寄存器的操作访问，我们便可以实现对DM9000的初始化、数据发送、接收等相关操作。而要实现ARP、IP、TCP等功能，则需要对相关协议的理解，由编写相关协议或移植协议栈来实现。 　　功能描述 　　1、总线 　　总线是ISA总线兼容模式，8个IO基址,分别是300H, 310H,320H, 330H, 340H, 350H, 360H, 370H。IO基址与设定引脚或内部EEPROM的共同选定 　　访问芯片有两个地址端口，分别是地址端口和数据端口。当引脚CMD接地时，为地址端口；当引脚CMD接高电平时，为数据端口。在访问任何寄存器前，地址端口输入的是数据端口的寄存器地址，寄存器的地址必须保存在地址端口。 　　2、存储器直接访问控制 　　DM9000提供DMA（直接存取技术）来简化对内部存储器的 访问。在对内部存储器起始地址完成编程后，然后发出伪读写命令就可以加载当期数据到内部数据缓冲区，可以通过读写命令寄存器来定位内部存储区地址。根据当 前总线模式的字长使存储地址自动加1，下一个地址数据将会自动加载到内部数据缓冲区。要注意的是在连续突发式的第一次访问是读写命令的内容。 　　内部存储器空间大少16K字节。低3K字节单元用作发送包的缓 冲区，其他13K字节用作接收包的缓冲区。所以在写发送包存储区的时候，当存储器地址越界后，自动跳回0地址并置位IMR第七位。同样在读接收包存储器的 时候，当存储器地址越界后，自动跳回起始地址0x0c00。 　　3、包的发送 　　有两个指数，顺序命名为指针1和指针2，能同时存储在发送包缓冲区。发送控制寄存器（02H）控制冗余校验码和填充的插入，其状态分别记录在发送状态寄存器1（03H）和发送状态2（04H） 　　发送器的起始地址是0x00H，软件或硬件复位后默认是指针1，先通过DMA端口写数据到发送包缓冲区，然后写字节计数长度到字节计数寄存器","title":"DM9000A 中文芯片资料"},{"content":"1. 安装nfs服务 $sudo apt-get install nfs-kernel-server portmap 2. 在配置文件/etc/exports中添加以下内容 /home/jxhui/nfs_root *(rw,sync,no_root_squash)；以后就可以通过网络文件系统访问/home/jxhui/nfs_root目录 3. 修改完后，执行以下命令重启NFS服务：     $sudo /etc/init.d/nfs-kernel-server restart","title":"Linux下安装nfs服务器"},{"content":"  1、 *.src.rpm形式的源代码软件包     安装： rpm  -rebuild  *.src.rpm     cd  /usr/src/dist/RPMS     rpm  -ivh  *.rpm     卸载：rpm  -e  packgename     2、 *.tar.gz/*.tgz、*.bz2形式的源代码软件包     安装：tar  zxvf  *.tar.gz  或  tar  yxvf  *.bz2  先解压     然后进入解压后的目录：     ./configure  配置     make  编译     make  install  安装     卸载：make  uninstall  或  手动删除    ","title":"linux环境下软件包的安装"},{"content":"女神、壁虎和娃娃 Firefox OS 从架构上来讲具有了三个层面： Gaia（盖亚，大地女神）：Firefox OS 的用户界面，包含了在开机之后所有用户能看到部分，比如锁屏、主屏幕、应用程序启动器、拨号器、短信、相机等等作为智能手机必须具备的。Gaia 完全使用 HTML、CSS 和 JavaScript 编写，使用成为标准的 Web API 的接口和底层设备关联。因此，Gaia 可以在任何实现了 Web API 的设备上运行，比如桌面浏览器。Firefox OS 上的第三方程序也是以类似的方式运行并与 Gaia 共存的。 Gecko（壁虎）：Firefox OS 的应用程序运行时环境，用 C++（不知道后期是否会转用Rust ）实现了 Web API，供包括 Gaia 在内的应用程序使用，同时保证 Web API 可以在 Firefox OS 的目标硬件平台上运行。于是乎 Gecko 包含了必要的网络层，图像层、布局管理和 JavaScript 虚拟机以及移植层。 Gonk（蛋形娃娃）：Firefox OS 的操作系统底层，也是 Gecko 的一个目标移植平台，包含 Linux 内核和用户态的硬件抽象层，这一部分和 Android 以及嵌入式 Linux 共享了很多组件和驱动，比如 bluez, libusb 等。说是一个目标移植平台，是由于 Gecko 抽象层在理论上也可以运行在 Android 或者桌面操作系统上，不过由于 Firefox OS 项目主导了 Gonk 开发，可以提供一些其他系统上不具备的接口给 Gecko 使用，比如完整的电话通讯层。 光、信号和起源 和绝大多数 Android 手机一样，预装 Firefox OS 的手机在开机后也会首先由极小化的 bootloader 实现最初的引导操作，然后链式引导更高级别更复杂的引导器，最终实现内核的加载。这个过程具体如何与设备制造商有关，相应的 bootloader 操作很有可能重用现在各个厂商在 Android 设备上所用的私有fastboot 协议实现。意味着只要适当调整 Firefox OS 所用的引导器，在 Android 手机上使用现有刷机工具刷入 Firefox OS 在技术上没有障碍。 由于嵌入式领域还比较封闭，这个过程也会加载很可能是设备相关的私有调制解调器固件。于是乎在这个层面上 Firefox OS 和 Android 一样不是开放的。 紧接的故事就是 Linux 内核的载入和 PID 1 号 init 进程的产生了，和一般嵌入式 Linux 的初始化没有太大差别。这里使用的 Linux 内核会紧随上游，不过也会吸纳厂商通过Android Open Source Project 提交的一些尚未合并的设备相关代码。内核载入之后的大多数设备访问将通过sysfs 的方式供用户态程序访问。 爬行动物时代 在这里，b2g 以主系统进程的形态被 init 进程激活，并通过 RPC 或者 Socket 的方式实现和其他负责诸如网络、无线电等功能的进程通讯。除此之外，b2g 还会通过dbus-daemon 和 IPDL 这两种特殊的方式实现用户态进程间通讯。 dbus 不用赘述，用过任意一个现代桌面 Linux 发行版的用户对其都不陌生 最近合并入了systemd 成为其一部分，不过依然可以单独运行。IPDL 则是Mozilla 特有的进程间通讯协议定义语言，允许在 C++ 进程间安全且有组织的传递消息。运行着 libxul.so 的b2g 进程将使用IPDL 启动一系列内容子进程，上层的网页程序和其他网页内容将在独立的内容子进程中运行，在技术上和现在 Firefox 浏览器的标签页处理类似。 面对多媒体文件， Gecko 对于 OGG Vorbis 音频, OGG Theora 视频和 WebM 视频这些开放格式将提供原生支持，以后正式发布时为了 WebRTC 引入对Opus 的支持也是完全有可能的。而对于私有格式将通过 libstagefright 的方式访问私有解码器和实现硬件加速。 感触、表现和尾巴 Gecko 负责将来自 Gonk 的各种输入事件解析成可供标准网页程序使用的 DOM 事件，包括按键、触屏操作等等，源自标准 Linux 输入设备 input-device。这些来自 Gecko 的 DOM API 由在 C++ 和 JavaScript 之间的外部函数接口和对象模型组成，使用普遍的XPIDL 规定。 网络通讯则分别交由 wpasupplicant 和 RIL(Radio Interface Layer) 完成。和桌面 Linux 发行版一样，wpasupplicant 负责 WiFi 环境下的接入，Gecko 为其开发了附属的WifiWorker.js 供网页程序了解 WiFi 连接状态。RIL 则负责广域网络的通讯，其中负责跟调制解调部分沟通的 rild 很可能是来自制造商的私有代码，rildproxy 则是一个为了安全考虑而设置的中间代理，起到连结 rild 和b2g 的作用。同样，也有 ril_worker.js 暴露状态和操作接口供上层程序使用。 和 Android 4.0+ 类似，Gecko 完全使用 OpenGL ES 2.0 实现混合。Gecko 会将页面的各个区域绘制入内存缓冲，然后调用 OpenGL 命令将内容混合并渲染于屏幕上。和 Android 早期借助 skia 实现的软件混合相比，Firebox OS 从一开始就依赖于 GPU 的渲染能力，其效果值得期待。 在 Gecko 的最底层则是负责和目标系统交互的移植层。在这一部分包含针对不同目标系统的平台相关代码(Gonk，Android，OS X 等)，并将其统一化为可供 Gecko 上层子系统使用的 C++ API。","title":"Firefox OS 架构简析"},{"content":"linux下默认是不产生core文件的，要用ulimit -c unlimited放开 概述 系统性能一直是一个受关注的话题，如何通过最简单的设置来实现最有效的性能调优，如何在有限资源的条件下保证程序的运作，ulimit 是我们在处理这些问题时，经常使用的一种简单手段。ulimit 是一种 linux 系统的内键功能，它具有一套参数集，用于为由它生成的 shell 进程及其子进程的资源使用设置限制。本文将在后面的章节中详细说明 ulimit 的功能，使用以及它的影响，并以具体的例子来详细地阐述它在限制资源使用方面的影响。 ulimit 的功能和用法 ulimit 功能简述 假设有这样一种情况，当一台 Linux 主机上同时登陆了 10 个人，在系统资源无限制的情况下，这 10 个用户同时打开了 500 个文档，而假设每个文档的大小有 10M，这时系统的内存资源就会受到巨大的挑战。 而实际应用的环境要比这种假设复杂的多，例如在一个嵌入式开发环境中，各方面的资源都是非常紧缺的，对于开启文件描述符的数量，分配堆栈的大 小，CPU 时间，虚拟内存大小，等等，都有非常严格的要求。资源的合理限制和分配，不仅仅是保证系统可用性的必要条件，也与系统上软件运行的性能有着密不可分的联 系。这时，ulimit 可以起到很大的作用，它是一种简单并且有效的实现资源限制的方式。 ulimit 用于限制 shell 启动进程所占用的资源，支持以下各种类型的限制：所创建的内核文件的大小、进程数据块的大小、Shell 进程创建文件的大小、内存锁住的大小、常驻内存集的大小、打开文件描述符的数量、分配堆栈的最大大小、CPU 时间、单个用户的最大线程数、Shell 进程所能使用的最大虚拟内存。同时，它支持硬资源和软资源的限制。 作为临时限制，ulimit 可以作用于通过使用其命令登录的 shell 会话，在会话终止时便结束限制，并不影响于其他 shell 会话。而对于长期的固定限制，ulimit 命令语句又可以被添加到由登录 shell 读取的文件中，作用于特定的 shell 用户。 图 1. ulimit 的使用  在下面的章节中，将详细介绍如何使用 ulimit 做相应的资源限制。 如何使用 ulimit ulimit 通过一些参数选项来管理不同种类的系统资源。在本节，我们将讲解这些参数的使用。 ulimit 命令的格式为：ulimit [options] [limit] 具体的 options 含义以及简单示例可以参考以下表格。 表 1. ulimit 参数说明 选项 [options] 含义 例子 -H 设置硬资源限制，一旦设置不能增加。 ulimit – Hs 64；限制硬资源，线程栈大小为 64K。 -S 设置软资源限制，设置后可以增加，但是不能超过硬资源设置。 ulimit – Sn 32；限制软资源，32 个文件描述符。 -a 显示当前所有的 limit 信息。 ulimit – a；显示当前所有的 limit 信息。 -c 最大的 core 文件的大小， 以 blocks 为单位。 ulimit – c unlimited； 对生成的 core 文件的大小不进行限制。 -d 进程最大的数据段的大小，以 Kbytes 为单位。 ulimit -d unlimited；对进程的数据段大小不进行限制。 -f 进程可以创建文件的最大值，以 blocks 为单位。 ulimit – f 2048；限制进程可以创建的最大文件大小为 2048 blocks。 -l 最大可加锁内存大小，以 Kbytes 为单位。 ulimit – l 32；限制最大可加锁内存大小为 32 Kbytes。 -m 最大内存大小，以 Kbytes 为单位。 ulimit – m unlimited；对最大内存不进行限制。 -n 可以打开最大文件描述符的数量。 ulimit – n 128；限制最大可以使用 128 个文件描述符。 -p 管道缓冲区的大小，以 Kbytes 为单位。 ulimit – p 512；限制管道缓冲区的大小为 512 Kbytes。 -s 线程栈大小，以 Kbytes 为单位。 ulimit – s 512；限制线程栈的大小为 512 Kbytes。 -t 最大的 CPU 占用时间，以秒为单位。 ulimit – t unlimited；对最大的 CPU 占用时间不进行限制。 -u 用户最大可用的进程数。 ulimit – u 64；限制用户最多可以使用 64 个进程。 -v 进程最大可用的虚拟内存，以 Kbytes 为单位。 ulimit – v 200000；限制最大可用的虚拟内存为 200000 Kbytes。   我们可以通过以下几种方式来使用 ulimit： 在用户的启动脚本中 如果用户使用的是 bash，就可以在用户的目录下的 .bashrc 文件中，加入 ulimit – u 64，来限制用户最多可以使用 64 个进程。此外，可以在与 .bashrc 功能相当的启动脚本中加入 ulimt。 在应用程序的启动脚本中 如果用户要对某个应用程序 myapp 进行限制，可以写一个简单的脚本 startmyapp。  ulimit – s 512  myapp  以后只要通过脚本 startmyapp 来启动应用程序，就可以限制应用程序 myapp 的线程栈大小为 512K。 直接在控制台输入  user@tc511-ui:~>ulimit – p 256  限制管道的缓冲区为 256K。 用户进程的有效范围 ulimit 作为对资源使用限制的一种工作，是有其作用范围的。那么，它限制的对象是单个用户，单个进程，还是整个系统呢？事实上，ulimit 限制的是当前 shell 进程以及其派生的子进程。举例来说，如果用户同时运行了两个 shell 终端进程，只在其中一个环境中执行了 ulimit – s 100，则该 shell 进程里创建文件的大小收到相应的限制，而同时另一个 shell 终端包括其上运行的子程序都不会受其影响： Shell 进程 1  ulimit – s 100  cat testFile > newFile  File size limit exceeded  Shell 进程 2  cat testFile > newFile  ls – s newFile  323669 newFile    那么，是否有针对某个具体用户的资源加以限制的方法呢？答案是有的，方法是通过修改系统的 /etc/security/limits 配置文件。该文件不仅能限制指定用户的资源使用，还能限制指定组的资源使用。该文件的每一行都是对限定的一个描述，格式如下：  <domain> <type> <item> <value>    domain 表示用户或者组的名字，还可以使用 * 作为通配符。Type 可以有两个值，soft 和 hard。Item 则表示需要限定的资源，可以有很多候选值，如 stack，cpu，nofile 等等，分别表示最大的堆栈大小，占用的 cpu 时间，以及打开的文件数。通过添加对应的一行描述，则可以产生相应的限制。例如：  * hard noflle 100    该行配置语句限定了任意用户所能创建的最大文件数是 100。 现在已经可以对进程和用户分别做资源限制了，看似已经足够了，其实不然。很多应用需要对整个系统的资源使用做一个总的限制，这时候我们需要修改 /proc 下的配置文件。/proc 目录下包含了很多系统当前状态的参数，例如 /proc/sys/kernel/pid_max，/proc/sys/net/ipv4/ip_local_port_range 等等，从文件的名字大致可以猜出所限制的资源种类。由于该目录下涉及的文件众多，在此不一一介绍。有兴趣的读者可打开其中的相关文件查阅说明。 ulimit 管理系统资源的例子 ulimit 提供了在 shell 进程中限制系统资源的功能。本章列举了一些使用 ulimit 对用户进程进行限制的例子，详述了这些限制行为以及对应的影响，以此来说明 ulimit 如何对系统资源进行限制，从而达到调节系统性能的功能。 使用 ulimit 限制 shell 的内存使用 在这一小节里向读者展示如何使用 – d，– m 和 – v 选项来对 shell 所使用的内存进行限制。 首先我们来看一下不设置 ulimit 限制时调用 ls 命令的情况： 图 2. 未设置 ulimit 时 ls 命令使用情况  大家可以看到此时的 ls 命令运行正常。下面设置 ulimit：  >ulimit -d 1000 -m 1000 -v 1000    这里再温习一下前面章节里介绍过的这三个选项的含义： -d：设置数据段的最大值。单位：KB。 -m：设置可以使用的常驻内存的最大值。单位：KB。 -v：设置虚拟内存的最大值。单位：KB。 通过上面的 ulimit 设置我们已经把当前 shell 所能使用的最大内存限制在 1000KB 以下。接下来我们看看这时运行 ls 命令会得到什么样的结果：  haohe@sles10-hehao:~/code/ulimit> ls test -l  /bin/ls: error while loading shared libraries: libc.so.6: failed to map segment  from shared object: Cannot allocate memory    从上面的结果可以看到，此时 ls 运行失败。根据系统给出的错误信息我们可以看出是由于调用 libc 库时内存分配失败而导致的 ls 出错。那么我们来看一下这个 libc 库文件到底有多大： 图 3. 查看 libc 文件大小  从上面的信息可以看出，这个 libc 库文件的大小是 1.5MB。而我们用 ulimit 所设置的内存使用上限是 1000KB，小于 1.5MB，这也就充分证明了 ulimit 所起到的限制 shell 内存使用的功能。 使用 ulimit 限制 shell 创建的文件的大小 接下来向读者展示如何使用 -f 选项来对 shell 所能创建的文件大小进行限制。 首先我们来看一下，没有设置 ulimit -f 时的情况： 图 4. 查看文件  现有一个文件 testFile 大小为 323669 bytes，现在使用 cat 命令来创建一个 testFile 的 copy： 图 5. 未设置 ulimit 时创建复本  从上面的输出可以看出，我们成功的创建了 testFile 的拷贝 newFile。 下面我们设置 ulimt – f 100：  > ulimit -f 100  -f 选项的含义是：用来设置 shell 可以创建的文件的最大值。单位是 blocks。 现在我们再来执行一次相同的拷贝命令看看会是什么结果： 图 6. 设置 ulimit 时创建复本  这次创建 testFile 的拷贝失败了，系统给出的出错信息时文件大小超出了限制。在 Linux 系统下一个 block 的默认大小是 512 bytes。所以上面的 ulimit 的含义就是限制 shell 所能创建的文件最大值为 512 x 100 = 51200 bytes，小于 323669 bytes，所以创建文件失败，符合我们的期望。这个例子说明了如何使用 ulimit 来控制 shell 所能创建的最大文件。 使用 ulimit 限制程序所能创建的 socket 数量 考虑一个现实中的实际需求。对于一个 C/S 模型中的 server 程序来说，它会为多个 client 程序请求创建多个 socket 端口给与响应。如果恰好有大量的 client 同时向 server 发出请求，那么此时 server 就会需要创建大量的 socket 连接。但在一个系统当中，往往需要限制单个 server 程序所能使用的最大 socket 数，以供其他的 server 程序所使用。那么我们如何来做到这一点呢？答案是我们可以通过 ulimit 来实现！细心的读者可能会发现，通过前面章节的介绍似乎没有限制 socket 使用的 ulimit 选项。是的，ulimit 并没有哪个选项直接说是用来限制 socket 的数量的。但是，我们有 -n 这个选项，它是用于限制一个进程所能打开的文件描述符的最大值。在 Linux 下一切资源皆文件，普通文件是文件，磁盘打印机是文件，socket 当然也是文件。在 Linux 下创建一个新的 socket 连接，实际上就是创建一个新的文件描述符。如下图所示（查看某个进程当前打开的文件描述符信息）： 图 7. 查看进程打开文件描述符  因此，我们可以通过使用 ulimit – n 来限制程序所能打开的最大文件描述符数量，从而达到限制 socket 创建的数量。 使用 ulimit 限制 shell 多线程程序堆栈的大小（增加可用线程数量） 在最后一个例子中，向大家介绍如何使用 -s（单位 KB）来对线程的堆栈大小进行限制，从而减少整个多线程程序的内存使用，增加可用线程的数量。这个例子取自于一个真实的案例。我们所遇到的问题是系统对我们的多线程程序有如下的限制： ulimit -v 200000 根据本文前面的介绍，这意味着我们的程序最多只能使用不到 200MB 的虚拟内存。由于我们的程序是一个多线程程序，程序在运行时会根据需要创建新的线程，这势必会增加总的内存需求量。一开始我们对堆栈大小的限制是 1024 （本例子中使用 1232 来说明）：  # ulimit – s 1232    当我们的程序启动后，通过 pmap 来查看其内存使用情况，可以看到多个占用 1232KB 的数据段，这些就是程序所创建的线程所使用的堆栈： 图 8. 程序线程所使用的堆栈  每当一个新的线程被创建时都需要新分配一段大小为 1232KB 的内存空间，而我们总的虚拟内存限制是 200MB，所以如果我们需要创建更多的线程，那么一个可以改进的方法就是减少每个线程的固定堆栈大小，这可以通过 ulimit – s 来实现：  # ulimit -s 512    我们将堆栈大小设置为 512KB，这时再通过 pmap 查看一下我们的设置是否起作用： 图 9. 设置 ulimit 后堆栈大小  从上面的信息可以看出，我们已经成功的将线程的堆栈大小改为 512KB 了，这样在总内存使用限制不变的情况下，我们可以通过本小节介绍的方法来增加可以创建的线程数，从而达到改善程序的多线程性能。 总结 综上所述，linux 系统中的 ulimit 指令，对资源限制和系统性能优化提供了一条便捷的途径。从用户的 shell 启动脚本，应用程序启动脚本，以及直接在控制台，都可以通过该指令限制系统资源的使用，包括所创建的内核文件的大小、进程数据块的大小、Shell 进程创建文件的大小、内存锁住的大小、常驻内存集的大小、打开文件描述符的数量、分配堆栈的最大大小、CPU 时间、单个用户的最大线程数、Shell 进程所能使用的最大虚拟内存，等等方面。本文中的示例非常直观的说明了 ulimit 的使用及其产生的效果，显而易见，ulimit 对我们在 Linux 平台的应用和开发工作是非常实用的。","title":"ulimit命令"},{"content":"本文首先介绍了 crash 的基本概念和安装方法，其次详细介绍了如何使用 crash 工具分析内核崩溃转储文件，包括各种常用调试命令的使用方法，最后以几个实际工作中遇到的真实案例向读者展示了 crash 的强大功能。在这篇文章中，既有详细的工具使用方法，又有丰富的实际案例分析，相信您读过以后定会受益匪浅。 什么是 crash 如前文所述，当 linux 系统内核发生崩溃的时候，可以通过 kdump 等方式收集内核崩溃之前的内存，生成一个转储文件 vmcore。内核开发者通过分析该 vmcore 文件就可以诊断出内核崩溃的原因，从而进行操作系统的代码改进。那么 crash 就是一个被广泛使用的内核崩溃转储文件分析工具，掌握 crash 的使用技巧，对于定位问题有着十分重要的作用。 使用 crash 的先决条件 由于 crash 用于调试内核崩溃的转储文件，因此使用 crash 需要依赖如下条件： 1. kernel 映像文件 vmlinux 在编译的时候必须指定了 -g 参数，即带有调试信息。 2. 需要有一个内存崩溃转储文件（例如 vmcore），或者可以通过 /dev/mem 或 /dev/crash 访问的实时系统内存。如果 crash 命令行没有指定转储文件，则 crash 默认使用实时系统内存，这时需要 root 权限。 3. crash 支持的平台处理器包括：x86, x86_64, ia64, ppc64, arm, s390, s390x ( 也有部分 crash 版本支持 Alpha 和 32-bit PowerPC，但是对于这两种平台的支持不保证长期维护 )。 4. crash 支持 2.2.5-15（含）以后的 Linux 内核版本。随着 Linux 内核的更新，crash 也在不断升级以适应新的内核。 crash 安装指南 要想使用 crash 调试内核转储文件，需要安装 crash 工具和内核调试信息包。不同的发行版安装包名称略有差异，这里仅列出 RHEL 和 SLES 发行版对应的安装包名称如下： 表 1. crash 工具和内核调试包 系统版本 crash 工具名称 内核调试信息包 RHEL6.2 crash kernel-debuginfo-common kernel-debuginfo SLES11SP2 crash kernel-default-debuginfo kernel-ppc64-debuginfo 以 RHEL 为例，安装 crash 及内核调试信息包的步骤如下：  rpm -ivh crash-5.1.8-1.el6.ppc64.rpm  rpm -ivh kernel-debuginfo-common-ppc64-2.6.32-220.el6.ppc64.rpm  rpm -ivh kernel-debuginfo-2.6.32-220.el6.ppc64.rpm  启动 crash 启动参数说明 使用 crash 调试转储文件，需要在命令行输入两个参数：debug kernel 和 dump file，其中 dump file 是内核转储文件的名称，debug kernel 是由内核调试信息包安装的，不同的发行版名称略有不同，以 RHEL 和 SLES 为例：  RHEL6.2：/usr/lib/debug/lib/modules/2.6.32-220.el6.ppc64/vmlinux  SLES11SP2：/usr/lib/debug/boot/vmlinux-3.0.13-0.27-ppc64.debug  使用 crash -h 或 man crash 可以查看 crash 支持的一系列选项，这里仅以常用的选项为例说明如下： -h：打印帮助信息 -d：设置调试级别 -S：使用 /boot/System.map 作为默认的映射文件 -s：不显示版本、初始调试信息等，直接进入命令行 -i file：启动之后自动运行 file 中的命令，再接受用户输入","title":"如何使用crash工具分析Linux内核崩溃转储文件"},{"content":"可能在编译过程中关闭CONFIG_STRICT_DEVMEM选项。","title":"vmware中使用crash"},{"content":"ubuntu下apt-get 命令参数 常用的APT命令参数 apt-cache search package 搜索包 apt-cache show package 获取包的相关信息，如说明、大小、版本等 sudo apt-get install package 安装包 sudo apt-get install package - - reinstall 重新安装包 sudo apt-get -f install 修复安装\"-f = --fix-missing\" sudo apt-get remove package 删除包 sudo apt-get remove package - - purge 删除包，包括删除配置文件等 sudo apt-get update 更新源 sudo apt-get upgrade 更新已安装的包 sudo apt-get dist-upgrade 升级系统 sudo apt-get dselect-upgrade 使用 dselect 升级 apt-cache depends package 了解使用依赖 apt-cache rdepends package 是查看该包被哪些包依赖 sudo apt-get build-dep package 安装相关的编译环境 apt-get source package 下载该包的源代码 sudo apt-get clean && sudo apt-get autoclean 清理无用的包 sudo apt-get check 检查是否有损坏的依赖 其中： 1 有SUDO的表示需要管理员特权！ 2 在UBUNTU中命令后面参数为短参数是用“-”引出，长参数用“--”引出 3 命令帮助信息可用man 命令的方式查看或者 命令 -H（--help）方式查看 4 在MAN命令中需要退出命令帮助请按“q”键！！ 选项 含义 作用 sudo -h Help 列出使用方法，退出。 sudo -V Version 显示版本信息，并退出。 sudo -l List 列出当前用户可以执行的命令。只有在sudoers里的用户才能使用该选项。 sudo -u username|#uid User 以指定用户的身份执行命令。后面的用户是除root以外的，可以是用户名，也可以是#uid。 sudo -k Kill 清除“入场卷”上的时间，下次再使用sudo时要再输入密码。 sudo -K Sure kill 与-k类似，但是它还要撕毁“入场卷”，也就是删除时间戳文件。 sudo -b command Background 在后台执行指定的命令。 sudo -p prompt command Prompt 可以更改询问密码的提示语，其中%u会代换为使用者帐号名称，%h会显示主机名称。非常人性化的设计。 sudo -e file Edit 不是执行命令，而是修改文件，相当于命令sudoedit。","title":"Ubuntu Linux操作系统下Apt-get命令参数"},{"content":"linux常用svn命令  原地址：http://www.rjgc.net/control/content/content.php?nid=4418       1、将文件checkout到本地目录 svn checkout path（path是服务器上的目录） 例如：svn checkout svn://192.168.1.1/pro/domain 简写：svn co         2、往版本库中添加新的文件 svn add file 例如：svn addtest.php(添加test.php) svn add *.php(添加当前目录下所有的php文件)         3、将改动的文件提交到版本库 svn commit -m “LogMessage“ [-N] [--no-unlock] PATH(如果选择了保持锁，就使用–no-unlock开关) 例 如：svn commit -m “add test file for my test“ test.php 简写：svn ci         4、加锁/解锁 svn lock -m “LockMessage“ [--force] PATH 例如：svn lock -m “lock test file“ test.php svn unlock PATH         5、更新到某个版本 svn update -r m path 例如： svn update如果后面没有目录，默认将当前目录以及子目录下的所有文件都更新到最新版本。 svn update -r 200 test.php(将版本库中的文件test.php还原到版本200) svn update test.php(更新，于版本库同步。如果在提交的时候提示过期的话，是因为冲突，需要先update，修改文件，然后清除svn resolved，最后再提交commit) 简写：svn up         6、查看文件或者目录状态 1）svn status path（目录下的文件和子目录的状态，正常状态不显示） 【?：不在svn的控制中；M：内容被修改；C：发生冲突；A：预定加入到版本库；K： 被锁定】 2）svn status -v path(显示文件和子目录状态) 第一列保持相同，第二列显示工作版本号，第三和第四列显示最 后一次修改的版本号和修改人。 注：svn status、svn diff和 svn revert这三条命令在没有网络的情况下也可以执行的，原因是svn在本地的.svn中保留了本地版本的原始拷贝。 简写：svn st         7、删除文件 svn delete path -m “delete test fle“ 例如：svn delete svn://192.168.1.1/pro/domain/test.php -m “delete test file” 或者直接svn delete test.php 然后再svn ci -m ‘delete test file‘，推荐使用这种 简写：svn (del, remove, rm)         8、查看日志 svn log path 例如：svn log test.php 显示这个文件的所有修改记录，及其版本号的变化         9、查看文件详细信息 svn info path 例如：svn info test.php         10、比较差异 svn diff path(将修改的文件与基础版本比较) 例如：svn diff test.php svn diff -r m:n path(对版本m和版本n比较差异) 例如：svn diff -r 200:201 test.php 简 写：svn di         11、将两个版本之间的差异合并到当前文件 svn merge -r m:n path 例如：svn merge -r 200:205 test.php（将版本200与205之间的差异合并到当前文件，但是一般都会产生冲突，需要处理一下）         12、SVN 帮助 svn help svn help ci —————————————————————————— 以上是常用命令，下面写几个不经常用的 ——————————————————————————         13、版本库下的文件和目录列表 svn list path 显示path目录下的所有属于版本库的文件和目录 简写：svn ls         14、创建纳入版本控制下的新目录 svn mkdir: 创建纳入版本控制下的新目录。 用法:          1、mkdir PATH…         2、mkdir URL… 创建版本控制的目录。         1、每一个以工作副本 PATH 指定的目录，都会创建在本地端，并且加入新增调度，以待下一次的提交。         2、每个以URL指定的目录，都会透过立即提交于仓库中创建。在这两个情况下，所有的中间目录都必须事先存在。         15、恢复本地修改 svn revert: 恢复原始未改变的工作副本文件 (恢复大部份的本地修改)。revert:          用法: revert PATH…          注意: 本子命令不会存取网络，并且会解除冲突的状况。但是它不会恢复被删除的目录         16、代码库URL变更 svn switch (sw): 更新工作副本至不同的URL。 用法: 1、switch URL [PATH]           2、switch –relocate FROM TO [PATH...]           1、更新你的工作副本，映射到一个新的URL，其行为跟“svn update”很像，也会将服务器上文件与本地文件合并。这是将工作副本对应到同一仓库中某个分支或者标记的方法。           2、改写工作副本的URL元数据，以反映单纯的URL上的改变。当仓库的根URL变动(比如方案名或是主机名称变动)，但是工作副本仍旧对映到同一仓库的 同一目录时使用这个命令更新工作副本与仓库的对应关系。           17、解决冲突 svn resolved: 移除工作副本的目录或文件的“冲突”状态。 用法: resolved PATH… 注意: 本子命令不会依语法来解决冲突或是移除冲突标记；它只是移除冲突的 相关文件，然后让 PATH 可以再次提交。          18、输出指定文件或URL的内容。 svn cat 目标[@版本]…如果指定了版本，将从指定的版本开始查找。 svn cat -r PREV filename > filename (PREV 是上一版本,也可以写具体版本号,这样输出结果是可以提交的)","title":"linux常用命令"},{"content":"  标签： 杂谈 分类： makefile 在make命令后出现这种错误提示，是提示第2行没有分隔符。 例如：       1 main:main.o fun.o       2 gcc main.o fun.o -o main       3 mian.o:miao.c fun.c       4 gcc -c main.c -o main.o       5 fun.o:fun.c fun.h       6 gcc -c fun.c -o fun.o       7 clean:       8  rm -f main *.o       9 改为：       1 main:main.o fun.o       2         gcc main.o fun.o -o main       3 mian.o:miao.c fun.c       4         gcc -c main.c -o main.o       5 fun.o:fun.c fun.h       6         gcc -c fun.c -o fun.o       7 clean:       8         rm -f main *.o       9 就可以了。 在Makefile文件中，命令必须以【tab】键开始。","title":"Makefile：2：*** missing separator. Stop"},{"content":"面向连接的客户端和服务器端使用TCP协议的流程                                                                     1：TCP的工作原理  在TCP/IP协议提供可靠的连接服务，是采用三次握手建议一个接连 第一次握手:建立连接时，客户端发送一个SYN包到服务器，并进入SYN_SEND状态，等待服务器确认 第二次握手：服务器收到SYN包，同时自己也发送一个SYN包作为确认收到客户的SYN，即将发送的一个SYN包数据段的起始字节的顺序号，应答，并带有收到的一个数据段的字节和确认号。此时服务器进入SYN_RECV状态。 第三次握手：客户端收到服务器的SYN+ACK包，相服务器发送确认包ACK包，发送完毕，客户端和服务器端进入建立阶段，完成三次握手 2：socket socket接口是TCP/IP网络的API，socket接口定义了许多函数或例程，程序员可以用他们来开发TCP/TP网络上的应用程序 socket是进程之间通信的抽象连接点，它封装了主机地址，端口，传输层协议 如何开发一个Server-client模型的程序 开发原理： 服务器，使用ServerSocket监听指定的端口，端口可以随意指定（由于1024以下的端口通常属于保留端口），在一些操作系统中不可以随意使用，所以建议使用大于1024 的端口待客户连接请求，客户连接后，会话产生；在完成会话后，关闭连接。 客户端：使用socket对网络上某一个服务器的某一端口发出连接请求，一旦连接成功，打开会话；会话完成后，关闭Socket。客户端不需要指定打开的端口，通常临时的，动态的分配一个1024端口以上的端口 3：socket网络基本函数 socket编程的基本函数有socket，bink，listen，accept，send，sendto,recv,recvfrom １、socket函数：为了执行网络输入输出，一个进程必须做的第一件事就是调用socket函数获得一个文件描述符。 -----------------------------------------------------------------  #include <sys/socket.h>  int socket(int family,int type,int protocol); 　　　   　　 　返回：非负描述字－－－成功　　　-1－－－失败  ----------------------------------------------------------------- 　　第一个参数指明了协议簇，目前支持5种协议簇，最常用的有AF_INET(IPv4协议)和AF_INET6(IPv6协议)；第二个参数指明套接口类型，有三种类型可选：SOCK_STREAM(字节流套接口)、SOCK_DGRAM(数据报套接口)和SOCK_RAW(原始套接口)；如果套接口类型不是原始套接口，那么第三个参数就为0。 ２、connect函数：当用socket建立了套接口后，可以调用connect为这个套接字指明远程端的地址；如果是字节流套接口，connect就使用三次握手建立一个连接；如果是数据报套接口，connect仅指明远程端地址，而不向它发送任何数据。 -----------------------------------------------------------------  #include <sys/socket.h>　　 　 　   int connect(int sockfd, const struct sockaddr * addr, socklen_t addrlen); 　  　 　　　 　 　　返回：0－－－成功　　　-1－－－失败  ----------------------------------------------------------------- 　　第一个参数是socket函数返回的套接口描述字；第二和第三个参数分别是一个指向套接口地址结构的指针和该结构的大小。 这些地址结构的名字均已“sockaddr_”开头，并以对应每个协议族的唯一后缀结束。以IPv4套接口地址结构为例，它以“sockaddr_in”命名，定义在头文件<netinet/in.h>；以下是结构体的内容： ------------------------------------------------------------------ struct in_addr {  in_addr_t s_addr;　　 　 /* IPv4地址 */ }; struct sockaddr_in {  uint8_t sin_len; /* 无符号的8位整数 */  sa_family_t sin_family;  /* 套接口地址结构的地址簇，这里为AF_INET */  in_port_t sin_port; /* TCP或UDP端口 */  struct in_addr sin_addr;  char sin_zero[8];   };  　 　 ------------------------------------------------------------------- ３、bind函数：为套接口分配一个本地IP和协议端口，对于网际协议，协议地址是32位IPv4地址或128位IPv6地址与16位的TCP或UDP端口号的组合；如指定端口为0，调用bind时内核将选择一个临时端口，如果指定一个通配IP地址，则要等到建立连接后内核才选择一个本地IP地址。 ------------------------------------------------------------------- #include <sys/socket.h> 　  int bind(int sockfd, const struct sockaddr * server, socklen_t addrlen);  返回：0－－－成功　　　-1－－－失败　  ------------------------------------------------------------------- 　　第一个参数是socket函数返回的套接口描述字；第二和第第三个参数分别是一个指向特定于协议的地址结构的指针和该地址结构的长度。 ４、listen函数：listen函数仅被TCP服务器调用，它的作用是将用sock创建的主动套接口转换成被动套接口，并等待来自客户端的连接请求。 ------------------------------------------------------------------- #include <sys/socket.h>  int listen(int sockfd,int backlog); 　　  返回：0－－－成功　　　-1－－－失败  ------------------------------------------------------------------- 　　第一个参数是socket函数返回的套接口描述字；第二个参数规定了内核为此套接口排队的最大连接个数。由于listen函数第二个参数的原因，内核要维护两个队列：以完成连接队列和未完成连接队列。未完成队列中存放的是TCP连接的三路握手为完成的连接，accept函数是从以连接队列中取连接返回给进程；当以连接队列为空时，进程将进入睡眠状态。 ５、accept函数：accept函数由TCP服务器调用，从已完成连接队列头返回一个已完成连接，如果完成连接队列为空，则进程进入睡眠状态。 ------------------------------------------------------------------- #include <sys/socket.h> 　　 　 　 　  int accept(int listenfd, struct sockaddr *client, socklen_t * addrlen); 　   回：非负描述字－－－成功　　　-1－－－失败  ------------------------------------------------------------------- 第一个参数是socket函数返回的套接口描述字；第二个和第三个参数分别是一个指向连接方的套接口地址结构和该地址结构的长度；该函数返回的是一个全新的套接口描述字；如果对客户段的信息不感兴趣，可以将第二和第三个参数置为空。 6、write和read函数：当服务器和客户端的连接建立起来后，就可以进行数据传输了，服务器和客户端用各自的套接字描述符进行读/写操作。因为套接字描述符也是一种文件描述符，所以可以用文件读/写函数write()和read()进行接收和发送操作。 （1）write()函数用于数据的发送。 ------------------------------------------------------------------- #include <unistd.h> 　　 　 　 　  int write(int sockfd, char *buf, int len);　   回：非负－－－成功　　　-1－－－失败  ------------------------------------------------------------------- 参数sockfd是套接字描述符，对于服务器是accept()函数返回的已连接套接字描述符，对于客户端是调用socket()函数返回的套接字描述符；参数buf是指向一个用于发送信息的数据缓冲区；len指明传送数据缓冲区的大小。   （2）read()函数用于数据的接收。 ------------------------------------------------------------------- #include <unistd.h> 　　 　 　 　  int read(int sockfd, char *buf, intlen); 　   回：非负－－－成功　　　-1－－－失败  ------------------------------------------------------------------- 参数sockfd是套接字描述符，对于服务器是accept()函数返回的已连接套接字描述符，对于客户端是调用socket()函数返回的套接字描述符；参数buf是指向一个用于接收信息的数据缓冲区；len指明接收数据缓冲区的大小。 7、send和recv函数：TCP套接字提供了send()和recv()函数，用来发送和接收操作。这两个函数与write()和read()函数很相似，只是多了一个附加的参数。 （1）send()函数用于数据的发送。 ------------------------------------------------------------------- #include <sys/types.h> #include < sys/socket.h > 　　 　 　 　 ssize_t send(int sockfd, const void *buf, size_t len, int flags); 　   回：返回写出的字节数－－－成功　　　-1－－－失败  ------------------------------------------------------------------- 前3个参数与write()相同，参数flags是传输控制标志。 （2）recv()函数用于数据的发送。 ------------------------------------------------------------------- #include <sys/types.h> #include < sys/socket.h > 　　 　 　 　 ssize_t recv(int sockfd, void *buf, size_t len, int flags); 　   回：返回读入的字节数－－－成功　　　-1－－－失败  ------------------------------------------------------------------- 前3个参数与read()相同，参数flags是传输控制标志。 TCP编程的服务器段的一般步骤如下 1：首先要创建一个套接字,即Socket，用函数socket（） 2：接下来要设这socket属性，用函数setscoketpt（），这个可选 3：绑定IP地址，端口等信息到socket上，用函数bind（） 4：开启监听，用函数listen（） 5：接受客户端发来的连接，用函数accept（）。 6：收发数据，用函数send（）和recv（），或者read（）和write（）。 7：关闭网络连接 8：关闭监听 服务器软件代码： #include<stdio.h>#include<stdlib.h>#include<sys/types.h>#include<sys/socket.h>#include<sys/wait.h>#include<netinet/in.h>#include<string.h>#define SERVPORT 3333  //端口号#define BACKLOG 10   //请求队列中的最大连接数int main(){ int sockfd,client_fd; int sin_size;struct sockaddr_in my_addr;struct sockaddr_in remote_addr;if ((sockfd=socket(AF_INET,SOCK_STREAM,0))==-1)   //创建套接字{ perror(\"socket创建出错！\");exit(1);} my_addr.sin_family=AF_INET;   my_addr.sin_port=htons(SERVPORT);   //定义套接字的端口 my_addr.sin_addr.s_addr=INADDR_ANY;if(bind(sockfd,(struct sockaddr *)&my_addr,sizeof(struct sockaddr))==-1)   //使用bind（）绑定一个端口{ perror(\"bind出错!\");exit(1);}if(listen(sockfd,BACKLOG)==-1){perror(\"Listen 出错！\");exit(1);}while(1) { //sin_size=sizeof(struct sockaddr_in); if((client_fd=accept(sockfd,(struct sockaddr *)&remote_addr,&sin_size))==-1)   //使用accept（）函数开始接受客户端发过来的消息{   perror(\"accept 出错！\"); continue;} printf(\"received a connection from %s\\n\",inet_ntoa(remote_addr.sin_addr));if(!fork())   //如果不是子进程{ if(send(client_fd,\"Hello,you   are  connected!\\n\",26,0)==-1)perror(\"send 出错！\");close(client_fd);exit(0);}close(client_fd);}}服务器的工作流程是这样的，首先调用socket（）函数创建一个socket，然后调用bind（）函数将其与本机地址以及一个本地端口绑定，然后调用listen（）函数在相应的socket上监听，当accept（）函数接受到一个连接服务器请求时，将生成一个新的socket。服务器显示该客户机的IP地址，并通过新的socket向客户端发送字符串“Hello you   are  connected”最后关闭socket。","title":"linux网络编程（socket）"},{"content":"原文作者博客地址：http://www.micmiu.com   在linux下利用短信modem发送短信，由于短信modem使用的是USB串口转换器（芯片为PL2303），把在配置和调试的过程和方法在此记录下，希望给有同样需求的同仁提供一点帮助。  【一】、驱动相关说明：  如果直接使用串口线，而没有用到USB转串口设备，就不需要安装驱动。  如果使用了USB转串口，一般情况下也不需要安装驱动了，目前linux系统已经包含了该驱动，可以自动识别，亦可通过以下命令查看以便确认是否支持。  查看模块装载的情况：  引用 # lsmod |grep pl2303  pl2303                 18629  0  usbserial              29865  1 pl2303 如果看到类似于上述信息，则表明能正确识别该设备，否则安装该设备的驱动。  同时你可以查看系统的一些信息  引用 # dmesg | tail -f  。。。。。。  drivers/usb/serial/usb-serial.c: USB Serial support registered for PL-2303  pl2303 3-1:1.0: PL-2303 converter detected  usb 3-1: PL-2303 converter now attached to ttyUSB0  usbcore: registered new driver pl2303  drivers/usb/serial/pl2303.c: Prolific PL2303 USB to serial adaptor driver v0.11  。。。。。。  如果看到类似上述信息，可知usb转串口芯片PL-2303的驱动已经注册加载，对应系统设备是/dev/ttyUSB0（下面对串口设置时需要用）  linux系统下PL2303的芯片驱动可以到它的官网下载：http://www.prolific.com.tw/Eng/downloads.asp?ID=31  如果以下几种情况是不需要安装驱动：  Linux Kernel 2.4.10 and above already includes built-in drivers for PL-2303H. Linux Kernel 2.4.31 and above already includes built-in drivers for PL-2303H, PL-2303XA/HXA and PL-2303HXD. NOTE: Google Android OS is also based on Linux kernel so it also supports PL2303. 【二】、minicom配置：  当然先查看下minicom是否已经安装好，具体的安装这里就不再描述了。  首页以root用户登录linux系统，后执行：  1.＃minicom -s    2.选择 serial port setup：  “A - Serial Device”要配置为/dev/ttyUSB0（该值和之前dmesg查询到信息一致，如果直接用的串口线，一般配置为/dev/ttyS0） “E - Bps/Par/Bits”设置成“9600 8N1” “F - Hardware Flow Control”设置成“No” 如下图：    按照各项提示的按键，修改需要的内容，比如选择“E - Bps/Par/Bits”如下图所示：    上述三项修改完成后，按回车一直返回主选项目录。  3.选择Modem and dialing  如果不是用来控制modem, 一般需要修改此选项，具体配置如下：    修改完成按回车一直返回主选项目录。  4.保存配置退出（一定要记得这一步）  设置完成后选择 Save setup as dfl 将当前设置保存为默认设置. 选Exit退出即可。  到此已经基本配置好，可以输入AT命令简单测试下串口通信。 ","title":"linux下USB转串口的设置"},{"content":"Linux 系统信息存放在文件里，文件与普通的公务文件类似。每个文件都有自己的名字、内容、存放地址及其它一些管理信息，如文件的用户、文件的大小等。文件可以是一封信、一个通讯录，或者是程序的源语句、程序的数据，甚至可以包括可执行的程序和其它非正文内容。 Linux文件系统具有良好的结构，系统提供了很多文件处理程序。这里主要介绍常用的文件处理命令。 file 1.作用 件内容判断文件类型，使用权限是所有用户。 2.格式 file通过探测文 file [options] 文件名 3.[options]主要参数 -v：在标准输出后显示版本信息，并且退出。 -z：探测压缩过的文件类型。 -L：允许符合连接。 -f name：从文件namefile中读取要分析的文件名列表。 4.简单说明 使用file命令可以知道某个文件究竟是二进制（ELF格式）的可执行文件, 还是Shell Script文件，或者是其它的什么格式。file能识别的文件类型有目录、Shell脚本、英文文本、二进制可执行文件、C语言源文件、文本文件、DOS的可执行文件。 5.应用实例 如果我们看到一个没有后缀的文件grap，可以使用下面命令： $ file grap grap： English text 此时系统显示这是一个英文文本文件。需要说明的是，file命令不能探测包括图形、音频、视频等多媒体文件类型。 mkdir 1.作用 mkdir命令的作用是建立名称为dirname的子目录，与MS DOS下的md命令类似，它的使用权限是所有用户。 2.格式 mkdir [options] 目录名 3.[options]主要参数 －m, －－mode=模式：设定权限<模式>，与chmod类似。 －p, －－parents：需要时创建上层目录；如果目录早已存在，则不当作错误。 －v, －－verbose：每次创建新目录都显示信息。 －－version：显示版本信息后离开。 4.应用实例 在进行目录创建时可以设置目录的权限，此时使用的参数是“－m”。假设要创建的目录名是“tsk”，让所有用户都有rwx(即读、写、执行的权限)，那么可以使用以下命令： $ mkdir －m 777 tsk grep 1.作用 grep命令可以指定文件中搜索特定的内容，并将含有这些内容的行标准输出。grep全称是Global Regular Expression Print，表示全局正则表达式版本，它的使用权限是所有用户。 2.格式 grep [options] 3.主要参数 [options]主要参数： －c：只输出匹配行的计数。 －I：不区分大小写（只适用于单字符）。 －h：查询多文件时不显示文件名。 －l：查询多文件时只输出包含匹配字符的文件名。 －n：显示匹配行及行号。 －s：不显示不存在或无匹配文本的错误信息。 －v：显示不包含匹配文本的所有行。 pattern正则表达式主要参数： \\：忽略正则表达式中特殊字符的原有含义。 ^：匹配正则表达式的开始行。 $: 匹配正则表达式的结束行。 \\<：从匹配正则表达式的行开始。 \\>：到匹配正则表达式的行结束。 [ ]：单个字符，如[A]即A符合要求 。 [ - ]：范围，如[A-Z]，即A、B、C一直到Z都符合要求 。 。：所有的单个字符。 * ：有字符，长度可以为0。 正则表达式是Linux/Unix系统中非常重要的概念。正则表达式（也称为“regex”或“regexp”）是一个可以描述一类字符串的模式（Pattern）。如果一个字符串可以用某个正则表达式来描述，我们就说这个字符和该正则表达式匹配（Match）。这和DOS中用户可以使用通配符 “*”代表任意字符类似。在Linux系统上，正则表达式通常被用来查找文本的模式，以及对文本执行“搜索－替换”操作和其它功能。 4.应用实例 查询DNS服务是日常工作之一，这意味着要维护覆盖不同网络的大量IP地址。有时IP地址会超过2000个。如果要查看nnn.nnn网络地址，但是却忘了第二部分中的其余部分，只知到有两个句点，例如nnn nn..。要抽取其中所有nnn.nnn IP地址，使用[0－9 ]\\{3 \\}\\.[0－0\\{3\\}\\。含义是任意数字出现3次，后跟句点，接着是任意数字出现3次，后跟句点。 $grep '[0－9 ]\\{3 \\}\\.[0－0\\{3\\}\\' ipfile 补充说明，grep家族还包括fgrep和egrep。fgrep是fix grep，允许查找字符串而不是一个模式；egrep是扩展grep，支持基本及扩展的正则表达式，但不支持\\q模式范围的应用及与之相对应的一些更加规范的模式。 dd 1.作用 dd命令用来复制文件，并根据参数将数据转换和格式化。 2.格式 dd [options] 3.[opitions]主要参数 bs=字节：强迫 ibs=<字节>及obs=<字节>。 cbs=字节：每次转换指定的<字节>。 conv=关键字：根据以逗号分隔的关键字表示的方式来转换文件。 count=块数目：只复制指定<块数目>的输入数据。 ibs=字节：每次读取指定的<字节>。 if=文件：读取<文件>内容，而非标准输入的数据。 obs=字节：每次写入指定的<字节>。 of=文件：将数据写入<文件>，而不在标准输出显示。 seek=块数目：先略过以obs为单位的指定<块数目>的输出数据。 skip=块数目：先略过以ibs为单位的指定<块数目>的输入数据。 4.应用实例 dd命令常常用来制作Linux启动盘。先找一个可引导内核，令它的根设备指向正确的根分区，然后使用dd命令将其写入软盘： $ rdev vmlinuz /dev/hda $dd if＝vmlinuz of＝/dev/fd0 上面代码说明，使用rdev命令将可引导内核vmlinuz中的根设备指向/dev/hda，请把“hda”换成自己的根分区，接下来用dd命令将该内核写入软盘。 find 1.作用 find命令的作用是在目录中搜索文件，它的使用权限是所有用户。 2.格式 find [path][options][expression] path指定目录路径，系统从这里开始沿着目录树向下查找文件。它是一个路径列表，相互用空格分离，如果不写path，那么默认为当前目录。 3.主要参数 [options]参数： －depth：使用深度级别的查找过程方式，在某层指定目录中优先查找文件内容。 －maxdepth levels：表示至多查找到开始目录的第level层子目录。level是一个非负数，如果level是0的话表示仅在当前目录中查找。 －mindepth levels：表示至少查找到开始目录的第level层子目录。 －mount：不在其它文件系统（如Msdos、Vfat等）的目录和文件中查找。 －version：打印版本。 [expression]是匹配表达式，是find命令接受的表达式，find命令的所有操作都是针对表达式的。它的参数非常多，这里只介绍一些常用的参数。 —name：支持统配符*和?。 －atime n：搜索在过去n天读取过的文件。 －ctime n：搜索在过去n天修改过的文件。 －group grpoupname：搜索所有组为grpoupname的文件。 －user 用户名：搜索所有文件属主为用户名（ID或名称）的文件。 －size n：搜索文件大小是n个block的文件。 －print：输出搜索结果，并且打印。 4.应用技巧 find命令查找文件的几种方法： （1）根据文件名查找 例如，我们想要查找一个文件名是lilo.conf的文件，可以使用如下命令： find / －name lilo.conf find命令后的“/”表示搜索整个硬盘。 （2）快速查找文件 根据文件名查找文件会遇到一个实际问题，就是要花费相当长的一段时间，特别是大型Linux文件系统和大容量硬盘文件放在很深的子目录中时。如果我们知道了这个文件存放在某个目录中，那么只要在这个目录中往下寻找就能节省很多时间。比如smb.conf文件，从它的文件后缀“.conf”可以判断这是一个配置文件，那么它应该在/etc目录内，此时可以使用下面命令： find /etc －name smb.conf 这样，使用“快速查找文件”方式可以缩短时间。 （3）根据部分文件名查找方法 有时我们知道只某个文件包含有abvd这4个字，那么要查找系统中所有包含有这4个字符的文件可以输入下面命令： find / －name '*abvd*' 输入这个命令以后，Linux系统会将在/目录中查找所有的包含有abvd这4个字符的文件（其中*是通配符），比如abvdrmyz等符合条件的文件都能显示出来。 (4) 使用混合查找方式查找文件 find命令可以使用混合查找的方法，例如，我们想在/etc目录中查找大于500000字节，并且在24小时内修改的某个文件，则可以使用-and (与)把两个查找参数链接起来组合成一个混合的查找方式。 find /etc -size +500000c -and -mtime +1 mv 1.作用 mv命令用来为文件或目录改名，或者将文件由一个目录移入另一个目录中，它的使用权限是所有用户。该命令如同DOS命令中的ren和move的组合。 2.格式 mv[options] 源文件或目录 目标文件或目录 3.[options]主要参数 －i：交互方式操作。如果mv操作将导致对已存在的目标文件的覆盖，此时系统询问是否重写，要求用户回答“y”或“n”，这样可以避免误覆盖文件。 －f：禁止交互操作。mv操作要覆盖某个已有的目标文件时不给任何指示，指定此参数后i参数将不再起作用。 4.应用实例 （1）将/usr/cbu中的所有文件移到当前目录（用“.”表示）中： $ mv /usr/cbu/ * . （2）将文件cjh.txt重命名为wjz.txt： $ mv cjh.txt wjz.txt　 ls 1.作用 ls命令用于显示目录内容，类似DOS下的dir命令，它的使用权限是所有用户。 2.格式 ls [options][filename] 3.options主要参数 －a, －－all：不隐藏任何以“.” 字符开始的项目。 －A, －－almost－all：列出除了“ . ”及 “.. ”以外的任何项目。 －－author：印出每个文件著作者。 －b, －－escape：以八进制溢出序列表示不可打印的字符。 －－block－size=大小：块以指定<大小>的字节为单位。 －B, －－ignore－backups：不列出任何以 ~ 字符结束的项目。 －f：不进行排序，－aU参数生效，－lst参数失效。 －F, －－classify：加上文件类型的指示符号 (*/=@| 其中一个)。 －g：like －l, but do not list owner。 －G, －－no－group：inhibit display of group information。 －i, －－inode：列出每个文件的inode号。 －I, －－ignore=样式：不印出任何符合Shell万用字符<样式>的项目。 －k：即－－block－size=1K。 －l：使用较长格式列出信息。 －L, －－dereference：当显示符号链接的文件信息时，显示符号链接所指示的对象，而并非符号链接本身的信息。 －m：所有项目以逗号分隔，并填满整行行宽。 －n, －－numeric－uid－gid：类似－l，但列出UID及GID号。 －N, －－literal：列出未经处理的项目名称，例如不特别处理控制字符。 －p, －－file－type：加上文件类型的指示符号 (/=@| 其中一个)。 －Q, －－quote－name：将项目名称括上双引号。 －r, －－reverse：依相反次序排列。 －R, －－recursive：同时列出所有子目录层。 －s, －－size：以块大小为序。 4.应用举例 ls 命令是Linux系统使用频率最多的命令，它的参数也是Linux命令中最多的。使用ls命令时会有几种不同的颜色，其中蓝色表示是目录，绿色表示是可执行文件，红色表示是压缩文件，浅蓝色表示是链接文件，加粗的黑色表示符号链接，灰色表示是其它格式文件。ls最常使用的是ls- l，见图1所示。 图1 使用ls-l命令 文件类型开头是由10个字符构成的字符串。其中第一个字符表示文件类型，它可以是下述类型之一：－（普通文件）、d（目录）、l（符号链接）、b（块设备文件）、c（字符设备文件）。后面的9个字符表示文件的访问权限，分为3组，每组3位。第一组表示文件属主的权限，第二组表示同组用户的权限，第三组表示其他用户的权限。每一组的三个字符分别表示对文件的读（r）、写（w）和执行权限（x）。对于目录，表示进入权限。s表示当文件被执行时，把该文件的UID 或GID赋予执行进程的UID（用户ID）或GID（组 ID）。t表示设置标志位（留在内存，不被换出）。如果该文件是目录，那么在该目录中的文件只能被超级用户、目录拥有者或文件属主删除。如果它是可执行文件，那么在该文件执行后，指向其正文段的指针仍留在内存。这样再次执行它时，系统就能更快地装入该文件。接着显示的是文件大小、生成时间、文件或命令名称。 diff 1.作用 diff命令用于两个文件之间的比较，并指出两者的不同，它的使用权限是所有用户。 2.格式 diff [options] 源文件 目标文件 3.[options]主要参数 -a：将所有文件当作文本文件来处理。 -b：忽略空格造成的不同。 -B：忽略空行造成的不同。 -c：使用纲要输出格式。 -H：利用试探法加速对大文件的搜索。 -I：忽略大小写的变化。 -n --rcs：输出RCS格式。 cmp 1.作用 cmp（“compare”的缩写）命令用来简要指出两个文件是否存在差异，它的使用权限是所有用户。 2.格式 cmp[options] 文件名 3.[options]主要参数 -l: 将字节以十进制的方式输出，并方便将两个文件中不同的以八进制的方式输出。 cat 1.作用 cat（“concatenate”的缩写）命令用于连接并显示指定的一个和多个文件的有关信息，它的使用权限是所有用户。 2.格式 cat [options] 文件1 文件2…… 3.[options]主要参数 －n：由第一行开始对所有输出的行数编号。 －b：和－n相似，只不过对于空白行不编号。 －s：当遇到有连续两行以上的空白行时，就代换为一行的空白行。 4.应用举例 （1）cat命令一个最简单的用处是显示文本文件的内容。例如，我们想在命令行看一下README文件的内容，可以使用命令： $ cat README　 （2）有时需要将几个文件处理成一个文件，并将这种处理的结果保存到一个单独的输出文件。cat命令在其输入上接受一个或多个文件，并将它们作为一个单独的文件打印到它的输出。例如，把README和 INSTALL的文件内容加上行号（空白行不加）之后，将内容附加到一个新文本文件File1 中： $ cat README INSTALL File1 （3）cat还有一个重要的功能就是可以对行进行编号，见图2所示。这种功能对于程序文档的编制，以及法律和科学文档的编制很方便，打印在左边的行号使得参考文档的某一部分变得容易，这些在编程、科学研究、业务报告甚至是立法工作中都是非常重要的。 图2 使用cat命令/etc/named.conf文件进行编号 对行进行编号功能有-b（只能对非空白行进行编号）和-n（可以对所有行进行编号）两个参数： $ cat -b /etc/named.conf ln 1.作用 ln命令用来在文件之间创建链接，它的使用权限是所有用户。 2.格式 ln [options] 源文件 [链接名] 3.参数 －f：链结时先将源文件删除。 －d：允许系统管理者硬链结自己的目录。 －s：进行软链结(Symbolic Link)。 －b：将在链结时会被覆盖或删除的文件进行备份。 链接有两种，一种被称为硬链接（Hard Link），另一种被称为符号链接（Symbolic Link）。默认情况下，ln命令产生硬链接。 硬连接指通过索引节点来进行的连接。在Linux的文件系统中，保存在磁盘分区中的文件不管是什么类型都给它分配一个编号，称为索引节点号(Inode Index)。在Linux中，多个文件名指向同一索引节点是存在的。一般这种连接就是硬连接。硬连接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬连接到重要文件，以防止“误删”的功能。其原因如上所述，因为对应该目录的索引节点有一个以上的连接。只删除一个连接并不影响索引节点本身和其它的连接，只有当最后一个连接被删除后，文件的数据块及目录的连接才会被释放。也就是说，文件才会被真正删除。 与硬连接相对应，Lnux系统中还存在另一种连接，称为符号连接（Symbilc Link），也叫软连接。软链接文件有点类似于Windows的快捷方式。它实际上是特殊文件的一种。在符号连接中，文件实际上是一个文本文件，其中包含的有另一文件的位置信息。 动手联系 上面我们介绍了Linux文件处理命令，下面介绍几个实例，大家可以动手练习一下刚才讲过的命令。 1.利用符号链接快速访问关键目录 符号链接是一个非常实用的功能。假设有一些目录或文件需要频繁使用，但由于Linux的文件和目录结构等原因，这个文件或目录在很深的子目录中。比如， Apache Web服务器文档位于系统的/usr/local/httpd/htdocs中，并且不想每次都要从主目录进入这样一个长的路径之中(实际上，这个路径也非常不容易记忆)。 为了解决这个问题，可以在主目录中创建一个符号链接，这样在需要进入该目录时，只需进入这个链接即可。 为了能方便地进入Web服务器(/usr/local/httpd/htdocs)文档所在的目录，在主目录下可以使用以下命令： $ ln -s /usr/local/httpd/htdocs gg 这样每次进入gg目录就可访问Web服务器的文档，以后如果不再访问Web服务器的文档时，删除gg即可，而真正的Web服务器的文档并没有删除。 2.使用dd命令将init.rd格式的root.ram内容导入内存 dd if=/dev/fd0 of=floppy.fd dd if=root.ram of=/dev/ram0 # 3.grep命令系统调用 grep是Linux/Unix中使用最广泛的命令之一，许多Linux系统内部都可以调用它。 (1)如果要查询目录列表中的目录，方法如下： $ ls -l | grep '∧d' (2)如果在一个目录中查询不包含目录的所有文件，方法如下： $ ls -l | grep '∧[∧d]' (3)用find命令调用grep，如所有C源代码中的“Chinput”，方法如下： $find /ZhXwin -name *.c -exec grep -q -s Chinput {} \\;-print","title":"Linux必学的60个命令-文件处理"},{"content":"女神、壁虎和娃娃 Firefox OS 从架构上来讲具有了三个层面： Gaia（盖亚，大地女神）：Firefox OS 的用户界面，包含了在开机之后所有用户能看到部分，比如锁屏、主屏幕、应用程序启动器、拨号器、短信、相机等等作为智能手机必须具备的。Gaia 完全使用 HTML、CSS 和 JavaScript 编写，使用成为标准的 Web API 的接口和底层设备关联。因此，Gaia 可以在任何实现了 Web API 的设备上运行，比如桌面浏览器。Firefox OS 上的第三方程序也是以类似的方式运行并与 Gaia 共存的。 Gecko（壁虎）：Firefox OS 的应用程序运行时环境，用 C++（不知道后期是否会转用Rust ）实现了 Web API，供包括 Gaia 在内的应用程序使用，同时保证 Web API 可以在 Firefox OS 的目标硬件平台上运行。于是乎 Gecko 包含了必要的网络层，图像层、布局管理和 JavaScript 虚拟机以及移植层。 Gonk（蛋形娃娃）：Firefox OS 的操作系统底层，也是 Gecko 的一个目标移植平台，包含 Linux 内核和用户态的硬件抽象层，这一部分和 Android 以及嵌入式 Linux 共享了很多组件和驱动，比如 bluez, libusb 等。说是一个目标移植平台，是由于 Gecko 抽象层在理论上也可以运行在 Android 或者桌面操作系统上，不过由于 Firefox OS 项目主导了 Gonk 开发，可以提供一些其他系统上不具备的接口给 Gecko 使用，比如完整的电话通讯层。 光、信号和起源 和绝大多数 Android 手机一样，预装 Firefox OS 的手机在开机后也会首先由极小化的 bootloader 实现最初的引导操作，然后链式引导更高级别更复杂的引导器，最终实现内核的加载。这个过程具体如何与设备制造商有关，相应的 bootloader 操作很有可能重用现在各个厂商在 Android 设备上所用的私有fastboot 协议实现。意味着只要适当调整 Firefox OS 所用的引导器，在 Android 手机上使用现有刷机工具刷入 Firefox OS 在技术上没有障碍。 由于嵌入式领域还比较封闭，这个过程也会加载很可能是设备相关的私有调制解调器固件。于是乎在这个层面上 Firefox OS 和 Android 一样不是开放的。 紧接的故事就是 Linux 内核的载入和 PID 1 号 init 进程的产生了，和一般嵌入式 Linux 的初始化没有太大差别。这里使用的 Linux 内核会紧随上游，不过也会吸纳厂商通过Android Open Source Project 提交的一些尚未合并的设备相关代码。内核载入之后的大多数设备访问将通过sysfs 的方式供用户态程序访问。 爬行动物时代 在这里，b2g 以主系统进程的形态被 init 进程激活，并通过 RPC 或者 Socket 的方式实现和其他负责诸如网络、无线电等功能的进程通讯。除此之外，b2g 还会通过dbus-daemon 和 IPDL 这两种特殊的方式实现用户态进程间通讯。 dbus 不用赘述，用过任意一个现代桌面 Linux 发行版的用户对其都不陌生 最近合并入了systemd 成为其一部分，不过依然可以单独运行。IPDL 则是Mozilla 特有的进程间通讯协议定义语言，允许在 C++ 进程间安全且有组织的传递消息。运行着 libxul.so 的b2g 进程将使用IPDL 启动一系列内容子进程，上层的网页程序和其他网页内容将在独立的内容子进程中运行，在技术上和现在 Firefox 浏览器的标签页处理类似。 面对多媒体文件， Gecko 对于 OGG Vorbis 音频, OGG Theora 视频和 WebM 视频这些开放格式将提供原生支持，以后正式发布时为了 WebRTC 引入对Opus 的支持也是完全有可能的。而对于私有格式将通过 libstagefright 的方式访问私有解码器和实现硬件加速。 感触、表现和尾巴 Gecko 负责将来自 Gonk 的各种输入事件解析成可供标准网页程序使用的 DOM 事件，包括按键、触屏操作等等，源自标准 Linux 输入设备 input-device。这些来自 Gecko 的 DOM API 由在 C++ 和 JavaScript 之间的外部函数接口和对象模型组成，使用普遍的XPIDL 规定。 网络通讯则分别交由 wpasupplicant 和 RIL(Radio Interface Layer) 完成。和桌面 Linux 发行版一样，wpasupplicant 负责 WiFi 环境下的接入，Gecko 为其开发了附属的WifiWorker.js 供网页程序了解 WiFi 连接状态。RIL 则负责广域网络的通讯，其中负责跟调制解调部分沟通的 rild 很可能是来自制造商的私有代码，rildproxy 则是一个为了安全考虑而设置的中间代理，起到连结 rild 和b2g 的作用。同样，也有 ril_worker.js 暴露状态和操作接口供上层程序使用。 和 Android 4.0+ 类似，Gecko 完全使用 OpenGL ES 2.0 实现混合。Gecko 会将页面的各个区域绘制入内存缓冲，然后调用 OpenGL 命令将内容混合并渲染于屏幕上。和 Android 早期借助 skia 实现的软件混合相比，Firebox OS 从一开始就依赖于 GPU 的渲染能力，其效果值得期待。 在 Gecko 的最底层则是负责和目标系统交互的移植层。在这一部分包含针对不同目标系统的平台相关代码(Gonk，Android，OS X 等)，并将其统一化为可供 Gecko 上层子系统使用的 C++ API。","title":"Firefox OS 架构简析"},{"content":"　vi 的三种命令模式　　 Command（命令）模式，用于输入命令 　　Insert（插入）模式，用于插入文本 　　Visual（可视）模式，用于视化的的高亮并选定正文 　　光标移动　　 　　当我们按ESC进入Command模式后，我们可以用下面的一些键位来移动光标； 　　j 向下移动一行 　　k 向上移动一行 　　h 向左移动一个字符 　　l 向右移动一个字符 　　ctrl+b 向上移动一屏 　　ctrl+f 向下移动一屏 　　向上箭头 向上移动 　　向下箭头 向下移动 　　向左箭头 向左移动 　　向右箭头 向右移动 　　我们编辑一个文件时，对于 j、k、l和h键，还能在这些动作命令的前面加上数字，比如 3j，表示向下移动3行。 　　/# +Enter #为查找的内容　 　　插入模式（文本的插入） 　　 　　i 在光标之前插入 　　a 在光标之后插入 　　I 在光标所在行的行首插入 　　A 在光标所在行的行末插入 　　o 在光标所在的行的下面插入一行 　　O 在光标所在的行的上面插入一行 　　s 用输入的文本替换光标所在字符 　　S 用输入的文本替换光标所在行　 　　文本内容的删除操作； 　　 　　x 一个字符 　　#x 删除几个字符，#表示数字，比如3x 　　dw 删除一个单词 　　#dw 删除几个单词，#用数字表示，比如3dw表示删除三个单词 　　dd 删除一行； 　　#dd 删除多个行，#代表数字，比如3dd 表示删除光标行及光标的下两行 　　d$ 删除光标到行尾的内容 　　J 清除光标所处的行与下一行之间的换行，行尾没有空格的话会自动添加一个空格。 　　#J 表示合并#(数字)行。 　　退出保存； 　　在命令模式下按 shift+: 文本底端出现冒号 　　:w 保存； 　　:w filename 另存为filename； 　　:wq! 保存退出； 　　:wq! filename 注：以filename为文件名保存后退出； 　　:q! 不保存退出； 　　:x 应该是保存并退出 ，功能和:wq!相同 　　撤销操作 　　u命令取消最近一次的操作，可以使用多次来恢复原有的操作[1] 　　U取消所有操作 　　Ctrl+R可以恢复对使用u命令的操作 　　复制操作 　　yy命令复制当前整行的内容到vi缓冲区 　　yw复制当前光标所在位置到单词尾字符的内容到vi缓存区，相当于复制一个单词 　　y$复制光标所在位置到行尾内容到缓存区 　　y^复制光标所在位置到行首内容到缓存区 　　#yy例如：5yy就是复制5行 　　#yw例如：2yw就是复制两个单词 　　如果要复制第m行到第n行之间的内容，可以在末行模式中输入m，ny例如：3，5y复制第三行到第五行内容到缓存区。 　　查找和替换 　　vi的查找和替换功能主要在末行模式完成： 　　至上而下的查找 　　/ 要查找的字符串，其中/代表从光标所在位置起开始查找，例如：/ work 　　至下而上的查找 　　?要查找的字符串 例如：? work 　　替换 　　:s/old/new用new替换行中首次出现的old 　　: s/old/new/g 用new替换行中所有出现的old 　　:#,# s/old/new/g用new替换从第#行到第#行中出现的old 　　:% s/old/new/g用new替换整篇中出现的old 　　如果替换的范围较大时，在所有的命令尾加一个c命令，强制每个替换需要用户进行确认，例如:s/old/new/c 或s/old/new/gc 　　恢复文件　　 　vi在编辑某一个文件时，会生成一个临时文件，这个文件以 . 开头并以 .swp结尾。正常退出该文件自动删除，如果意外退出例如忽然断电，该文件不会删除，我们在下次编辑时可以选择一下命令处理： 　　O只读打开，不改变文件内容 　　E继续编辑文件，不恢复.swp文件保存的内容 　　R将恢复上次编辑以后未保存文件内容 　　Q退出vi 　　D删除.swp文件 　　或者使用vi －r 文件名来恢复未保存的内容","title":"Linux下Vi基本操作"},{"content":"Linux命令学习笔记 新装系统进入： 1、新装的ubuntu10.04 进入root用户先要设置密码： sudo passwd root 输入密码 确认密码 2、系统软件安装、卸载、更新等操作命令 ·       apt-get update —在修改/etc/apt/sources.list或者/etc/apt/preferences之後运行该命令。此外您需要定期运行这一命令以确保您的软件包列表是最新的。 ·       apt-get install packagename —安装一个新软件包（参见下文的aptitude） ·       apt-get remove packagename —卸载一个已安装的软件包（保留配置文件） ·       apt-get --purge remove packagename —卸载一个已安装的软件包（删除配置文件） ·       dpkg --force-all --purge packagename 有些软件很难卸载，而且还阻止了别的软件的应用，就可以用这个，不过有点冒险。 ·       apt-get autoclean apt会把已装或已卸的软件都备份在硬盘上，所以如果需要空间的话，可以让这个命令来删除你已经删掉的软件 ·       apt-get clean 这个命令会把安装的软件的备份也删除，不过这样不会影响软件的使用的。 ·       apt-get upgrade —更新所有已安装的软件包 ·       apt-get dist-upgrade —将系统升级到新版本 ·       apt-cache search string —在软件包列表中搜索字符串 ·       dpkg -l package-name-pattern —列出所有与模式相匹配的软件包。如果您不知道软件包的全名，您可以使用“*package-name-pattern*”。 ·       aptitude —详细查看已安装或可用的软件包。与apt-get类似，aptitude可以通过命令行方式调用，但仅限于某些命令 —最常见的有安装和卸载命令。由于aptitude比apt-get了解更多信息，可以说它更适合用来进行安装和卸载。 ·       apt-cache showpkg pkgs —显示软件包信息。 ·       apt-cache dumpavail —打印可用软件包列表。 ·       apt-cache show pkgs —显示软件包记录，类似于dpkg –print-avail。 ·       apt-cache pkgnames —打印软件包列表中所有软件包的名称。 ·       dpkg -S file —这个文件属于哪个已安装软件包。 ·       dpkg -L package —列出软件包中的所有文件。 ·       apt-file search filename —查找包含特定文件的软件包（不一定是已安装的），这些文件的文件名中含有指定的字符串。apt-file是一个独立的软件包。您必须先使用apt-get install来安装它，然後运行apt-file update。如果apt-file search filename输出的内容太多，您可以尝试使用apt-file search filename | grep -w filename（只显示指定字符串作为完整的单词出现在其中的那些文件名）或者类似方法，例如：apt-file search filename | grep /bin/（只显示位于诸如/bin或/usr/bin这些文件夹中的文件，如果您要查找的是某个特定的执行文件的话，这样做是有帮助的）。 ·       apt-get autoclean —定期运行这个命令来清除那些已经卸载的软件包的.deb文件。通过这种方式，您可以释放大量的磁盘空间。如果您的需求十分迫切，可以使用apt-get clean以释放更多空间。这个命令会将已安装软件包裹的.deb文件一并删除。大多数情况下您不会再用到这些.debs文件，因此如果您为磁盘空间不足而感到焦头烂额，这个办法也许值得一试。   文件权限及目录配置 1、ls 命令： ls命令中列出所有文件的详细权限及属性的参数为 –al，命令格式如下： # ls –al -rw-rw-rw-  1     linux   linux     100     2012-12-17 19:52  test.c drwxr-xr-x  2     linux   linux     4096    2012-12-18 09:32  test 权限    连接    所有者  用户组  文件大小  修改日期          文件名 第一个参数 ‘-’代表文件 ‘d’代表文件夹 ‘l’链接文件 ‘b’接口设备 ‘c’串行端口设备 第二到第四个参数，文件所有者的权限  ‘r’可读 ‘w’可写 ‘x’可执行 第五到第七个参数，同用户组的权限  ‘r’可读 ‘w’可写 ‘x’可执行 第八到第十个参数，其他非本用户组的权限  ‘r’可读 ‘w’可写 ‘x’可执行     2、chgrp改变文件属性用户组，chown改变所有者，chmod改变文件的权限 chgrp命令格式：# chgrp [-R] usr dirname/filename ，其中‘R’表示进行递归的持续更改，连同子目录下的所有文件。如果存在疑问可以参见help： #chgrp –help chown命令格式：    # chown[-R] 帐号名称 dirname/filename    # chown[-R] 帐号名称：组名称  dirname/filename ， 其中‘R’表示进行递归的持续更改，连同子目录下的所有文件。如果存在疑问可以参见help： #chown –help chmod命令格式：# chown[-R] 帐号名称 dirname/filename ， 其中‘R’表示进行递归的持续更改，连同子目录下的所有文件。如果存在疑问可以参见help： #chmod –help eg： #chmod u=rwx，g=rx，o=r  test.c #chmod u=rwx，go=rx  test.c     r----4   w----2   x----1，因此用户和用户组的权限可以4，2，1三个数的组合表示。 eg：#chmod 777 test.c     u：用户，g：组，o：其他，a：所有，可以通过‘+’‘-’‘=’等设置文件的属性。     eg: chmod a+w test.c   所有的用户添加写权限。 chmod a-x test.c   所用的用户取消可执行权限。 注意：a、‘ ./’表示当前目录  b、‘ .’文件名前多了一个‘.’代表为隐藏文件  c、chmod的w权限不能随便给  d、/etc，/bin，/lib，/dev，/sbin 这5个目录不可与根目录放在不同的分区。   文件及目录管理 1、cd 命令： test/ test1 现在在test1中如果要直接到test2中，命令格式：#cd ../test2     / test2 返回上一级目录用#cd .. 进入到一下级子目录#cd 目录名 进入到绝对路径的目录#cd /home/…/… 2、pwd 命令： pwd 显示当前路径，命令格式为：#pwd 加上参数‘-P’显示当前路径而非链接路径命令格式为：#pwd –P 3、mkdir 命令： 建立目录命令格式为：#mkdir 文件名 加上参数‘-p’可自行创建多层目录命令格式为：#mkdir –p test1/test2/test3 注意p为小写。 加上参数‘-m’用来设置目录权限，命令格式为：#mkdir –m 755 test11 4、rmdir 命令： 删除目录命令格式为：#rmdir 文件名 加上参数‘-p’删除目录及子目录的命令格式为：#rmdir –p test1/test2/test3 注意p为小写。 注意：强行删除不为空的命令为：#rm –r  目录名   压缩 命令 1、tar 命令： 命令格式为：#tar [-j|-z][cv][-f 新建文件名] filename 打包 #tar [-j|-z][xv][-f 新建文件名] [-C目录] 如：#tar –jcv –f filename.tar.bz2 要被压缩的文件或目录     #tar –jxv –f filename.tar.bz2 –C目录     #tar –zcv –f filename.tar.gz 要被压缩的文件或目录     #tar –zxv –f filename.tar.gz –C目录   vi, vim 命令 通常系统带有vi命令，要安装一下vim命令，安装命令如下： #sudo apt-get install vim #密码 安装好后可以进行编辑。 vi有三种模式，一般模式，编辑模式和命令行模式。 一般模式：可以进行删除，复制，粘贴等，移动光标到指定的位置 [Ctrl]+[f]屏幕向下移动一页 [Ctrl]+[b]屏幕向上移动一页 0或 home键 光标移动到开始位置 $或end键 光标移动到最后位置   G光标移动到最后一行 nG光标移动到第n行 gg光标移动到第一行 N[Enter]光标下移n行   dd 删除光标所在行整行， ndd删除光标所在行以下的n行， x向后删除一个字符 X向前删除一个字符 yy复制光标所在行的一整行 nyy复制光标所在行的以下n行 p将已复制的数据在光标的下一行粘贴 P将已复制的数据在光标的上一行粘贴   :n1,n2s/word1/word2/g,n1,n2为数字，在n1和n2行之间查找word1并用word2替换 :1,#s/word1/word2/g，在第一和最后行之间查找word1并用word2替换 :1,#s/word1/word2/gc，在第一和最后行之间查找word1并用word2替换，需要确认   编辑模式：可以进行删除，复制，粘贴等，移动光标到指定的位置 i/I  i为在光标处插入，I在所在行第一个非空字符处插入 a/A  a为在光标处下一个字符处插入，A在所在行第后一个字符处插入 o/O  o为在光标处下一行处插入新一行，O在所在行处的上一行处插入新行 r/R  r为在光标处下一行处插入新一行，R在所在行处的上一行处插入新行      命令行模式：保存退出等相关操作    ：wq 退出保存    ：q退出    ：q! 强制离开不保存    ：ZZ 如果没有改动则不保存离开，如果改动则保存后离开    ：w[filename]另存为filename    ：n1，n2 w[filename] 将n1和n2行之间的内容保存成filename    ：set nu 显示行号    ：set nonu 不显示行号","title":"linux 学习笔记一"},{"content":"linux下文件的权限 1.什么是linux下的文件，文件权限有哪些。  文件：计算机中的资源在操作系统中的体现。在windows下文件有类型，用扩展名来区别。在linux下没有文件类型，没有扩展名。在linux下a.txt可能是可执行程序，a.exe可能是文本。  linux下，文件的命名规则：最长不能超过255个字符，包括：字母、数字、.、-、_等。windows下文件名不区分大小写，而在linux下严重区分大小写。  linux下文件权限：文件本身属性+用户操作的权限。  用ll指令查看文件或目录的权限。   其中： 第一个字符表示文件的类型   d表示目录   -表示普通文件   l表示链接文件（软链接）   r：read   w：write   x：execute（可执行文件）  第2-10个字符分3组表示文件的权限  2，3，4表示了文件所有者的权限  5，6，7表示文件所有者所在组的成员对该文件的权限  8，9，10other（除了文件所有者之外）权限 修改权限： chmod [权限选项] 文件 -限选项的写法：  1.数字表示法：r:4  w:2   x:1 -:0  将每组数字分别相加，得到权限数字代码  rw-r--r-- ====>420400400------->644  2.文本表示法：  用户的表示： u：user文件所有者    g：group 文件所有者同组成员    o：other    a：all所有用户    权限表示： r：read    w：write    x：execute      更改文件所有者： chown [参数] 用户 文件    chown php aa  ","title":"Linux下文件的权限"},{"content":"java程序中要执行linux命令主要依赖2个类：Process和Runtime 首先看一下Process类： [plain] view plaincopyprint? ProcessBuilder.start() 和 Runtime.exec 方法创建一个本机进程，并返回 Process 子类的一个实例，   该实例可用来控制进程并获得相关信息。Process 类提供了执行从进程输入、执行输出到进程、等待进程完成、   检查进程的退出状态以及销毁（杀掉）进程的方法。   创建进程的方法可能无法针对某些本机平台上的特定进程很好地工作，比如，本机窗口进程，守护进程，Microsoft Windows   上的 Win16/DOS 进程，或者 shell 脚本。创建的子进程没有自己的终端或控制台。它的所有标准 io（即 stdin、stdout 和 stderr）   操作都将通过三个流 (getOutputStream()、getInputStream() 和 getErrorStream()) 重定向到父进程。   父进程使用这些流来提供到子进程的输入和获得从子进程的输出。因为有些本机平台仅针对标准输入和输出流提供有限的缓冲区大小，   如果读写子进程的输出流或输入流迅速出现失败，则可能导致子进程阻塞，甚至产生死锁。   当没有 Process 对象的更多引用时，不是删掉子进程，而是继续异步执行子进程。   对于带有 Process 对象的 Java 进程，没有必要异步或并发执行由 Process 对象表示的进程。   ProcessBuilder.start() 和 Runtime.exec 方法创建一个本机进程，并返回 Process 子类的一个实例，该实例可用来控制进程并获得相关信息。Process 类提供了执行从进程输入、执行输出到进程、等待进程完成、检查进程的退出状态以及销毁（杀掉）进程的方法。创建进程的方法可能无法针对某些本机平台上的特定进程很好地工作，比如，本机窗口进程，守护进程，Microsoft Windows上的 Win16/DOS 进程，或者 shell 脚本。创建的子进程没有自己的终端或控制台。它的所有标准 io（即 stdin、stdout 和 stderr）操作都将通过三个流 (getOutputStream()、getInputStream() 和 getErrorStream()) 重定向到父进程。父进程使用这些流来提供到子进程的输入和获得从子进程的输出。因为有些本机平台仅针对标准输入和输出流提供有限的缓冲区大小，如果读写子进程的输出流或输入流迅速出现失败，则可能导致子进程阻塞，甚至产生死锁。当没有 Process 对象的更多引用时，不是删掉子进程，而是继续异步执行子进程。对于带有 Process 对象的 Java 进程，没有必要异步或并发执行由 Process 对象表示的进程。 特别需要注意的是： 1，创建的子进程没有自己的终端控制台，所有标注操作都会通过三个流 (getOutputStream()、getInputStream() 和 getErrorStream()) 重定向到父进程（父进程可通过这些流判断子进程的执行情况） 2，因为有些本机平台仅针对标准输入和输出流提供有限的缓冲区大小，如果读写子进程的输出流或输入流迅速出现失败， 则可能导致子进程阻塞，甚至产生死锁 [plain] view plaincopyprint? abstract  void destroy()              杀掉子进程。    abstract  int exitValue()              返回子进程的出口值。根据惯例，值0表示正常终止。    abstract  InputStream getErrorStream()              获取子进程的错误流。    abstract  InputStream getInputStream()              获取子进程的输入流。    abstract  OutputStream getOutputStream()              获取子进程的输出流。    abstract  int waitFor()              导致当前线程等待，如有必要，一直要等到由该 Process 对象表示的进程已经终止。        如果已终止该子进程，此方法立即返回。如果没有终止该子进程，调用的线程将被阻塞，直到退出子进程。   abstract  void destroy()           杀掉子进程。 abstract  int exitValue()           返回子进程的出口值。根据惯例，值0表示正常终止。 abstract  InputStream getErrorStream()           获取子进程的错误流。 abstract  InputStream getInputStream()           获取子进程的输入流。 abstract  OutputStream getOutputStream()           获取子进程的输出流。 abstract  int waitFor()           导致当前线程等待，如有必要，一直要等到由该 Process 对象表示的进程已经终止。 \t 如果已终止该子进程，此方法立即返回。如果没有终止该子进程，调用的线程将被阻塞，直到退出子进程。 特别需要注意：如果子进程中的输入流，输出流或错误流中的内容比较多，最好使用缓存（注意上面的情况2） 再来看一下Runtime类： [plain] view plaincopyprint? 每个Java应用程序都有一个Runtime类实例，使应用程序能够与其运行的环境相连接。可以通过getRuntime方法获取当前运行时环境。    应用程序不能创建自己的Runtime类实例。    每个Java应用程序都有一个Runtime类实例，使应用程序能够与其运行的环境相连接。可以通过getRuntime方法获取当前运行时环境。 应用程序不能创建自己的Runtime类实例。 介绍几个主要方法： [plain] view plaincopyprint? Process exec(String command)             在单独的进程中执行指定的字符串命令。   Process exec(String command, String[] envp)             在指定环境的单独进程中执行指定的字符串命令。   Process exec(String command, String[] envp, File dir)             在有指定环境和工作目录的独立进程中执行指定的字符串命令。   Process exec(String[] cmdarray)             在单独的进程中执行指定命令和变量。    Process exec(String[] cmdarray, String[] envp)             在指定环境的独立进程中执行指定命令和变量。    Process exec(String[] cmdarray, String[] envp, File dir)             在指定环境和工作目录的独立进程中执行指定的命令和变量。     Process exec(String command)           在单独的进程中执行指定的字符串命令。 Process exec(String command, String[] envp)           在指定环境的单独进程中执行指定的字符串命令。 Process exec(String command, String[] envp, File dir)           在有指定环境和工作目录的独立进程中执行指定的字符串命令。 Process exec(String[] cmdarray)           在单独的进程中执行指定命令和变量。  Process exec(String[] cmdarray, String[] envp)           在指定环境的独立进程中执行指定命令和变量。  Process exec(String[] cmdarray, String[] envp, File dir)           在指定环境和工作目录的独立进程中执行指定的命令和变量。  command： 一条指定的系统命令。 envp：环境变量字符串数组，其中每个环境变量的设置格式为name=value；如果子进程应该继承当前进程的环境，则该参数为null。 dir：子进程的工作目录；如果子进程应该继承当前进程的工作目录，则该参数为null。 cmdarray：包含所调用命令及其参数的数组。 以下为示例（要打成可执行jar包扔到linux下执行）： [java] view plaincopyprint? public class test {       public static void main(String[] args){           InputStream in = null;           try {               Process pro = Runtime.getRuntime().exec(new String[]{\"sh\",                                        \"/home/test/test.sh\",\"select admin from M_ADMIN\",                                        \"/home/test/result.txt\"});               pro.waitFor();               in = pro.getInputStream();               BufferedReader read = new BufferedReader(new InputStreamReader(in));               String result = read.readLine();               System.out.println(\"INFO:\"+result);           } catch (Exception e) {               e.printStackTrace();           }       }   }   public class test {\tpublic static void main(String[] args){\t\tInputStream in = null;\t\ttry {\t\t\tProcess pro = Runtime.getRuntime().exec(new String[]{\"sh\",                        \t         \"/home/test/test.sh\",\"select admin from M_ADMIN\",                        \t         \"/home/test/result.txt\"});\t\t\tpro.waitFor();\t\t\tin = pro.getInputStream();\t\t\tBufferedReader read = new BufferedReader(new InputStreamReader(in));\t\t\tString result = read.readLine();\t\t\tSystem.out.println(\"INFO:\"+result);\t\t} catch (Exception e) {\t\t\te.printStackTrace();\t\t}\t}} 在这用的是Process exec(String[] cmdarray)这个方法  /home/test/test.sh脚本如下： [plain] view plaincopyprint? #!/bin/sh      #查询sql   SQL=$1   #查询结果保存文件   RESULT_FILE=$2   #数据库连接   DB_NAME=scott   DB_PWD=tiger   DB_SERVER=DB_TEST      RESULT=`sqlplus -S ${DB_NAME}/${DB_PWD}@${DB_SERVER}<< !    set heading off   set echo off   set pages 0   set feed off   set linesize 3000   ${SQL}   /   commit   /   !`          echo \"${RESULT}\" >> ${RESULT_FILE}   echo 0;  ","title":"java 实现linux命令"},{"content":"1、关于设备驱动中的中断问题       操作系统为了使得快速设备和慢速设备合适工作，需要中断来提高效率，一个外设要使用一个中断就必须注册中断号，获得跟这个中断号相关的一些资源，并且在中断发生的时候内核可以进行一些处理，例如：调用中断处理例程来真正的处理设备中断。Linux处理中断的方式很大程度上与它在用户空间处理信号的方式是一样的。       我们知道，从本质上讲，中断处理例程会和其他代码并发运行，这就会涉及到竞态和并发的问题。       接下来我们就来讲讲有关中断的实现和使用：        首先，我们需要注册一个中断，可如下注册，在 [cpp] view plaincopyprint? <SPAN style=\"FONT-SIZE: 18px\">int request_irq(unsigned int irq, irq_handler_t handler, unsigned long flags,           const char *name, void *dev)   int request_irq(unsigned int irq, irq_handler_t handler, unsigned long flags, const char *name, void *dev)        参数说明：                  第一个参数：要申请的中断号，主要看硬件的连接方式决定；                  第二个参数：中断处理例程，自己实现，在发生中断的时候调用，稍候详细说明；                  第三个参数：中断管理的标志，是一个位掩码选项，例如可设置一个中断号在几个设备间共享，常见的就                                        是开发板上的ADC和Touch Screen共享ADC中断；                  第四个参数：用来标示中断拥有者的名称，可自己设定；                  第五个参数：用于共享的中断信号线，稍候详细说明。        调用request_irq的正确位置应该是设备第一次打开、硬件被告知产生中断之前。        接下来，注册后怎么注销呢？调用如下函数即可： [cpp] view plaincopyprint? <SPAN style=\"FONT-SIZE: 18px\">void free_irq(unsigned int irq, void *dev);   void free_irq(unsigned int irq, void *dev);       这里参数的意义和上面是一样的。         调用free_irq的位置应该是最后一次关闭设备、硬件被告知不用再中断处理器后。 有关中断处理例程：         首先看看irq_handler_t的定义，显然它应该是一个自定义类型，定义在：include/linux/interrupt.h中： [cpp] view plaincopyprint? <SPAN style=\"FONT-SIZE: 18px\">typedef irqreturn_t (*irq_handler_t)(int, void *);   typedef irqreturn_t (*irq_handler_t)(int, void *);        确实是一个类型定义，是一个函数指针类型，指向的函数有两个参数，一个irqreturn_t类型的返回值，这也是一个自定义类型，定义在include/linux/irqreturn.h中： [cpp] view plaincopyprint? <SPAN style=\"FONT-SIZE: 18px\">typedef enum irqreturn irqreturn_t;   typedef enum irqreturn irqreturn_t;        确实是一个自定义类型，看看typedef就知道了，而且是一个枚举类型，接着看看这个枚举类型 [cpp] view plaincopyprint? <SPAN style=\"FONT-SIZE: 18px\">/**   * enum irqreturn   * @IRQ_NONE        interrupt was not from this device   * @IRQ_HANDLED     interrupt was handled by this device   * @IRQ_WAKE_THREAD handler requests to wake the handler thread   */   enum irqreturn {       IRQ_NONE,       IRQ_HANDLED,       IRQ_WAKE_THREAD,   };      /** * enum irqreturn * @IRQ_NONE interrupt was not from this device * @IRQ_HANDLED interrupt was handled by this device * @IRQ_WAKE_THREAD handler requests to wake the handler thread */ enum irqreturn { IRQ_NONE, IRQ_HANDLED, IRQ_WAKE_THREAD, };          这个枚举类型里面的值代表着中断处理例程的处理结果，也就是中断程序的返回值。OK，这下就清除多了！ 2、中断处理的示例      这里是友善之臂的按键设备驱动程序，做了一些注释，对比这上面的理论部分就比较好理解了。 [cpp] view plaincopyprint? #include <linux/module.h>    #include <linux/kernel.h>    #include <linux/fs.h>    #include <linux/init.h>    #include <linux/delay.h>    #include <linux/poll.h>    #include <linux/irq.h>    #include <asm/irq.h>    #include <asm/io.h>    #include <linux/interrupt.h>    #include <asm/uaccess.h>    #include <mach/hardware.h>    #include <linux/platform_device.h>    #include <linux/cdev.h>    #include <linux/miscdevice.h>       #include <mach/map.h>    #include <mach/regs-clock.h>    #include <mach/regs-gpio.h>       #include <plat/gpio-cfg.h>    #include <mach/gpio-bank-n.h>    #include <mach/gpio-bank-l.h>       #define DEVICE_NAME     \"buttons\"       /*用于描述每个按键中断的结构体*/   struct button_irq_desc {       int irq;       int number;       char *name;    };      static struct button_irq_desc button_irqs [] = {       {IRQ_EINT( 0), 0, \"KEY0\"},       {IRQ_EINT( 1), 1, \"KEY1\"},       {IRQ_EINT( 2), 2, \"KEY2\"},       {IRQ_EINT( 3), 3, \"KEY3\"},       {IRQ_EINT( 4), 4, \"KEY4\"},       {IRQ_EINT( 5), 5, \"KEY5\"},       {IRQ_EINT(19), 6, \"KEY6\"},       {IRQ_EINT(20), 7, \"KEY7\"},   };   static volatile char key_values [] = {'0', '0', '0', '0', '0', '0', '0', '0'};         /*涉及到中断处理例程，所以就需要注意竟态和并发问题*/   static DECLARE_WAIT_QUEUE_HEAD(button_waitq);      /*唤醒等待队列的条件，可以是任意的布尔表达式*/   static volatile int ev_press = 0;      /*中断处理例程*/   static irqreturn_t buttons_interrupt(int irq, void *dev_id)   {       struct button_irq_desc *button_irqs = (struct button_irq_desc *)dev_id;       int down;       int number;       unsigned tmp;          udelay(0);       number = button_irqs->number;       switch(number) {       /*key0~key5使用的是EINT0～EINT5,看芯片手册就知道是GPN口上的功能*/       case 0: case 1: case 2: case 3: case 4: case 5:           tmp = readl(S3C64XX_GPNDAT);           down = !(tmp & (1<<number));           break;           /*key6~key7使用EINT19~EINT20,使用GPL引脚*/       case 6: case 7:           tmp = readl(S3C64XX_GPLDAT);           down = !(tmp & (1 << (number + 5)));           break;       default:           down = 0;       }          /*判断是否有按键按下*/       if (down != (key_values[number] & 1)) {           key_values[number] = '0' + down;              /*唤醒等待队列，此刻实际上是唤醒读进程*/               ev_press = 1;               wake_up_interruptible(&button_waitq);           }          /*该返回值代表中断确实真的处理了该中断*/           return IRQ_RETVAL(IRQ_HANDLED);   }         static int s3c64xx_buttons_open(struct inode *inode, struct file *file)   {       int i;       int err = 0;                     for (i = 0; i < sizeof(button_irqs)/sizeof(button_irqs[0]); i++) {       if (button_irqs[i].irq < 0) {           continue;       }       /*申请中断号*/           err = request_irq(button_irqs[i].irq, buttons_interrupt, IRQ_TYPE_EDGE_BOTH,                              button_irqs[i].name, (void *)&button_irqs[i]);           if (err)               break;       }          /*如果在申请中断的时候发生错误，那么就释放掉已申请的中断号*/       if (err) {           i--;           for (; i >= 0; i--) {           if (button_irqs[i].irq < 0) {           continue;           }           disable_irq(button_irqs[i].irq);               free_irq(button_irqs[i].irq, (void *)&button_irqs[i]);           }           return -EBUSY;       }          ev_press = 1;              return 0;   }         static int s3c64xx_buttons_close(struct inode *inode, struct file *file)   {       int i;              /*释放获得的中断资源*/       for (i = 0; i < sizeof(button_irqs)/sizeof(button_irqs[0]); i++) {       if (button_irqs[i].irq < 0) {           continue;       }       free_irq(button_irqs[i].irq, (void *)&button_irqs[i]);       }          return 0;   }         static int s3c64xx_buttons_read(struct file *filp, char __user *buff, size_t count, loff_t *offp)   {       unsigned long err;          if (!ev_press) {       if (filp->f_flags & O_NONBLOCK)      //非阻塞读取            return -EAGAIN;       else                               wait_event_interruptible(button_waitq, ev_press);   //阻塞读取，则进入休眠，等待发生中断时由中断例程唤醒        }              ev_press = 0;          err = copy_to_user((void *)buff, (const void *)(&key_values), min(sizeof(key_values), count));          return err ? -EFAULT : min(sizeof(key_values), count);   }      /*用于轮询操作*/   static unsigned int s3c64xx_buttons_poll( struct file *file, struct poll_table_struct *wait)   {       unsigned int mask = 0;       poll_wait(file, &button_waitq, wait);       if (ev_press)           mask |= POLLIN | POLLRDNORM;       /*返回标示是否可立即无阻塞执行的位掩码*/       return mask;   }         static struct file_operations dev_fops = {       .owner   =   THIS_MODULE,       .open    =   s3c64xx_buttons_open,       .release =   s3c64xx_buttons_close,        .read    =   s3c64xx_buttons_read,       .poll    =   s3c64xx_buttons_poll,   };      /*定义misc设备*/   static struct miscdevice misc = {       .minor = MISC_DYNAMIC_MINOR,       .name = DEVICE_NAME,       .fops = &dev_fops,   };      static int __init dev_init(void)   {       int ret;          ret = misc_register(&misc);          printk (DEVICE_NAME\"\\tinitialized\\n\");          return ret;   }      static void __exit dev_exit(void)   {       misc_deregister(&misc);   }      module_init(dev_init);   module_exit(dev_exit);   MODULE_LICENSE(\"GPL\");   MODULE_AUTHOR(\"FriendlyARM Inc.\");  转自：http://blog.chinaunix.net/uid-28210032-id-3383138.html","title":"设备驱动中的中断问题及实例解析"},{"content":"linux设备驱动程序学习笔记.doc 转自：http://my.oschina.net/accesssoul/blog/61401","title":"linux设备驱动程序学习笔记"},{"content":"【IT168 技术】　　1.什么是段错误? 　　所谓的段错误就是指访问的内存超出了系统所给这个程序的内存空间，通常这个值是由gdtr来保存的，他是一个48位的寄存器，其中的32位是保存由它指向的gdt表，后13位保存相应于gdt的下标，最后3位包括了程序是否在内存中以及程序的在cpu中的运行级别，指向的gdt 是由以64位为一个单位的表，在这张表中就保存着程序运行的代码段以及数据段的起始地址以及与此相应的段限和页面交换还有程序运行级别还有内存粒度等等的信息。一旦一个程序发生了越界访问，cpu就会产生相应的异常保护，于是segmentatiON fault就出现了。 　　通过上面的解释，段错误应该就是访问了不可访问的内存，这个内存区要么是不存在的，要么是受到系统保护的。 　　2.那什么操作会引起段错误呢? 　　粗略的分一下类： 　　1)往受到系统保护的内存地址写数据 　　有些内存是内核占用的或者是其他程序正在使用，为了保证系统正常工作，所以会受到系统的保护，而不能任意访问。 　　2)内存越界(数组越界，变量类型不一致等) 　　3)其他 　　例如： 　　<1>定义了指针后记得初始化，在使用的时候记得判断是否为NULL 　　<2>在使用数组的时候是否被初始化，数组下标是否越界，数组元素是否存在等 　　<3>在变量处理的时候变量的格式控制是否合理等 　　3.那么我们如何去发现程序中的段错误呢? 　　通过学习前人的经验和开发的工具，不断的尝试和研究，找出更恰当的方法来避免、发现并处理它。对于一些常见的地方，我们可以避免，对于一些“隐藏”的地方，我们要发现它，发现以后就要及时处理，避免留下隐患。 　　用gdb来调试，在运行到段错误的地方，会自动停下来并显示出错的行和行号，gdb也是最常用的，如果需要用gdb调试，记得在编译的时候加上-g参数。   摘自：http://os.chinaunix.net/a2012/0130/1304/000001304535.shtml","title":"Linux C中段错误"},{"content":"【IT168 技术】　　Linux chkconfig命令主要用来更新(启动或停止)和查询系统服务的运行级信息。谨记chkconfig不是立即自动禁止或激活一个服务，它只是简单的改变了符号连接。 　　Linux chkconfig命令使用语法： 　　chkconfig [--add] [--del ][--list] [系统服务] 或 chkconfig [--level <等级代号> ] [系统服务] [on/off/reset] 　　Linux chkconfig命令在没有参数运行时，显示用法。如果加上服务名，那么就检查这个服务是否在当前运行级启动。如果是，返回true，否则返回 false。如果在服务名后面指定了on，off或者reset，那么chkconfi会改变指定服务的启动信息。on和off分别指服务被启动和停止，reset指重置服务的启动信息，无论有问题的初始化脚本指定了什么。on和off开关，系统默认只对运行级3，4，5有效，但是reset可以对所有运行级有效。 　　Linux chkconfig命令参数用法： 　　--add　增加所指定的系统服务，让chkconfig指令得以管理它，并同时在系统启动的叙述文件内增加相关数据。 　　--del　删除所指定的系统服务，不再由chkconfig指令管理，并同时在系统启动的叙述文件内删除相关数据。 　　--level<等级代号>　指定读系统服务要在哪一个执行等级中开启或关毕。 　　等级0表示：表示关机 　　等级1表示：单用户模式 　　等级2表示：无网络连接的多用户命令行模式 　　等级3表示：有网络连接的多用户命令行模式 　　等级4表示：不可用 　　等级5表示：带图形界面的多用户模式 　　等级6表示：重新启动 　　需要说明的是，level选项可以指定要查看的运行级而不一定是当前运行级。对于每个运行级，只能有一个启动脚本或者停止脚本。当切换运行级时，init不会重新启动已经启动的服务，也不会再次去停止已经停止的服务。 　　chkconfig --list name ：显示所有运行级系统服务的运行状态信息(on或off)。如果指定了name，那么只显示指定的服务在不同运行级的状态。 　　chkconfig --add name：增加一项新的服务。chkconfig确保每个运行级有一项启动(S)或者杀死(K)入口。如有缺少，则会从缺省的init脚本自动建立。 　　chkconfig --del name：删除服务，并把相关符号连接从/etc/rc[0-6].d删除。 　　chkconfig --level [levels] name：设置某一服务在指定的运行级是被启动，停止还是重置。 　　Linux chkconfig命令运行级文件： 　　每个被chkconfig管理的服务需要在对应的init.d下的脚本加上两行或者更多行的注释。第一行告诉chkconfig缺省启动的运行级以及启动和停止的优先级。如果某服务缺省不在任何运行级启动，那么使用-代替运行级。第二行对服务进行描述，可以用\\跨行注释。 例如，crond包含三行： 　　# chkconfig: 2345 90 60 　　# description: cron is a standard UNIX program that runs user-specified \\ 　　# programs at periodic scheduled times. vixie cron adds a \\ 　　# number of features to the basic UNIX cron, including better \\ 　　# security and more powerful configuration options. 　　# processname: crond 　　Linux chkconfig命令使用范例： 　　chkconfig --list #列出所有的系统服务 　　chkconfig --add httpd #增加httpd服务 　　chkconfig --del httpd #删除httpd服务 　　chkconfig --level 2345 httpd on #设置httpd在运行级别为2、3、4、5的情况下都是on(开启)的状态 　　Linux chkconfig命令如何增加一个服务： 　　1.服务脚本必须存放在/etc/ini.d/目录下; 　　2.chkconfig--addservicename 　　在chkconfig工具服务列表中增加此服务，此时服务会被在/etc/rc.d/rcN.d中赋予K/S入口了; 　　3.chkconfig --level 35 mysqld on 　　修改服务的默认启动等级 　　chkconfig 功能说明：检查、设定系统的各种服务。 　　语法：chkconfig [--add][--del][--list][系统服务]或 　　chkconfig [--level<等级代号>][系统服务][on/off/reset] 　　补充说明：这个是redhat公司遵循gpl规则所开发的程序，它可以查询操作系统在每一个执行等级(runlevel)中，会执行哪些系统服务，其中包括各种daemon。 　　linux os 将操作环境分为以下7个等级： 　　0:关机(请不要切换到此等级) 　　1:单人使用者模式的文字界面 　　2:多人使用者模式的文字界面，不具有网络档案系统(NFS)功能 　　3:多人使用者模式的文字界面，具有网络档案系统(NFS)功能 　　4:某些发行版的linux使用此等级进入x windows system 　　5:某些发行版的linux使用此等级进入x windows system 　　6:重新启动 　　参数： --add 新增所指定的系统服务 　　--del 删除所指定的系统服务 　　--level 指定该系统服务要在哪个执行等级中开启或关闭 　　--list 列出当前可从chkconfig指令管理的所有系统服务和等级代号 　　on/off/reset 在指定的执行登记，开启/关闭/重置该系统服务 　　chkconfig命令主要用来更新(启动或停止)和查询系统服务的运行级信息。谨记chkconfig不是立即自动禁止或激活一个服务，它只是简单的改变了符号连接。 　　语法： 　　chkconfig --list [name] 　　chkconfig --add name 　　chkconfig --del name 　　chkconfig [--level levels] name 　　chkconfig [--level levels] name 　　chkconfig 没有参数运行时，显示用法。如果加上服务名，那么就检查这个服务是否在当前运行级启动。如果是，返回true，否则返回false。如果在服务名后面指定 了on，off或者reset，那么chkconfi 会改变指定服务的启动信息。on和off分别指服务被启动和停止，reset指重置服务的启动信息，无论有问题的初始化脚本指定了什么。on和off开 关，系统默认只对运行级3，4，5有效，但是reset可以对所有运行级有效。 　　--level选项可以指定要查看的运行级而不一定是当前运行级。 　　需要说明的是，对于每个运行级，只能有一个启动脚本或者停止脚本。当切换运行级时，init不会重新启动已经启动的服务，也不会再次去停止已经停止的服务。 　　chkconfig --list ：显示所有运行级系统服务的运行状态信息(on或off)。如果指定了name，那么只显示指定的服务在不同运行级的状态。 　　chkconfig --add name：增加一项新的服务。chkconfig确保每个运行级有一项启动(S)或者杀死(K)入口。如有缺少，则会从缺省的init脚本自动建立。 　　chkconfig --del name：删除服务，并把相关符号连接从/etc/rc[0-6].d删除。 　　chkconfig [--level levels] name ：设置某一服务在指定的运行级是被启动，停止还是重置。例如，要在3，4，5运行级停止nfs服务，则命令如下： 　　chkconfig --level 345 nfs off 　　运行级文件： 　　每个被chkconfig管理的服务需要在对应的init.d下的脚本加上两行或者更多行的注释。第一行告诉chkconfig缺省启动的运行级以及启动 和停止的优先级。如果某服务缺省不在任何运行级启动，那么使用 - 代替运行级。第二行对服务进行描述，可以用\\ 跨行注释。 　　例如，random.init包含三行： 　　# chkconfig: 2345 20 80 　　# description: Saves and restores system entropy pool for \\ 　　# higher quality random number generation. 　　附加介绍一下Linux系统的运行级的概念： 　　Linux中有多种运行级，常见的就是多用户的2，3，4，5 ，很多人知道5是运行X-Windows的级别，而0就是关机了。运行级的改变可以通过init命令来切换。例如，假设你要维护系统进入单用户状态，那 么，可以使用init1来切换。在Linux的运行级的切换过程中，系统会自动寻找对应运行级的目录/etc/rc[0-6].d下的K和S开头的文件， 按后面的数字顺序，执行这些脚本。对这些脚本的维护，是很繁琐的一件事情，Linux提供了chkconfig命令用来更新和查询不同运行级上的系统服务。   摘自：http://os.chinaunix.net/a2012/0131/1305/000001305007.shtml","title":"Linux内核参数-proc"},{"content":"【IT168 技术】　　1) Linux Proc文件系统，通过对Proc文件系统进行调整，达到性能优化的目的。 　　2) Linux性能诊断工具，介绍如何使用Linux自带的诊断工具进行性能诊断。 　　/proc/sys/kernel/优化 　　1) /proc/sys/kernel/ctrl-alt-del 　　该文件有一个二进制值，该值控制系统在接收到ctrl+alt+delete按键组合时如何反应。这两个值分别是： 　　零(0)值，表示捕获ctrl+alt+delete，并将其送至 init 程序;这将允许系统可以安全地关闭和重启，就好象输入shutdown命令一样。 　　壹(1)值，表示不捕获ctrl+alt+delete，将执行非正常的关闭，就好象直接关闭电源一样。 　　缺省设置：0 　　建议设置：1，防止意外按下ctrl+alt+delete导致系统非正常重启。 　　2) proc/sys/kernel/msgmax 　　该文件指定了从一个进程发送到另一个进程的消息的最大长度(bytes)。进程间的消息传递是在内核的内存中进行的，不会交换到磁盘上，所以如果增加该值，则将增加操作系统所使用的内存数量。 　　缺省设置：8192 　　3) /proc/sys/kernel/msgmnb 　　该文件指定一个消息队列的最大长度(bytes)。 　　缺省设置：16384 　　4) /proc/sys/kernel/msgmni 　　该文件指定消息队列标识的最大数目，即系统范围内最大多少个消息队列。 　　缺省设置：16 　　5) /proc/sys/kernel/panic 　　该文件表示如果发生“内核严重错误(kernel panic)”，则内核在重新引导之前等待的时间(以秒为单位)。 　　零(0)秒，表示在发生内核严重错误时将禁止自动重新引导。 　　缺省设置：0 　　6) proc/sys/kernel/shmall 　　该文件表示在任何给定时刻，系统上可以使用的共享内存的总量(bytes)。 　　缺省设置：2097152 　　7) /proc/sys/kernel/shmmax 　　该文件表示内核所允许的最大共享内存段的大小(bytes)。 　　缺省设置：33554432 　　建议设置：物理内存 * 50% 　　实际可用最大共享内存段大小=shmmax * 98%，其中大约2%用于共享内存结构。 　　可以通过设置shmmax，然后执行ipcs -l来验证。 　　8) 　　/proc/sys/kernel/shmmni 　　该文件表示用于整个系统的共享内存段的最大数目(个)。 　　缺省设置：4096 　　9) /proc/sys/kernel/threads-max 　　该文件表示内核所能使用的线程的最大数目。 　　缺省设置：2048 　　10) /proc/sys/kernel/sem 　　该文件用于控制内核信号量，信号量是System VIPC用于进程间通讯的方法。 　　建议设置：250 32000 100 128 　　第一列，表示每个信号集中的最大信号量数目。 　　第二列，表示系统范围内的最大信号量总数目。 　　第三列，表示每个信号发生时的最大系统操作数目。 　　第四列，表示系统范围内的最大信号集总数目。 　　所以，(第一列)*(第四列)=(第二列) 　　以上设置，可以通过执行ipcs -l来验证。 　　11) 待续…… 　 /proc/sys/vm/优化 　　1) /proc/sys/vm/block_dump 　　该文件表示是否打开Block Debug模式，用于记录所有的读写及Dirty Block写回动作。 　　缺省设置：0，禁用Block Debug模式 　　2) /proc/sys/vm/dirty_background_ratio 　　该文件表示脏数据到达系统整体内存的百分比，此时触发pdflush进程把脏数据写回磁盘。 　　缺省设置：10 　　3) /proc/sys/vm/dirty_expire_centisecs 　　该文件表示如果脏数据在内存中驻留时间超过该值，pdflush进程在下一次将把这些数据写回磁盘。 　　缺省设置：3000(1/100秒) 　　4) /proc/sys/vm/dirty_ratio 　　该文件表示如果进程产生的脏数据到达系统整体内存的百分比，此时进程自行把脏数据写回磁盘。 　　缺省设置：40 　　5) 　　/proc/sys/vm/dirty_writeback_centisecs 　　该文件表示pdflush进程周期性间隔多久把脏数据写回磁盘。 　　缺省设置：500(1/100秒) 　　6) /proc/sys/vm/vfs_cache_pressure 　　该文件表示内核回收用于directory和inode cache内存的倾向;缺省值100表示内核将根据pagecache和swapcache，把directory和inode cache保持在一个合理的百分比;降低该值低于100，将导致内核倾向于保留directory和inode cache;增加该值超过100，将导致内核倾向于回收directory和inode cache。 　　缺省设置：100 　　7) /proc/sys/vm/min_free_kbytes 　　该文件表示强制Linux VM最低保留多少空闲内存(Kbytes)。 　　缺省设置：724(512M物理内存) 　　8) /proc/sys/vm/nr_pdflush_threads 　　该文件表示当前正在运行的pdflush进程数量，在I/O负载高的情况下，内核会自动增加更多的pdflush进程。 　　缺省设置：2(只读) 　　9) /proc/sys/vm/overcommit_memory 　　该文件指定了内核针对内存分配的策略，其值可以是0、1、2。 　　0， 表示内核将检查是否有足够的可用内存供应用进程使用;如果有足够的可用内存，内存申请允许;否则，内存申请失败，并把错误返回给应用进程。 　　1， 表示内核允许分配所有的物理内存，而不管当前的内存状态如何。 　　2， 表示内核允许分配超过所有物理内存和交换空间总和的内存(参照overcommit_ratio)。 　　缺省设置：0 　　10) /proc/sys/vm/overcommit_ratio 　　该文件表示，如果overcommit_memory=2，可以过载内存的百分比，通过以下公式来计算系统整体可用内存。 　　系统可分配内存=交换空间+物理内存*overcommit_ratio/100 　　缺省设置：50(%) 　　11) /proc/sys/vm/page-cluster 　　该文件表示在写一次到swap区的时候写入的页面数量，0表示1页，1表示2页，2表示4页。 　　缺省设置：3(2的3次方，8页) 　　12) /proc/sys/vm/swapiness 　　该文件表示系统进行交换行为的程度，数值(0-100)越高，越可能发生磁盘交换。 　　缺省设置：60 　　13) legacy_va_layout 　　该文件表示是否使用最新的32位共享内存mmap()系统调用，Linux支持的共享内存分配方式包括mmap()，Posix，System VIPC。 　　0， 使用最新32位mmap()系统调用。 　　1， 使用2.4内核提供的系统调用。 　　缺省设置：0 　　14) nr_hugepages 　　该文件表示系统保留的hugetlb页数。 　　15) hugetlb_shm_group 　　该文件表示允许使用hugetlb页创建System VIPC共享内存段的系统组ID。 　　16) 待续…… 　　/proc/sys/fs/优化 　　1) /proc/sys/fs/file-max 　　该文件指定了可以分配的文件句柄的最大数目。如果用户得到的错误消息声明由于打开 　　文件数已经达到了最大值，从而他们不能打开更多文件，则可能需要增加该值。 　　缺省设置：4096 　　建议设置：65536 　　2) /proc/sys/fs/file-nr 　　该文件与 file-max 相关，它有三个值： 　　已分配文件句柄的数目 　　已使用文件句柄的数目 　　文件句柄的最大数目 　　该文件是只读的，仅用于显示信息。 　　3) 待续…… 　　/proc/sys/net/core/优化 　　该目录下的配置文件主要用来控制内核和网络层之间的交互行为。 　　1) /proc/sys/net/core/message_burst 　　写新的警告消息所需的时间(以 1/10 秒为单位);在这个时间内系统接收到的其它警告消息会被丢弃。这用于防止某些企图用消息“淹没”系统的人所使用的拒绝服务(Denial of Service)攻击。 　　缺省设置：50(5秒) 　　2) /proc/sys/net/core/message_cost 　　该文件表示写每个警告消息相关的成本值。该值越大，越有可能忽略警告消息。 　　缺省设置：5 　　3) /proc/sys/net/core/netdev_max_backlog 　　该文件表示在每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。 　　缺省设置：300 　　4) /proc/sys/net/core/optmem_max 　　该文件表示每个套接字所允许的最大缓冲区的大小。 　　缺省设置：10240 　　5) /proc/sys/net/core/rmem_default 　　该文件指定了接收套接字缓冲区大小的缺省值(以字节为单位)。 　　缺省设置：110592 　　6) /proc/sys/net/core/rmem_max 　　该文件指定了接收套接字缓冲区大小的最大值(以字节为单位)。 　　缺省设置：131071 　　7) /proc/sys/net/core/wmem_default 　　该文件指定了发送套接字缓冲区大小的缺省值(以字节为单位)。 　　缺省设置：110592 　　8) /proc/sys/net/core/wmem_max 　　该文件指定了发送套接字缓冲区大小的最大值(以字节为单位)。 　　缺省设置：131071 　　9) 待续…… 　　六、/proc/sys/net/ipv4/优化 　　1) /proc/sys/net/ipv4/ip_forward 　　该文件表示是否打开IP转发。 　　0，禁止 　　1，转发 　　缺省设置：0 　　2) /proc/sys/net/ipv4/ip_default_ttl 　　该文件表示一个数据报的生存周期(Time To Live)，即最多经过多少路由器。 　　缺省设置：64 　　增加该值会降低系统性能。 　　3) /proc/sys/net/ipv4/ip_no_pmtu_disc 　　该文件表示在全局范围内关闭路径MTU探测功能。 　　缺省设置：0 　　4) /proc/sys/net/ipv4/route/min_pmtu 　　该文件表示最小路径MTU的大小。 　　缺省设置：552   摘自：http://os.chinaunix.net/a2012/0131/1305/000001305007.shtml","title":"Linux内核参数-proc"},{"content":"【IT168 技术】　　无论是在Linux还是在Unix环境中，make都是一个非常重要的编译命令。不管是自己进行项目开发还是安装应用软件，我们都经常要用到make或make install.利用make工具，我们可以将大型的开发项目分解成为多个更易于管理的模块，对于一个包括几百个源文件的应用程序，使用make和makefile工具就可以简洁明快地理顺各个源文件之间纷繁复杂的相互关系。而且如此多的源文件，如果每次都要键入gcc命令进行编译的话，那对程序员来说简直就是一场灾难。而make工具则可自动完成编译工作，并且可以只对程序员在上次编译后修改过的部分进行编译。因此，有效的利用make和makefile工具可以大大提高项目开发的效率。同时掌握make和makefile之后，您也不会再面对着Linux下的应用软件手足无措了。 　　但令人遗憾的是，在许多讲述Linux应用的书籍上都没有详细介绍这个功能强大但又非常复杂的编译工具。在这里我就向大家详细介绍一下 　　make及其描述文件makefile. Makefile文件Make工具最主要也是最基本的功能就是通过makefile文件来描述源程序之间的相互关系并自动维护编译工作。而makefile 文件需要按照某种语法进行编写，文件中需要说明如何编译各个源文件并连接生成可执行文件，并要求定义源文件之间的依赖关系。makefile 文件是许多编译器——包括 Windows NT 下的编译器——维护编译信息的常用方法，只是在集成开发环境中，用户通过友好的界面修改 makefile 文件而已。 　　在 UNIX 系统中，习惯使用 Makefile 作为 makfile 文件。如果要使用其他文件作为 makefile，则可利用类似下面的 make 命令选项指定 makefile 文件：$ make -f Makefile.debug例如，一个名为prog的程序由三个C源文件filea.c、fileb.c和filec.c以及库文件LS编译生成，这三个文件还分别包含自己的头文件a.h 、b.h和c.h.通常情况下，C编译器将会输出三个目标文件filea.o、fileb.o和filec.o.假设filea.c和fileb.c都要声明用到一个名为defs的文件，但filec.c不用。即在filea.c和fileb.c里都有这样的声明：#include \"defs\"那么下面的文档就描述了这些文件之间的相互联系： 　　--------------------------------------------------------- 　　#It is a example for describing makefile prog ： filea.o fileb.o filec.o cc filea.o fileb.o filec.o -LS -o prog filea.o ： filea.c a.h defs cc -c filea.c fileb.o ： fileb.c b.h defs cc -c fileb.c filec.o ： filec.c c.h cc -c filec.c 　　---------------------------------------------------------- 　　这个描述文档就是一个简单的makefile文件。 　　从上面的例子注意到，第一个字符为 # 的行为注释行。第一个非注释行指定prog由三个目标文件filea.o、fileb.o和filec.o链接生成。第三行描述了如何从prog所依赖的文件建立可执行文件。接下来的4、6、8行分别指定三个目标文件，以及它们所依赖的。c和。h文件以及defs文件。而5、7、9行则指定了如何从目标所依赖的文件建立目标。 　　当filea.c或a.h文件在编译之后又被修改，则 make 工具可自动重新编译filea.o，如果在前后两次编译之间，filea.C 和a.h 均没有被修改，而且 test.o 还存在的话，就没有必要重新编译。这种依赖关系在多源文件的程序编译中尤其重要。通过这种依赖关系的定义，make 工具可避免许多不必要的编译工作。当然，利用 Shell 脚本也可以达到自动编译的效果，但是，Shell 脚本将全部编译任何源文件，包括哪些不必要重新编译的源文件，而 make 工具则可根据目标上一次编译的时间和目标所依赖的源文件的更新时间而自动判断应当编译哪个源文件。 　　所以有时候重新编译内核，速度比较快。 不编译没有更新的。 　　Makefile文件作为一种描述文档一般需要包含以下内容：◆ 宏定义◆ 源文件之间的相互依赖关系◆ 可执行的命令Makefile中允许使用简单的宏指代源文件及其相关编译信息，在Linux中也称宏为变量。在引用宏时只需在变量前加$符号，但值得注意的是，如果变量名的长度超过一个字符，在引用时就必须加圆括号()。 　　下面都是有效的宏引用：$(CFLAGS) 　　$Z $(Z) 　　其中最后两个引用是完全一致的。 　　需要注意的是一些宏的预定义变量，在Unix系统中，$*、$@、$?和$<四个特殊宏的值在执行命令的过程中会发生相应的变化，而在GNU make中则定义了更多的预定义变量。 　　宏定义的使用可以使我们脱离那些冗长乏味的编译选项，为编写makefile文件带来很大的方便。 　　--------------------------------------------------------- 　　# Define a macro for the object files OBJECTS= filea.o fileb.o filec.o # Define a macro for the library file LIBES= -LS # use macros rewrite makefile prog： $(OBJECTS) 　　cc $(OBJECTS) $(LIBES) -o prog…… 　　--------------------------------------------------------- 　　此时如果执行不带参数的make命令，将连接三个目标文件和库文件LS;但是如果在make命令后带有新的宏定义：make \"LIBES= -LL -LS\"则命令行后面的宏定义将覆盖makefile文件中的宏定义。若LL也是库文件，此时make命令将连接三个目标文件以及两个库文件LS和LL. Make命令在make命令后不仅可以出现宏定义，还可以跟其他命令行参数，这些参数指定了需要编译的目标文件。其标准形式为：target1 [target2 …]：[：][dependent1 …][;commands][#…] [(tab) commands][#…]方括号中间的部分表示可选项。Targets和dependents当中可以包含字符、数字、句点和\"/\"符号。除了引用，commands中不能含有\"#\"，也不允许换行。 　　在通常的情况下命令行参数中只含有一个\"：\"，此时command序列通常和makefile文件中某些定义文件间依赖关系的描述行有关。如果与目标相关连的那些描述行指定了相关的command序列，那么就执行这些相关的command命令，即使在分号和(tab)后面的aommand字段甚至有可能是NULL.如果那些与目标相关连的行没有指定command，那么将调用系统默认的目标文件生成规则。 　　如果命令行参数中含有两个冒号\"：：\"，则此时的command序列也许会和makefile中所有描述文件依赖关系的行有关。此时将执行那些与目标相关连的描述行所指向的相关命令。同时还将执行build-in规则。 　　如果在执行command命令时返回了一个非\"0\"的出错信号，例如makefile文件中出现了错误的目标文件名或者出现了以连字符打头的命令字符串，make操作一般会就此终止，但如果make后带有\"-i\"参数，则make将忽略此类出错信号。 　　Make命本身可带有四种参数：标志、宏定义、描述文件名和目标文件名。其标准形式为：Make [flags] [macro definitions] [targets] Unix系统下标志位flags选项及其含义为：-f file　 指定file文件为描述文件，如果file参数为\"-\"符，那么描述文件指向标准输入。如果没有\"-f\"参数，则系统将默认当前目录下名为makefile或者名为Makefile的文件为描述文件。在Linux中， GNU make 工具在当前工作目录中按照GNUmakefile、makefile、Makefile的顺序搜索 makefile文件。 　　-i 　　忽略命令执行返回的出错信息。 　　-s 　　沉默模式，在执行之前不输出相应的命令行信息。 　　-r 　　禁止使用build-in规则。 　　-n 　　非执行模式，输出所有执行命令，但并不执行。 　　-t 　　更新目标文件。 　　-q　　 make操作将根据目标文件是否已经更新返回\"0\"或非\"0\"的状态信息。 　　-p　　 输出所有宏定义和目标文件描述。 　　-d　　 Debug模式，输出有关文件和检测时间的详细信息。 　　Linux下make标志位的常用选项与Unix系统中稍有不同，下面我们只列出了不同部分：-C dir　　 在读取 makefile 之前改变到指定的目录dir. -I dir 　　当包含其他 makefile文件时，利用该选项指定搜索目录。 　　-h 　　help文挡，显示所有的make选项。 　　-w 　　在处理 makefile 之前和之后，都显示工作目录。 　　通过命令行参数中的target ，可指定make要编译的目标，并且允许同时定义编译多个目标，操作时按照从左向右的顺序依次编译target选项中指定的目标文件。如果命令行中没有指定目标，则系统默认target指向描述文件中第一个目标文件。 　　通常，makefile 中还定义有 clean 目标，可用来清除编译过程中的中间文件，例如：clean：rm -f *.o运行 make clean 时，将执行 rm -f *.o 命令，最终删除所有编译过程中产生的所有中间文件。 　　隐含规则在make 工具中包含有一些内置的或隐含的规则，这些规则定义了如何从不同的依赖文件建立特定类型的目标。Unix系统通常支持一种基于文件扩展名即文件名后缀的隐含规则。这种后缀规则定义了如何将一个具有特定文件名后缀的文件(例如。c文件)，转换成为具有另一种文件名后缀的文件(例如。o文件)：。c：。o $(CC) $(CFLAGS) $(CPPFLAGS) -c -o $@ $<系统中默认的常用文件扩展名及其含义为：。o 　目标文件。c 　C源文件。f 　FORTRAN源文件。s 　汇编源文件。y 　Yacc-C源语法。l 　Lex源语法在早期的Unix系统系统中还支持Yacc-C源语法和Lex源语法。在编译过程中，系统会首先在makefile文件中寻找与目标文件相关的。C文件，如果还有与之相依赖的。y和。l文件，则首先将其转换为。c文件后再编译生成相应的。o文件;如果没有与目标相关的。c文件而只有相关的。y文件，则系统将直接编译。y文件。 　　而GNU make 除了支持后缀规则外还支持另一种类型的隐含规则——模式规则。这种规则更加通用，因为可以利用模式规则定义更加复杂的依赖性规则。模式规则看起来非常类似于正则规则，但在目标名称的前面多了一个 % 号，同时可用来定义目标和依赖文件之间的关系，例如下面的模式规则定义了如何将任意一个 file.c 文件转换为 file.o 文件：%.c：%.o $(CC) $(CFLAGS) $(CPPFLAGS) -c -o $@ $< #EXAMPLE#下面将给出一个较为全面的示例来对makefile文件和make命令的执行进行进一步的说明，其中make命令不仅涉及到了C源文件还包括了Yacc语法。本例选自\"Unix Programmer's Manual 7th Edition， Volume 2A\" Page 283-284下面是描述文件的具体内容： 　　--------------------------------------------------------- 　　#Description file for the Make command #Send to print P=und -3 | opr -r2 #The source files that are needed by object files FILES= Makefile version.c defs main.c donamc.c misc.c file.c \\ dosys.c gram.y lex.c gcos.c #The definitions of object files OBJECTS= vesion.o main.o donamc.o misc.o file.o dosys.o gram.o LIBES= -LS LINT= lnit -p CFLAGS= -O make： $(OBJECTS) 　　cc $(CFLAGS) $(OBJECTS) $(LIBES) -o make size make $(OBJECTS)： defs gram.o： lex.c cleanup：-rm *.o gram.c install：@size make /usr/bin/make cp make /usr/bin/make ; rm make #print recently changed files print： $(FILES) 　　pr $? | $P touch print test：make -dp | grep -v TIME>1zap /usr/bin/make -dp | grep -v TIME>2zap diff 1zap 2zap rm 1zap 2zap lint： dosys.c donamc.c file.c main.c misc.c version.c gram.c $(LINT) dosys.c donamc.c file.c main.c misc.c version.c \\ gram.c rm gram.c arch：ar uv /sys/source/s2/make.a $(FILES) 　　---------------------------------------------------------- 　　通常在描述文件中应象上面一样定义要求输出将要执行的命令。在执行了make命令之后，输出结果为：$ make cc -c version.c cc -c main.c cc -c donamc.c cc -c misc.c cc -c file.c cc -c dosys.c yacc gram.y mv y.tab.c gram.c cc -c gram.c cc version.o main.o donamc.o misc.o file.o dosys.o gram.o \\ -LS -o make 13188+3348+3044=19580b=046174b最后的数字信息是执行\"@size make\"命令的输出结果。之所以只有输出结果而没有相应的命令行，是因为\"@size make\"命令以\"@\"起始，这个符号禁止打印输出它所在的命令行。 　　描述文件中的最后几条命令行在维护编译信息方面非常有用。其中\"print\"命令行的作用是打印输出在执行过上次\"make print\"命令后所有改动过的文件名称。系统使用一个名为print的0字节文件来确定执行print命令的具体时间，而宏$?则指向那些在print文件改动过之后进行修改的文件的文件名。如果想要指定执行print命令后，将输出结果送入某个指定的文件，那么就可修改P的宏定义：make print \"P= cat>zap\"在Linux中大多数软件提供的是源代码，而不是现成的可执行文件，这就要求用户根据自己系统的实际情况和自身的需要来配置、编译源程序后，软件才能使用。只有掌握了make工具，才能让我们真正享受到到Linux这个自由软件世界的带给我们无穷乐趣。   摘自：http://os.chinaunix.net/a2012/0202/1305/000001305980.shtml","title":"Linux环境下的 make和makefile详解"},{"content":"  1、 *.src.rpm形式的源代码软件包     安装： rpm  -rebuild  *.src.rpm     cd  /usr/src/dist/RPMS     rpm  -ivh  *.rpm     卸载：rpm  -e  packgename     2、 *.tar.gz/*.tgz、*.bz2形式的源代码软件包     安装：tar  zxvf  *.tar.gz  或  tar  yxvf  *.bz2  先解压     然后进入解压后的目录：     ./configure  配置     make  编译     make  install  安装     卸载：make  uninstall  或  手动删除    ","title":"linux环境下软件包的安装"},{"content":"1. 安装nfs服务 $sudo apt-get install nfs-kernel-server portmap 2. 在配置文件/etc/exports中添加以下内容 /home/jxhui/nfs_root *(rw,sync,no_root_squash)；以后就可以通过网络文件系统访问/home/jxhui/nfs_root目录 3. 修改完后，执行以下命令重启NFS服务：     $sudo /etc/init.d/nfs-kernel-server restart","title":"Linux下安装nfs服务器"},{"content":"linux下，在应用程序看来，对设备的操作其实就是对文件的操作，利用open，read，write，close等函数进行控制和IO。 对于一个字符设备驱动模块，有几个关键结构体： 1、struct file_operations：在设备编号和驱动程序操作之间建立连接 2、struct file: file结构代表着一个打开的文件，由内核在open时创建，并传递给在该文件上操作的所有函数（如read），直到close。 3、inode: 在linux内部表示一个文件，与file不同，file表示文件描述符，对于许多个表示打开的文件描述符的file结构，它们都指向同一个inode结构。驱动程序使用其中的cdev*获取cdev的指针。 建立一个字符设备驱动程序通常包括以下几步： 1、定义read和write等函数，初始化file_operations结构体 2、分配设备号，注册字符设备 3、加载字符设备模块，并建立字符设备文件 下面是simple_cdev.c的源码：   #include <linux/init.h>#include <linux/module.h>#include <linux/fs.h>\t\t// struct  file and file_operations#include <asm/uaccess.h>\t// interface copy_from_user and copy to user#include <linux/types.h>#include <linux/kdev_t.h>MODULE_LICENSE(\"GPL\");#define MAJOR_NUM 241 \t\t// MAJOR DEV NUMint major_num;dev_t dev;static ssize_t cdev_read(struct file *, char *, size_t, loff_t*);static ssize_t cdev_write(struct file *, const char *, size_t, loff_t*);struct file_operations cdev_fops = {\t//.owner = THIS_MODULE,\t.read = cdev_read,\t.write = cdev_write,};static int cdev_var = 0;static int __init cdev_init(void){\tint ret, allocateresult;\t// allocate dev major\t//allocateresult = alloc_chrdev_region(&dev, 0 /*dev minor*/, 1 /*count*/, \"simple_cdevnum\");\t/*major_num = MAJOR(dev);\tif (allocateresult < 0)\t{\t\tprintk(\"simple cdev can't get major %d\\n\", major_num);\t\treturn allocateresult;\t}\tprintk(\"simple cdev  get major %d\\n\", major_num);*/\t\t// register dev\tret = register_chrdev(MAJOR_NUM, \"simple_cdev\", &cdev_fops);\tif (ret)\t{\t\t//unregister_chrdev_region(dev, 1);\t\tprintk(\"simple cdev regiseter failure.\\n\");\t}\telse\t{\t\tprintk(\"simple cdev register success.\\n\");\t}\treturn ret;}static void __exit cdev_exit(void){\tunregister_chrdev(MAJOR_NUM, \"simple_cdev\");\t//unregister_chrdev_region(dev, 1);\tprintk(\"simple cdev unregister success.\\n\");}static ssize_t cdev_read(struct file *filp, char *buf, size_t len, loff_t* offset){\tif (copy_to_user(buf, &cdev_var, sizeof(int)))\t{\t\treturn -EFAULT;\t}\treturn sizeof(int);}static ssize_t cdev_write(struct file *filp, const char *buf, size_t len, loff_t* offset){\tif (copy_from_user(&cdev_var, buf, sizeof(int)))\t{\t\treturn -EFAULT;\t}\treturn sizeof(int);}module_init(cdev_init);module_exit(cdev_exit);   相应的Makefile文件参考第一节的内容。 注意，这里的主设备号是我们指定的，通常我们不知道该设备号是否与系统中已有的设备冲突，可以用下面命令查看： cat /proc/devices Character devices:  1 mem  4 /dev/vc/0  4 tty  4 ttyS  5 /dev/tty  5 /dev/console  5 /dev/ptmx  6 lp  7 vcs 10 misc 13 input 21 sg 29 fb 99 ppdev108 ppp116 alsa128 ptm136 pts150 rtai_fifo180 usb189 usb_device241 simple_cdev   紧接着，执行 sudo insmod simple_cdev.ko 在模块初始化函数中注册了我们的设备（在/proc/devices中可以看到对应的设备号241），调用内核函数register_chrdev，把驱动程序的基本入口点指针存放在内核的字符设备地址列表中，在用户进程对该设备执行系统调用时提供入口地址。 应用程序在读写文件之前，先要创建字符设备文件： sudo mknod /dev/simple_cdev c 241 0 其中，c表示该文件类型是字符设备，241是主设备号，与/proc/devices中一致   最后我们写一个测试文件来读写字符设备中的变量：   #include <stdio.h>#include <sys/types.h>#include <sys/stat.h>#include <fcntl.h>int main(){\tint rnum, wnum;\tFILE* fd;\tfd = fopen(\"/dev/simplecdev\", \"rb+\");\tif (fd != -1)\t{\t\tfread((void*)(&rnum), sizeof(int), 1, fd);\t\tprintf(\"char dev int num is %d.\\n\", rnum);\t\tscanf(\"%d\",&wnum);\t\tfwrite((void*)(&wnum), sizeof(int), 1, fd);\t\tfread((void*)(&rnum), sizeof(int), 1, fd);\t\tprintf(\"char dev int num is %d.\\n\", rnum);\t\tfclose(fd);\t}\telse\t\tprintf(\"open error.\\n\");\treturn 0;} gcc testcdev.c sudo ./a.out sudo rmmod simple_cdev 补充几个问题： 1、利用dmesg可以查看内核中打出的log，用于调试，dmesg -c可以清空之前的内容； 2、新版的内核中，unregister_chrdev_region似乎变成了void返回； 3、copy_from_user和copy_to_user返回的是未成功复制的字节数； 4、lsmod可以查看当前系统注册的设备。   在编写设备驱动程序的时候发现了一个问题： 如果用register_chrdev注册字符设备的话，无法使用alloc_chrdev_region来动态分配设备号，后者会分配一个号码（在/proc/devices里面可以看到），register的时候使用这个主设备号会出现冲突。是不是只能手工指定主设备号？      ","title":"Linux驱动学习(二)——字符设备驱动程序入门 ."},{"content":"今天装CodeBlock，编译都一切正常，安装缺出问题，应用程序菜单里的快捷方式打不开程序，报错。 于是想先删除掉，郁闷的发现不知道在哪删除。 网上找了个工具，叫alacarte，安装     yum install alacarte 系统->首选项->主菜单，就找道它了。","title":"CentOS 修改应用程序菜单 alacarte"},{"content":"基于ARM 的Linux 的启动分析报告 摘要：本文主要分析基于ARM 的Linux－2.2.26 内核启动过程。将首先从／ arch/arm/Makefile着手，介绍三种不同的启动方案，再剖析典型的压缩内核 zImage启动方案的代码结构，最后将详细分析这种方案的启动过程，直到调用 start_kernel()为止。 1、Linux 内核的启动方案： 由／arch/arm/Makefile的代码可以看出，主要有三种启动方案,分别是: echo '* zImage - Compressed kernel image (arch/$ (ARCH)/boot/zImage)' echo ' Image - Uncompressed kernel image (arch/$ (ARCH)/boot/Image)' echo ' bootpImage - Combined zImage and initial RAM disk' echo ' (supply initrd image via make variable INITRD=<path>)' Linux内核有两种映像：一种是非压缩内核，叫 Image，另一种是它的压缩版 本，叫zImage。根据内核映像的不同，Linux内核的启动在开始阶段也有所不同。 zImage是Image经过压缩形成的，所以它的大小比 Image小。但为了能使用 zImage，必须在它的开头加上解压缩的代码，将 zImage解压缩之后才能执行， 因此它的执行速度比Image要慢。但考虑到嵌入式系统的存储空容量一般比较小， 采用zImage可以占用较少的存储空间，因此牺牲一点性能上的代价也是值得的。 所以一般的嵌入式系统均采用压缩内核的方式(另外bootpImage 是编译包含 zImage和initrd的映像，可以通过make变量INITRD=<path>提供initrd映像)。 2、基于zImage 的启动方案。 1、zImage 的生成过程 1、编译链接vmlinux 2、生成vmlinux.lds链接脚本 3、链接生成zImage 2、zImage 的代码结构 在内核编译完成后会在arch/arm/boot/下生成zImage。 #arch/arm/boot/Makefile： $(obj)/zImage: $(obj)/compressed/vmlinux FORCE $(call if_changed,objcopy) @echo ' Kernel: $@ is ready' 由此可见，zImage的是elf格式的，由内核顶层目录下的 arch/arm/boot /compressed/vmlinux二进制化得到的： #arch/armboot/compressed/Makefile： $(obj)/vmlinux: $(obj)/vmlinux.lds $(obj)/$(HEAD) $(obj)/piggy.o / $(addprefix $(obj)/, $(OBJS)) FORCE $(call if_changed,ld) @: $(obj)/piggy.gz: $(obj)/../Image FORCE $(call if_changed,gzip) $(obj)/piggy.o: $(obj)/piggy.gz FORCE 总结一下zImage 的组成，它是由一个压缩后的内核piggy.o，连接 上一段初始化及解压功能的代码（head.o misc.o）组成的。 3、zImage 的启动过程 1. Linux 内核的一般启动过程： 1)对于ARM 系列处理器来说，zImage 的入口程序即为 arch/arm/boot/ compressed/head.S。它依次完成以下工作：开启 MMU 和 Cache，调用 decompress_kernel()解压内核，最后通过调用 call_kernel()进入非压缩内核 Image 的启动。 Linux 非压缩内核的入口位于文件/arch/arm/kernel/head-armv.S 中 的 stext 段。该段的基地址就是压缩内核解压后的跳转地址。如果系统中加载的 内核是非压缩的 Image，那么bootloader将内核从 Flash中拷贝到 RAM 后将 直接跳到该地址处，从而启动 Linux 内核。 2）执行镜像：解压後/非压缩镜像直接执行（linux/arch/arm/kernel/headarmv. S：ENTRY(stext)-> __entry->__ret->__switch_data->__mmap_switched->） 3）该程序通过查找处理器内核类型和处理器类型调用相应的初始化函数， 再建立页表，最后跳转到 start_kernel()函数开始内核的初始化工作。 （linux/init/main.c：start_kernel()） 2、zImage 的启动过程 1) 内核启动地址的确定 1、#/arch/arm/Makefile文件中，设置内核启动的虚拟地址 textaddr-y := 0xC0008000 这个是内核启动的虚拟地址 TEXTADDR := $(textaddr-y) 2、#/arch/arm/boot/Makefile文件中，设置内核启动的物理地址 ZRELADDR := $(zreladdr-y) PARAMS_PHYS := $(params_phys-y) 3、 #/arch/arm/boot/compressed/Makefile文件中， SEDFLAGS = s/TEXT_START/$(ZTEXTADDR)/;s/LOAD_ADDR/$(ZRELADDR)/;s/BSS_START/$ (ZBSSADDR)/ 使得TEXT_START = ZTEXTADDR(从flash 中启动时)，LOAD_ADDR = ZRELADDR 其中TEXT_START是内核ram启动的偏移地址，这个地址是物理地址 ZTEXTADDR就是解压缩代码的ram偏移地址， LOAD_ADDR就是zImage中解压缩代码的ram偏移地址， ZRELADDR是内核ram启动的偏移地址， zImage的入口点由# /arch/arm/boot/compressed/vmlinux.lds.in决定： OUTPUT_ARCH(arm) ENTRY(_start) SECTIONS { . = TEXT_START; _text = .; .text : { _start = .; *(.start) *(.text) …… } 2) 内核解压缩过程 内核压缩和解压缩代码都在目录#/arch/arm/boot/compressed，编译完成后 将产生vmlinux、head.o、misc.o、head-xscale.o、piggy.o这几个文件，其中 head.o：内核的头部文件，负责初始设置； misc.o：主要负责内核的解压工作，它在head.o之后； head-xscale.o：主要针对Xscale的初始化，将在链接时与head.o合并； piggy.o：一个中间文件，其实是一个压缩的内核(kernel/vmlinux)，只不过没 有和 初始化文件及解压文件链接而已； vmlinux：没有(zImage是压缩过的内核)压缩过的内核，就是由piggy.o、 head.o、misc.o、head-xscale.o组成的。 3) 在BootLoader 完成系统的引导以后并将Linux 内核调入内存之后， 调用 bootLinux()，这个函数将跳转到kernel的起始位置。如果kernel没有压缩， 就可以启动了。 如果kernel压缩过，则要进行解压，在压缩过的kernel头部有解压程序。 压缩过的kernel入口第一个文件源码位置 arch/arm/boot/compressed/head.S。 它将调用函数decompress_kernel()，这个函数在arch/arm/boot/compressed/ misc.c 中，decompress_kernel()又调用 proc_decomp_setup()，arch_decomp_ setup()进行设置，然后使用在打印出信 息“Uncompressing Linux...”后，调用gunzip()。将内核放于指定的位置。 4) 以下分析#/arch/arm/boot/compressed/head.S 文件： (1) 对于各种Arm CPU的DEBUG输出设定，通过定义宏来统一操作。 (2) 设置kernel开始和结束地址，保存architecture ID。 (3) 如果在ARM2以上的CPU中，用的是普通用户模式，则升到超级用户模式， 然后关中断。 (4) 分析LC0结构delta offset，判断是否需要重载内核地址(r0存入偏移量， 判断 r0是否为零)。 接下来要把内核镜像的相对地址转化为内存的物理地址，即重载内核地 址： (5) 需要重载内核地址，将r0的偏移量加到BSS region和GOT table中。 (6) 清空bss堆栈空间r2－r3。 (7) 建立C程序运行需要的缓存，并赋于64K的栈空间。 (8) 这时r2是缓存的结束地址，r4是kernel的最后执行地址，r5是kernel境 象文件的开始地址。检查是否地址有冲突。将r5等于r2，使decompress后的 kernel地址就在64K的栈之后。 (9) 调用文件misc.c的函数decompress_kernel()，解压内核于缓存结束的地 方(r2地址之后)。此时各寄存器值有如下变化： r0为解压后kernel的大小 r4为kernel执行时的地址 r5为解压后kernel的起始地址 r6为CPU类型值(processor ID) r7为系统类型值(architecture ID) (10) 将reloc_start代码拷贝之kernel之后(r5+r0之后)，首先清除缓存，而 后执行reloc_start。 (11) reloc_start将r5开始的kernel重载于r4地址处。 (12) 清除cache内容，关闭cache，将r7中architecture ID赋于r1，执行 r4开始的kernel代码。 5) 我们在内核启动的开始都会看到这样的输出 Uncompressing Linux...done, booting the kernel. 这也是由decompress_kernel函数内部输出的，它调用了putc()输出字符串， putc是在#/include/asm-arm/arch-pxa/uncompress.h中实现的。执行完解压过 程，再返回到#/arch/arm/boot/compressed/head.S中，启动内核： call_kernel: bl cache_clean_flush bl cache_off mov r0, #0 mov r1, r7 @ restore architecture number mov pc, r4 @ call kernel 6) 执行zImage 镜像，到start_kernel( ) 整个arm linux内核的启动可分为三个阶段：第一阶段主要是进行cpu和 体系结构的检查、cpu本身的初始化以及页表的建立等；第一阶段的初始化是从 内核入口（ENTRY(stext)）开始到start_kernel前结束。这一阶段的代码 在/arch/arm/kernel/head.S中。/arch/arm/kernel/head.S用汇编代码完成， 是内核最先执行的一个文件。这一段汇编代码的主要作用，是检查cpu id，architecture number，初始化页表、cpu、bbs等操作，并跳到 start_kernel函数。它在执行前，处理器的状态应满足： r 0 - should be 0 r1 - unique architecture number MMU - off I-cache - on or off D-cache – off a) 流程图 b) 代码详细注释 #/arch/arm/kernel/head.S /* * swapper_pg_dir is the virtual address of the initial page table. * We place the page tables 16K below KERNEL_RAM_VADDR. Therefore, we * must make sure that KERNEL_RAM_VADDR is correctly set. Currently, we *expect the least significant 16 bits to be 0x8000, but we could probably relax this *restriction to KERNEL_RAM_VADDR >= PAGE_OFFSET + 0x4000. */ #if (KERNEL_RAM_VADDR & 0xffff) != 0x8000 #error KERNEL_RAM_VADDR must start at 0xXXXX8000 #endif .globl swapper_pg_dir .equ swapper_pg_dir, KERNEL_RAM_VADDR - 0x4000 .macro pgtbl, rd ldr /rd, =(KERNEL_RAM_PADDR - 0x4000) .endm /* * Since the page table is closely related to the kernel start address, we * can convert the page table base address to the base address of the section * containing both. */ .macro krnladr, rd, pgtable, rambase bic /rd, /pgtable, #0x000ff000 .endm /* /* * Kernel startup entry point. * --------------------------- * * This is normally called from the decompressor code. The requirements * are: MMU = off, D-cache = off, I-cache = dont care, r0 = 0, * r1 = machine nr, r2 = atags pointer. * * See linux/arch/arm/tools/mach-types for the complete list of machine * numbers for r1. */ .section \".text.head\", \"ax\" .type stext, %function ENTRY(stext) //内核入口点 msr cpsr_c, #PSR_F_BIT | PSR_I_BIT | SVC_MODE //程序状态，禁止FIQ、IRQ，设定Supervisor模式。0b11010011 mrc p15, 0, r9, c0, c0 @ get processor id bl __lookup_processor_type @ r5=procinfo r9=cupid //跳转到 判断 //cpu类型，查找运行的cpu的id值和此linux编译支持的id值是否有相 等 movs r10, r5 @ invalid processor (r5=0)? beq __error_p @ yes, error 'p' bl __lookup_machine_type @ r5=machinfo //跳转到判断体系类型，看r1寄存器的architecture number值是否支持。 movs r8, r5 @ invalid machine (r5=0)? beq __error_a @ yes, error 'a' bl __vet_atags bl __create_page_tables //创建核心页表 /* * The following calls CPU specific code in a position independent * manner. See arch/arm/mm/proc-*.S for details. r10 = base of * xxx_proc_info structure selected by __lookup_machine_type * above. On return, the CPU will be ready for the MMU to be * turned on, and r0 will hold the CPU control register value. */ ldr r13, __switch_data @ address to jump to after @ mmu has been enabled adr lr, __enable_mmu @ return (PIC) address //lr=0xc0028054 add pc, r10, #PROCINFO_INITFUNC @ initialise processor //r10：pointer to processor structure #/arch/arm/kernel/head-common.S */ #define ATAG_CORE 0x54410001 #define ATAG_CORE_SIZE ((2*4 + 3*4) >> 2) .type __switch_data, %object __switch_data: .long __mmap_switched .long __data_loc @ r4 .long __data_start @ r5 .long __bss_start @ r6 long _end @ r7 .long processor_id @ r4 .long __machine_arch_type @ r5 .long __atags_pointer @ r6 .long cr_alignment @ r7 .long init_thread_union + THREAD_START_SP @ sp /* * The following fragment of code is executed with the MMU on in MMU mode, * and uses absolute addresses; this is not position independent. * r0 = cp#15 control register * r1 = machine ID * r2 = atags pointer * r9 = processor ID */ .type __mmap_switched, %function __mmap_switched: //把sp指针指向init_task_union+8192（include/linux/sched.h）处，即第 //一个进程的task_struct和系统堆栈的地址；清空BSS段；保存processor ID //和machine type到全局变量processor_id和__machine_arch_type，这些值 //以后要用到；r0为\"A\"置位的control register 值，r2为\"A\"清空的 //control register 值，即对齐检查（Alignment fault checking）位，并保 //存到cr_alignment，和cr_no_alignment（在文件entry-armv.S中）。最 //后跳转到start_kernel（init/main.c） adr r3, __switch_data + 4 ldmia r3!, {r4, r5, r6, r7} @ r2 = compat//r2＝0xc0000000 cmp r4, r5 @ Copy data segment if needed //r4＝0xc00c04e0； __bss_start 1: cmpne r5, r6 //r5＝0xc00e02a8；_end //r6＝0xc00c0934； processor_id ldrne fp, [r4], #4 //r7＝0xc00c0930；__machine_arch_type strne fp, [r5], #4 //r8＝0xc00bcb88；cr_alignment bne 1b //sp＝0xc00bc000;(init_task_union)+8192 mov fp, #0 @ Clear BSS (and zero fp) 1: cmp r6, r7 strcc fp, [r6],#4 bcc 1b ldmia r3, {r4, r5, r6, r7, sp} str r9, [r4] @ Save processor ID str r1, [r5] @ Save machine type str r2, [r6] @ Save atags pointer bic r4, r0, #CR_A @ Clear 'A' bit stmia r7, {r0, r4} @ Save control register values b start_kernel //下面就开始真正的内核了：） /* * Enable the MMU. This completely changes the structure of the visible * memory space. You will not be able to trace execution through this. * If you have an enquiry about this, *please* check the linux-armkernel * mailing list archives BEFORE sending another post to the list. * * r0 = cp#15 control register * r13 = *virtual* address to jump to upon completion * * other registers depend on the function called upon completion */ .align 5 .type __turn_mmu_on, %function __turn_mmu_on: mov r0, r0 mcr p15, 0, r0, c1, c0, 0 @ write control reg mrc p15, 0, r3, c0, c0, 0 @ read id reg mov r3, r3 mov r3, r3 mov pc, r13 /* * Setup the initial page tables. We only setup the barest * amount which are required to get the kernel running, which * generally means mapping in the kernel code. * * r8 = machinfo * r9 = cpuid * r10 = procinfo * * Returns: * r0, r3, r6, r7 corrupted * r4 = physical page table address */ .type __create_page_tables, %function __create_page_tables: pgtbl r4 @ page table address //调用宏pgtbl，r4＝0xc0024000：页表基址 /* * Clear the 16K level 1 swapper page table */ mov r0, r4 //r0＝0xc0024000 mov r3, #0 add r6, r0, #0x4000 //r6=0xc0028000 1: str r3, [r0], #4 str r3, [r0], #4 str r3, [r0], #4 str r3, [r0], #4 teq r0, r6 bne 1b //将地址0xc0024000～0xc0028000清0 ldr r7, [r10, #PROCINFO_MM_MMUFLAGS] @ mm_mmuflags /* * Create identity mapping for first MB of kernel to * cater for the MMU enable. This identity mapping * will be removed by paging_init(). We use our current program * counter to determine corresponding section base address. */ mov r6, pc, lsr #20 @ start of kernel section orr r3, r7, r6, lsl #20 @ flags + kernel base str r3, [r4, r6, lsl #2] @ identity mapping /* * Now setup the pagetables for our kernel direct * mapped region. */ add r0, r4, #(KERNEL_START & 0xff000000) >> 18 str r3, [r0, #(KERNEL_START & 0x00f00000) >> 18]! ldr r6, =(KERNEL_END - 1) add r0, r0, #4 add r6, r4, r6, lsr #18 1: cmp r0, r6 add r3, r3, #1 << 20 strls r3, [r0], #4 bls 1b /* * Read processor ID register (CP#15, CR0), and look up in the linker-built * supported processor list. Note that we can't use the absolute addresses * for the __proc_info lists since we aren't running with the MMU on * (and therefore, we are not in the correct address space). We have to * calculate the offset. * * r9 = cpuid * Returns: * r3, r4, r6 corrupted * r5 = proc_info pointer in physical address space * r9 = cpuid (preserved) */ .type __lookup_processor_type, %function __lookup_processor_type: //判断cpu类型 adr r3, 3f //取标号3的地址 ldmda r3, {r5 - r7} sub r3, r3, r7 @ get offset between virt&phys add r5, r5, r3 @ convert virt addresses to add r6, r6, r3 @ physical address space 1: ldmia r5, {r3, r4} @ value, mask //读取arm linux中cpu信 息 and r4, r4, r9 @ mask wanted bits //屏蔽cpu id的低8位 teq r3, r4 //寄存器0的cpu id与arm linux中cpu id比较 beq 2f add r5, r5, #PROC_INFO_SZ @ sizeof(proc_info_list) //否则寻找 下一块 //proc_info cmp r5, r6 blo 1b mov r5, #0 @ unknown processor //没有匹配信息，r5＝0 2: mov pc, lr /* * This provides a C-API version of the above function. */ ENTRY(lookup_processor_type) stmfd sp!, {r4 - r7, r9, lr} mov r9, r0 bl __lookup_processor_type mov r0, r5 ldmfd sp!, {r4 - r7, r9, pc} /* * Look in include/asm-arm/procinfo.h and arch/arm/kernel/arch.[ch] for * more information about the __proc_info and __arch_info structures. */ .long __proc_info_begin .long __proc_info_end 3: .long . .long __arch_info_begin .long __arch_info_end /* * Lookup machine architecture in the linker-build list of architectures. * Note that we can't use the absolute addresses for the __arch_info * lists since we aren't running with the MMU on (and therefore, we are * not in the correct address space). We have to calculate the offset. * * r1 = machine architecture number * Returns: * r3, r4, r6 corrupted * r5 = mach_info pointer in physical address space */ .type __lookup_machine_type, %function __lookup_machine_type: //判断体系类型 adr r3, 3b //取上面标号2的地址 ldmia r3, {r4, r5, r6} sub r3, r3, r4 @ get offset between virt&phys add r5, r5, r3 @ convert virt addresses to add r6, r6, r3 @ physical address space 1: ldr r3, [r5, #MACHINFO_TYPE] @ get machine type teq r3, r1 @ matches loader number? beq 2f @ found add r5, r5, #SIZEOF_MACHINE_DESC @ 不匹配，查找next machine_desc cmp r5, r6 blo 1b mov r5, #0 @ unknown machine 2: mov pc, lr /* * This provides a C-API version of the above function. */ ENTRY(lookup_machine_type) stmfd sp!, {r4 - r6, lr} mov r1, r0 bl __lookup_machine_type mov r0, r5 ldmfd sp!, {r4 - r6, pc} 因水平有限，如有不妥之处或者更好的方法，敬请指出。","title":"ARM+Linux 的启动分析"},{"content":"一、Exim队列的全局管理 1.统计队列邮件数量 帮助 1 root@localhost# exim –bpc 2.查看exim 队列中的所有邮件信息 帮助 1 root@localhost# exim –bp 3.汇总队列邮件信息 帮助 1 root@localhost# exim -bp | exiqsumm 4.查看Exim服务的当前工作情况 帮助 1 root@localhost# exiwhat 二、基于邮件ID的队列操作 – ID可为多个 1.删除邮件 帮助 1 root@localhost# exim -Mrm <message-id> [ <message-id> ... ] 2.冻结邮件 帮助 1 root@localhost# exim -Mf <message-id> [ <message-id> ... ] 3.解冻邮件 帮助 1 root@localhost# exim -Mt <message-id> [ <message-id> ... ] 4.强制投递邮件 帮助 1 root@localhost# exim -M <message-id> [ <message-id> ... ] 5.强制退回邮件 帮助 1 root@localhost# exim -Mg <message-id> [ <message-id> ... ] 6.查看邮件头 帮助 1 root@localhost# exim -Mvh <message-id> 7.查看邮件内容 帮助 1 root@localhost# exim -Mvb <message-id> 8.查看邮件日志 帮助 1 root@localhost# exim -Mvl <message-id> 9.新增一个收件人 帮助 1 root@localhost# exim -Mar <message-id> 10.编辑发件人信息 帮助 1 root@localhost# exim -Mes <message-id> 三、队列邮件ID查找命令 – exiqgrep 1.查看来自指定发件人的所有队列邮件 帮助 1 root@localhost# exiqgrep -f [发件人]@domain 2.查看发给指定收件人的所有队列邮件 帮助 1 root@localhost# exiqgrep -r [收件人]@domain 3.查看1天前的队列邮件 (以秒为单位) 帮助 1 root@localhost# exiqgrep -o 86400 4.查看1小时内的队列邮件 (以秒为单位) 帮助 1 root@localhost# exiqgrep -y 3600 5.查看700到800字节大小的队列邮件 (支持正则表达式) 帮助 1 root@localhost# exiqgrep -s '^7..$' 6.其他常用参数：-z 只查看被冻结的队列邮件-i 只显示邮件ID-c 只显示查找到的邮件数量 四、队列邮件的批量操作 1.删除所有被冻结的邮件 帮助 1 root@localhost# exiqgrep -z -i | xargs exim –Mrm 2　解冻所有被冻结的邮件 1 root@localhost# exiqgrep -z -i | xargs exim –Mt   2.删除所有5天前的队列邮件 帮助 1 root@localhost# exiqgrep -o 432000 -i | xargs exim –Mrm 3.冻结所有来自某一发件人的邮件 帮助 1 root@localhost# exiqgrep -i -f 发件人@zeknet.com | xargs exim -Mf","title":"Exim 命令行　功能"},{"content":"1、VI编辑器的启动与退出 #vi file1 新建一个文本文件为file1 ~ ~ :q! 在末行模式下退出 2、文本的操作 ~ :e! file1 在当前文件下编辑新的文件 :r /etc/passwd 实现文件的读入功能 :wq 保持并退出 :q! 强行退出 3、光标移动操作   3.1、光标移动操作(命令模式下) h--向左移动光标 l--向右移动光标 k--向上移动光标 j--向下移动光标   3.2、翻页移动(命令模式下) Ctril+F向前翻整页 Ctril+B向后翻整页 Ctril+U向前翻半页 Ctril+D向后翻半页   3.3、行内快速跳转(命令模式下) ^ 将光标快速跳转到本行的首行字符 $ 将光标快速跳转到本行的行尾字符 nw 将光标快速跳转到当前光标所在位置的后n个单词的首字母 nb 将光标快速跳转到当前光标所在位置的前n个单词的首字母 nc 将光标快速跳转到当前光标所在位置的后n个单词的尾字母   3.4、文件内行间快速跳转 :set nu 显示行号 :set nonu 取消显示行号 4、编辑操作   4.1进入输入模式(在命令模式下) i  在当前光标处进入插入状态 cw 删除当前光标所在单词尾部的字符，并进入插入状态 c$ 删除当期光标到行尾的字符，并进入插入状态 c^ 删除当前光标到行尾的字符，并进入插入状态   4.2、输入模式的操作 使用上下左右方向键进行光标移动  Home和End  快速定位光标到行首和行尾 Page Up和Page Down 进行文本的上下翻页 Backspace 删除光标左侧字符 Delect 删除光标位置的字符   4.3、删除操作 x 删除光标处的单个字符 dd 删除光标所在的行 dw 删除当前字符到单词尾的所有字符 d$ 删除当前字符到行尾的所有字符 d^ 删除当前字符到行首的所有字符 J 合并当前行和下一行的内容   4.4、撤销操作 u 取消最近一次的操作 U 取消当前行进行的所有操作 Ctrl+R 对使用u命令撤销的操作进行恢复   4.5、复制操作 yy 复制当前正行内容到VI缓冲区 yw 复制当前光标到单词尾部字符的内容到VI缓冲区 y$ 复制当前光标到行尾的内容到VI缓冲区 y^ 复制当前光标到行首的内容到VI缓冲区 :m,ny 复制第m行到第n行之间的文本到VI缓冲区   4.6、粘贴操作 p 读取VI缓冲区到当前光标所在位置   5、查找和替换操作   5.1、自上而下的查找操作 :/word 查找与word匹配的字符串 n 查找下一个匹配的字符串 N 反向查找下一个匹配的字符串   5.2、自下而上的查找操作 ?word 查找与word匹配的字符串 n 查找下一个匹配的字符串 N 反向查找下一个匹配的字符串   5.3、替换操作 :s/old/new 替换当前行的第一个字符old为字符new :s/old/new/g 替换当前行的所有字符old为字符new :m,ns/old/new/g 替换当前行号m到行号n的所有字符old为字符new :%s/old/new/g 替换整个文本的所有字符old为字符new   5.7、使用替换的确认功能 :s/old/new/c 替换当前行的第一个字符old为字符new并提示用户确认操作 :s/old/new/gc 替换当前行的所有字符old为字符new并提示用户确认操作 :m,ns/old/new/gc 替换当前行号m到行号n的所有字符old为字符new并提示用户确认操作 :%s/old/new/gc 替换整个文本的所有字符old为字符new并提示用户确认操作 6、VI编辑器的在线帮助 6.1、安装VI编辑器的其他软件包 将RHEL4的第2张安装光盘放入主机的光盘驱动器，并使用管理员root权限执行以下命令操作，可安装VI程序的附加软件包。 #mount /dev/cdrom /media/cdrom #cd /media/cdrom/RedHat/RPMS/ #rpm -ivh vim-common-6.3.035-3.i386.rpm vim-enhanced-6.3.035-3.i386.rpm #cd ~ #umount /media/cdrom /dev/cdrom :help 查看VI帮助信息","title":"Linux下VIM编辑器的详细使用"},{"content":"第一步admin权限进入服务器 第二步进入SVN的bin目录下 输入命令 cd  /usr/local/apache2/bin  如图 第三步查看bin目录下的文件 输入命令 ls   如图 第四步查看有哪些用户 输入命令 cat pwd.txt 如图 第五步如果没有改用户，创建用户 1）输入命令  htpasswd  pwd.txt  zzq 2）如果账号创建以后密码忘记了，或者说对应账号的人员已经离职，删除账号    输入命令  vi  pwd.txt    输入命令  I 或者A     进行删除，然后保存退出 退出命令  按ESC 键  输入：wq 第六步如果改用户已存在，给在用户赋权限 输入命令  vi   authz/ 进行修改  I 键或A键 1) 找到对应的项目分组；如图项目ECP-Manage 对应的小组名为@dev3 如图： 2) 在上面对应的小组后面加上要赋权限的用户名字 如下图 在后面加 ，lct 如图： 3) 如果对于新的项目，则需要建立新的项目权限模型。 包括建立项目和分组 如: [/trunk/ECP-NEW] @new-dev = rw 然后在组区域增加组，并增加人员到组中 new-dev=mc,zct 4）如果对应账号的人员已经离职，删除账号权限    输入命令  vi  authz    输入命令  I 或者A     进行删除，然后保存退出 退出命令  按ESC 键  输入：wq 第七步修改完成 按 Esc 键 输入命令：wq 退出保存 输入命令：q！ 强制退出不保存","title":"LINUX SVN 账号 配置"},{"content":"本人安装的是ubuntu12.04 64位系统 1、mkdir ~/bin PATH=~/bin:$PATH 2、curl https://dl-ssl.google.com/dl/googlesource/git-repo/repo >~/bin/repo chmod a+x ~/bin/repo 注：因为google.com被拉黑，可能连接不上。如果从其他链接下载，版本较低的话，也会出现问题，本人将该脚本上传，以备不时之需。 3、mkdir android_jellybean cd android_jellybean 4、repo init -u https://android.googlesource.com/platform/manifest -bandroid-4.2.1_r1 在repo sync之前，修改了.repo/manifest.xml文件(先备份一下)，主要是去掉一些不想下载的仓库，如:device/asus/grouper,device/asus/tilapia, device/lge/mako, device/ti/panda,device/samsung/*，只保留device下通用的仓库，因为这些仓库实在太大了，当前也用不到。可以需要时再下载。精简的manifest.xml也已经上传。 5、repo sync 由于网速原因，执行了四五次才全部下载完毕，如果不是事先去掉了一些仓库，可能执行次数更多，时间花费也会更长。下载文件大小总共大概4.3G,在.repo/projects查看的。我宽带是1MB/s，如果网络稳定，1个半小时应该能够搞定。但是由于google网站被“特殊关照”，连接过程中总不免磕磕碰碰，执行了3个多小时。 6、编译。source ./build/envsetup.sh make 竟然一路下来，没有出错，有点出乎意料。编译出来的out路径总大小有20G左右，编译时间4个小时左右。 7、默认编译出来的是odex版本，需要修改脚本。 应该是在./build/target/board/generic/BoardConfig.mk下，将WITH_DEXPREOPT设置为false。(未经测试) 以前编译时出现很多问题。 当时我工程是在windows上使用cygwin下载的，直接在linux下编译。那是错误百出啊，包括： 1>JDK找不到，我当时安装的是openJDK，执行java -version是没有问题的，还专门编译一个helloworld。android编译脚本中有JAVA_HOME变量，修改之后，又有新问题； 2>JDK中有找不到tools.java，还是有变量配置不对。 3>然后是/build/tools/findleaves.py等一堆文件没有权限，本人对linux菜鸟，最初在root下都无法更改这些文件权限。上网一阵搜索，chown，终于添加了可执行权限。 4>还有就是prebuilts/tools/gcc-sdk/gcc:行40:prebuilts/tools/gcc-sdk/../../gcc/linux-x86/host/i686-linux-glibc2.7-4.6/bin/i686-linux-gcc:没有那个文件或目录。 找了一下，网上的解决方案是： cd prebuilts/tools/ git reset --hard HEAD^ cd ../../external/qemu git reset --hard d4f5a3ae87a7246613188940c1667bf2880da402 但是我执行之后还是出现这个错误，不想再摸着石头过河了，索性在linux上下载了一下，没想到如此给力。","title":"android 4.2.1 下载和编译"},{"content":"cat /proc/pid/status 查看VmRSS 值的大小。 ps aux 一项的RSS 也可以查看应用程序内存使用情况","title":"linux 进程内存使用情况观测"},{"content":"判断有不有安装过： rpm –qa | grep 安装包名 如果已经安装过，就会有显示，若没有安装过，则无若何结果 找到某安装包： yum search iostat 安装包 如果有则会显示安装包的信息","title":"CentOS 安装包查询"},{"content":"Linux下对文件操作有两种方式：系统调用(system call)和库函数调用(Library functions)。系统调用实际上就是指最底层的一个调用，在linux程序设计里面就是底层调用的意思。面向的是硬件。而库函数调用则面向的是应用开发的，相当于应用程序的api,采用这样的方式有很多种原因： 1. 双缓冲技术的实现。 2. 可移植性。 3. 底层调用本身的一些性能方面的缺陷。 4. 让api也可以有了级别和专门的工作面向。 　　1、系统调用 　　系统调用提供的函数如open, close, read, write, ioctl等，需包含头文件unistd.h.以write为例：其函数原型为 size_t write(int fd, const void *buf, size_t nbytes)，其操作对象为文件描述符或文件句柄fd(file descriptor)，要想写一个文件，必须先以可写权限用open系统调用打开一个文件，获得所打开文件的fd,例如 fd=open(\\“/dev/video\\”, O_RDWR)。fd是一个整型值，每新打开一个文件，所获得的fd为当前最大fd加1.Linux系统默认分配了3个文件描述符值：0-standard input,1-standard output,2-standard error. 　　系统调用通常用于底层文件访问(low-level file access)，例如在驱动程序中对设备文件的直接访问。 　　系统调用是操作系统相关的，因此一般没有跨操作系统的可移植性。 　　系统调用发生在内核空间，因此如果在用户空间的一般应用程序中使用系统调用来进行文件操作，会有用户空间到内核空间切换的开销。事实上，即使在用户空间使用库函数来对文件进行操作，因为文件总是存在于存储介质上，因此不管是读写操作，都是对硬件(存储器)的操作，都必然会引起系统调用。也就是说，库函数对文件的操作实际上是通过系统调用来实现的。例如C库函数fwrite()就是通过write()系统调用来实现的。 　　这样的话，使用库函数也有系统调用的开销，为什么不直接使用系统调用呢？这是因为，读写文件通常是大量的数据(这种大量是相对于底层驱动的系统调用所实现的数据操作单位而言)，这时，使用库函数就可以大大减少系统调用的次数。这一结果又缘于缓冲区技术。在用户空间和内核空间，对文件操作都使用了缓冲区，例如用fwrite写文件，都是先将内容写到用户空间缓冲区，当用户空间缓冲区满或者写操作结束时，才将用户缓冲区的内容写到内核缓冲区，同样的道理，当内核缓冲区满或写结束时才将内核缓冲区内容写到文件对应的硬件媒介。 　　2、库函数调用 　　标准C库函数提供的文件操作函数如fopen, fread, fwrite, fclose, fflush, fseek等，需包含头文件stdio.h。以fwrite为例，其函数原型为size_t fwrite(const void *buffer, size_t size, size_t item_num, FILE *pf)，其操作对象为文件指针FILE *pf,要想写一个文件，必须先以可写权限用fopen函数打开一个文件，获得所打开文件的FILE结构指针pf,例如pf=fopen(\\“~/proj/filename\\”, \\“w\\”)。实际上，由于库函数对文件的操作最终是通过系统调用实现的，因此，每打开一个文件所获得的FILE结构指针都有一个内核空间的文件描述符fd与之对应。同样有相应的预定义的FILE指针：stdin-standard input,stdout-standard output,stderr-standard error. 　　库函数调用通常用于应用程序中对一般文件的访问。 　　库函数调用是系统无关的，因此可移植性好。 　　由于库函数调用是基于C库的，因此也就不可能用于内核空间的驱动程序中对设备的操作。 　　※ 函数库调用 VS 系统调用","title":"Linux系统调用和库函数调用的区别"},{"content":"一、rpm包的安装：       1.安装一个包 　　# rpm -ivh 　　2.升级一个包 　　# rpm -Uvh 　　3.移走一个包 　　# rpm -e 　　4.安装参数 　　--force 即使覆盖属于其它包的文件也强迫安装 　　--nodeps 如果该RPM包的安装依赖其它包，即使其它包没装，也强迫安装。 　　5.查询一个包是否被安装 　　# rpm -q < rpm package name> 　　6.得到被安装的包的信息 　　# rpm -qi < rpm package name> 　　7.列出该包中有哪些文件 　　# rpm -ql < rpm package name> 　　8.列出服务器上的一个文件属于哪一个RPM包 　　#rpm -qf 　　9.可综合好几个参数一起用 　　# rpm -qil < rpm package name> 　　10.列出所有被安装的rpm package 　　# rpm -qa 　　11.列出一个未被安装进系统的RPM包文件中包含有哪些文件？ 　　# rpm -qilp < rpm package name>   二、rpm包的卸载：       rpm -qa | grep 包名      这个命令是为了把包名相关的包都列出来            rpm -e 文件名     这个命令就是你想卸载的软件，后面是包名称，最后的版本号是不用打的    例如：      # rpm -qa |  grep mysql       mod_auth_mysql-2.6.1-2.2        php-mysql-5.3.9-3.15        mysql-devel-5.1.77-1.CenOS 5.2       mysql-5.0.77-1.CenOS 5.2       mysqlclient10-5.0.77-1.CentOS 5.2       libdbi-dbd-mysql-0.6.5-10.CentOS 5.2    # rpm -e mysqlclient      三、yum安装：        # yum install 包名  四、yum卸载：        # yum -y remove 包名","title":"CentOS 下 rpm包与 yum 安装与卸载"},{"content":"当编辑完文件，准备退出Vi返回到shell时，可以使用以下几种方法之一。 在命令模式中，连按两次大写字母Z，若当前编辑的文件曾被修改过，则Vi保存该文件后退出，返回到shell；若当前编辑的文件没被修改过，则Vi直接退出, 返回到shell。 在末行模式下，输入命令 :w Vi保存当前编辑文件，但并不退出，而是继续等待用户输入命令。在使用w命令时，可以再给编辑文件起一个新的文件名。 :w newfile 此时Vi将把当前文件的内容保存到指定的newfile中，而原有文件保持不变。若newfile是一个已存在的文件，则Vi在显示窗口的状态行给出提示信息： File exists (use ! to override) 此时，若用户真的希望用文件的当前内容替换newfile中原有内容，可使用命令 :w! newfile 否则可选择另外的文件名来保存当前文件。 在末行模式下，输入命令 :q 系统退出Vi返回到shell。若在用此命令退出Vi时，编辑文件没有被保存，则Vi在显示窗口的最末行显示如下信息： No write since last change (use ! to overrides) 提示用户该文件被修改后没有保存，然后Vi并不退出，继续等待用户命令。若用户就是不想保存被修改后的文件而要强行退出Vi时，可使用命令 :q! Vi放弃所作修改而直接退到shell下。 在末行模式下，输入命令 :wq Vi将先保存文件，然后退出Vi返回到shell。 在末行模式下，输入命令 : x 该命令的功能同命令模式下的ZZ命令功能相同。","title":"linux下退出VI的方法：不保存退出:q！ 先保存后"},{"content":"static变量 及 作用域控制 一、static变量 　　static变量放在函数中，就只有这个函数能访问它；放在函数外就只有这个文件能访问它。 下面我们看看两个函数中重名的static变量是怎么区别开来的（static.c）： #include <stdio.h>void func1(){    static int n = 1;    n++;}void func2(){    static int n = 2;    n++;}int main(){    return 0;} 　　下面是编译后的部分汇编： func1:    pushl   %ebp    movl    %esp, %ebp    movl    n.1671, %eax    addl    $1, %eax    movl    %eax, n.1671    popl    %ebp    retfunc2:    pushl   %ebp    movl    %esp, %ebp    movl    n.1674, %eax    addl    $1, %eax    movl    %eax, n.1674    popl    %ebp    ret 　　好家伙！编译器居然\"偷偷\"地改了变量名，这样两个static变量就容易区分了。 　　其实static变量跟全局变量一样被放置在 .data段 或 .bss段 中，所以它们也是程序运行期间一直存在的，最终也是通过绝对地址来访问。但是它们的作用域还是比全局变量低了一级： static变量被标识为LOCAL符号，全局变量被标识为GLOBAL符号，在链接过程中，目标文件寻找外部变量时只在GLOBAL符号中找，所以static变量别的源文件是\"看不见\"的。 二、作用域控制 　　作用域控制为的是提高源代码的可读性，一个变量的作用域越小，它可能出没的范围就越小。 　　C语言中的变量按作用域从大到小可分为四种：全局变量、函数外static变量、函数内static变量、局部变量： 全局变量是杀伤半径最大的：不仅在定义该变量的源文件中可用，而且在任一别的源文件中只要用 extern 声明它后也可以使用，因此，当你看到一个全局变量的时候应该心生敬畏！ 函数外的static变量处于文件域中，只有定义它的源文件中可以使用。如果你看到一个static变量，那是作者在安慰你：哥们（妹子），这个变量不会在别的文件中出现。 函数内static变量在函数的每次调用中可用（只初始化一次）， 它同以上两种变量一样在程序运行期间一直存在，所以它的功能是局部变量无法实现的。 局部变量在函数的一次调用中使用，调用结束后就消失了。 　　显然，作用域越小越省心，该是局部变量的就不要定义成全局变量，如果\"全局变量\"只在本源文件中使用那就加个static。 　　即便是局部变量也还可以压缩其作用域： 　　有的同学写的函数一开头就声明了函数中要用到的所有局部变量，一开始我也这么做，因为我担心：如果把变量定义在循环体内，是不是每一次循环都会给它们分配空间、回收空间，从而降低效率？ 但事实是它们的空间在函数的开头就一次性分配好了（scope.c）： #include <stdio.h>int main(){    int a = 1;    {        int a = 2;        {            int a = 3;        }        {            int a = 4;        }    }    return 0;} 编译后的汇编代码如下： main:    pushl   %ebp    movl    %esp, %ebp    subl    $16, %esp    movl    $1, -4(%ebp)    movl    $2, -8(%ebp)    movl    $3, -12(%ebp)    movl    $4, -16(%ebp)    movl    $0, %eax    leave    ret 　　各层局部环境中的变量a是subl $16, %esp一次性分配好的。由此可见不是每个{}都要分配回收局部变量，一个函数只分配回收一次。因此，如果某个变量只在某个条件、循环中用到的话，还是在条件、循环中定义吧，这样，规模比较大的函数的可读性将提高不少，而效率丝毫没有下降，可谓是百利而无一害！","title":"static变量 及 作用域控制"},{"content":"进程内存分布 　　之前一直在分析栈，栈这个东西的作用也介绍得差不多了，但是栈在哪儿还没有搞清楚，以及堆、代码、全局变量它们在哪儿，这都牵涉到进程的内存分布。 linux 0.01 的进程内存分布 　　内存分布随着操作系统的更新换代，越来越科学合理，也越来越复杂，所以我们还是先了解一下早期操作系统的典型 linux 0.01 的进程的内存分布： 　　linux 0.01 的一个进程固定拥有64MB的线性内存空间（ACM竞赛中单个程序的最大内存占用限制为64MB，这肯定有猫腻O(∩_∩)O~），各个进程挨个放置在一张页目录表中，一个页目录表可管理4G的线性空间，因此 linux0.01 最多有 64个进程。每个进程的内存分布如下： .text 里存的是机器码序列 .rodata 里存的是源字符串等只读内容 .data 里存的是初始化的全局变量 .bss 上一篇介绍过了，存的是未初始化的全局变量 堆、栈就不用介绍了吧！ 　　.text .rodata .data .bss 是常驻内存的，也就是说进程从开始运行到进程僵死它们一直蹲在那里，所以访问它们用的是常量地址；而栈是不断的加帧（函数调用）、减帧（函数返回）的，帧内的局部变量只能用相对于当前 esp（指向栈顶）或 ebp（指向当前帧）的相对地址来访问。 　　栈被放置在高地址也是有原因的： 调用函数（加帧）是减 esp 的，函数返回（减帧）是加 esp 的，调用在前，所以栈是向低地址扩展的，放在高地址再合适不过了。 现代操作系统的进程内存分布 　　认识了 linux 0.01 的内存分布后，再看看现代操作系统的内存分布发生了什么变化： 　　首先，linux 0.01 进程的64MB内存限制太过时了，现在的程序都有潜力使用到 2GB、3GB 的内存空间（每个进程一张页目录表），当然，机器有硬伤的话也没办法，我的电脑就只有 2GB 的内存，想用 3GB 的内存是没指望了。但也不是有4GB内存就可以用4GB（32位），因为操作系统还要占个坑呢！现代 linux 中 0xC0000000 以上的 1GB 空间是操作系统专用的，而 linux 0.01 中第1个 64MB 是操作系统的坑，所以别的进程完全占有它们的 64MB，也不用跟操作系统客气。 　　其次，linux 0.01只有进程没有线程，但是现代 linux 有多线程了（linux 的线程其实是个轻量级的进程），一个进程的多个线程之间共享全局变量、堆、打开的文件…… 但栈是不能共享的：栈中各层函数帧代表着一条执行线索，一个线程是一条执行线索，所以每个线程独占一个栈，而这些栈又都必须在所属进程的内存空间中。 　　根据以上两点，进程的内存分布就变成了下面这个样子： 　　再者，如果把动态装载的动态链接库也考虑进去的话，上面的分布图将会更加\"破碎\"。 　　如果我们的程序没有采用多线程的话，一般可以简单地认为它的内存分布模型是 linux 0.01 的那种。","title":"进程内存分布"},{"content":"未初始化全局变量 　　为下一篇介绍进程内存分布做准备，这一篇先来介绍一下未初始化全局变量： 　　未初始化全局变量，这名字就很直白，就是 C 程序中定义成全局作用域而又没有初始化的变量，我们知道这种变量在程序运行后是被自动初始化为 全0 的。编译器编译的时候会将这类变量收集起来集中放置到 .bss 段中，这个段只记录了段长，没有实际上的内容（全是0，没必要存储），在程序被装载时操作系统会为它分配等于段长的内存，并全部初始化为0。 　　这有两个 C程序，都定义了全局数组 data（长度为1M，占用内存4MB），一个部分初始化（bss_init1.c），一个未初始化（bss_uninit1.c）： bss_init1.c： #include <stdio.h>#include <windows.h>#define MAXLEN 1024*1024int data[MAXLEN]={1,};int main(){    Sleep(-1);    return 0;} bss_uninit1.c： #include <stdio.h>#include <windows.h>#define MAXLEN 1024*1024int data[MAXLEN];int main(){    Sleep(-1);    return 0;} 　　编译以上两个程序后： 　　可以看到有初始化的可执行文件的大小差不多是4MB，而未初始化的只有47KB！这就是 .bss 段有段长，而没有实际内容的表现。用 UltraEdit 打开 bss_init1.exe 可看到文件中大部分是全0（data数组的内容）： 　　但是接下来运行（return 0 之前的 Sleep(-1) 保证了程序暂时不会退出）的时候，却发现 bss_init1.exe 占用的空间明显少于 4MB，这是怎么回事呢？ 　　这就涉及程序装载的策略了。早期的操作系统（如：linux 0.01）采用的是一次装载：将可执行文件一次性完整装入内存后再执行程序。不管程序是 1KB 还是 60MB，都要等全部装入内存后才能执行，这显然是不太合理的。 　　而现在的操作系统都是采用延迟装载： 将进程空间映射到可执行文件之后就开始执行了，执行的时候如果发现要读/写的页不在内存中，就根据映射关系去读取进来，然后继续执行应用程序（应该是在页保护异常的处理中实现的）。 　　bss_init1.exe 肯定是被映射了，而程序中又没有对 data 数组进行读/写操作，所以操作系统也就懒得去装入这片内存了。下面修改一下这两个程序：在 Sleep(-1) 前将 data 数组的每个元素赋值为 -1： int i;for(i=0; i<MAXLEN; ++i)    data[i] = -1; 　　再运行，它们占用的内存都是 4M 了：","title":"未初始化全局变量"},{"content":"这是原文地址: svn 提交出现Password for ‘(null)’ GNOME keyring: 错误","title":"svn 提交出现Password for ‘(null)’ GNOME keyring: 错误"},{"content":"原帖：http://www.linuxsir.org/bbs/thread362988.html http://forum.ubuntu.org.cn/viewtopic.php?p=2693955 以ubuntu、debian为例 概貌： 源列表主文件为 /etc/apt/sources.list，另兼取 /etc/apt/sources.list.d/*，最终结果以并集论。 源列表文件以行为单位，每行分多个字段，字段间以空白符分隔。井号（#）开头行为注释行。 字段说明： 第一字段，指示包类型。 取值只有「deb」「deb-src」两个，分别对应二进制包和源码包。通常只有二进制包对我们有用。 第二字段，指示镜像站点，即「源」！ URL 通常需要定位到某个目录，一般是打开该目录就能看到有「dists」「pool」两个子目录。看看 http://ftp.cn.debian.org/debian 或 http://ftp.sjtu.edu.cn/ubuntu/。 第三字段，指示包的「版本」，姑且称为「仓库」。 打开一个源，再进入「dists」子目录可见该「源」中有哪些「版本」可用，就是那些子目录。通常都是大小版本用减号（-）连在一起命名。 很明显大版本号即系统的版本名称，比如「squeeze」「wheezy」。没有减号连接小版本的就是主版本。 Debian 的小版本名称自 squeeze 起与 Ubuntu 基本相同。除主版本外，小版本有 「security」，Ubuntu 用于指安全性更新。即影响系统安全的 bug 修补。对此，Debian 特殊一些，见下文。 「updates」，非安全性更新。即不影响到系统安全的 bug 修补。 「proposed-updates」，预更新。小 beta 版。过后会进入「updates」或「security」。Ubuntu 仅用「proposed」，无后缀「updates」。 「backports」，后备。某系统版本自正式发行后，其所有软件便会冻结版本号（按原始软件发布时间论），所有软件只修 bug，不增加任何功能。但有些人可能需要更新的版本所提供的新功能，甚至某些较新的软件根本就没有。该仓库正因此而设，但欠官方维护。此仓库版本处于第二优先顺序，除非特别指明或原来没有的软件，否则不会被安装。其余版本都处于第一优先顺序。 后续字段，指示包许可类型。 后续字段排名不分先后，最终结果取其并集。 按包本身的许可及所直接依赖的包的许可划分。打开一个源，进入「dists」子目录，然后再进入某个版本目录，又可见几个子目录。 Debian 最多有三种 「main」，本身是自由软件，且所有直接依赖的包也都是自由软件。 「contrib」，本身是自由软件，但直接依赖的包中有某个是非自由软件。 「non-free」，本身并非自由软件，无论依赖如何。当然，该软件本身是可以免费使用的。 Ubuntu 最多有四种 「main」，官方维护的自由软件。 「universe」，社区维护的自由软件。 「restricted」，设备专有驱动。 「multiverse」，同 Debian 的「non-free」。 特别之处： Debian 的安全性更新 不像 Ubuntu 放在「security」仓库，而是放在单独一个源中。各大镜像站通常都把一般的包放在根下来一级的「debian」目录中，而安全性更新则会放在「debian-security」目录中，如果有的话。 Debian 官方建议，所有安全性更新，只从官方（http://security.debian.org/debian-security）更新，不要用其它的镜像站，除非你对它非常放心。 安全性更新的第三字段形式固定为「版本名/updates」，比如「squeeze/updates」「wheezy/updates」。 Debian 的多媒体源 一些多媒体软件因牵涉到版权问题，Debian 官方并未收录，有一网站专门填补该空缺，见 http://www.deb-multimedia.org。 最后忠告： 不要启用太多的源，同一「版本」的源启用一个即可，否则容易引起混乱。 以下源可能较老，已经无人维护，只是对源的一个说明     # Debian 源列表说明      #      # 本文以 lenny 版本为例，使用时注意适当修改。      # 同一仓库的官方主站和各镜像站点只可取其一，不可叠加。            # ------------------------------------------------------------------------------      # 主源      # 必须，一般的包都从此获取。            # 官方主站      deb http://ftp.debian.org/debian lenny main contrib non-free      deb-src http://ftp.debian.org/debian lenny main contrib non-free            # 大陆网易镜像      deb http://mirrors.163.com/debian lenny main contrib non-free      deb-src http://mirrors.163.com/debian lenny main contrib non-free            # 台湾镜像之一      deb http://ftp.tw.debian.org/debian lenny main contrib non-free      deb-src http://ftp.tw.debian.org/debian lenny main contrib non-free            # 台湾镜像之二      deb http://ftp.twaren.net/debian lenny main contrib non-free      deb-src http://ftp.twaren.net/debian lenny main contrib non-free            # ------------------------------------------------------------------------------      # 计划更新      # 通常不必，发布小版本之前的测试库。该库包括所有的安全更新，有此则无需再设置安全      # 更新源。            # 官方主站      deb http://ftp.debian.org/debian lenny-proposed-updates main contrib non-free      deb-src http://ftp.debian.org/debian lenny-proposed-updates main contrib non-free            # 大陆网易镜像      deb http://mirrors.163.com/debian lenny-proposed-updates main contrib non-free      deb-src http://mirrors.163.com/debian lenny-proposed-updates main contrib non-free            # 台湾镜像之一      deb http://ftp.tw.debian.org/debian lenny-proposed-updates main contrib non-free      deb-src http://ftp.tw.debian.org/debian lenny-proposed-updates main contrib non-free            # 台湾镜像之二      deb http://ftp.twaren.net/debian lenny-proposed-updates main contrib non-free      deb-src http://ftp.twaren.net/debian lenny-proposed-updates main contrib non-free            # ------------------------------------------------------------------------------      # 安全更新      # 建议，若使用了计划更新源则无需此源。            # 官方主站      deb http://security.debian.org/debian-security lenny/updates main contrib non-free      deb-src http://security.debian.org/debian-security lenny/updates main contrib non-free            # 大陆网易镜像      deb http://mirrors.163.com/debian-security lenny/updates main contrib non-free      deb-src http://mirrors.163.com/debian-security lenny/updates main contrib non-free            # 台湾镜像之一      deb http://ftp.twaren.net/debian-security lenny/updates main contrib non-free      deb-src http://ftp.twaren.net/debian-security lenny/updates main contrib non-free            # ------------------------------------------------------------------------------      # 易变量更新      # 建议，有些软件存在部分数据经常变动，如杀软病毒库之类。            # 官方主站      deb http://volatile.debian.org/debian-volatile lenny/volatile main contrib non-free      deb-src http://volatile.debian.org/debian-volatile lenny/volatile main contrib non-free            # 台湾镜像之一      deb http://ftp.tw.debian.org/debian-volatile lenny/volatile main contrib non-free      deb-src http://ftp.tw.debian.org/debian-volatile lenny/volatile main contrib non-free            # ------------------------------------------------------------------------------      # 多媒体源      # 想当桌面用的就必须加上，解码器等都在此。      # 使用前先下载安装 http://www.debian-multimedia.org/pool/main/d/debian-multimedia-keyring/ 中的 debian-multimedia-keyring_2008.10.16_all.deb 或更新版本。            # 官方主站      deb http://www.debian-multimedia.org lenny main      deb-src http://www.debian-multimedia.org lenny main            # 台湾镜像之一      deb http://ftp.tw.debian.org/debian-multimedia lenny main      deb-src http://ftp.tw.debian.org/debian-multimedia lenny main            # ------------------------------------------------------------------------------      # 后备源      # 一般进入 stable 的软件都会被锁定版本，只有安全更新，绝无版本升级，但仍有部分软      # 件可能需要新版，甚至添加一些原本没有的软件，此库正为此例外情况而设。      # 使用前先下载安装 http://www.backports.org/debian/pool/main/d/debian-backports-keyring/ 中的 debian-backports-keyring_2009.02.20_all.deb 或更新版本。      # 使用时带 -t lenny-backports 参数，如：      # aptitude install -R -t lenny-backports opoffice.org      # 这将安装 3.1.1 版本的 OpenOffice.org ，否则将是 2.4.1 版。            # 官方主站      deb http://www.backports.org/debian lenny-backports main contrib non-free      deb-src http://www.backports.org/debian lenny-backports main contrib non-free            # 大陆网易镜像      deb http://mirrors.163.com/debian-backport lenny-backports main contrib non-free      deb-src http://mirrors.163.com/debian-backport lenny-backports main contrib non-free            # 台湾镜像之一      deb http://ftp.tw.debian.org/backports.org lenny-backports main contrib non-free      deb-src http://ftp.tw.debian.org/backports.org lenny-backports main contrib non-free","title":"Linux源的知识。。。"},{"content":" 队列的一个显著的特征正好的和栈是相反的，它是按照先进先出（FIFO）的方式存储和检索元素，这就是说，对线插入队列的要先删除。还有就是队列是限制在两端进行插入和删除操作的线性表，允许进行存入操作的一端就叫“队尾”，允许进行删除操作的就是“对头”。当线性表中没有元素时，称为“空队“。那么，我们可以吧队列想象地理解成银行办理业务的一队人。   下面介绍顺序队列的定义和实现（以前写的代码） /*sequeue.h*/#define N 8typedef int datatyde;typedef struct {\tdatatyde data[N];\tint front,rear; }sequeue;sequeue *Createsequeue();int Emptysequeue(sequeue *sq);int Fullsequeue(sequeue *sq);void Clearsequeue(sequeue *sq);void Ensequeue(sequeue *sq,datatyde x);datatyde Desequeue(sequeue *sq); /*sequeue.c#include \"sequeue.h\"#include <stdio.h>#include <stdlib.h>sequeue *Createsequeue(){\tsequeue *sq;\tsq=(sequeue *)malloc(sizeof(sequeue));  sq ->\tfront = sq -> rear=0;\treturn sq;}int Emptysequeue(sequeue *sq){\treturn (sq -> front == sq -> rear);}int Fullsequeue(sequeue *sq){\treturn ((sq -> rear+1)%N == sq -> front);}void Clearsequeue(sequeue *sq){   sq -> front = sq -> rear;\treturn;}void Ensequeue(sequeue *sq,datatyde x){\tsq -> rear = (sq -> rear+1) % N;\tsq -> data[sq -> rear]=x;}datatyde Desequeue(sequeue *sq){  sq -> front = (sq -> front + 1) % N; return (sq ->data[sq -> front]);} 下面是链式队的定义和实现  队列的定义的和实现和栈的定义和实现差不多。好多函数接口在单链表定义的时候已经实现，具体可以参照单链表的实现和定义。单链表博客链接：点击打开链接。      /*queue.h*/#ifndef QUEUE_H#define QUEUE_H#include <stdlib.h>#include \"list.h\"/*inplement as linked lists */typedef List Queue;/*Public inerface */#define queue_init list_init #define queue_destroy list_destory int queue_enqueue(Queue *queue,const void *data);int queue_dequeue(Queue *queue,void *data);#define queue_peek(queue)  ((queue) ->head == NULL? NULL:(queue)->head->data)#define queue_size list_size#endif   /*queue.c*/#include <stdlib.h>#include \"../include/list.h\"#include \"../include/queue.h\"/*queue_enqueue */int queue_enqueue(Queue * queue, const void * data){    return list_ins_next(queue, list_tail(queue),  data);}/*queue_dequeue*/int queue_dequeue(Queue * queue, void * data){    return list_rem_next(queue, NULL, data);}    ","title":"数据结构---队列的实现和个人分析"},{"content":"题：输入一个10进制整数，输出16进制。     转化16进制数，首先应该除以基数16，得到的模为转化后的最低位的数，得到的商再除以基数16，再得到模就是下个位的数........以此类推，当商等于0时，停止转化。这样我们很容易想到运用栈的特性先进后出来保存得到模，最后全部打印出来；下面使用顺序栈实现： #include <stdio.h>#include <stdlib.h>#define N 20typedef int datatype;typedef struct stack{datatype data[N];int top;}sqstack;int main(){\tint n;\tscanf(\"%d\",&n);\tsqstack *s;\ts = (sqstack *)malloc(sizeof(sqstack));\ts -> top =-1;\twhile(n>0)\t{\t\ts -> data[++s->top]=n%16;\t\tn= n/16;\t}\twhile(-1 !=s->top)\t{\t  if(s -> data[s ->top] > 9)\t\t  printf(\"%c\",s -> data[s -> top]-10 + 'a');\t  else\t\t  printf(\"%d\",s-> data[s -> top]);\t s -> top --;\t}\tputs(\"\");\treturn 0;} 题：求一个表达式的计算结果       首先要建立2个栈：操作数栈和运算符栈，这里要考虑到运算符的优先级。      规则：1、自左向右扫面表达式，如遇到操作数一律进栈；                 2、当遇到运算符时，如果他的优先级比栈顶元素的优先级别高时，就进栈。反之，取出栈顶元素和操作数的栈顶元素进行计算，并将结果存如操作数栈，然后继续。                 3、左括号一律进运算符栈，右括号一律不进运算符栈，取出运算符栈栈顶元素和操作数栈顶的两个操作数进行计算，并将结果压入操作数栈，知道取出左括号为止。按照下面的规则，实现代码：         #include <stdio.h>#include <stdlib.h>#include \"linkstack.h\"#define  N  32int Pri(char op){\tswitch ( op )\t{\tcase '+':\tcase '-':\t\treturn 1;\tcase '*':\tcase '/':\t\treturn 2;\t}\treturn 0;}int Compute(int left, int right, char op){\tswitch ( op )\t{\tcase '+':\t\treturn left + right;\tcase '-':\t\treturn left - right;\tcase '*':\t\treturn left * right;\tcase '/':\t\treturn left / right;\t}\treturn 0;}void del_op(linkstack *operand, linkstack *operator, char op){\tint left, right;\tchar sign;\twhile (!EmptyLinkstack(operator) && Pri(op) <= Pri(GetTop(operator)))\t{\t\tright = PopLinkstack(operand);\t\tleft = PopLinkstack(operand);\t\tsign = PopLinkstack(operator);\t\tPushLinkstack(operand, Compute(left, right, sign));\t}\tPushLinkstack(operator, op);\treturn;}int main(){\tchar str[N], *p = str, sign;\tint sum = 0, left, right;\tlinkstack *operand, *operator;\toperand = CreateLinkstack();\toperator = CreateLinkstack();\tscanf(\"%s\", str);\twhile (*p != '\\0')\t{\t\tif ('0' <= *p && *p <= '9')\t\t{\t\t\twhile ('0' <= *p && *p <= '9')\t\t\t{\t\t\t\tsum = 10*sum + *p - '0';\t\t\t\tp++;\t\t\t}\t\t\tPushLinkstack(operand, sum);\t\t\tsum = 0;\t\t}\t\telse\t\t{\t\t\tdel_op(operand, operator, *p);\t\t\tp++;\t\t}\t}\twhile ( ! EmptyLinkstack(operator) )\t{\t\tright = PopLinkstack(operand);\t\tleft = PopLinkstack(operand);\t\tsign = PopLinkstack(operator);\t\tPushLinkstack(operand, Compute(left, right, sign));\t}\tprintf(\"%s = %d\\n\", str, GetTop(operand));\treturn 0;}  ","title":"数据结构----栈运用的小例子"},{"content":"转载：http://linuxgirl.blog.51cto.com/1910230/378876   一．填空题： 1. 在Linux系统中，以 文件 方式访问设备 。 2. Linux内核引导时，从文件 /etc/fstab 中读取要加载的文件系统。 3. Linux文件系统中每个文件用 i节点 来标识。 4. 全部磁盘块由四个部分组成，分别为引导块 、专用块 、 i节点表块 和数据存储块。 5. 链接分为： 硬链接 和 符号链接 。 6. 超级块包含了i节点表 和 空闲块表 等重要的文件系统信息。 7. 某文件的权限为：d-rw-_r--_r--，用数值形式表示该权限，则该八进制数为： 644 ，该文件属性是 目录 。 8. 前台起动的进程使用 Ctrl+c 终止。 9. 静态路由设定后，若网络拓扑结构发生变化，需由系统管理员修改路由的设置。 10. 网络管理的重要任务是： 控制 和 监控 。 11. 安装Linux系统对硬盘分区时，必须有两种分区类型： 文件系统分区 和 交换分区 。 13. 编写的Shell程序运行前必须赋予该脚本文件 执行 权限。 14. 系统管理的任务之一是能够在 分布式 环境中实现对程序和数据的安全保护、备份、恢复和更新。 15. 系统交换分区是作为系统 虚拟存储器 的一块区域。 16. 内核分为 进程管理系统 、 内存管理系统 、 I/O管理系统 和文件管理系统 等四个子系统。 17. 内核配置是系统管理员在改变系统配置 硬件 时要进行的重要操作。 18. 在安装Linux系统中，使用netconfig程序对网络进行配置，该安装程序会一步步提示用户输入主机名、域名、域名服务器、IP地址、 网关地址 和 子网掩码 等必要信息。 19. 唯一标识每一个用户的是用户 ID 和用户名。 20 . RIP 协议是最为普遍的一种内部协议，一般称为动态路由信息协议。 21. 在Linux系统中所有内容都被表示为文件，组织文件的各种方法称为 文件系统 。 22. DHCP可以实现动态 IP 地址分配。 23. 系统网络管理员的管理对象是服务器、 用户 和服务器的进程 以及系统的各种资源。 24. 网络管理通常由监测、传输和管理三部分组成，其中管理部分是整个网络管理的中心。 25. 当想删除本系统用不上的 设备驱动程序 时必须编译内核，当内核不支持系统上的 设备驱动程序 时，必须对内核 升级 。 26 Ping命令可以测试网络中本机系统是否能到达 一台远程主机 ，所以常常用于测试网络的 连通性 。 27. vi编辑器具有两种工作模式： 命令模式 和 输入模式 。 28. 可以用ls –al命令来观察文件的权限，每个文件的权限都用10位表示，并分为四段，其中第一段占 1 位，表示 文件类型 ，第二段占3位，表示 文件所有者 对该文件的权限。 29. 进程与程序的区别在于其动态性，动态的产生和终止，从产生到终止进程可以具有的基本状态为： 运行态 、就绪态 和 等待态（阻塞态） 。 30. DNS实际上是分布在internet上的主机信息的数据库，其作用是实现 IP地址和主机名 之间的转换。 31. Apache是实现WWW服务器功能的应用程序，即通常所说的“浏览web服务器”，在服务器端 为用户提供浏览 web服务 的就是apache应用程序。 32. 在Linux系统上做备份可以有两种类型：系统备份 和 用户备份 。其中前者是指对 操作系统 的备份，后者是指对 应用程序和用户文件的备份。 33. CD-ROM标准的文件系统类型是 iso9660 。 34. 当lilo.conf配置完毕后，使之生效，应运行的命令及参数是 lilo 。 35. 在使用ls命令时，用八进制形式显示非打印字符应使用参数 -b 。 36. Linux使用支持Windows 9.x/2000长文件名的文件系统的类型是 vfat 。 37. 设定限制用户使用磁盘空间的命令是 quota 。 38 在Linux系统中，用来存放系统所需要的配置文件和子目录的目录是 /etc 。 39. 硬连接只能建立对 文件 链接。符号链接可以跨不同文件系统创建。 40. 套接字文件的属性位是 s 。 41. 结束后台进程的命令是 kill 。 42. 进程的运行有两种方式，即 独立运行和使用父进程运行 。 43. Links分为 硬链接和符号链接 。 44. 在超级用户下显示Linux系统中正在运行的全部进程，应使用的命令及参数是 ps -aux 。 45. 管道文件的属性位是 p 。 46. 将前一个命令的标准输出作为后一个命令的标准输入，称之为 管道 。 47. 为脚本程序指定执行权的命令及参数是 chmod a+x filename 。 48. 进行远程登录的命令是 telnet 。 49. 欲发送10个分组报文测试与主机abc.tuu.edu.cn的连通性，应使用的命令和参数是： ping abc.tuu.edu.cn –c 10 。 50. DNS服务器的进程命名为named，当其启动时，自动装载 /etc目录下的 named.conf 文件中定义的DNS分区数据库文件。 51. Apache服务器进程配置文件是 httpd.conf 。 52.在 Linux系统中，压缩文件后生成后缀为.gz文件的命令是 gzip 。 53. 在用vi编辑文件时，将文件内容存入test.txt文件中，应在命令模式下键入 ：w test.txt 。 54 可以在标准输出上显示整年日历的命令及参数是 cal -y 。 55. 在shell编程时，使用方括号表示测试条件的规则是：方括号两边必须有 空格 。 56. 检查已安装的文件系统/dev/had5是否正常，若检查有错，则自动修复，其命令及参数是 fsck –a /dev/had5。 57. 在Windows9.x环境下共享Unix/Linux中的用户目录的一个工具是 Samba服务器 。 58. 系统管理员的职责是进行系统资源管理、系统性能管理、设备管理、安全管理和 系统性能监测 。 59 在Linux系统中，测试DNS服务器是否能够正确解析域名的的客户端命令，使用命令 nslookup 。 60. 在Linux系统下，第二个IDE通道的硬盘（从盘）被标识为 hdb 。 61. 当系统管理员需升级内核版本和改变系统硬件配置时，应 重新编译内核 。 62. 如果只是要修改系统的IP地址，应修改 /etc/rc.d/rc.inet1 配置文件。 63. 当LAN内没有条件建立DNS服务器，但又想让局域网内的用户可以使用计算机名互相访问时，应配置 /etc/hosts文件。 64. 在vi编辑环境下，使用 Esc键 进行模式转换。 65. Slackware Linux 9.0通常使用 ext3 文件系统，系统的全部磁盘块由 四 部分组成。 66. 将/home/stud1/wang目录做归档压缩，压缩后生成wang.tar.gz文件，并将此文件保存到/home目录下，实现此任务的tar命令格式 tar zcvf /home/wang.tar.gz /home/stud1/wang 。 67. 管道就是将前一个命令的 标准输出 作为后一个命令的 标准输入 。 68. 在使用手工的方法配置网络时，可通过修改 /etc/HOSTNAME 文件来改变主机名，若要配置该计算机的域名解析客户端，需配置 /etc/resolv.conf 文件。 69. 启动进程有手动启动和调度启动两种方法，其中调度启动常用的命令为 at 、 batch 和 crontab 。 70. test.bns.com.cn的域名是 bns.com.cn ，如果要配置一域名服务器，应在 named.conf 文件中定义DNS数据库的工作目录。 71. Sendmail邮件系统使用的两个主要协议是： SMTP 和 POP ，前者用来发送邮件,后者用来接收邮件。 72. DHCP是动态主机配置协议的简称，其作用是：为网络中的主机分配IP地址 。 73. 目前代理服务器使用的软件包有很多种，教材中使用的是 squid 。 74. rm命令可删除文件或目录，其主要差别就是是否使用递归开关 -r或-R 。 75. mv 命令可以移动文件和目录，还可以为文件和目录重新命名。 76. 路由选择协议（RIP）的跳数表示到达目的地之前必须通过的 网关 数，RIP接受的最长距离是 15跳 。 77. ping命令用于测试网络的连通性，ping命令通过 ICMP 协议（internet控制信息协议）来实现。 78. nfs 协议用于实现Unix（/linux）主机之间的文件系统共享。 79. 在Linux操作系统中，设备都是通过特殊的 文件 来访问。 80. shell不仅是 用户命令的解释器 ，它同时也是一种功能强大的编程语言。 bash是Linux的缺省shell。 81. 用 >;>; 符号将输出重定向内容附加在原文的后面。 82. 增加一个用户的命令是：adduser 或useradd 。 83 进行字符串查找，使用grep命令。 84. 使用 * 每次匹配若干个字符。 85. /sbin 目录用来存放系统管理员使用的管理程序。 二．单项选择题: 1. 下面的网络协议中，面向连接的的协议是： A 。 A 传输控制协议 B 用户数据报协议 C 网际协议 D 网际控制报文协议 2. 在/etc/fstab文件中指定的文件系统加载参数中， D 参数一般用于CD-ROM等移动设备。 A defaults B sw C rw和ro D noauto 3. Linux文件权限一共10位长度，分成四段，第三段表示的内容是 C 。 A 文件类型 B 文件所有者的权限  C 文件所有者所在组的权限 D 其他用户的权限 4. 终止一个前台进程可能用到的命令和操作 B 。 A kill B <CTRL>;+C C shut down D halt 5．在使用mkdir命令创建新的目录时，在其父目录不存在时先创建父目录的选项是 D 。 A -m B -d C -f D -p 6. 下面关于i节点描述错误的是 A 。（inode是一种数据结构，vfs中描述文件的相关参数？？） A i节点和文件是一一对应的 B i节点能描述文件占用的块数 C i节点描述了文件大小和指向数据块的指针 D 通过i节点实现文件的逻辑结构和物理结构的转换 7. 一个文件名字为rr.Z，可以用来解压缩的命令是： D 。 A tar B gzip C compress D uncompress 8. 具有很多C语言的功能，又称过滤器的是 C 。 A csh B tcsh C awk　　（awk详解） D sed 9. 一台主机要实现通过局域网与另一个局域网通信，需要做的工作是 C 。 A 配置域名服务器 B 定义一条本机指向所在网络的路由 C 定义一条本机指向所在网络网关的路由 D 定义一条本机指向目标网络网关的路由 10. 建立动态路由需要用到的文件有 D 。 A /etc/hosts B /etc/HOSTNAME C /etc/resolv.conf D /etc/gateways 11. 局域网的网络地址192.168.1.0/24，局域网络连接其它网络的网关地址是192.168.1.1。主机192.168.1.20访问172.16.1.0/24网络时，其路由设置正确的是 B 。 A route add –net 192.168.1.0 gw 192.168.1.1 netmask 255.255.255.0 metric 1 B route add –net 172.16.1.0 gw 192.168.1.1 netmask 255.255.255.255 metric 1 C route add –net 172.16.1.0 gw 172.16.1.1 netmask 255.255.255.0 metric 1 D route add default 192.168.1.0 netmask 172.168.1.1 metric 1 12. 下列提法中，不属于ifconfig命令作用范围的是 D 。 A 配置本地回环地址 B 配置网卡的IP地址 C 激活网络适配器 D 加载网卡到内核中 13. 下列关于链接描述，错误的是 B 。 A 硬链接就是让链接文件的i节点号指向被链接文件的i节点 B 硬链接和符号连接都是产生一个新的i节点 C 链接分为硬链接和符号链接 D 硬连接不能链接目录文件 14. 在局域网络内的某台主机用ping命令测试网络连接时发现网络内部的主机都可以连同，而不能与公网连通，问题可能是 C。 A 主机IP设置有误 B 没有设置连接局域网的网关 C 局域网的网关或主机的网关设置有误 D 局域网DNS服务器设置有误 15. 下列文件中，包含了主机名到IP地址的映射关系的文件是： B 。 A /etc/HOSTNAME B /etc/hosts C /etc/resolv.conf D /etc/networks 16. 不需要编译内核的情况是 D 。 A 删除系统不用的设备驱动程序时 B 升级内核时 C 添加新硬件时 D 将网卡激活 17. 在shell中变量的赋值有四种方法，其中，采用name=12的方法称 A 。 A 直接赋值 B使用read命令 C 使用命令行参数 D使用命令的输出 18. D 命令可以从文本文件的每一行中截取指定内容的数据。 A cp B dd C fmt D cut 19. 下列不是Linux系统进程类型的是 D 。 A 交互进程 B 批处理进程 C 守护进程 D 就绪进程（进程状态） 20．配置Apache 1.3.19服务器需要修改的配置文件为___A______ A httpd.conf B access.conf C srm.conf D named.conf 21. 内核不包括的子系统是 D 。 A 进程管理系统 B 内存管理系统 C I/O管理系统 D硬件管理系统 22． 在日常管理中，通常CPU会影响系统性能的情况是： A 。 A CPU已满负荷地运转 B CPU的运行效率为30% C CPU的运行效率为50% D CPU的运行效率为80% 23． 若一台计算机的内存为128MB，则交换分区的大小通常是 C 。 A 64MB B 128MB C 256MB D 512MB 24． 在安装Linux的过程中的第五步是让用户选择安装方式，如果用户希望安装部分组件（软件程序），并在选择好后让系统自动安装，应该选择的选项是 D 。 A full B expert C newbie D menu 25． Linux有三个查看文件的命令，若希望在查看文件内容过程中可以用光标上下移动来查看文件内容，应使用 C命令。 A cat B more C less D menu 26． 下列信息是某系统用ps –ef命令列出的正在运行的进程， D 进程是运行Internet超级服务器，它负责监听Internet sockets上的连接，并调用合适的服务器来处理接收的信息。 A root 1 4.0 0.0 344 204? S 17:09 0:00 init  B root 2 0.0 0.1 2916 1520? S 17:09 0:00 /sbin/getty  C root 3 0.0 0.2 1364 632? S 17:09 0:00 /usr/sbin/syslogd  D root 4 0.0 1344 1204? S 17:09 0:10 /usr/sbin/inetd  27．在TCP/IP模型中，应用层包含了所有的高层协议，在下列的一些应用协议中， B 是能够实现本地与远程主机之间的文件传输工作。 A telnet B FTP C SNMP D NFS  28．当我们与某远程网络连接不上时，就需要跟踪路由查看，以便了解在网络的什么位置出现了问题，满足该目的的命令是 C 。 A ping B ifconfig C traceroute D netstat 29．对名为fido的文件用chmod 551 fido 进行了修改，则它的许可权是 D 。 A -rwxr-xr-x B -rwxr--r-- C -r--r--r-- D -r-xr-x—x 30． 在i节点表中的磁盘地址表中，若一个文件的长度是从磁盘地址表的第1块到第11块，则该文件共占有 B 块号。 A 256 B 266 C 11 D 256×10 (??)31． 用ls –al 命令列出下面的文件列表， D 文件是符号连接文件。 A -rw-rw-rw- 2 hel-s users 56 Sep 09 11:05 hello B -rwxrwxrwx 2 hel-s users 56 Sep 09 11:05 goodbey C drwxr--r-- 1 hel users 1024 Sep 10 08:10 zhang D lrwxr--r-- 1 hel users 2024 Sep 12 08:12 cheng 32． DNS域名系统主要负责主机名和 A 之间的解析。 A IP地址 B MAC地址 C 网络地址 D 主机别名 33． WWW服务器是在Internet上使用最为广泛，它采用的是 B 结构。 A 服务器/工作站 B B/S C 集中式 D 分布式 34．Linux系统通过 C 命令给其他用户发消息。 A less B mesg y C write D echo to [ 注：mesg [y|n] 所有使用者 决定是否允许其他人传讯息到自己的终端机介面 ] 35．NFS是 C 系统。 A 文件 B 磁盘 C 网络文件 D 操作 36． B 命令可以在Linux的安全系统中完成文件向磁带备份的工作。 A cp B tr C dir D cpio [注：如果用 echo $PATH 或者 echo $LD_LIBRARY_PATH 等类似的命令来显示路径信息的话，我们看到的将会是一大堆用冒号连接在一起的路径， tr 命令可以把这些冒号转换为回车，这样，这些路径就具有很好的可读性了： echo $PATH | tr \":\" \"\\n\"] 37．Linux文件系统的文件都按其作用分门别类地放在相关的目录中，对于外部设备文件，一般应将其放在 C 目录中。 A /bin B /etc C /dev D /lib  38．在重新启动Linux系统的同时把内存中的信息写入硬盘，应使用 D 命令实现。 A # reboot B # halt C # reboot D # shutdown –r now 39．网络管理具备以下几大功能：配置管理、 A 、性能管理、安全管理和计费管理等。 A 故障管理 B 日常备份管理 C 升级管理 D 发送邮件 40．关于代理服务器的论述，正确的是 A 。 A 使用internet上已有的公开代理服务器，只需配置客户端。 B 代理服务器只能代理客户端http的请求。 C 设置好的代理服务器可以被网络上任何主机使用。 D 使用代理服务器的客户端没有自己的ip地址。 41.关闭linux系统（不重新启动）可使用命令 B 。 A Ctrl+Alt+Del B halt C shutdown -r now D reboot 42．实现从IP地址到以太网MAC地址转换的命令为： C 。 A ping B ifconfig C arp D traceroute 43．在vi编辑器中的命令模式下，键入 B 可在光标当前所在行下添加一新行。 A <a>; B <o>; C <I>; D A 44．在vi编辑器中的命令模式下，删除当前光标处的字符使用 A 命令。 A <x>; B <d>;<w>; C <D>; D <d>;<d>; 45．在vi编辑器中的命令模式下，重复上一次对编辑的文本进行的操作，可使用 C 命令。 A 上箭头 B 下箭头 C <.>; D <*>; 46．用命令ls -al显示出文件ff的描述如下所示，由此可知文件ff的类型为 A 。 -rwxr-xr-- 1 root root 599 Cec 10 17:12 ff A 普通文件 B 硬链接 C 目录 D 符号链接 47．删除文件命令为： D 。 A mkdir B rmdir C mv D rm 48．在下列的名称中，不属于DNS服务器类型的是：____C_____ A Primary Master Server B Secondary Master Server C samba D Cache_only Server 49．网络管理员对WWW服务器进行访问、控制存取和运行等控制，这些控制可在 A 文件中体现。 A httpd.conf B lilo.conf C inetd.conf D resolv.conf 50．邮件转发代理也称邮件转发服务器，它可以使用SMTP协议，也可以使用 C 协议。  A FTP B TCP C UUCP D POP 51．启动samba服务器进程，可以有两种方式：独立启动方式和父进程启动方式，其中前者是在 C 文件中以独立进程方式启动。 A /usr/sbin/smbd B /usr/sbin/nmbd C rc.samba D /etc/inetd.conf 52．DHCP是动态主机配置协议的简称，其作用是可以使网络管理员通过一台服务器来管理一个网络系统，自动地为一个网络中的主机分配___D______地址。 A 网络 B MAC C TCP D IP 53．为了保证在启动服务器时自动启动DHCP进程，应将 A文件中的dhcpd=no改为dhcpd=yes。  A rc.inet1 B lilo.conf C inetd.conf D httpd.conf [注： 英文原义：RC 中文释义：含有程序（应用程序甚至操作系统）启动指令的脚本文件 注解：这一文件在操作系统启动时会自动执行，它含有要运行的指令（命令或其它脚本）列表。] 54．对文件进行归档的命令为 D 。 A dd B cpio C gzip D tar 55．改变文件所有者的命令为 C 。 A chmod B touch C chown D cat 56．在给定文件中查找与设定条件相符字符串的命令为： A 。 A grep B gzip C find D sort 57．建立一个新文件可以使用的命令为 D 。 A chmod B more C cp D touch(指令改变档案的时间记录。) 58．在下列命令中，不能显示文本文件内容的命令是： D 。  A more B less C tail D join 59．在使用匿名登录ftp时，用户名为 B 。 A users B anonymous C root D guest 60．在实际操作中，想了解命令logname 的用法，可以键入 D 得到帮助。 A logname --man B logname/？ C help logname D logname --help 61．如果LILO被安装在MBR，使用 A 命令即可卸载LILO。 A lilo –u B lilo –c C lilo –v D lilo -V 62．当用命令ls –al查看文件和目录时，欲观看卷过屏幕的内容，应使用组合键 D 。 A Shift+Home B Ctrl+ PgUp C Alt+ PgDn D Shift+ PgUp 63．mc是UNIX风格操作系统的 C 。 A 文件编辑器/程序编译器 B 配置网络的窗口工具  C 目录浏览器/文件管理器 D Samba服务器管理工具 64．i节点是一个 D 长的表，表中包含了文件的相关信息。 A 8字节 B 16字节 C 32字节 D 64字节 65．文件权限读、写、执行的三种标志符号依次是 A 。 A rwx B xrw C rdx D srw 66．Linux 文件名的长度不得超过 C 个字符。 A 64 B 128 C 256 D 512 67．进程有三种状态： C 。 A 准备态、执行态和退出态 B 精确态、模糊态和随机态 C 运行态、就绪态和等待态 D 手工态、自动态和自由态 68． 从后台启动进程，应在命令的结尾加上符号 A 。 A & B @ C # D $ 69． B 不是邮件系统的组成部分。 A 用户代理 B 代理服务器 C 传输代理 D 投递代理 70．在Shell脚本中，用来读取文件内各个域的内容并将其赋值给Shell变量的命令是 D 。 A fold B join C tr D read 71．crontab文件由六个域组成，每个域之间用空格分割，其排列如下： B 。 A MIN HOUR DAY MONTH YEAR COMMAND B MIN HOUR DAY MONTH DAYOFWEEK COMMAND C COMMAND HOUR DAY MONTH DAYOFWEEK  D COMMAND YEAR MONTH DAY HOUR MIN crontab命令：实现程序定时运行 72．用ftp进行文件传输时，有两种模式： C 。 A Word和binary B .txt和Word Document  C ASCII和binary D ASCII和Rich Text Format 73．某文件的组外成员的权限为只读；所有者有全部权限；组内的权限为读与写，则该文件的权限为 D 。 A 467 B 674 C 476 D 764 74．在DNS系统测试时，设named进程号是53，命令 D 通知进程重读配置文件。 A kill –USR2 53 B kill –USR1 53 C kill -INT 63 D kill –HUP 53 75．Apache服务器默认的接听连接端口号是 C 。 A 1024 B 800 C 80 (http)D 8 76．PHP和MySQL的联合使用解决了 C 。 A 在Proxy上处理数据库的访问问题 B 在WWW服务器上处理黑客的非法访问问题 C 在WWW服务器上处理数据库的访问问题 D 在Sendmail邮件系统上处理数据库的访问问题 77．OpenSSL是一个 A 。 A 加密软件 B 邮件系统 C 数据库管理系统 D 嵌入式脚本编程语言 78．Samba服务器的配置文件是 D 。 A httpd.conf B inetd.conf C rc.samba D smb.conf 79．关于DNS服务器，叙述正确的是 D 。 A DNS服务器配置不需要配置客户端 B 建立某个分区的DNS服务器时只需要建立一个主DNS服务器 C 主DNS服务器需要启动named进程，而辅DNS服务器不需要 D DNS服务器的root.cache文件包含了根名字服务器的有关信息 80．退出交互模式的shell，应键入 C 。 A <Esc>; B ^q C exit D quit 81．将Windows C:盘(hda1)安装在Linux文件系统的/winsys目录下，命令是 B 。 A root@l04.edu.cn:~#mount dev/had1 /winsys  B root@l04.edu.cn:~#mount /dev/had1 /winsys C root@l04.edu.cn:~#mount /dev/had1 winsys D root@l04.edu.cn:~#mount dev/had1 winsys 82．设超级用户root当前所在目录为：/usr/local，键入cd命令后，用户当前所在目录为 B 。 A /home B /root C /home/root D /usr/local 83．字符设备文件类型的标志是 B 。 A p B c C s D l 84．将光盘CD-ROM（hdc）安装到文件系统的/mnt/cdrom目录下的命令是 C 。  A mount /mnt/cdrom B mount /mnt/cdrom /dev/hdc C mount /dev/hdc /mnt/cdrom D mount /dev/hdc 85．将光盘/dev/hdc卸载的命令是 C 。 A umount /dev/hdc B unmount /dev/hdc C umount /mnt/cdrom /dev/hdc D unmount /mnt/cdrom /dev/hdc 86．在/home/stud1/wang目录下有一文件file，使用 D 可实现在后台执行命令，此命令将file文件中的内容输出到file.copy文件中。 A cat file >;file.copy B cat >;file.copy C cat file file.copy & D cat file >;file.copy & 87．在DNS配置文件中，用于表示某主机别名的是： B 。 A NS B CNAME C NAME D CN 88．可以完成主机名与IP地址的正向解析和反向解析任务的命令是： A 。 A nslookup B arp C ifconfig D dnslook 89．下列变量名中有效的shell变量名是： C 。 A -2-time B _2$3 C trust_no_1 D 2004file 90．qmail是 B 。 A 收取邮件的协议 B 邮件服务器的一种 C 发送邮件的协议 D 邮件队列 92．已知某用户stud1，其用户目录为/home/stud1。分页显示当前目录下的所有文件的文件或目录名、用户组、用户、文件大小、文件或目录权限、文件创建时间等信息的命令是 D 。 A more ls –al B more –al ls C more < ls –al D ls –al | more  93．关于进程调度命令， B 是不正确的。at--定期执行程序的调度命令 A 当日晚11点执行clear命令，使用at命令：at 23:00 today clear B 每年1月1日早上6点执行date命令，使用at命令：at 6am Jan 1 date C 每日晚11点执行date命令，crontab文件中应为：0 23 * * * date D 每小时执行一次clear命令，crontab文件中应为：0 */1 * * * clear 94．系统中有用户user1和user2，同属于users组。在user1用户目录下有一文件file1，它拥有644的权限，如果user2用户想修改user1用户目录下的file1文件，应拥有 B 权限。 A 744 B 664 C 646 D 746 ??95．如果想配置一台匿名ftp服务器，应修改 C 文件。 A /etc/gateway B /etc/ftpservers C /etc/ftpusers D /etc/inetd.conf 96．Samba服务器的进程由B 两部分组成 。 A named和sendmail B smbd和nmbd C bootp和dhcpd D httpd和squid 97．要配置NFS服务器，在服务器端主要配置 C 文件。 A /etc/rc.d/rc.inet1 B /etc/rc.d/rc.M C /etc/exports D /etc/rc.d/rc.S 98．为保证在启动服务器时自动启动DHCP进程，应对 B 文件进行编辑。 A /etc/rc.d/rc.inet2 B /etc/rc.d/rc.inet1 C /etc/dhcpd.conf D /etc/rc.d/rc.S 99．在配置代理服务器时，若设置代理服务器的工作缓存为64MB，配置行应为 D 。 A cache 64MB B cache_dir ufs /usr/local/squid/cache 10000 16 256 C cache_ mgr 64MB D cache_ mem 64MB 100．安全管理涉及的问题包括保证网络管理工作可靠进行的安全问题和保护网络用户及网络管理对象问题。 C 属于安全管理的内容。 A 配置设备的工作参数 B 收集与网络性能有关的数据  C 控制和维护访问权限 D 监测故障 101．以下命令对中，正确的是： B 。 A ls和sl B cat和tac C more和erom D exit和tixe cat是显示文件夹的命令，这个大家都知道，tac是cat的倒写，意思也和它是相反的。cat是从第一行显示到最后一行，而tac是从最后一行显示到第一行，而rev 则是从最后一个字符显示到第一个字符 102． B 命令是在vi编辑器中执行存盘退出。 A :q B ZZ C :q! D :WQ 103．下列关于/etc/fstab文件描述，正确的是 D 。 A fstab文件只能描述属于linux的文件系统 B CD_ROM和软盘必须是自动加载的 C fstab文件中描述的文件系统不能被卸载 D 启动时按fstab文件描述内容加载文件系统 104．通过文件名存取文件时，文件系统内部的操作过程是通过 C 。 A 文件在目录中查找文件数据存取位置。B 文件名直接找到文件的数据，进行存取操作。 C 文件名在目录中查找对应的I节点，通过I节点存取文件数据。 D 文件名在中查找对应的超级块，在超级块查找对应i节点，通过i节点存取文件数据 105．Linux将存储设备和输入/输出设备均看做文件来操作， C 不是以文件的形式出现。 A 目录 B 软链接 C i节点表 D 网络适配器 106．关于i节点和超级块，下列论述不正确的是 B 。 A i节点是一个长度固定的表 B 超级块在文件系统的个数是唯一的 C i节点包含了描述一个文件所必需的全部信息 D 超级块记录了i节点表和空闲块表信息在磁盘中存放的位置 107． D 设备是字符设备。 A hdc B fd0 C hda1 D tty1(A,B,C为块设备) 108． B 目录存放着Linux的源代码。 A /etc B /usr/src C /usr D /home 109．关于文件系统的安装和卸载，下面描述正确的是 A 。 A 如果光盘未经卸载，光驱是打不开的 B 安装文件系统的安装点只能是/mnt下 C 不管光驱中是否有光盘，系统都可以安装CD-ROM设备 D mount /dev/fd0 /floppy 此命令中目录/floppy是自动生成的 110． B 不是进程和程序的区别。 A 程序是一组有序的静态指令，进程是一次程序的执行过程 B 程序只能在前台运行，而进程可以在前台或后台运行 C 程序可以长期保存，进程是暂时的 D 程序没有状态，而进程是有状态的 111．文件exer1的访问权限为rw-r--r--，现要增加所有用户的执行权限和同组用户的写权限，下列命令正确的是 A。 A chmod a+x g+w exer1 B chmod 765 exer1 C chmod o+x exer1 D chmod g+w exer1 112．有关归档和压缩命令，下面描述正确的是 C 。 A 用uncompress命令解压缩由compress命令生成的后缀为.zip的压缩文件 B unzip命令和gzip命令可以解压缩相同类型的文件 C tar归档且压缩的文件可以由gzip命令解压缩 D tar命令归档后的文件也是一种压缩文件 113．不是shell具有的功能和特点的是 C 。 A 管道 B 输入输出重定向 C 执行后台进程 D 处理程序命令 114．下列对shell变量FRUIT操作，正确的是： C 。 A 为变量赋值：$FRUIT=apple B 显示变量的值：fruit=apple C 显示变量的值：echo $FRUIT D 判断变量是否有值：[ -f “$FRUIT” ] 三．简答题： 1．简述Linux文件系统通过i节点把文件的逻辑结构和物理结构转换的工作过程。 参考答案： Linux通过i节点表将文件的逻辑结构和物理结构进行转换。 i 节点是一个64字节长的表，表中包含了文件的相关信息，其中有文件的大小、文件所有者、文件的存取许可方式以及文件的类型等重要信息。在i节点表中最重要 的内容是磁盘地址表。在磁盘地址表中有13个块号，文件将以块号在磁盘地址表中出现的顺序依次读取相应的块。Linux文件系统通过把i节点和文件名进行 连接，当需要读取该文件时，文件系统在当前目录表中查找该文件名对应的项，由此得到该文件相对应的i节点号，通过该i节点的磁盘地址表把分散存放的文件物 理块连接成文件的逻辑结构。 2．简述进程的启动、终止的方式以及如何进行进程的查看。 参考答案： 在Linux中启动一个进程有手工启动和调度启动两种方式： （1）手工启动 用户在输入端发出命令，直接启动一个进程的启动方式。可以分为： ①前台启动：直接在SHELL中输入命令进行启动。 ②后台启动：启动一个目前并不紧急的进程，如打印进程。 （2）调度启动 系统管理员根据系统资源和进程占用资源的情况，事先进行调度安排，指定任务运行的时间和场合，到时候系统会自动完成该任务。 经常使用的进程调度命令为：at、batch、crontab。 3. 简述DNS进行域名解析的过程。 参考答案： 首先，客户端发出DNS请求翻译IP地址或主机名。DNS服务器在收到客户机的请求后： （1）检查DNS服务器的缓存，若查到请求的地址或名字，即向客户机发出应答信息； （2）若没有查到，则在数据库中查找，若查到请求的地址或名字，即向客户机发出应答信息； （3）若没有查到，则将请求发给根域DNS服务器，并依序从根域查找顶级域，由顶级查找二级域，二级域查找三级，直至找到要解析的地址或名字，即向客户机所在网络的DNS服务器发出应答信息，DNS服务器收到应答后现在缓存中存储，然后，将解析结果发给客户机。 （4）若没有找到，则返回错误信息。 4．系统管理员的职责包括那些？管理的对象是什么？ 参考答案： 系统管理员的职责是进行系统资源管理、设备管理、系统性能管理、安全管理和系统性能监测。管理的对象是服务器、用户、服务器的进程及系统的各种资源等。 5．简述安装Slackware Linux系统的过程。 参考答案：  （1）对硬盘重新分区。 （2）启动Linux系统（用光盘、软盘等）。 （3）建立Linux主分区和交换分区。（4）用setup命令安装Linux系统。 （5）格式化Linux主分区和交换分区（6）安装Linux软件包 （7）安装完毕，建立从硬盘启动Linux系统的LILO启动程序，或者制作一张启动Linux系统的软盘。重新启动Linux系统。 6．什么是静态路由，其特点是什么？什么是动态路由，其特点是什么？ 参考答案： 静态路由是由系统管理员设计与构建的路由表规定的路由。适用于网关数量有限的场合，且网络拓朴结构不经常变化的网络。其缺点是不能动态地适用网络状况的变化，当网络状况变化后必须由网络管理员修改路由表。 动态路由是由路由选择协议而动态构建的，路由协议之间通过交换各自所拥有的路由信息实时更新路由表的内容。动态路由可以自动学习网络的拓朴结构，并更新路由表。其缺点是路由广播更新信息将占据大量的网络带宽。 87．进程的查看和调度分别使用什么命令？ 参考答案： 进程查看的命令是ps和top。 进程调度的命令有at，crontab，batch，kill。 8．当文件系统受到破坏时，如何检查和修复系统？ 参考答案： 成功修复文件系统的前提是要有两个以上的主文件系统，并保证在修复之前首先卸载将被修复的文件系统。 使用命令fsck对受到破坏的文件系统进行修复。fsck检查文件系统分为5步，每一步检查系统不同部分的连接特性并对上一步进行验证和修改。在执行 fsck命令时，检查首先从超级块开始，然后是分配的磁盘块、路径名、目录的连接性、链接数目以及空闲块链表、i-node。 9．解释i节点在文件系统中的作用。 参考答案： 在linux文件系统中，是以块为单位存储信息的，为了找到某一个文件在存储空间中存放的位置，用i节点对一个文件进行索引。I节点包含了描述一个文件所必须的全部信息。所以i节点是文件系统管理的一个数据结构。 10．什么是符号链接，什么是硬链接？符号链接与硬链接的区别是什么？ 参考答案： 链接分硬链接和符号链接。 符号链接可以建立对于文件和目录的链接。符号链接可以跨文件系统，即可以跨磁盘分区。符号链接的文件类型位是l，链接文件具有新的i节点。 硬链接不可以跨文件系统。它只能建立对文件的链接，硬链接的文件类型位是－，且硬链接文件的i节点同被链接文件的i节点相同。 11．在对linux系统分区进行格式化时需要对磁盘簇（或i节点密度）的大小进行选择，请说明选择的原则。 参考答案： 磁盘簇（或i节点密度）是文件系统调度文件的基本单元。磁盘簇的大小，直接影响系统调度磁盘空间效率。当磁盘分区较大时，磁盘簇也应选得大些；当分区较小时，磁盘簇应选得小些。通常使用经验值。 12．简述网络文件系统NFS，并说明其作用。 参考答案： 网络文件系统是应用层的一种应用服务，它主要应用于Linux和Linux系统、Linux和Unix系统之间的文件或目录的共享。对于用户而言可以通过 NFS方便的访问远地的文件系统，使之成为本地文件系统的一部分。采用NFS之后省去了登录的过程，方便了用户访问系统资源。 13．某/etc/fstab文件中的某行如下： /dev/had5 /mnt/dosdata msdos defaults,usrquota 1 2 请解释其含义。 参考答案: （1）第一列：将被加载的文件系统名；（2）第二列：该文件系统的安装点； （3）第三列：文件系统的类型；（4）第四列：设置参数； （5）第五列：供备份程序确定上次备份距现在的天数； （6）第六列：在系统引导时检测文件系统的顺序。 14．Apache服务器的配置文件httpd.conf中有很多内容，请解释如下配置项： （1）MaxKeepAliveRequests 200 （2）UserDir public_html （3）DefaultType text/plain （4）AddLanguare en.en （5）DocumentRoot“/usr/local/httpd/htdocs” （6）AddType application/x-httpd-php.php.php.php4 参考答案: （1）允许每次连接的最大请求数目，此为200；（2）设定用户放置网页的目录； （3）设置服务器对于不认识的文件类型的预设格式； （4）设置可传送语言的文件给浏览器；（5）该目录为Apache放置网页的地方； （6）服务器选择使用php4。 15．某Linux主机的/etc/rc.d/rc.inet1文件中有如下语句，请修正错误，并解释其内容。 /etc/rc.d/rc.inet1： …… ROUTE add –net default gw 192.168.0.101 netmask 255.255.0.0 metric 1 ROUTE add –net 192.168.1.0 gw 192.168.0.250 netmask 255.255.0.0 metric 1 参考答案: 修正错误: （1）ROUTE应改为小写：route；（2）netmask 255.255.0.0应改为:netmask 255.255.255.0； （3）缺省路由的子网掩码应改为:netmask 0.0.0.0； （4）缺省路由必须在最后设定,否则其后的路由将无效。 解释内容: （1）route：建立静态路由表的命令；（2）add：增加一条新路由； （3）-net 192.168.1.0：到达一个目标网络的网络地址； （4）default：建立一条缺省路由；（5）gw 192.168.0.101：网关地址； （6）metric 1：到达目标网络经过的路由器数（跳数）。 16．试解释apache服务器以下配置的含义：  （1）port 1080 （2）UserDir userdoc （3）DocumentRoot “/home/htdocs” （4）<Directory /home/htdocs/inside>; Options Indexes FollowSymLinks AllowOverride None Order deny,allow deny from all allow from 192.168.1.5 <\/Directory>; （5）Server Type Standlone 参考答案： Apache服务器配置行含义如下：  （1）将apache服务器的端口号设定为1080； （2）设定用户网页目录为userdoc； （3）设定apache服务器的网页根目录:/home/htdocs； （4）在此apache服务器上设定一个目录/home/htdocs/inside，且此目录只允许IP地址为192.168.1.5的主机访问； （5）定义apache服务器以独立进程的方式运行。 17．简述使用ftp进行文件传输时的两种登录方式？它们的区别是什么？常用的ftp文件传输命令是什么？  参考答案： （1）ftp有两种登录方式：匿名登录和授权登录。使用匿名登录时，用户名为：anonymous，密码为：任何合法email地址；使用授权登录时，用户名为用户在远程系统中的用户帐号，密码为用户在远程系统中的用户密码。 区别：使用匿名登录只能访问ftp目录下的资源，默认配置下只能下载；而授权登录访问的权限大于匿名登录，且上载、下载均可。 （2）ftp文件传输有两种文件传输模式：ASCII模式和binary模式。ASCII模式用来传输文本文件，其他文件的传输使用binary模式。 （3）常用的ftp文件传输命令为：bin、asc、put、get、mput、mget、prompt、bye","title":"Linux面试题汇总答案"},{"content":"环境 RedHat Linux 9 + VWWare 8.0 + SSH 3.2.9 + Putty 0.62 + MySQL 3.2   问题 通过JDBC连接MySQL，出现“读取 /usr/java/jdk1.6.0_27/jre/lib/ext/mysql-connector-java-3.2.0-alpha-bin.jar时出错cannot read zip file”   解决 换jar包。比如之前使用的mysql-connector-java-3.2.0-alpha-bin.jar只有300接近200K，换了个接近400K的就对了。估计是最开始那个是zip文件。","title":"读取 $JAVA_HOME/jre/lib/ext/mysql-connector-java-3.2.0-alpha-bin.jar 时出错cannot read zip file解决"},{"content":"环境 RedHat Linux 9 + VWWare 8.0 + SSH 3.2.9 + Putty 0.62 + MySQL 3.2   问题 Linux下Java连接Mysql出现“ClassNotFoundException:com.mysql.jdbc.Driver”错误   解决 1.      把驱动文件放在这个文件夹里   $JAVA_HOME//jre/lib/ext/mysql-connector-java-5.1.19-bin.jar   2. 编辑/etc/profile文件       参考资料   Linux下jdbc连接mysql http://blog.csdn.net/laxsong/article/details/570722     linux下java连接mysql运行时报ClassNotFoundException:com.mysql.jdbc.Driver http://zhidao.baidu.com/question/211714663.html    ","title":"Linux下Java连接Mysql 出现“ClassNotFoundException:com.mysql.jdbc.Driver”"},{"content":"环境 RedHat Linux 9 + VWWare 8.0 + SSH 3.2.9 + Putty 0.62 + MySQL 3.2   一、查看软件安装路径：   whereis mysqlmysql: /usr/bin/mysql /usr/lib/mysql /usr/include/mysql /usr/share/mysql /usr/share/man/man1/mysql.1.gz     二、查询运行文件所在路径：   which mysql/usr/bin/mysql       总结   1.查看软件安装路径：whereis 软件名 2.查询运行文件所在路径：which 软件名    ","title":"Linux查找软件安装路径"},{"content":"1 RCS: 版本控制系统 RCS (Revision Control System) 是现存的最古老的 UNIX 应用程序之一。如果您把文件 /etc/rsyslog.conf 置于 RCS 的控制之下，那么 RCS 会将它的各个版本保存在 /etc/rsyslog.conf,v 里。 为了减少混乱，RCS 在和原来文件相同的目录下寻找一个叫做 RCS 的目录。如果有这个目录，RCS 就把 ,v 文件放在那个目录里，这样一来，列出的目录内容就会变得清楚多了，因为许多文件都可以共享 RCS 目录。这是一种很棒的功能，而且也是我们极力推荐的一种做法。您确实需要知道的 RCS 命令只有几个: ci 用于检入, co 用于检出，而 rcs 执行各种维护工作。如果您使用的编辑器是 emacs, 那么就完全不必使用命令行工具了，因为 emacs 内置了对 RCS 的支持。 要让一个文件开始处于 RCS 的跟踪之下，可以像下面这样在这个文件上运行 ci: $ ci -u filename RCS/filename,v <-- filenameenter description, terminated with single '.' or end of file:NOTE: This is NOT the log message!>> This is the orgmode file. -u 标志让 ci 立即以一种未上锁（不可编辑）的状态检出 filename 文件。如果您省略了这个标记，那么 ci 就会梌这个文件，然后删除原来的副本，这或许并不是您想要的做法。 您每次想要改变一个受 RCS 控制的文件时，都必须检出它，并用 co -l 命令对它上锁： $ co -l filename 如果您使用 emacs, 那么就更方便了，只需打开受 RCS 控制的文件，然后 C-x v v 就可以实现文件检出和上锁。当你对所做的修改感到满意时就可以使用 ci -u 命令将它签入，这时 RCS 会要求你提供一条注释，说明您刚才做的是什么。虽然人们倾向于路过这步，或者写些诸如“做了一次修改”这样的无用信息，但是应该坚持加注释这个习惯。在两年以后，当您要弄清楚为什么要做改动的时候，有帮助的注释会救您一命。在 emacs 里面，当您写完注释后就可以使用 C-c C-c 将 frame 关掉同时签入 RCS。 $ ci -u filename RCS/filename,v <-- filenamenew revision: 1.2; previous revision: 1.2enter log message, terminated with single '.' or end of file:>> Started describe what I gonna do in this week>> .done 当您需要比较两个版本之间的差别的时候, rcsdiff 是一个非常好的帮手，它是一个能懂 RCS 的 diff 版本。 $ rcsdiff filename 但我会建议您使用 emacs 来做这件事，因为它的 Diff 模式相当地智能，能够将修改的地方高亮显示出来，利用 TAB, n 和 p 键能够在不相同处进行跳转, o 或者 RET 键能够轻松地打开源文件进行查看。 您可能还需要用 rlog 命令查看一下文件的版本历史信息： $ rlog filename 如果您想要看看文件在换到新文件之前的样子，可以用 co 的 -r 选项检出这个文件的 1.2 版，不过在做这事之前最好已经将最新的版本签入到 RCS 中，否则它会用老版本替换当前的 filename 文件： $ co -r1.2 filename 2 CVS: 并发版本系统 CVS (Concurrent Version System, 并发版本系统) 是目前在 UNIX 和 Linux 系统上使用最为广泛的版本控制系统。 CVS 背后的主要思想之一是项目文件（及其历史版本）都保存在一个中心位置。和在 RCS 系统中一样，您要签出要开始在上面工作的文件，然后做完修改之后把这些文件再次签入到代码库里。CVS 的优势在于，它没有“上锁”和“解锁”检出的概念，基于人可以同时检出并修改文件（“并发”由此得名）。 下面从用户的角度快速列举一下最重要的 CVS 命令。修改一个项目的第一步是登录到服务器，检出想要改动的模块。我们在这里要修改的模块叫做 sort: $ cvs -d :pserver:user@server:/path/to/repository login CVS password: <password> $ cvs -d :pserver:user@server:/path/to/repository co sort 其中 pserver 是联络代码库所用的访问方法，本例中的代码库是一个专用的 CVS 口令服务器. login 操作把口令与服务器的口令进行对照检查，并且保留口令的一个副本，供以后的交互使用. co 操作直接类似于 RCS 的同名命令。 现在可以进行 sort 目录在本地的副本，开始编辑文件。当您准备把文件再次签入 CVS 库的时候，不需要使用 -d 选项，因为 CVS 在子目录 sort/CVS 里留下了一份所有必须的本地信息。 $ cvs commit foo.c -m \"Added more efficient sort routine\" 如果您已经在模块的副本上工作了一段时间，想要用其他人自从您检出该文件后已经对它做的修改来刷新本地副本，可以使用 cvs update 命令. -d 选项的意思是要包括所有的子目录，而 -P 选项则要求 CVS 删除任何空目录。 $ cvs update -dP 3 Subversion: 做得好的 CVS 虽然 CVS 是当前占据主导的版本控制系统，但是我们建议系统管理员从 RCS 直接跳到 Subversion。这个软件包的官方网址是 http://subversion.tigris.org/，不过现在已经在使用新的网址 http://subversion.apache.org/ 了。因为 Subversion 所使用的 License 就是 Apache License。 接下来我将要在我的 ubuntu 12.04 系统上安装并配置 subversion，虽然我所选用的发行版本是 ubuntu 但是我相信其中的绝大部分内容和操作都应该同样适用于其他的发行版本，甚至同样是 ubuntu 的其他时期的发行版。 首先，安装所需要的软件包： $ sudo apt-get install subversion $ sudo apt-get install libapache2-svn 稍等片刻，安装好软件之后就开始对其进行配置。这时候需要先创建一个 SVN 仓库（Repository），许多位置都可以放置 Subversion 文件仓库，我选用的位置是 /home/svn, 因为这是我的一个空间非常大的硬盘，足足 1 TB 的说。:) $ sudo mkdir /home/svn $ cd /home/svn $ sudo svnadmin create softplayer $ sudo chown -R www-data:www-data softplayer 其中的 www-data 是 apache2 默认的用户和组，我将使用 http 的方式对 Subversion 文件仓库进行访问，所以我将 softplayer 这个 Subversion 仓库的属主和属组都修改成 www-data, 如果不修改的话，会出现提交不了文件的错误，没权限呀，你懂的！ 接下来，创建 /etc/subversion/passwd 文件，该文件包含了能够使用 Subversion 文件仓库的用户的授权信息。 $ sudo htpasswd -c /etc/subversion/passwd user_name 上面的 user_name 需要根据您实际的情况来进行分配，比如是 david 或者 john 等用户. -c 选项表示创建新的 /etc/subversion/passwd 文件，所以 user_name 所指的用户将是文件中唯一的用户。如果要添加其他用户，则去掉 -c 选项即可，比如像下面的命令一样： $ sudo htpasswd /etc/subversion/passwd another_name Subversion 文件仓库的访问分为以下几种： mode access file:// 直接访问本地硬盘上文件仓库 http:// 通过 WebDAV 协议访问支持 Subversion 的 Apache2 Web 服务器 https:// 类似 http:// 支持 SSL 加密 svn:// 通过自带协议访问 svnserve 服务器 svn+ssh:// 类似 svn:// 支持通过 SSH 通道 要通过 WebDAV 协议访问 SVN 文件仓库，还必须配置一下 Apache2 Web 服务器。在 /etc/apache2/mods-available/dav_svn.conf 文件中写入以下代码: <Location /svn>DAV svnSVNParentPath /home/svnAuthType BasicAuthName \"subversion repository\"AuthUserFile /etc/subversion/passwd  #<LimitExcept GET PROPFIND OPTIONS REPORT>    Require valid-user  #<\/LimitExcept> <\/Location> 如果需要用户每次登录时都进行用户密码验证，请将 <LimitExcept GET PROPFIND OPTIONS REPORT> 与 <\/LimitExcept> 两行注释掉。 当您添加了上面的内容，您必须重新起动 Apache 2 Web 服务器，请输入下面的命令： $ sudo /etc/init.d/apache2 restart 好的，这时就可以尝试着使用浏览器打开 http://localhost/svn/softplayer 这个地址啦，能够正常打开，perfect. 里面是空的，当然啦，还没有导入数据进去嘛！ 接着就是将数据 import 到 Subversion 仓库啦： $ svn import /path/data http://localhost/svn/softplayer -m \"Initial import.\" 导入成功之后，刷新浏览器，同时也可以在浏览器上看到所做的更新！ 接下来的工作就是将 Subversion 仓库中的文件 checkout 出来，修改或删除，再 commit 回去： $ svn co http://localhost/svn/softplayer SoftPlayerBeta --username david 我使用刚才 htpasswd 命令创建的 david 用户名 checkout softplayer 到 SoftPlayerBeta 文件夹中，此时会提示输入密码。如果遇到 Password for ‘(null)’ GNOME keyring: 问题的时候可以直接 $ rm ~/.gnome2/keyrings/login.keyring 原因是 svn 和 gnome 的一个 key 冲突了。 这时进入 SoftPlayerBeta 文件夹中，修改其中的文件，比如说 foo.c 文件，成功修改后，直接 $ svn ci foo.c -m \"Making a testing comment.\" 就可以将修改提交到 Subverion 库里。也可以使用 svn add filename.ext 或者 svn del filename.ext 添加到库里或者从库中删除 filename.ext 文件，更多 svn 命令的使用可以在命令行中输出 svn help 进行查看。 但是说实在话，直接通过命令来操作 svn 的情况还是比较少见的，更多时候，是通过集成到开发环境中的版本控制管理插件来对文件的版本进行操作，如果您使用 emacs 那么在 Tools 菜单中就已经提供了 Version Control 的菜单项，方便对受版本控制器管理的文件进行操作；如果是使用 eclipse 来进行开发，那么在 eclipse 世界里就已经有非常方便实用的 subclipse 插件来对操作 Subverion，并且还是 GUI 界面的，非常地棒！ 更多关于 Subversion 的信息可以参考以下的网址： http://subversion.tigris.org/ http://subversion.apache.org/ Subversion 源代码 Subversion 官方文档 SubVersion服务安装设置 SubVersion服务安装设置(另一个简短版本) 安装 subversion 指南","title":"Linux 学习笔记（十一S）版本控制"},{"content":"我是一名电子信息专业的本科毕业生，毕业后就一直在做嵌入式软件开发的这条路，可以说，现在的工作跟我毕业之前所想要从事的工作是一致的，从这点来说，我还是有计划的一个人。            刚开始是做51单片机的，后来又接着做nxp的单片，现在是做ARM11。软件平台也换到了linux从这里来看，工作的技术含量是越来越高，这点还是很肯定我这一年来的工作。可是让自己很苦恼的事情就是关于薪资的问题。从网上的消息或者是调查来看，嵌入式软件开发无疑是当前工资最多的工作，周围的朋友和同事也是这样子认为的，可是自己的工资却不是这样，跟网上炒作的高工资差别很大。这个很打击我的工作热情，也让自己对从事技术开发这条路产生了动摇。我该不该继续走下去，继续从事软件开发的工作，还是换到别的行业，比如说工业控制领域。           还有一个疑问，嵌入式行业真的很赚钱？工资真的很高吗？网页上面说的高工资是不是只是针对那些所谓的什么专家的人来说的呢？我们实际上从事这个行业的工作的人，都没有体会到有高工资的甜头啊。现在做的工作还不如那些毕业后去从事别的行业的工作的同学过得滋润，他们进去了供电局，有的去考了公务员，从事的工作完成跟我们的专业无关。可是他们的日子却过得比我们这些所谓的从事高技术含量的工作的人的日子要好。           这种现实真的很打击人的工作积极性。","title":"工作一年的感受，电子专业"},{"content":"Books: Core kernel programming books: 1. Linux device drivers by Rubini, Greg kroah hartman and Jim Corbett: Third edition if you really want to learn Kernel programming, this is your book. Its a MUST BUY book. Probably most questions will be answered somewhere in this one. 2. Linux kernel Development by Robert Love third edition. Again, this is a highly recommended textbook. It gives you working details of kernel in fairly simple language. 3. Understanding Linux Kernel by Bovet and Cessati This is an advance book, this is intended for more serious coding. Its recommended that you get yourself a bit familiar with x86 arch to use this book to fullest. 4.Essential Linux device drivers by Sreekrishnan Venkateswaran This book is a good book in addition to classic text, its well written and simpler in nature, highly recommended. C language programming books: 1. The C programming language by Kerninghan and Ritchie. Its a must-have book, most code in Kernel is written in C language and mastering C is important and there is nothing better than KnR for this job. 2. Practical C programming by By Steve Oualline Good book for developing a good coding style in C language 3. C traps and pitfalls by Andrew koeing A book which talks about limitations and issues with C programming, a very helpful textbook to understand where you can make mistakes. 4. Expert C programming: deep C secrets by Peter V Linden A very good books, which teaches a lot of nuances of C language. 5. The C programming Manual by Harbison and Steele This book ventures deep into the C programming language mostly details of standards and changes in C, its quite advance in nature. Some preliminary books: You may need to get yourself familiar with a lot of extra stuff, which may be needed: 1. Advance 80836 programming techniques by Jim Turley: A good book which gives details about x86 arch, this book will make you ready to use ULK as previously pointed out. 2. The art of assembly programming: A good book to learn some assembly language, which may be required if you want to dig into some architecture related code. 3. Design of Unix operating system by Maurice J bach: Classic text on how unix operating system is designed, its a good text to understand the principles behind a lot of subsystems in operating system. 4. Beginning Linux programming by Richard Stones and Neil Matthews its always a good idea to learn more about user space programming, before you dive in kernel. Mostly for two reasons: a) Get familiar with facilities provided by operating systems b) Get your hands on some coding. This book is highly recommended text for user space. links: 1. http://www.Linux.com/ Home page of everything related to Linux, you may find a lot of useful articles there. 2. http://www.Linux-magazine.com/ This magazine have a lot of general information about Linux, its not highly directly related to kernel but a very useful resource. 3. http://lwn.net/ One of the most respected site, its maintained by one of the most senior developer of the kernel. It has a lot of useful article related to the Linux kernel. 4.http://kerneltrap.org/ This site host the digests of hottest topic on Linux kernel mailing list. Its again a very useful site to look for what is going on in much simpler way. 5. http://sourceforge.net If you want to participate in some project, this is the place to begin. There are lot of projects hosted on this site, some of them are related to kernel and/or device drivers.Most of those projects are in need of developers, so if you have skills, you can participate. 6. http://tldp.org/ The famous Linux documentation project, this will help you with a lot of HOWTo for everything related to Linux, including kernel. 7. http://crashcourse.ca/ This is a very good site, which is quite up-to-date. This site have very good kernel programming tutorials for beginner. Linux Kernel Development by Robert Love  O'Reilly'sUnderstanding The Linux Kernel.   Linux Device Drivers and  Essential Linux Device Drivers. ","title":"Linux内核学习相关资料"},{"content":"【IT168 技术】　　一个进程，包括代码、数据和分配给进程的资源。fork()函数通过系统调用创建一个与原来进程几乎完全相同的进程，也就是两个进程可以做完全相同的事，但如果初始参数或者传入的变量不同，两个进程也可以做不同的事。 　　一个进程调用fork()函数后，系统先给新的进程分配资源，例如存储数据和代码的空间。然后把原来的进程的所有值都复制到新的新进程中，只有少数值与原来的进程的值不同。相当于克隆了一个自己。 　　我们来看一个例子： 　　[cpp] view plaincopy 　　/* 　　* fork_test.c 　　* version 1 　　* Created on: 2010-5-29 　　* Author: wangth 　　*/ 　　#include 　　#include 　　int main () 　　{ 　　pid_t fpid; //fpid表示fork函数返回的值 　　int count=0; 　　fpid=fork(); 　　if (fpid < 0) 　　printf(\"error in fork!\"); 　　else if (fpid == 0) { 　　printf(\"i am the child process, my process id is %d/n\",getpid()); 　　printf(\"我是爹的儿子/n\");//对某些人来说中文看着更直白。 　　count++; 　　} 　　else { 　　printf(\"i am the parent process, my process id is %d/n\",getpid()); 　　printf(\"我是孩子他爹/n\"); 　　count++; 　　} 　　printf(\"统计结果是： %d/n\",count); 　　return 0; 　　} 　　运行结果是： 　　i am the child process, my process id is 5574 　　我是爹的儿子 　　统计结果是： 1 　　i am the parent process, my process id is 5573 　　我是孩子他爹 　　统计结果是： 1 　　在语句fpid=fork()之前，只有一个进程在执行这段代码，但在这条语句之后，就变成两个进程在执行了，这两个进程的几乎完全相同，将要执行的下一条语句都是if(fpid<0)…… 　　为什么两个进程的fpid不同呢，这与fork函数的特性有关。fork调用的一个奇妙之处就是它仅仅被调用一次，却能够返回两次，它可能有三种不同的返回值： 　　1)在父进程中，fork返回新创建子进程的进程ID; 　　2)在子进程中，fork返回0; 　　3)如果出现错误，fork返回一个负值; 　　在fork函数执行完毕后，如果创建新进程成功，则出现两个进程，一个是子进程，一个是父进程。在子进程中，fork函数返回0，在父进程中，fork返回新创建子进程的进程ID。我们可以通过fork返回的值来判断当前进程是子进程还是父进程。 　　引用一位网友的话来解释fpid的值为什么在父子进程中不同。“其实就相当于链表，进程形成了链表，父进程的fpid(p 意味point)指向子进程的进程id, 因为子进程没有子进程，所以其fpid为0. 　　fork出错可能有两种原因： 　　1)当前的进程数已经达到了系统规定的上限，这时errno的值被设置为EAGAIN。 　　2)系统内存不足，这时errno的值被设置为ENOMEM。 　　创建新进程成功后，系统中出现两个基本完全相同的进程，这两个进程执行没有固定的先后顺序，哪个进程先执行要看系统的进程调度策略。 　　每个进程都有一个独特(互不相同)的进程标识符(process ID)，可以通过getpid()函数获得，还有一个记录父进程pid的变量，可以通过getppid()函数获得变量的值。 　　fork执行完毕后，出现两个进程， 　　有人说两个进程的内容完全一样啊，怎么打印的结果不一样啊，那是因为判断条件的原因，上面列举的只是进程的代码和指令，还有变量啊。 　　执行完fork后，进程1的变量为count=0，fpid!=0(父进程)。进程2的变量为count=0，fpid=0(子进程)，这两个进程的变量都是独立的，存在不同的地址中，不是共用的，这点要注意。可以说，我们就是通过fpid来识别和操作父子进程的。iude 　　还有人可能疑惑为什么不是从#include处开始复制代码的，这是因为fork是把进程当前的情况拷贝一份，执行fork时，进程已经执行完了int count=0;fork只拷贝下一个要执行的代码到新的进程。(自己添加：因为FORK是复制产生一个新的进程，因此新的进程与旧的的进程之间的上下文，如寄存器上下文等是一致的，也就是说两个进程的变量值，PC指针值也是一样的，因此两个进程都是在同一个位置开始运行) 　　二、fork进阶知识 　　先看一份代码： 　　[cpp] view plaincopy 　　/* 　　* fork_test.c 　　* version 2 　　* Created on: 2010-5-29 　　* Author: wangth 　　*/ 　　#include 　　#include 　　int main(void) 　　{ 　　int i=0; 　　printf(\"i son/pa ppid pid fpid/n\"); 　　//ppid指当前进程的父进程pid 　　//pid指当前进程的pid, 　　//fpid指fork返回给当前进程的值 　　for(i=0;i<2;i++){ 　　pid_t fpid=fork(); 　　if(fpid==0) 　　printf(\"%d child %4d %4d %4d/n\",i,getppid()，getpid()，fpid); 　　else 　　printf(\"%d parent %4d %4d %4d/n\",i,getppid()，getpid()，fpid); 　　} 　　return 0; 　　} 　　运行结果是： 　　i son/pa ppid pid fpid 　　0 parent 2043 3224 3225 　　0 child 3224 3225 0 　　1 parent 2043 3224 3226 　　1 parent 3224 3225 3227 　　1 child 1 3227 0 　　1 child 1 3226 0 　　这份代码比较有意思，我们来认真分析一下： 　　第一步：在父进程中，指令执行到for循环中，i=0，接着执行fork，fork执行完后，系统中出现两个进程，分别是p3224和p3225(后面我都用 pxxxx表示进程id为xxxx的进程)。可以看到父进程p3224的父进程是p2043，子进程p3225的父进程正好是p3224。我们用一个链表来表示这个关系： 　　p2043->p3224->p3225 　　第一次fork后，p3224(父进程)的变量为i=0，fpid=3225(fork函数在父进程中返向子进程id)，代码内容为： 　　[c-sharp] view plaincopy 　　for(i=0;i<2;i++){ 　　pid_t fpid=fork();//执行完毕，i=0，fpid=3225 　　if(fpid==0) 　　printf(\"%d child %4d %4d %4d/n\",i,getppid()，getpid()，fpid); 　　else 　　printf(\"%d parent %4d %4d %4d/n\",i,getppid()，getpid()，fpid); 　　} 　　return 0; 　　p3225(子进程)的变量为i=0，fpid=0(fork函数在子进程中返回0)，代码内容为： 　　[c-sharp] view plaincopy 　　for(i=0;i<2;i++){ 　　pid_t fpid=fork();//执行完毕，i=0，fpid=0 　　if(fpid==0) 　　printf(\"%d child %4d %4d %4d/n\",i,getppid()，getpid()，fpid); 　　else 　　printf(\"%d parent %4d %4d %4d/n\",i,getppid()，getpid()，fpid); 　　} 　　return 0; 　　所以打印出结果： 　　0 parent 2043 3224 3225 　　0 child 3224 3225 0 　　第二步：假设父进程p3224先执行，当进入下一个循环时，i=1，接着执行fork，系统中又新增一个进程p3226，对于此时的父进程，p2043->p3224(当前进程)->p3226(被创建的子进程)。 　　对于子进程p3225，执行完第一次循环后，i=1，接着执行fork，系统中新增一个进程p3227，对于此进程，p3224->p3225(当前进程)->p3227(被创建的子进程)。从输出可以看到p3225原来是p3224的子进程，现在变成p3227的父进程。父子是相对的，这个大家应该容易理解。只要当前进程执行了fork，该进程就变成了父进程了，就打印出了parent。   摘自：http://os.chinaunix.net/a2012/0203/1306/000001306508.shtml","title":"linux中fork（）函数详解"},{"content":"【IT168 技术】　　#include ; 　　#include ; 　　main () 　　{ 　　pid_t pid; 　　pid=fork(); 　　if (pid < 0) 　　printf(\"error in fork!\"); 　　else if (pid == 0) 　　printf(\"i am the child process, my process id is %dn\",getpid()); 　　else 　　printf(\"i am the parent process, my process id is %dn\",getpid()); 　　} 　　结果是 　　[root@localhost c]# ./a.out 　　i am the child process, my process id is 4286 　　i am the parent process, my process id is 4285 　　我就想不到为什么两行都打印出来了，在我想来，不管pid是多少，都应该只有一行才对 　　chg.s 回复于：2004-04-27 21:09:30 　　要搞清楚fork的执行过程，就必须先讲清楚操作系统中的“进程(process)”概念。一个进程，主要包含三个元素： 　　o. 一个可以执行的程序; 　　o. 和该进程相关联的全部数据(包括变量，内存空间，缓冲区等等); 　　o. 程序的执行上下文(execution context)。 　　不妨简单理解为，一个进程表示的，就是一个可执行程序的一次执行过程中的一个状态。操作系统对进程的管理，典型的情况，是通过进程表完成的。进程表中的每一个表项，记录的是当前操作系统中一个进程的情况。对于单 CPU的情况而言，每一特定时刻只有一个进程占用 CPU，但是系统中可能同时存在多个活动的(等待执行或继续执行的)进程。 　　一个称为“程序计数器(program counter, pc)”的寄存器，指出当前占用 CPU的进程要执行的下一条指令的位置。 　　当分给某个进程的 CPU时间已经用完，操作系统将该进程相关的寄存器的值，保存到该进程在进程表中对应的表项里面;把将要接替这个进程占用 CPU的那个进程的上下文，从进程表中读出，并更新相应的寄存器(这个过程称为“上下文交换(process context switch)”，实际的上下文交换需要涉及到更多的数据，那和fork无关，不再多说，主要要记住程序寄存器pc指出程序当前已经执行到哪里，是进程上下文的重要内容，换出 CPU的进程要保存这个寄存器的值，换入CPU的进程，也要根据进程表中保存的本进程执行上下文信息，更新这个寄存器)。 　　好了，有这些概念打底，可以说fork了。当你的程序执行到下面的语句： 　　pid=fork(); 　　操作系统创建一个新的进程(子进程)，并且在进程表中相应为它建立一个新的表项。新进程和原有进程的可执行程序是同一个程序;上下文和数据，绝大部分就是原进程(父进程)的拷贝，但它们是两个相互独立的进程!此时程序寄存器pc，在父、子进程的上下文中都声称，这个进程目前执行到fork调用即将返回(此时子进程不占有CPU，子进程的pc不是真正保存在寄存器中，而是作为进程上下文保存在进程表中的对应表项内)。问题是怎么返回，在父子进程中就分道扬镳。 　　父进程继续执行，操作系统对fork的实现，使这个调用在父进程中返回刚刚创建的子进程的pid(一个正整数)，所以下面的if语句中pid<0, pid==0的两个分支都不会执行。所以输出i am the parent process… 　　子进程在之后的某个时候得到调度，它的上下文被换入，占据 CPU，操作系统对fork的实现，使得子进程中fork调用返回0。所以在这个进程(注意这不是父进程了哦，虽然是同一个程序，但是这是同一个程序的另外一次执行，在操作系统中这次执行是由另外一个进程表示的，从执行的角度说和父进程相互独立)中pid=0。这个进程继续执行的过程中，if语句中 pid<0不满足，但是pid==0是true。所以输出i am the child process… 　　我想你比较困惑的就是，为什么看上去程序中互斥的两个分支都被执行了。在一个程序的一次执行中，这当然是不可能的;但是你看到的两行输出是来自两个进程，这两个进程来自同一个程序的两次执行。 　　我的天，不知道说明白了没…… 　　zhaojinbo 回复于：2004-04-28 12:35:50 　　fork 之后，操作系统会复制一个与父进程完全相同的子进程，虽说是父子关系，但是在操作系统看来，他们更像兄弟关系，这2个进程共享代码空间，但是数据空间是互相独立的，子进程数据空间中的内容是父进程的完整拷贝，指令指针也完全相同，但只有一点不同，如果fork成功，子进程中 fork的返回值是0，父进程中fork的返回值是子进程的进程号，如果fork不成功，父进程会返回错误。 　　可以这样想象，2个进程一直同时运行，而且步调一致，在fork之后，他们分别作不同的工作，也就是分岔了。这也是fork为什么叫fork的原因。 　　至于那一个最先运行，可能与操作系统有关，而且这个问题在实际应用中并不重要，如果需要父子进程协同，可以通过原语的办法解决。 　　sniper 回复于：2004-04-28 22:11:15 　　哦，偶明白了，在程序段里用了fork();之后程序出了分岔，派生出了两个进程。具体哪个先运行就看该系统的调度算法了。 　　在这里，我们可以这么认为，在运行到\"pid=fork();\"时系统派生出一个跟主程序一模一样的子进程。该进程的\"pid=fork();\"一句中pid得到的就是子进程本身的 pid;子进程结束后，父进程的\"pid=fork();\"中pid得到的就是父进程本身的pid。因此改程序有两行输出。 　　注：此处不准确，在子进程中pid的值为0，通过getpid可以获取子进程的进程id;在父进程中pid为父进程编号。 　　勘误：父进程中的pid值为子进程进程号，只有父进程执行的getpid()才是他自己的进程号。寒，彻底的in了 　　jjl3 回复于：2004-07-14 11:43:20 　　我做如下修改 　　#include ; 　　#include ; 　　main () 　　{ 　　pid_t pid; 　　printf(\"fork!\"); // printf(\"fork!n\"); 　　pid=fork(); 　　if (pid < 0) 　　printf(\"error in fork!\"); 　　else if (pid == 0) 　　printf(\"i am the child process, my process id is %dn\",getpid()); 　　else 　　printf(\"i am the parent process, my process id is %dn\",getpid()); 　　} 　　结果是 　　[root@localhost c]# ./a.out 　　fork!i am the child process, my process id is 4286 　　fork!i am the parent process, my process id is 4285 　　但我改成printf(\"fork!n\");后，结果是 　　[root@localhost c]# ./a.out 　　fork! 　　i am the child process, my process id is 4286 　　i am the parent process, my process id is 4285 　　为什么只有一个fork!打印出来了?上一个为什么有2个? 　　bashfulboy 回复于：2004-07-14 22:10:52 　　我也来一下： 　　wujiajia 的理解有些错误， 　　printf(\"AAAAAAAA\");//print 一次; 这里会print 2次 　　如果你将 printf(\"AAAAAA\") 换成 printf(\"AAAAAAn\") 那么就是只打印一次了。 　　主要的区别是因为有了一个 n 回车符号 　　这就跟Printf的缓冲机制有关了，printf某些内容时，操作系统仅仅是把该内容放到了stdout的缓冲队列里了，并没有实际的写到屏幕上 　　但是，只要看到有 n 则会立即刷新stdout,因此就马上能够打印了。 　　运行了printf(\"AAAAAA\") 后， AAAAAA 仅仅被放到了缓冲里，再运行到fork时，缓冲里面的 AAAAAA 被子进程继承了 　　因此在子进程度stdout缓冲里面就也有了 AAAAAA. 　　所以，你最终看到的会是 AAAAAA 被printf了2次!!!! 　　而运行 printf(\"AAAAAAn\")后， AAAAAA 被立即打印到了屏幕上，之后fork到的子进程里的stdout缓冲里不会有 AAAAAA 内容 　　因此你看到的结果会是 AAAAAA 被printf了1次!!!! 　　(精要) 　　albcamus 回复于：2005-03-08 15:56:11 　　>;>;派生子进程的pid变量并没有被改变是什么意思 对于子进程来讲pid不就是0吗 　　1,派生子进程的进程，即父进程，其pid不变; 　　2,对子进程来说，fork返回给它0,但它的pid绝对不会是0;之所以fork返回0给它，是因为它随时可以调用getpid()来获取自己的pid; 　　3,楼上的楼上的你的观点是对的，fork之后夫子进程除非采用了同步手段，否则不能确定谁先运行，也不能确定谁先结束。认为子进程结束后父进程才从fork返回的，这是不对的，fork不是这样的，vfork才这样。VFORK调用结束后，父进程处于非可中断状态，直到子进程运行结束返回。   摘自：http://os.chinaunix.net/a2012/0203/1306/000001306511.shtml","title":"linux fork函数的精辟解说"},{"content":"From:http://www.ibm.com/developerworks/cn/linux/i18n/unicode/linuni/ Unicode 并不只是一个编程工具，它还是一个政治的、经济的工具。没有结合世界的语言支持的应用程序通常只能被那些能读写 ASCII 所支持语言的个人使用。这使得建立在 ASCII 基础之上的计算机技术脱离了世界上大部分人。Unicode 允许程序使用世界上任何一种字符集，因此它支持所有语言。 Unicode 让程序员为普通人提供用他们本国语言就能使用的软件。这样就不用再学一门外语了，而且更容易实现计算机技术社会和财政上的利益。很容易设想，如果用户必须为使用因特网浏览器而学习乌尔都语的话， 您就难以看到计算机在美国的使用。Web 就更不会出现了。 Linux 承担了对 Unicode 很大程度上的支持。Unicode 支持被嵌入到内核和代码开发库中。在很大程度上，使用程序中几句简单的命令就能将它们自动的结合到代码中。 所有现代字符集的基础都是在 1968 年以 ANSIX3.4 版本出版的美国信息交换标准码（American Standard Code for Information Interchange，ASCII）。一个值得注意的例外是在 ASCII 之前定义的 IBM 的扩充的二进制编码的十进制交换码（Extended Binary Coded Decimal Information Code，EBCDIC）。ASCII 是一个编码字符集（coded character set，CCS），换句话说，它是整数到字符表示的映射。ASCII 编码字符集允许用一个八位（基于二进制的，用值 0 或 1 表示的）字段或字节（2^8 =256）表示 256 个字符。 这是一个高度受限的编码字符集，它不能表示许多不同语言的所有字符（如中文和日文），不能表示科学符号，更不能表示古代文字（神秘符号和象形文字）和音乐符号。通过更改一个字节的长度而使更大的字符集得以被编码，这似乎有效但完全不切实际。所有的计算机都基于八位字节。解决方法是一种字符编码方案（Character encoding scheme，CES）― 用定长或变长的多字节序列能够表示比 256 大的数.这些数值接着通过编码字符集被映射到它们表示的字符。 Unicode 的定义 Unicode 通常用作涉及双字节字符编码方案的通用术语。Unicode CCS 3.1 的官方称谓是 ISO10646-1 通用多八字节编码字符集（Universal Multiple Octet Coded Character Set，UCS）。Unicode 3.1 版本添加了 44,946 个新的编码字符。算上 Unicode 3.0 版本已经存在的 49,194 个字符，共计 94,140 个。 Unicode 编码字符集利用了一个由 128 个三维的组构成的四维编码空间。其中每个组包含 256 个二维平面。每个平面由 256 个一维的行组成，并且每个行有 256 个单元。每个单元在这个编码空间内对一个字符编码，或者被声明为未经使用。这种编码概念被称为 UCS-4；四个八位元用来表示指定组、平面、行和单元的每个字符。 第一个平面（第 00 组的第 00 平面）是基本多语言平面（Basic Multilingual Plane，BMP）。BMP 按字母、音节、表意符号和各种符号及数字定义了常规使用的字符。后续的平面用于附加字符或其它还没有发明的编码实体。我们需要这完整的范围去处理世界上的所有语言；特别是拥有将近 64,000 个字符的一些东亚语言。 BMP 被用作双字节的编码字符集，这种编码字符集确定为 ISO 10646 UCS-2 格式。ISO 10646 UCS-2 就是指 Unicode（并且两者相同）。BMP，像所有 UCS 平面那样，包含了 256 行，其中每行包含 256 个单元，字符仅仅按照 BMP 中的行和单元的八位元在单元中被编码。 这就允许 16 位编码字符能够被用来书写大多数商业上最重要的语言。UCS-2 不需要代码页切换、代码扩展或代码状态。UCS-2 是一种将 Unicode 结合到软件中的简单方法，但它只限于支持 Unicode BMP。 若要用 8 位字节表示一个多于 2^8 =256 个字符的字符编码系统（character coding system，CCS），就需要一种字符编码方案(character-encoding scheme，CES）。 回页首 Unicode 转换 在 UNIX 中，使用得最多的字符编码方案是 UTF-8。 它考虑到了对整个 Unicode 全部页和平面的全面支持，而且它仍能正确的识别 ASCII。除了 UTF-8 的其他选择还有：UCS-4、UTF-16、UTF-7.5、UTF-7、SCSU、HTML 和 JAVA。 Unicode 转换格式（Unicode Transformation Formats，UTFs）是一种通过映射多字节编码中的值来支持 Unicode 的字符编码方案。本文将分析最流行的格式 ― UTF-8 字符编码系统。 UTF-8 UTF-8 转换格式正逐步成为一种占主导地位的交换国际文本信息的方法，因为它可以支持世界上所有的语言，而且它还与 ASCII 兼容。UTF-8 使用变长编码。从 0 到 0x7f（127）的字符把自身编码成单字节，而将值更大的字符编码成 2 到 6 个字节。 表 1. UTF-8 编码 0x00000000 - 0x0000007F:   0 xxxxxxx 0x00000080 - 0x000007FF:   110 xxxxx10 xxxxxx 0x00000800 - 0x0000FFFF:   1110 xxxx10 xxxxxx10 xxxxxx 0x00010000 - 0x001FFFFF:   11110 xxx10 xxxxxx10 xxxxxx 10 xxxxxx 0x00200000 - 0x03FFFFFF:   111110 xx10 xxxxxx10 xxxxxx10 xxxxxx 10 xxxxxx 0x04000000 - 0x7FFFFFFF:   1111110 x10 xxxxxx10 xxxxxx10 xxxxxx 10 xxxxxx10 xxxxxx 字节 10 xxxxxx是一个扩展字节，它的 xxxxxx 位位置被以二进制表示的字符代码号的位所填充。这是能够代表被使用代码的最短的可能的多字节序列。 UTF-8 编码示例 Unicode 字符版权标记字符 0xA9 = 1010 1001 用 UTF-8 编码如下所示： 11000010 10101001 = 0xC2 0xA9 “不等于”符号字符 0x2260 = 0010 0010 0110 0000 编码如下所示： 11100010 10001001 10100000 = 0xE2 0x89 0xA0 通过获取 continuation byte 的值可以看到原始数据： [1110]0010 [10]001001 [10]100000  0010 001001 100000  0010 0010 0110 0000 = 0x2260 第一个字节定义后面紧跟的八位元数，如果是 7F 或更小，这就是等价的 ASCII 值。每个八位字节以 10 xxxxxx 开头，确保字节不与 ASCII 的值混淆。 回页首 UTF 支持 在 Linux 平台上使用 UTF-8 之前，请确信分发包里有 glibc 2.2 和 XFree86 4.0 或更新的版本。早先的版本缺少 UTF-8 语言环境支持和 ISO10646-1 X11 字体。 在 UTF-8 发布之前，Linux 用户使用各种不同特定语言的扩展 ASCII，像欧洲用户用 ISO 8859-1 或 ISO 8859-2，希腊用户使用 ISO 8859-7，俄罗斯用户使用 KOI-8 / ISO 8859-5/CP1251（西里尔字母）。这使得数据交换出现了很多问题，并且需要为这些编码之间的差异编写应用软件。这种语言支持是不完善的，而且数据交换没有经过测试。Linux 主要的发行商和应用程序开发者正致力于让主要以 UTF-8 格式表示的 Unicode 成为 Linux 中的标准。 为了识别 Unicode 文件，Microsoft 建议所有的 Unicode 文件应该以 ZERO WIDTH NOBREAK SPACE（U+FEFF）字符开头。这作为一个“特征符”或“字节顺序标记（byte-order mark，BOM）”来识别文件中使用的编码和字节顺序。但是，Linux/UNIX 并没有使用 BOM，因为它会破坏现有的 ASCII 文件的语法约定。在 POSIX 系统中，选中的语言环境识别了在一个过程中的所有输入输出文件期望的编码形式。 有两种方法可以将 UTF-8 支持添加到 Linux 应用程序中。第一种方法，数据都以 UTF-8 形式存放在各处，这样软件改动很少（被动的）。另一种方法，被读取的 UTF-8 数据用标准的 C 语言库函数转变成为宽字符数组（转换的）。在输出时，用函数 wcsrtombs()使字符串被转变回 UTF-8： 清单 1. wcsrtombs() #include <wchar.h> size_t wcsrtombs (char *dest, const wchar_t **src, size_t len, mbstate_t *ps); 方法的选择取决于应用程序的性质。大多数应用程序可以使用被动的方法操作。这就是在 UNIX 平台上使用 UTF-8 会如此流行的原因。像 cat 和 echo 那样的程序就不需要修改。字节流仍只是字节流，并没有对它进行任何处理。ASCII 字符和控制代码在 UTF-8 语言环境中不改变。 通过字节计数对字符进行计数的程序需要一些小小的改动。在 UTF-8 中应用程序不对任何扩展的字节进行计数。如果选择了 UTF-8 语言环境，C 语言库的 strlen(s) 函数需要用 mbstowcs() 函数来代替： 清单 2. mbstowcs() 函数 #include <stdlib.h>size_t mbstowcs(wchar_t *pwcs, const char *s, size_t n); strlen 的一种常见用法是估算显示宽度。中文和其它表意符号将占用两列位置。 wcwidth() 函数用来测试每个字符的显示宽度： 清单 3. wcwidth() 函数 #include <        wchar.h> int wcwidth(wchar_t wc);      回页首 Unicode 的 C 语言支持 在正式情况下，从 GNU glibc 2.2 开始，wchar_t 类型只为 32 位的 ISO 10646 格式数值所特定使用，与当前使用的语言环境无关。通过 ISO C99 所要求的 __STDC_ISO_10646__ 宏的定义作为信号通知应用程序。 __STDC_ISO_10646__ 的定义用来指出 wchar_t 是 Unicode。精确的值是一个十进制的 yyyymmL 格式的常数。例如，使用： 清单 4. 指出 wchar_t 是 Unicode #define __STDC_ISO_10646__ 200104L 是为指出 wchar_t 类型的值是由 ISO/IEC 10646 和到指定的年月为止的所有修正与技术勘误定义的字符编码表示。 对 wchar_t 的利用如这个示例所示，使用宏确定在 ISO C99 可移植代码中写双引号的方法。 清单 5. 确定写双引号的方法 #if __STDC_ISO_10646__     printf(\"%lc\", 0x201c);  #else     putchar('\"');  #fi 语言环境 激活 UTF-8 的恰当的办法是 POSIX 语言环境机制。语言环境是一种包含有关软件行为特定文化约定的配置设定。它包含了字符编码、日期／时间符号、分类规则以及度量系统。语言环境的名称通常由 ISO 639-1 语言、ISO 3166-1 国家或地区代码以及可选的编码名称和其它限定符组成。您可以用命令 locale -a 获取所有安装在系统上的语言环境列表（通常在 /usr/lib/locale/）。 如果没有预安装 UTF-8 语言环境，你可以用 localedef 命令生成它。若要为某个特定用户生成并激活一个德语的 UTF-8 语言环境，请使用如下语句： 清单 6. 为特定用户生成语言环境 localedef -v -c -i de_DE -f UTF-8 $HOME/local/locale/de_DE.UTF-8export LOCPATH=$HOME/local/localeexport LANG=de_DE.UTF-8 有时候为所有用户添加 UTF-8 语言环境会很有用。root 用户使用如下指令就可以完成： 清单 7. 为每个用户生成语言环境 localedef -v -c -i de_DE -f UTF-8 /usr/share/locale/de_DE.UTF-8 若要为每个用户将这个语言环境设为缺省值，可以将以下行添加到 /etc/profile 文件中： 清单 8. 为所有用户设置缺省的语言环境 export LANG=de_DE.UTF-8 处理多字节字符代码序列的函数行为依赖于当前语言环境的 LC_CTYPE 类别；它确定了依赖语言环境的多字节编码。值 LANG=de_DE（德语）会导致输出按 ISO 8859-1 被格式化。值 LANG=de_DE.UTF-8 会把输出格式化成 UTF-8。语言环境设置会导致 printf 中的 %ls 格式说明符调用 wcsrtombs() 函数以便于将宽字符的参数字符串转换成依赖语言环境的多字节编码。语言环境中的国家或地区标识符如：LC_CTYPE= en_GB （英国英语）和 LC_CTYPE= en_AU（澳大利亚英语），它们之间的差异只在 LC_MONETARY 类别中，原因在于货币的名称和打印货币数量的规则不同。 请给您首选的语言环境设置环境变量 LANG。当一个 C 程序执行 setlocale() 函数时： 清单 9. setlocale() 函数 #include <stdio.h>#include <locale.h>//char *setlocale(int category, const char *locale);int main(){  if (!setlocale(LC_CTYPE, \"\"))   {    fprintf(stderr, \"Locale not specified. Check LANG, LC_CTYPE, LC_ALL.\");    return 1;  } C 语言库将会依次测试环境变量 LC_ALL、LC_CTYPE 和 LANG。其中第一个含值的环境变量将决定为 LC_CTYPE 类别装入哪种语言环境数据。语言环境数据分裂成独立的类别。值 LC_CTYPE 定义了字符编码，而 LC_COLLATE 定义了排序顺序。我们用 LANG 环境变量为所有类别设置缺省语言环境，但 LC_* 变量可以用来覆盖单个类别。 您可以用命令 locale charmap 查询当前语言环境中字符编码的名称。如果您从 LC_CTYPE 类别中成功选取了 UTF-8 语言环境，会输出 UTF-8。命令 locale -m 提供一张已安装的所有字符编码名称的列表。 如果您使用专门的 C 语言库的多字节函数来完成所有外部字符编码和内部使用的 wchar_t 编码之间的转换，那么 C 语言库将承担责任，根据 LC_CTYPE 使用正确的编码方式。这甚至不需要程序被明确的编码成当前的多字节编码。 如果需要一个应用程序能明确的支持 UTF-8（或其它编码）转换方法而不用 libc 多字节函数，则应用程序必须确定是否需要激活 UTF-8 模式。带有 <langinfo.h> 库头文件的与 X/Open 兼容系统可以用如下代码： 清单 10. 检测当前的语言环境是否使用了 UTF-8 编码 BOOL utf8_mode = FALSE;if( !  strcmp(nl_langinfo(CODESET), \"UTF-8\")   utf8_mode = TRUE; 为检测当前语言环境是否使用了 UTF-8 编码。首先必须调用 setlocale(LC_CTYPE, \"\") 函数，依据环境变量设置语言环境。nl_langinfo(CODESET) 函数也是由 locale charmap 命令调用，从而查找当前语言环境指定的编码名称。 另一种可以使用的方法是查询语言环境变量： 清单 11. 查询语言环境变量 char *s;BOOL utf8_mode = FALSE;if ((s = getenv(\"LC_ALL\")) || (s = getenv(\"LC_CTYPE\")) || (s = getenv (\"LANG\"))) {   if (strstr(s, \"UTF-8\"))      utf8_mode = TRUE;} 这项测试假设 UTF-8 语言环境名称中有值“UTF-8”，但实际情况并不总是如此，所以应该使用 nl_langinfo() 方法。 回页首 总结 为支持世界上的所有语言，需要一种具有八位字节字符编码策略的字符编码系统，它的字符应多于 ASCII（一种使用无符号字节的扩展版本）的 2^8 = 256 个字符。Unicode 就是这样一种字符编码系统，它具有由 128 个三维组（带有由大量字符编码方案的方法支持的 94,140 个定义好的字符值）组成的四维编码空间，在 Linux 中更流行的字符编码方案是 Unicode 转换格式 UTF-8。 参考资料 您可以参阅本文在 developerWorks 全球站点上的 英文原文.  请访问 Unicode 联盟的 Unicode 主页，这里定义了 Unicode 字符之间的行为和关系，并为实现者提供了技术信息。  国际标准组织（International Organization for Standardization，ISO）是一个由 140 个国家组成的全球性的国家标准社团联盟。  ANSI 是个私有的、非营利组织，它管理并调整 U.S. 的志愿标准化以及一致性评价系统。  ISO C99 Draft（Acrobat PDF 格式，556 页），是新的 C 语言标准，来自 Calgary 大学 Ben 的 C 编程课程。  请阅读 Roman Czyborra 的 Unix 环境下的 Unicode。  请阅读 IANA（Internet Assigned Numbers Authority）中的 IANA Charset Registration Procedures。  请参阅 Virginia 大学图书馆 Robertson Media 中心的 Unicode Music Symbols。  请看看 graphic representation of the Roadmap to the BMP, Plane 0 of the UCS。这些表包含了由 0 号，也就是通用字符集（Universal Character Set，UCS）的基本多语言平面（Basic Multilingual Plane，BMP）实际大小的映射组成的。Everson Gunn Teoranta 是一个自 1990 年开办的支持少数民族语言团体的软件和出版公司，由 Michael Everson 和 Marion Gunn 共同建立。  请浏览 UTF-8 and Unicode FAQ for UNIX/Linux，Markus Kuhn 的综合性的 one-stop 信息资源，关于您如何在 POSIX 系统（Linux，UNIX）使用 Unicode/UTF-8。  请检查 Technology Appraisals Ltd 的 Solution Given by the Universal Character Set，其中提供了独立的、高质量的有关电子商务系统、电子信息传递、XML、网络和 IT 安全的信息、教育和培训。  请阅读 Mulberry Technologies, Inc 的 Unicode presentation titled“10646 and All That”，一个专攻基于 SGML 和 XML 系统的电子出版物的咨询公司。  请咨询 Linux 程序员手册上的 UTF-8 ― an ASCII compatible multi-byte Unicode encoding。  请阅读 Unicode Standard Annex#15 Unicode Normalization Forms，一篇描写了四种 Unicode 文本标准化格式规范的文档。有了这些格式，等价的（规范或是兼容的）文本将会有同样的二进制表式。当实现工具在标准化的格式中保留了一个字符串，可以确保有一个以二进制形式表现的独一无二的等价字符串。  请阅读 man-pages.net 上的 mbstowcs ，它把多字节字符串转换成了宽字符的字符串，man-pages.net 为 Linux 手册页面提供了永久的基于 Web 的归档文件。  请阅读 Hewlett Packard 的开发者资源站点的 Linux 程序员手册上的 wcsrtombs ，它能将宽字符的字符串转化为多字节字符串。  请阅读 MKS 工具箱文档中的 setlocale() ，它能改变或查询语言环境。MKS 软件公司是在 Windows 环境或混合 UNIX/Linux 和 Windows 环境中用于系统管理和开发的 Windows 自动化工具的领先供应商。  请学习 IBM Classes for Unicode (ICU)，一个 C 语言和 C++ 语言库，它在许多平台上提供了健壮的和功能完善的 Unicode 支持。  请参阅 IBM 的 “Introduction to Unicode”站点，这里深入涵盖了 Unicode 基础知识。  在 IBM 的关于新兴技术的 alphaWorks站点 。请参阅： UnicodeCompressor，这里提供了使用标准 Unicode 压缩方案的压缩和解压缩 Unicode 文本的工具 Unicode Normalizer，为实现快速排序和搜索将 Java 字符串对象转换为标准 Unicode 格式。 请阅读 TW Burger 撰写的 “Cyrillic in Unicode”和 Jim Melnick 撰写的 “Multilingual forms in Unicode”，也在developerWorks上。  请在 developerWorks上浏览 更多 Linux 参考资料。  关于作者 TW Burger 从 1979 年起曾经做过编程、讲授中等计算机课程以及撰写有关计算机技术方面的书。他正在经营一个信息技术咨询公司。您可以通过 twburger@bigfoot.com 与他联系。","title":"Linux Unicode 编程---如何（在程序中）加入并使用 Unicode 以实现外语支持"},{"content":"from:http://blog.csdn.net/harry_lyc/article/details/6667399 1：简介        Leveldb是一个google实现的非常高效的kv数据库，可按照字符串键值顺序映射进行存贮。目前的版本1.2能够支持billion级别的数据量了。 在这个数量级别下还有着非常高的性能。         Leveldb是一个C++库，可用于很多情况。比如用于一个网页浏览器存储最近存取网页的缓存，或用于操作系统存储安装包列表，或用于应用存储用户的设置参数。其实新版本的Chrome浏览器里部署的IndexedDB HTML5 API就是基于LevelDB打造的。Google自己的数据库Bigtable掌管着数百万数据表也是用LevelDB的。          今天在Linux(Fedra14)下编译了一下，感觉不错。中间遇到了很多问题，记录下来。作为学习之用。          在这里我想发泄一下郁闷之情。我对学过Linux下的编程，但是不是很深入，大部分时间时自己摸索的，周围没有可以交流的人，再说周围的大部分在搞java、C#、.net没人在研究c\\c++尤其是Linux下的。有些研究生毕业了还不知道什么是ubuntu。我以一直喜欢技术特别是Linux的，不管怎样算是一种追求吧。自己摸索之路是很坎坷的，深知一个人探索的困难，所以遇到问题会自己写下来发成博客，对自己是一种学习，也希望别的有共同兴趣的人有所帮助，如果能让没有一点基础的人们能看懂，并且根据示例自己操作成功，也算是一件很有成就感的事。 2：编译源代码         我用的版本为Release 1.2 2011-05-16，这个需要用SVN下载，过程就不多说了。        2.1 解压缩文件，我的路径是/home/lyc/leveldb/Leveldb       2.2 进入解压缩后的路径，cd /home/lyc/leveldb/Leveldb       2.3 编译，这个很简单一个命令makefile就行了，注意这个编译需要g++的支持       2.4 编译后在/home/lyc/leveldb/Leveldb路径下会出现一个库文件libleveldb.a，这个可以用在自己的项目中 3：leveldb性能测试          默认的编译makefile命令是不会生成测试程序的，如果要生成这些辅助的程序,可以用命令makefile test          结果在/home/lyc/leveldb/Leveldb路径下会产生可执行文件db_bench，arena_test，db_test等测试程序。这个就不解少了，我的目标的是在自己的程序中使用leveldb，所以重点在使用库文件libleveldb.a上。 4：leveldb头文件准备         头文件的问题花了很多时间来解决，其实很简单，到/home/lyc/leveldb/Leveldb路径下(这个具体要根据自己的文件路径)，用命令 cp -r include/leveldb   /usr/local/include。把./include/leveldb文件夹的内容都拷到/usr/local/include路径下。        注意要切还到root用户，要不没有执行的权限。 5：示例程序 把libleveldb.a、db.h拷到本程序的同一路径下。 编译命令为： g++ -o sa Main.cpp libleveldb.a -lpthread 执行： [lyc@Fedora test]$ ./sa 结果： Open db OK liyc7711@gamil.com 源码Main.cpp: [cpp] view plaincopy #include <assert.h>   #include <iostream>   #include \"db.h\"      using namespace std;      int main(int argc,char * argv[])   {       leveldb::DB* db;       leveldb::Options options;       options.create_if_missing = true;       std::string dbpath = \"testdb\";       leveldb::Status status = leveldb::DB::Open(options, dbpath, &db);       assert(status.ok());       std::string key1 = \"lyc\";       std::string key2 = \"liyc7711@gamil.com\";       cout<<\"Open db OK\"<<std::endl;              std::string value;       leveldb::Status s ;       s = db->Put(leveldb::WriteOptions(), key1, key2);/*key1和key2作为一对key-value对插入*/       s = db->Get(leveldb::ReadOptions(), key1, &value);/*根据key返回对应的value值*/              cout<<value<<std::endl;       delete db;/*删除数据库*/          return 0;   }   6：注意事项         6.1 编译中加上库文件的路径（libleveldb.a）和线程库标志（-lpthread），执行后在当前文件产生一个文件夹testdb保存了插入的数据。         6.2 leveldb用于一些单间的数据比如名称-值对，并且数据量远大于内存并且需要永久保存的情况下。很适合大规模的语言模型文件存贮。        6.3 插入的数据为两个字符串对一个为key，另外一个为value，查询时可以根据key取得value的值，相反不可以。 leveldb综合专栏：leveldb源代码分析:http://blog.csdn.net/column/details/leveldb.html","title":"在Linux下编译Google leveldb数据库及在C++中操作示例"},{"content":"LINUX系统启动过程如下： 1）BIOS自检查看启动方式（启动项） 2）启动GRUB/LIL0启动引导界面 3)运行LINUX内核并检测硬件 4）运行系统的的第一个进程init 5）init 读取系统引导配置文件/etc/inittab中的信息进行初始化 6）/etc/rc.d/rc.sysinit系统初始化脚本 7）/etc/rc.d/rcX.d [KS] * -根据运行级别X配置服务 终止以‘K’开头的服务； 启动以‘S’开头的服务； 8）/etc/rc.d/rc.local执行本地特殊配置 9）其它特殊服务","title":"linux系统启动过程"},{"content":"CentOS默认的yum --install subversion ，安装的是1.6版本 安装1.7脚本为： #!/bin/bash       echo WANdisco Subversion Installer for CentOS 5  echo Please report bugs or feature suggestions to opensource@wandisco.com  echo   echo Gathering some information about your system...    MINVERSION='2'  SVNVER='1.7.7'  NOW=$(date +\"%b-%d-%y%s\")    #functions  gather_info () {      ARCH=`uname -m`      SVNSTATUS=`rpm -qa|grep ^subversion-[0-9]|awk 'BEGIN { FS = \"-\" } ; { print $1 }'`  }  check_tools () {          COMMANDS=\"yum wget rpm\"          for C in $COMMANDS; do                  if [ -z \"$(which $C)\" ] ; then                          echo \"This installer uses the $C command which was not found in \\$PATH.\"              exit 1                  fi          done  }    check_centos_version ()  {         if [ ! -e /etc/redhat-release ]; then                  echo \"No /etc/redhat-release file, exiting\"                  echo \"You are most likely not using CentOS.\"                  echo \"Installers for other operating systems are available from our downloads page:\"                  echo \"http://www.wandisco.com/subversion/download\"          echo \"Exiting..\"                  exit 1          fi;      cat /etc/redhat-release |grep -e 5.[0-9]      if [ $? == 0 ]; then          echo \"CentOS version 5.x confirmed..\"      else                  echo \"You are most likely using an incompatible version of CentOS.\"          echo \"This installer is made for CentOS 5.x\"                  echo \"Installers for other operating systems are available from our downloads page:\"                  echo \"http://www.wandisco.com/subversion/download\"                  exit 1      fi;  }      check_is_root ()  {      if [[ $EUID -ne 0 ]]; then          echo \"This script must be run as root\" 1>&2          exit 1      fi    }  svn_remove_old ()  {      if [ -f /etc/httpd/conf.d/subversion.conf ]; then          echo Backing up /etc/httpd/conf.d/subversion.conf to /etc/httpd/conf.d/subversion.conf.backup-$NOW          cp /etc/httpd/conf.d/subversion.conf /etc/httpd/subversion.conf.backup-$NOW      fi      echo Removing old packages...      yum -y remove mod_dav_svn subversion subversion-devel subversion-perl subversion-python subversion-tools &>/dev/null  }  add_repo_config ()  {          echo Adding repository configuration to /etc/yum.repos.d/          echo '  # WANdisco Repo    [WANdisco-dev]  name=WANdisco SVN Repo 1.7  enabled=1  baseurl=http://opensource.wandisco.com/centos/5/devel/RPMS/$basearch/  gpgcheck=1  gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-WANdisco' >/etc/yum.repos.d/WANdisco-1.7.repo           echo \"Importing GPG key\"      wget http://opensource.wandisco.com/RPM-GPG-KEY-WANdisco -O /tmp/RPM-GPG-KEY-WANdisco &>/dev/null      rpm --import /tmp/RPM-GPG-KEY-WANdisco      rm -rf /tmp/RPM-GPG-KEY-WANdisco      echo \" ------ Installing yum repo: Done ------\"   }  install_svn ()  {          echo Checking to see if you already have Subversion installed via rpm...          if [[ \"$SVNSTATUS\" =~ subversion ]]; then              echo Subversion is already installed on the system.              echo Do you wish to replace the version of subversion currently installed with the WANdisco version?           echo This action will remove the previous version from your system           echo \"[y/n]\"          read svn_install_confirm          if [ \"$svn_install_confirm\" == \"y\" -o \"$svn_install_confirm\" == \"Y\" ]; then              svn_remove_old              add_repo_config              echo                      echo Installing Subversion $SVNVER              echo              yum -y install subversion.$ARCH subversion-perl.$ARCH subversion-python.$ARCH subversion-javahl.$ARCH subversion-tools.$ARCH              echo Would you like to install apache and the apache SVN modules?              echo \"[y/n]\"              read dav_svn_confirm              if [ \"$dav_svn_confirm\" == \"y\" -o \"$dav_svn_confirm\" == \"Y\" ]; then                  echo Installing apache and subversion modules                  yum -y install mod_dav_svn.$ARCH httpd                  echo \"Installation complete.\"                  echo \"You can find the subversion configuration file for apache HTTPD at /etc/httpd/conf.d/subversion.conf\"                  echo \"By default, the modules are commented out in subversion.conf.\"                  echo \"To enable the modules, please edit subversion.conf and remove the # infront of the LoadModule lines.\"                  echo \"You should then restart httpd (/etc/init.d/httpd restart)\"              fi                            else              echo \"Install Cancelled\"              exit 1          fi        else          # Install SVN          echo \"Subversion is not currently installed\"          echo \"Starting installation, are you sure you wish to continue?\"          echo \"[y/n]\"          read svn_install_confirm                  if [ \"$svn_install_confirm\" == \"y\" -o \"$svn_install_confirm\" == \"Y\" ]; then              add_repo_config                          echo                          echo Installing Subversion $SVNVER                          echo              yum -y install subversion.$ARCH subversion-perl.$ARCH subversion-python.$ARCH subversion-tools.$ARCH                          echo Would you like to install apache HTTPD and the apache SVN modules?              echo \"[y/n]\"                          read dav_svn_confirm                          if [ \"$dav_svn_confirm\" == \"y\" -o \"$dav_svn_confirm\" == \"Y\" ]; then                                  echo Installing apache and subversion modules                  yum -y install mod_dav_svn.$ARCH httpd                                  echo \"Installation complete.\"                                  echo \"You can find the subversion configuration file for apache HTTPD at /etc/httpd/conf.d/subversion.conf\"                                  echo \"By default, the modules are commented out in subversion.conf.\"                                  echo \"To enable the modules, please edit subversion.conf and remove the # infront of the LoadModule lines.\"                                  echo \"You should then restart httpd (/etc/init.d/httpd restart)\"                          fi                    else                          echo \"Install Cancelled\"                          exit 1                  fi                    fi        }    install_32 ()  {          echo Installing for $ARCH      install_svn  }  install_64 ()  {          echo Installing for $ARCH      install_svn  }    #Main  check_is_root  check_centos_version  check_tools  gather_info    echo Checking your system arch  if [ \"$ARCH\" == \"i686\" -o \"$ARCH\" == \"i386\" ]; then      if [ \"$ARCH\" == \"i686\" ]; then          ARCH=\"i386\"      fi;      install_32  elif [ \"$ARCH\" == \"x86_64\" ];  then      install_64  else       echo Unsupported platform: $ARCH      exit 1  fi","title":"CentOS 安装 SVN1.7.7"},{"content":"才安装的CentOS系统，SSH登陆输入密码就卡了半天。 vi /etc/ssh/sshd_config 关闭 SSH 的 DNS 反解析,添加下面一行: UseDNS no 重启SSH搞定","title":"SSH登陆比较慢"},{"content":"tar [-cxtzjvfpPN] 文件与目录 .... 参数： -c ：建立一个压缩文件的参数指令(create 的意思)； -x ：解开一个压缩文件的参数指令！ -t ：查看 tarfile 里面的文件！ 特别注意，在参数的下达中， c/x/t 仅能存在一个！不可同时存在！ 因为不可能同时压缩与解压缩。 -z ：是否同时具有 gzip 的属性？亦即是否需要用 gzip 压缩？ -j ：是否同时具有 bzip2 的属性？亦即是否需要用 bzip2 压缩？ -v ：压缩的过程中显示文件！这个常用，但不建议用在背景执行过程！ -f ：使用档名，请留意，在 f 之后要立即接档名喔！不要再加参数！ 　　　例如使用『 tar -zcvfP tfile sfile』就是错误的写法，要写成 　　　『 tar -zcvPf tfile sfile』才对喔！ -p ：使用原文件的原来属性（属性不会依据使用者而变） -P ：可以使用绝对路径来压缩！ -N ：比后面接的日期(yyyy/mm/dd)还要新的才会被打包进新建的文件中！ --exclude FILE：在压缩的过程中，不要将 FILE 打包！ 范例： 范例一：将整个 /etc 目录下的文件全部打包成为 /tmp/etc.tar [root@linux ~]# tar -cvf /tmp/etc.tar /etc<==仅打包，不压缩！ [root@linux ~]# tar -zcvf /tmp/etc.tar.gz /etc<==打包后，以 gzip 压缩 [root@linux ~]# tar -jcvf /tmp/etc.tar.bz2 /etc<==打包后，以 bzip2 压缩 # 特别注意，在参数 f 之后的文件档名是自己取的，我们习惯上都用 .tar 来作为辨识。 # 如果加 z 参数，则以 .tar.gz 或 .tgz 来代表 gzip 压缩过的 tar file ～ # 如果加 j 参数，则以 .tar.bz2 来作为附档名啊～ # 上述指令在执行的时候，会显示一个警告讯息： # 『tar: Removing leading `/\" from member names』那是关於绝对路径的特殊设定。 范例二：查阅上述 /tmp/etc.tar.gz 文件内有哪些文件？ [root@linux ~]# tar -ztvf /tmp/etc.tar.gz # 由於我们使用 gzip 压缩，所以要查阅该 tar file 内的文件时， # 就得要加上 z 这个参数了！这很重要的！ 范例三：将 /tmp/etc.tar.gz 文件解压缩在 /usr/local/src 底下 [root@linux ~]# cd /usr/local/src [root@linux src]# tar -zxvf /tmp/etc.tar.gz # 在预设的情况下，我们可以将压缩档在任何地方解开的！以这个范例来说， # 我先将工作目录变换到 /usr/local/src 底下，并且解开 /tmp/etc.tar.gz ， # 则解开的目录会在 /usr/local/src/etc 呢！另外，如果您进入 /usr/local/src/etc # 则会发现，该目录下的文件属性与 /etc/ 可能会有所不同喔！ 范例四：在 /tmp 底下，我只想要将 /tmp/etc.tar.gz 内的 etc/passwd 解开而已 [root@linux ~]# cd /tmp [root@linux tmp]# tar -zxvf /tmp/etc.tar.gz etc/passwd # 我可以透过 tar -ztvf 来查阅 tarfile 内的文件名称，如果单只要一个文件， # 就可以透过这个方式来下达！注意到！ etc.tar.gz 内的根目录 / 是被拿掉了！ 范例五：将 /etc/ 内的所有文件备份下来，并且保存其权限！ [root@linux ~]# tar -zcvpf /tmp/etc.tar.gz /etc # 这个 -p 的属性是很重要的，尤其是当您要保留原本文件的属性时！ 范例六：在 /home 当中，比 2005/06/01 新的文件才备份 [root@linux ~]# tar -N \"2005/06/01\" -zcvf home.tar.gz /home 范例七：我要备份 /home, /etc ，但不要 /home/dmtsai [root@linux ~]# tar --exclude /home/dmtsai -zcvf myfile.tar.gz /home/* /etc 范例八：将 /etc/ 打包后直接解开在 /tmp 底下，而不产生文件！ [root@linux ~]# cd /tmp [root@linux tmp]# tar -cvf - /etc | tar -xvf - # 这个动作有点像是 cp -r /etc /tmp 啦～依旧是有其有用途的！ # 要注意的地方在於输出档变成 - 而输入档也变成 - ，又有一个 | 存在～ # 这分别代表 standard output, standard input 与管线命令啦！ # 这部分我们会在 Bash shell 时，再次提到这个指令跟大家再解释啰！","title":"linux tar 文件解压"},{"content":"NFS 安装与配置 NFS 全称为“网络文件系统”（ Network File System ） 本机 ip 地址： 219.229.128.44 用“机器一”表示 要连接的机器地址： 219.229.128.87 用“机器二”表示   1 、安装 nfs 服务版（机器一、机器二都要装） 服务器端安装 : sudo aptitude install nfs-common nfs-kernel-server portmap 在客户端则需要安装： sudo aptitude install nfs-common portmap sudo apt-get install nfs-kernel-server ( 这条命令好像就可以 ) 启动服务 sudo /etc/init.d/nfs-kernel-server start 停止服务 sudo /etc/init.d/nfs-kernel-server stop 重启服务 sudo /etc/init.d/nfs-kernel-server restart 2 、修改 nsf 配置文件（机器二） （ 1 ）配置 expores 文件  sudo gedit /etc/exports  在文件中添加 nfs 的目录 书写规则是：（每个共享规则一行） 共享目录 主机 ( 参数 ) 例如： /home/fzu/dd 219.229.128.44(ro,sync, no_root_squash) 上面的规则代表将 /home/fzu/dd 目录以读写同步方式共享给主机 219.229.128.44 。如果登陆到 NFS 主机的用户是 root, 那么该用户就具有 NFS 主机的 root 用户的权限。 Ip 地址可以写成 219.229.128.* 代表 ip 地址以 219.229.128 开始的主机或者直接写成是＊代表全部的主机。  下面是一些 NFS 共享的常用参数： rw ： 可读写的权限； ro ： 只读的权限； no_root_squash ：登入到 NFS 主机的用户如果是 ROOT 用户，他就拥有 ROOT 的权限 root_squash ：在登入 NFS 主机使用目录的使用者如果是 root 时，那么这个使用者的权限将被压缩成为匿名使用者，通常他的 UID 与 GID 都会变成 nobody 那个身份 all_squash ：不管登陆 NFS 主机的用户是什么都会被重新设定为 nobody 。 anonuid ：将登入 NFS 主机的用户都设定成指定的 user id, 此 ID 必须存在于 /etc/passwd 中。 anongid ：同 anonuid ，但是变成 group ID 就是了！ sync ：资料同步写入存储器中。 async ：资料会先暂时存放在内存中，不会直接写入硬盘。 insecure ：允许从这台机器过来的非授权访问。  存盘退出 （ 2 ）配置 hosts.deny 文件 sudo gedit /etc/hosts.deny 在文件末尾加入 ### NFS DAEMONS portmap:ALL lockd:ALL mountd:ALL rquotad:ALL statd:ALL （ 3 ）配置 hosts.allow 文件 在文件末尾加入 ### NFS DAEMONS portmap: 219.229.128. lockd: 219.229.128. rquotad: 219.229.128. mountd: 219.229.128. statd: 219.229.128. 表示给以 219.228.128. 开头的 ip 地址权限，以上两个文件主要是安全设置 3 、在目录 /home/fzu/ 下建立 nsf 的目录 dd （机器二）  sudo mkdir /home/fzu/dd  修改该目录的权限  sudo chmod 777 -R /home/fzu/dd 4 、从新启动 nfs （机器一）  sudo /etc/init.d/nfs-kernel-server restart 5 、挂载（机器一）  sudo mount 219.229.128.44:/home/fzu/dd /home/fzu/disk1 表示将 219.229.128.44 上的 /home/fzu/dd 文件夹挂载到本机的 /home/fzu/disk1 下","title":"ubuntu 12.10 nfs配置"},{"content":"今天在新安装的 fedora 17 虚拟机上写多线程程序的时候，本想查看下系统帮助手册中关于线程相关函数的说明，结果。。。 [tom@localhost thread]$ man pthread_create No manual entry for pthread_create 为啥呢？ 在以下网页上找到了答案：http://blog.163.com/yungang_z/blog/static/1751531332011103103529810/ 于是操作如下（安装手册）： [tom@localhost thread]$ yum install man-pages -y Loaded plugins: langpacks, presto, refresh-packagekit You need to be root to perform this command. [tom@localhost thread]$ sudo yum install man-pages -y Loaded plugins: langpacks, presto, refresh-packagekit Existing lock /var/run/yum.pid: another copy is running as pid 6661. Another app is currently holding the yum lock; waiting for it to exit...   The other application is: PackageKit     Memory :  26 M RSS (431 MB VSZ)     Started: Sun Dec 16 17:57:33 2012 - 00:32 ago     State  : Sleeping, pid: 6661  从上面红色部分可以看到，由于 yum 锁被另一个名为 PackageKit 的进程占用，因此本安装没法继续进行，于是查出那个进程，然后 kill 掉： [tom@localhost ~]$ ps -ef | grep package root      6656     1  0 17:57 ?        00:00:00 /usr/libexec/packagekitd tom       6744  6686  0 17:59 pts/0    00:00:00 grep --color=auto package [tom@localhost ~]$ kill 6656 [tom@localhost ~]$ sudo kill 6656 [sudo] password for tom:  [tom@localhost ~]$ ps -ef | grep package tom       6780  6686  0 18:01 pts/0    00:00:00 grep --color=auto package  一旦该进程被 kill 成功之后，手册安装就能成功进行了： Resolving Dependencies --> Running transaction check ---> Package man-pages.noarch 0:3.35-4.fc17 will be installed --> Finished Dependency Resolution Dependencies Resolved =============================================================================================================================================================  Package                               Arch                               Version                                  Repository                           Size ============================================================================================================================================================= Installing:  man-pages                             noarch                             3.35-4.fc17                              updates                             4.9 M Transaction Summary ============================================================================================================================================================= Install  1 Package Total download size: 4.9 M Installed size: 4.4 M Downloading Packages: http://mirrors.ustc.edu.cn/fedora/linux/updates/17/x86_64/man-pages-3.35-4.fc17.noarch.rpm: [Errno 12] Timeout onhttp://mirrors.ustc.edu.cn/fedora/linux/updates/17/x86_64/man-pages-3.35-4.fc17.noarch.rpm: (28, '') Trying other mirror. man-pages-3.35-4.fc17.noarch.rpm                                                                                                      | 4.9 MB     00:41      Running Transaction Check Running Transaction Test Transaction Test Succeeded Running Transaction   Installing : man-pages-3.35-4.fc17.noarch                                                                                                              1/1    Verifying  : man-pages-3.35-4.fc17.noarch                                                                                                              1/1  Installed:   man-pages.noarch 0:3.35-4.fc17                                                                                                                              Complete! 再查一下相关函数的帮助，就 ok 了： [tom@localhost thread]$ man pthread_create PTHREAD_CREATE(3)                                               Linux Programmer's Manual                                               PTHREAD_CREATE(3) NAME        pthread_create - create a new thread SYNOPSIS        #include <pthread.h>        int pthread_create(pthread_t *thread, const pthread_attr_t *attr,                           void *(*start_routine) (void *), void *arg);        Compile and link with -pthread. DESCRIPTION        The  pthread_create()  function  starts  a new thread in the calling process.  The new thread starts execution by invoking start_routine(); arg is        passed as the sole argument of start_routine(). ","title":"Linux 帮助手册安装不全"},{"content":"centos下adsl自动拨号设置 实现的功能：开机自动拨号、断线自动重拨 一、安装的前提条件 1、确保安装了网卡并工作正常 使用命令 #ifconfig eth0 查看网卡状态 2、在系统中一定不要设置默认路由(网关),让ADSL拨号后 自动获得 如果已经设置了默认路由,使用以下方法删除: 在文件/etc/sysconfig/network/ifconfig-eth0 或者/etc/sysconfig/network 中注释掉 GATEWAY= 这一行,然后以root 执行: # service network restart 3、已经安装了pppd软件包 如果存在文件/usr/sbin/pppd,则说明已经安装了pppd; 如果未安装,下载安装这个软件包。 二、安装PPPOE客户端软件 Linux 下的PPPOE 客户端软件比较多,而且大多使用GNU License,推荐使用rp-pppoe 这 个软件包。从http://www.roaringpenguin.com/products/pppoe 这个网站上，不仅可以下载 各发布包下的rp-pppoe 的二进制软件包，而且可以下载源代码软件包。 我们使用centos 下的yum 安装方法,来安装rp-pppoe 软件包 #yum install rp-pppoe 三、配置PPPOE客户端软件 1、手动设置配置文件 安装完软件包后，必须配置PPPOE 的配置文件/etc/ppp/pppoe.conf，从而让ADSL 拨号 时使用配置文件中的用户名、密码等参数。 2、命令行自动生成配置文件 [root@cap187 ~]# adsl-setup Welcome to the ADSL client setup. First, I will run some checks on your system to make sure the PPPoE client is installed properly... LOGIN NAME Enter your Login Name (default root): 300000490382 INTERFACE Enter the Ethernet interface connected to the ADSL modem For Solaris, this is likely to be something like /dev/hme0. For Linux, it will be ethX, where 'X' is a number. (default eth0): eth1 Do you want the link to come up on demand, or stay up continuously? If you want it to come up on demand, enter the idle time in seconds after which the link should be dropped. If you want the link to stay up permanently, enter 'no' (two letters, lower-case.) NOTE: Demand-activated links do not interact well with dynamic IP addresses. You may have some problems with demand-activated links. Enter the demand value (default no): no DNS Please enter the IP address of your ISP's primary DNS server. If your ISP claims that 'the server will provide dynamic DNS addresses', enter 'server' (all lower-case) here. If you just press enter, I will assume you know what you are doing and not modify your DNS setup. Enter the DNS information here: 8.8.8.8 Please enter the IP address of your ISP's secondary DNS server. If you just press enter, I will assume there is only one DNS server. Enter the secondary DNS server address here: PASSWORD Please enter your Password: Please re-enter your Password: USERCTRL Please enter 'yes' (three letters, lower-case.) if you want to allow normal user to start or stop DSL connection (default yes): yes FIREWALLING Please choose the firewall rules to use. Note that these rules are very basic. You are strongly encouraged to use a more sophisticated firewall setup; however, these will provide basic security. If you are running any servers on your machine, you must choose 'NONE' and set up firewalling yourself. Otherwise, the firewall rules will deny access to all standard servers like Web, e-mail, ftp, etc. If you are using SSH, the rules will block outgoing SSH connections which allocate a privileged source port. The firewall choices are: 0 - NONE: This script will not set any firewall rules. You are responsible for ensuring the security of your machine. You are STRONGLY recommended to use some kind of firewall rules. 1 - STANDALONE: Appropriate for a basic stand-alone web-surfing workstation 2 - MASQUERADE: Appropriate for a machine acting as an Internet gateway for a LAN Choose a type of firewall (0-2): 0 Start this connection at boot time Do you want to start this connection at boot time? Please enter no or yes (default no):yes ** Summary of what you entered ** Ethernet Interface: eth1 User name: 300000490382 Activate-on-demand: No Primary DNS: 8.8.8.8 Firewalling: NONE User Control: yes Accept these settings and adjust configuration files (y/n)? y Adjusting /etc/sysconfig/network-scripts/ifcfg-ppp0 Adjusting /etc/resolv.conf (But first backing it up to /etc/resolv.conf.bak) Adjusting /etc/ppp/chap-secrets and /etc/ppp/pap-secrets (But first backing it up to /etc/ppp/chap-secrets.bak) (But first backing it up to /etc/ppp/pap-secrets.bak) Congratulations, it should be all set up! Type '/sbin/ifup ppp0' to bring up your xDSL link and '/sbin/ifdown ppp0' to bring it down. Type '/sbin/adsl-status /etc/sysconfig/network-scripts/ifcfg-ppp0' to see the link status. 四、启动PPPOE客户端软件 # adsl-start 查看当前连接的状态 /usr/sbin/adsl-status","title":"centos下adsl自动拨号设置"},{"content":"1.列出所有可更新的软件清单 命令：yum check-update 2.安装所有更新软件 命令：yum update 3.仅安装指定的软件 命令：yum install <package_name> 4.仅更新指定的软件 命令：yum update <package_name> 5.列出所有可安裝的软件清单 命令：yum list 用YUM安装删除软件 装了系统添加删除软件是常事，yum同样可以胜任这一任务，只要软件是rpm安装的。  安装的命令是，yum install xxx，yum会查询数据库，有无这一软件包，如果有，则检查其依赖冲突关系，如果没有依赖冲突，那么最好，下载安装;如果有，则会给出提示，询问是否要同时安装依赖，或删除冲突的包，你可以自己作出判断。  删除的命令是，yum remove xxx，同安装一样，yum也会查询数据库，给出解决依赖关系的提示。  1.用YUM安装软件包 命令：yum install <package_name> 2.用YUM删除软件包 命令：yum remove <package_name> 用YUM查询软件信息 我 们常会碰到这样的情况，想要安装一个软件，只知道它和某方面有关，但又不能确切知道它的名字。这时yum的查询功能就起作用了。你可以用 yum search keyword这样的命令来进行搜索，比如我们要则安装一个Instant Messenger，但又不知到底有哪些，这时不妨用 yum search messenger这样的指令进行搜索，yum会搜索所有可用rpm的描述，列出所有描述中和messeger有关的rpm包，于 是我们可能得到gaim，kopete等等，并从中选择。  有时我们还会碰到安装了一个包，但又不知道其用途，我们可以用yum info packagename这个指令来获取信息。  1.使用YUM查找软件包 命令：yum search <keyword> 2.列出所有可安装的软件包 命令：yum list 3.列出所有可更新的软件包 命令：yum list updates 4.列出所有已安装的软件包 命令：yum list installed 5.列出所有已安装但不在 Yum Repository 內的软件包 命令：yum list extras 6.列出所指定的软件包 命令：yum list <package_name> 7.使用YUM获取软件包信息 命令：yum info <package_name> 8.列出所有软件包的信息 命令：yum info 9.列出所有可更新的软件包信息 命令：yum info updates 10.列出所有已安裝的软件包信息 命令：yum info installed 11.列出所有已安裝但不在 Yum Repository 內的软件包信息 命令：yum info extras 12.列出软件包提供哪些文件 命令：yum provides <package_name> 清除YUM缓存 yum 会把下载的软件包和header存储在cache中，而不会自动删除。如果我们觉得它们占用了磁盘空间，可以使用yum clean指令进行清除，更精确 的用法是yum clean headers清除header，yum clean packages清除下载的rpm包，yum clean all一 股脑儿端  1.清除缓存目录(/var/cache/yum)下的软件包 命令：yum clean packages 2.清除缓存目录(/var/cache/yum)下的 headers 命令：yum clean headers 3.清除缓存目录(/var/cache/yum)下旧的 headers 命令：yum clean oldheaders 4.清除缓存目录(/var/cache/yum)下的软件包及旧的headers 命令：yum clean, yum clean all (= yum clean packages; yum clean oldheaders) yum安装vsftpd 1. yum -y install vsftpd （yum 自动安装）；　　 2. 修改vsftpd的配置： 在/etc/vsftpd/vsftpd.conf 文件，修改默认配置，包括监听地址和端口，是否打开 tcp、psav模式等等 3.启动vsftpd服务： 运行service vsftpd start即可，或者运行/etc/init.d/vsftpd start 说明： 创建匿名用户根目录： anon_root=/var/ftp/ 匿名用户上传文件： write_enable=YES  anon_world_readable_only=NO  anon_upload_enable=YES  anon_mkdir_write_enable=YES  anon_other_write_enable=YES 然后创建供匿名用户上传文件的目录，并设定权限：  # mkdir /var/ftp/incoming  # chmod o+w /var/ftp/incoming  file_open_mode=0777 ##如果希望上传的文件可以执行，设此值为0777。默认值为0666。  限制用户在自家目录 1、限制所有的本地用户在自家目录  chroot_local_user=YES  2、限制部分本地用户在自家目录  chroot_local_user=NO  chroot_list_enable=YES  chroot_list_file=/etc/vsftpd.chroot_list  在/etc/vsftpd.chroot_list文件中加入要限制的本地用户名。注意一个用户名一行。 日志设置: xferlog_enable=YES|NO xferlog_file=  这个选项设定记录传输日志的文件名。默认值为/var/log/vsftpd.log。 用setup 可以把它选择为开机自动运行 关于windows用户访问服务器时候出现乱码的问题 windows访问vsftp出现乱码因为windows默认编码是GB2312，linux用的是UTF-8编码，所以上传文件会有乱 码，这时可以更改修改 /etc/sysconfig/i18n文件，将第二行改成这样：LANG = \"zh_CN.GB2312\"就可以了 vsFTP（二）让虚拟账户使用不同的主目录，并且又完全权限 (转自http://blog.chinaunix.net/u1/42928/showart_334305.html） virtual_user的主目录: /home/ftp  vsftpd.conf中加入  guest_username=virtual_user  user_config_dir=/etc/vsftpd_user_config  user_sub_token=$USER  /etc/vsftpd_user_config目录下为每个用户建一个配置文件，文件名与用户名相同，内容中必须有  local_root=/home/ftp/$USER 让虚拟账户使用不同的主目录，并且又完全权限， 在vsftpd.conf中输入下面代码：anonymous_enable=NO local_enable=YES write_enable=YES local_umask=022 anon_upload_enable=YES anon_mkdir_write_enable=YES anon_other_write_enable=YES dirmessage_enable=YES xferlog_enable=YES connect_from_port_20=YES xferlog_std_format=YES pam_service_name=vsftpd userlist_enable=YES one_process_model=NO anon_world_readable_only=NO guest_enable=YES guest_username=nihao listen=YES tcp_wrappers=YES user_config_dir=/etc/vsftpd_user_config user_sub_token=$USER ===================================== 创建数据库文件 db_load -T -t hash -f /etc/vsftpd/logins.txt /etc/vsftpd/vsftpd_login.db 且设置权限 chmod 600 /etc/vsftpd/vsftpd_login.db 创建数据库的PAM文件 vi vsftpd.pam 内容如下: auth required /lib/security/pam_userdb.so db=/etc/vsftpd/vsftpd_login account required /lib/security/pam_userdb.so db=/etc/vsftpd/vsftpd_login 并复制到/etc/pam.d下 cp vsftpd.pam /etc/pam.d 设置虚拟用户的根目录 useradd -d /home/ftp vftp 限制个人用户目录: user_config_dir=/etc/vsftpd/vsftpd_user_conf 在该目录下建立与特定虚拟用户同名的文件 在用户文件里加入: local_root=/home/test 就可设置用户的目录 并按实际需要开启相关的权限 anon_world_readable_only=NO write_enable=YES anon_upload_enable=YES anon_other_write_enable=YES anon_umask=  匿名用户新增文件的umask 数值。默认值为077。 vi vsftpd.conf anonymous_enable=NO local_enable=YES local_umask=022 anon_umask=022 write_enable=NO anon_upload_enable=NO anon_mkdir_write_enable=NO anon_other_write_enable=NO chroot_local_user=YES guest_enable=YES guest_username=vftp listen=YES pam_service_name=vsftpd.pam user_config_dir=/www/servers/vsftpdv/user pasv_enable=YES pasv_min_port=10240 pasv_max_port=10250 userlist_enable=YES userlist_deny=YES userlist_file=/etc/vsftpd.denyuser","title":"YUM常用命令介绍"},{"content":"【IT168 技术】Linux内核安全随着Linux系统的流行，也就越来越受到大家的关注，这里向大家介绍LIDS也就是Linux内核安全入侵侦察系统。看看Linux内核存在哪些问题，LIDS又能为我们带来哪些方面特点。 　　LIDS( Linux入侵侦察系统是Linux内核补丁和系统管理员工lidsadm)，它加强了Linux内核。它在内核中实现了一种安全模式 -- 参考模式以及内核中的Mandatory Access Control(命令进入控制)模式。本文将阐述LIDS的功能和如何使用它来建立一个安全的Linux系统。 　　为什么选择LIDS 　　随着互连网上Linux越来越受欢迎 ,越来越多现有GNU/LINUX系统上的应用软件中的安全漏洞被发现。很多程序利用了程序员的粗心，例如缓存溢出、格式化代码攻击。当系统安全受到程序的危及，黑客获得ROOT权限以后，整个系统将被入侵者控制。 　　由于代码的开放性，我们可以获得很多所希望Linux应用程序的原代码，并且根据我们的需要来修改。所以bug能很容易地被找到，并很快修补。但是当漏洞被揭示后，而系统管理员疏于给漏洞打补丁，从而造成很容易地就被入侵，更糟的是黑客能获得ROOT SHELL。利用现有的GNU/Linux系统，他为所欲为。这正是LIDS想要解决的问题。 　　首先看看现有的GNU/Linux系统存在哪些问题。 　　文件系统未受到保护 　　系统中的很多重要的文件，例如 /bin/login，一旦黑客入侵后，他可以上传修改过的login文件来代替/bin/login ，然后他就可以不需要任何登陆名和密码就登陆系统。这常被称为Trojan house。 　　进程未受到保护 　　系统上运行的进程是为某些系统功能所服务的，例如HTTPD是一个web服务器来满足远程客户端对于web的需求。作为web服务器系统，保护其进程不被非法终止是很重要的。但是当入侵者获得了ROOT权限后，我们却无能为力。 　　系统管理未受保护 　　很多系统管理，例如，模块的装载/卸载，路由的设置，防火墙的规则，能很容易就被修改，如果用户的ID是0。所以当入侵者获得ROOT权限后，就变得很不安全。 　　超级用户(root)作为ROOT可能滥用权限 　　他可以为所欲为，作为ROOT他甚至可以对现有的权限进行修改。 　　综上所述，我们发现在现有的Linux系统中的进入控制模式是不足以建立一个安全的Linux系统。我们必须在系统中添加新的模式来解决这些问题。这就是LIDS所要做的。 　　LIDS的特色 　　Linux入侵侦察系统是Linux内核补丁和系统管理员工具，它加强了内核的安全性。它在内核中实现了参考监听模式以及Mandatory Access Control(命令进入控制)模式。当它起作用后，选择文件进入，每一个系统/网络的管理操作，任何使用权限， raw device， mem和 I/O 进入将可以禁止甚至对于ROOT也一样。它使用和扩展了系统的功能，在整个系统上绑定控制设置，在内核中添加网络和文件系统的安全特性，从而加强了安全性。你可以在线调整安全保护，隐藏敏感进程，通过网络接受安全警告等等。 　　简而言之，LIDS提供了保护、侦察、响应的功能，从而是LINUX系统内核中的安全模式得以实现。 　　保护 　　LIDS提供以下的保护： 　　保护硬盘上任何类型的重要文件和目录，任何人包括ROOT都无法改变。能保护重要进程不被终止 能防止非法程序的RAW IO 操作。保护硬盘，包括MBR保护，等等。能保护系统中的敏感文件，防止未被授权者(包括ROOT)和未被授权的程序进入。 　　侦察 　　当有人扫描你的主机， LIDS能侦察到并报告系统管理员。LIDS也可以检测到系统上任何违法规则的进程。 　　响应 　　当有人违反规则， LIDS会将非法的运作细节记录到受LIDS保护的系统log文件中。LIDS还可以将log信息传到你的信箱中。LIDS也可以马上关闭与用户的对话。   摘自：http://os.chinaunix.net/a2012/0828/1390/000001390745.shtml","title":"Linux内核系统之安全入侵侦察解析"},{"content":"Linux 面临的威胁主要有DoS 攻击、本地用户获取非授权的文件的读写权限、远程用户获得特权文件的读写权限、远程用户获得root 权限等。 　　可采用以下措施进行预防： 　　(1)删除所有的特殊账户，包括lp、shutdown、halt、news、uucp、operator、games、gopher 等。 　　可参考以下命令： 　　[root@redhat root]# userdel lp 　　[root@redhat root]# groupdel lp 　　(2)修改默认root 密码长度。默认root 密码长度是5 位，建议修改为8 位。 　　编辑/etc/login.defs, 把 PASS_MIN_LEN 5 修改为PASS_MIN_LEN 8. 　　(3)打开密码shadow 支持功能，利用md5 算法加密为shadow 文件添加不可更改属性。 　　具体命令为： 　　[root@redhat root]# chattr +i /etc/shadow 　　(4)取消所有不需要的服务，如Telnet、HTTP 等默认启动的服务。关闭Telnet,编辑/etc/xinetd.d/telnet,修改disable = no 为disable = yes,更改/etc/xinetd.conf 的权限为600,只允许root 来读写该文件。 　　具体命令为： 　　[root@redhat root]# chmod 600 /etc/ 　　xinetd.conf 　　(5)屏蔽系统登录信息，包括Linux 发行版、内核版本名和服务器主机名等。 　　具体命令为： 　　[root@redhat root]# rm /etc/issue 　　[root@redhat root]# rm /etc/issue.net 　　(6)禁止按Ctrl+Alt+Del 键关闭系统。 　　编辑/etc/inittab,将： 　　ca::ctrlaltdel:/sbin/shutdown-t3 -rnow 　　改为： 　　#ca::ctrlaltdel:/sbin/shutdown-t3-rnow 　　(7)不允许root 从不同的控制台进行登录。 　　编辑/etc/securetty,在不需要登录的TTY设备前添加#,禁止从TTY 设备进行root 登录。 　　(8)使用SSH 进行远程连接。通过SSH 客户端软件连接Linux,在Linux 下利用以下命令连接其他Linux: 　　[root@redhat root]# ssh -l root 　　192.168.2.180 　　(9)禁止随意通过su 命令将普通用户变为root 用户。编辑/etc/pam.d/su,加入以下内容： 　　auth sufficient /lib/security/pam_ 　　rootok.so debug 　　auth required /lib/security/pam_ 　　wheel.so group=wheel 　　wheel 为系统中隐含的组，只有wheel 组的成员才能用su 命令成为root. 　　(10)配置防火墙，并随时关注Linux 网站上内核更新，保持最新的系统内核。   摘自：http://os.chinaunix.net/a2012/0829/1391/000001391013.shtml","title":"Linux操作系统的安全模块要点分析"},{"content":"netlink 资源释放函数 sock_release(my_nfd->sk_socket) 在高版本内核会导致死机。 现修改成： #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,25)        netlink_kernel_release(my_nfd);#else        sock_release(my_nfd->sk_socket);#endif 2.6.25  include/linux/netlink.h extern void netlink_kernel_release(struct sock *sk);  而 2.6.24 include/linux/netlink.h 没有此函数， 对应的 sock_release(struct socket *sock) 却位于 net.h 中。 可见 void netlink_kernel_release(struct sock *sk); 是linux kernel 2.6.25 新增函数且2.6.25 （含）以后内核netlink不可再使用 sock_release(struct socket *sock)","title":"netlink 释放导致死机问题"},{"content":"引言 “Oops，系统挂死了...\" “Oops，程序崩溃了...\" “Oops，命令执行报错...\" 对于维护人员来说，这样的悲剧每天都在上演。理想情况下，系统或应用程序的错误日志提供了足够全面的信息，通过查看相关日志，维护人员就能很快地定位出问题发生的原因。但现实情况，许多错误日志打印模凌两可，更多地描述了出错时的现象(比如\"could not open file\"，\"connect to XXX time out\")，而非出错的原因。 错误日志不能满足定位问题的需求，我们能从更“深层”的方面着手分析吗？程序或命令的执行，需要通过系统调用(system call)与操作系统产生交互，其实我们可以通过观察这些系统调用及其参数、返回值，界定出错的范围，甚至找出问题出现的根因。 在Linux中，strace就是这样一款工具。通过它，我们可以跟踪程序执行过程中产生的系统调用及接收到的信号，帮助我们分析程序或命令执行中遇到的异常情况。 一个简单的例子 如何使用strace对程序进行跟踪，如何查看相应的输出？下面我们通过一个例子来说明。 1.被跟踪程序示例 //main.c #include <sys/types.h> #include <sys/stat.h> #include <fcntl.h> int main( ) { 　　int fd ; 　　int i = 0 ; 　　fd = open( “/tmp/foo”, O_RDONLY ) ; 　　if ( fd < 0 ) 　　　　i=5; 　　else 　　　　i=2; 　　return i; }   以上程序尝试以只读的方式打开/tmp/foo文件，然后退出，其中只使用了open这一个系统调用函数。之后我们对该程序进行编译，生成可执行文件： lx@LX:~$ gcc main.c -o main   2.strace跟踪输出 使用以下命令，我们将使用strace对以上程序进行跟踪，并将结果重定向至main.strace文件： lx@LX:~$ strace -o main.strace ./main 接下来我们来看main.strace文件的内容： lx@LX:~$ cat main.strace 1 execve(\"./main\", [\"./main\"], [/* 43 vars */]) = 0 2 brk(0)                                  = 0x9ac4000 3 access(\"/etc/ld.so.nohwcap\", F_OK)      = -1 ENOENT (No such file or directory) 4 mmap2(NULL, 8192, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7739000 5 access(\"/etc/ld.so.preload\", R_OK)      = -1 ENOENT (No such file or directory) 6 open(\"/etc/ld.so.cache\", O_RDONLY)      = 3 7 fstat64(3, {st_mode=S_IFREG|0644, st_size=80682, ...}) = 0 8 mmap2(NULL, 80682, PROT_READ, MAP_PRIVATE, 3, 0) = 0xb7725000 9 close(3)                                = 0 10 access(\"/etc/ld.so.nohwcap\", F_OK)      = -1 ENOENT (No such file or directory) 11 open(\"/lib/i386-linux-gnu/libc.so.6\", O_RDONLY) = 3 12 read(3, \"\\177ELF\\1\\1\\1\\0\\0\\0\\0\\0\\0\\0\\0\\0\\3\\0\\3\\0\\1\\0\\0\\0\\220o\\1\\0004\\0\\0\\0\"..., 512) = 512 13 fstat64(3, {st_mode=S_IFREG|0755, st_size=1434180, ...}) = 0 14 mmap2(NULL, 1444360, PROT_READ|PROT_EXEC, MAP_PRIVATE|MAP_DENYWRITE, 3, 0) = 0x56d000 15 mprotect(0x6c7000, 4096, PROT_NONE)     = 0 16 mmap2(0x6c8000, 12288, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_DENYWRITE, 3, 0x15a) = 0x6c8000 17 mmap2(0x6cb000, 10760, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_FIXED|MAP_ANONYMOUS, -1, 0) = 0x6cb000 18 close(3)                                = 0 19 mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb7724000 20 set_thread_area({entry_number:-1 -> 6, base_addr:0xb77248d0, limit:1048575, seg_32bit:1, contents:0, read_exec_    only:0, limit_in_pages:1, seg_not_present:0, useable:1}) = 0 21 mprotect(0x6c8000, 8192, PROT_READ)     = 0 22 mprotect(0x8049000, 4096, PROT_READ)    = 0 23 mprotect(0x4b0000, 4096, PROT_READ)     = 0 24 munmap(0xb7725000, 80682)               = 0 25 open(\"/tmp/foo\", O_RDONLY)              = -1 ENOENT (No such file or directory) 26 exit_group(5)                           = ? //标红的行号为方便说明而添加，非strace执行输出   看到这一堆输出，是否心生畏难情绪？不用担心，下面我们对输出逐条进行分析。 strace跟踪程序与系统交互时产生的系统调用，以上每一行就对应一个系统调用，格式为： 系统调用的名称( 参数... ) = 返回值 错误标志和描述 Line 1: 对于命令行下执行的程序，execve(或exec系列调用中的某一个)均为strace输出系统调用中的第一个。strace首先调用fork或clone函数新建一个子进程，然后在子进程中调用exec载入需要执行的程序(这里为./main) Line 2: 以0作为参数调用brk，返回值为内存管理的起始地址(若在子进程中调用malloc，则从0x9ac4000地址开始分配空间) Line 3: 调用access函数检验/etc/ld.so.nohwcap是否存在 Line 4: 使用mmap2函数进行匿名内存映射，以此来获取8192bytes内存空间，该空间起始地址为0xb7739000，关于匿名内存映射，可以看这里 Line 6: 调用open函数尝试打开/etc/ld.so.cache文件，返回文件描述符为3 Line 7: fstat64函数获取/etc/ld.so.cache文件信息 Line 8: 调用mmap2函数将/etc/ld.so.cache文件映射至内存，关于使用mmap映射文件至内存，可以看这里 Line 9: close关闭文件描述符为3指向的/etc/ld.so.cache文件 Line12: 调用read，从/lib/i386-linux-gnu/libc.so.6该libc库文件中读取512bytes，即读取ELF头信息 Line15: 使用mprotect函数对0x6c7000起始的4096bytes空间进行保护(PROT_NONE表示不能访问，PROT_READ表示可以读取) Line24: 调用munmap函数，将/etc/ld.so.cache文件从内存中去映射，与Line 8的mmap2对应 Line25: 对应源码中使用到的唯一的系统调用——open函数，使用其打开/tmp/foo文件 Line26: 子进程结束，退出码为5(为什么退出值为5？返回前面程序示例部分看看源码吧：)   3.输出分析 呼呼！看完这么多系统调用函数，是不是有点摸不着北？让我们从整体入手，回到主题strace上来。 从上面输出可以发现，真正能与源码对应上的只有open这一个系统调用(Line25)，其他系统调用几乎都用于进行进程初始化工作：装载被执行程序、载入libc函数库、设置内存映射等。 源码中的if语句或其他代码在相应strace输出中并没有体现，因为它们并没有唤起系统调用。strace只关心程序与系统之间产生的交互，因而strace不适用于程序逻辑代码的排错和分析。 对于Linux中几百个系统调用，上面strace输出的几个只是冰山一角，想要更深入地了解Linux系统调用，那就man一下吧！ man 2 系统调用名称 man ld.so  //Linux动态链接的manpage   strace常用选项 该节介绍经常用到的几个strace命令选项，以及在何时使用这些选项合适。 1.跟踪子进程 默认情况下，strace只跟踪指定的进程，而不对指定进程中新建的子进程进行跟踪。使用-f选项，可对进程中新建的子进程进行跟踪，并在输出结果中打印相应进程PID： mprotect(0x5b1000, 4096, PROT_READ)     = 0 munmap(0xb77fc000, 80682)               = 0 clone(Process 13600 attached child_stack=0, flags=CLONE_CHILD_CLEARTID|CLONE_CHILD_SETTID|SIGCHLD, child_tidptr=0xb77fb938) = 13600 [pid 13599] fstat64(1, {st_mode=S_IFCHR|0620, st_rdev=makedev(136, 0), ...}) = 0 [pid 13600] fstat64(1, {st_mode=S_IFCHR|0620, st_rdev=makedev(136, 0), ...}) = 0 [pid 13599] mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0 <unfinished ...> [pid 13600] mmap2(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0xb780f000 ……   对多进程程序、命令和脚本使用strace进行跟踪的时，一般打开-f选项。   2.记录系统调用时间 strace还可以记录程序与系统交互时，各个系统调用发生时的时间信息，有r、t、tt、ttt、T等几个选项，它们记录时间的方式为： -T: 记录各个系统调用花费的时间，精确到微秒 -r: 以第一个系统调用(通常为execve)计时，精确到微秒 -t: 时：分：秒 -tt: 时：分：秒. 微秒 -ttt: 计算机纪元以来的秒数. 微秒 比较常用的为T选项，因为其提供了每个系统调用花费时间。而其他选项的时间记录既包含系统调用时间，又算上用户级代码执行用时，参考意义就小一些。对部分时间选项我们可以组合起来使用，例如： strace -Tr ./main 0.000000 execve(“./main”, [“main”], [/* 64 vars */]) = 0 0.000931 fcntl64(0, F_GETFD)= 0 <0.000012> 0.000090 fcntl64(1, F_GETFD)= 0 <0.000022> 0.000060 fcntl64(2, F_GETFD)= 0 <0.000012> 0.000054 uname({sys=”Linux”, node=”ion”, ...}) = 0 <0.000014> 0.000307 geteuid32()= 7903 <0.000011> 0.000040 getuid32()= 7903 <0.000012> 0.000039 getegid32()= 200 <0.000011> 0.000039 getgid32()= 200 <0.000011> ……   最左边一列为-r选项对应的时间输出，最右边一列为-T选项对应的输出。   3.跟踪正在运行的进程 使用strace对运行中的程序进行跟踪，使用命令“strace -p PID”即可，命令执行之后，被跟踪的进程照常执行，strace的其他选项也适用于运行中的进程跟踪。 使用strace处理程序挂死 最后我们通过一个程序示例，学习使用strace分析程序挂死的方法。 1.挂死程序源码 //hang.c #include <stdio.h> #include <sys/types.h> #include <unistd.h> #include <string.h>   int main(int argc, char** argv) {     getpid(); //该系统调用起到标识作用     if(argc < 2)     {         printf(\"hang (user|system)\\n\");         return 1;     }     if(!strcmp(argv[1], \"user\"))         while(1);     else if(!strcmp(argv[1], \"system\"))         sleep(500);     return 0; }   可向该程序传送user和system参数，以上代码使用死循环模拟用户态挂死，调用sleep模拟内核态程序挂死。   2.strace跟踪输出 用户态挂死跟踪输出： lx@LX:~$ gcc hang.c -o hang lx@LX:~$ strace ./hang user …… mprotect(0x8049000, 4096, PROT_READ)    = 0 mprotect(0xb59000, 4096, PROT_READ)     = 0 munmap(0xb77bf000, 80682)               = 0 getpid()                                = 14539   内核态挂死跟踪输出： lx@LX:~$ strace ./hang system …… mprotect(0x8049000, 4096, PROT_READ)    = 0 mprotect(0xddf000, 4096, PROT_READ)     = 0 munmap(0xb7855000, 80682)               = 0 getpid()                                = 14543 rt_sigprocmask(SIG_BLOCK, [CHLD], [], 8) = 0 rt_sigaction(SIGCHLD, NULL, {SIG_DFL, [], 0}, 8) = 0 rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0 nanosleep({500, 0},   3.输出分析 用户态挂死情况下，strace在getpid()一行输出之后没有其他系统调用输出；进程在内核态挂死，最后一行的系统调用nanosleep不能完整显示，这里nanosleep没有返回值表示该调用尚未完成。 因而我们可以得出以下结论：使用strace跟踪挂死程序，如果最后一行系统调用显示完整，程序在逻辑代码处挂死；如果最后一行系统调用显示不完整，程序在该系统调用处挂死。 当程序挂死在系统调用处，我们可以查看相应系统调用的man手册，了解在什么情况下该系统调用会出现挂死情况。另外，系统调用的参数也为我们提供了一些信息，例如挂死在如下系统调用： read(16, 那我们可以知道read函数正在对文件描述符为16的文件或socket进行读取，进一步地，我们可以使用lsof工具，获取对应于文件描述符为16的文件名、该文件被哪些进程占用等信息。 小结 本文对Linux中常用的问题诊断工具strace进行了介绍，通过程序示例，介绍了strace的使用方法、输出格式以及使用strace分析程序挂死问题的方法，另外对strace工具的几个常用选项进行了说明，描述了这几个选项适用的场景。 下次再遇到程序挂死、命令执行报错的问题，如果从程序日志和系统日志中看不出问题出现的原因，先别急着google或找高手帮忙，别忘了一个强大的工具它就在那里，不离不弃，strace一下吧","title":"Linux问题诊断工具strace"},{"content":"借助grub开机管理程序使用单人维护模式： 读秒时按任意键，再按【e】光标移动到kernel，再按【e】 最后放输入【single】，再按确定后按【b】，就可以使用\"passwd\"命令修改密码了","title":"Linux 修改 root 密码"},{"content":"大概看了一遍LDD，从今天开始动手实践，下面给出linux内核模块开发入门的代码，helloworld。 hello.c   #include <linux/init.h>#include <linux/module.h>MODULE_LICENSE(\"Dual BSD/GPL\");static int __init hello_init(){\tprintk(KERN_ALERT \"Hello, kernel world\\n\");\treturn 0;}static void __exit hello_exit(){\tprintk(KERN_ALERT \"Goodbye, cruel world\\n\");}module_init(hello_init);module_exit(hello_exit);   有几点说明： 1、模块应该指定代码所使用的许可证，如\"GPL\"； 2、初始化函数应该被声明为static，因为这种函数在特定文件之外没有其他意义，static可以帮助实现局部隐藏； 3、__init标记暗示该函数仅在初始化期间使用，模块装载之后，该函数会被模块装载器扔掉，函数占用的内存也会被相应释放； 4、module_init这个宏会在模块的目标代码中增加一个特殊的段，用于说明模块初始化函数所在的位置，调用初始化函数。   makefile如下   ifneq ($(KERNELRELEASE),)\tobj-m := hello.oelse\tKERNELDIR ?= /lib/modules/$(shell uname -r)/build\tPWD := $(shell pwd)default:\t$(MAKE) -C $(KERNELDIR) M=$(PWD) modulesclean:\trm -rf *.ko *.o *~ core .depend .*.cmd *.mod.c *.tmp_versions *.symvers.tmp_versionsendif   几点说明： 1、Makefile中的命令前一定要加tab，否则会报错； 2、实际上调用的make modules的命令定义在KERNELDIR下的makefile中，所以要通过-C指定这个路径。 3、makefile中的选项是用make xxx执行的，直接make默认执行第一个。 4、:=是第一次初始化赋值，?=类似三目运算符，如果已经定义了就不再赋值，否则初始化，引用多字母变量需要加上$(varname)   使用insmod加载模块，rmmod卸载模块： sudo insmod hello.ko sudo rmmod hello 可以用dmesg查看打出的信息。    补充： 如果需要对模块传递参数，应该使用如下代码：   static int iVar = 1;static char* sVar = \"string\";module_param(iVar, int, S_IRUGO);module_param(sVar, charp, S_IRUGO); 并且加载模块时使用 insmod hello iVar=10 sVar=\"mystring\"","title":"Linux驱动学习(一)——简单的hello模块"},{"content":"Fixing Authentication refused: bad ownership or modes for directory From HowToGeek Jump to: navigation, search If you get this error in your logs when trying to setup public key authenticated automatic logins, the problem is a permissions one. You'll need to perform the following commands on the user account you are trying to setup: chmod go-w ~/chmod 700 ~/.sshchmod 600 ~/.ssh/authorized_keys","title":"Fixing Authentication refused: bad ownership or modes for directory"},{"content":"   运行在Linux系统上的Java程序可能会出现\"Too many open files\"的异常情况，且常见于高并发访问文件系统，多线程网络连接等场景。         程序经常访问的文件、socket在Linux中都是文件file，系统需要记录每个当前访问file的name、location、access authority等相关信息，这样的一个实体被称为file entry。“open files table”(图中橙色标识)存储这些file entry，以数组的形式线性管理。文件描述符(file descriptor)作为进程到open files table的指针，也就是open files table的下标索引，将每个进程与它所访问的文件关联起来了。         每个进程中都有一个file descriptor table管理当前进程所访问(open orcreate)的所有文件，文件描述符关联着open files table中文件的file entry。细节不表，对于open files table能容纳多少file entry。Linux系统配置open files table的文件限制，如果超过配置值，就会拒绝其它文件操作的请求，并抛出Too many open files异常。这种限制有系统级和用户级之分。        系统级：                 系统级设置对所有用户有效。可通过两种方式查看系统最大文件限制                 1  cat /proc/sys/fs/file-max                  2  sysctl -a 查看结果中fs.file-max这项的配置数量                 如果需要增加配置数量就修改/etc/sysctl.conf文件，配置fs.file-max属性，如果属性不存在就添加。                 配置完成后使用sysctl -p来通知系统启用这项配置        用户级：                 Linux限制每个登录用户的可连接文件数。可通过  ulimit -n来查看当前有效设置。如果想修改这个值就使用ulimit -n <setting number> 命令。                另外需要修改两个文件：               1. 编辑文件/etc/sysctl.conf，插入下行：                fs.file-max = 8192               2. 编辑文件/etc/security/limits.conf，在 #<domain>  <type>  <item>  <value>  后插入下行：                * - nofile 8192                   对于文件描述符增加的比例，资料推荐是以2的幂次为参考。如当前文件描述符数量是1024，可增加到2048，如果不够，可设置到4096，依此类推。        在出现Too many open files问题后，首先得找出主要原因。最大的可能是打开的文件或是socket没有正常关闭。为了定位问题是否由Java进程引起，通过Java进程号查看当前进程占用文件描述符情况： Java代码   lsof -p $java_pid 每个文件描述符的具体属性   lsof -p $java_pid | wc -l  当前Java进程file descriptor table中FD的总量           分析命令的结果，可判断问题是否由非正常释放资源所引起。 文章转自：http://langyu.iteye.com/blog/763247","title":"详解 Too many open files"},{"content":"yum -y install gcc gcc-c++ gcc-g77 flex bison autoconf automake bzip2-devel zlib-devel ncurses-devel libjpeg-devel libpng-devel libtiff-devel freetype-devel pam-devel","title":"安装centos开发包"},{"content":"  list命令后显示No symbol table is loaded. Use the \"file\" command. 原来编译用：gcc -o filename filename.c 解决办法，编译时加 一定要加-g:gcc -o filename -g filename.c   使用 GDB 调试程序之前，必须使用 -g 选项编译源文件。可在 makefile 中如下定义 CFLAGS 变量：CFLAGS = -g ，这样list命令才能列出源代码。","title":"解决gdb list No symbol table提示"},{"content":"mkdosfs 把分区信息写进磁盘．(三) 以扇区大小为单位，分几步走： 一，保留扇区 1:清空保留扇区，(即FATS表之前的所有扇区清零，包括启动扇区,信息扇区,启动扇区备份,除以上其它的保留扇区)  reserved sector． 2:启动扇区，boot sector．　(0--------511) 3:如果是FAT32,写信息扇区，info sector ．  (512------1023) 4.如果是FAT32,且有设置有保留启动扇区备份，写备份启动扇区，backup boot sector．　(backup_boot*512-------backup_boot*512+512) 二，FATS表 5.跟着保留扇区的是第一个FAT表，把第一个FAT表清零．first fat sector .    (backup_boot*512+512) ----- ((backup_boot*512+512) + (blank_fat_length*512)) 6.跟着第一个FAT表后的是第二个FAT表，把第二个FAT表清零．　second fat sector .    ((backup_boot*512+512) + (blank_fat_length*512)) -------(((backup_boot*512+512) + (blank_fat_length*512))+(blank_fat_length*512)) 三．根目录项 7.跟着第二个FAT表的是根目录项，root directory　　　(((backup_boot*512+512) + (blank_fat_length*512))+(blank_fat_length*512)) ------((((backup_boot*512+512) + (blank_fat_length*512))+(blank_fat_length*512))+(size_root_dir*512)) static void write_tables(void) {     int x;     int fat_length;     fat_length = (size_fat == 32) ?  CF_LE_L(bs.fat32.fat32_length) : CF_LE_W(bs.fat_length);     seekto(0, \"start of device\");     /* clear all reserved sectors */     for (x = 0; x < reserved_sectors; ++x)  writebuf(blank_sector, sector_size, \"reserved sector\");     /* seek back to sector 0 and write the boot sector */     seekto(0, \"boot sector\");     writebuf((char *)&bs, sizeof(struct msdos_boot_sector), \"boot sector\");     printf(\"sizeof(struct msdos_boot_sector) = %d\\n\",sizeof(struct msdos_boot_sector));   //sizeof(struct msdos_boot_sector) = 512     /* on FAT32, write the info sector and backup boot sector */     if (size_fat == 32) {  seekto(CF_LE_W(bs.fat32.info_sector) * sector_size, \"info sector\");     printf(\"bs.fat32.info_sector = %d,sector_size = %d\\n\",bs.fat32.info_sector,sector_size);  //bs.fat32.info_sector = 1,sector_size = 512  writebuf(info_sector, 512, \"info sector\");     printf(\"backup_boot  = %d\\n\",backup_boot);    //backup_boot  = 6  if (backup_boot != 0) {      seekto(backup_boot * sector_size, \"backup boot sector\");      writebuf((char *)&bs, sizeof(struct msdos_boot_sector),        \"backup boot sector\");  }     }     /* seek to start of FATS and write them all */     seekto(reserved_sectors * sector_size, \"first FAT\");     printf(\"reserved_sectors = %d,sector_size = %d\\n\",reserved_sectors,sector_size);    //reserved_sectors = 32,sector_size = 512     for (x = 1; x <= nr_fats; x++) {  int y;  int blank_fat_length = fat_length - alloced_fat_length;  writebuf(fat, alloced_fat_length * sector_size, \"FAT\");     printf(\"alloced_fat_length = %d , sector_size = %d\\n\",alloced_fat_length , sector_size);  //alloced_fat_length = 1 , sector_size = 512     printf(\"blank_fat_length  = %d\\n\",blank_fat_length);    //blank_fat_length  = 16351  for (y = 0; y < blank_fat_length; y++)      writebuf(blank_sector, sector_size, \"FAT\");     }     /* Write the root directory directly after the last FAT. This is the root      * dir area on FAT12/16, and the first cluster on FAT32. */     printf(\"size_root_dir = %d\\n\",size_root_dir );     //size_root_dir = 4096     writebuf((char *)root_dir, size_root_dir, \"root directory\");     if (blank_sector)  free(blank_sector);     if (info_sector)  free(info_sector);     free(root_dir);  /* Free up the root directory space from setup_tables */     free(fat);   /* Free up the fat table space reserved during setup_tables */ }","title":"mkdosfs 把分区信息写进磁盘．(三)"},{"content":"mkdosfs 建立硬盘启动扇区参数 （bs结构体 二) /* Create the filesystem data tables */ static void setup_tables(void) {     unsigned num_sectors;     unsigned cluster_count = 0, fat_length;     struct tm *ctime;     struct msdos_volume_info *vi =  (size_fat == 32 ? &bs.fat32.vi : &bs.oldfat.vi); //设置vi指针     if (atari_format)   //atari_format = 0  /* On Atari, the first few bytes of the boot sector are assigned   * differently: The jump code is only 2 bytes (and m68k machine code   * :-), then 6 bytes filler (ignored), then 3 byte serial number. */  memcpy(bs.system_id - 1, \"mkdosf\", 6);     else  strcpy((char *)bs.system_id, \"mkdosfs\");     if (sectors_per_cluster)　　// 每簇扇区数sectors_per_cluster暂时为０  bs.cluster_size = (char)sectors_per_cluster;     if (size_fat == 32) {  /* Under FAT32, the root dir is in a cluster chain, and this is   * signalled by bs.dir_entries being 0. */  root_dir_entries = 0;     }     if (atari_format) {  bs.system_id[5] = (unsigned char)(volume_id & 0x000000ff);  bs.system_id[6] = (unsigned char)((volume_id & 0x0000ff00) >> 8);  bs.system_id[7] = (unsigned char)((volume_id & 0x00ff0000) >> 16);     } else {  vi->volume_id[0] = (unsigned char)(volume_id & 0x000000ff);  vi->volume_id[1] = (unsigned char)((volume_id & 0x0000ff00) >> 8);  vi->volume_id[2] = (unsigned char)((volume_id & 0x00ff0000) >> 16);  vi->volume_id[3] = (unsigned char)(volume_id >> 24);     printf(\"volume_id = 0x%08lx,,vi->volume_id[0] = 0x%02x,vi->volume_id[1] = 0x%02x,vi->volume_id[2] = 0x%02x,vi->volume_id[3] = 0x%02x\\n\",volume_id,vi->volume_id[0],vi->volume_id[1],vi->volume_id[2],vi->volume_id[3]); //volume_id = 0x0fee11bb,,vi->volume_id[0] = 0xbb,vi->volume_id[1] = 0x11,vi->volume_id[2] = 0xee,vi->volume_id[3] = 0x0f  //volume_id 是一个随机值．     }     if (!atari_format) {  memcpy(vi->volume_label, volume_name, 11);     printf(\"volume_name = [%s]\\n\",volume_name);//volume_name = [           ]  memcpy(bs.boot_jump, dummy_boot_jump, 3);  //char dummy_boot_jump[3] = { 0xeb, 0x3c, 0x90 }; 这三个字节是汇编跳转指令．  /* Patch in the correct offset to the boot code */  bs.boot_jump[1] = ((size_fat == 32 ?        (char *)&bs.fat32.boot_code :        (char *)&bs.oldfat.boot_code) - (char *)&bs) - 2;   //启动代码的偏移地址赋值给第二个字节．  if (size_fat == 32) {      int offset = (char *)&bs.fat32.boot_code -   (char *)&bs + MESSAGE_OFFSET + 0x7c00;      if (dummy_boot_code[BOOTCODE_FAT32_SIZE - 1])   printf(\"Warning: message too long; truncated\\n\");      dummy_boot_code[BOOTCODE_FAT32_SIZE - 1] = 0;      memcpy(bs.fat32.boot_code, dummy_boot_code, BOOTCODE_FAT32_SIZE); //BOOTCODE_FAT32_SIZE = 420 ,将默认的启动代码dummy_boot_code拷到bs.fat32.boot_code里．         printf(\"dummy_boot_code:%s\\n\",dummy_boot_code);      bs.fat32.boot_code[MSG_OFFSET_OFFSET] = offset & 0xff;    //MSG_OFFSET_OFFSET  = 3      bs.fat32.boot_code[MSG_OFFSET_OFFSET + 1] = offset >> 8;   //将默认启动代码的前４２０字节，计算好了的偏移量，赋给bs.fat32.boot_code的第３第４个字节进行更改．  } else {      memcpy(bs.oldfat.boot_code, dummy_boot_code, BOOTCODE_SIZE);  }  bs.boot_sign = CT_LE_W(BOOT_SIGN);    //0xAA55 结束，启动扇区标记忆　．小端存储变成　55  AA.     } else {  memcpy(bs.boot_jump, dummy_boot_jump_m68k, 2);     }     if (verbose >= 2)  printf(\"Boot jump code is %02x %02x\\n\",         bs.boot_jump[0], bs.boot_jump[1]);     if (!reserved_sectors)   //未通过mkdosfs -R 设置．reserved_sectors = 0        reserved_sectors = (size_fat == 32) ? 32 : 1;   //保留扇区数为３２     else {  if (size_fat == 32 && reserved_sectors < 2)      die(\"On FAT32 at least 2 reserved sectors are needed.\");     }     bs.reserved = CT_LE_W(reserved_sectors);     if (verbose >= 2)  printf(\"Using %d reserved sectors\\n\", reserved_sectors);     bs.fats = (char)nr_fats;    //nr_fats 未通过mkdosfs -f 设置．默认为２.　bs.fats = 2 个fats表．     if (!atari_format || size_fat == 32)  bs.hidden = CT_LE_L(hidden_sectors);     //隐藏扇区 未通过mkdosfs -h设置．默认为０.     else {  /* In Atari format, hidden is a 16 bit field */  __u16 hidden = CT_LE_W(hidden_sectors);  if (hidden_sectors & ~0xffff)      die(\"#hidden doesn't fit in 16bit field of Atari format\\n\");  memcpy(&bs.hidden, &hidden, 2);     }     num_sectors = (long long)(blocks *BLOCK_SIZE / sector_size)+orphaned_sectors;  //总扇区数　＝　总块数＊1024／512　＋　最后一块未能包含一扇区数．     if (!atari_format) {  unsigned fatdata1216; /* Sectors for FATs + data area (FAT12/16) */  unsigned fatdata32; /* Sectors for FATs + data area (FAT32) */  unsigned fatlength12, fatlength16, fatlength32;  unsigned maxclust12, maxclust16, maxclust32;  unsigned clust12, clust16, clust32;  int maxclustsize;  unsigned root_dir_sectors = cdiv(root_dir_entries * 32, sector_size);  /*   * If the filesystem is 8192 sectors or less (4 MB with 512-byte   * sectors, i.e. floppy size), don't align the data structures.   */  if (num_sectors <= 8192) { 　　　　　　　 //扇区数小于8192 ,就不进行对齐．      if (align_structures && verbose >= 2)   printf(\"Disabling alignment due to tiny filesystem\\n\");      align_structures = FALSE;  }  if (sectors_per_cluster)     //sectors_per_cluster 每簇的扇区数未通过mkdosfs -s设置，默认为０．      bs.cluster_size = maxclustsize = sectors_per_cluster;  else      /* An initial guess for bs.cluster_size should already be set */      maxclustsize = 128; printf(\"1111111111111111111111\\n\");  do {　　　　　//这个do while 循环是找找出合适的簇大小．      fatdata32 = num_sectors   - align_object(reserved_sectors, bs.cluster_size);      fatdata1216 = fatdata32   - align_object(root_dir_sectors, bs.cluster_size); printf(\"2222222222222222222222\\n\");      if (verbose >= 2)   printf(\"Trying with %d sectors/cluster:\\n\", bs.cluster_size);      /* The factor 2 below avoids cut-off errors for nr_fats == 1.       * The \"nr_fats*3\" is for the reserved first two FAT entries */      clust12 = 2 * ((long long)fatdata1216 * sector_size + nr_fats * 3) /   (2 * (int)bs.cluster_size * sector_size + nr_fats * 3);      fatlength12 = cdiv(((clust12 + 2) * 3 + 1) >> 1, sector_size);      fatlength12 = align_object(fatlength12, bs.cluster_size);      /* Need to recalculate number of clusters, since the unused parts of the       * FATS and data area together could make up space for an additional,       * not really present cluster. */      clust12 = (fatdata1216 - nr_fats * fatlength12) / bs.cluster_size;      maxclust12 = (fatlength12 * 2 * sector_size) / 3;      if (maxclust12 > MAX_CLUST_12)   maxclust12 = MAX_CLUST_12;      if (verbose >= 2)   printf(\"FAT12: #clu=%u, fatlen=%u, maxclu=%u, limit=%u\\n\",          clust12, fatlength12, maxclust12, MAX_CLUST_12);      if (clust12 > maxclust12 - 2) {   clust12 = 0;   if (verbose >= 2)       printf(\"FAT12: too much clusters\\n\");      }      clust16 = ((long long)fatdata1216 * sector_size + nr_fats * 4) /   ((int)bs.cluster_size * sector_size + nr_fats * 2);      fatlength16 = cdiv((clust16 + 2) * 2, sector_size);      fatlength16 = align_object(fatlength16, bs.cluster_size);      /* Need to recalculate number of clusters, since the unused parts of the       * FATS and data area together could make up space for an additional,       * not really present cluster. */      clust16 = (fatdata1216 - nr_fats * fatlength16) / bs.cluster_size;      maxclust16 = (fatlength16 * sector_size) / 2;      if (maxclust16 > MAX_CLUST_16)   maxclust16 = MAX_CLUST_16;      if (verbose >= 2)   printf(\"FAT16: #clu=%u, fatlen=%u, maxclu=%u, limit=%u\\n\",          clust16, fatlength16, maxclust16, MAX_CLUST_16);      if (clust16 > maxclust16 - 2) {   if (verbose >= 2)       printf(\"FAT16: too much clusters\\n\");   clust16 = 0;      }      /* The < 4078 avoids that the filesystem will be misdetected as having a       * 12 bit FAT. */      if (clust16 < FAT12_THRESHOLD   && !(size_fat_by_user && size_fat == 16)) {   if (verbose >= 2)       printf(clust16 < FAT12_THRESHOLD ?       \"FAT16: would be misdetected as FAT12\\n\" :       \"FAT16: too much clusters\\n\");   clust16 = 0;      }      clust32 = ((long long)fatdata32 * sector_size + nr_fats * 8) /   ((int)bs.cluster_size * sector_size + nr_fats * 4);      fatlength32 = cdiv((clust32 + 2) * 4, sector_size);      fatlength32 = align_object(fatlength32, bs.cluster_size);      /* Need to recalculate number of clusters, since the unused parts of the       * FATS and data area together could make up space for an additional,       * not really present cluster. */      clust32 = (fatdata32 - nr_fats * fatlength32) / bs.cluster_size;      maxclust32 = (fatlength32 * sector_size) / 4;      if (maxclust32 > MAX_CLUST_32)   maxclust32 = MAX_CLUST_32;      if (clust32 && clust32 < MIN_CLUST_32   && !(size_fat_by_user && size_fat == 32)) {   clust32 = 0;   if (verbose >= 2)       printf(\"FAT32: not enough clusters (%d)\\n\", MIN_CLUST_32);      }      if (verbose >= 2)   printf(\"FAT32: #clu=%u, fatlen=%u, maxclu=%u, limit=%u\\n\",          clust32, fatlength32, maxclust32, MAX_CLUST_32);      if (clust32 > maxclust32) {   clust32 = 0;   if (verbose >= 2)       printf(\"FAT32: too much clusters\\n\");      }      if ((clust12 && (size_fat == 0 || size_fat == 12)) ||   (clust16 && (size_fat == 0 || size_fat == 16)) ||   (clust32 && size_fat == 32))   break;      bs.cluster_size <<= 1;  } while (bs.cluster_size && bs.cluster_size <= maxclustsize); printf(\"3333333333333333333333\\n\");  /* Use the optimal FAT size if not specified;   * FAT32 is (not yet) choosen automatically */  if (!size_fat) {     //未设置就设置一下．      size_fat = (clust16 > clust12) ? 16 : 12;      if (verbose >= 2)   printf(\"Choosing %d bits for FAT\\n\", size_fat);  } printf(\"4444444444444444444444size_fat = %d\\n\",size_fat);  switch (size_fat) {  case 12:      cluster_count = clust12;      fat_length = fatlength12;      bs.fat_length = CT_LE_W(fatlength12);      memcpy(vi->fs_type, MSDOS_FAT12_SIGN, 8);      break;  case 16:      if (clust16 < FAT12_THRESHOLD) {   if (size_fat_by_user) {       fprintf(stderr, \"WARNING: Not enough clusters for a \"        \"16 bit FAT! The filesystem will be\\n\"        \"misinterpreted as having a 12 bit FAT without \"        \"mount option \\\"fat=16\\\".\\n\");   } else {       fprintf(stderr, \"This filesystem has an unfortunate size. \"        \"A 12 bit FAT cannot provide\\n\"        \"enough clusters, but a 16 bit FAT takes up a little \"        \"bit more space so that\\n\"        \"the total number of clusters becomes less than the \"        \"threshold value for\\n\"        \"distinction between 12 and 16 bit FATs.\\n\");       die(\"Make the file system a bit smaller manually.\");   }      }      cluster_count = clust16;      fat_length = fatlength16;      bs.fat_length = CT_LE_W(fatlength16);      memcpy(vi->fs_type, MSDOS_FAT16_SIGN, 8);      break;  case 32:      if (clust32 < MIN_CLUST_32)   //#define MIN_CLUST_32    65529   fprintf(stderr,    \"WARNING: Not enough clusters for a 32 bit FAT!\\n\");         printf(\"clust32 = %d,MIN_CLUST_32 = %d\\n\",clust32,MIN_CLUST_32);　　//clust32 = 2092804,MIN_CLUST_32 = 65529      cluster_count = clust32;   //簇总数．      fat_length = fatlength32;      bs.fat_length = CT_LE_W(0);      bs.fat32.fat32_length = CT_LE_L(fatlength32);      memcpy(vi->fs_type, MSDOS_FAT32_SIGN, 8);　　　　//#define MSDOS_FAT32_SIGN \"FAT32   \" 　　　　　/* FAT32 filesystem signature */      root_dir_entries = 0;      break;  default:      die(\"FAT not 12, 16 or 32 bits\");  }  /* Adjust the reserved number of sectors for alignment */  reserved_sectors = align_object(reserved_sectors, bs.cluster_size);  bs.reserved = CT_LE_W(reserved_sectors);     //保留的扇区数．     printf(\"align_structures = %d\\n\",align_structures);  /* Adjust the number of root directory entries to help enforce alignment */  if (align_structures) {　   //未通过mkdosfs -a设置．默认为true ,强制对齐目录项．root_dir_entries　＝　０；      root_dir_entries = align_object(root_dir_sectors, bs.cluster_size)   * (sector_size >> 5);         printf(\"root_dir_entries = %d\\n\",root_dir_entries);  }     } else {  unsigned clusters, maxclust, fatdata;  /* GEMDOS always uses a 12 bit FAT on floppies, and always a 16 bit FAT on   * hard disks. So use 12 bit if the size of the file system suggests that   * this fs is for a floppy disk, if the user hasn't explicitly requested a   * size.   */  if (!size_fat)      size_fat = (num_sectors == 1440 || num_sectors == 2400 ||    num_sectors == 2880 || num_sectors == 5760) ? 12 : 16;  if (verbose >= 2)      printf(\"Choosing %d bits for FAT\\n\", size_fat);  /* Atari format: cluster size should be 2, except explicitly requested by   * the user, since GEMDOS doesn't like other cluster sizes very much.   * Instead, tune the sector size for the FS to fit.   */  bs.cluster_size = sectors_per_cluster ? sectors_per_cluster : 2;  if (!sector_size_set) {      while (num_sectors > GEMDOS_MAX_SECTORS) {   num_sectors >>= 1;   sector_size <<= 1;      }  }  if (verbose >= 2)      printf(\"Sector size must be %d to have less than %d log. sectors\\n\",      sector_size, GEMDOS_MAX_SECTORS);  /* Check if there are enough FAT indices for how much clusters we have */  do {      fatdata = num_sectors - cdiv(root_dir_entries * 32, sector_size) -   reserved_sectors;      /* The factor 2 below avoids cut-off errors for nr_fats == 1 and       * size_fat == 12       * The \"2*nr_fats*size_fat/8\" is for the reserved first two FAT entries       */      clusters =   (2 *    ((long long)fatdata * sector_size -     2 * nr_fats * size_fat / 8)) / (2 * ((int)bs.cluster_size *              sector_size +              nr_fats * size_fat / 8));      fat_length = cdiv((clusters + 2) * size_fat / 8, sector_size);      /* Need to recalculate number of clusters, since the unused parts of the       * FATS and data area together could make up space for an additional,       * not really present cluster. */      clusters = (fatdata - nr_fats * fat_length) / bs.cluster_size;      maxclust = (fat_length * sector_size * 8) / size_fat;      if (verbose >= 2)   printf(\"ss=%d: #clu=%d, fat_len=%d, maxclu=%d\\n\",          sector_size, clusters, fat_length, maxclust);      /* last 10 cluster numbers are special (except FAT32: 4 high bits rsvd);       * first two numbers are reserved */      if (maxclust <=   (size_fat == 32 ? MAX_CLUST_32 : (1 << size_fat) - 0x10)   && clusters <= maxclust - 2)   break;      if (verbose >= 2)   printf(clusters > maxclust - 2 ?          \"Too many clusters\\n\" : \"FAT too big\\n\");      /* need to increment sector_size once more to  */      if (sector_size_set)   die(\"With this sector size, the maximum number of FAT entries \"       \"would be exceeded.\");      num_sectors >>= 1;      sector_size <<= 1;  } while (sector_size <= GEMDOS_MAX_SECTOR_SIZE);  if (sector_size > GEMDOS_MAX_SECTOR_SIZE)      die(\"Would need a sector size > 16k, which GEMDOS can't work with\");  cluster_count = clusters;  if (size_fat != 32)      bs.fat_length = CT_LE_W(fat_length);  else {      bs.fat_length = 0;      bs.fat32.fat32_length = CT_LE_L(fat_length);  }     }     printf(\"sector_size = %d,root_dir_entries = %d\\n\",sector_size,root_dir_entries);   //sector_size = 512,root_dir_entries = 0     bs.sector_size[0] = (char)(sector_size & 0x00ff);     bs.sector_size[1] = (char)((sector_size & 0xff00) >> 8);     bs.dir_entries[0] = (char)(root_dir_entries & 0x00ff);     bs.dir_entries[1] = (char)((root_dir_entries & 0xff00) >> 8);     if (size_fat == 32) {  /* set up additional FAT32 fields */  bs.fat32.flags = CT_LE_W(0);  bs.fat32.version[0] = 0;  bs.fat32.version[1] = 0;  bs.fat32.root_cluster = CT_LE_L(2);  bs.fat32.info_sector = CT_LE_W(1);  if (!backup_boot)     //backup_boot未通过mkdosfs -b设置．默认为0.      backup_boot = (reserved_sectors >= 7) ? 6 :   //保留扇区reserved_sectors　为 32;   (reserved_sectors >= 2) ? reserved_sectors - 1 : 0;  else {      if (backup_boot == 1)   die(\"Backup boot sector must be after sector 1\");      else if (backup_boot >= reserved_sectors)   die(\"Backup boot sector must be a reserved sector\");  }  if (verbose >= 2)      printf(\"Using sector %d as backup boot sector (0 = none)\\n\",      backup_boot);  bs.fat32.backup_boot = CT_LE_W(backup_boot);     printf(\"backup_boot = %d\\n\",backup_boot); 　　　　//backup_boot = 6  memset(&bs.fat32.reserved2, 0, sizeof(bs.fat32.reserved2));     }     if (atari_format) {  /* Just some consistency checks */  if (num_sectors >= GEMDOS_MAX_SECTORS)      die(\"GEMDOS can't handle more than 65531 sectors\");  else if (num_sectors >= OLDGEMDOS_MAX_SECTORS)      printf(\"Warning: More than 32765 sector need TOS 1.04 \"      \"or higher.\\n\");     }     printf(\"num_sectors = %d\\n\",num_sectors);//num_sectors = 16775168     if (num_sectors >= 65536) {  bs.sectors[0] = (char)0;  bs.sectors[1] = (char)0;  bs.total_sect = CT_LE_L(num_sectors);　　　　//扇区总数．     } else {  bs.sectors[0] = (char)(num_sectors & 0x00ff);  bs.sectors[1] = (char)((num_sectors & 0xff00) >> 8);  if (!atari_format)      bs.total_sect = CT_LE_L(0);     }     if (!atari_format)  vi->ext_boot_sign = MSDOS_EXT_SIGN;　　//#define MSDOS_EXT_SIGN 0x29 /* extended boot sector signature */     if (!cluster_count) {  if (sectors_per_cluster) /* If yes, die if we'd spec'd sectors per cluster */      die(\"Too many clusters for file system - try more sectors per cluster\");  else      die(\"Attempting to create a too large file system\");     }     /* The two following vars are in hard sectors, i.e. 512 byte sectors! */     start_data_sector = (reserved_sectors + nr_fats * fat_length) *  (sector_size / HARD_SECTOR_SIZE);     printf(\"reserved_sectors = %d, nr_fats = %d, fat_length = %d, sector_size = %d, HARD_SECTOR_SIZE = %d\\n\",reserved_sectors , nr_fats , fat_length , sector_size , HARD_SECTOR_SIZE);     //reserved_sectors = 32, nr_fats = 2, fat_length = 16352, sector_size = 512, HARD_SECTOR_SIZE = 512     start_data_block = (start_data_sector + SECTORS_PER_BLOCK - 1) /  SECTORS_PER_BLOCK;     if (blocks < start_data_block + 32) /* Arbitrary undersize file system! */  die(\"Too few blocks for viable file system\");     printf(\"verbose = %d\\n\",verbose);    //verbose = 0  ,感觉这一变量是调试用的．     if (verbose) {  printf(\"%s has %d head%s and %d sector%s per track,\\n\",         device_name, CF_LE_W(bs.heads),         (CF_LE_W(bs.heads) != 1) ? \"s\" : \"\", CF_LE_W(bs.secs_track),         (CF_LE_W(bs.secs_track) != 1) ? \"s\" : \"\");  printf(\"logical sector size is %d,\\n\", sector_size);  printf(\"using 0x%02x media descriptor, with %d sectors;\\n\",         (int)(bs.media), num_sectors);  printf(\"file system has %d %d-bit FAT%s and %d sector%s per cluster.\\n\",         (int)(bs.fats), size_fat, (bs.fats != 1) ? \"s\" : \"\",         (int)(bs.cluster_size), (bs.cluster_size != 1) ? \"s\" : \"\");  printf(\"FAT size is %d sector%s, and provides %d cluster%s.\\n\",         fat_length, (fat_length != 1) ? \"s\" : \"\",         cluster_count, (cluster_count != 1) ? \"s\" : \"\");  printf(\"There %s %u reserved sector%s.\\n\",         (reserved_sectors != 1) ? \"are\" : \"is\",         reserved_sectors, (reserved_sectors != 1) ? \"s\" : \"\");  if (size_fat != 32) {      unsigned root_dir_entries =   bs.dir_entries[0] + ((bs.dir_entries[1]) * 256);      unsigned root_dir_sectors =   cdiv(root_dir_entries * 32, sector_size);      printf(\"Root directory contains %u slots and uses %u sectors.\\n\",      root_dir_entries, root_dir_sectors);  }  printf(\"Volume ID is %08lx, \", volume_id &         (atari_format ? 0x00ffffff : 0xffffffff));  if (strcmp(volume_name, \"           \"))      printf(\"volume label %s.\\n\", volume_name);  else      printf(\"no volume label.\\n\");     }     /* Make the file allocation tables! */     printf(\"malloc_entire_fat = %d,alloced_fat_length = %d,fat_length = %d\\n\",malloc_entire_fat,alloced_fat_length,fat_length); //malloc_entire_fat = 0,alloced_fat_length = 0,fat_length = 16352     if (malloc_entire_fat)  alloced_fat_length = fat_length;     else  alloced_fat_length = 1;     if ((fat =   (unsigned char *)malloc(alloced_fat_length * sector_size)) == NULL)  die(\"unable to allocate space for FAT image in memory\");     memset(fat, 0, alloced_fat_length * sector_size);     mark_FAT_cluster(0, 0xffffffff); /* Initial fat entries */     mark_FAT_cluster(1, 0xffffffff);  //前两个簇，初始化，用户只能从第2簇开始。     fat[0] = (unsigned char)bs.media; /* Put media type in first byte! */     if (size_fat == 32) {  /* Mark cluster 2 as EOF (used for root dir) */  mark_FAT_cluster(2, FAT_EOF);  //#define FAT_EOF      (atari_format ? 0x0fffffff : 0x0ffffff8)     }     /* Make the root directory entries */     printf(\"bs.cluster_size = %d , sector_size = %d\\n\",bs.cluster_size , sector_size);   //bs.cluster_size = 8 , sector_size = 512   一个簇＝８扇区＝８＊５１２bytes     size_root_dir = (size_fat == 32) ?  bs.cluster_size * sector_size :  (((int)bs.dir_entries[1] * 256 + (int)bs.dir_entries[0]) *   sizeof(struct msdos_dir_entry));                      //根目录项size_root_dir =bs.cluster_size * sector_size = 8 个簇     if ((root_dir = (struct msdos_dir_entry *)malloc(size_root_dir)) == NULL) {  free(fat);  /* Tidy up before we die! */  die(\"unable to allocate space for root directory in memory\");     }     memset(root_dir, 0, size_root_dir);     //设置磁盘卷名volume_name     if (memcmp(volume_name, \"           \", 11)) {  struct msdos_dir_entry *de = &root_dir[0];　　//struct msdos_dir_entry目录项信息结构体．  memcpy(de->name, volume_name, 8);  memcpy(de->ext, volume_name + 8, 3);  de->attr = ATTR_VOLUME;  ctime = localtime(&create_time);  de->time = CT_LE_W((unsigned short)((ctime->tm_sec >> 1) +          (ctime->tm_min << 5) +          (ctime->tm_hour << 11)));  de->date =      CT_LE_W((unsigned short)(ctime->tm_mday +          ((ctime->tm_mon + 1) << 5) +          ((ctime->tm_year - 80) << 9)));  de->ctime_ms = 0;  de->ctime = de->time;  de->cdate = de->date;  de->adate = de->date;  de->starthi = CT_LE_W(0);  de->start = CT_LE_W(0);  de->size = CT_LE_L(0);     }     if (size_fat == 32) {  /* For FAT32, create an info sector */  struct fat32_fsinfo *info;  if (!(info_sector = malloc(sector_size)))      die(\"Out of memory\");  memset(info_sector, 0, sector_size);  /* fsinfo structure is at offset 0x1e0 in info sector by observation */  info = (struct fat32_fsinfo *)(info_sector + 0x1e0);  /* Info sector magic */  info_sector[0] = 'R';  info_sector[1] = 'R';  info_sector[2] = 'a';  info_sector[3] = 'A';  /* Magic for fsinfo structure */  info->signature = CT_LE_L(0x61417272);  /* We've allocated cluster 2 for the root dir. */  info->free_clusters = CT_LE_L(cluster_count - 1);  info->next_cluster = CT_LE_L(2);       //2簇为根目录．  /* Info sector also must have boot sign */  *(__u16 *) (info_sector + 0x1fe) = CT_LE_W(BOOT_SIGN);     }     if (!(blank_sector = malloc(sector_size)))  die(\"Out of memory\");     memset(blank_sector, 0, sector_size); }","title":"mkdosfs 建立硬盘启动扇区参数 （bs结构体 二)"},{"content":"yum安装apache服务 yum -y install httpd* service httpd start #启动apache服务 service httpd stop #关闭apache服务 service httpd restart #重启apache服务 service httpd reload #重新加载 service httpd status #查看状态 chkconfig httpd on #设置开机启动 chkconfig httpd on #设置开机不启动 chkconfig httpd --level 35 on #设置在3、5上开机启动 修改selinux的状态 vi /etc/selinux/config SELINUX=disabled 编译安装apache 1、yum install ntp vim-enhanced gcc gcc-c++ gcc-g77 flex bison autoconf bzip2-devel ncurses-devel openssl-devel libtool* \\ zlib-devel libxml2-devel libjpeg-devel libpng-devel libtiff-devel fontconfig-devel freetype-devel libXpm-devel \\ gettext-devel curl-devel curl pam-devel e2fsprogs-devel krb5-devel libidn libidn-devel -y 2、apr-1.4.2.tar.gz的安装 # tar -zxvf apr-1.4.2.tar.gz # cd apr-1.4.2.tar.gz # ./configure  --prefix=/usr/local/apr # make  && make install 3、apr-util-1.3.10.tar.gz的安装 # tar -zxvf apr-util-1.3.10.tar.gz # cd apr-util-1.3.10.tar.gz # ./configure \\ --prefix=/usr/local/apr-util \\ --with-apr=/usr/local/apr # make && make install 4、# tar -zxvf pcre-8.10.tar.gz # cd pcre-8.10 # ./configure --prefix=/usr/local/pcre # make && make install 5、tar xvf tar xvf httpd-2.4.2.tar.gz  ./configure \\ --prefix=/usr/local/apache \\ --with-apr-util=/usr/local/apr-util/ \\ --with-pcre=/usr/local/pcre/ make && make install 6、/usr/local/apache/bin/apachectl start /usr/local/apache/conf/httpd.conf DocumentRoot \"/usr/local/apache//htdocs\"","title":"linux下利用yum、编译安装配置apache服务"},{"content":"UNIX世界的软件开发大多都是协作式的，因此，Patch（补丁）是一个相当重要的东西，因为几乎所有的大型UNIX项目的普通贡献者，都是通过 Patch来提交代码的。作为最重要的开源项目之一，Linux，也是这样的。普通开发者从软件仓库clone下代码，然后写入代码，做一个Patch， 最后用E-mail发给Linux Kernel的维护者就好了。Git最初作为Linux的版本控制工具，提供了透明、完整、稳定的Patch功能。 我们先介绍一下Patch是什么。如果一个软件有了新版本，我们可以完整地下载新版本的代码进行编译安装。然而，像Linux Kernel这样的大型项目，代码即使压缩，也超过70MB，每次全新下载是有相当大的代价的。然而，每次更新变动的代码可能不超过1MB，因此，我们只 要能够有两个版本代码的diff的数据，应该就可以以极低的代价更新程序了。因此，Larry Wall开发了一个工具：patch。它可以根据一个diff文件进行版本更新。 不过在git中，我们没有必要直接使用diff和patch来做补丁，这样做既危险又麻烦。git提供了两种简单的patch方案。一是用git diff生成的标准patch，二是git format-patch生成的Git专用Patch。 1.git diff生成的标准patch 我们可以首先用git diff制作一个patch。本文示例的工作目录里最初有一个文件a，内容是“This is the file a.”，放置在master分支中。为了修改代码，我们一般的做法是建立一个新分支： sweetdum@sweetdum-ASUS:~/GitEx$ git branch Fix sweetdum@sweetdum-ASUS:~/GitEx$ git checkout Fix Switched to branch 'Fix' 接下来我们在a文件里面追加一行，然后执行git diff。 sweetdum@sweetdum-ASUS:~/GitEx$ echo 'Fix!!!'>>a sweetdum@sweetdum-ASUS:~/GitEx$ git diff diff --git a/a b/a index 4add65f..0d295ac 100644 --- a/a +++ b/a @@ -1 +1,2 @@ This is the file a. +Fix!!! 我们看到了Git diff的输出，这是一个非常典型的Patch式diff。这样我们可以直接把这个输出变为一个Patch： sweetdum@sweetdum-ASUS:~/GitEx$ git commit -a -m \"Fix\" [Fix b88c46b] Fix 1 files changed, 1 insertions(+), 0 deletions(-) sweetdum@sweetdum-ASUS:~/GitEx$ git diff master > patch sweetdum@sweetdum-ASUS:~/GitEx$ git checkout master Switched to branch 'master' 我们现在有一个patch文件，并且签出了master，接下来我们可以使用git apply来应用这个patch。当然了，实际应用中，我们不会这样在一个分支建patch，到另一个分支去应用，因为只有merge一下就好了。我们现 在权当没有这个Fix分支。一般情况下，为了保护master，我们会建立一个专门处理新交来的patch的分支： sweetdum@sweetdum-ASUS:~/GitEx$ git branch PATCH sweetdum@sweetdum-ASUS:~/GitEx$ git checkout PATCH Switched to branch 'PATCH' sweetdum@sweetdum-ASUS:~/GitEx$ git apply patch sweetdum@sweetdum-ASUS:~/GitEx$ git commit -a -m \"Patch Apply\" [PATCH 9740af8] Patch Apply 1 files changed, 1 insertions(+), 0 deletions(-) 看，现在我们在PATCH分支中应用了这个补丁，我们可以把PATCH分支和Fix比对一下，结果肯定是什么也没有，说明PATCH分支和Fix分支完全一样。patch应用成功。即使有多个文件git diff 也能生成一个patch。 2.git format-patch生成的git专用补丁。 我们同样用上面那个例子的工作目录，这次，我们在Fix分支中的a添加了新行之后，用git format-patch生成一个patch。 sweetdum@sweetdum-ASUS:~/GitEx$ git checkout Fix Switched to branch 'Fix' sweetdum@sweetdum-ASUS:~/GitEx$ echo 'Fix!!!'>>a sweetdum@sweetdum-ASUS:~/GitEx$ git commit -a -m \"Fix1\" [Fix 6991743] Fix1 1 files changed, 1 insertions(+), 0 deletions(-) sweetdum@sweetdum-ASUS:~/GitEx$ git format-patch -M master 0001-Fix1.patch git format-patch的-M选项表示这个patch要和那个分支比对。现在它生成了一个patch文件，我们看看那是什么： sweetdum@sweetdum-ASUS:~/GitEx$ cat 0001-Fix1.patch From 6991743354857c9a6909a253e859e886165b0d90 Mon Sep 17 00:00:00 2001 From: Sweetdumplings <linmx0130@163.com> Date: Mon, 29 Aug 2011 14:06:12 +0800 Subject: [PATCH] Fix1 --- a |    1 + 1 files changed, 1 insertions(+), 0 deletions(-) diff --git a/a b/a index 4add65f..0d295ac 100644 --- a/a +++ b/a @@ -1 +1,2 @@ This is the file a. +Fix!!! -- 1.7.4.1 看，这次多了好多东西，不仅有diff的信息，还有提交者，时间等等，仔细一看你会发现，这是个E-mail的文件，你可以直接发送它！这种patch，我们要用git am来应用。 sweetdum@sweetdum-ASUS:~/GitEx$ git checkout master Switched to branch 'master' sweetdum@sweetdum-ASUS:~/GitEx$ git branch PATCH sweetdum@sweetdum-ASUS:~/GitEx$ git checkout PATCH sweetdum@sweetdum-ASUS:~/GitEx$ git am 0001-Fix1.patch Applying: Fix1 sweetdum@sweetdum-ASUS:~/GitEx$ git commit -a -m \"PATCH apply\" 在提交了补丁之后，我们可以再看看目前文件a的情况： sweetdum@sweetdum-ASUS:~/GitEx$ cat a This is the file a. Fix!!! 果然，多了一个Fix!!! 不过要注意的是，如果master与Fix分支中间有多次提交，它会针对每次提交生成一个patch。 3.两种patch的比较： 兼容性：很明显，git diff生成的Patch兼容性强。如果你在修改的代码的官方版本库不是Git管理的版本库，那么你必须使用git diff生成的patch才能让你的代码被项目的维护人接受。 除错功能：对于git diff生成的patch，你可以用git apply --check 查看补丁是否能够干净顺利地应用到当前分支中；如果git format-patch 生成的补丁不能打到当前分支，git am会给出提示，并协助你完成打补丁工作，你也可以使用git am -3进行三方合并，详细的做法可以参考git手册或者《Progit》。从这一点上看，两者除错功能都很强。 版本库信息：由于git format-patch生成的补丁中含有这个补丁开发者的名字，因此在应用补丁时，这个名字会被记录进版本库，显然，这样做是恰当的。因此，目前使用Git的开源社区往往建议大家使用format-patch生成补丁。","title":"git 的patch用法"},{"content":"touch first   //创建一个名为first的文件 vi first         //用vi编辑器编辑first，内容如下图 按“esc\" 输入 :wq   //退出文件编辑保存文件 这时候wdl目录下的内容如图 下一步： 创建first文件的物理连接Hello ln first Hello 这是wdl目录下的内容 vi 打开Hello文件 vi Hello Hello里的内容如下图，会发现跟first内容完全一样（这就是链接文件的用处） 创建first文件的软连接 ln -s first hello 这时wdl目录下的内容（多了first的软连接hello) 同样hello文件的内容跟first内容一致 下一步：删除first文件 rm first 显示wdl目录下的内容： first文件已不存在，物理连接Hello存在且内容保持不变，而这个时候逻辑连接文件hello虽然存在但文件已没有内容！      ","title":"linux ln file1 file2"},{"content":"德州仪器在线技术支持 http://www.deyisupport.com/search/searchresults.aspx?q=dvsdk%e7%bc%96%e8%af%91%e5%87%ba%e9%94%99 Configuring Codec Engine in Arm apps with createFromServer http://processors.wiki.ti.com/index.php?title=Configuring_Codec_Engine_in_Arm_apps_with_createFromServer Ti 快速入门codec enginer http://www.ti.com.cn/general/cn/docs/gencontent.tsp?contentId=61575 Digital Video Test Bench (DVTB) http://processors.wiki.ti.com/index.php/Digital_Video_Test_Bench_%28DVTB%29 Davinci Multimedia Application Interface (DMAI) 2.20.00 Build 14 Us file:///home/rowboat/rowboat_android/external/ti-dsp/ti-dvsdk_dm3730-evm_4_01_00_09/dmai_2_20_00_14/docs/html/user_guide.html Davinci Multimedia Application Interface http://processors.wiki.ti.com/index.php/Davinci_Multimedia_Application_Interface http://processors.wiki.ti.com/index.php?title=Configuring_Codec_Engine_in_Arm_apps_with_createFromServer#Don.27t_forget_to_match_up_engine_names.21 file:///home/rowboat/rowboat_android/external/ti-dsp/ti-dvsdk_dm3730-evm_4_01_00_09/dmai_2_20_00_14/docs/html/user_guide.html AM35x-OMAP35x-PSP 04.02.00.07 UserGuide http://processors.wiki.ti.com/index.php/AM35x-OMAP35x-PSP_04.02.00.07_UserGuide How do I Integrate new codecs into DVSDK processors.wiki.ti.com/index.php/How_do_I_Integrate_new_codecs_into_DVSDK DVSDK 4.x FAQ http://processors.wiki.ti.com/index.php/DVSDK_4.x_FAQ#How_to_install_DVSDK_4.01_on_unsupported_host TI E2E™ Community 这个是TI 的技术论坛，很不错，和老外可以交流哈哈：http://e2e.ti.com/support/embedded/linux/f/354/t/96171.aspx#335428 geogle rowboat project http://code.google.com/p/rowboat/ 如何构建达芬奇的DSP Server  http://www.cnblogs.com/huaping-audio/archive/2008/10/13/1309967.html","title":"Ti Davinc 经常使用的网址"},{"content":"在Unix系统下，维护源码版本可以使用很多方法，其中最常用的当然是大名鼎鼎的CVS，但实际上，简单的版本维护工作并没有必要使用复杂的CVS等专门的版本维护工具，Unix标配中的diff和patch工具就完全可以完成代码的简单备份和升级工作。 diff以\"行\"为单位比较两个文本文件（也可以是目录比较），并将不同之处以某种格式输出到标准输出上；patch可以读入这种输出，并按照一定指令使源文件（目录）按照目标文件（目录）更新。Linux内核源码就是按照这种方式保持更新的，我们在www.kernel.org上可以下载到最新内核的patch文件的bzip2包。本文以gnudiffutils 2.7和patch 2.5为例介绍diff和patch工具的使用。 1．diff diff既可以用来比较两个文件，也可以用来比较两个目录中每个文件。使用-r（--recursive）参数时还可以在目录中嵌套比较。比较目录时除比较同名文件外，对不同名的文件当成新文件处理。对于比较C程序文件，diff还提供了专门的参数（-p，--show-c-function）来标识不同之处所在的函数名。 diff的输出格式有三种：列举方式、命令模式和上下文模式，其中命令模式有分为两种：ed命令格式和RCS（Revision Control System，版本控制系统）命令格式，上下文模式也按格式分为老版和新版两种。看下面的例子就能基本清楚各个格式的区别： 命令格式记录的是从test1更新到test2所需要执行的命令，而上下文模式通常可读性更好一些，它所记录的主要是二者的差异，通常还记录所需修改部分的上下几行（可配置）内容以供比较。见下面的例子： 新版格式较之老版要紧凑一些，Linux内核源码的升级就是按照新版上下文格式用diff组织的，比如patch-2.4.16中所用的具体命令为： diff -Nur linux-2.4.15 linux 参数N表示如果某个文件仅在一个目录中出现，则假定其在另一个目录中为空文件；u表示unified格式，r表示在目录中嵌套使用，linux-2.4.15显然是老核的目录名，而linux则为新核的目录名。 回页首 2．patch 尽管并没有指定patch和diff的关系，但通常patch都使用diff的结果来完成打补丁的工作，这和patch本身支持多种diff输出文件格式有很大关系。patch通过读入patch命令文件（可以从标准输入），对目标文件进行修改。通常先用diff命令比较新老版本，patch命令文件则采用diff的输出文件，从而保持原版本与新版本一致。 patch的标准格式为 patch [options] [originalfile] [patchfile] 如果patchfile为空则从标准输入读取patchfile内容；如果originalfile也为空，则从patchfile（肯定来自标准输入）中读取需要打补丁的文件名。因此，如果需要修改的是目录，一般都必须在patchfile中记录目录下的各个文件名。绝大多数情况下，patch都用以下这种简单的方式使用： patch -p[num] <patchfile patch命令可以忽略文件中的冗余信息，从中取出diff的格式以及所需要patch的文件名，文件名按照diff参数中的\"源文件\"、\"目标文件\"以及冗余信息中的\"Index：\"行中所指定的文件的顺序来决定。也就是说，对于如下diff结果文件（Linux内核源码2.4.16升级包，部分）：  diff -Nur linux-2.4.15/Makefile linux/Makefile--- linux-2.4.15/Makefile       Thu Nov 22 17:22:58 2001+++ linux/Makefile      Sat Nov 24 16:21:53 2001@@ -1,7 +1,7 @@ VERSION = 2 PATCHLEVEL = 4-SUBLEVEL = 15-EXTRAVERSION =-greased-turkey+SUBLEVEL = 16+EXTRAVERSION = KERNELRELEASE=$(VERSION).$(PATCHLEVEL).$(SUBLEVEL)$(EXTRAVERSION)…… patch首先尝试当前目录（或者-d参数指定的目录）下的linux-2.4.15/Makefile文件是否存在，如果不存在则试图对linux/Makefile文件操作，仅当两者都不存在时（或者设置了POSIXLY_CORRECT环境变量）才会读取Index:的内容（此文件中没有标识）。 前面提到的-p参数决定了是否使用读出的源文件名的前缀目录信息，不提供-p参数，则忽略所有目录信息，-p0（或者-p 0）表示使用全部的路径信息，-p1将忽略第一个\"/\"以前的目录，依此类推。如/usr/src/linux-2.4.15/Makefile这样的文件名，在提供-p3参数时将使用linux-2.4.15/Makefile作为所要patch的文件。 对于刚才举的Linux内核源码2.4.16升级包的例子，假定源码目录位于/usr/src/linux中，则在当前目录为/usr/src时使用\"patch -p0 <patch-2.4.16\"可以工作，在当前目录为/usr/src/linux时，\"patch -p1<patch-2.4.16\"也可以正常工作。 patch可以直接操作上下文格式以及混合ed格式的diff输出文件，而将ed格式文件通过管道提交给ed程序操作（暂时不知RCS格式的文件如何处理）。 回页首 3．配合使用diff和patch升级源码 在此仅举一个简单的例子来说明如何用diff/patch工具维护源码升级。 假设program-1.0目录中为老版，现开发完成的新版位于program-2.0目录中，将两个目录置于同一父目录下，然后在该父目录上执行： diff -Nur program-1.0 program-2.0 >program-2.0.patch 将生成一个program-2.0.patch的补丁文件，发布该补丁文件（当然可以先压缩成bzip2格式）。 假设拿到的是program-2.0.patch.bz2文件，则在program-1.0目录同级执行： bzcat program-2.0.patch.bz2 | patch -p0 如此即完成了从1.0到2.0的升级。 如果希望恢复到原版本，可以使用-R（--reverse）参数，但仅对上下文格式的diff文件有效。还有一个备份参数也可以使用，但简单应用中，整个目录备份可能更方便一些。 参考资料 Patch手册页 Diff手册页 关于作者 杨沙洲，目前在国防科技大学计算机学院攻读软件方向博士学位。您可以通过 pubb@163.net与他联系。","title":"用Diff和Patch工具维护源码"},{"content":"ORA-39083: Object type TABLE:\"TEST\".\"TEST_SS_NAME\" failed to create with error: ORA-00439: feature not enabled: Deferred Segment Creation 错误解析与解决方法； 错误：当表为空时，不分配segment，以便节省空间，导致表在新库中是无法创建的。 解决方法： 查看源库中deferred_segment_creation的状态； 设置deferred_segment_creation状态为false，以便以后可以顺利导出导入空表； 查看当前用户下所有的空表； 对空表进行数据添加删除的操作； 重新导出、导入数据； 1、查看源库、目标库的deferred_segment_creation状态： SQL> show parameter deferred_segment_creation    NAME\t\t\t\t     TYPE\t VALUE------------------------------------ ----------- ------------------------------deferred_segment_creation\t     boolean\t FALSE 2、将状态true设置为false； sql> alter system set deferred_segment_creation=false scope=both; System altered. 查看设置后的状态 SQL> show parameter deferred_segment_creation    NAME\t\t\t\t     TYPE\t VALUE------------------------------------ ----------- ------------------------------deferred_segment_creation\t     boolean\t FALSE 3、查看源库中的空表： select table_name from user_tables where NUM_ROWS = 0;   4、对查出来的空表进行数据编辑，并及时还原为原来的空值； 5、重新导入导出数据即可； expdp username/password@ORACLESID DIRECTORY=/backup/oracle DUMPFILE=test00001.dmp impdp username/password@ORACLESID DIRECTORY=/backup/oracle DUMPFILE=test00001.dmp remap_schema=username:username","title":"oracle数据库导入导出时，ORA-39083;ORA-00439错误解决思路"},{"content":"1. 基本的替换 :s/vivian/sky/ 替换当前行第一个 vivian 为 sky :s/vivian/sky/g 替换当前行所有 vivian 为 sky :n,$s/vivian/sky/ 替换第 n 行开始到最后一行中每一行的第一个 vivian 为 sky :n,$s/vivian/sky/g 替换第 n 行开始到最后一行中每一行所有 vivian 为 sky （n 为数字，若 n 为 .，表示从当前行开始到最后一行） :%s/vivian/sky/（等同于 :g/vivian/s//sky/） 替换每一行的第一个 vivian 为 sky :%s/vivian/sky/g（等同于 :g/vivian/s//sky/g） 替换每一行中所有 vivian 为 sky 2. 可以使用 # 作为分隔符，此时中间出现的 / 不会作为分隔符 :s#vivian/#sky/# 替换当前行第一个 vivian/ 为 sky/ :%s+/oradata/apras/+/user01/apras1+ （使用+ 来 替换 / ）： /oradata/apras/替换成/user01/apras1/ 3. 删除文本中的^M 问题描述：对于换行，window下用回车换行（0A0D）来表示，linux下是回车（0A）来表示。这样，将window上的文件拷到unix上用时，总会有个^M，请写个用在unix下的过滤windows文件的换行符（0D）的shell或c程序。 使用命令：cat filename1 | tr -d “^V^M” > newfile; 使用命令：sed -e “s/^V^M//” filename > outputfilename 需要注意的是在1、2两种方法中，^V和^M指的是Ctrl+V和Ctrl+M。你必须要手工进行输入，而不是粘贴。 在vi中处理：首先使用vi打开文件，然后按ESC键，接着输入命令： :%s/^V^M// :%s/^M$//g 如果上述方法无用，则正确的解决办法是： tr -d “\\r” < src >dest tr -d “\\015″ dest strings A>B 4. 其它用法 利用 :s 命令可以实现字符串的替换。具体的用法包括： :s/str1/str2/ 用字符串 str2 替换行中首次出现的字符串 str1 :s/str1/str2/g 用字符串 str2 替换行中所有出现的字符串 str1 :.,$ s/str1/str2/g 用字符串 str2 替换正文当前行到末尾所有出现的字符串 str1 :1,$ s/str1/str2/g 用字符串 str2 替换正文中所有出现的字符串 str1 :g/str1/s//str2/g 功能同上 从上述替换命令可以看到：g 放在命令末尾，表示对搜索字符串的每次出现进行替换；不加 g，表示只对搜索字符串的首次出现进行替换；g 放在命令开头，表示对正文中所有包含搜索字符串的行进行替换操作。","title":"linux vi 常用操作"},{"content":"C 语言是一种 “高级” 语言，所谓的高级，就是拥有逻辑控制语句，可以使得我们实现诸如 循环、分支、跳转等操作。我们来逐一分析。 第一，循环语句。 C语言中，总共有3种循环语句，它们分别是 while 循环， do_while 循环 ， 和 for 循环。 1，while循环，下面是示例代码： int a = 0;while( a < 100 )  // 每循环一次a加1，总共循环100次。{        printf(\"%d\\n\", a);        a++;}上面的例子虽然简单，但已经说明白了while循环的用法了，当程序碰到 while (表达式)  时，系统会计算表达式的值，如果表达式的值为真，那么就执行后面的循环体，即后面用一对花括号包含起来的所有语句。 执行完之后，再来计算一遍这个表达式，如果还是为真，那就把循环体在执行一遍，就这样不断地重复，一直到表达式的值为假为止。如果 while(表达式)  中的表达式永远为真，那就是所谓的 死循环，永不退出。 上面的例子由于 a 的值会不断地递增，当 a 等于 100 时， 表示 a < 100 不成立，值为假，循环退出。 仔细观察 while 循环结构，你会发现，while 循环中的循环体有可能不会被执行，因为循环条件可能一开始就不成立。如果你需要你的循环体代码至少被执行一遍，那么推荐你使用另一种循环结构： 2，do-while 循环，下面是示例代码： int a = 0;do{        printf(\"%d\\n\", a);        a++;}while( a < 100 ); // 每循环一次a加1，总共循环100次。 注意，在 do-while 循环结构中，while语句后面有一个分号，不能省略。上面这段代码的意思是：开始的时候不管三七二十一，先来打印一遍a的值，然后 加1，然后再来判断条件是否成立，成立则继续循环，不成立则退出循环。   除此之外，C语言还有第三种循环结构，也是最常用的循环结构： 3，for循环，先来看示例代码： int a;for(a = 0; a < 100; a++){        printf(\"%d\\n\", a);} 从代码中得知，for循环中，for语句里面有 3 个表达式，第一个表达式是 a = 0， 这个表达式仅在最开始的时候被执行一遍，然后就跟for循环没有任何关系了，这个表达式一般称为循环变量初始化表达式，示例中 a 就是循环变量，被初始化为0。 第二个表达式是 a < 0， 这个表达式相当于 while 循环和 do-while 循环中的循环条件，当这个条件为真时，执行循环体，否则退出循环，这个表达式一般称为条件测试表达式。 第三个表达式是 a++ ， 这个表达式在执行完整个循环体之后执行，一般用来更新条件变量。 事实上，以上代码完全等价于： int a;a = 0;for(; a < 100; ){        printf(\"%d\\n\", a);        a++;} 注意到，for 语句当中的表达式可以被移除，但是两个分号不可省略。   C语言中除了循环结构，还有分支跳转结构，它们分别是： 1， if 语句 和 if - else 语句，请看示例代码： int a = 100;if( a%2 == 0){        printf(\"a 是偶数\");}else{        printf(\"a 是奇数\");} 上述代码中，使用了if - else 语句，在if 语句中，有一个表达式 a%2 == 0， 这个表达式的值决定了程序是否执行 if 语句所包含的代码块，即第 5 行。 如果该语句为真，则执行第 5 行，否则执行 else所包含的语句，即第 9 行。   注意，else语句不可单独使用， 它必须要跟if 语句配套使用。 if 语句所带的代码块和else 语句所带的代码块是互斥的，换句话说，它们是程序执行的两路分支，非此即彼，不可同时执行。 那如果不是两路分支，而是多路分支呢？ 此时可以写成 阶梯形 的if - else 语句，例如： int color = red;if(color == yellow){        printf(\"黄色\");}else if(color == blue){        printf(\"蓝色\");}else if(color == red){        printf(\"红色\");}else if(color == pink){        printf(\"粉色\");}else{        printf(\"不认识的颜色\");} 这段代码展示了所谓的阶梯形的 if - else 语句，用来实现多路分支，代码中的各种颜色是互斥的，运行时只会打印其中的一种。   事实上，要实现上述的多路分支，有一个更好的选择：switch。请看打印颜色的另一个版本代码： int color = red;switch(color){case yellow:        printf(\"黄色\");        break;case blue:        printf(\"蓝色\");        break;case red:        printf(\"红色\");        break;case pink:        printf(\"粉色\");        break;default:        printf(\"不认识的颜色\");} 这段代码实现跟上面 阶梯形 if - else 代码完全一样的功能，但是明显更加简洁易读，其主要的语法要点有： 1， switch(表达式) 语句中的那个表达式的类型必须是一个整型（包括字符型） 2， case语句后面的表达式必须是一个整型常量。比如100, 200, 或者yellow，blue等宏常量或者枚举常量，或者'A', 'X', 等字符常量。 3， case语句是一个入口标签，程序会先计算switch语句的值，然后跟下面的所有case语句相比较，如果相等则执行下面的代码，否则跳过。 另外， case 标签是只管进去不管出来的，换句话讲，如果要让 color 的值为 yellow 时只打印“黄色”，那在第 6 行下面必须有一句break 语句，否则，程序将会将“蓝色”也打印出来，直到遇到右花括号或者break语句为止。 4， default语句是可选的。 如果有这条语句，它的意思是：假如所有的情况都不匹配，那么就执行default的语句。   最后，C语言中还有一位“臭名昭著”的家伙： goto，在任何书籍中都被警告为会破坏程序逻辑的语句，编程者少用为妙。情况到底是怎样的呢？ goto 语句在语法结构上，确实跟刚刚提到的那些“正常”的控制流不同，它几乎不受约束，它可以跳转到任意你所指定的位置，这样做的后果是程序代码太自由，滥用将会使得整个程序面临无法阅读的境地，但是goto语句并不可怕，翻开LINUX源代码，你不仅可以看到goto语句的身影，而且它出现的频率还相当地高，但是用的多不代表用的广，goto语句往往只被用在一个地方：出错处理。 C语言跟C++比较，缺少所谓的异常捕获机制，在工程中，为了更好地管理代码，往往会将出错处理代码统一放在一个地方，程序中当发现有错误的时候，就可以使用goto 语句直接跳转到该代码处进行处理。这么做的好处是，程序中出错的地方可能被深层嵌套在函数或者循环语句当中，要一层一层地返回无疑极其繁琐， goto语句的直接跳转特性使得这一切都不再是问题。","title":"LINUX-C成长之路（五）：控制流"},{"content":"[base]name=CentOS-$releasever - Basebaseurl=http://mirrors.163.com/centos/$releasever/os/$basearch/gpgcheck=1gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-5#released updates[updates]name=CentOS-$releasever - Updatesbaseurl=http://mirrors.163.com/centos/$releasever/updates/$basearch/gpgcheck=1gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-5#packages used/produced in the build but not released[addons]name=CentOS-$releasever - Addonsbaseurl=http://mirrors.163.com/centos/$releasever/addons/$basearch/gpgcheck=1gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-5#additional packages that may be useful[extras]name=CentOS-$releasever - Extrasbaseurl=http://mirrors.163.com/centos/$releasever/extras/$basearch/gpgcheck=1gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-5#additional packages that extend functionality of existing packages[centosplus]name=CentOS-$releasever - Plusbaseurl=http://mirrors.163.com/centos/$releasever/centosplus/$basearch/gpgcheck=1enabled=0gpgkey=http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-5","title":"linux yum源"},{"content":"linux常用命令 一、文件、目录操作类 浏览目录类： 1、pwd：显示当前所在目录 2、cd：进入相应的目录  cd  ==== cd ~ 进入主文件夹  cd /  进入根文件  cd /var/tmp 进入指定文件  cd ..    向上 3、ls ：显示文件或目录的信息 语法格式：ls [参数] [文件或目录]  参数：  -a:显示所有文件或文件夹  -A:显示指定目录下所有子文件夹及文件，但是路径中不显示‘.’和‘..’  -c:按照文件的修改时间排列显示  -C:将显示结果分为多列显示  -l:按照长格式显示文件（详细信息）等价于ll命令 浏览文件类： 1、cat 浏览文件内容 格式：cat [参数] 文件名 参数：  -b:只对非空行进行行号的标注  -n:对所有行进行行号的标注 2、more 分页显示文件内容 格式：more [参数]  文件名   （注意：按q结束浏览） 参数：  -num:num为一个整数，表示每页显示的行数  +num:num为一个整数，从哪行开始显示 3、less 分页显示文件（方便对显示文件进行查找） 格式：less 文件名 目录操作类： 1、mkdir 创建文件夹 格式：mkdir [参数] 文件夹的名称 参数：-p:在父目录不存在的情况下，创建父目录及子目录（创建了一个文件夹的树形结构） 2、rmdir 删除目录(注意删除时目录必须为空) 格式：rmdir [参数] 文件夹的名称 参数：-p:在删除当前目录时，如果父目录为空，将父目录一起删除。 文件操作类 1.cp命令 复制文件 格式:cp [参数] 源文件 目的文件 参数:  -f:如果目标文件已经存在，直接覆盖目标文件，没有提示  -i:如果目标文件已经存在，给出提示（y代表yes，n代表no）  -R:复制目录结构 2.mv 移动万文件或文件夹 格式：mv [参数] 源文件或目录 目的文件或目录 3.rm  删除文件或目录 格式:rm [参数] 文件或目录  参数:  -i:给出提示  -f:不给提示，直接删除  -R:删除文件及目录 4.touch 创建一个空文件 格式：touch [参数] 文件名（目录结构） 参数: -d: 同时修改创建时间  -a: 将文件存取的时间改为当前时间  -m: 将文件的修改时间改为当前时间","title":"linux常用命令"},{"content":"5.ln 创建文件链接 硬链接：相当于两个文件，这两个文件指向同一存储空间，当修改一个文件时，另一个跟着变，当删除一个文件时，另一个文件不会被删除 软链接：类似windows中的快捷方式 格式：ln [参数] 源文件或目录 链接文件名 参数：-s:代表软链接 6.gzip和gunzip  压缩和解压缩(压缩后文件的扩展明为.gz) 格式: gzip [参数] 文件名  gunzip [参数] 压缩文件名 参数:-v 显示压缩和解压时的信息 7.tar 用于文件的打包（类似于winrar） 格式：tar [参数] 档案文件(打包生成的文件) 源文件的列表 参数: -c:创建档案文件  -v:显示打包的详细信息  -f:指定档案文件的名称  -z:以zip格式压缩或解压文件  -j:以bzip的格式压缩或解压文件  -r:将文件追加到档案文件的末尾  -x:解压文件 8.rpm 进行软件包的管理（安装，卸载，升级，查找） 格式：rpm [参数] 软件包 参数: -q:查询指定的软件在系统中是否被安装  -qa:查询系统中安装的所有软件  -qi:显示系统中安装的软件的详细信息  -qf:显示系统中指定的文件所属的软件包  -i:指定要安装的rpm包  -v:显示安装时的详细信息  -h:以“＃”显示安装进度  -e:卸载以安装的RPM  -U:升级软件包 9.whereis 获取软件路径 格式：whereis 命令名称 10.whatis 获取命令的信息 格式：whatis 命令名称 11.find 文件查找   格式：find [路径] ［匹配表达式］ 几种情况： (1). 查找指定名称的文件：-name  文件名称 (2). 查找指定类型的文件：-type 文件类型（f:普通文件  b:快设备文件 c:字符设备文件 d:目录 p:管道 l:链接文件） (3).按照大小查找文件：-size n:n为一个整数。代表查找的文件大小不大于n块（一块是512B） (4).按照最后访问时间来查找：-atime n:n为一个整数。＋n表示超过n天访问的内容；－n表示为超过n天访问的文件  (5).将查找到的文件执行相应的命令：    -exec 命令 {} \\;将查找到的文件直接执行命令   -ok   命令 {} \\;先提示用户是否要执行，然后再执行（给提示） 12.grep 用于查找文本中包含指定字符串的行。 格式：grep [参数] 要查找的字符串 文件名 参数： -v:列出不匹配的信息  -c:对匹配的行进行计数  -i:不去分大小写  -n:显示行号 显示系统信息类命令 1.dmesg显示设备的详细信息 2.df 显示文件系统的详细信息 3.du 显示当前文件夹及其子文件夹的信息（之显示占用的硬盘空间大小） 4.free 查看内存使用信息 5.date 查看当前系统的时间和日期 6.clock 显示计算机的时间和日期 7.cal month year （显示日历） 进程管理类 1.ps 显示系统的进程 格式：ps [参数] 参数: -a:显示当前终端的进程  -u:显示进程的用户信息包括启动时间等  -l:显示进程的详细信息(长格式)  -e:显示系统所有的进程 2.kill结束进程 kill [参数] 进程1 进程2..... 参数：-s:sign按照指定的进程类型符号来结束进程 kill -l来显示进程类型符号 killall杀死所有进程 3.bg将相应的进程放到后台运行 bg find将find命令相应的进程放到后台去运行 利用jobs命令可以查看后台运行的进程（任务） 4.fg将后台运行的任务调到前台工作 fg find将后台运行的find调到前台工作 其他常用的命令 1.clear清屏 2.man显示命令的帮助文件 3.uname显示系统的信息 uname -a 4.poweroff 关机 5.shutdown ［-r:重启;-h:关机］[now|hh:mm|+minite] 6.history 显示命令历史          ","title":"linux常用命令2"},{"content":"系统信息 arch 显示机器的处理器架构(1) uname -m 显示机器的处理器架构(2) uname -r 显示正在使用的内核版本 dmidecode -q 显示硬件系统部件 - (SMBIOS / DMI) hdparm -i /dev/hda 罗列一个磁盘的架构特性 hdparm -tT /dev/sda 在磁盘上执行测试性读取操作 cat /proc/cpuinfo 显示CPU info的信息 cat /proc/interrupts 显示中断 cat /proc/meminfo 校验内存使用 cat /proc/swaps 显示哪些swap被使用 cat /proc/version 显示内核的版本 cat /proc/net/dev 显示网络适配器及统计 cat /proc/mounts 显示已加载的文件系统 lspci -tv 罗列 PCI 设备 lsusb -tv 显示 USB 设备 date 显示系统日期 cal 2007 显示2007年的日历表 date 041217002007.00 设置日期和时间 - 月日时分年.秒 clock -w 将时间修改保存到 BIOS 关机 (系统的关机、重启以及登出 ) shutdown -h now 关闭系统(1) init 0 关闭系统(2) telinit 0 关闭系统(3) shutdown -h hours:minutes & 按预定时间关闭系统 shutdown -c 取消按预定时间关闭系统 shutdown -r now 重启(1) reboot 重启(2) logout 注销 文件和目录 cd /home 进入 '/ home' 目录' cd .. 返回上一级目录 cd ../.. 返回上两级目录 cd 进入个人的主目录 cd ~user1 进入个人的主目录 cd - 返回上次所在的目录 pwd 显示工作路径 ls 查看目录中的文件 ls -F 查看目录中的文件 ls -l 显示文件和目录的详细资料 ls -a 显示隐藏文件 ls *[0-9]* 显示包含数字的文件名和目录名 tree 显示文件和目录由根目录开始的树形结构(1) lstree 显示文件和目录由根目录开始的树形结构(2) mkdir dir1 创建一个叫做 'dir1' 的目录' mkdir dir1 dir2 同时创建两个目录 mkdir -p /tmp/dir1/dir2 创建一个目录树 rm -f file1 删除一个叫做 'file1' 的文件' rmdir dir1 删除一个叫做 'dir1' 的目录' rm -rf dir1 删除一个叫做 'dir1' 的目录并同时删除其内容 rm -rf dir1 dir2 同时删除两个目录及它们的内容 mv dir1 new_dir 重命名/移动 一个目录 cp file1 file2 复制一个文件 cp dir/* . 复制一个目录下的所有文件到当前工作目录 cp -a /tmp/dir1 . 复制一个目录到当前工作目录 cp -a dir1 dir2 复制一个目录 ln -s file1 lnk1 创建一个指向文件或目录的软链接 ln file1 lnk1 创建一个指向文件或目录的物理链接 touch -t 0712250000 file1 修改一个文件或目录的时间戳 - (YYMMDDhhmm) file file1 outputs the mime type of the file as text iconv -l 列出已知的编码 iconv -f fromEncoding -t toEncoding inputFile > outputFile creates a new from the given input file by assuming it is encoded in fromEncoding and converting it to toEncoding. find . -maxdepth 1 -name *.jpg -print -exec convert \"{}\" -resize 80x60 \"thumbs/{}\" \\; batch resize files in the current directory and send them to a thumbnails directory (requires convert from Imagemagick) 文件搜索 find / -name file1 从 '/' 开始进入根文件系统搜索文件和目录 find / -user user1 搜索属于用户 'user1' 的文件和目录 find /home/user1 -name \\*.bin 在目录 '/ home/user1' 中搜索带有'.bin' 结尾的文件 find /usr/bin -type f -atime +100 搜索在过去100天内未被使用过的执行文件 find /usr/bin -type f -mtime -10 搜索在10天内被创建或者修改过的文件 find / -name \\*.rpm -exec chmod 755 '{}' \\; 搜索以 '.rpm' 结尾的文件并定义其权限 find / -xdev -name \\*.rpm 搜索以 '.rpm' 结尾的文件，忽略光驱、捷盘等可移动设备 locate \\*.ps 寻找以 '.ps' 结尾的文件 - 先运行 'updatedb' 命令 whereis halt 显示一个二进制文件、源码或man的位置 which halt 显示一个二进制文件或可执行文件的完整路径 挂载一个文件系统 mount /dev/hda2 /mnt/hda2 挂载一个叫做hda2的盘 - 确定目录 '/ mnt/hda2' 已经存在 umount /dev/hda2 卸载一个叫做hda2的盘 - 先从挂载点 '/ mnt/hda2' 退出 fuser -km /mnt/hda2 当设备繁忙时强制卸载 umount -n /mnt/hda2 运行卸载操作而不写入 /etc/mtab 文件- 当文件为只读或当磁盘写满时非常有用 mount /dev/fd0 /mnt/floppy 挂载一个软盘 mount /dev/cdrom /mnt/cdrom 挂载一个cdrom或dvdrom mount /dev/hdc /mnt/cdrecorder 挂载一个cdrw或dvdrom mount /dev/hdb /mnt/cdrecorder 挂载一个cdrw或dvdrom mount -o loop file.iso /mnt/cdrom 挂载一个文件或ISO镜像文件 mount -t vfat /dev/hda5 /mnt/hda5 挂载一个Windows FAT32文件系统 mount /dev/sda1 /mnt/usbdisk 挂载一个usb 捷盘或闪存设备 mount -t smbfs -o username=user,password=pass //WinClient/share /mnt/share 挂载一个windows网络共享 磁盘空间 df -h 显示已经挂载的分区列表 ls -lSr |more 以尺寸大小排列文件和目录 du -sh dir1 估算目录 'dir1' 已经使用的磁盘空间' du -sk * | sort -rn 以容量大小为依据依次显示文件和目录的大小 rpm -q -a --qf '%10{SIZE}t%{NAME}n' | sort -k1,1n 以大小为依据依次显示已安装的rpm包所使用的空间 (fedora, redhat类系统) dpkg-query -W -f='${Installed-Size;10}t${Package}n' | sort -k1,1n 以大小为依据显示已安装的deb包所使用的空间 (ubuntu, debian类系统) 返回顶部索引 ^ 用户和群组 groupadd group_name 创建一个新用户组 groupdel group_name 删除一个用户组 groupmod -n new_group_name old_group_name 重命名一个用户组 useradd -c \"Name Surname \" -g admin -d /home/user1 -s /bin/bash user1 创建一个属于 \"admin\" 用户组的用户 useradd user1 创建一个新用户 userdel -r user1 删除一个用户 ( '-r' 排除主目录) usermod -c \"User FTP\" -g system -d /ftp/user1 -s /bin/nologin user1 修改用户属性 passwd 修改口令 passwd user1 修改一个用户的口令 (只允许root执行) chage -E 2005-12-31 user1 设置用户口令的失效期限 pwck 检查 '/etc/passwd' 的文件格式和语法修正以及存在的用户 grpck 检查 '/etc/passwd' 的文件格式和语法修正以及存在的群组 newgrp group_name 登陆进一个新的群组以改变新创建文件的预设群组 返回顶部索引 ^ 文件的权限 - 使用 \"+\" 设置权限，使用 \"-\" 用于取消 ls -lh 显示权限 ls /tmp | pr -T5 -W$COLUMNS 将终端划分成5栏显示 chmod ugo+rwx directory1 设置目录的所有人(u)、群组(g)以及其他人(o)以读（r ）、写(w)和执行(x)的权限 chmod go-rwx directory1 删除群组(g)与其他人(o)对目录的读写执行权限 chown user1 file1 改变一个文件的所有人属性 chown -R user1 directory1 改变一个目录的所有人属性并同时改变改目录下所有文件的属性 chgrp group1 file1 改变文件的群组 chown user1:group1 file1 改变一个文件的所有人和群组属性 find / -perm -u+s 罗列一个系统中所有使用了SUID控制的文件 chmod u+s /bin/file1 设置一个二进制文件的 SUID 位 - 运行该文件的用户也被赋予和所有者同样的权限 chmod u-s /bin/file1 禁用一个二进制文件的 SUID位 chmod g+s /home/public 设置一个目录的SGID 位 - 类似SUID ，不过这是针对目录的 chmod g-s /home/public 禁用一个目录的 SGID 位 chmod o+t /home/public 设置一个文件的 STIKY 位 - 只允许合法所有人删除文件 chmod o-t /home/public 禁用一个目录的 STIKY 位 返回顶部索引 ^ 文件的特殊属性 - 使用 \"+\" 设置权限，使用 \"-\" 用于取消 chattr +a file1 只允许以追加方式读写文件 chattr +c file1 允许这个文件能被内核自动压缩/解压 chattr +d file1 在进行文件系统备份时，dump程序将忽略这个文件 chattr +i file1 设置成不可变的文件，不能被删除、修改、重命名或者链接 chattr +s file1 允许一个文件被安全地删除 chattr +S file1 一旦应用程序对这个文件执行了写操作，使系统立刻把修改的结果写到磁盘 chattr +u file1 若文件被删除，系统会允许你在以后恢复这个被删除的文件 lsattr 显示特殊的属性 返回顶部索引 ^ 打包和压缩文件 bunzip2 file1.bz2 解压一个叫做 'file1.bz2'的文件 bzip2 file1 压缩一个叫做 'file1' 的文件 gunzip file1.gz 解压一个叫做 'file1.gz'的文件 gzip file1 压缩一个叫做 'file1'的文件 gzip -9 file1 最大程度压缩 rar a file1.rar test_file 创建一个叫做 'file1.rar' 的包 rar a file1.rar file1 file2 dir1 同时压缩 'file1', 'file2' 以及目录 'dir1' rar x file1.rar 解压rar包 unrar x file1.rar 解压rar包 tar -cvf archive.tar file1 创建一个非压缩的 tarball tar -cvf archive.tar file1 file2 dir1 创建一个包含了 'file1', 'file2' 以及 'dir1'的档案文件 tar -tf archive.tar 显示一个包中的内容 tar -xvf archive.tar 释放一个包 tar -xvf archive.tar -C /tmp 将压缩包释放到 /tmp目录下 tar -cvfj archive.tar.bz2 dir1 创建一个bzip2格式的压缩包 tar -xvfj archive.tar.bz2 解压一个bzip2格式的压缩包 tar -cvfz archive.tar.gz dir1 创建一个gzip格式的压缩包 tar -xvfz archive.tar.gz 解压一个gzip格式的压缩包 zip file1.zip file1 创建一个zip格式的压缩包 zip -r file1.zip file1 file2 dir1 将几个文件和目录同时压缩成一个zip格式的压缩包 unzip file1.zip 解压一个zip格式压缩包 返回顶部索引 ^ RPM 包 - （Fedora, Redhat及类似系统） rpm -ivh package.rpm 安装一个rpm包 rpm -ivh --nodeeps package.rpm 安装一个rpm包而忽略依赖关系警告 rpm -U package.rpm 更新一个rpm包但不改变其配置文件 rpm -F package.rpm 更新一个确定已经安装的rpm包 rpm -e package_name.rpm 删除一个rpm包 rpm -qa 显示系统中所有已经安装的rpm包 rpm -qa | grep httpd 显示所有名称中包含 \"httpd\" 字样的rpm包 rpm -qi package_name 获取一个已安装包的特殊信息 rpm -qg \"System Environment/Daemons\" 显示一个组件的rpm包 rpm -ql package_name 显示一个已经安装的rpm包提供的文件列表 rpm -qc package_name 显示一个已经安装的rpm包提供的配置文件列表 rpm -q package_name --whatrequires 显示与一个rpm包存在依赖关系的列表 rpm -q package_name --whatprovides 显示一个rpm包所占的体积 rpm -q package_name --scripts 显示在安装/删除期间所执行的脚本l rpm -q package_name --changelog 显示一个rpm包的修改历史 rpm -qf /etc/httpd/conf/httpd.conf 确认所给的文件由哪个rpm包所提供 rpm -qp package.rpm -l 显示由一个尚未安装的rpm包提供的文件列表 rpm --import /media/cdrom/RPM-GPG-KEY 导入公钥数字证书 rpm --checksig package.rpm 确认一个rpm包的完整性 rpm -qa gpg-pubkey 确认已安装的所有rpm包的完整性 rpm -V package_name 检查文件尺寸、 许可、类型、所有者、群组、MD5检查以及最后修改时间 rpm -Va 检查系统中所有已安装的rpm包- 小心使用 rpm -Vp package.rpm 确认一个rpm包还未安装 rpm2cpio package.rpm | cpio --extract --make-directories *bin* 从一个rpm包运行可执行文件 rpm -ivh /usr/src/redhat/RPMS/`arch`/package.rpm 从一个rpm源码安装一个构建好的包 rpmbuild --rebuild package_name.src.rpm 从一个rpm源码构建一个 rpm 包 返回顶部索引 ^ YUM 软件包升级器 - （Fedora, RedHat及类似系统） yum install package_name 下载并安装一个rpm包 yum localinstall package_name.rpm 将安装一个rpm包，使用你自己的软件仓库为你解决所有依赖关系 yum update package_name.rpm 更新当前系统中所有安装的rpm包 yum update package_name 更新一个rpm包 yum remove package_name 删除一个rpm包 yum list 列出当前系统中安装的所有包 yum search package_name 在rpm仓库中搜寻软件包 yum clean packages 清理rpm缓存删除下载的包 yum clean headers 删除所有头文件 yum clean all 删除所有缓存的包和头文件 返回顶部索引 ^ DEB 包 (Debian, Ubuntu 以及类似系统) dpkg -i package.deb 安装/更新一个 deb 包 dpkg -r package_name 从系统删除一个 deb 包 dpkg -l 显示系统中所有已经安装的 deb 包 dpkg -l | grep httpd 显示所有名称中包含 \"httpd\" 字样的deb包 dpkg -s package_name 获得已经安装在系统中一个特殊包的信息 dpkg -L package_name 显示系统中已经安装的一个deb包所提供的文件列表 dpkg --contents package.deb 显示尚未安装的一个包所提供的文件列表 dpkg -S /bin/ping 确认所给的文件由哪个deb包提供 返回顶部索引 ^ APT 软件工具 (Debian, Ubuntu 以及类似系统) apt-get install package_name 安装/更新一个 deb 包 apt-cdrom install package_name 从光盘安装/更新一个 deb 包 apt-get update 升级列表中的软件包 apt-get upgrade 升级所有已安装的软件 apt-get remove package_name 从系统删除一个deb包 apt-get check 确认依赖的软件仓库正确 apt-get clean 从下载的软件包中清理缓存 apt-cache search searched-package 返回包含所要搜索字符串的软件包名称 返回顶部索引 ^ 查看文件内容 cat file1 从第一个字节开始正向查看文件的内容 tac file1 从最后一行开始反向查看一个文件的内容 more file1 查看一个长文件的内容 less file1 类似于 'more' 命令，但是它允许在文件中和正向操作一样的反向操作 head -2 file1 查看一个文件的前两行 tail -2 file1 查看一个文件的最后两行 tail -f /var/log/messages 实时查看被添加到一个文件中的内容 返回顶部索引 ^ 文本处理 cat file1 file2 ... | command <> file1_in.txt_or_file1_out.txt general syntax for text manipulation using PIPE, STDIN and STDOUT cat file1 | command( sed, grep, awk, grep, etc...) > result.txt 合并一个文件的详细说明文本，并将简介写入一个新文件中 cat file1 | command( sed, grep, awk, grep, etc...) >> result.txt 合并一个文件的详细说明文本，并将简介写入一个已有的文件中 grep Aug /var/log/messages 在文件 '/var/log/messages'中查找关键词\"Aug\" grep ^Aug /var/log/messages 在文件 '/var/log/messages'中查找以\"Aug\"开始的词汇 grep [0-9] /var/log/messages 选择 '/var/log/messages' 文件中所有包含数字的行 grep Aug -R /var/log/* 在目录 '/var/log' 及随后的目录中搜索字符串\"Aug\" sed 's/stringa1/stringa2/g' example.txt 将example.txt文件中的 \"string1\" 替换成 \"string2\" sed '/^$/d' example.txt 从example.txt文件中删除所有空白行 sed '/ *#/d; /^$/d' example.txt 从example.txt文件中删除所有注释和空白行 echo 'esempio' | tr '[:lower:]' '[:upper:]' 合并上下单元格内容 sed -e '1d' result.txt 从文件example.txt 中排除第一行 sed -n '/stringa1/p' 查看只包含词汇 \"string1\"的行 sed -e 's/ *$//' example.txt 删除每一行最后的空白字符 sed -e 's/stringa1//g' example.txt 从文档中只删除词汇 \"string1\" 并保留剩余全部 sed -n '1,5p;5q' example.txt 查看从第一行到第5行内容 sed -n '5p;5q' example.txt 查看第5行 sed -e 's/00*/0/g' example.txt 用单个零替换多个零 cat -n file1 标示文件的行数 cat example.txt | awk 'NR%2==1' 删除example.txt文件中的所有偶数行 echo a b c | awk '{print $1}' 查看一行第一栏 echo a b c | awk '{print $1,$3}' 查看一行的第一和第三栏 paste file1 file2 合并两个文件或两栏的内容 paste -d '+' file1 file2 合并两个文件或两栏的内容，中间用\"+\"区分 sort file1 file2 排序两个文件的内容 sort file1 file2 | uniq 取出两个文件的并集(重复的行只保留一份) sort file1 file2 | uniq -u 删除交集，留下其他的行 sort file1 file2 | uniq -d 取出两个文件的交集(只留下同时存在于两个文件中的文件) comm -1 file1 file2 比较两个文件的内容只删除 'file1' 所包含的内容 comm -2 file1 file2 比较两个文件的内容只删除 'file2' 所包含的内容 comm -3 file1 file2 比较两个文件的内容只删除两个文件共有的部分 返回顶部索引 ^ 字符设置和文件格式转换 dos2unix filedos.txt fileunix.txt 将一个文本文件的格式从MSDOS转换成UNIX unix2dos fileunix.txt filedos.txt 将一个文本文件的格式从UNIX转换成MSDOS recode ..HTML < page.txt > page.html 将一个文本文件转换成html recode -l | more 显示所有允许的转换格式 返回顶部索引 ^ 文件系统分析 badblocks -v /dev/hda1 检查磁盘hda1上的坏磁块 fsck /dev/hda1 修复/检查hda1磁盘上linux文件系统的完整性 fsck.ext2 /dev/hda1 修复/检查hda1磁盘上ext2文件系统的完整性 e2fsck /dev/hda1 修复/检查hda1磁盘上ext2文件系统的完整性 e2fsck -j /dev/hda1 修复/检查hda1磁盘上ext3文件系统的完整性 fsck.ext3 /dev/hda1 修复/检查hda1磁盘上ext3文件系统的完整性 fsck.vfat /dev/hda1 修复/检查hda1磁盘上fat文件系统的完整性 fsck.msdos /dev/hda1 修复/检查hda1磁盘上dos文件系统的完整性 dosfsck /dev/hda1 修复/检查hda1磁盘上dos文件系统的完整性 返回顶部索引 ^ 初始化一个文件系统 mkfs /dev/hda1 在hda1分区创建一个文件系统 mke2fs /dev/hda1 在hda1分区创建一个linux ext2的文件系统 mke2fs -j /dev/hda1 在hda1分区创建一个linux ext3(日志型)的文件系统 mkfs -t vfat 32 -F /dev/hda1 创建一个 FAT32 文件系统 fdformat -n /dev/fd0 格式化一个软盘 mkswap /dev/hda3 创建一个swap文件系统 返回顶部索引 ^ SWAP文件系统 mkswap /dev/hda3 创建一个swap文件系统 swapon /dev/hda3 启用一个新的swap文件系统 swapon /dev/hda2 /dev/hdb3 启用两个swap分区 返回顶部索引 ^ 备份 dump -0aj -f /tmp/home0.bak /home 制作一个 '/home' 目录的完整备份 dump -1aj -f /tmp/home0.bak /home 制作一个 '/home' 目录的交互式备份 restore -if /tmp/home0.bak 还原一个交互式备份 rsync -rogpav --delete /home /tmp 同步两边的目录 rsync -rogpav -e ssh --delete /home ip_address:/tmp 通过SSH通道rsync rsync -az -e ssh --delete ip_addr:/home/public /home/local 通过ssh和压缩将一个远程目录同步到本地目录 rsync -az -e ssh --delete /home/local ip_addr:/home/public 通过ssh和压缩将本地目录同步到远程目录 dd bs=1M if=/dev/hda | gzip | ssh user@ip_addr 'dd of=hda.gz' 通过ssh在远程主机上执行一次备份本地磁盘的操作 dd if=/dev/sda of=/tmp/file1 备份磁盘内容到一个文件 tar -Puf backup.tar /home/user 执行一次对 '/home/user' 目录的交互式备份操作 ( cd /tmp/local/ && tar c . ) | ssh -C user@ip_addr 'cd /home/share/ && tar x -p' 通过ssh在远程目录中复制一个目录内容 ( tar c /home ) | ssh -C user@ip_addr 'cd /home/backup-home && tar x -p' 通过ssh在远程目录中复制一个本地目录 tar cf - . | (cd /tmp/backup ; tar xf - ) 本地将一个目录复制到另一个地方，保留原有权限及链接 find /home/user1 -name '*.txt' | xargs cp -av --target-directory=/home/backup/ --parents 从一个目录查找并复制所有以 '.txt' 结尾的文件到另一个目录 find /var/log -name '*.log' | tar cv --files-from=- | bzip2 > log.tar.bz2 查找所有以 '.log' 结尾的文件并做成一个bzip包 dd if=/dev/hda of=/dev/fd0 bs=512 count=1 做一个将 MBR (Master Boot Record)内容复制到软盘的动作 dd if=/dev/fd0 of=/dev/hda bs=512 count=1 从已经保存到软盘的备份中恢复MBR内容","title":"linux命令大全"},{"content":"创建一个管道，然后创建一个子进程。让父进程想管道里写入数据，让子进程从管道中读取数据，程序在写或读之前把那些不用的描述符给关掉 源码 #include<stdio.h>#include<stdlib.h>#include<unistd.h>#include<sys/types.h>int main(){  int n;  int fd[2]; //管道【1】为写入端，管道【0】为读出端  pid_t pid;//定义一个进程号  char  line[1024];  //定义一个缓存区 if(pipe(fd)<0)    //建立管道 perror(\"pipe error\"); if((pid=fork())<0)//创建子进程 perror(\"fork error\"); else if (pid==0)  //pid号为1则是父进程，为0表示子进程{ close(fd[0]); //关闭子进程 write(fd[1],\"I'm child,hello father!\",23);//让父进程从管道中写入数据}else { close(fd[1]);//程序在写或读之前把不用的描述符给关掉wait();//  带等子进程结束n=read(fd[0],line,1024);  //让子进程从管道中读取数据，读取到缓冲数组中write(STDOUT_FILENO,line,n);//把缓冲区的数据写入到屏幕上}exit(0);}","title":"linux进程通信编程2"},{"content":"管道应用的一个重大限制就是它没有名字，因此，只能用于具有亲缘关系的进程间的通信，在有名管道（Named Pipe或 FIFO）提出后，该限制得到了克服，FIFO不同于管道之处 在于它提供了一个路径名与之关联，以FIFO的文件形式存在与文件系统中。这样，即使与FIFO的创建进程不存在亲缘关系的进程，只要可以访问该路径，彼此之间就能进行通信 一个比较好的命名管道例子： 下面这个例子使用FIFO进行进程间的通信，程序lucy.c创建了FIFO write_fifo用于向程序peter.c发送消息；peter.c程序创建了FIFO read_fifo用于向lucy.c发送消息 同时，lucy.c能够通过打开peter.c创建的FIFO来得到的peter.c发来的消息，peter.c能够通过打开lucy.c创建的FIFO来得到lucy.c发来的消息。因此两者就能互相通信了，两者必须在线才能进行通信聊天，这个有点类似qq的聊天功能。 下面是源程序lucy.c #include<sys/types.h>#include<sys/stat.h>// 文件状态的头文件#include<string.h>   //字符串函数头文件#include<stdio.h>     //标准的输入输出头文件#include<errno.h>     //错误提示头文件#include<fcntl.h>     //控制头文件#include<unistd.h>  //创建进程的头文件int main(void){ char write_fifo_name[]=\"write-fifo\";    //定义一个写管道名字 char read_fifo_name[]=\"read-fifo\";//定义一个读管道的名字 int  write_fd,read_fd; char buf[256];   //定义存储通信的会话空间长度 int len; struct stat stat_buf;    int ret=mkfifo(write_fifo_name,S_IRUSR | S_IWUSR); if(ret==-1)   //创建一个命名管道{ printf(\"Fail to create FIFO %s\",write_fifo_name,strerror(errno)); exit(-1);}write_fd=open(write_fifo_name,O_WRONLY);  //以读写方式打开命名的管道if(write_fd==-1) {printf(\"Fail to open FIFO %s: %s\",write_fifo_name,strerror(errno));exit(-1);} while((read_fd=open(read_fifo_name,O_RDONLY))==-1) {    //以只读方式打开管道文件 sleep(1);} while(1) {printf(\"熊尧: \");fgets(buf,256,stdin);  //fgets（）函数，从stdin流中读取256-1个字符存储在以buf为地址的空间里，至到读取成功，成功则返回buf的指针buf[strlen(buf)-1]='\\0';if(strncmp(buf,\"quit\",4)==0) {   //用strncmp（）函数来比较buf中的前四个字符是否为quitclose(write_fd);//若是，则关闭写入函数unlink(write_fifo_name); //删除文件的目录并减少它的链接数close(read_fd);   //最后要关闭打开的对话文件exit(0);}write(write_fd,buf,strlen(buf));len=read(read_fd,buf,256);if(len>0) {buf[len]='\\0';printf(\"红刚: %s\\n\",buf);}}} 下面是peter.c #include<sys/types.h>#include<sys/stat.h>#include<string.h>#include<stdio.h>#include<errno.h>#include<fcntl.h>int main(void){  char  write_fifo_name[]= \"read-fifo\"; char read_fifo_name[]= \"write-fifo\"; int write_fd,read_fd;char buf[256]; int len; int ret=mkfifo(write_fifo_name,S_IRUSR | S_IWUSR); if(ret==-1) {  printf(\"Fail to create FIFO %s\",write_fifo_name,strerror(errno)); exit(-1);} while((read_fd=open(read_fifo_name,O_RDONLY))==-1) { sleep(1);} write_fd=open(write_fifo_name,O_WRONLY);if(write_fd==-1) {printf(\"Fail to open FIFO %s: %s\",write_fifo_name,strerror(errno));exit(-1);}while(1) {len=read(read_fd,buf,256);if(len>0) {buf[len]='\\0';printf(\"熊尧: %s\\n\",buf);}printf(\"红刚：\");fgets(buf,256,stdin);buf[strlen(buf)-1]='\\0';if(strncmp(buf,\"quit\",4)==0) {close(write_fd);unlink(write_fifo_name);close(read_fd);exit(0);}write(write_fd,buf,strlen(buf));}} 在两个端口分别开始运行lucy.c和peter.c，即可以开始聊天了","title":"linux进程通信（命名管道）"},{"content":"PS是LINUX下最常用的也是非常强大的进程查看命令 1. ps简介 前面介绍的两个命令都是用于查看当前系统用户的情况，下面就来看看进程的情况，这也是本章的主题。 要对进程进行监测和控制，首先必须要了解当前进程的情况，也就是需要查看当前进程，而ps命令就是最基本 同时也是非常强大的进程查看命令。使用该命令可以确定有哪些进程正在运行和运行的状态、进程是否结束、 进程有没有僵死、哪些进程占用了过多的资源等等。总之大部分信息都是可以通过执行该命令得到的。 2. ps命令及其参数 ps命令最常用的还是用于监控后台进程的工作情况，因为后台进程是不和屏幕键盘这些标准输入/输出设 备进行通信的，所以如果需要检测其情况，便可以使用ps命令了。 该命令语法格式如下： ps [选项] 下面对命令选项进行说明： -e 显示所有进程。 -f 全格式。 -h 不显示标题。 -l 长格式。 -w 宽输出。 a 显示终端上的所有进程，包括其他用户的进程。 r 只显示正在运行的进程。 x 显示没有控制终端的进程。 O[+|-] k1 [，[+|-] k2 [，…]] 根据SHORT KEYS、k1、k2中快捷键指定的多级排序顺序显示进程列表。 对于ps的不同格式都存在着默认的顺序指定。这些默认顺序可以被用户的指定所覆盖。其中“+”字符是可选 的，“-”字符是倒转指定键的方向。 pids 只列出付ń 痰那榭觥８鹘 蘄D之间使用逗号分隔。该进程列表必须在命令行参数的最后一个选项 后面紧接着给出，中间不能插入空格。比如：ps -f1,4,5。 以下介绍长命令行选项，这些选项都使用“--”开头： --sort X[+|-] key [，[+|-] key [，…]] 从SORT KEYS段中选一个多字母键。“+”字符是可选的，因 为默认的方向就是按数字升序或者词典顺序。比如： ps -jax -sort=uid，-ppid，+pid。 --help 显示帮助信息。 --version 显示该命令的版本信息。 在前面的选项说明中提到了排序键，接下来对排序键作进一步说明。需要注意的是排序中使用的值是ps使 用的内部值，并非仅用于某些输出格式的伪值。排序键列表见表4-3。 表4-3　排序键列表 短格式 长格式 说 明 c cmd 可执行的简单名称 C cmdline 完整命令行 f flags 长模式标志 g pgrp 进程的组ID G tpgid 控制tty进程组ID j cutime 累计用户时间 J cstime 累计系统时间 k utime 用户时间 K stime 系统时间 m min_flt 次要页错误的数量 M maj_flt 主要页错误的数量 n cmin_flt 累计次要页错误 N cmaj_flt 累计主要页错误 o session 对话ID p pid 进程ID P ppid 父进程ID r rss 驻留大小 R resident 驻留页 s size 内存大小（千字节） S share 共享页的数量 t tty tty次要设备号 T start_time 进程启动的时间 U uid UID u user 用户名 v vsize 总的虚拟内存数量（字节） y priority 内核调度优先级 3. 常用ps命令参数 前面两节介绍的参数可能让读者觉得有些可怕，实际上这是一个非常容易使用的命令，一般的用户只 需掌握一些最常用的命令参数就可以了。 最常用的三个参数是u、a、x，下面将通过例子来说明其具体用法。 [例20] 以root身份登录系统，查看当前进程状况 $ ps PID TTY TIME COMMAND 5800 ttyp0 00:00:00 bash 5835 ttyp0 00:00:00 ps 可以看到，显示的项目共分为四项，依次为PID（进程ID）、TTY（终端名称）、TIME（进程执行时间） 、COMMAND（该进程的命令行输入）。 可以使用u选项来查看进程所有者及其他一些详细信息，如下所示： $ ps u USER PID %CPU %MEM USZ RSS TTY STAT START TIME COMMAND test 5800 0.0 0.4 1892 1040 ttyp0 S Nov27 0:00 -bash test 5836 0.0 0.3 2528 856 ttyp0 R Nov27 0:00 ps u 在bash进程前面有条横线，意味着该进程便是用户的登录shell，所以对于一个登录用户来说带短横线的进 程只有一个。还可以看到%CPU、%MEM两个选项，前者指该进程占用的CPU时间和总时间的百分比；后者指该进程 占用的内存和总内存的百分比。 在这种情况下看到了所有控制终端的进程；但是对于其他那些没有控制终端的进程还是没有观察到，所以这 时就需要使用x选项。使用x选项可以观察到所有的进程情况。","title":"linux ps命令参数和使用详解"}]