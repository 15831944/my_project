[{"content":"select convert(varchar(10),getdate(),120)  -- 只返回当前日期，且为2012-12-12格式（最有用）         datediff(day,createdate,GetDate())=0      -- 判断是否当天，createdate为日期字段    \t--                                                                                    ╔════════════════════╗\t-- =================================================================================  ║    第一天、第几月  ║\t--                                                                                    ╚════════════════════╝ \t\t\t-- 1.一个月第一天的\t\t\tSelect DATEADD(mm, DATEDIFF(mm,0,getdate()), 0)\t\t\t-- 2.本周的星期一\t\t\tSelect DATEADD(wk, DATEDIFF(wk,0,getdate()), 0)\t\t\t-- 3.一年的第一天\t\t\tSelect DATEADD(yy, DATEDIFF(yy,0,getdate()), 0)\t\t\t-- 4.季度的第一天\t\t\tSelect DATEADD(qq, DATEDIFF(qq,0,getdate()), 0)\t\t\t-- 5.当天的半夜\t\t\tSelect DATEADD(dd, DATEDIFF(dd,0,getdate()), 0)\t\t\t-- 6.上个月的最后一天\t\t\tSelect dateadd(ms,-3,DATEADD(mm, DATEDIFF(mm,0,getdate()), 0))\t\t\t-- 7.去年的最后一天\t\t\tSelect dateadd(ms,-3,DATEADD(yy, DATEDIFF(yy,0,getdate()), 0))\t\t\t-- 8.本月的最后一天\t\t\tSelect dateadd(ms,-3,DATEADD(mm, DATEDIFF(m,0,getdate())+1, 0))\t\t\t-- 9.本年的最后一天\t\t\tSelect dateadd(ms,-3,DATEADD(yy, DATEDIFF(yy,0,getdate())+1, 0))\t\t\t-- 10.本月的第一个星期一\t\t\tselect DATEADD(wk, DATEDIFF(wk,0,dateadd(dd,6-datepart(day,getdate()),getdate())), 0) \t\t\tselect 本年第多少周=datename(week,getdate())\t\t\t\t  ,今天是周几=datename(weekday,getdate())            --  dateadd 在向指定日期加上一段时间的基础上，返回新的datetime值\t\t\t-- 向日期加上2天 或 增加1个月\t\t\t\tselect dateadd(day,2,'2004-10-15') --返回：2004-10-17 00:00:00.000\t\t\t\tselect dateadd(month,2,'2004-10-15') --返回：2004-12-17 00:00:00.000\t\t\t--3. datediff 返回跨两个指定日期的日期和时间边界数。\t\t\t     select datediff(day,'2004-09-01','2004-09-18') --返回天数：17                 select DateDiff(s,'2005-07-20','2005-7-25 22:56:32') --返回值为 514592 秒                 select DateDiff(ms,'2005-07-20','2005-7-25 22:56:32') --返回值为 微秒\t\t\t\t select DateDiff(d,'2005-07-20','2005-7-25 22:56:32') -- 返回值为 5 天\t\t\t\t select DatePart(w,'2005-7-25 22:56:32')--返回值为 2 即星期一(周日为1，周六为7)\t\t\t\t select DatePart('d','2005-7-25 22:56:32')--返回值为 25即25号\t\t\t\t select DatePart('y','2005-7-25 22:56:32')--返回值为 206即这一年中第206天\t\t\t\t select DatePart('yyyy','2005-7-25 22:56:32')--返回值为 2005即2005年\t\t\t--DateDiff (interval,date1,date2) 以interval 指定的方式，\t\t\t--返回date2 与date1两个日期之间的差值 date2-date1\t\t\t--DateAdd (interval,number,date) 以interval指定的方式，加上number之后的日期\t\t\t--DatePart (interval,date) 返回日期date中，interval指定部分所对应的整数值\t\t\t--DateName (interval,date) 返回日期date中，interval指定部分所对应的字符串名称\t--                                                                                    ╔════════════════════╗\t-- =================================================================================  ║  当前时间函数      ║\t--                                                                                    ╚════════════════════╝ \t\t\t-- 返回当前日期和时间\t\t       select GETDATE()\t\t\t--  返回代表指定日期的指定日期部分的整数。\t\t\t\tselect datepart(month, '2004-10-15') --返回 月\t\t\t\tselect datepart(day, '2004-10-15') --返回 日\t\t\t\tselect datepart(year, getdate()) --返回 年\t\t\t    select convert(varchar(8),getdate(),114)  -- 当前时间\t\t\t    select datename(weekday, getdate()) --返回：星期五\t\t\t    select datepart(weekday, getdate()) --返回：小写星期2-1\t\t\t    select convert(varchar(10),getdate(),120)  -- 当前日期\t\t\t\tselect datepart(S, '2004-10-15') --返回 月\t\t\t--  返回时间到豪秒                Select CONVERT(VARCHAR(30),GETDATE(),9)\t\t\t--  获取当前日期，年、月、日、周、时、分、秒\t\t\t\tselect GETDATE() as '当前日期',\t\t\t\tDateName(year,GetDate()) as '年',\t\t\t\tDateName(month,GetDate()) as '月',\t\t\t\tDateName(day,GetDate()) as '日',\t\t\t\tDateName(dw,GetDate()) as '星期',\t\t\t\tDateName(week,GetDate()) as '周数',\t\t\t\tDateName(hour,GetDate()) as '时',\t\t\t\tDateName(minute,GetDate()) as '分',\t\t\t\tDateName(second,GetDate()) as '秒'print DateName(second,GetDate())+'1'            --  格式\t\t\t\tselect replace(replace(replace(CONVERT(varchar, getdate(), 120 ),'-',''),' ',''),':','')\t\t\t\t20040912110608\t\t\t\tselect CONVERT(varchar(12) , getdate(), 111 )\t\t\t\t2004/09/12\t\t\t\tselect CONVERT(varchar(12) , getdate(), 112 )\t\t\t\t20040912\t\t\t\tselect CONVERT(varchar(12) , getdate(), 102 )\t\t\t\t2004.09.12\t\t\t\tselect CONVERT(varchar(12) , getdate(), 101 )\t\t\t\t09/12/2004\t\t\t\tselect CONVERT(varchar(12) , getdate(), 103 )\t\t\t\t12/09/2004\t\t\t\tselect CONVERT(varchar(12) , getdate(), 104 )\t\t\t\t12.09.2004\t\t\t\tselect CONVERT(varchar(12) , getdate(), 105 )\t\t\t\t12-09-2004\t\t\t\tselect CONVERT(varchar(12) , getdate(), 106 )\t\t\t\t12 09 2004\t\t\t\tselect CONVERT(varchar(12) , getdate(), 107 )\t\t\t\t09 12, 2004\t\t\t\tselect CONVERT(varchar(12) , getdate(), 108 )\t\t\t\t11:06:08\t\t\t\tselect CONVERT(varchar(12) , getdate(), 109 )\t\t\t\t09 12 2004 1\t\t\t\tselect CONVERT(varchar(12) , getdate(), 110 )\t\t\t\t09-12-2004\t\t\t\tselect CONVERT(varchar(12) , getdate(), 113 )\t\t\t\t12 09 2004 1\t\t\t\tselect CONVERT(varchar(12) , getdate(), 114 )\t\t\t\t11:06:08.177\t--                                                                                    ╔════════════════════╗\t-- =================================================================================  ║  数据库时间函数    ║\t--                                                                                    ╚════════════════════╝ \t\t\t\t-- 查询最近一个月内的点击率大于100的记录数据：\t\t\t\tselect * from t_business_product where hit_count>100 and datediff(Dd,last_date,getdate())<=30 order by id desc\t\t\t\t-- 查询最近一周内的点击率大于100的记录数据：\t\t\t\tselect * from t_business_product where hit_count>100 and datediff(Dw,last_date,getdate())<=7 order by id desc\t\t\t\t-- 你可以使用LIKE来返回正确的记录。通过在日期表达式中包含通配符“％”，\t\t\t\t-- 你可以匹配一个特定日期的所有时间。这里有一个例子：                --这个语句可以匹配正确的记录。因为通配符“％”代表了任何时间。\t\t\t\tSelect * FROM weblog Where entrydate LIKE ‘Dec 25 2000%’\t--                                                                                    ╔════════════════════╗\t-- =================================================================================  ║ CAST和CONVERT函数  ║\t--                                                                                    ╚════════════════════╝ select @@version     select convert(varchar(10),getdate(),120)  -- 只返回当前日期，且为2012-12-12格式（最有用）      --                                                                                    ╔════════════════════╗ -- =================================================================================  ║    第一天、第几月  ║ --                                                                                    ╚════════════════════╝  -- 1.一个月第一天的 Select DATEADD(mm, DATEDIFF(mm,0,getdate()), 0) -- 2.本周的星期一 Select DATEADD(wk, DATEDIFF(wk,0,getdate()), 0) -- 3.一年的第一天 Select DATEADD(yy, DATEDIFF(yy,0,getdate()), 0) -- 4.季度的第一天 Select DATEADD(qq, DATEDIFF(qq,0,getdate()), 0) -- 5.当天的半夜 Select DATEADD(dd, DATEDIFF(dd,0,getdate()), 0) -- 6.上个月的最后一天 Select dateadd(ms,-3,DATEADD(mm, DATEDIFF(mm,0,getdate()), 0)) -- 7.去年的最后一天 Select dateadd(ms,-3,DATEADD(yy, DATEDIFF(yy,0,getdate()), 0)) -- 8.本月的最后一天 Select dateadd(ms,-3,DATEADD(mm, DATEDIFF(m,0,getdate())+1, 0)) -- 9.本年的最后一天 Select dateadd(ms,-3,DATEADD(yy, DATEDIFF(yy,0,getdate())+1, 0)) -- 10.本月的第一个星期一 select DATEADD(wk, DATEDIFF(wk,0,dateadd(dd,6-datepart(day,getdate()),getdate())), 0)  select 本年第多少周=datename(week,getdate())  ,今天是周几=datename(weekday,getdate())             --  dateadd 在向指定日期加上一段时间的基础上，返回新的datetime值 -- 向日期加上2天 或 增加1个月 select dateadd(day,2,'2004-10-15') --返回：2004-10-17 00:00:00.000 select dateadd(month,2,'2004-10-15') --返回：2004-12-17 00:00:00.000 --3. datediff 返回跨两个指定日期的日期和时间边界数。     select datediff(day,'2004-09-01','2004-09-18') --返回天数：17                  select DateDiff(s,'2005-07-20','2005-7-25 22:56:32') --返回值为 514592 秒                  select DateDiff(ms,'2005-07-20','2005-7-25 22:56:32') --返回值为 微秒 select DateDiff(d,'2005-07-20','2005-7-25 22:56:32') -- 返回值为 5 天 select DatePart(w,'2005-7-25 22:56:32')--返回值为 2 即星期一(周日为1，周六为7) select DatePart('d','2005-7-25 22:56:32')--返回值为 25即25号 select DatePart('y','2005-7-25 22:56:32')--返回值为 206即这一年中第206天 select DatePart('yyyy','2005-7-25 22:56:32')--返回值为 2005即2005年 --DateDiff (interval,date1,date2) 以interval 指定的方式， --返回date2 与date1两个日期之间的差值 date2-date1 --DateAdd (interval,number,date) 以interval指定的方式，加上number之后的日期 --DatePart (interval,date) 返回日期date中，interval指定部分所对应的整数值 --DateName (interval,date) 返回日期date中，interval指定部分所对应的字符串名称 --                                                                                    ╔════════════════════╗ -- =================================================================================  ║  当前时间函数      ║ --                                                                                    ╚════════════════════╝  -- 返回当前日期和时间       select GETDATE() --  返回代表指定日期的指定日期部分的整数。 select datepart(month, '2004-10-15') --返回 月 select datepart(day, '2004-10-15') --返回 日 select datepart(year, getdate()) --返回 年    select convert(varchar(8),getdate(),114)  -- 当前时间    select datename(weekday, getdate()) --返回：星期五    select datepart(weekday, getdate()) --返回：小写星期2-1    select convert(varchar(10),getdate(),120)  -- 当前日期 select datepart(S, '2004-10-15') --返回 月 --  返回时间到豪秒                 Select CONVERT(VARCHAR(30),GETDATE(),9) --  获取当前日期，年、月、日、周、时、分、秒 select GETDATE() as '当前日期', DateName(year,GetDate()) as '年', DateName(month,GetDate()) as '月', DateName(day,GetDate()) as '日', DateName(dw,GetDate()) as '星期', DateName(week,GetDate()) as '周数', DateName(hour,GetDate()) as '时', DateName(minute,GetDate()) as '分', DateName(second,GetDate()) as '秒' print DateName(second,GetDate())+'1'             --  格式 select replace(replace(replace(CONVERT(varchar, getdate(), 120 ),'-',''),' ',''),':','') 20040912110608 select CONVERT(varchar(12) , getdate(), 111 ) 2004/09/12 select CONVERT(varchar(12) , getdate(), 112 ) 20040912 select CONVERT(varchar(12) , getdate(), 102 ) 2004.09.12 select CONVERT(varchar(12) , getdate(), 101 ) 09/12/2004 select CONVERT(varchar(12) , getdate(), 103 ) 12/09/2004 select CONVERT(varchar(12) , getdate(), 104 ) 12.09.2004 select CONVERT(varchar(12) , getdate(), 105 ) 12-09-2004 select CONVERT(varchar(12) , getdate(), 106 ) 12 09 2004 select CONVERT(varchar(12) , getdate(), 107 ) 09 12, 2004 select CONVERT(varchar(12) , getdate(), 108 ) 11:06:08 select CONVERT(varchar(12) , getdate(), 109 ) 09 12 2004 1 select CONVERT(varchar(12) , getdate(), 110 ) 09-12-2004 select CONVERT(varchar(12) , getdate(), 113 ) 12 09 2004 1 select CONVERT(varchar(12) , getdate(), 114 ) 11:06:08.177 --                                                                                    ╔════════════════════╗ -- =================================================================================  ║  数据库时间函数    ║ --                                                                                    ╚════════════════════╝  -- 查询最近一个月内的点击率大于100的记录数据： select * from t_business_product where hit_count>100 and datediff(Dd,last_date,getdate())<=30 order by id desc -- 查询最近一周内的点击率大于100的记录数据： select * from t_business_product where hit_count>100 and datediff(Dw,last_date,getdate())<=7 order by id desc -- 你可以使用LIKE来返回正确的记录。通过在日期表达式中包含通配符“％”， -- 你可以匹配一个特定日期的所有时间。这里有一个例子：                 --这个语句可以匹配正确的记录。因为通配符“％”代表了任何时间。 Select * FROM weblog Where entrydate LIKE ‘Dec 25 2000%’ --                                                                                    ╔════════════════════╗ -- =================================================================================  ║ CAST和CONVERT函数  ║ --                                                                                    ╚════════════════════╝  select @@version","title":"Sql Server起今为止最全的【日期函数大全】！（超经典，全部为示例）"},{"content":"sql语句优化  性能不理想的系统中除了一部分是因为应用程序的负载确实超过了服务器的实际处理能力外,更多的是因为系统存在大量的SQL语句需要优化。 为了获得稳定的执行性能，SQL语句越简单越好。对复杂的SQL语句，要设法对之进行简化。 常见的简化规则如下：   1）不要有超过5个以上的表连接（JOIN） 2）考虑使用临时表或表变量存放中间结果。 3）少用子查询 4）视图嵌套不要过深,一般视图嵌套不要超过2个为宜。   连接的表越多，其编译的时间和连接的开销也越大，性能越不好控制。 最好是把连接拆开成较小的几个部分逐个顺序执行。 优先执行那些能够大量减少结果的连接。 拆分的好处不仅仅是减少SQL Server优化的时间，更使得SQL语句能够以你可以预测的方式和顺序执行。 如果一定需要连接很多表才能得到数据，那么很可能意味着设计上的缺陷。   连接是outer join，非常不好。因为outer join意味着必须对左表或右表查询所有行。 如果表很大而没有相应的where语句，那么outer join很容易导致table scan或index scan。 要尽量使用inner join避免scan整个表。 优化建议：   1）使用临时表存放t1表的结果,能大大减少logical reads（或返回行数）的操作要优先执行。  仔细分析语句，你会发现where中的条件全是针对表t1的，所以直接使用上面的where子句查询表t1，然后把结果存放再临时表＃t1中：   Select t1….. into #tt1 from t1 where…(和上面的where一样)   2）再把＃tt1和其他表进行连接:   Select #t1… Left outer join … Left outer join…     3）修改 like 程序，去掉前置百分号。like语句却因为前置百分号而无法使用索引 4）从系统设计的角度修改语句，去掉outer join。 5）考虑组合索引或覆盖索引消除clustered index scan。   上面1和2点建议立即消除了worktable，性能提高了几倍以上，效果非常明显。       1）限制结果集   要尽量减少返回的结果行，包括行数和字段列数。 返回的结果越大，意味着相应的SQL语句的logical reads 就越大，对服务器的性能影响就越甚。 一个很不好的设计就是返回表的所有数据：   Select * from tablename   即使表很小也会导致并发问题。更坏的情况是，如果表有上百万行的话，那后果将是灾难性的。 它不但可能带来极重的磁盘IO，更有可能把数据库缓冲区中的其他缓存数据挤出，使得这些数据下次必须再从磁盘读取。 必须设计良好的SQL语句，使得其有where语句或TOP语句来限制结果集大小。 2）合理的表设计   SQL Server 2005将支持表分区技术。利用表分区技术可以实现数据表的流动窗口功能。 在流动窗口中可以轻易的把历史数据移出，把新的数据加入，从而使表的大小基本保持稳定。   另外，表的设计未必需要非常范式化。有一定的字段冗余可以增加SQL语句的效率，减少JOIN的数目，提高语句的执行速度。 3）OLAP和OLTP模块要分开   OLAP和OLTP类型的语句是截然不同的。前者往往需要扫描整个表做统计分析，索引对这样的语句几乎没有多少用处。 索引只能够加快那些如sum，group by之类的聚合运算。因为这个原因，几乎很难对OLAP类型的SQL语句进行优化。 而OLTP语句则只需要访问表的很小一部分数据，而且这些数据往往可以从内存缓存中得到。 为了避免OLAP 和OLTP语句相互影响，这两类模块需要分开运行在不同服务器上。 因为OLAP语句几乎都是读取数据，没有更新和写入操作，所以一个好的经验是配置一台standby 服务器，然后OLAP只访问standby服务器。 4）使用存储过程   可以考虑使用存储过程封装那些复杂的SQL语句或商业逻辑，这样做有几个好处。 一是存储过程的执行计划可以被缓存在内存中较长时间，减少了重新编译的时间。 二是存储过程减少了客户端和服务器的繁复交互。 三是如果程序发布后需要做某些改变你可以直接修改存储过程而不用修改程序，避免需要重新安装部署程序。      索引优化 很多数据库系统性能不理想是因为系统没有经过整体优化，存在大量性能低下的SQL 语句。 这类SQL语句性能不好的首要原因是缺乏高效的索引。 没有索引除了导致语句本身运行速度慢外，更是导致大量的磁盘读写操作，使得整个系统性能都受之影响而变差。 解决这类系统的首要办法是优化这些没有索引或索引不够好的SQL语句。 创建索引的关键     优化SQL语句的关键是尽可能减少语句的logical reads。   这里说的logical reads是指语句执行时需要访问的单位为8K的数据页总数。 logical reads 越少，其需要的内存和CPU时间也就越少，语句执行速度就越快。 不言而喻，索引的最大好处是它可以极大减少SQL语句的logical reads数目，从而极大减少语句的执行时间。 创建索引的关键是索引要能够大大减少语句的logical reads。一个索引好不好，主要看它减少的logical reads多不多。   运行set statistics io命令可以得到SQL语句的logical reads信息。 set statistics io on select au_id,au_lname ,au_fname  from pubs..authors where au_lname ='Green' set statistics io on 如果Logical reads很大，而返回的行数很少，也即两者相差较大，那么往往意味者语句需要优化。 Logical reads中包含该语句从内存数据缓冲区中访问的页数和从物理磁盘读取的页数。 而physical reads表示那些没有驻留在内存缓冲区中需要从磁盘读取的数据页。 Read-ahead reads是SQL Server为了提高性能而产生的预读。预读可能会多读取一些数据。  优化的时候我们主要关注Logical Reads就可以了。 注意如果physical Reads或Read-ahead reads很大，那么往往意味着语句的执行时间（duration）里面会有一部分耗费在等待物理磁盘IO上。 二、单字段索引，组合索引和覆盖索引 单字段索引是指只有一个字段的索引，而组合索引指有多个字段构成的索引。 1． 对出现在where子句中的字段加索引 set statistics profile on set statistics io on go select .... from tb where ... go set statistics profile off set statistics io off set statistics profile命令将输出语句的执行计划。 也许你会问，为什么不用SET SHOWPLAN_ALL呢？使用SET SHOWPLAN_ALL也是可以的。 不过set statistics profile输出的是SQL 语句的运行时候真正使用的执行计划， 而SET SHOWPLAN_ALL输出的是预计（Estimate）的执行计划。 使用SET SHOWPLAN_ALL是后面的语句并不会真正运行。 用了Table Scan，也就是对整个表进行了全表扫描。全表扫描的性能通常是很差的，要尽量避免。 如果上面的select语句是数据库系统经常运行的关键语句， 那么应该对它创建相应的索引。 创建索引的技巧之一是对经常出现在where条件中的字段创建索引 Table Scan也变成了Index Seek，性能极大提高 设法避免Table scan或Index scan是优化SQL 语句使用的常用技巧。通常Index Seek需要的logical reads比前两者要少得多。 2．组合索引   如果where语句中有多个字段，那么可以考虑创建组合索引。 组合索引中字段的顺序是非常重要的，越是唯一的字段越是要靠前。 另外，无论是组合索引还是单个列的索引，尽量不要选择那些唯一性很低的字段。 比如说，在只有两个值0和1的字段上建立索引没有多大意义。 所以如果对单字段进行索引，建议使用set statistics profile来验证索引确实被充分使用。logical reads越少的索引越好。 3．覆盖索引 覆盖索引能够使得语句不需要访问表仅仅访问索引就能够得到所有需要的数据。 因为聚集索引叶子节点就是数据所以无所谓覆盖与否，所以覆盖索引主要是针对非聚集索引而言。 执行计划中除了index seek外，还有一个Bookmark Lookup关键字。   Bookmark Lookup表示语句在访问索引后还需要对表进行额外的Bookmark Lookup操作才能得到数据。 也就是说为得到一行数据起码有两次IO，一次访问索引，一次访问基本表。 如果语句返回的行数很多，那么Bookmark Lookup操作的开销是很大的。 覆盖索引能够避免昂贵的Bookmark Lookup操作，减少IO的次数，提高语句的性能。 覆盖索引需要包含select子句和WHERE子句中出现的所有字段。Where语句中的字段在前面，select中的在后面。 logical reads，是大大减少了。Bookmark Lookup操作也消失了。所以创建覆盖索引是减少logical reads提升语句性能的非常有用的优化技巧。 实际上索引的创建原则是比较复杂的。有时候你无法在索引中包含了Where子句中所有的字段。 在考虑索引是否应该包含一个字段时，应考虑该字段在语句中的作用。 比如说如果经常以某个字段作为where条件作精确匹配返回很少的行，那么就绝对值得为这个字段建立索引。 再比如说，对那些非常唯一的字段如主键和外键，经常出现在group by，order by中的字段等等都值得创建索引。 问题1，是否值得在identity字段上建立聚集索引。 答案取决于identity 字段如何在语句中使用。如果你经常根据该字段搜索返回很少的行，那么在其上建立索引是值得的。 反之如果identity字段根本很少在语句中使用，那么就不应该对其建立任何索引。   问题2，一个表应该建立多少索引合适。 如果表的80％以上的语句都是读操作，那么索引可以多些。但是不要太多。 特别是不要对那些更新频繁的表其建立很多的索引。很少表有超过5个以上的索引。 过多的索引不但增加其占用的磁盘空间，也增加了SQL Server 维护索引的开销。   问题4：为什么SQL Server 在执行计划中没有使用你认为应该使用的索引？原因是多样的。 一种原因是该语句返回的结果超过了表的20％数据，使得SQL Server 认为scan比seek更有效。   另一种原因可能是表字段的statistics过期了，不能准确反映数据的分布情况。 你可以使用命令UPDATE STATISTICS tablename with FULLSCAN来更新它。 只有同步的准确的statistics才能保证SQL Server 产生正确的执行计划。 过时的老的statistics常会导致SQL Server生成不够优化的甚至愚蠢的执行计划。 所以如果你的表频繁更新，而你又觉得和之相关的SQL语句运行缓慢，不妨试试UPDATE STATISTIC with FULLSCAN 语句。 问题5、什么使用聚集索引，什么时候使用非聚集索引   在SQL Server 中索引有聚集索引和非聚集索引两种。它们的主要差别是前者的索引叶子就是数据本身，而后者的叶子节点包含的是指向数据的书签（即数据行号或聚集索引的key）。   对一个表而言聚集索引只能有一个，而非聚集索引可以有多个。   只是聚集索引没有Bookmark Lookup操作。   什么时候应该使用聚集索引?  什么时候使用非聚集索引? 取决于应用程序的访问模式。   我的建议是在那些关键的字段上使用聚集索引。一个表一般都需要建立一个聚集索引。   对于什么时候使用聚集索引，SQL Server 2000联机手册中有如下描述：   在创建聚集索引之前，应先了解您的数据是如何被访问的。可考虑将聚集索引用于：   包含大量非重复值的列。   使用下列运算符返回一个范围值的查询：BETWEEN、>、>=、< 和 <=。   被连续访问的列。   返回大型结果集的查询。   经常被使用联接或 GROUP BY 子句的查询访问的列；一般来说，这些是外键列。   对 ORDER BY 或 GROUP BY 子句中指定的列进行索引，可以使 SQL Server 不必对数据进行排序，因为这些行已经排序。这样可以提高查询性能。   OLTP 类型的应用程序，这些程序要求进行非常快速的单行查找（一般通过主键）。应在主键上创建聚集索引。   聚集索引不适用于：   频繁更改的列   这将导致整行移动（因为 SQL Server 必须按物理顺序保留行中的数据值）。这一点要特别注意，因为在大数据量事务处理系统中数据是易失的。   宽键    来自聚集索引的键值由所有非聚集索引作为查找键使用，因此存储在每个非聚集索引的叶条目内。   总结：   如何使一个性能缓慢的系统运行更快更高效，不但需要整体分析数据库系统，找出系统的性能瓶颈，更需要优化数据库系统发出的SQL 语句。 一旦找出关键的SQL 语句并加与优化，性能问题就会迎刃而解。             《 数据库技术内幕 》 处理百万级以上的数据提高查询速度的方法：  1.应尽量避免在 where 子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描。  2.对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。  3.应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如：      select id from t where num is null      可以在num上设置默认值0，确保表中num列没有null值，然后这样查询：      select id from t where num=0  4.应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如：      select id from t where num=10 or num=20      可以这样查询：      select id from t where num=10      union all      select id from t where num=20  5.下面的查询也将导致全表扫描：(不能前置百分号)      select id from t where name like ‘%abc%’     若要提高效率，可以考虑全文检索。  6.in 和 not in 也要慎用，否则会导致全表扫描，如：      select id from t where num in(1,2,3)      对于连续的数值，能用 between 就不要用 in 了：      select id from t where num between 1 and 3 select xx,phone FROM send  a JOIN (  select '13891030091' phone  union select '13992085916' …………  UNION  SELECT '13619100234' ) b    on  a.Phone=b.phone --替代下面  很多数据隔开的时候 in('13891030091','13992085916','13619100234'…………)   7.如果在 where 子句中使用参数，也会导致全表扫描。因为SQL只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然 而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描：      select id from t where num=@num     可以改为强制查询使用索引：      select id from t with(index(索引名)) where num=@num  8.应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如：      select id from t where num/2=100      应改为:      select id from t where num=100*2  9.应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如：      select id from t where substring(name,1,3)=’abc’–name以abc开头的id      select id from t where datediff(day,createdate,’2005-11-30′)=0–’2005-11-30′生成的id      应改为:      select id from t where name like ‘abc%’      select id from t where createdate>=’2005-11-30′ and createdate<’2005-12-1′  10.不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。  11.在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使 用，并且应尽可能的让字段顺序与索引顺序相一致。  12.不要写一些没有意义的查询，如需要生成一个空表结构：      select col1,col2 into #t from t where 1=0      这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样：      create table #t(…)  13.很多时候用 exists 代替 in 是一个好的选择：      select num from a where num in(select num from b)      用下面的语句替换：      select num from a where exists(select 1 from b where num=a.num)  14.并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引，如一表中有字段 sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。  15.索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有 必要。  16.应尽可能的避免更新 clustered 索引数据列，因为 clustered 索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新 clustered 索引数据列，那么需要考虑是否应将该索引建为 clustered 索引。  17.尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会 逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。  18.尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。  19.任何地方都不要使用 select * from t ，用具体的字段列表代替“*”，不要返回用不到的任何字段。  20.尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。  21.避免频繁创建和删除临时表，以减少系统表资源的消耗。  22.临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件，最好使 用导出表。  23.在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert。  24.如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。  25.尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。  26.使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。  27.与临时表一样，游标并不是不可使用。对小型数据集使用 FAST_FORWARD 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时 间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。  28.在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON ，在结束时设置 SET NOCOUNT OFF 。无需在执行存储过程和触发器的每个语句后向客户端发送 DONE_IN_PROC 消息。  29.尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。  30.尽量避免大事务操作，提高系统并发能力。 查询速度慢的原因： 1、没有索引或者没有用到索引(这是查询慢最常见的问题，是程序设计的缺陷)    2、I/O吞吐量小，形成了瓶颈效应。   3、没有创建计算列导致查询不优化。    4、内存不足   5、网络速度慢   6、查询出的数据量过大（可以采用多次查询，其他的方法降低数据量）   7、锁或者死锁(这也是查询慢最常见的问题，是程序设计的缺陷)   8、sp_lock,sp_who,活动的用户查看,原因是读写竞争资源。    9、返回了不必要的行和列   10、查询语句不好，没有优化   可以通过如下方法来优化查询   1、把数据、日志、索引放到不同的I/O设备上，增加读取速度，以前可以将Tempdb应放在RAID0上，SQL2000不在支持。数据量（尺寸）越大，提高I/O越重要.   2、纵向、横向分割表，减少表的尺寸(sp_spaceuse)   3、升级硬件   4、根据查询条件,建立索引,优化索引、优化访问方式，限制结果集的数据量。注意填充因子要适当（最好是使用默认值0）。索引应该尽量小，使用字节数小的列建索引好（参照索引的创建）,不要对有限的几个值的字段建单一索引如性别字段   5、提高网速;   6、扩大服务器的内存,Windows   2000和SQL   server   2000能支持4-8G的内存。配置虚拟内存：虚拟内存大小应基于计算机上并发运行的服务进行配置。运行   Microsoft   SQL   Server?   2000   时，可考虑将虚拟内存大小设置为计算机中安装的物理内存的   1.5   倍。如果另外安装了全文检索功能，并打算运行   Microsoft   搜索服务以便执行全文索引和查询，可考虑：将虚拟内存大小配置为至少是计算机中安装的物理内存的   3   倍。将   SQL   Server   max   server   memory   服务器配置选项配置为物理内存的   1.5   倍（虚拟内存大小设置的一半）。   7、增加服务器CPU个数;但是必须明白并行处理串行处理更需要资源例如内存。使用并行还是串行程是MsSQL自动评估选择的。单个任务分解成多个任务，就可以在处理器上运行。例如耽搁查询的排序、连接、扫描和GROUP   BY字句同时执行，SQL   SERVER根据系统的负载情况决定最优的并行等级，复杂的需要消耗大量的CPU的查询最适合并行处理。但是更新操作UPDATE,INSERT， DELETE还不能并行处理。   8、如果是使用like进行查询的话，简单的使用index是不行的，但是全文索引，耗空间。   like   'a%'   使用索引   like   '%a'   不使用索引用   like   '%a%'   查询时，查询耗时和字段值总长度成正比,所以不能用CHAR类型，而是VARCHAR。对于字段的值很长的建全文索引。   9、DB   Server   和APPLication   Server   分离；OLTP和OLAP分离   10、分布式分区视图可用于实现数据库服务器联合体。联合体是一组分开管理的服务器，但它们相互协作分担系统的处理负荷。这种通过分区数据形成数据库服务器联合体的机制能够扩大一组服务器，以支持大型的多层   Web   站点的处理需要。有关更多信息，参见设计联合数据库服务器。（参照SQL帮助文件'分区视图'）       a、在实现分区视图之前，必须先水平分区表       b、在创建成员表后，在每个成员服务器上定义一个分布式分区视图，并且每个视图具有相同的名称。这样，引用分布式分区视图名的查询可以在任何一个成员服务器上运行。系统操作如同每个成员服务器上都有一个原始表的复本一样，但其实每个服务器上只有一个成员表和一个分布式分区视图。数据的位置对应用程序是透明的。   11、重建索引   DBCC   REINDEX   ,DBCC   INDEXDEFRAG,收缩数据和日志   DBCC   SHRINKDB,DBCC   SHRINKFILE.   设置自动收缩日志.对于大的数据库不要设置数据库自动增长，它会降低服务器的性能。   在T-sql的写法上有很大的讲究，下面列出常见的要点：首先，DBMS处理查询计划的过程是这样的：       1、   查询语句的词法、语法检查               2、   将语句提交给DBMS的查询优化器       3、   优化器做代数优化和存取路径的优化       4、   由预编译模块生成查询规划       5、   然后在合适的时间提交给系统处理执行       6、   最后将执行结果返回给用户其次，看一下SQL   SERVER的数据存放的结构：一个页面的大小为8K(8060)字节，8个页面为一个盘区，按照B树存放。   12、Commit和rollback的区别   Rollback:回滚所有的事物。   Commit:提交当前的事物.   没有必要在动态SQL里写事物，如果要写请写在外面如：   begin   tran   exec(@s)   commit   trans   或者将动态SQL   写成函数或者存储过程。   13、在查询Select语句中用Where字句限制返回的行数,避免表扫描,如果返回不必要的数据，浪费了服务器的I/O资源，加重了网络的负担降低性能。如果表很大，在表扫描的期间将表锁住，禁止其他的联接访问表,后果严重。   14、SQL的注释申明对执行没有任何影响   15、尽可能不使用游标，它占用大量的资源。如果需要row-by-row地执行，尽量采用非光标技术,如：在客户端循环，用临时表，Table变量，用子查询，用Case语句等等。游标可以按照它所支持的提取选项进行分类：   只进   必须按照从第一行到最后一行的顺序提取行。FETCH   NEXT   是唯一允许的提取操作,也是默认方式。可滚动性   可以在游标中任何地方随机提取任意行。游标的技术在SQL2000下变得功能很强大，他的目的是支持循环。   有四个并发选项   READ_ONLY：不允许通过游标定位更新(Update)，且在组成结果集的行中没有锁。   OPTIMISTIC   WITH   valueS:乐观并发控制是事务控制理论的一个标准部分。乐观并发控制用于这样的情形，即在打开游标及更新行的间隔中，只有很小的机会让第二个用户更新某一行。当某个游标以此选项打开时，没有锁控制其中的行，这将有助于最大化其处理能力。如果用户试图修改某一行，则此行的当前值会与最后一次提取此行时获取的值进行比较。如果任何值发生改变，则服务器就会知道其他人已更新了此行，并会返回一个错误。如果值是一样的，服务器就执行修改。   选择这个并发选项OPTIMISTIC   WITH   ROW   VERSIONING:此乐观并发控制选项基于行版本控制。使用行版本控制，其中的表必须具有某种版本标识符，服务器可用它来确定该行在读入游标后是否有所更改。   在   SQL   Server   中，这个性能由   timestamp   数据类型提供，它是一个二进制数字，表示数据库中更改的相对顺序。每个数据库都有一个全局当前时间戳值：@@DBTS。每次以任何方式更改带有   timestamp   列的行时，SQL   Server   先在时间戳列中存储当前的   @@DBTS   值，然后增加   @@DBTS   的值。如果某   个表具有   timestamp   列，则时间戳会被记到行级。服务器就可以比较某行的当前时间戳值和上次提取时所存储的时间戳值，从而确定该行是否已更新。服务器不必比较所有列的值，只需比较   timestamp   列即可。如果应用程序对没有   timestamp   列的表要求基于行版本控制的乐观并发，则游标默认为基于数值的乐观并发控制。   SCROLL   LOCKS   这个选项实现悲观并发控制。在悲观并发控制中，在把数据库的行读入游标结果集时，应用程序将试图锁定数据库行。在使用服务器游标时，将行读入游标时会在其上放置一个更新锁。如果在事务内打开游标，则该事务更新锁将一直保持到事务被提交或回滚；当提取下一行时，将除去游标锁。如果在事务外打开游标，则提取下一行时，锁就被丢弃。因此，每当用户需要完全的悲观并发控制时，游标都应在事务内打开。更新锁将阻止任何其它任务获取更新锁或排它锁，从而阻止其它任务更新该行。   然而，更新锁并不阻止共享锁，所以它不会阻止其它任务读取行，除非第二个任务也在要求带更新锁的读取。滚动锁根据在游标定义的   SELECT   语句中指定的锁提示，这些游标并发选项可以生成滚动锁。滚动锁在提取时在每行上获取，并保持到下次提取或者游标关闭，以先发生者为准。下次提取时，服务器为新提取中的行获取滚动锁，并释放上次提取中行的滚动锁。滚动锁独立于事务锁，并可以保持到一个提交或回滚操作之后。如果提交时关闭游标的选项为关，则   COMMIT   语句并不关闭任何打开的游标，而且滚动锁被保留到提交之后，以维护对所提取数据的隔离。所获取滚动锁的类型取决于游标并发选项和游标   SELECT   语句中的锁提示。   锁提示   只读   乐观数值   乐观行版本控制   锁定无提示   未锁定   未锁定   未锁定   更新   NOLOCK   未锁定   未锁定   未锁定   未锁定   HOLDLOCK   共享   共享   共享   更新   UPDLOCK   错误   更新   更新   更新   TABLOCKX   错误   未锁定   未锁定   更新其它   未锁定   未锁定   未锁定   更新   *指定   NOLOCK   提示将使指定了该提示的表在游标内是只读的。   16、用Profiler来跟踪查询，得到查询所需的时间，找出SQL的问题所在;用索引优化器优化索引   17、注意UNion和UNion   all   的区别。UNION   all好   18、注意使用DISTINCT，在没有必要时不要用，它同UNION一样会使查询变慢。重复的记录在查询里是没有问题的   19、查询时不要返回不需要的行、列   20、用sp_configure   'query   governor   cost   limit'或者SET   QUERY_GOVERNOR_COST_LIMIT来限制查询消耗的资源。当评估查询消耗的资源超出限制时，服务器自动取消查询,在查询之前就扼杀掉。 SET   LOCKTIME设置锁的时间   21、用select   top   100   /   10   Percent   来限制用户返回的行数或者SET   ROWCOUNT来限制操作的行   22、在SQL2000以前，一般不要用如下的字句 “IS   NULL\",   \" <> \",   \"!=\",   \"!> \",   \"! <\",   \"NOT\",   \"NOT   EXISTS\",   \"NOT   IN\",   \"NOT   LIKE\",   and   \"LIKE   '%500'\"，因为他们不走索引全是表扫描。 也不要在WHere字句中的列名加函数，如Convert，substring等,如果必须用函数的时候，创建计算列再创建索引来替代.还可以变通写法：WHERE   SUBSTRING(firstname,1,1)   =   'm'改为WHERE   firstname   like   'm%'（索引扫描），一定要将函数和列名分开。并且索引不能建得太多和太大。 NOT   IN会多次扫描表，使用EXISTS、NOT   EXISTS   ，IN   ,   LEFT   OUTER   JOIN   来替代，特别是左连接,而Exists比IN更快，最慢的是NOT操作.如果列的值含有空，以前它的索引不起作用，现在2000的优化器能够处理了。相同的是IS   NULL，“NOT\",   \"NOT   EXISTS\",   \"NOT   IN\"能优化她，而” <> ”等还是不能优化，用不到索引。   23、使用Query   Analyzer，查看SQL语句的查询计划和评估分析是否是优化的SQL。一般的20%的代码占据了80%的资源，我们优化的重点是这些慢的地方。   24、如果使用了IN或者OR等时发现查询没有走索引，使用显示申明指定索引：   SELECT   *   FROM   PersonMember   (INDEX   =   IX_Title)   WHERE   processid   IN   (‘男’，‘女’)   25、将需要查询的结果预先计算好放在表中，查询的时候再SELECT。这在SQL7.0以前是最重要的手段。例如医院的住院费计算。   26、MIN()   和   MAX()能使用到合适的索引   27、数据库有一个原则是代码离数据越近越好，所以优先选择Default,依次为Rules,Triggers,   Constraint（约束如外健主健CheckUNIQUE……,数据类型的最大长度等等都是约束）,Procedure.这样不仅维护工作小，编写程序质量高，并且执行的速度快。   28、如果要插入大的二进制值到Image列，使用存储过程，千万不要用内嵌INsert来插入(不知JAVA是否)。因为这样应用程序首先将二进制值转换成字符串（尺寸是它的两倍），服务器受到字符后又将他转换成二进制值.存储过程就没有这些动作:   方法：Create   procedure   p_insert   as   insert   into   table(Fimage)   values   (@image),   在前台调用这个存储过程传入二进制参数，这样处理速度明显改善。   29、Between在某些时候比IN速度更快,Between能够更快地根据索引找到范围。用查询优化器可见到差别。   select   *   from   chineseresume   where   title   in   ('男','女')   Select   *   from   chineseresume   where   between   '男'   and   '女'   是一样的。由于in会在比较多次，所以有时会慢些。   30、在必要是对全局或者局部临时表创建索引，有时能够提高速度，但不是一定会这样，因为索引也耗费大量的资源。他的创建同是实际表一样。   31、不要建没有作用的事物例如产生报表时，浪费资源。只有在必要使用事物时使用它。   32、用OR的字句可以分解成多个查询，并且通过UNION   连接多个查询。他们的速度只同是否使用索引有关,如果查询需要用到联合索引，用UNION   all执行的效率更高.多个OR的字句没有用到索引，改写成UNION的形式再试图与索引匹配。一个关键的问题是否用到索引。   33、尽量少用视图，它的效率低。对视图操作比直接对表操作慢,可以用stored   procedure来代替她。特别的是不要用视图嵌套,嵌套视图增加了寻找原始资料的难度。我们看视图的本质：它是存放在服务器上的被优化好了的已经产生了查询规划的SQL。对单个表检索数据时，不要使用指向多个表的视图，直接从表检索或者仅仅包含这个表的视图上读，否则增加了不必要的开销,查询受到干扰.为了加快视图的查询，MsSQL增加了视图索引的功能。   34、没有必要时不要用DISTINCT和ORDER   BY，这些动作可以改在客户端执行。它们增加了额外的开销。这同UNION   和UNION   ALL一样的道理。   SELECT   top   20   ad.companyname,comid,position,ad.referenceid,worklocation,   convert(varchar(10),ad.postDate,120)   as   postDate1,workyear,degreedescription   FROM   jobcn_query.dbo.COMPANYAD_query   ad   where   referenceID   in('JCNAD00329667','JCNAD132168','JCNAD00337748','JCNAD00338345','JCNAD00333138','JCNAD00303570',   'JCNAD00303569','JCNAD00303568','JCNAD00306698','JCNAD00231935','JCNAD00231933','JCNAD00254567',   'JCNAD00254585','JCNAD00254608','JCNAD00254607','JCNAD00258524','JCNAD00332133','JCNAD00268618',   'JCNAD00279196','JCNAD00268613')   order   by   postdate   desc   35、在IN后面值的列表中，将出现最频繁的值放在最前面，出现得最少的放在最后面，减少判断的次数   36、当用SELECT   INTO时，它会锁住系统表(sysobjects，sysindexes等等)，阻塞其他的连接的存取。创建临时表时用显示申明语句，而不是 select   INTO.   drop   table   t_lxh   begin   tran   select   *   into   t_lxh   from   chineseresume   where   name   =   'XYZ'   --commit   在另一个连接中SELECT   *   from   sysobjects可以看到   SELECT   INTO   会锁住系统表，Create   table   也会锁系统表(不管是临时表还是系统表)。所以千万不要在事物内使用它！！！这样的话如果是经常要用的临时表请使用实表，或者临时表变量。   37、一般在GROUP   BY   个HAVING字句之前就能剔除多余的行，所以尽量不要用它们来做剔除行的工作。他们的执行顺序应该如下最优：select   的Where字句选择所有合适的行，Group   By用来分组个统计行，Having字句用来剔除多余的分组。这样Group   By   个Having的开销小，查询快.对于大的数据行进行分组和Having十分消耗资源。如果Group   BY的目的不包括计算，只是分组，那么用Distinct更快   38、一次更新多条记录比分多次更新每次一条快,就是说批处理好   39、少用临时表，尽量用结果集和Table类性的变量来代替它,Table   类型的变量比临时表好   40、在SQL2000下，计算字段是可以索引的，需要满足的条件如下：     a、计算字段的表达是确定的     b、不能用在TEXT,Ntext，Image数据类型     c、必须配制如下选项   ANSI_NULLS   =   ON,   ANSI_PADDINGS   =   ON,   …….   41、尽量将数据的处理工作放在服务器上，减少网络的开销，如使用存储过程。存储过程是编译好、优化过、并且被组织到一个执行规划里、且存储在数据库中的 SQL语句，是控制流语言的集合，速度当然快。反复执行的动态SQL,可以使用临时存储过程，该过程（临时表）被放在Tempdb中。以前由于SQL   SERVER对复杂的数学计算不支持，所以不得不将这个工作放在其他的层上而增加网络的开销。SQL2000支持UDFs,现在支持复杂的数学计算，函数的返回值不要太大，这样的开销很大。用户自定义函数象光标一样执行的消耗大量的资源，如果返回大的结果采用存储过程   42、不要在一句话里再三的使用相同的函数，浪费资源,将结果放在变量里再调用更快   43、SELECT   COUNT(*)的效率教低，尽量变通他的写法，而EXISTS快.同时请注意区别：   select   count(Field   of   null)   from   Table   和   select   count(Field   of   NOT   null)   from   Table   的返回值是不同的。   44、当服务器的内存够多时，配制线程数量   =   最大连接数+5，这样能发挥最大的效率；否则使用   配制线程数量 <最大连接数启用SQL   SERVER的线程池来解决,如果还是数量   =   最大连接数+5，严重的损害服务器的性能。   45、按照一定的次序来访问你的表。如果你先锁住表A，再锁住表B，那么在所有的存储过程中都要按照这个顺序来锁定它们。如果你（不经意的）某个存储过程中先锁定表B，再锁定表A，这可能就会导致一个死锁。如果锁定顺序没有被预先详细的设计好，死锁很难被发现   46、通过SQL   Server   Performance   Monitor监视相应硬件的负载   Memory:   Page   Faults   /   sec计数器如果该值偶尔走高，表明当时有线程竞争内存。如果持续很高，则内存可能是瓶颈。   Process:       1、%   DPC   Time   指在范例间隔期间处理器用在缓延程序调用(DPC)接收和提供服务的百分比。(DPC   正在运行的为比标准间隔优先权低的间隔)。   由于   DPC   是以特权模式执行的，DPC   时间的百分比为特权时间   百分比的一部分。这些时间单独计算并且不属于间隔计算总数的一部   分。这个总数显示了作为实例时间百分比的平均忙时。       2、%Processor   Time计数器　如果该参数值持续超过95%，表明瓶颈是CPU。可以考虑增加一个处理器或换一个更快的处理器。       3、%   Privileged   Time   指非闲置处理器时间用于特权模式的百分比。(特权模式是为操作系统组件和操纵硬件驱动程序而设计的一种处理模式。它允许直接访问硬件和所有内存。另一种模式为用户模式，它是一种为应用程序、环境分系统和整数分系统设计的一种有限处理模式。操作系统将应用程序线程转换成特权模式以访问操作系统服务)。   特权时间的   %   包括为间断和   DPC   提供服务的时间。特权时间比率高可能是由于失败设备产生的大数量的间隔而引起的。这个计数器将平均忙时作为样本时间的一部分显示。       4、%   User   Time表示耗费CPU的数据库操作，如排序，执行aggregate   functions等。如果该值很高，可考虑增加索引，尽量使用简单的表联接，水平分割大表格等方法来降低该值。   Physical   Disk:   Curretn   Disk   Queue   Length计数器该值应不超过磁盘数的1.5~2倍。要提高性能，可增加磁盘。   SQLServer:Cache   Hit   Ratio计数器该值越高越好。如果持续低于80%，应考虑增加内存。   注意该参数值是从SQL   Server启动后，就一直累加记数，所以运行经过一段时间后，该值将不能反映系统当前值。   47、分析select   emp_name   form   employee   where   salary   >   3000   在此语句中若salary是Float类型的，则优化器对其进行优化为Convert(float,3000)，因为3000是个整数，我们应在编程时使用3000.0而不要等运行时让DBMS进行转化。同样字符和整型数据的转换。","title":"sql语句优化"},{"content":"SELECT p.product_directory_level  , COUNT (CASE WHEN p.product_directory_level = 1 THEN 1                                                  ELSE NULL                                             END) 物资,                             COUNT (CASE WHEN p.product_directory_level = 2 THEN 1                                             ELSE NULL                                             END) 大类,                                                                        COUNT (CASE WHEN p.product_directory_level = 3 THEN 1                                             ELSE NULL                                             END) 中类,                             COUNT (CASE WHEN p.product_directory_level = 4 THEN 1                                             ELSE NULL                                             END) 小类,                             COUNT (CASE WHEN p.product_directory_level = 5 THEN 1                                             ELSE NULL                                             END) 细类    FROM pl_product_directory p GROUP BY   p.product_directory_level ORDER BY  p.product_directory_level ; 使用select  case when 语句就能轻松搞定","title":"oracle中用一条select 语句把符合多个条件的查询结果列出来"},{"content":"SQL批处理是JDBC性能优化的重要武器，经本人研究总结，批处理的用法有三种。   package lavasoft.jdbctest; import lavasoft.common.DBToolkit; import java.sql.Connection; import java.sql.PreparedStatement; import java.sql.SQLException; import java.sql.Statement; /** * JDBC的批量操作三种方式 * * @author leizhimin 2009-12-4 14:42:11 */ public class BatchExeSQLTest {         public static void main(String[] args) {                 exeBatchStaticSQL();         }         /**          * 批量执行预定义模式的SQL          */         public static void exeBatchParparedSQL() {                 Connection conn = null;                 try {                         conn = DBToolkit.getConnection();                         String sql = \"insert into testdb.book (kind, name) values (?,?)\";                         PreparedStatement pstmt = conn.prepareStatement(sql);                         pstmt.setString(1, \"java\");                         pstmt.setString(2, \"jjjj\");                         pstmt.addBatch();                     //添加一次预定义参数                         pstmt.setString(1, \"ccc\");                         pstmt.setString(2, \"dddd\");                         pstmt.addBatch();                     //再添加一次预定义参数                         //批量执行预定义SQL                         pstmt.executeBatch();                 } catch (SQLException e) {                         e.printStackTrace();                 } finally {                         DBToolkit.closeConnection(conn);                 }         }         /**          * 批量执行混合模式的SQL、有预定义的，还有静态的          */         public static void exeBatchMixedSQL() {                 Connection conn = null;                 try {                         conn = DBToolkit.getConnection();                         String sql = \"insert into testdb.book (kind, name) values (?,?)\";                         PreparedStatement pstmt = conn.prepareStatement(sql);                         pstmt.setString(1, \"java\");                         pstmt.setString(2, \"jjjj\");                         pstmt.addBatch();    //添加一次预定义参数                         pstmt.setString(1, \"ccc\");                         pstmt.setString(2, \"dddd\");                         pstmt.addBatch();    //再添加一次预定义参数                         //添加一次静态SQL                         pstmt.addBatch(\"update testdb.book set kind = 'JAVA' where kind='java'\");                         //批量执行预定义SQL                         pstmt.executeBatch();                 } catch (SQLException e) {                         e.printStackTrace();                 } finally {                         DBToolkit.closeConnection(conn);                 }         }         /**          * 执行批量静态的SQL          */         public static void exeBatchStaticSQL() {                 Connection conn = null;                 try {                         conn = DBToolkit.getConnection();                         Statement stmt = conn.createStatement();                         //连续添加多条静态SQL                         stmt.addBatch(\"insert into testdb.book (kind, name) values ('java', 'java in aciton')\");                         stmt.addBatch(\"insert into testdb.book (kind, name) values ('c', 'c in aciton')\");                         stmt.addBatch(\"delete from testdb.book where kind ='C#'\");                         stmt.addBatch(\"update testdb.book set kind = 'JAVA' where kind='java'\"); //                        stmt.addBatch(\"select count(*) from testdb.book\");                //批量执行不支持Select语句                         //执行批量执行                         stmt.executeBatch();                 } catch (SQLException e) {                         e.printStackTrace();                 } finally {                         DBToolkit.closeConnection(conn);                 }         } } 注意：JDBC的批处理不能加入select语句，否则会抛异常： java.sql.BatchUpdateException: Can not issue SELECT via executeUpdate().   at com.mysql.jdbc.StatementImpl.executeBatch(StatementImpl.java:1007)","title":"JDBC的批处理操作三种方式"},{"content":"repcached介绍 repcached是日本人开发的实现memcached复制功能，它是一个单 master单 slave的方案，但它的 master/slave都是可读写的，而且可以相互同步，如果 master坏掉， slave侦测到连接断了，它会自动 listen而成为 master；而如果 slave坏掉， master也会侦测到连接断，它就会重新 listen等待新的 slave加入。 安装步骤 1.安装libevent-devel包 因为repcached依赖于libevent-devel包，所以首先安装libevent-devel包 下载地址：http://www.monkey.org/~provos/libevent-1.4.13-stable.tar.gz --尝试使用yum安装失败 [root@njdyw memcached-1.2.8-repcached-2.2]# yum install libevent-devel Loaded plugins: rhnplugin, security This system is not registered with ULN. ULN support will be disabled. Setting up Install Process No package libevent-devel available. Nothing to do --下载再安装 [root@njdyw ~]# wget http://www.monkey.org/~provos/libevent-1.4.13-stable.tar.gz [root@njdyw ~]# tar zxvf libevent-1.4.13-stable.tar.gz [root@njdyw ~]# cd libevent-1.4.13-stable [root@njdyw libevent-1.4.13-stable]# ./configure --prefix=/usr/local/libevent [root@njdyw libevent-1.4.13-stable]# make && make install 2.安装repcached (1).下载对应的repcached版本(里面已经包含了memcached) [root@njdyw ~]# wget http://downloads.sourceforge.net/repcached/memcached-1.2.8-repcached-2.2.tar.gz --2012-12-30 22:44:28--  http://downloads.sourceforge.net/repcached/memcached-1.2.8-repcached-2.2.tar.gz 正在解析主机 downloads.sourceforge.net... 216.34.181.59 Connecting to downloads.sourceforge.net|216.34.181.59|:80... 已连接。 已发出 HTTP 请求，正在等待回应... 301 Moved Permanently 位置：http://downloads.sourceforge.net/project/repcached/repcached/2.2-1.2.8/memcached-1.2.8-repcached-2.2.tar.gz [跟随至新的 URL] --2012-12-30 22:44:28--  http://downloads.sourceforge.net/project/repcached/repcached/2.2-1.2.8/memcached-1.2.8-repcached-2.2.tar.gz Reusing existing connection to downloads.sourceforge.net:80. 已发出 HTTP 请求，正在等待回应... 302 Found 位置：http://jaist.dl.sourceforge.net/project/repcached/repcached/2.2-1.2.8/memcached-1.2.8-repcached-2.2.tar.gz [跟随至新的 URL] --2012-12-30 22:44:29--  http://jaist.dl.sourceforge.net/project/repcached/repcached/2.2-1.2.8/memcached-1.2.8-repcached-2.2.tar.gz 正在解析主机 jaist.dl.sourceforge.net... 150.65.7.130, 2001:200:141:feed::feed Connecting to jaist.dl.sourceforge.net|150.65.7.130|:80... 已连接。 已发出 HTTP 请求，正在等待回应... 200 OK 长度：227510 (222K) [application/x-gzip] Saving to: `memcached-1.2.8-repcached-2.2.tar.gz' 100%[==========================================================================================>] 227,510      104K/s   in 2.1s    2012-12-30 22:44:32 (104 KB/s) - `memcached-1.2.8-repcached-2.2.tar.gz' saved [227510/227510] (2).解压下载文件 [root@njdyw ~]# tar zxvf memcached-1.2.8-repcached-2.2.tar.gz [root@njdyw ~]# cd memcached-1.2.8-repcached-2.2/ [root@njdyw memcached-1.2.8-repcached-2.2]# ls aclocal.m4         ChangeLog.repcached  configure.ac  items.c             memcached_dtrace.h  replication.c  stats.h assoc.c            compile              COPYING       items.h             memcached.h         replication.h  t assoc.h            config.guess         daemon.c      Makefile.am         memcached.spec      scripts        thread.c AUTHORS            config.h.in          depcomp       Makefile.in         missing             slabs.c        TODO AUTHORS.repcached  config.sub           doc           memcached.c         NEWS                slabs.h        t.rep ChangeLog          configure            install-sh    memcached_dtrace.d  README              stats.c (3).编译repcached程序文件 [root@njdyw memcached-1.2.8-repcached-2.2]# ./configure --enable-replication --program-transform-name=s/memcached/repcached/ --with-libevent=/usr/local/libevent checking build system type... x86_64-unknown-linux-gnu checking host system type... x86_64-unknown-linux-gnu checking target system type... x86_64-unknown-linux-gnu checking for a BSD-compatible install... /usr/bin/install -c checking whether build environment is sane... yes checking for a thread-safe mkdir -p... /bin/mkdir -p checking for gawk... gawk checking whether make sets $(MAKE)... yes checking for gcc... gcc checking for C compiler default output file name... a.out checking whether the C compiler works... yes checking whether we are cross compiling... no checking for suffix of executables... checking for suffix of object files... o checking whether we are using the GNU C compiler... yes checking whether gcc accepts -g... yes checking for gcc option to accept ISO C89... none needed checking for style of include used by make... GNU checking dependency style of gcc... gcc3 checking whether gcc and cc understand -c and -o together... yes checking for a BSD-compatible install... /usr/bin/install -c checking for libevent directory... /usr/local/libevent/ checking for library containing socket... none required checking for library containing gethostbyname... none required checking for library containing mallinfo... none required checking for daemon... yes checking how to run the C preprocessor... gcc -E checking for grep that handles long lines and -e... /bin/grep checking for egrep... /bin/grep -E checking for ANSI C header files... yes checking for sys/types.h... yes checking for sys/stat.h... yes checking for stdlib.h... yes checking for string.h... yes checking for memory.h... yes checking for strings.h... yes checking for inttypes.h... yes checking for stdint.h... yes checking for unistd.h... yes checking for stdbool.h that conforms to C99... yes checking for _Bool... yes checking for an ANSI C-conforming const... yes checking malloc.h usability... yes checking malloc.h presence... yes checking for malloc.h... yes checking for struct mallinfo.arena... yes checking for socklen_t... yes checking for endianness... little checking for mlockall... yes checking for getpagesizes... no checking for memcntl... no configure: creating ./config.status config.status: creating Makefile config.status: creating doc/Makefile config.status: creating config.h config.status: executing depfiles commands [root@njdyw memcached-1.2.8-repcached-2.2]# make && make install make  all-recursive make[1]: Entering directory `/root/memcached-1.2.8-repcached-2.2' Making all in doc make[2]: Entering directory `/root/memcached-1.2.8-repcached-2.2/doc' make[2]: Nothing to be done for `all'. make[2]: Leaving directory `/root/memcached-1.2.8-repcached-2.2/doc' make[2]: Entering directory `/root/memcached-1.2.8-repcached-2.2' gcc -DHAVE_CONFIG_H -I.  -DNDEBUG -I/usr/local/libevent//include   -g -O2 -MT memcached-memcached.o -MD -MP -MF .deps/memcached-memcached.Tpo -c -o memcached-memcached.o `test -f 'memcached.c' || echo './'`memcached.c mv -f .deps/memcached-memcached.Tpo .deps/memcached-memcached.Po .......... (4).按前3步配置其它slave节点 --因本实验master,slave在同一台机器上，固省去此步。 (5).启动repcached --启动master节点 [root@njdyw memcached-1.2.8-repcached-2.2]# /usr/local/bin/repcached -p 11211 -v -d can't run as root without the -u switch [root@njdyw memcached-1.2.8-repcached-2.2]# su - oracle [oracle@njdyw ~]$ /usr/local/bin/repcached -p 11211 -v -d replication: listen --启动slave节点 [oracle@njdyw ~]$ /usr/local/bin/repcached -p 11212 -x localhost -v -d [oracle@njdyw ~]$ replication: connect (peer=127.0.0.1:11212) replication: marugoto copying replication: accept replication: start 注意：启动repcached要用非root用户，不然会启动失败，如上面所示 3.repcached复制实验 --master->slave复制 [oracle@njdyw ~]$ telnet localhost 11211 Trying 127.0.0.1... Connected to localhost.localdomain (127.0.0.1). Escape character is '^]'. set licz 0 0 5 zai STORED get licz VALUE licz 0 5 zai END quit Connection closed by foreign host. ----数据已经同步到slave [oracle@njdyw ~]$ telnet localhost 11212 Trying 127.0.0.1... Connected to localhost.localdomain (127.0.0.1). Escape character is '^]'. get licz VALUE licz 0 5 zai END --slave->master复制 [oracle@njdyw ~]$ telnet localhost 11212 Trying 127.0.0.1... Connected to localhost.localdomain (127.0.0.1). Escape character is '^]'. set hello2 ERROR set hello2 0 0 4 ruby STORED quit Connection closed by foreign host. ----数据已经同步到master [oracle@njdyw ~]$ telnet localhost 11211 Trying 127.0.0.1... Connected to localhost.localdomain (127.0.0.1). Escape character is '^]'. get hello2 VALUE hello2 0 4 ruby END --看到repcached可以成功的做到数据的双向复制 4.监控memcached [oracle@njdyw ~]$ telnet localhost 11211 Trying 127.0.0.1... Connected to localhost.localdomain (127.0.0.1). Escape character is '^]'. stats cachedump 1 10 ITEM hello2 [4 b; 1356885605 s] ITEM licz [5 b; 1356885605 s] END stats items STAT items:1:number 2 STAT items:1:age 1067 STAT items:1:evicted 0 STAT items:1:evicted_time 0 STAT items:1utofmemory 0 STAT items:1:tailrepairs 0 END 遇到的问题： 1.编译repcached失败 现象： [root@njdyw ~]# cd memcached-1.2.8-repcached-2.2 [root@njdyw memcached-1.2.8-repcached-2.2]# ./configure --enable-replication --program-transform-name=s/memcached/repcached/ checking build system type... x86_64-unknown-linux-gnu checking host system type... x86_64-unknown-linux-gnu checking target system type... x86_64-unknown-linux-gnu checking for a BSD-compatible install... /usr/bin/install -c checking whether build environment is sane... yes checking for a thread-safe mkdir -p... /bin/mkdir -p checking for gawk... gawk checking whether make sets $(MAKE)... yes checking for gcc... gcc checking for C compiler default output file name... a.out checking whether the C compiler works... yes checking whether we are cross compiling... no checking for suffix of executables... checking for suffix of object files... o checking whether we are using the GNU C compiler... yes checking whether gcc accepts -g... yes checking for gcc option to accept ISO C89... none needed checking for style of include used by make... GNU checking dependency style of gcc... gcc3 checking whether gcc and cc understand -c and -o together... yes checking for a BSD-compatible install... /usr/bin/install -c checking for libevent directory... configure: error: libevent is required.  You can get it from http://www.monkey.org/~provos/libevent/       If it's already installed, specify its path using --with-libevent=/dir/        解决： 加上--with-libevent=/dir/ 如下： ./configure --enable-replication --program-transform-name=s/memcached/repcached/ --with-libevent=/usr/local/libevent 2.memcached找不到-x参数 现象： [oracle@njdyw ~]$ /usr/local/memcache/bin/memcached -p 11212 -x localhost -v -d /usr/local/memcache/bin/memcached: invalid option -- x Illegal argument \"?\" [oracle@njdyw ~]$   解决： 根据问题1方法操作，重新make，再次执行正常 /usr/local/bin/repcached -p 11212 -x localhost -v -d   参考： http://code.google.com/p/memcached/wiki/NewInstallFromSource http://blog.csdn.net/wyzxg/article/details/6086523","title":"repcached安装配置及复制实验"},{"content":"USE tempdbGO--Xml采用元素时，Xml文件比较小，用属性解析速度会相关较，通过查看执行计划可以--Sql:column--元素DECLARE @x XMLSET @x='<SO>\t<ID>1<\/ID>\t<SONr>SO#1<\/SONr>\t<Customer>Roy<\/Customer>\t<OrderDate>2012-12-01 10:00<\/OrderDate><\/SO>'--属性DECLARE @y XML SET @y='<SO ID=\"1\" SONr=\"SO#1\" Customer=\"Roy\" OrderDate=\"2012-12-01 10:00\"/>'--方法1SELECT \tb.*FROM \t(SELECT ID =1) AS aCROSS APPLY(SELECT \tT.c.value('(text())[1]','int')  AS ID,\tT.c.value('(../SONr/text())[1]','varchar(50)')  AS SONr,\tT.c.value('(../Customer/text())[1]','varchar(50)')  AS Customer,\tT.c.value('(../OrderDate/text())[1]','datetime')  AS OrderDateFROM @x.nodes('SO/ID[text()=sql:column(\"a.ID\")]') T(c)) AS b--方法2SELECT \tb.*FROM \t(SELECT ID =1) AS aCROSS APPLY(SELECT \tT.c.value('ID[1]','int')  AS ID,\tT.c.value('SONr[1]','varchar(50)')  AS SONr,\tT.c.value('Customer[1]','varchar(50)')  AS Customer,\tT.c.value('OrderDate[1]','datetime')  AS OrderDateFROM @x.nodes('SO[ID=sql:column(\"a.ID\")]') T(c)) AS b--方法3SELECT \tb.*FROM \t(SELECT ID =1) AS aCROSS APPLY(SELECT \tT.c.value('(ID/text())[1]','int')  AS ID,\tT.c.value('(SONr/text())[1]','varchar(50)')  AS SONr,\tT.c.value('(Customer/text())[1]','varchar(50)')  AS Customer,\tT.c.value('(OrderDate/text())[1]','datetime')  AS OrderDateFROM @x.nodes('SO[ID=sql:column(\"a.ID\")]') T(c)) AS b--方法4:属性SELECT \tb.*FROM \t(SELECT ID =1) AS aCROSS APPLY(SELECT \tT.c.value('@ID[1]','int')  AS ID,\tT.c.value('@SONr[1]','varchar(50)')  AS SONr,\tT.c.value('@Customer[1]','varchar(50)')  AS Customer,\tT.c.value('@OrderDate[1]','datetime')  AS OrderDateFROM @y.nodes('SO[@ID=sql:column(\"a.ID\")]') T(c)) AS b 查看执行计划: sql:column+position用法: DECLARE @z XML SET @z='<SO ID=\"1\" SONr=\"SO#1\" Customer=\"Roy\" OrderDate=\"2012-12-01 10:00\"/><SO ID=\"3\" SONr=\"SO#1\" Customer=\"Roy\" OrderDate=\"2012-12-01 10:00\"/>'SELECT \tb.*FROM \t(SELECT ID =1 UNION ALL SELECT 2) AS aCROSS APPLY(SELECT \tT.c.value('@ID','int')  AS ID,\tT.c.value('@SONr','varchar(50)')  AS SONr,\tT.c.value('@Customer','varchar(50)')  AS Customer,\tT.c.value('@OrderDate','datetime')  AS OrderDateFROM @z.nodes('SO[position()=sql:column(\"a.ID\")]') T(c)) AS b/*ID\tSONr\tCustomer\tOrderDate1\tSO#1\tRoy\t2012-12-01 10:00:00.0003\tSO#1\tRoy\t2012-12-01 10:00:00.000*/","title":"Xml之sql:column用法对性能影响"},{"content":"==================================================== 【四舍五入取整截取】 select round(54.56,0) ==================================================== 【向下取整截取】 SELECT FLOOR(54.56) ==================================================== 【向上取整截取】  SELECT   CEILING(13.15) 以下转自：http://www.2cto.com/database/201209/156996.html --MSSQL取整函数的使用   --两个整数相除将截断小数部分  select 3/4,4/3,5/3  --结果 0，1，1    --返回大于或等于所给数字表达式的最小整数  SELECT CEILING(123.55), CEILING(123.45),CEILING(-123.45), CEILING(0.0)  --结果 124，124，-123，0   -- www.2cto.com   --四舍五入 round(a,b) -- 结果a 精确到小数点右 b位，或是左 -b位 select round(54.36,-2), round(54.36,-1),round(54.36,0), round(54.36,1),round(54.36,2)  --结果 100.00，50.00，54.00，54.40，54.36    ---四舍五入 并转化为 整数  select cast(round(56.361,0) as int),cast(round(56.561,0) as int)  --结果 56，57    --举例使用    ---两个整数相除 舍弃小数部分( 全部都向前进位)  declare @dividend decimal(20,2), @divisor decimal(20,2)    set @dividend=3  set @divisor=4  select CEILING(@dividend/@divisor)  --结果 1    set @dividend=4  set @divisor=3  select CEILING(@dividend/@divisor)  --结果 2    set @dividend=5  set @divisor=3  select CEILING(@dividend/@divisor)  --结果 2  ---两个整数相除 四舍五入到整数  set @dividend=3  set @divisor=4  select cast(round(@dividend/@divisor,0) as int)  --结果 1    set @dividend=4  set @divisor=3  select cast(round(@dividend/@divisor,0) as int)  --结果 1    set @dividend=5  set @divisor=3  select cast(round(@dividend/@divisor,0) as int)  --结果 2 ==================================================== 【四舍五入取整截取】 select round(54.56,0) ==================================================== 【向下取整截取】 SELECT FLOOR(54.56) ==================================================== 【向上取整截取】  SELECT   CEILING(13.15)","title":"Sql Server 里的向上取整、向下取整、四舍五入取整的实例！"},{"content":"           首先介绍一下自己的工作内容，让大家了解一下数据库这方面的工作内容，以及可能遇到的问题，还有发展方向：            我在公司的工作内容之一：主要是通过整理文档和数据库内部数据，然后了解旧的数据库的结构。（公司的做法和自己的做法）            第二项工作内容是：鉴于系统升级的时候总是会有数据库的不同或者是表结构的不同，进而导致旧的数据无法直接导入新的数据库进行使用，所以需要用到数据的清洗，迁移等的工作。           通过百科可以看到数据迁移的概念：http://baike.baidu.com/view/1342339.htm           我做的是用工具（ODI进行数据清洗和迁移）:主要就是通过工具获取了元数据库的数据，然后通过工具进行一系列的操作，然后成为合格的数据放进新的数据库。           作为基层应用就是对这个工具的功能的开发，就像是开发软件一样，需要了解用户的需求，了解业务，然后根据对方的要求对数据进行合乎要求的处理。                  有人具体做过大的系统，说的比较具体一点：                http://blog.csdn.net/baoqiangwang/article/details/5492910                  文库中有数据迁移的方法：               http://wenku.baidu.com/view/d874e719964bcf84b9d57b3f.html                主要也就是根据不同的需求进行的不同操作。                  迁移的情况和内容有很多，比如也是文库中提到的：                数据迁移跨平台。http://wenku.baidu.com/view/e7db45f9941ea76e58fa0426.html              这个过程中涉及到咱们学过的技术就是：oracle数据库的基本结构，然后是数据库的基本函数和sql语句（根据各种组合各种关系进行书写sql语句），还有就是存储过程触发器等。之后就是数据的导入导出，表结构的导入导出。          同时比较深入一点的技术就是：权限的分配和管理，因为数据安全是很重要的一块内容，只要用数据库的人大都关心，甚至非常关心这个内容，所以权限的分配和管理不是一般人可以管理的。          咱们一般学习的权限就是基本的最高级别或者是一般级别等，实际上用户的权限还有很多咱们平时不常用的。比如你让操作每一个板块的人只能操作某个方法或者某个表，让某个用户可以访问另外一个用户的某一个方法，等等。当然这是最基本的。         据了解数据库作最高的能做到DBA，（深入的不了解）不过DBA对这个数据库的操作了如指掌，操作无误，至少不会让数据出错。以后就只用管理一下数据库的小的变动即可，基本没有什么工作量，是一个很不错的发展方向。             说数据迁移比较片面，之所以说主要是因为我自己做的说完数据迁移，其实数据的处理很多方面是分不开的，下面咱们大概可以了解一些相关的概念。（百科）          通过做的内容，了解一下数据库相关方面的应用：                数据抽取：http://baike.baidu.com/view/709638.htm                数据清洗：对不合格的数据进行处理。                数据迁移：主要是对数据进行大的变迁。                数据仓库：对处理的数据做重要的存储http://baike.baidu.com/view/19711.htm                数据挖掘：http://baike.baidu.com/view/7893.htm                数据安全：http://baike.baidu.com/view/2308446.htm                 同时还有一些具体的其他应用 。              数据处理和管理方面的主要问题跟开发中的问题其实是大同小异的：主要问题也就是数据库的文档记录要清晰，同时数据库咱们一般也都要写清楚注释，命名，还有就是数据库一定要有  数据字典，再就是主外键关系的保持。               对于开发而言，要有版本的纪录，对于数据库操作也一定要有版本的记录。              对于开发而言有 瀑布模型等各种模型，对于数据库的操作而言，先做哪步处理再做哪步处理其实也是一样的要有这样的处理加工模型。              主要不同的是系统是通过代码进行操作。数据库更多是跟sql语句打交道。      数据库更深层的东西不太懂，更长远的发展有待咱们去研究 ，在此仅仅分享一个不同的视角，愿我们共同去深入研究讨论。","title":"分享自己的工作内容及数据库相关概念"},{"content":"        题外话：年底了，就以这篇博文结束2012吧         总结回顾一下pg服务进程中的内存上下文吧。          Pg的内存管理就像经济体制，计划经济和市场经济并存，主要是共享内存和内存上下文。共享内存就是计划经济，启动时根据各相关参数计算好大小就固定了，使用时也严格按照计划使用。内存上下文就是市场经济，这一部分是按需使用。这两种内存的管理前面有几篇文章做了专门讨论，可以参考pg的内存管理机制一：AllocSet的内存分配 http://blog.csdn.net/beiigang/article/details/7051589 PostgreSQL的内存管理机制二：AllocSet/MemoryContext的内存回收 http://blog.csdn.net/beiigang/article/details/7058324 PostgreSQL的内存管理机制三：AllocSet/MemoryContext实例删除和内存回收 http://blog.csdn.net/beiigang/article/details/7093975 PostgreSQL的内存管理机制四：AllocSet/MemoryContext的内存再分配 http://blog.csdn.net/beiigang/article/details/7096613 PostgreSQL的内存管理机制十一：初始化共享内存shared memory及其哈希表索引 http://blog.csdn.net/beiigang/article/details/7176390 PostgreSQL的内存管理机制十二：共享内存/shmem分配 http://blog.csdn.net/beiigang/article/details/7288763等。          这一节结合前面讨论简单查询的例子回顾一下pg服务进程处理简单查询时用到的各内存上下文。   1 下面是从pg服务进程从postmaster进程进程过来的内存上下文。     2 创建了CacheMemoryContext内存上下文，在CacheMemoryContext里创建catchache的相关对象，并创建了管理relchache的哈希表RelationIdCache。     3 创建了PortalMemory内存上下文，在PortalMemory里创建了管理protal的哈西表“Postalhash”对象。     4 创建了MessageContext、TransactionAbortContext、TopTransactionContext内存上下文，在TopTransactionContext创建了内存快照、资源属主，MessageContext在其里创建了解析树、query树、plan树，在TransactionAbortContext里记录在事务提交或回滚时要清理相关资源的情况。     5 创建了inline_set_returning_function临时内存上下文，在里面处理内联函数返回值，用完后马上删除。     6 创建了PortalHeapMemory，ExecutorState、HashTableContext、HashBatchContext等内存上下文。这些内存上下文和前面讨论简单查询时的例子紧密相关，会为了完成不同的查询语句而创建不同的内存上下文，下面是前面讨论时用到的例子，及这个查询语句的执行计划。 简单查询例子： create tabletest1 (ID numeric(10), cname varchar(30)); create tabletest2 (ID numeric(10), comp varchar(30)); selectcname,comp from test1,test2 where test1.id=test2.id;            该例子的执行计划，可以看出对这两个表做hash连接和分别做顺序扫描，并做hash连接需要的hash运算。 explain select cname,comp from test1,test2 where test1.id=test2.id; \"Hash Join  (cost=24.63..116.69 rows=2113width=156)\" \" Hash Cond: (test1.id = test2.id)\" \" ->  Seq Scan on test1  (cost=0.00..16.50 rows=650 width=94)\" \" ->  Hash  (cost=16.50..16.50 rows=650 width=94)\" \"       ->  Seq Scan on test2  (cost=0.00..16.50 rows=650 width=94)\"   在PortalHeapMemory里创建了这个查询计划的描述符QueryDesc，及这个查询计划描述符querydesc的成员，这个查询计划的执行状态Estate等对象。         ------------ 转载请注明出处，来自博客： blog.csdn.net/beiigang beigang.iteye.com    ","title":"PostgreSQL服务过程中的那些事三：pg服务进程中的内存上下文"},{"content":"Oracle 11g Audit Oracle审计（Audit）功能用于监视用户所执行的数据库操作，审计记录可存在数据字典表（称为审计记录：存储在system表空间中的 SYS.AUD$ 表中，可通过视图 dba_audit_trail 查看） 或操作系统审计记录（默认位置为 $ORACLE_BASE/admin/$ORACLE_SID/adump/ ）中。 而不管是否打开数据库的审计功能，以下这些操作Oracle系统都会强制记录： 用管理员权限连接Instance； 启动数据库； 关闭数据库。 注意：Oracle 10g默认是不开启审计的，而Oracle 11g默认是开启审计的！一般上市公司的核心数据都被要求开启审计功能。 审计数据/日志被写满是会导致Oracle RAC无法服务的！因此对于 Oracle 11g 要重点关注审计功能，如果没有必要就赶紧关闭吧。 Oracle 10g ASM 在海量数据库环境中，DBA可能会花费很多的时间来做磁盘管理。比如一个表空间将占满整个磁盘，DBA就需要再添加一块磁盘到操作系统中，然后再在新的磁盘上创建新的数据文件。如果是单个磁盘这倒不是很繁琐，问题是如果原先我们使用的是RAID或者说是LVM，那么现在大量的数据仍然是分布在以前的那些磁盘上，如果我们想让这些数据均匀地分布在以前的磁盘和新增加的磁盘上，就可能就要耗费一天甚至几天的时间来做原先数据的导出导入。 如果有一种方法，能实现我们就把一块磁盘加到系统里，然后告诉Oracle我们要用这块盘了，剩下的工作全部由Oracle来完成，该是多好的一件事情！ Oracle10g 已经提供了这个功能，这就是自动存储管理，即ASM（自动存储管理，Automatic Storage Management）。Oracle10g 的ASM不但帮助DBA从繁琐的磁盘空间管理中解脱出来，而且更值得关注的是ASM同时提供了条带和镜像的功能，而这些功能原先需要通过单独地配置RAID来实现。 ASM 提供了专门为 Oracle 数据库文件建立的文件系统与卷管理器的垂直整合功能。ASM 在所有可用的资源中分布 I/O 负载，以便在免除手动 I/O 调节需要（通过分散数据库文件来避免热点）的同时优化性能。ASM 帮助 DBA 管理动态数据库环境，让 DBA 能够在扩大数据库规模的情况下，无需关闭数据库以调整存储分配。 ASM 允许DBA 定义一个存储器组（称作磁盘组）。然后，由 Oracle 内核管理该存储器组上的文件命名与数据库文件的放置。DBA 可利用全新的 SQL 命令（create diskgroup, alter diskgroup 与 drop diskgroup）来改变存储分配——添加或删除磁盘。用户也可通过使用企业管理器（EM）和数据库配置助理（DBCA）来管理磁盘组。 ASM 通过自动重新平衡来促进非侵入性存储配置的改变。它在所有可用的存储器中分配数据库文件，以便优化性能和资源利用率。 ASM 是一种能力，它通过实现手动存储器的自动化来节省 DBA 的时间，使其能够以更高的效率管理更大、更多的数据库。 确保正确配置你的ASM功能并开启它。 Oracle System Global Area （SGA）当启动 Oracle 数据库时，系统会先在内存内规划一个固定区域，用来储存用户需要的数据，以及Oracle运行时必备的系统信息。我们称此区域为系统全局区（System Global Area），简称SGA。 SGA 有几个重要区域，它们是： Database Buffer Cache - 数据库缓冲区 Redo Log Buffer - 重做日志缓冲区 Shared Pool - 共享区 Java pool, Large pool ... 确保分配给你的数据库足够的SGA空间。 Oracle SGA ulimit Linux 系统中的 ulimit 指令，对资源限制和系统性能优化提供了一条便捷的途径。用户的 shell 启动脚本、应用程序启动脚本以及直接在控制台输入命令都可以通过该指令限制系统资源的使用，包括所创建的内核文件的大小、进程数据块的大小、Shell 进程创建文件的大小、内存锁住的大小、常驻内存集的大小、打开文件描述符的数量、分配堆栈的最大大小、CPU时间、单个用户的最大线程数、Shell 进程所能使用的最大虚拟内存等方面……显而易见，ulimit 对我们在 Linux 平台的应用和开发工作是非常实用的。 但是，对于Oracle SGA来说，我们要消除对它的限制。 例如：64位 Linux+Oracle 10g r2 设置 lock_sga 参数后，Oracle无法启动。Linux系统设置 ulimit -l unlimited 即可解决问题。 Oracle RAC Failover Oracle RAC 高可用性的基础就是 Failover（故障转移）。它使得RAC集群中任何一个节点的故障都不会影响用户的使用，连接到故障节点的用户会被自动转移到健康节点，并且从用户感受而言是感受不到这种切换。 Oracle RAC（10g为例） 的 Failover 可以分为3种： Client-Side Connect time Failover 即，如果用户端 tnsname 中配置了多个地址，用户发起连接请求时，会先尝试连接地址表中的第一个地址，如果这个连接尝试失败，则继续尝试使用第二个地址，直至连接成功或者遍历了所有的地址。 特点：只在建立连接那一时刻起作用，也就是说，Client-Side Connect time Failover 只在发起连接时才会去感知节点故障，如果节点没有反应，则自动尝试地址列表中的下一个地址。一旦连接建立之后，节点出现故障都不会做处理，从客户端的表现就是会话断开了，用户程序必须重新建立连接。并且，故障转移集群的配置是写死在客户端的。 很明显，一般不在生产环境下使用Client-Side Connect time Failover。 TAF - Transparent Application Failover 现在大部分应用程序都使用数据库连接池，即在启动时就建立若干到数据库的长连接，应用程序在其整个生命周期内重用这些连接。 而 Client-Side Connet Time Failover 的工作方式在这种情况下对应用程序的可用性没有太大帮助。  所以从 Oracle 8.1.5 版本引入了新的 Failover 机制——TAF。 所谓TAF，就是连接建立以后，应用系统运行过程中，如果某个实例发生故障，连接到这个实例上的用户会被自动迁移到其他的健康实例上。对于应用程序而言，这个迁移过程是透明的，不需要用户的介入，当然，这种透明要是有引导的，因为用户的未提交事务会回滚。相对于 Client-Side Connect Time Failover 的用户程序中断、抛出连接错误、重启应用程序，TAF 这种方式在提高 HA 上有很大的进步。 传统的 TAF 故障集群仍然需要在客户端配置，这在大量应用程序存在的情况下，对于服务端变化的修改成本是比较高的。 Service-Side TAF Service-Side TAF 可以看作是 TAF 的一种变种，首先Service-Side TAF 也是 TAF，所有 TAF 的特点它都有，其次这种 TAF 是在服务器上配置的，而不像传统TAF是在客户端配置的。 Client-Side TAF 是在客户端修改 tnsnames.ora 文件来配置的，如果有很多客户端使用这个数据库，那么每次服务端调整都需要把所有的客户端应用程序更改一遍，既低效又容易出错。而 Service-Side TAF 通过服务端，在数据库里保存 FAIL_MODE 的配置，把所有的 TAF 配置保存在数据字典中，从而省去了客户端的配置工作，因此客户端的 tns 文件就不需要任何 TAF 的配置选项了。 当然 Service-Side TAF 的客户端需要指向一个RAC VPS，以保证对数据库集群的轮询。 Oracle DB Console 提供Web应用界面，实时监控 Oracle RAC 应用实例的方方面面，例如：服务器资源、性能表现以及执行计划、行级锁等运行细节。","title":"Oracle（RAC）数据库调优和事故分析应关注的技术点"},{"content":"一:ManyToOne的cfg.xml配置 1.实体,省略setter&getter public class User implements Serializable{\tprivate static final long serialVersionUID = 1L;\t\tprivate Integer id;// 编号\tprivate String account;// 用户名\tprivate String password;\t\tprivate Dept dept;//多个人属于一个部门, 所以是many(用户) to one(部门) public class Dept implements Serializable{\t\tpublic Integer deptno;//部门编号\tpublic String deptname;//部门名称等等...如果是要双向连接 这要多写一个Set<User> 2.xml配置 ManyToOne肯定是要配置在\"多\"的一方 , 因为User表中每一行最后, 多存一个部门编号就可以了 .要是\"一\"的一行保存需要很多行数据才能反映全部关联关系.(两头都有那就是冗余了) <hibernate-mapping package=\"com.rt.model\">\t<class name=\"User\" table=\"t_user\">\t\t<id name=\"id\" type=\"java.lang.Integer\" length=\"10\">\t\t\t<generator class=\"assigned\"/>\t\t<\/id>\t\t<property name=\"account\" type=\"string\" not-null=\"true\" length=\"45\"/>\t\t<property name=\"password\" type=\"string\" not-null=\"true\" length=\"45\"/>\t\t<!--<property name=\"admin\" type=\"com.rt.model.Admin\" />\t\t<property name=\"dept\" type=\"com.rt.model.Dept\" />-->\t\t<!-- 多对一映射用户 -->\t\t<!-- 这不配置lazy且不配置fetch的话, 就已经不存在N+1问题了, 后边具体分析-->\t\t<many-to-one name=\"dept\"         column=\"deptno\"         class=\"com.rt.model.Dept\"         not-null=\"true\"         cascade=\"none\"         />         \t<\/class><\/hibernate-mapping>作为\"一\"这一端, 可以不做任何配置, 他不需要知道具体哪些User要关联自己 <hibernate-mapping package=\"com.rt.model\">\t<class name=\"Dept\" table=\"t_dept\">\t\t<id name=\"deptno\" type=\"java.lang.Integer\" length=\"10\">\t\t<\/id>\t\t<property name=\"deptname\" not-null=\"true\" length=\"45\"/>\t<\/class> 3.自动生成表 <property name=\"hbm2ddl.auto\">update<\/property>  二:N+1问题 试验了好多次, 先写清楚结论再分析: 1.结论 这样配置就没有N+1问题,   \t\t<many-to-one name=\"dept\"         column=\"deptno\"         class=\"com.rt.model.Dept\"         not-null=\"true\"         cascade=\"none\"         />如果加上 fetch=\"join\"仍然没有N+1问题 2.分析一下: Hibernate3已经默认把lazy配置设置成了true ,所以不手动改掉的话 就已经是延迟加载了. 所以就是用延迟加载的方式解决了N+1 fetch是用另一种思路解决N+1的: join就是查表时候 ,一次性把所有有关的项目都查出来, 既然一次性都查全了 就业不用N+1了 . 所以fetch更适合配上缓存用. lazy 参数值常见有 false 和 true，Hibernate3 映射文件中默认lazy = true ； fetch 指定了关联对象抓取的方式，参数值常见是select和join，默认是select, select方式先查询主对象，再根据关联外键，每一个对象发一个select查询，获取关联的对象，形成了n+1次查询；而join方式，是left outer join查询，主对象和关联对象用一句外键关联的sql同时查询出来，不会形成多次查询。 在映射文件中，不同的组合会使用不同的查询： 1、lazy=\"true\" fetch = \"select\" ，使用延迟策略，开始只查询出主对象，关联对象不会查询，只有当用到的时候才会发出sql语句去查询 ； 2、lazy=\"false\" fetch = \"select\" ，没有用延迟策略，同时查询出主对象和关联对象，产生1+n条sql. 3、lazy=\"true\"或lazy=\"false\" fetch = \"join\"，延迟都不会作用，因为采用的是外连接查询，同时把主对象和关联对象都查询出来了. 另外，在hql查询中,配置文件中设置的join方式是不起作用的,而在其他查询方式如get、criteria等是有效的，使用 select方式;除非在hql中指定join fetch某个关联对象。fetch策略用于get/load一个对象时，如何获取非lazy的对象/集合。 这些参数在Query中无效。 3.测试程序 User u=testDao.findUser(i);\t\t\tSystem.out.println(\"=>\" + u.getAccount());\t\tSystem.out.println(\"=>\" + u.getPassword());\t\tSystem.out.println(\"=>\" + u.getId());\t\t\t\tSystem.out.println(\"--111----\");\t\tSystem.out.println(\"=>\" + u.getDept().getDeptname());\t\tSystem.out.println(\"--222----\");\t\tSystem.out.println(\"=>\" + u.getAdmin().getPmain()); 前三项是User实体内的字段,  后两项是ManyToOne关系关联的, 看下输出SQL语句的顺序就明白了 (1)没有fetch=\"join\"的情况下: 就是lazy形式, 没有用到的就不去查 用到哪个查哪个 Hibernate: select user0_.id as id1_0_, user0_.account as account1_0_, user0_.password as password1_0_, user0_.deptno as deptno1_0_, user0_.adminid as adminid1_0_ from t_user user0_ where user0_.id=?=>tao=>123456=>250--111----Hibernate: select dept0_.deptno as deptno3_0_, dept0_.deptname as deptname3_0_ from t_dept dept0_ where dept0_.deptno=?=>10--222----Hibernate: select admin0_.adminid as adminid2_0_, admin0_.pmain as pmain2_0_, admin0_.pc1 as pc3_2_0_, admin0_.pc2 as pc4_2_0_ from t_admin admin0_ where admin0_.adminid=?=>1 (2)有fetch=\"join\"  一次性一条之内全查出来, Hibernate: select user0_.id as id1_2_, user0_.account as account1_2_, user0_.password as password1_2_, user0_.deptno as deptno1_2_, user0_.adminid as adminid1_2_, dept1_.deptno as deptno3_0_, dept1_.deptname as deptname3_0_, admin2_.adminid as adminid2_1_, admin2_.pmain as pmain2_1_, admin2_.pc1 as pc3_2_1_, admin2_.pc2 as pc4_2_1_ from t_user user0_ inner join t_dept dept1_ on user0_.deptno=dept1_.deptno inner join t_admin admin2_ on user0_.adminid=admin2_.adminid where user0_.id=?=>tao=>123456=>250--111----=>10--222----=>1","title":"ManyToOne的xml配置 及 解决N+1问题"},{"content":"MyBatis 用户需警惕！ 最近，在网上看到一则消息，消息称，MyBatis 的性能比 ibatis 要慢一倍，具体可看官方相关 Issues“http://code.google.com/p/mybatis/issues/detail?id=580”··· 但官方人员称，导致这个问题的原因是 MyBatis 框架自身，在不停地编译动态 sql 语句，而实际上这是不必要的。他们打算在下一个版本进行修复（目前版本是 MyBatis 3.1.1）。 不过，其实这个问题在数据量比较大时才有影响（如官方 Issues 上所提到的数据量是 100W 条记录时，MyBatis 需要 283秒，而 iBatis 却只要 137秒），所以一般的网络应用估计没太大影响，所以可以放心使用··· 另一个值得高兴的事情是，官方称 “mybatis-3.2.0-SNAPSHOT-bundle.zip” 已经很久没有发现新问题了，这意味着这个新版本已经基本可以看做是 beta 版本了，用不了太久的时间就会发布正式版，一起期待吧···","title":"警惕！ MyBatis 性能比 ibatis 慢一倍"},{"content":"平时多用的一些基本的mysql命令，开始学习的时候这些都是一点一点积累的，结果弄了好多TXT，现在把他们总结一下，和大家分享分享。还有一些进阶操作，以后在做总结。 1.连接数据库 mysql -h IP -u username -pthepassword; 语句中-h IP可以指定MYSQL的服务器，如果指定服务器为本地（localhost），可以省略该参数。 注：-p与thepassword之间不可以有空格。 2.创建、显示、删除数据库 创建数据库： CREATE DATABASE  database; 显示数据库： SHOW DATABASES; 删除数据库： DROP DATABASE database; 数据库删除后不可恢复，如果进行重命名操作，一般首先备份目标数据库，在新建数据库并导入数据。 3.选择所要操作的数据库 USE database; 执行后出现Database changed提示时，说明操作成功。 语句中database代表所要操作的数据库名。 4.创建、显示、重命名、删除表 创建表： CREATE TABLE tablename  (  column1,data_type,  column2,data_type,  .....  }; 显示表： SHOW TABLES； 重命名表： RENAME TABLE old_tablename TO new_tablename; 删除表： DROP TABLE tablename; 5.显示表构成 DESCRIPBE tablename; 该语句可以用来显示表的列名以及各列的数据类型。 6.查询数据 SELECT columni,columnj,... FROM tablename WHERE [columnx = valuex,....][columnx LIKE '%valuex%'] ORDER BY cloumny [desc][asc] 语句中columni,columnj,...表示需要查询显示的列名，如果需要返回所有列可以使用通配符（*）。 语句中表述查询语句的条件时，可以使用精确条件，也可以使用模糊条件。（%）通常表示一个或多个字符。 7.插入数据 INSERT INTO tablename(column1,column2,..) VALUES(data01,data02,..),(data11,data12,..),...;INSERT INTO tablename SET column1 = value1，column2 = value2，....; 插入数据有上述两中形式可以使用。使用时注意如果有一些不可留空并且不可自动填充的列，必须在SET后设置相应的值。 8.更新数据 UPDATE tablename SET columni = valuei,columnj = valuej,... WHERE columnx = valuex,....; 在进行数据更新时，符合WHERE条件的可能不只一条记录，此时，会更新所有记录，但是如果需要更新的列包含主键的话，会出现错误，因为主键不允许数据重复。 9.删除数据 DELETE FROM tablename WHERE columnx = valuex,..... 该语句中如果没有设定条件，会删除表中所有记录。 10.为用户设置、修改密码 SET PASSWORD FOR 'username'@'hostname' = PASSWORD('thepassword'); MYSQL的密码是区分大小写的，在实际引用密码之前的PASSWORD术语告诉MYSQL要对这个字符串进行加密。并且在PASSWORD与左括号之间不能有任何空白字符。 11.创建用户和设置权限 GRANT privileges ON database.* TO 'username'@'hostname' IDENTIFIED BY 'password'; 该语句的privileges部分可以列出下表权限，或者通过使用ALL来指定所有权限 该语句的database.*部分指出了用户可以使用哪个数据库或表。可以使用database.tablename这样的语法来指定表的名字。或者使用*.*来指定所有的数据库。 用户名最大长度为16个字节。不可以使用空格且区分大小写。 密码没有长度限制，但是区分大小写。省略IDENTIFIED BY 'password'子句可以不要求用户输入密码。 可以选择将用户限制在特定的主机名上，用户名或者是运行有MYSQL服务器的计算机名（常用localhost），或者是用户访问服务器时所在的计算机名。其值甚至可以是IP地址。要制定任意主机，可以在主机命中使用通配符（%）。 例如创建一个对数据库只有一个基本访问权限的用户 GRANT SELECT,INSERT,UPDATE,DELETE ON ISCC.* TO'isclab'@'202.204.80.166'; 修改用户权限时的语句与创建用户的语句相同。 FLUSH PRIVILEGES 运行该语句就是MYSQL重置其可以接受的用户和权限列表。 12.数据库备份与还原 备份语句： mysqldump -h IP -u username -pthepassword database  > filename.sql 语句中-h IP可以指定MYSQL的服务器，如果指定服务器为本地，可以省略该参数。 语句中所使用的username/thepassword必须有备份数据库的权限。 语句中的filename.sql可以是指定文件保存的绝对地址或相对地址。 还原语句： mysql -u username -pthepassword database < filename.sql 该语句中参数与备份语句中参数含义相同。 13.已知root密码时修改密码的两种方法 使用mysql的提供的程序： mysqladmin -u username -pold_password password old_password 命令行修改 UPDATE mysql.user SET password = PASSWORD('thepassword') where user = 'root'; 14.暴力修改root密码 首先停止MYSQL服务，打开一个命令行窗口并执行： mysqld-nt --skip-grant-tables & 再打开一个命令行窗口并执行： mysql mysql>UPDATE user SET password = PASSWORD('thepassword') where user = 'root'; 这时候root的密码就设置为thepassword了。再次启动MYSQL服务即可。 注：这里是以windows环境为例，在linux下将mysqld-nt换为mysqld_safe即可。   转载请注明出处：http://blog.csdn.net/xkjcf","title":"MYSQL基本命令的使用"},{"content":"        何谓全表扫？                    不合理地消耗大量资源的数据访问方式                  为啥会有全表扫？                     原因大致如下：                       ① 缺乏索引             ② 索引被抑制             ③ 表连接技术使用不当             ④ 表连接和索引结合不好             ⑤ 优化器问题             ⑥ 统计信息未及时采集和更新             ⑦ 数据库设计问题             ⑧ 事务设计不合理             ...等待                      “高富帅”的处理方案？                         ① 购买最新进的机器和存储设备             ② 复杂的分库、分表技术，如RAC、Data Guard、分区表                       这是种治标不治标的办法，因为我有“仇富”心态                     “矮丑穷”的土方？                         解决全表扫最简单的就是合理制定索引策略                数据增长与全表扫的关系                                           ","title":"侃侃全表扫描"},{"content":"包UTL_FIle用于读写操作系统的文件,前提是首先创建Directory对象、授权。然后就可以使用UTL_FILE包中提供的类型、过程、函数来读取，写入，操作目录中的文件了。 创建Directory的示例如下: SQL> CREATE DIRECTORY CZW AS 'D:\\'; Directory created SQL> GRANT READ,WRITE ON DIRECTORY CZW TO SCOTT; Grant succeeded 1、FILE_TYPE 该类型是UTL_FILE包中定义的记录类型，其成员是私有的，不能够被直接引用。该类型的定义如下： TYPE file_type IS RECORD(     id  BINARY_INTEGER,datatype BINARY_INTEGER ); 2、FOPEN 该函数用于打开文件。使用这个函数最多可以打开50个文件，语法如下： UTL_FILE.FOPEN(     location IN VARCHAR2,     filename IN VARCHAR2,     open_mode IN VARCHAR2,     max_linesize IN BINARY_INTEGER ) RETURN file_type; 当成功的执行了该函数之后，就会返回文件句柄，访问该文件可以使用该文件句柄。如果执行失败的话，则会触发例外或者显示错误。注意，当指定文件位置的时候，必须要使用DIRECTORY对象，并且其名称必须为大写。示例如下： DECLARE   HANDLE UTL_FILE.FILE_TYPE; BEGIN   HANDLE := UTL_FILE.fopen('CZW','DYWT.TXT','R',1000);   DBMS_OUTPUT.PUT_LINE('D:\\DYWT.TXT已经被打开'); END; 3、FOPEN_NCHAR 该函数用于以UNICODE方式打开文件。当使用该函数打开文件之后，读写文件会使用UNICODE取代数据库字符集。语法如下： UTL_FILE.FOPEN_NCHAR(   location IN VARCHAR2，   filename IN VARCHAR2，   open_mode IN VARCHAR2，   max_linesize IN BINARY_INTEGER) RETURN file_type; 4、IS_OPEN 该函数用于确定文件是否已经被打开，语法如下： UTL_FILE.IS_OPEN(file IN FILE_TYPE) RETURN BOOLEAN; 如上所示，file用于指定文件句柄。如果文件已经被打开，则返回TRUE，否则则返回FALSE，该函数的示例如下： DECLARE   HANDLE UTL_FILE.FILE_TYPE; BEGIN IF NOT UTL_FILE.is_open(HANDLE) THEN   HANDLE := UTL_FILE.fopen('CZW','DYWT.TXT','R',1000); END IF;   DBMS_OUTPUT.PUT_LINE('D:\\DYWT.TXT已经被打开'); END; 5、FCLOSE 该过程用于关闭已经打开的文件，语法如下： UTL_FILE.FCLOSE(FILE IN OUT FILE_TYPE); 6、FCLOSE_ALL 该过程用于关闭当前打开的所有文件。语法如下： UTL_FILE.FCLOSE_ALL; 7、GET_LINE 该过程用于从已经打开的文件中读取行内容，行内容会被读取到输出缓冲区。语法如下： UTL_FILE.GET_LINE(   file IN FILE_TYPE,   buffer OUT VARCHAR2,   linesize IN NUMBER,   len IN PLS_INTEGER DEFAULT NULL ); 如上所示，buffer用于存储读取信息；linesize用于要指定读取的最大字节数；len用于指定实际读取的长度。使用该过程的示例如下： DECLARE   HANDLE UTL_FILE.FILE_TYPE;   BUFFER VARCHAR2(100); BEGIN IF NOT UTL_FILE.is_open(HANDLE) THEN   HANDLE := UTL_FILE.fopen('CZW','DYWT.TXT','R',1000); END IF;   UTL_FILE.GET_LINE(HANDLE,BUFFER,100);   DBMS_OUTPUT.PUT_LINE(BUFFER);   UTL_FILE.fclose(HANDLE); END; 8、GET_LINE_NCHAR 该过程的用法同上面的是一样的，只不过是用UNICODE方式读取已经打开的文件的行内容，并且将行内容读取到输出缓冲区中。 9、GET_RAW 该过程用于从文件中读取RAW字符串，并调节文件指针到读取位置。语法如下： UTL_FILE.GET_RAW(   fid IN UTL_FILE.TYPE,   r  OUT NOCOPY RAW,   len IN PLS_INTEGER DEFAULT NULL ); 上面所示：fid用于指定文件的句柄，r用于取得读取信息，示例如下： DECLARE   HANDLE UTL_FILE.FILE_TYPE;   BUFFER VARCHAR2(2000); BEGIN IF NOT UTL_FILE.is_open(HANDLE) THEN   HANDLE := UTL_FILE.fopen('CZW','DYWT.TXT','R',1000); END IF;   UTL_FILE.GET_RAW(HANDLE,BUFFER,1000);   DBMS_OUTPUT.PUT_LINE(BUFFER);   UTL_FILE.fclose(HANDLE); END; 10、PUT 该过程用于将缓冲区内容写入到文件中。当使用PUT过程的时候，文件必须以写方式打开，在写入缓冲区之后，如果要结束行，那么可以使用NEW_LINE过程。语法如下： UTL_FILE.PUT(file IN FILE_TYPE,buffer IN VARCHAR2); 使用该过程的示例如下： DECLARE   HANDLE UTL_FILE.FILE_TYPE;   BUFFER VARCHAR2(2000); BEGIN IF NOT UTL_FILE.IS_OPEN(HANDLE) THEN   HANDLE := UTL_FILE.FOPEN('CZW','NEW.TXT','W',1000); END IF;   BUFFER:='&CONTENT1';   UTL_FILE.PUT(HANDLE,BUFFER);   UTL_FILE.NEW_LINE(HANDLE);   BUFFER:='&CONTENT2';   UTL_FILE.PUT(HANDLE,BUFFER);   UTL_FILE.NEW_LINE(HANDLE);   UTL_FILE.FCLOSE(HANDLE); END; 11、PUT_NCHAR 作用同上，该过程用于将缓冲区的内容以UNICODE方式写入到文件。 12、PUT_RAW 该过程用于将RAW缓冲区中的数据写入文件中。语法如下： UTL_FILE.PUT_RAW(   fid IN UTL_FILE.FILE_TYPE,   R   IN RAW,   autoflush IN BOOLEAN DEFAULT FALSE ) 上述,fid用于指定文件句柄,r用于指定存放RAW数据的缓冲区,autoflush用于指定是否自动刷新缓冲区数据.该过程的示例如下: DECLARE   HANDLE UTL_FILE.FILE_TYPE;   BUFFER VARCHAR2(2000); BEGIN IF NOT UTL_FILE.IS_OPEN(HANDLE) THEN   HANDLE := UTL_FILE.FOPEN('CZW','NEW.TXT','W',1000); END IF;   BUFFER:='&CONTENT1';   UTL_FILE.PUT_RAW(HANDLE,BUFFER);   UTL_FILE.NEW_LINE(HANDLE);   UTL_FILE.FCLOSE(HANDLE); END; 13、NEW_LINE 该过程用于为文件增加行终止符，语法如下： UTL_FILE.NEW_LINE(file IN FILE_TYPE,lines IN NATURAL :=1); 后面的lines用于指定在文件中增加的行终止符的个数。 14、PUT_LINE 该过程用于将文本缓冲区内容写入到文件中。当使用该过程为文件追加内容时，会自动在文件的尾部追加行终止符。 DECLARE   HANDLE UTL_FILE.FILE_TYPE;   BUFFER VARCHAR2(2000); BEGIN IF NOT UTL_FILE.is_open(HANDLE) THEN   HANDLE := UTL_FILE.fopen('CZW','DYWT.TXT','W',1000); END IF;   BUFFER := '&CONTENT';   UTL_FILE.put_line(HANDLE,BUFFER);   UTL_FILE.fclose(HANDLE); END; 注意：会删掉之前的数据，是在新写入的行后面增加一个行结束符。 15、PUT_LINE_NCHAR 同上，该过程用于将文本缓冲区内容以UNICODE方式写入文件。当使用该过程写入内容的时候，会自动的在尾部追加行终止符。 2012/12/31 13:50经过测试，会清空原有文件中的内容。 16、PUTF 该过程用于以特定的格式将文本内容写入到文件中，其中%s标识字符串，格式\\n表示行终止符。语法如下： UTL_FILE.PUTF(   file IN FILE_TYPE,   format IN VARCHAR2，   [arg1 IN VARCHAR2 DEFAULT NULL,   ...   arg5 IN VARCHAR2 DEFAULT NULL]); 上述format用于指定格式符（最多支持5个%s），arg1...arg5用于指定对应于格式符的字符串。使用该过程的示例如下： DECLARE   HANDLE UTL_FILE.FILE_TYPE;   BUFFER VARCHAR2(2000); BEGIN IF NOT UTL_FILE.is_open(HANDLE) THEN   HANDLE := UTL_FILE.fopen('CZW','DYWT.TXT','W',1000); END IF;   UTL_FILE.PUTF(HANDLE,'%s\\n%s\\n%s\\n','&line1','&line2','&line3');   UTL_FILE.FCLOSE(HANDLE); END; 17、PUTF_NCHAR 同上，该过程用于以特定的格式将文本内容以UNICODE方式写入到文件中。 18、FFLUSH 该过程用于将数据强制性写入到文件中，正常情况下，当给文件写入数据的时候，数据会被暂时的放到缓存中。过程FFLUSH用于强制将数据写入到文件中。语法如下： UTL_FILE.FFLUSH(file IN FILE_TYPE): 19、FSEEK 该过程用于移动文件指针到特定的位置。当使用该过程移动文件指针的时候，既可以指定文件指针的绝对位置，也可以指定文件指针的相对位置，语法如下： UTL_FILE.FSEEK(   fid IN utl_file.FILE_TYPE,   absolute_offset IN PL_INTEGER DEFALUT NULL,   relative_offset IN PL_INTEGER DEFALUT NULL)； 如上所示，absolute_offset 用于指定文件的绝对位置，relative_offset 用于指定文件的相对位置（单位：字节），使用该过程的示例如下： DECLARE   HANDLE UTL_FILE.FILE_TYPE;   BUFFER VARCHAR2(2000); BEGIN IF NOT UTL_FILE.is_open(HANDLE) THEN   HANDLE := UTL_FILE.fopen('CZW','DYWT.TXT','R',1000); END IF;   DBMS_OUTPUT.PUT_LINE('起始位置'||'==>'||UTL_FILE.FGETPOS(HANDLE));   UTL_FILE.fseek(HANDLE,5);   DBMS_OUTPUT.PUT_LINE('现在位置'||'==>'||UTL_FILE.FGETPOS(HANDLE));   UTL_FILE.FCLOSE(HANDLE); END; 20、FREMOVE 该过程用于删除磁盘文件。语法如下： UTL_FILE.FREMOVE(location IN VARCHAR2，filename IN VARCHAR2); 上面的location用于指定DIRECTORY，注意，这里也必须要大写，filename用于指定要删除的文件名，示例如下： SQL> EXEC UTL_FILE.FREMOVE('CZW','NEW.TXT'); PL/SQL procedure successfully completed 21、FCOPY 该过程用于将源文件的全部或者部分内容复制到目标文件中。当使用该过程的时候，如果不设起始行和结束行，则将复制文件所有的内容。语法如下： UTL_FILE.FCOPY(   location IN VARCHAR2，   filename IN VARCHAR2，   dest_dir IN VARCHAR2,   dest_file IN VARCHAR2,   start_line IN PLS_INTEGER DEFAULT 1,   end_line IN PLS_INTEGER DEFALUT NULL); 上面location用于指定源文件所在的DIRECTORY对象，filename用于指定具体的文件名字，dest_dir指定希望复制到的文件的directory对象，dest_file用于指定目标文件的名称，start_line用于指定起始行号,end_line用于指定结束行号。 下面是UTL_FILE.FCOPY的例子： SQL> exec UTL_FILE.FCOPY('CZW','DYWT.TXT','CZW','CZW.TXT'); PL/SQL procedure successfully completed 22、FRENAME 该过程用于修改已经存在的文件名字，其作用于UNIX的MV命令完全相同，在修改文件名字的时候，通过指定overwrite参数可以覆盖已经存在的文件。语法如下： UTL_FILE.FRENAME(   location IN VARCHAR2，   filename IN VARCHAR2，   dest_dir IN VARCHAR2，   dest_file IN VARCHAR2，   overwrite IN BOOLEAN DEFAULT FALSE); 上面的，overwrite用于指定是否要覆盖已经存在的文件（false 不覆盖，true可以覆盖）例子如下： SQL> exec UTL_FILE.FRENAME('CZW','CZW.TXT','CZW','HANJB.TXT') PL/SQL procedure successfully completed 温习例子: 使用UTL_FILE包，按照一定的格式，导出数据库中某张表的数据： 使用具有DBA权限的用户创建DIRECTORY名为“CZW_DIR” DECLARE   HANDLE UTL_FILE.FILE_TYPE; BEGIN   HANDLE := UTL_FILE.FOPEN('CZW_DIR','DEPT.TXT','W',1000);   FOR I IN (SELECT T.DEPTNO||','||T.DNAME||','||T.LOC AS MSG FROM SCOTT.DEPT T) LOOP     UTL_FILE.PUT_LINE(HANDLE,I.MSG);   END LOOP;   UTL_FILE.FFLUSH(HANDLE);   UTL_FILE.FCLOSE(HANDLE); END;","title":"ORACLE的UTL_FILE包"},{"content":"     ㈠ 不合理的大表全表扫描         详见：点击打开链接         v$session_longops视图记录了超过6秒的所有SQL语句         这其中绝大部是全表扫描的语句！               ㈡ 语句共享性不好         常出没在OLTP，由于app没有合理使用绑定变量，导致大量重复的语句Parse，浪费大量的shared pool，使CPU利用率居高不下               ㈢ 过量的排序操作         有个原则：能不排序就不排序         特别是multi-pass，与事务设计、缺乏索引、优化器的选择等均有关系                ㈣ 大量递归SQL语句         由sys执行，以大量的空间管理sql语句为甚         常见于大数据处理         作为DBA，大数据处理前，主动进行存储空间的分配                ㈤ 优化器和统计信息         代码有时候，在测试环境能跑，到了生产环境就“萎”了         这是因为，生产环境没有及时采集统计信息，导致Oracle优化器不了解最新的数据和应用情况，而错误地选择了非优化的执行路径         所以，我们需及时采集统计信息，保证基于CBO的优化器能欢快运行                ㈥ 不合理的参数设置         系统参数一定要调，还要合理地调         主要是些内存参数、进程参数等                ㈦ 存储部署不合理         由于存储部署不合理导致I/O效率低下         处理方案：ASM、RAID10等                 ㈧ 频繁的数据库连接操作         主要是C/S结构比较常见，几乎绝迹于B/S了                ㈨ Redo Log 设计不合理         Redo log文件设计太小，频繁触发checkpoint事件，导致内存紧张和I/O繁忙         Redo log文件文件组太少，则可能使归档无法赶上redo entries产生的速度","title":"浅析导致数据库性能问题的常见原因"},{"content":"Oracle数据库与MySQL数据库的区别是本文我们主要介绍的内容，希望能够对您有所帮助。 1.组函数用法规则 mysql中组函数在select语句中可以随意使用，但在oracle中如果查询语句中有组函数，那其他列名必须是组函数处理过的，或者是group by子句中的列否则报错 eg： select name,count(money) from user；这个放在mysql中没有问题在oracle中就有问题了。 2.自动增长的数据类型处理 MYSQL有自动增长的数据类型，插入记录时不用操作此字段，会自动获得数据值。ORACLE没有自动增长的数据类型，需要建立一个自动增长的序列号，插入记录时要把序列号的下一个值赋于此字段。 CREATE SEQUENCE序列号的名称(最好是表名+序列号标记)INCREMENT BY 1 START WITH 1 MAXVALUE 99999 CYCLE NOCACHE; 其中最大的值按字段的长度来定，如果定义的自动增长的序列号NUMBER(6)，最大值为999999 INSERT语句插入这个字段值为：序列号的名称.NEXTVAL 3.单引号的处理 MYSQL里可以用双引号包起字符串，ORACLE里只可以用单引号包起字符串。在插入和修改字符串前必须做单引号的替换：把所有出现的一个单引号替换成两个单引号。 4.翻页的SQL语句的处理 MYSQL处理翻页的SQL语句比较简单，用LIMIT开始位置，记录个数；PHP里还可以用SEEK定位到结果集的位置。ORACLE处理翻页的SQL语句就比较繁琐了。每个结果集只有一个ROWNUM字段标明它的位置，并且只能用ROWNUM<100，不能用ROWNUM>80。 以下是经过分析后较好的两种ORACLE翻页SQL语句(ID是唯一关键字的字段名)： 语句一： SELECT ID, [FIELD_NAME,...] FROM TABLE_NAME WHERE ID IN ( SELECT ID FROM (SELECT ROWNUM AS NUMROW, ID FROM TABLE_NAME WHERE 条件1 ORDER BY 条件2) WHERE NUMROW > 80 AND NUMROW < 100 ) ORDER BY 条件3; 语句二： SELECT * FROM (( SELECT ROWNUM AS NUMROW, c.* from (select [FIELD_NAME,...] FROM TABLE_NAME WHERE 条件1 ORDER BY 条件2) c) WHERE NUMROW > 80 AND NUMROW < 100 ) ORDER BY 条件3; 5.长字符串的处理 长字符串的处理ORACLE也有它特殊的地方。INSERT和UPDATE时最大可操作的字符串长度小于等于4000个单字节，如果要插入更长的字符串，请考虑字段用CLOB类型，方法借用ORACLE里自带的DBMS_LOB程序包。插入修改记录前一定要做进行非空和长度判断，不能为空的字段值和超出长度字段值都应该提出警告，返回上次操作。 6.日期字段的处理 MYSQL日期字段分DATE和TIME两种，ORACLE日期字段只有DATE，包含年月日时分秒信息，用当前数据库的系统时间为SYSDATE，精确到秒，或者用字符串转换成日期型函数TO_DATE(‘2001-08-01’,’YYYY-MM-DD’)年-月-日24小时:分钟:秒的格式YYYY-MM-DD HH24:MI:SS TO_DATE()还有很多种日期格式，可以参看ORACLE DOC.日期型字段转换成字符串函数TO_CHAR(‘2001-08-01’,’YYYY-MM-DD HH24:MI:SS’) 日期字段的数学运算公式有很大的不同。MYSQL找到离当前时间7天用DATE_FIELD_NAME > SUBDATE(NOW()，INTERVAL 7 DAY)ORACLE找到离当前时间7天用 DATE_FIELD_NAME >SYSDATE - 7; MYSQL中插入当前时间的几个函数是：NOW()函数以`’YYYY-MM-DD HH:MM:SS’返回当前的日期时间，可以直接存到DATETIME字段中。CURDATE()以’YYYY-MM-DD’的格式返回今天的日期，可以直接存到DATE字段中。CURTIME()以’HH:MM:SS’的格式返回当前的时间，可以直接存到TIME字段中。例：insert into tablename (fieldname) values (now()) 而oracle中当前时间是sysdate 7.空字符的处理 MYSQL的非空字段也有空的内容，ORACLE里定义了非空字段就不容许有空的内容。按MYSQL的NOT NULL来定义ORACLE表结构，导数据的时候会产生错误。因此导数据时要对空字符进行判断，如果为NULL或空字符，需要把它改成一个空格的字符串。 8.字符串的模糊比较 MYSQL里用字段名like%‘字符串%’，ORACLE里也可以用字段名like%‘字符串%’但这种方法不能使用索引，速度不快，用字符串比较函数instr(字段名，‘字符串’)>0会得到更精确的查找结果。 9.程序和函数里，操作数据库的工作完成后请注意结果集和指针的释放。","title":"Oracle数据库与MySQL数据库的区别"},{"content":"一、导入 基本方法：将语句copy执行 plsqlDev：导入表——tab为SQL插入页是选择文件导入     二、导出 1、工具 2、导出表(或导出用户对象) 3、选择需要导出的数据对象(表，视图，函数，过程等) 4、tab为SQL插入页导出中选择“导出”，比如导出为xy.sql 值得注意的是第4步骤中可以勾选需要导出的内容  ","title":"oracle中导入导出sql文件"},{"content":"1、尽量少用IN操作符，基本上所有的IN操作符都可以用EXISTS代替。 2、不用NOT IN操作符，可以用NOT EXISTS或者外连接+（外连接+判断为空）替代。 3、不用“<>”或者“!=”操作符。对不等于操作符的处理会造成全表扫描，可以用“<” or “>”代替。例如：a<>0 改为 a>0 or a<0，a<>’ ’ 改为 a>’ ’ 4、Where子句中出现IS NULL或者IS NOT NULL时，Oracle会停止使用索引而执行全表扫描。可以考虑在设计表时，对索引列设置为NOT NULL。这样就可以用其他操作来取代判断NULL的操作。 5、当通配符“%”或者“_”作为查询字符串的第一个字符时，索引不会被使用，因此一般不要作为第一个字符出现。 6、对于有连接的列“||”，最后一个连接列索引会无效。尽量避免连接，可以分开连接或者使用不作用在列上的函数替代。 7、如果索引不是基于函数的，那么当在Where子句中对索引列使用函数时，索引不再起作用。 8、Where子句中避免在索引列上使用计算，否则将导致索引失效而进行全表扫描。 9、对数据类型不同的列进行比较时，会使索引失效。 10、用“>=”替代“>”。 11、UNION操作符会对结果进行筛选，消除重复，数据量大的情况下可能会引起磁盘排序。如果不需要删除重复记录，应该使用UNION ALL。 12、Oracle从下到上处理Where子句中多个查询条件，所以表连接语句应写在其他Where条件前，可以过滤掉最大数量记录的条件必须写在Where子句的末尾。 13、Oracle从右到左处理From子句中的表名，所以在From子句中包含多个表的情况下，将记录最少的表放在最后。 14、Order By语句中的非索引列会降低性能，可以通过添加索引的方式处理。严格控制在Order By语句中使用表达式。 15、不同区域出现的相同的Sql语句，要保证查询字符完全相同，以利用SGA共享池，防止相同的Sql语句被多次分析。 16、多利用内部函数提高Sql效率。 17、当在Sql语句中连接多个表时，使用表的别名，并将之作为每列的前缀。这样可以减少解析时间。 18、根据SQL不同设定优化模式的方式，选择不同的优化策略，通过SELECT /*+ALL+_ROWS*/ ……;来设定。可用的HINT包括/*+ALL_ROWS*/、/*+FIRST_ROWS*/、/*+CHOOSE*/、/*+RULE*/ 等一般在SQL前加first_rows策略，速度都会提高，特殊情况下改用choose策略。（本策略架构包已经支持） 19、对于大表查询中的列应尽量避免进行诸如to_char，to_date，to-number等转换 20、有索引的尽量用索引，有用到索引的条件写在前面 21、如有可能和有必要就建立一些索引 22、尽量避免进行全表扫描，限制条件尽可能多，以便更快搜索到要查询的数据","title":"sql优化策略"},{"content":"         通过对Hibernate框架的学习,已经慢慢的对Hibernate有了进一步的了解,接下来我们要说的是Hibernate Qusery Language(HQL),如果你正在学习SSH框架,那SQL对你来说也是不陌生的,通过学习会发现HQL跟SQL有很多的相似之处.             在学习的过程中通过对比找到两个知识点的联系,包括相同点和不同点,通过重点学习那些不同点将会大大减少我们学习的成本.因为HQL跟SQL有很大的相似处,尤其是语法,所以HQL的学习建立在SQL的基础之上,那对HQL的掌握变非常容易.            HQL和SQL不同点       第一点(从宏观的角度)               SQL是基于关系型数据库模型,没有面向对象的特点,而HQL是面向对象编程跟数据库关系的组合.因为这个不同点即HQL所具有的面向对象的特点.便有了接下来的不同之处.       第二点(操作内容):                 SQL更关注存在数据库中的表,并对表的一些操作,而HQL更关心对象及其属性的操作.       第三点(处理的关系):                 SQL更多处理的是表和表之间的关系,HQL则是处理对象之间的关系.         以上的对比是从一个宏观的角度对他们的对比,接下来我们将会从HQL具体的语法和简单的运用来逐渐掌握了HQL的基本用法.         需要说明的是在hql中关键字是不区分大小写，通常小写但是类的名称和属性名称必须区分大小写,因为面向对象的特征. 例如:fromStudent s where s.id<2跟fromStudent s where s.ID<2是不一样的.  from子句 例如:HQL的\"from Student\".相当于Sql的\"select * from Student\"从这点可以看出来HQL比SQL简洁了一些.  带参数查询(两种查询方式) 采用？方式，查询学号为1,2的学生 Liststudents = session.createQuery(\"select s.id, s.name from Student s wheres.id in(?, ?, ?, ?, ?)\") .setParameter(0,1) .setParameter(1,2) .list(); 采用 :参数名方式，查询学号为1,2的学生 Liststudents = session.createQuery(\"select s.id, s.name from Student s wheres.id in(:ids)\") .setParameterList(\"ids\",new Object[]{1, 2}) .list();    查询数量(查询所有学生数目) Long count = (Long)session.createQuery(\"select count(*) from Student\").uniqueResult(); 另一种查询方式 Longcount = (Long)session.createQuery(\"select count(*) from Student\")                                         .setMaxResults(1)                                         .uniqueResult();   在HQL中查询原生sql语句 List students = session.createSQLQuery(\"select * from t_student\").list(); 分页查询 Liststudents = session.createQuery(\"from Student\") .setFirstResult(1) .setMaxResults(2) .list();   ……            以上是对HQL的一些基本的介绍,建议在进行Hibernate的过程中可以在Hibernate核心配置文件配上以下属性:         <propertyname=\"hibernate.show_sql\">true<\/property>         这样在程序执行HQL语句时可以看到具体的Sql执行情况.通过查看Sql的执行情况我们也会看到Hibernate存在的一些问题,例如N+1问题.         希望通过以上的内容能够对HQL有个基本认识,接下来还需要在实践中提高.           对HQL的一句话总结为:面向对象的SQL.                     ","title":"Hibernate 之 HQL"},{"content":"批量更新是指在一个事务中更新大批量数据，批量删除是指在一个事务中删除大批量数据。以下程序直接通过Hibernate API批量更新CUSTOMERS表中年龄大于零的所有记录的AGE字段： tx = session.beginTransaction(); Iterator customers=session.find(\"from Customer c where c.age>0\").iterator(); while(customers.hasNext()){ Customer customer=(Customer)customers.next(); customer.setAge(customer.getAge()+1); } tx.commit(); session.close(); 如果CUSTOMERS表中有1万条年龄大于零的记录，那么Session的find()方法会一下子加载1万个Customer对象到内存。当执行tx.commit()方法时，会清理缓存，Hibernate执行1万条更新CUSTOMERS表的update语句： update CUSTOMERS set AGE=? …. where >update CUSTOMERS set AGE=? …. where >…… update CUSTOMERS set AGE=? …. where > 以上批量更新方式有两个缺点： (1) 占用大量内存，必须把1万个Customer对象先加载到内存，然后一一更新它们。 (2) 执行的update语句的数目太多，每个update语句只能更新一个Customer对象，必须通过1万条update语句才能更新一万个Customer对象，频繁的访问数据库，会大大降低应用的性能。 为了迅速释放1万个Customer对象占用的内存，可以在更新每个Customer对象后，就调用Session的evict()方法立即释放它的内存： tx = session.beginTransaction(); Iterator customers=session.find(\"from Customer c where c.age>0\").iterator(); while(customers.hasNext()){ Customer customer=(Customer)customers.next(); customer.setAge(customer.getAge()+1); session.flush(); session.evict(customer); } tx.commit(); session.close(); 在以上程序中，修改了一个Customer对象的age属性后，就立即调用Session的flush()方法和evict()方法，flush()方法使Hibernate立刻根据这个Customer对象的状态变化同步更新数据库，从而立即执行相关的update语句；evict()方法用于把这个Customer对象从缓存中清除出去，从而及时释放它占用的内存。 但evict()方法只能稍微提高批量操作的性能，因为不管有没有使用evict()方法，Hibernate都必须执行1万条update语句，才能更新1万个Customer对象，这是影响批量操作性能的重要因素。假如Hibernate能直接执行如下SQL语句： update CUSTOMERS set AGE=AGE+1 where AGE>0; 那么以上一条update语句就能更新CUSTOMERS表中的1万条记录。但是Hibernate并没有直接提供执行这种update语句的接口。应用程序必须绕过Hibernate API，直接通过JDBC API来执行该SQL语句： tx = session.beginTransaction(); Connection con=session.connection(); PreparedStatement stmt=con.prepareStatement(\"update CUSTOMERS set AGE=AGE+1 \" +\"where AGE>0 \"); stmt.executeUpdate(); tx.commit(); 以上程序演示了绕过Hibernate API，直接通过JDBC API访问数据库的过程。应用程序通过Session的connection()方法获得该Session使用的数据库连接，然后通过它创建PreparedStatement对象并执行SQL语句。值得注意的是，应用程序仍然通过Hibernate的Transaction接口来声明事务边界。 如果底层数据库（如Oracle）支持存储过程，也可以通过存储过程来执行批量更新。存储过程直接在数据库中运行，速度更加快。在Oracle数据库中可以定义一个名为batchUpdateCustomer()的存储过程，代码如下： create or replace procedure batchUpdateCustomer(p_age in number) as begin update CUSTOMERS set AGE=AGE+1 where AGE>p_age; end; 以上存储过程有一个参数p_age，代表客户的年龄，应用程序可按照以下方式调用存储过程： tx = session.beginTransaction(); Connection con=session.connection(); String procedure = \"{call batchUpdateCustomer(?) }\"; CallableStatement cstmt = con.prepareCall(procedure); cstmt.setInt(1,0); //把年龄参数设为0 cstmt.executeUpdate(); tx.commit(); 从上面程序看出，应用程序也必须绕过Hibernate API，直接通过JDBC API来调用存储过程。 Session的各种重载形式的update()方法都一次只能更新一个对象，而delete()方法的有些重载形式允许以HQL语句作为参数，例如： session.delete(\"from Customer c where c.age>0\"); 如果CUSTOMERS表中有1万条年龄大于零的记录，那么以上代码能删除一万条记录。但是Session的delete()方法并没有执行以下delete语句： delete from CUSTOMERS where AGE>0; Session的delete()方法先通过以下select语句把1万个Customer对象加载到内存中： select * from CUSTOMERS where AGE>0; 接下来执行一万条delete语句，逐个删除Customer对象： delete from CUSTOMERS where >delete from CUSTOMERS where >…… delete from CUSTOMERS where > 由此可见，直接通过Hibernate API进行批量更新和批量删除都不值得推荐。而直接通过JDBC API执行相关的SQL语句或调用相关的存储过程，是批量更新和批量删除的最佳方式，这两种方式都有以下优点： (1) 无需把数据库中的大批量数据先加载到内存中，然后逐个更新或修改它们，因此不会消耗大量内存。 (2) 能在一条SQL语句中更新或删除大批量的数据。","title":"在Hibernate应用中批量更新和批量删除"},{"content":"1、安全性     设置客户端连接后进行任何操作指定前需要密码，一个外部用户可以再一秒钟进行150W次访问，具体操作密码修改设置redis.conf里面的requirepass属性给予密码，当然我这里给的是primos 之后如果想操作可以采用登陆的时候就授权使用: sudo /opt/java/redis/bin/redis-cli -a primos 或者是进入以后auth primos然后就可以随意操作了 2、主从复制 做这个操作的时候我准备了两个虚拟机，ip分别是192.168.15.128和192.168.15.133     通过主从复制可以允许多个slave server拥有和master server相同的数据库副本 具体配置是在slave上面配置slave slaveof 192.168.15.128 6379 masterauth primos 如果没有主从同步那么就检查一下是不是防火墙的问题，我用的是ufw，设置一下sudo ufw allow 6379就可以了 这个时候可以通过info查看具体的情况 3、事务处理 redis对事务的支持还比较简单，redis只能保证一个client发起的事务中的命令可以连续执行，而中间不会插入其他client的命令。当一个client在一个连接中发出multi命令时，这个连接会进入一个事务的上下文，连接后续命令不会立即执行，而是先放到一个队列中，当执行exec命令时，redis会顺序的执行队列中的所有命令。 比如我下面的一个例子 set age 100 multi set age 10 set age 20 exec get age --这个内容就应该是20 multi set age 20 set age 10 exec get age --这个时候的内容就成了10，充分体现了一下按照队列顺序执行的方式 discard  取消所有事务，也就是事务回滚 不过在redis事务执行有个别错误的时候，事务不会回滚，会把不错误的内容执行，错误的内容直接放弃，目前最新的是2.6.7也有这个问题的 乐观锁 watch key如果没watch的key有改动那么outdate的事务是不能执行的 4、持久化机制 redis是一个支持持久化的内存数据库 snapshotting快照方式，默认的存储方式，默认写入dump.rdb的二进制文件中，可以配置redis在n秒内如果超过m个key被修改过就自动做快照 append-only file aof方式，使用aof时候redis会将每一次的函 数都追加到文件中，当redis重启时会重新执行文件中的保存的写命 令在内存中。 5、发布订阅消息 sbusribe publish操作，其实就类似linux下面的消息发布 6、虚拟内存的使用 可以配置vm功能，保存路径，最大内存上线，页面多少，页面大小，最大工作线程 临时修改ip地址ifconfig eth0 192.168.15.129","title":"redis入门——redis高级应用"},{"content":"DataType 属性 参阅应用于示例特性 使用 DataType 属性可以指定保存在表字段中数据的类型。每一字段只能包含单一数据类型的数据。 设置 DataType 属性使用下列设置： 设置 数据类型 大小 文本 （默认值）文本或文本和数字的组合，以及不需要计算的数字，例如电话号码。 最多为 255 个字符或长度小于 FieldSize 属性的设置值。Microsoft Access 不会为文本字段中未使用的部分保留空间。 备注 长文本或文本和数字的组合。 最多为 65,535 个字符（如果备注字段是通过 DAO 来操作，并且只有文本和数字（非二进制数据）保存在其中，则备注字段的大小受数据库大小的限制）。 数字 用于数学计算的数值数据。有关如何设置特定数字类型的详细信息，请参见 FieldSize 属性主题。 1、2、4 或 8 个字节（如果 FieldSize 属性设为 Replication ID，则为 16 个字节）。 日期/时间 从 100 到 9999 年的日期与时间值。 8 个字节。 货币 货币值或用于数学计算的数值数据，这里的数学计算的对象是带有 1 到 4 位小数的数据。精确到小数点左边 15 位和小数点右边 4 位。 8 个字节。 自动编号 每当向表中添加一条新记录时，由 Microsoft Access 指定的一个唯一的顺序号（每次递增 1）或随机数。自动编号字段不能更新。有关详细信息，请参见 NewValues 属性主题。 4 个字节（如果 FieldSize 属性设为 Replication ID 则为 16 个字节）。 是/否 “是”和“否”值，以及只包含两者之一的字段（Yes/No、True/False 或 On/Off）。 1 位 OLE 对象 Microsoft Access 表中链接或嵌入的对象（例如 Microsoft Excel 电子表格、Microsoft Word 文档、图形、声音或其他二进制数据）。 最多为 1 G 字节（受可用磁盘空间限制）。 超链接 文本或文本和以文本形式存储的数字的组合，用作超链接地址。超链接地址最多包含三部分： 显示的文本 — 在字段或控件中显示的文本。 地址 — 指向文件（UNC 路径）或页（URL）的路径。 子地址 — 位于文件或页中的地址。 屏幕提示 — 作为工具提示显示的文本。 在字段或控件中插入超链接地址最简易的方法是单击“插入”菜单上的“超链接”。 超链接数据类型三个部分中的每一部分最多只能包含 2048 个字符。 查阅向导 创建字段，该字段可以使用列表框或组合框从另一个表或值列表中选择一个值。单击该选项将启动“查阅向导”，它用于创建一个“查阅”字段。在向导完成之后，Microsoft Access 将基于在向导中选择的值来设置数据类型。 与用于执行查阅的主键字段大小相同，通常为 4 个字节。 只能在表“设计”视图的上方窗格中对该属性进行设置。 在 Visual Basic 中，将该字段追加到 Fields 集合之前，可以使用 ADO Type 属性来设置字段的数据类型。 说明 备注、超链接和 OLE 对象字段不能进行索引。 如果要对字段中包含了 1 到 4 位小数的数据进行大量计算，请用货币数据类型。Single 和 Double 数据类型字段要求浮点运算。货币数据类型则使用较快的定点计算。 注意  如果在表中输入数据后更改字段的数据类型，在保存表时，由于要进行大量的数据转换处理，时间会比较长。如果在字段中的数据类型与更改后的 DataType 属性设置发生冲突，则有可能会丢失一些数据。 设置 Format 属性，将预定义的显示格式指定为数字、日期/时间、货币及是/否数据类型。   以上是Access数据库的帮助中的内容。","title":"ACCESS数据库中的数据类型"},{"content":"USE tempdbGO--Xml采用元素时，Xml文件比较小，用属性解析速度会相关较，通过查看执行计划可以，通过Openxml先分析比较，性能等同--元素DECLARE @x XMLSET @x='<SO>\t<ID>1<\/ID>\t<SONr>SO#1<\/SONr>\t<Customer>Roy<\/Customer>\t<OrderDate>2012-12-01 10:00<\/OrderDate><\/SO>'--属性DECLARE @y XML SET @y='<SO ID=\"1\" SONr=\"SO#1\" Customer=\"Roy\" OrderDate=\"2012-12-01 10:00\"/>'DECLARE @idoc_x intEXEC sp_xml_preparedocument @idoc_x OUTPUT,@xDECLARE @idoc_y intEXEC sp_xml_preparedocument @idoc_y OUTPUT,@y--sql:variableDECLARE @ID INTSET @ID=1--1、元素SELECT \tT.c.value('(ID/text())[1]','int')  AS ID,\tT.c.value('(SONr/text())[1]','varchar(50)')  AS SONr,\tT.c.value('(Customer/text())[1]','varchar(50)')  AS Customer,\tT.c.value('(OrderDate/text())[1]','datetime')  AS OrderDateFROM @x.nodes('SO[ID=sql:variable(\"@ID\")]') T(c)--2、用Openxml读元素SELECT \t* FROM OPENXML(@idoc_x,'SO[ID=sql:variable(\"@ID\")]',2) WITH(\tID INT 'ID',\tSONr varchar(50) 'SONr',\tCustomer varchar(50) 'Customer',\tOrderDate DATETIME 'OrderDate')--3、属性SELECT \tT.c.value('@ID[1]','int')  AS ID,\tT.c.value('@SONr[1]','varchar(50)')  AS SONr,\tT.c.value('@Customer[1]','varchar(50)')  AS Customer,\tT.c.value('@OrderDate[1]','datetime')  AS OrderDateFROM @y.nodes('SO[@ID=sql:variable(\"@ID\")]') T(c)--4、用Openxml读属性SELECT \t* FROM OPENXML(@idoc_y,'SO[ID=sql:variable(\"@ID\")]',2) WITH(\tID INT '@ID',\tSONr varchar(50) '@SONr',\tCustomer varchar(50) '@Customer',\tOrderDate DATETIME '@OrderDate')EXEC sp_xml_removedocument @idoc_x;EXEC sp_xml_removedocument @idoc_y; 查看执行计划：","title":"XML之sql:variable性能比较"},{"content":"sp_rename   N'表名.原字段名','新字段名','column' sp_rename   N'user.编号123','编号','column' 查了那么多，都是些参数教程，现在放一实例，备用和分享！,中文字符考虑到兼容性，最好加N'","title":"Sql Server中改变表中的字段名的语句！(不是教程胜似教程，是示例代码)"},{"content":"一、通过命令行方式 在cmd中输入imp或exp命令，根据提示操作。     二、利用plsql developer 导出 1、工具 2、导出表(或导出用户对象) 3、选择需要导出的数据对象(表，视图，函数，过程等) 4、tab页为Oracle导出中选择“导出”，比如导出为xy.dmp   导入 1、工具 2、导入表 3、tab页为Oracle导入中选择需要导入的文件导入即可      ","title":"oracle中导入导出dmp文件"},{"content":"            在我们业务实现的过程中,往往会有这样的需求:保证数据访问的排他性,也就是我正在访问的数据,别人不能够访问,或者不能对我的数据进行操作.面对这样的需求,就需要通过一种机制来保证这些数据在一定的操作过程中不会被他人修改,这种机制就是我们今天要说的Locking 即\"锁\".由此我们可以得出一个小结论,锁主要是解决并发性问题.          Hibernate支持两种锁机制:\"悲观锁\"(Pessimistic Locking )和\"乐观锁\"(Optimistic Locking )            先来看悲观锁         通过悲观这两个字我们能够看出,它对数据被外界操作所采取的态度是悲观的,保守的.也就是在整个数据处理的过程中,,它都将数据处于锁定状态.悲观锁，通常是由数据库机制实现的，在整个过程中把数据锁住（查询时），只要事务不释放（提交/回滚）那么任何用户都不能查看或修改.需要等待资源释放.         接下来将通过一个简单查询语句来解释Hibernate是如何实现悲观锁.             //查询用户为\"jnqqls\"的用户        String hqlStr =\"from User as user where user.name='Jnqqls'\";        Query query = session.createQuery(hqlStr);        // 加锁        query.setLockMode(\"user\",LockMode.UPGRADE);          // 执行查询，获取数据         List userList = query.list();            通过查看运行时Hibernate的执行语句会发现,它是通过数据库的for update子句来实现了悲观锁的机制.        根据悲观锁的保守特点,在并发比较高的情况下不建议使用.特别是事务内的执行周期特别的长的情况下,其他请求资源都处于等待状态,导致数据库性能的大量开销.   接下来来看乐观锁         乐观锁(其实根本上不是锁,跟数据库没有关系.而是解决冲突的检测手段,机制是在数据库中加字段,例如增加一个版本号或者是时间戳). Hibernate实现乐观锁机制的原理        大多数的使用是采用数据版本的方式（version）实现，一般在数据库中加入一个version字段在读取数据的时候将version读取出来，在保存数据的时候判断version的值是否小于数据库中的version值，如果小于不予更新，否则给予更新.               了解原理之后接下来我们将会通过代码来了解Hibernate是如何实现乐观锁. 第一步,在Hibernate配置文件中添加version字段,Hibernate会自动进行相关的锁处理.   \t\t\t<?xml version=\"1.0\"?>\t\t\t<!DOCTYPE hibernate-mapping PUBLIC \t\t\t\t\"-//Hibernate/Hibernate Mapping DTD 3.0//EN\"\t\t\t\t\"http://hibernate.sourceforge.net/hibernate-mapping-3.0.dtd\">\t\t\t<hibernate-mapping>\t\t\t\t<class name=\"com.tgb.hibernate.User\" table=\"t_user\" optimistic-lock=\"version\">\t\t\t\t\t<id name=\"id\">\t\t\t\t\t\t<generator class=\"assigned\"/>\t\t\t\t\t<\/id>\t\t\t\t\t<version name=\"version\"/>\t\t\t\t\t<property name=\"name\"/>\t\t\t\t\t<property name=\"age\"/>\t\t\t\t<\/class>\t\t\t<\/hibernate-mapping>   在此配置的过程中需要注意version的结点必须在id结点之后.此处version的作用注意是存放着用户的版本信息.   下面编写一段代码,将用户的年龄减少2岁.   \t\tpublic void testLoad() {\t\t\t\t\tSession session = null;\t\t\t\t\ttry {\t\t\t\t\t\t//一个获取session的工具.\t\t\t\t\t\tsession = HibernateUtils.getSession();\t\t\t\t\t\t//开启事务\t\t\t\t\t\tsession.beginTransaction();\t\t\t\t\t\t//加载用户id为1001\t\t\t\t\t\tUser User = (User)session.load(User.class, \"1001\");\t\t\t\t\t\t//打印相关信息\t\t\t\t\t\tSystem.out.println(\"opt1-->Id=\" + user.getId());\t\t\t\t\t\tSystem.out.println(\"opt1-->Name=\" + user.getName());\t\t\t\t\t\tSystem.out.println(\"opt1-->Version=\" + user.getVersion());\t\t\t\t\t\tSystem.out.println(\"opt1-->Age=\" + user.getAge());\t\t\t\t\t\t\t\t\t\t\t\tuser.setAge(user.getAge() - 2);\t\t\t\t\t\t//提交事务\t\t\t\t\t\tsession.getTransaction().commit();\t\t\t\t\t}catch(Exception e) {\t\t\t\t\t\te.printStackTrace();\t\t\t\t\t\tsession.getTransaction().rollback();\t\t\t\t\t}finally {\t\t\t\t\t\t//关闭session\t\t\t\t\t\tHibernateUtils.closeSession(session);\t\t\t\t\t}\t\t\t\t}          通过操作可以发现,在每次更新User信息的时候,数据库中的version字段都在递增,如果我们在session提交之前开启另外一个session2对User年龄进行操作的话会出现错误提示.         org.hibernate.StaleObjectStateException:Row was updated ordeleted by another transaction(or unsaved-value mapping was incorrect):…………..      我们可以进行异常捕获版本错误并对用户进行相应的提示,例如\"数据已经被修改\".   Hibernate 锁小结          悲观锁容易出现资源等待现象,因为对资源的完整占有.如果并发逻辑的时间过长的话则会导致系统其他并发逻辑的等待,会大大降低系统的并发性,并加大数据库的开销.         乐观锁因为采用版本机制,不会出现资源等待的现象,它会在提交数据的那一瞬间去判断版本的大小,如果出现并发修改的情况则会抛出异常错误,对于乐观锁而言,异常捕获显得尤为重要.  ","title":"Hibernate 之 Locking"},{"content":"1添加MySQL用户和组 useradd -M -s /sbin/nologin mysql       2解压MySQL软件包         tar zxvf mysql-5.0.56.tar.gz cd mysql-5.0.56    3编译前的预配置 ./configure--prefix=/usr/local/mysql  关于mysql支持GBK的问题解决方法 1)．修改配置文件 vi /etc/my.cnf 在此文件中相应位置加入 default-character-set = gbk ######################## [client] default-character-set = gbk [mysqld] default-character-set = gbk #########################   2)．编译解决 make WITH_CHARSET=gbk WITH_XCHARSET=allWITH_COLLATION=gbk_chinese_ci BUILD_STATIC=yes install clean 如果是装好后发现忘记支持GBK，需要重新编译，记得重启MYSQL服务   4编译并安装      make && make install    5安装后的调整       建立配置文件 在展开的源码包目录中的support-files文件夹下 提供了多个MySQL服务器的配置样例文件，分别适用于不同负载的数据库服务器。 一般选择my-medium.cnf文件，这个配置文件适用于中等负载的数据库。 cp support-files/my-medium.cnf/etc/my.cnf  初始化数据库 以mysql用户的身份执行mysql_install_db脚本 对MySQL数据库进行初始化 cd /usr/local/mysql/ bin/mysql_install_db  --user=mysql  目录权限 修改相关目录的所有权，以便mysql用户可以读写数据库 chown -R  root.mysql  /usr/local/mysql/ chown -R  mysql  /usr/local/mysql/var  调整lib库路径 由于Mysql安装到了非标准的路径中。所以还需要将MySQL的库文件路径“/usr/local/mysql/lib/mysql” 加入到系统的库文件搜索路径中以便在用到时能够自动搜索到。增加库文件搜索路径可以通过修改“/etc/ld.so.conf”文件实现      vi /etc/ld.so.conf /usr/local/mysql/lib/mysql ldconfig   //刷新库文件搜索路径使修改生效    6     mysql启动控制  1使用mysqld_safe脚本安全启动服务      在“/usr/local/mysql/bin/”目录中，存放着管理mysql服务器的脚本和程序。 其中脚本文件mysql_safe可用来安全启动mysql服务器。结合命令选项“—user”可指定运行服务的用户身份。 /usr/local/mysql/bin/mysqld_safe --user=mysql &      2将mysqld添加为系统服务       在展开的MySQL源码包目录中的support-files文件夹下 ―mysql.server文件可用来作为mysqld服务的启动脚本。将其复制到“/etc/init.d”目录，并注意添加执行权限，否则在执行“service mysqld start ”时会提示 mysqldunrecognized service cd mysql-5.0.56/ cp support-files/mysql.server /etc/init.d/mysqld chmod +x /etc/init.d/mysqld chkconfig --add mysqld chkconfig mysqld on     3设置mysql程序的执行路径        为了在执行“mysql”等命令和脚本工具时输入更方便，修改PATH环境变量添加执行路径“/usr/local/mysql/bin”,并将相关设置定义到系统的“/etc/profile”中。     export PATH=$PATH:/usr/local/mysql/bin vi  /etc/profile PATH=$PATH:/usr/local/mysql/bin       其他： cp php遇到环境问题 重新安装指定mysql目录 PHP Warning:  PHPStartup: Unable to load dynamic library'/home/admin/php/lib/php/extensions/no-debug-non-zts-20090626/mcrypt.so' -libltdl.so.3: cannot open shared object file: No such file or directory inUnknown on line 0 机器环境原因引起的默认依赖包不存在，安装libtool-libs即可 sudo yum install libtool-libs","title":"linux下mysql安装全攻略"},{"content":"        从11月中旬以来一直在做教务系统，开始阶段是各个子系统独立开发，包括评教系统、选修课系统、考试系统三个子系统，这三个系统已经有原型，我们采用的都是原型开发，因为需求已经确定，研究了一段时间把用例图、类图等画了画，完成了大部分了，快该写代码了然后，老师说需要把这三个系统整合在一起，做一个教务系统，教务系统是一个平台，可以往里面扩充子系统，使得信息可以共享，避免信息孤岛的出现。           对于想要建立共享性、集成性高的系统即要设计一个结构紧密又灵活性好的共享数据库，下面一段很长的时间就是设计教务系统的数据库……        下面是我们数据库设计的过程中遇到的一些问题          1. 数据库表之间该不该多用主外键呢 ?             先说我们做的评教系统，单独从这一个系统角度考虑，建立我们自己的数据库表，我们多加一些主键无所谓，加多点主键还可以使得表结构严谨，数据一致性好，但是当我们再加入新的系统的时候，把选课系统也加入到这个系统中，那么评教系统中的表就需要从新设计里面的主外键，出现这样的情况是当初设计表结构时没有考虑到灵活性，单独从一个系统角度考虑，即过多使用主外键也会使得表结构过于紧密、灵活性差，在什么情况下使用还需多多考虑。               那主外键就不使用了吗？当然不是，既然主外键可以使得表一致性高、扩展性差，那我们可以避开缺点，使用优点，在需要扩展的地方尽量不使用主外键关系，而在要求扩展性不高的地使用主键外键，根据这一原则更改表结构            更改后的数据库设计，如下                       新增了中间表（关系表）充当主外键的作用维持数据一致性，把基础表中的键关系移动到了基础表与关系表中，这看上去好像是降低了基础表与基础表之间的耦合度，给基础表解耦，这让我想起了中介者模式，通过一个中介类来给各个对象解耦，通过中介通信，而不是让各个类直接通信，举个例子：各个国家中国、美国、日本等有时并不直接交涉而不是通过联合国，给各个国家之间解耦，不管是在生活、学习中，设计模式的思想无处不在，值得学习。                   2.  基础表与子系统表如何划分 ?           从每一个子系统方面考虑，子系统表无论放基础里还是放自己系统里都可以实现，其区别是放基础里面别的子系统可以使用，来共享信息，分表的时候按着信息是否需要共享来分表，如果这种信息不需要共享，那我们就没有必要往基础表里面放，如果放在基础表里面反而会增加基础表负担，增加数据库表冗余。             举个例子：例如TB_Student、TB_Teacher、TB_College、TB_Department等表，只要是学校里的系统，一般都会用到这些信息，很显然，这些表应该归为基础表，另外还有一些特殊关系表也应该规则基础表，如老师课程关系表等，这也是基础信息，这些信息不依附于某个子系统。                     其中，也还有很多细节问题，不一一列举，下面是数据库设计一点点经验             我们设计数据库时可以遵循这样的设计原则：             (1) 数据库中表的个数越少越好。                    形成了对客观世界的高度抽象，进行了系统的数据集成，防止了打补丁式的设计           (2) 表中组合主键的字段个数越少越好。                   因为主键的作用，一是建主键索引，二是做为子表的外键，所以组合主键的字段个数少了，不仅节省了运行时间，而且节省了索引存储空间；           (3) 表中的字段个数越少越好。                   减少数据冗余，一种方法是“列变行”，所谓“列变行”，就是将主表中的一部分内容拉出去，另外单独建一个子表。这样就防止了将子表中的字段拉入到主表中去，在主表中留下许多空余的字段。             (4) 降低范式，增加冗余, 少用触发器, 多用存储过程。           (5) 当计算非常复杂、而且记录条数非常巨大时,复杂计算要先在数据库外面。             (6) 发现某个表的记录太多，例如超过一千万条，则要对该表进行水平分割。水平分割的做法是，以该表主键PK的某个值为界线，将该表的记录水平分割为两个表。若发现某个表的字段太多，例如超过八十个，则垂直分割该表，将原来的一个表分解为两个表。           (7) 对数据库管理系统DBMS进行系统优化，即优化各种系统参数，如缓冲区个数。    ","title":"教务系统数据库设计 （一）"},{"content":"索引概述 什么是索引？ 索引是Oracle数据库中提供的一种可选的数据结构，用于关联一个表。  为什么要使用索引？ 索引在有些情况下可以加快访问速度，减少磁盘IO。 通常情况下时候使用索引？ 表中的某列经常会在查询中使用，并且经常用返回占表中数据总量比例较少的row set。 引用完整性约束列。 unique key 。   下面我们来简述一下两种常见的索引类型：B-Tree索引以及BitMap索引。 B-Tree 索引 B*Tree索引，这是OracleDatabase中最常用的索引类型，在各种Oracle各种数据库类型中都得到了广泛的使用。原理上来讲，它的逻辑结构就像一个B-树，一种多路搜索树（非二叉树），并且不管在Oracle数据库在维护索引的过程中，branch block 和 leaf block 如何分裂，或者收缩，它一直保持平衡状态（平衡树），这意味着我们需要的数据也就是leaf block都存放在相同的level上面（height-1）。 逻辑结构 逻辑结构如下图所示： 如上图所示，每个branch block 都拥有其child block的指针。每个indexentry都只指向一单一的row。如下所示： row#0[8024] flag: ------, lock: 0, len=12col 0; len 2; (2):  c1 02col 1; len 6; (6):  01 10 7a 5300 00row#1[7796] flag: ------, lock: 0, len=12col 0; len 2; (2):  c1 02col 1; len 6; (6):  01 10 7a 5500 00row#2[7676] flag: ------, lock: 0, len=12col 0; len 2; (2):  c1 02col 1; len 6; (6):  01 10 7a 5500 0arow#3[7556] flag: ------, lock: 2, len=12col 0; len 2; (2):  c1 02col 1; len 6; (6):  01 10 7a 5500 14row#4[7436] flag: ------, lock: 2, len=12col 0; len 2; (2):  c1 02col 1; len 6; (6):  01 10 7a 5500 1erow#5[8012] flag: ------, lock: 0, len=12col 0; len 2; (2):  c1 03col 1; len 6; (6):  01 10 7a 5300 01   可以看到，每一个index entry都指向单一的rowid，相同index key value下的行按照rowid asc排列。 我觉得，它不像是树，更像是一个森林。 B-tree索引维护要点 计算要创建索引的大小 可以使用dbms_space.create_index_cost存储过程来预估创建index需要的存储空间。这个操作比较依赖于数据字典中的表统计信息，所以在使用之前需要执行dbms_stats.gather_table_stats。 相关说明： DBMS_SPACE.CREATE_INDEX_COST (  ddl             IN    VARCHAR2,  used_bytes      OUT   NUMBER,  alloc_bytes     OUT   NUMBER,  plan_table      IN    VARCHAR2 DEFAULT NULL); Parameter Description ddl The create index DDL statement used_bytes The number of bytes representing the actual index data alloc_bytes Size of the index when created in the tablespace plan_table Which plan table to use, default NULL Usage Notes The table on which the index is created must already exist. The computation of the index size depends on statistics gathered on the segment. It is imperative that the table must have been analyzed recently. In the absence of correct statistics, the results may be inaccurate, although the procedure will not raise any errors. 考虑分离索引段到专用的表空间 以下几个情况，可以考虑分离索引段： 1.     对于表和索引，制定不同的备份策略。对于索引数据和表中数据，可以适当的根据重要性来调整备份的周期。甚至可以选择不备份索引数据。 2.     分离索引和表的数据到不同的表空间，可以针对两者给予不同的存储选项。比如说，对于索引表空间，可以适当的调整extent 的大小和 logging选项等。 何时重建索引 ANALYZE INDEX &&index_name VALIDATESTRUCTURE;col name        heading 'Index Name'          format a30col del_lf_rows  heading 'Deleted|LeafRows'   format 99999999col lf_rows_used heading 'Used|Leaf Rows'     format 99999999col ibadness     heading '%Deleted|Leaf Rows' format 999.99999SELECT name,del_lf_rows,lf_rows - del_lf_rows lf_rows_used,to_char(del_lf_rows /(lf_rows)*100,'999.99999') ibadnessFROM index_statswhere name = upper('&&index_name');   当10%-15%索引数据更改的时候，就可以考虑重建索引了。 BitMap索引 Bitmap索引不像B-Tree索引，它的一个index entry可以指向更多的rows。通常它比较适用于以下两种情况： 1.     索引列拥有较低的基数，重复值较少。 2.     表是read only 模式，或者极少更改其中的数据。 不管是OLTP 或者 OLAP ，只要满足上面的情况，都可以使用BitMap索引（当然适用于OLAP比较多）。 逻辑结构 BitMap Index使用B-Tree的索引结构去存储索引数据。这里不再列出。 下面给出一个简单示例： create table tb_test ( id number , gendervarchar2(1),level int) ;insert into tb_test select level , ‘F’ , 1from dual connect by level<=3 ;insert into tb_test select level , ‘M’,2 fromdual connect by level <=2 ;create bitmap index tb_test_btidx1 ontb_test(gender) ;create bitmap index tb_test_btidx2 ontb_test(level) ; 那么它的bitmap示意表如下： 键值 row#1 row#2 row#3 row#4 row#5 F 1 1 1 0 0 M 0 0 0 1 1 1 1 1 1 0 0 2 0 0 0 1 1 1 and F 1 1 1 0 0 2 or F 1 1 1 1 1 使用BitMap索引的性能提升（建立在low cardinality前提下）： 1.     相对于传统的B-Tree索引消耗更少的存储空间。 2.     查询更快，尤其是在拥有很多and、or 查询条件的时候。 3.     创建时间短（相对于B-Treeindex）。   缺点： DML锁的代价非常昂贵。更新一个带有bitmap index 的数据的时候，会锁定拥有该indexkey value的所有行。这也是为什么它只适用在拥有非常少的DML或者根本没有DML操作的表上面。详细测试请见附录1.   相关介绍先介绍到这里，下面我们来简单比较一下B-Tree索引和BitMap 索引在不同情况下的性能。 B-Tree和BitMap索引性能比较 场景1 在拥有较低基数的列上创建索引 --create tablecreate table tb_btree2(idnumber , name varchar2(20)) ;create table tb_bitmap2(idnumber , name varchar2(20)) ; --init datainsert into tb_btree2 selecttrunc(dbms_random.value(1,100001)) , 'name'||level from dual connect by level<= 100000;insert into tb_bitmap2 select* from tb_btree2 ;  --create indexcreate index tb_btree2_idx1on tb_btree2(id) ;create bitmap indextb_bitmap2_btidx1 on tb_bitmap2(id) ;  --gather statisticsexecdbms_stats.gather_table_stats ('dexter','tb_btree2',cascade=> true) ;execdbms_stats.gather_table_stats ('dexter','tb_bitmap2',cascade=> true) ;   测试语句1 单值查询 select * from tb_btree2 where id = 10 ; 两种索引性能对比如下表所示，详细执行计划请见附录2   select * from table where where id = 10 ;   consistent gets scan operation B-Tree index 5 index range scan BitMap index 5 bitmap index single value     测试语句2 范围查询 select * from tb_btree2 where id < 100 ; 两种索引性能对比如下表所示，详细执行计划请见附录3 select * from table where where id < 10 ;   consistent gets scan operation B-Tree index 101 index range scan BitMap index 101 bitmap index range scan   总结：在基数较大的情况下BitMap也能发挥较好的作用。 场景2 在拥有较高基数的列上创建索引： --create tablecreate table tb_btree3(id number , namevarchar2(20)) ;create table tb_bitmap3(id number , namevarchar2(20)) ; --init datainsert into tb_btree3 select trunc(dbms_random.value(1,100)), 'name'||level from dual connect by level <= 100000;insert into tb_bitmap3 select * from tb_btree3;  --create indexcreate index tb_btree3_idx1 on tb_btree3(id) ;create bitmap index tb_bitmap3_btidx1 ontb_bitmap3(id) ;  --gather statisticsexec dbms_stats.gather_table_stats('dexter','tb_btree3',cascade=> true) ;exec dbms_stats.gather_table_stats('dexter','tb_bitmap3',cascade=> true) ; 测试语句1 单值查询 select * from tb_btree3 where id = 10 两种索引性能对比如下表所示，详细执行计划请见附录4 select * from table where where id = 10 ;   consistent gets scan operation B-Tree index 365 table access full BitMap index 289 bitmap index single value   可以看到，在基数较高的时候，表甚至都不再使用B-Tree索引来检索数据，而BitMap这个时候能够发挥较好的性能。 测试语句2 范围查询 select * from tb_btree3 where id < 10 ; 两种索引性能对比如下表所示，详细执行计划请见附录5 select * from table where where id < 10 ;   consistent gets scan operation B-Tree index 917 table access full BitMap index 916 table access full   由于检索的数据量太多，所以都使用了全表扫描。   总结 上面的几个测试简单的比较了一下在不同基数情况下，B-Tree索引以及BitMap索引所发挥的作用。可以看到，不管基数如何，BitMap索引都能够发挥较高的性能。而B-Tree索引在基数较高的情况下则无法提升查询的性能。下面附录6提供了BitMap 索引与基数之间的关系，以及一个比较直观线性图。另外，BitMap索引还可以在使用多种谓词 and 、or 的情况下大幅度的提升查询的性能。总结一下： BitMap 适用范围：虽然BitMap索引能够提供较好的查询性能，但是因为BitMap索引在执行DML语句的时候，会锁定相关的bitmapsegment（dsi 402e p210），代价比较大，并且不支持唯一索引。所以它一般只适用于OLAP系统上的那些不常更新，或者根本不会执行DML语句的表上。 B-Tree 使用范围：对于unique 以及 primary key 一般都使用B-Tree索引，能够提升较高的性能，并且对比与BitMap索引来说，因为每一条Index entry只包含唯一的rowid，所以不需要额外的Lock，经常使用于OLTP系统当中。   附录 附录1 BitMap索引，DML锁相关测试 --bitmap index test --create tablecreate table tb_bitmap_test (id number , gendervarchar2(1)) ;--init datainsert into tb_bitmap_test select level , 'F'from dual connect by level <= 3 ;insert into tb_bitmap_test select level , 'M'from dual connect by level <= 2 ; --create indexcreate bitmap index tb_bitmap_test_btidx1 ontb_bitmap_test(gender) ;     Session1 Session2 Description T1 update tb_bitmap_test set gender='M' where id= 1 ;   session1执行的这个更新语句会将所有的bitmap segemnt锁住。 T2   dexter@ORCL> update tb_bitmap_test set gender='F' where id= 2 ;   因为session1已经将bitmap segment锁住，所以这里无法再执行删除，插入操作 T3   dexter@ORCL> insert into tb_bitmap_test values (6,'M') ;   因为session1已经将bitmap segment锁住，所以这里无法再执行插入操作 T4   dexter@ORCL> insert into tb_bitmap_test values (7,'F') ;   因为session1已经将bitmap segment锁住，所以这里无法再执行插入操作 T5   dexter@ORCL> delete tb_bitmap_test where id= 3 ;   因为session1已经将bitmap segment锁住，所以这里无法再执行删除操作 T6   dexter@ORCL> insert into tb_bitmap_test values (6,'N') ;   因为这里session2的插入操作不涉及index key value=’M’ and ‘F’被锁住的bitmap segment，所以可以正常插入     dexter@ORCL> insert into tb_bitmap_testvalues (6,'N') ;   1 row created. 附录2 select *from tb_btree2 where id = 10 ; dexter@ORCL> select * from tb_btree2where id = 10 ;     dexter@ORCL> select * from tb_bitmap2where id = 10 ; 附录3 select *from tb_btree2 where id < 100 ; dexter@ORCL> select * from tb_btree2where id < 100 ;   dexter@ORCL> select * from tb_bitmap2where id < 100 ; 附录4 select *from tb_btree3 where id = 10 ; dexter@ORCL>  select * from tb_btree3 where id = 10 ; dexter@ORCL>  select * from tb_bitmap3 where id = 10 ; 附录5 select *from tb_btree3 where id < 10 ; dexter@ORCL>  select * from tb_btree3 where id < 10 ;   dexter@ORCL>  select * from tb_bitmap3 where id < 10 ; 附录6 BITMAPINDEXES AND CARDINALITY 这里引用Oracle®PerformanceSurvival Guide 126页的内容： BITMAP INDEXES AND CARDINALITY At what point should we decide that thecolumn has too many unique values to be suitable for a bitmap index? Most examples of bitmap indexes (includingthat in Figure 5-7) show multi-ple columns of verylow cardinality, such asgender, marital status, and so on. When we look at those examples we’d beforgiven for thinking that bitmap in-dexes are not suitable when there are morethan a handful of key values. In fact, bitmap indexes are capable ofperforming well even when there are many thousands of unique values. Figure 5-8shows the relative performance of bitmap and B*-Tree-based queries on amillion row table for columns varying be-tween 5 and 10,000 distinct values. Aswe can see, bitmap indexes are still quite effective even when the number of distinctvalues is very large. 相关文档下载  Oracle performance survival guide ： http://download.csdn.net/detail/junegey_kimi/4363090 dsi402e-d12865_Data Types and block structure ： http://download.csdn.net/detail/renfengjun/4945581","title":"Oracle数据库中B-Tree以及BitMap index 的性能对比"},{"content":"Redhat 5.5 Orcle 10G 文件系统单实例迁移至ASM实战 1.安装ASMlib RPM包:        rpm -ivhoracleasm-support-2.1.7-1.el5.i386.rpm        rpm -ivh oracleasm-2.6.18-194.el5-2.0.5-1.el5.i686.rpm        rpm -ivhoracleasmlib-2.0.4-1.el5.i386.rpm   2.建立分区： [root@source ~]# fdisk -l /dev/sdb   Disk /dev/sdb: 10.7 GB, 10737418240 bytes 255 heads, 63 sectors/track, 1305 cylinders Units = cylinders of 16065 * 512 = 8225280 bytes      Device Boot      Start         End      Blocks  Id  System /dev/sdb1              1         730     5863693+ 83  Linux /dev/sdb2            731        1305     4618687+ 83  Linux   fdisk /dev/sdb（详细步骤省略,两个分区各5G） partprobe /dev/sdb   [root@source ~]# fdisk -l Disk /dev/sda: 16.1 GB, 16106127360 bytes 255 heads, 63 sectors/track, 1958 cylinders Units = cylinders of 16065 * 512 = 8225280 bytes      Device Boot      Start         End      Blocks  Id  System /dev/sda1   *           1          25      200781  83  Linux /dev/sda2              26        1894   15012742+  83  Linux /dev/sda3           1895        1958      514080  82  Linux swap / Solaris   Disk /dev/sdb: 10.7 GB, 10737418240 bytes 255 heads, 63 sectors/track, 1305 cylinders Units = cylinders of 16065 * 512 = 8225280 bytes      Device Boot      Start         End      Blocks  Id  System /dev/sdb1              1         730     5863693+ 83  Linux /dev/sdb2            731        1305     4618687+ 83  Linux   3.配置ASM: [root@source ~]#/etc/init.d/oracleasm configure Configuring the Oracle ASMlibrary driver.   This will configure theon-boot properties of the Oracle ASM library driver.  The following questions will determinewhether the driver is loaded on boot and whatpermissions it will have.  The currentvalues will be shown in brackets('[]').  Hitting <ENTER> withouttyping an answer will keep that currentvalue.  Ctrl-C will abort.   Default user to own thedriver interface []: oracle Default group to own thedriver interface []: oinstall Start Oracle ASM library driveron boot (y/n) [y]: y Scan for Oracle ASM disks onboot (y/n) [y]: y Writing Oracle ASM librarydriver configuration: done Initializing the OracleASMLib driver:                     [  OK  ] Scanning the system forOracle ASMLib disks:               [  OK  ]   /etc/init.d/oracleasmconfigure  /etc/init.d/oracleasm createdisk V0L1/dev/sdb1  /etc/init.d/oracleasm createdisk V0L2/dev/sdb2   [root@source ~]#/etc/init.d/oracleasm listdisks V0L1 V0L2   4.配置css进程（配置好后，进程开机启动）： [root@source bin]# /u01/oracle/product/10.2.0/bin/localconfigadd /etc/oracle does not exist. Creating it now. Successfully accumulated necessary OCR keys. Creating OCR keys for user 'root', privgrp 'root'.. Operation successful. Configuration for local CSS has been initialized   Adding to inittab Startup will be queued to init within 90 seconds. Checking the status of new Oracle init process... Expecting the CRS daemons to be up within 600 seconds. CSS is active on these nodes.         source CSS is active on all nodes. Oracle CSS service is installed and running underinit(1M)   [oracle@source ~]$ ps -ef|grep oracle root     4751     1  0 10:18 ?        00:00:00 /bin/su -l oracle -c sh -c 'cd/u01/oracle/product/10.2.0/log/source/cssd; ulimit -c unlimited; exec /u01/oracle/product/10.2.0/bin/ocssd ' oracle   4843  4751  0 10:19 ?        00:00:00/u01/oracle/product/10.2.0/bin/ocssd.bin   5.配置ASM实例： 创建ASM实例参数文件，添加相关参数： [oracle@source ~]$ cd /u01/oracle/product/10.2.0/dbs/ [oracle@source dbs]$ touch init+ASM.ora [oracle@source dbs]$ vim init+ASM.ora instance_type=asm large_pool_size=12m remote_login_passwordfile=exclusive asm_diskstring= background_dump_dest=/u01/oracle/admin/+ASM/bdump core_dump_dest=/u01/oracle/admin/+ASM/cdump user_dump_dest=/u01/oracle/admin/+ASM/udump   创建ASM密码文件： orapwd file=orapw+ASM entries=5 password=oracle   6.启动ASM实例： [oracle@source dbs]$ export ORACLE_SID=+ASM [oracle@source dbs]$ sqlplus /nolog SQL*Plus: Release 10.2.0.1.0 - Production on Fri Dec28 10:43:21 2012   Copyright (c) 1982, 2005, Oracle.  All rights reserved. SQL> conn / as sysdba Connected to an idle instance. SQL> startup ASM instance started   Total System Global Area   83886080 bytes Fixed Size                  1217836 bytes Variable Size              57502420 bytes ASM Cache                  25165824 bytes ORA-15110: no diskgroups mounted   报错是因为还没有建立磁盘组，忽略此报错，接下来建立ASM磁盘.   SQL> select name,state,free_mb,required_mirror_free_mb,usable_file_mb from v$asm_diskgroup; no rows selected   修改asm_diskstring参数，参数的含义官方文档解释如下： A comma-separated list of strings that limits the setof disks that ASM discovers. May include wildcard characters. Only disks thatmatch one of the strings are discovered. String format depends on the ASMlibrary in use and on the operating system. The standard system library for ASMsupports glob pattern matching.   SQL>  alter system set asm_diskstring='/dev/oracleasm/disks/V0L*'; System altered.   SQL>  create diskgroupdg1 external redundancy disk'/dev/oracleasm/disks/V0L1'; Diskgroup created.   SQL> create diskgrouprecovery external redundancy disk '/dev/oracleasm/disks/V0L2'; Diskgroup created.   SQL> select name,state,free_mb,required_mirror_free_mb,usable_file_mb from v$asm_diskgroup; NAME                           STATE          FREE_MB REQUIRED_MIRROR_FREE_MBUSABLE_FILE_MB ------------------------------ ----------- --------------------------------- -------------- DG1                            MOUNTED           5676                       0           5676 RECOVERY                       MOUNTED           4460                       0           4460   7.备份原库： RMAN> run { allocate channel c1 device type  disk;                                 allocate channel c2 device type disk;                                 backup database format '/home/oracle/full_databse%U'include current controlfile plus archivelog ; release channel c1; release channel c2; }   8.修改原库参数： alter system set db_create_file_dest='+DG1';  alter SYSTEM SET db_recovery_file_dest='+RECOVERY'; alter SYSTEM SET db_recovery_file_dest_size=5G; alter system set db_create_online_log_dest_1='+DG1';   9.迁移联机日志文件到ASM select group#,member from v$logfile;     GROUP#MEMBER ------------------------------------------------------------    3 /u01/oracle/oradata/sourcedb/redo03.log    2/u01/oracle/oradata/sourcedb/redo02.log    1 /u01/oracle/oradata/sourcedb/redo01.log   SQL> alter database add logfile member '+DG1' togroup 1; Database altered.   SQL> alter database add logfile member '+DG1' togroup 2; Database altered.   SQL> alter database add logfile member '+DG1' togroup 3; Database altered.   SQL> select group#,member from v$logfile;     GROUP#MEMBER ------------------------------------------------------------          3/u01/oracle/oradata/sourcedb/redo03.log          2/u01/oracle/oradata/sourcedb/redo02.log          1/u01/oracle/oradata/sourcedb/redo01.log          1+DG1/sourcedb/onlinelog/group_1.256.803217799          2+DG1/sourcedb/onlinelog/group_2.257.803217809          3+DG1/sourcedb/onlinelog/group_3.258.803217813   删除文件系统上的联机日志成员 SQL>alter database droplogfile member '/u01/oracle/oradata/sourcedb/redo02.log'; SQL> alter system switchlogfile; SQL> alter database droplogfile member '/u01/oracle/oradata/sourcedb/redo01.log'; SQL> alter system switchlogfile; SQL> alter database droplogfile member '/u01/oracle/oradata/sourcedb/redo03.log'; SQL> select member from v$logfile; MEMBER -------------------------------------------------- +DG1/sourcedb/onlinelog/group_1.256.803217799 +DG1/sourcedb/onlinelog/group_2.257.803217809 +DG1/sourcedb/onlinelog/group_3.258.803217813   10.迁移临时表空间文件到ASM:     SQL> select name from v$tempfile; NAME --------------------------------------------------------------------------- /u02/temp02.dbf SQL> alter tablespace temp add tempfile; Tablespace altered.   SQL> select file_name,tablespace_name fromdba_temp_files; FILE_NAME --------------------------------------------------------------------------- TABLESPACE_NAME ------------------------------ +DG1/sourcedb/tempfile/temp.259.803218283 TEMP /u02/temp02.dbf TEMP   SQL> alter tablespace temp drop tempfile'/u02/temp02.dbf'; Tablespace altered.   SQL> select file_name,tablespace_name fromdba_temp_files; FILE_NAME --------------------------------------------------------------------------- TABLESPACE_NAME ------------------------------ +DG1/sourcedb/tempfile/temp.259.803218283 TEMP   11.迁移控制文件和数据文件到ASM 首先修改参数文件： SQL> alter system setcontrol_files='+DG1/sourcedb/CONTROLFILE/control01.ctl','+DG1/sourcedb/CONTROLFILE/control02.ctl'scope=spfile; System altered.   SQL> shutdown immediate; Database closed. Database dismounted. ORACLE instance shut down. SQL> startup nomount; ORACLE instance started.   Total System Global Area  167772160 bytes Fixed Size                  1218316 bytes Variable Size              88082676 bytes Database Buffers           75497472 bytes Redo Buffers                2973696 bytes   [oracle@source ~]$ rman target / RMAN> restore controlfile from'/u01/oracle/oradata/sourcedb/control01.ctl';   Starting restore at 28-DEC-12 using channel ORA_DISK_1   channel ORA_DISK_1: copied control file copy output filename=+DG1/sourcedb/control01.ctl output filename=+DG1/sourcedb/control02.ctl Finished restore at 28-DEC-12   RMAN> alter database mount;   database mounted released channel: ORA_DISK_1   12.开始恢复数据文件到ASM: run{ set newname for datafile'/u01/oracle/oradata/sourcedb/system01.dbf' to '+DG1/sourcedb/DATAFILE/system01.dbf'; set newname for datafile'/u01/oracle/oradata/sourcedb/undotbs301.dbf' to'+DG1/sourcedb/DATAFILE/undotbs301.dbf'; set newname for datafile'/u01/oracle/oradata/sourcedb/sysaux01.dbf' to '+DG1/sourcedb/DATAFILE/sysaux01.dbf'; set newname for datafile'/u01/oracle/oradata/sourcedb/users01.dbf' to'+DG1/sourcedb/DATAFILE/users01.dbf'; set newname for datafile'/u01/oracle/oradata/sourcedb/example01.dbf' to'+DG1/sourcedb/DATAFILE/example01.dbf'; set newname for datafile '/u01/oracle/oradata/sourcedb/gguser.dbf'to '+DG1/sourcedb/DATAFILE/gguser.dbf'; restore database; switch datafile all; recover database; }   13.迁移结束，验证一下： SQL> select name fromv$controlfile; NAME --------------------------------------------------------------------------- +DG1/sourcedb/controlfile/control01.ctl +DG1/sourcedb/controlfile/control02.ctl   SQL> select name fromv$datafile; NAME ---------------------------------------------------------------------------+DG1/sourcedb/datafile/system01.dbf +DG1/sourcedb/datafile/undotbs301.dbf +DG1/sourcedb/datafile/sysaux01.dbf +DG1/sourcedb/datafile/users01.dbf +DG1/sourcedb/datafile/example01.dbf +DG1/sourcedb/datafile/gguser.dbf   SQL> select member fromv$logfile; MEMBER ---------------------------------------------------------------------------          1+DG1/sourcedb/onlinelog/group_1.256.803217799          2+DG1/sourcedb/onlinelog/group_2.257.803217809          3+DG1/sourcedb/onlinelog/group_3.258.803217813   SQL> select name fromv$tempfile; NAME --------------------------------------------------------------------------- +DG1/sourcedb/tempfile/temp.259.803218283    ","title":"Redhat 5.5 Orcle 10G 文件系统单实例迁移至ASM实战"},{"content":"MYSQL的优化是非常重要的.其他最常用也最需要优化的就是limit.mysql的limit给分页带来了极大的方便,但数据量一大的时候,limit的性能就急剧下降. 同样是取10条数据 select * from yanxue8_visit limit 10000,10 和 select * from yanxue8_visit limit 0,10  就不是一个数量级别的. 网上也很多关于limit的五条优化准则,都是翻译自mysql手册,虽然正确但不实用.今天发现一篇文章写了些关于limit优化的,很不错. 文中不是直接使用limit,而是获取到offset的id然后直接使用limit size来获取数据.根据他的数据,明显要好于直接使用limit.这里我具体使用数据分两种情况进行测试.（测试环境win2033 p4双核 (3GHZ) 4G内存 mysql 5.0.19） 1、offset比较小的时候. select * from yanxue8_visit limit 10,10  多次运行,时间保持在0.0004-0.0005之间 Select * From yanxue8_visit Where vid ＞=( Select vid From yanxue8_visit Order By vid limit 10,1 ) limit 10  多次运行,时间保持在0.0005-0.0006之间,主要是0.0006 结论：偏移offset较小的时候,直接使用limit较优.这个显然是子查询的原因. 2、offset大的时候. select * from yanxue8_visit limit 10000,10  多次运行,时间保持在0.0187左右 Select * From yanxue8_visit Where vid ＞=( Select vid From yanxue8_visit Order By vid limit 10000,1 ) limit 10  --www.222gs.com 多次运行,时间保持在0.0061左右,只有前者的1/3.可以预计offset越大,后者越优. 以后要注意改正自己的limit语句,优化一下mysql了","title":"MYSQL索引优化"},{"content":"使用UDEV在Oracle Linux 6上安装Oracle 11g RAC(11.2.0.3) (一) 使用UDEV在Oracle Linux 6上安装Oracle 11g RAC(11.2.0.3) (二) 使用UDEV在Oracle Linux 6上安装Oracle 11g RAC(11.2.0.3) (三) 将安装介质上传到node1,解压准备安装grid infrastructure 使用grid用户解压 p10404530_112030_Linux-x86-64_3of7.zip 使用Cluster Verification Utility检查CRS安装环境 [grid@node1 grid]$ ./runcluvfy.sh stage -pre crsinst -n node1,node2 -fixup -verbosePerforming pre-checks for cluster services setup Checking node reachability...Check: Node reachability from node \"node1\"  Destination Node                      Reachable?                ------------------------------------  ------------------------  node1                                 yes                       node2                                 yes                     Result: Node reachability check passed from node \"node1\"Checking user equivalence...Check: User equivalence for user \"grid\"  Node Name                             Status                    ------------------------------------  ------------------------  node2                                 passed                    node1                                 passed                  Result: User equivalence check passed for user \"grid\"Checking node connectivity...Checking hosts config file...  Node Name                             Status                    ------------------------------------  ------------------------  node2                                 passed                    node1                                 passed                  Verification of the hosts config file successfulInterface information for node \"node2\" Name   IP Address      Subnet          Gateway         Def. Gateway    HW Address        MTU    ------ --------------- --------------- --------------- --------------- ----------------- ------ eth0   192.168.1.52    192.168.0.0     0.0.0.0         192.168.1.254   00:0C:29:5C:FC:76 1500   eth1   172.168.1.52    172.168.0.0     0.0.0.0         192.168.1.254   00:0C:29:5C:FC:80 1500  Interface information for node \"node1\" Name   IP Address      Subnet          Gateway         Def. Gateway    HW Address        MTU    ------ --------------- --------------- --------------- --------------- ----------------- ------ eth0   192.168.1.51    192.168.0.0     0.0.0.0         192.168.1.254   00:0C:29:79:33:95 1500   eth1   172.168.1.51    172.168.0.0     0.0.0.0         192.168.1.254   00:0C:29:79:33:9F 1500  Check: Node connectivity of subnet \"192.168.0.0\"  Source                          Destination                     Connected?        ------------------------------  ------------------------------  ----------------  node2[192.168.1.52]             node1[192.168.1.51]             yes             Result: Node connectivity passed for subnet \"192.168.0.0\" with node(s) node2,node1Check: TCP connectivity of subnet \"192.168.0.0\"  Source                          Destination                     Connected?        ------------------------------  ------------------------------  ----------------  node1:192.168.1.51              node2:192.168.1.52              passed          Result: TCP connectivity check passed for subnet \"192.168.0.0\"Check: Node connectivity of subnet \"172.168.0.0\"  Source                          Destination                     Connected?        ------------------------------  ------------------------------  ----------------  node2[172.168.1.52]             node1[172.168.1.51]             yes             Result: Node connectivity passed for subnet \"172.168.0.0\" with node(s) node2,node1Check: TCP connectivity of subnet \"172.168.0.0\"  Source                          Destination                     Connected?        ------------------------------  ------------------------------  ----------------  node1:172.168.1.51              node2:172.168.1.52              passed          Result: TCP connectivity check passed for subnet \"172.168.0.0\"Interfaces found on subnet \"192.168.0.0\" that are likely candidates for VIP are:node2 eth0:192.168.1.52node1 eth0:192.168.1.51Interfaces found on subnet \"172.168.0.0\" that are likely candidates for VIP are:node2 eth1:172.168.1.52node1 eth1:172.168.1.51WARNING: Could not find a suitable set of interfaces for the private interconnectChecking subnet mask consistency...Subnet mask consistency check passed for subnet \"192.168.0.0\".Subnet mask consistency check passed for subnet \"172.168.0.0\".Subnet mask consistency check passed.Result: Node connectivity check passedChecking multicast communication...Checking subnet \"192.168.0.0\" for multicast communication with multicast group \"230.0.1.0\"...Check of subnet \"192.168.0.0\" for multicast communication with multicast group \"230.0.1.0\" passed.Checking subnet \"172.168.0.0\" for multicast communication with multicast group \"230.0.1.0\"...Check of subnet \"172.168.0.0\" for multicast communication with multicast group \"230.0.1.0\" passed.Check of multicast communication passed.Checking ASMLib configuration.  Node Name                             Status                    ------------------------------------  ------------------------  node2                                 passed                    node1                                 passed                  Result: Check for ASMLib configuration passed.Check: Total memory   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         2.9462GB (3089356.0KB)    1.5GB (1572864.0KB)       passed      node1         2.9462GB (3089356.0KB)    1.5GB (1572864.0KB)       passed    Result: Total memory check passedCheck: Available memory   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         2.7915GB (2927064.0KB)    50MB (51200.0KB)          passed      node1         2.6722GB (2801984.0KB)    50MB (51200.0KB)          passed    Result: Available memory check passedCheck: Swap space   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         6GB (6291452.0KB)         2.9462GB (3089356.0KB)    passed      node1         6GB (6291452.0KB)         2.9462GB (3089356.0KB)    passed    Result: Swap space check passedCheck: Free disk space for \"node2:/tmp\"   Path              Node Name     Mount point   Available     Required      Status        ----------------  ------------  ------------  ------------  ------------  ------------  /tmp              node2         /             88.7852GB     1GB           passed      Result: Free disk space check passed for \"node2:/tmp\"Check: Free disk space for \"node1:/tmp\"   Path              Node Name     Mount point   Available     Required      Status        ----------------  ------------  ------------  ------------  ------------  ------------  /tmp              node1         /             81.6788GB     1GB           passed      Result: Free disk space check passed for \"node1:/tmp\"Check: User existence for \"grid\"   Node Name     Status                    Comment                   ------------  ------------------------  ------------------------  node2         passed                    exists(1100)              node1         passed                    exists(1100)            Checking for multiple users with UID value 1100Result: Check for multiple users with UID value 1100 passed Result: User existence check passed for \"grid\"Check: Group existence for \"oinstall\"   Node Name     Status                    Comment                   ------------  ------------------------  ------------------------  node2         passed                    exists                    node1         passed                    exists                  Result: Group existence check passed for \"oinstall\"Check: Group existence for \"dba\"   Node Name     Status                    Comment                   ------------  ------------------------  ------------------------  node2         passed                    exists                    node1         passed                    exists                  Result: Group existence check passed for \"dba\"Check: Membership of user \"grid\" in group \"oinstall\" [as Primary]  Node Name         User Exists   Group Exists  User in Group  Primary       Status        ----------------  ------------  ------------  ------------  ------------  ------------  node2             yes           yes           yes           yes           passed        node1             yes           yes           yes           yes           passed      Result: Membership check for user \"grid\" in group \"oinstall\" [as Primary] passedCheck: Membership of user \"grid\" in group \"dba\"   Node Name         User Exists   Group Exists  User in Group  Status            ----------------  ------------  ------------  ------------  ----------------  node2             yes           yes           no            failed            node1             yes           yes           no            failed          Result: Membership check for user \"grid\" in group \"dba\" failedCheck: Run level   Node Name     run level                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         3                         3,5                       passed      node1         5                         3,5                       passed    Result: Run level check passedCheck: Hard limits for \"maximum open file descriptors\"   Node Name         Type          Available     Required      Status            ----------------  ------------  ------------  ------------  ----------------  node2             hard          65536         65536         passed            node1             hard          65536         65536         passed          Result: Hard limits check passed for \"maximum open file descriptors\"Check: Soft limits for \"maximum open file descriptors\"   Node Name         Type          Available     Required      Status            ----------------  ------------  ------------  ------------  ----------------  node2             soft          1024          1024          passed            node1             soft          1024          1024          passed          Result: Soft limits check passed for \"maximum open file descriptors\"Check: Hard limits for \"maximum user processes\"   Node Name         Type          Available     Required      Status            ----------------  ------------  ------------  ------------  ----------------  node2             hard          16384         16384         passed            node1             hard          16384         16384         passed          Result: Hard limits check passed for \"maximum user processes\"Check: Soft limits for \"maximum user processes\"   Node Name         Type          Available     Required      Status            ----------------  ------------  ------------  ------------  ----------------  node2             soft          2047          2047          passed            node1             soft          2047          2047          passed          Result: Soft limits check passed for \"maximum user processes\"Check: System architecture   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         x86_64                    x86_64                    passed      node1         x86_64                    x86_64                    passed    Result: System architecture check passedCheck: Kernel version   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         2.6.39-200.24.1.el6uek.x86_64  2.6.32                    passed      node1         2.6.39-200.24.1.el6uek.x86_64  2.6.32                    passed    Result: Kernel version check passedCheck: Kernel parameter for \"semmsl\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             250           250           250           passed            node1             250           250           250           passed          Result: Kernel parameter check passed for \"semmsl\"Check: Kernel parameter for \"semmns\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             32000         32000         32000         passed            node1             32000         32000         32000         passed          Result: Kernel parameter check passed for \"semmns\"Check: Kernel parameter for \"semopm\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             100           100           100           passed            node1             100           100           100           passed          Result: Kernel parameter check passed for \"semopm\"Check: Kernel parameter for \"semmni\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             128           128           128           passed            node1             128           128           128           passed          Result: Kernel parameter check passed for \"semmni\"Check: Kernel parameter for \"shmmax\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             4398046511104  4398046511104  1581750272    passed            node1             4398046511104  4398046511104  1581750272    passed          Result: Kernel parameter check passed for \"shmmax\"Check: Kernel parameter for \"shmmni\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             4096          4096          4096          passed            node1             4096          4096          4096          passed          Result: Kernel parameter check passed for \"shmmni\"Check: Kernel parameter for \"shmall\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             1073741824    1073741824    2097152       passed            node1             1073741824    1073741824    2097152       passed          Result: Kernel parameter check passed for \"shmall\"Check: Kernel parameter for \"file-max\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             6815744       6815744       6815744       passed            node1             6815744       6815744       6815744       passed          Result: Kernel parameter check passed for \"file-max\"Check: Kernel parameter for \"ip_local_port_range\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             between 9000.0 & 65500.0  between 9000.0 & 65500.0  between 9000.0 & 65500.0  passed            node1             between 9000.0 & 65500.0  between 9000.0 & 65500.0  between 9000.0 & 65500.0  passed          Result: Kernel parameter check passed for \"ip_local_port_range\"Check: Kernel parameter for \"rmem_default\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             262144        262144        262144        passed            node1             262144        262144        262144        passed          Result: Kernel parameter check passed for \"rmem_default\"Check: Kernel parameter for \"rmem_max\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             4194304       4194304       4194304       passed            node1             4194304       4194304       4194304       passed          Result: Kernel parameter check passed for \"rmem_max\"Check: Kernel parameter for \"wmem_default\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             262144        262144        262144        passed            node1             262144        262144        262144        passed          Result: Kernel parameter check passed for \"wmem_default\"Check: Kernel parameter for \"wmem_max\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             1048576       1048576       1048576       passed            node1             1048576       1048576       1048576       passed          Result: Kernel parameter check passed for \"wmem_max\"Check: Kernel parameter for \"aio-max-nr\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             1048576       1048576       1048576       passed            node1             1048576       1048576       1048576       passed          Result: Kernel parameter check passed for \"aio-max-nr\"Check: Package existence for \"binutils\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         binutils-2.20.51.0.2-5.34.el6  binutils-2.20.51.0.2      passed      node1         binutils-2.20.51.0.2-5.34.el6  binutils-2.20.51.0.2      passed    Result: Package existence check passed for \"binutils\"Check: Package existence for \"compat-libcap1\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         compat-libcap1-1.10-1     compat-libcap1-1.10       passed      node1         compat-libcap1-1.10-1     compat-libcap1-1.10       passed    Result: Package existence check passed for \"compat-libcap1\"Check: Package existence for \"compat-libstdc++-33(x86_64)\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         compat-libstdc++-33(x86_64)-3.2.3-69.el6  compat-libstdc++-33(x86_64)-3.2.3  passed      node1         compat-libstdc++-33(x86_64)-3.2.3-69.el6  compat-libstdc++-33(x86_64)-3.2.3  passed    Result: Package existence check passed for \"compat-libstdc++-33(x86_64)\"Check: Package existence for \"libgcc(x86_64)\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         libgcc(x86_64)-4.4.6-4.el6  libgcc(x86_64)-4.4.4      passed      node1         libgcc(x86_64)-4.4.6-4.el6  libgcc(x86_64)-4.4.4      passed    Result: Package existence check passed for \"libgcc(x86_64)\"Check: Package existence for \"libstdc++(x86_64)\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         libstdc++(x86_64)-4.4.6-4.el6  libstdc++(x86_64)-4.4.4   passed      node1         libstdc++(x86_64)-4.4.6-4.el6  libstdc++(x86_64)-4.4.4   passed    Result: Package existence check passed for \"libstdc++(x86_64)\"Check: Package existence for \"libstdc++-devel(x86_64)\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         libstdc++-devel(x86_64)-4.4.6-4.el6  libstdc++-devel(x86_64)-4.4.4  passed      node1         libstdc++-devel(x86_64)-4.4.6-4.el6  libstdc++-devel(x86_64)-4.4.4  passed    Result: Package existence check passed for \"libstdc++-devel(x86_64)\"Check: Package existence for \"sysstat\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         sysstat-9.0.4-20.el6      sysstat-9.0.4             passed      node1         sysstat-9.0.4-20.el6      sysstat-9.0.4             passed    Result: Package existence check passed for \"sysstat\"Check: Package existence for \"gcc\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         gcc-4.4.6-4.el6           gcc-4.4.4                 passed      node1         gcc-4.4.6-4.el6           gcc-4.4.4                 passed    Result: Package existence check passed for \"gcc\"Check: Package existence for \"gcc-c++\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         gcc-c++-4.4.6-4.el6       gcc-c++-4.4.4             passed      node1         gcc-c++-4.4.6-4.el6       gcc-c++-4.4.4             passed    Result: Package existence check passed for \"gcc-c++\"Check: Package existence for \"ksh\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         ksh-20100621-16.el6       ksh-20100621              passed      node1         ksh-20100621-16.el6       ksh-20100621              passed    Result: Package existence check passed for \"ksh\"Check: Package existence for \"make\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         make-3.81-20.el6          make-3.81                 passed      node1         make-3.81-20.el6          make-3.81                 passed    Result: Package existence check passed for \"make\"Check: Package existence for \"glibc(x86_64)\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         glibc(x86_64)-2.12-1.80.el6_3.6  glibc(x86_64)-2.12        passed      node1         glibc(x86_64)-2.12-1.80.el6_3.6  glibc(x86_64)-2.12        passed    Result: Package existence check passed for \"glibc(x86_64)\"Check: Package existence for \"glibc-devel(x86_64)\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         glibc-devel(x86_64)-2.12-1.80.el6_3.6  glibc-devel(x86_64)-2.12  passed      node1         glibc-devel(x86_64)-2.12-1.80.el6_3.6  glibc-devel(x86_64)-2.12  passed    Result: Package existence check passed for \"glibc-devel(x86_64)\"Check: Package existence for \"libaio(x86_64)\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         libaio(x86_64)-0.3.107-10.el6  libaio(x86_64)-0.3.107    passed      node1         libaio(x86_64)-0.3.107-10.el6  libaio(x86_64)-0.3.107    passed    Result: Package existence check passed for \"libaio(x86_64)\"Check: Package existence for \"libaio-devel(x86_64)\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         libaio-devel(x86_64)-0.3.107-10.el6  libaio-devel(x86_64)-0.3.107  passed      node1         libaio-devel(x86_64)-0.3.107-10.el6  libaio-devel(x86_64)-0.3.107  passed    Result: Package existence check passed for \"libaio-devel(x86_64)\"Checking for multiple users with UID value 0Result: Check for multiple users with UID value 0 passed Check: Current group ID Result: Current group ID check passedStarting check for consistency of primary group of root user  Node Name                             Status                    ------------------------------------  ------------------------  node2                                 passed                    node1                                 passed                  Check for consistency of root user's primary group passedStarting Clock synchronization checks using Network Time Protocol(NTP)...NTP Configuration file check started...The NTP configuration file \"/etc/ntp.conf\" is available on all nodesNTP Configuration file check passedNo NTP Daemons or Services were found to be runningPRVF-5507 : NTP daemon or service is not running on any node but NTP configuration file exists on the following node(s):node2,node1Result: Clock synchronization check using Network Time Protocol(NTP) failedChecking Core file name pattern consistency...Core file name pattern consistency check passed.Checking to make sure user \"grid\" is not in \"root\" group  Node Name     Status                    Comment                   ------------  ------------------------  ------------------------  node2         passed                    does not exist            node1         passed                    does not exist          Result: User \"grid\" is not part of \"root\" group. Check passedCheck default user file creation mask  Node Name     Available                 Required                  Comment     ------------  ------------------------  ------------------------  ----------  node2         0022                      0022                      passed      node1         0022                      0022                      passed    Result: Default user file creation mask check passedChecking consistency of file \"/etc/resolv.conf\" across nodesChecking the file \"/etc/resolv.conf\" to make sure only one of domain and search entries is definedFile \"/etc/resolv.conf\" does not have both domain and search entries definedChecking if domain entry in file \"/etc/resolv.conf\" is consistent across the nodes...domain entry in file \"/etc/resolv.conf\" is consistent across nodesChecking if search entry in file \"/etc/resolv.conf\" is consistent across the nodes...search entry in file \"/etc/resolv.conf\" is consistent across nodesChecking file \"/etc/resolv.conf\" to make sure that only one search entry is definedAll nodes have one search entry defined in file \"/etc/resolv.conf\"Checking all nodes to make sure that search entry is \"localdomain\" as found on node \"node2\"All nodes of the cluster have same value for 'search'Checking DNS response time for an unreachable node  Node Name                             Status                    ------------------------------------  ------------------------  node2                                 passed                    node1                                 passed                  The DNS response time for an unreachable node is within acceptable limit on all nodesFile \"/etc/resolv.conf\" is consistent across nodesCheck: Time zone consistency Result: Time zone consistency check passedFixup information has been generated for following node(s):node2,node1Please run the following script on each node as \"root\" user to execute the fixups:'/tmp/CVU_11.2.0.3.0_grid/runfixup.sh'Pre-check for cluster services setup was unsuccessful on all the nodes. 发现有两个failed,一个是ntp,一个是grid用户不在dba组中 oracle11gR2 RAC中使用Cluster Time Synchronization Service(CTSS)同步各节点的时间,当安装程序发现 NTP 协议处于非活动状态时，安装集群时间同步服务将以活动模式自动进行安装并通过所有节点的时间。如果发现配置了 NTP，则以观察者模式 启动集群时间同步服务，Oracle Clusterware 不会在集群中进行活动的时间同步。 使用root用户在node1,node2中执行以下操作,关闭ntp服务,mv配置文件 [root@node2 ~]# service ntpd stopShutting down ntpd:                                        [FAILED][root@node2 ~]# chkconfig ntpd off[root@node2 ~]# mv /etc/ntp.conf /etc/ntp.conf.original[root@node2 ~]# rm -rf /var/run/ntpd.pid[root@node2 ~]# 将grid用户加入到dba组中 [root@node1 ~]# id griduid=1100(grid) gid=1000(oinstall) groups=1000(oinstall),1200(asmadmin),1201(asmdba),1202(asmoper)[root@node1 ~]# /tmp/CVU_11.2.0.3.0_grid/runfixup.shResponse file being used is :/tmp/CVU_11.2.0.3.0_grid/fixup.responseEnable file being used is :/tmp/CVU_11.2.0.3.0_grid/fixup.enableLog file location: /tmp/CVU_11.2.0.3.0_grid/orarun.loguid=1100(grid) gid=1000(oinstall) groups=1000(oinstall),1200(asmadmin),1201(asmdba),1202(asmoper)[root@node1 ~]# id griduid=1100(grid) gid=1000(oinstall) groups=1000(oinstall),1200(asmadmin),1201(asmdba),1202(asmoper),1300(dba)[root@node1 ~]# 安装cvuqdisk-1.0.9-1.rpm [root@node1 ~]# rpm -ivh /home/grid/grid/rpm/cvuqdisk-1.0.9-1.rpm Preparing...                ########################################### [100%]Using default group oinstall to install package   1:cvuqdisk               ########################################### [100%] 再次使用Cluster Verification Utility检查CRS安装环境 [grid@node1 grid]$ ./runcluvfy.sh stage -pre crsinst -n node1,node2 -fixup -verbosePerforming pre-checks for cluster services setup Checking node reachability...Check: Node reachability from node \"node1\"  Destination Node                      Reachable?                ------------------------------------  ------------------------  node1                                 yes                       node2                                 yes                     Result: Node reachability check passed from node \"node1\"Checking user equivalence...Check: User equivalence for user \"grid\"  Node Name                             Status                    ------------------------------------  ------------------------  node2                                 passed                    node1                                 passed                  Result: User equivalence check passed for user \"grid\"Checking node connectivity...Checking hosts config file...  Node Name                             Status                    ------------------------------------  ------------------------  node2                                 passed                    node1                                 passed                  Verification of the hosts config file successfulInterface information for node \"node2\" Name   IP Address      Subnet          Gateway         Def. Gateway    HW Address        MTU    ------ --------------- --------------- --------------- --------------- ----------------- ------ eth0   192.168.1.52    192.168.0.0     0.0.0.0         192.168.1.254   00:0C:29:5C:FC:76 1500   eth1   172.168.1.52    172.168.0.0     0.0.0.0         192.168.1.254   00:0C:29:5C:FC:80 1500  Interface information for node \"node1\" Name   IP Address      Subnet          Gateway         Def. Gateway    HW Address        MTU    ------ --------------- --------------- --------------- --------------- ----------------- ------ eth0   192.168.1.51    192.168.0.0     0.0.0.0         192.168.1.254   00:0C:29:79:33:95 1500   eth1   172.168.1.51    172.168.0.0     0.0.0.0         192.168.1.254   00:0C:29:79:33:9F 1500  Check: Node connectivity of subnet \"192.168.0.0\"  Source                          Destination                     Connected?        ------------------------------  ------------------------------  ----------------  node2[192.168.1.52]             node1[192.168.1.51]             yes             Result: Node connectivity passed for subnet \"192.168.0.0\" with node(s) node2,node1Check: TCP connectivity of subnet \"192.168.0.0\"  Source                          Destination                     Connected?        ------------------------------  ------------------------------  ----------------  node1:192.168.1.51              node2:192.168.1.52              passed          Result: TCP connectivity check passed for subnet \"192.168.0.0\"Check: Node connectivity of subnet \"172.168.0.0\"  Source                          Destination                     Connected?        ------------------------------  ------------------------------  ----------------  node2[172.168.1.52]             node1[172.168.1.51]             yes             Result: Node connectivity passed for subnet \"172.168.0.0\" with node(s) node2,node1Check: TCP connectivity of subnet \"172.168.0.0\"  Source                          Destination                     Connected?        ------------------------------  ------------------------------  ----------------  node1:172.168.1.51              node2:172.168.1.52              passed          Result: TCP connectivity check passed for subnet \"172.168.0.0\"Interfaces found on subnet \"192.168.0.0\" that are likely candidates for VIP are:node2 eth0:192.168.1.52node1 eth0:192.168.1.51Interfaces found on subnet \"172.168.0.0\" that are likely candidates for VIP are:node2 eth1:172.168.1.52node1 eth1:172.168.1.51WARNING: Could not find a suitable set of interfaces for the private interconnectChecking subnet mask consistency...Subnet mask consistency check passed for subnet \"192.168.0.0\".Subnet mask consistency check passed for subnet \"172.168.0.0\".Subnet mask consistency check passed.Result: Node connectivity check passedChecking multicast communication...Checking subnet \"192.168.0.0\" for multicast communication with multicast group \"230.0.1.0\"...Check of subnet \"192.168.0.0\" for multicast communication with multicast group \"230.0.1.0\" passed.Checking subnet \"172.168.0.0\" for multicast communication with multicast group \"230.0.1.0\"...Check of subnet \"172.168.0.0\" for multicast communication with multicast group \"230.0.1.0\" passed.Check of multicast communication passed.Checking ASMLib configuration.  Node Name                             Status                    ------------------------------------  ------------------------  node2                                 passed                    node1                                 passed                  Result: Check for ASMLib configuration passed.Check: Total memory   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         2.9462GB (3089356.0KB)    1.5GB (1572864.0KB)       passed      node1         2.9462GB (3089356.0KB)    1.5GB (1572864.0KB)       passed    Result: Total memory check passedCheck: Available memory   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         2.7901GB (2925668.0KB)    50MB (51200.0KB)          passed      node1         2.649GB (2777688.0KB)     50MB (51200.0KB)          passed    Result: Available memory check passedCheck: Swap space   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         6GB (6291452.0KB)         2.9462GB (3089356.0KB)    passed      node1         6GB (6291452.0KB)         2.9462GB (3089356.0KB)    passed    Result: Swap space check passedCheck: Free disk space for \"node2:/tmp\"   Path              Node Name     Mount point   Available     Required      Status        ----------------  ------------  ------------  ------------  ------------  ------------  /tmp              node2         /             88.7832GB     1GB           passed      Result: Free disk space check passed for \"node2:/tmp\"Check: Free disk space for \"node1:/tmp\"   Path              Node Name     Mount point   Available     Required      Status        ----------------  ------------  ------------  ------------  ------------  ------------  /tmp              node1         /             81.6679GB     1GB           passed      Result: Free disk space check passed for \"node1:/tmp\"Check: User existence for \"grid\"   Node Name     Status                    Comment                   ------------  ------------------------  ------------------------  node2         passed                    exists(1100)              node1         passed                    exists(1100)            Checking for multiple users with UID value 1100Result: Check for multiple users with UID value 1100 passed Result: User existence check passed for \"grid\"Check: Group existence for \"oinstall\"   Node Name     Status                    Comment                   ------------  ------------------------  ------------------------  node2         passed                    exists                    node1         passed                    exists                  Result: Group existence check passed for \"oinstall\"Check: Group existence for \"dba\"   Node Name     Status                    Comment                   ------------  ------------------------  ------------------------  node2         passed                    exists                    node1         passed                    exists                  Result: Group existence check passed for \"dba\"Check: Membership of user \"grid\" in group \"oinstall\" [as Primary]  Node Name         User Exists   Group Exists  User in Group  Primary       Status        ----------------  ------------  ------------  ------------  ------------  ------------  node2             yes           yes           yes           yes           passed        node1             yes           yes           yes           yes           passed      Result: Membership check for user \"grid\" in group \"oinstall\" [as Primary] passedCheck: Membership of user \"grid\" in group \"dba\"   Node Name         User Exists   Group Exists  User in Group  Status            ----------------  ------------  ------------  ------------  ----------------  node2             yes           yes           yes           passed            node1             yes           yes           yes           passed          Result: Membership check for user \"grid\" in group \"dba\" passedCheck: Run level   Node Name     run level                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         3                         3,5                       passed      node1         5                         3,5                       passed    Result: Run level check passedCheck: Hard limits for \"maximum open file descriptors\"   Node Name         Type          Available     Required      Status            ----------------  ------------  ------------  ------------  ----------------  node2             hard          65536         65536         passed            node1             hard          65536         65536         passed          Result: Hard limits check passed for \"maximum open file descriptors\"Check: Soft limits for \"maximum open file descriptors\"   Node Name         Type          Available     Required      Status            ----------------  ------------  ------------  ------------  ----------------  node2             soft          1024          1024          passed            node1             soft          1024          1024          passed          Result: Soft limits check passed for \"maximum open file descriptors\"Check: Hard limits for \"maximum user processes\"   Node Name         Type          Available     Required      Status            ----------------  ------------  ------------  ------------  ----------------  node2             hard          16384         16384         passed            node1             hard          16384         16384         passed          Result: Hard limits check passed for \"maximum user processes\"Check: Soft limits for \"maximum user processes\"   Node Name         Type          Available     Required      Status            ----------------  ------------  ------------  ------------  ----------------  node2             soft          2047          2047          passed            node1             soft          2047          2047          passed          Result: Soft limits check passed for \"maximum user processes\"Check: System architecture   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         x86_64                    x86_64                    passed      node1         x86_64                    x86_64                    passed    Result: System architecture check passedCheck: Kernel version   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         2.6.39-200.24.1.el6uek.x86_64  2.6.32                    passed      node1         2.6.39-200.24.1.el6uek.x86_64  2.6.32                    passed    Result: Kernel version check passedCheck: Kernel parameter for \"semmsl\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             250           250           250           passed            node1             250           250           250           passed          Result: Kernel parameter check passed for \"semmsl\"Check: Kernel parameter for \"semmns\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             32000         32000         32000         passed            node1             32000         32000         32000         passed          Result: Kernel parameter check passed for \"semmns\"Check: Kernel parameter for \"semopm\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             100           100           100           passed            node1             100           100           100           passed          Result: Kernel parameter check passed for \"semopm\"Check: Kernel parameter for \"semmni\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             128           128           128           passed            node1             128           128           128           passed          Result: Kernel parameter check passed for \"semmni\"Check: Kernel parameter for \"shmmax\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             4398046511104  4398046511104  1581750272    passed            node1             4398046511104  4398046511104  1581750272    passed          Result: Kernel parameter check passed for \"shmmax\"Check: Kernel parameter for \"shmmni\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             4096          4096          4096          passed            node1             4096          4096          4096          passed          Result: Kernel parameter check passed for \"shmmni\"Check: Kernel parameter for \"shmall\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             1073741824    1073741824    2097152       passed            node1             1073741824    1073741824    2097152       passed          Result: Kernel parameter check passed for \"shmall\"Check: Kernel parameter for \"file-max\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             6815744       6815744       6815744       passed            node1             6815744       6815744       6815744       passed          Result: Kernel parameter check passed for \"file-max\"Check: Kernel parameter for \"ip_local_port_range\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             between 9000.0 & 65500.0  between 9000.0 & 65500.0  between 9000.0 & 65500.0  passed            node1             between 9000.0 & 65500.0  between 9000.0 & 65500.0  between 9000.0 & 65500.0  passed          Result: Kernel parameter check passed for \"ip_local_port_range\"Check: Kernel parameter for \"rmem_default\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             262144        262144        262144        passed            node1             262144        262144        262144        passed          Result: Kernel parameter check passed for \"rmem_default\"Check: Kernel parameter for \"rmem_max\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             4194304       4194304       4194304       passed            node1             4194304       4194304       4194304       passed          Result: Kernel parameter check passed for \"rmem_max\"Check: Kernel parameter for \"wmem_default\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             262144        262144        262144        passed            node1             262144        262144        262144        passed          Result: Kernel parameter check passed for \"wmem_default\"Check: Kernel parameter for \"wmem_max\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             1048576       1048576       1048576       passed            node1             1048576       1048576       1048576       passed          Result: Kernel parameter check passed for \"wmem_max\"Check: Kernel parameter for \"aio-max-nr\"   Node Name         Current       Configured    Required      Status        Comment       ----------------  ------------  ------------  ------------  ------------  ------------  node2             1048576       1048576       1048576       passed            node1             1048576       1048576       1048576       passed          Result: Kernel parameter check passed for \"aio-max-nr\"Check: Package existence for \"binutils\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         binutils-2.20.51.0.2-5.34.el6  binutils-2.20.51.0.2      passed      node1         binutils-2.20.51.0.2-5.34.el6  binutils-2.20.51.0.2      passed    Result: Package existence check passed for \"binutils\"Check: Package existence for \"compat-libcap1\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         compat-libcap1-1.10-1     compat-libcap1-1.10       passed      node1         compat-libcap1-1.10-1     compat-libcap1-1.10       passed    Result: Package existence check passed for \"compat-libcap1\"Check: Package existence for \"compat-libstdc++-33(x86_64)\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         compat-libstdc++-33(x86_64)-3.2.3-69.el6  compat-libstdc++-33(x86_64)-3.2.3  passed      node1         compat-libstdc++-33(x86_64)-3.2.3-69.el6  compat-libstdc++-33(x86_64)-3.2.3  passed    Result: Package existence check passed for \"compat-libstdc++-33(x86_64)\"Check: Package existence for \"libgcc(x86_64)\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         libgcc(x86_64)-4.4.6-4.el6  libgcc(x86_64)-4.4.4      passed      node1         libgcc(x86_64)-4.4.6-4.el6  libgcc(x86_64)-4.4.4      passed    Result: Package existence check passed for \"libgcc(x86_64)\"Check: Package existence for \"libstdc++(x86_64)\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         libstdc++(x86_64)-4.4.6-4.el6  libstdc++(x86_64)-4.4.4   passed      node1         libstdc++(x86_64)-4.4.6-4.el6  libstdc++(x86_64)-4.4.4   passed    Result: Package existence check passed for \"libstdc++(x86_64)\"Check: Package existence for \"libstdc++-devel(x86_64)\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         libstdc++-devel(x86_64)-4.4.6-4.el6  libstdc++-devel(x86_64)-4.4.4  passed      node1         libstdc++-devel(x86_64)-4.4.6-4.el6  libstdc++-devel(x86_64)-4.4.4  passed    Result: Package existence check passed for \"libstdc++-devel(x86_64)\"Check: Package existence for \"sysstat\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         sysstat-9.0.4-20.el6      sysstat-9.0.4             passed      node1         sysstat-9.0.4-20.el6      sysstat-9.0.4             passed    Result: Package existence check passed for \"sysstat\"Check: Package existence for \"gcc\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         gcc-4.4.6-4.el6           gcc-4.4.4                 passed      node1         gcc-4.4.6-4.el6           gcc-4.4.4                 passed    Result: Package existence check passed for \"gcc\"Check: Package existence for \"gcc-c++\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         gcc-c++-4.4.6-4.el6       gcc-c++-4.4.4             passed      node1         gcc-c++-4.4.6-4.el6       gcc-c++-4.4.4             passed    Result: Package existence check passed for \"gcc-c++\"Check: Package existence for \"ksh\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         ksh-20100621-16.el6       ksh-20100621              passed      node1         ksh-20100621-16.el6       ksh-20100621              passed    Result: Package existence check passed for \"ksh\"Check: Package existence for \"make\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         make-3.81-20.el6          make-3.81                 passed      node1         make-3.81-20.el6          make-3.81                 passed    Result: Package existence check passed for \"make\"Check: Package existence for \"glibc(x86_64)\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         glibc(x86_64)-2.12-1.80.el6_3.6  glibc(x86_64)-2.12        passed      node1         glibc(x86_64)-2.12-1.80.el6_3.6  glibc(x86_64)-2.12        passed    Result: Package existence check passed for \"glibc(x86_64)\"Check: Package existence for \"glibc-devel(x86_64)\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         glibc-devel(x86_64)-2.12-1.80.el6_3.6  glibc-devel(x86_64)-2.12  passed      node1         glibc-devel(x86_64)-2.12-1.80.el6_3.6  glibc-devel(x86_64)-2.12  passed    Result: Package existence check passed for \"glibc-devel(x86_64)\"Check: Package existence for \"libaio(x86_64)\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         libaio(x86_64)-0.3.107-10.el6  libaio(x86_64)-0.3.107    passed      node1         libaio(x86_64)-0.3.107-10.el6  libaio(x86_64)-0.3.107    passed    Result: Package existence check passed for \"libaio(x86_64)\"Check: Package existence for \"libaio-devel(x86_64)\"   Node Name     Available                 Required                  Status      ------------  ------------------------  ------------------------  ----------  node2         libaio-devel(x86_64)-0.3.107-10.el6  libaio-devel(x86_64)-0.3.107  passed      node1         libaio-devel(x86_64)-0.3.107-10.el6  libaio-devel(x86_64)-0.3.107  passed    Result: Package existence check passed for \"libaio-devel(x86_64)\"Checking for multiple users with UID value 0Result: Check for multiple users with UID value 0 passed Check: Current group ID Result: Current group ID check passedStarting check for consistency of primary group of root user  Node Name                             Status                    ------------------------------------  ------------------------  node2                                 passed                    node1                                 passed                  Check for consistency of root user's primary group passedStarting Clock synchronization checks using Network Time Protocol(NTP)...NTP Configuration file check started...Network Time Protocol(NTP) configuration file not found on any of the nodes. Oracle Cluster Time Synchronization Service(CTSS) can be used instead of NTP for time synchronization on the cluster nodesNo NTP Daemons or Services were found to be runningResult: Clock synchronization check using Network Time Protocol(NTP) passedChecking Core file name pattern consistency...Core file name pattern consistency check passed.Checking to make sure user \"grid\" is not in \"root\" group  Node Name     Status                    Comment                   ------------  ------------------------  ------------------------  node2         passed                    does not exist            node1         passed                    does not exist          Result: User \"grid\" is not part of \"root\" group. Check passedCheck default user file creation mask  Node Name     Available                 Required                  Comment     ------------  ------------------------  ------------------------  ----------  node2         0022                      0022                      passed      node1         0022                      0022                      passed    Result: Default user file creation mask check passedChecking consistency of file \"/etc/resolv.conf\" across nodesChecking the file \"/etc/resolv.conf\" to make sure only one of domain and search entries is definedFile \"/etc/resolv.conf\" does not have both domain and search entries definedChecking if domain entry in file \"/etc/resolv.conf\" is consistent across the nodes...domain entry in file \"/etc/resolv.conf\" is consistent across nodesChecking if search entry in file \"/etc/resolv.conf\" is consistent across the nodes...search entry in file \"/etc/resolv.conf\" is consistent across nodesChecking file \"/etc/resolv.conf\" to make sure that only one search entry is definedAll nodes have one search entry defined in file \"/etc/resolv.conf\"Checking all nodes to make sure that search entry is \"localdomain\" as found on node \"node2\"All nodes of the cluster have same value for 'search'Checking DNS response time for an unreachable node  Node Name                             Status                    ------------------------------------  ------------------------  node2                                 passed                    node1                                 passed                  The DNS response time for an unreachable node is within acceptable limit on all nodesFile \"/etc/resolv.conf\" is consistent across nodesCheck: Time zone consistency Result: Time zone consistency check passedPre-check for cluster services setup was successful. 在node1上使用grid用户安装grid infrastructure [grid@node1 grid]$ ./runInstaller Starting Oracle Universal Installer...Checking Temp space: must be greater than 120 MB.   Actual 79780 MB    PassedChecking swap space: must be greater than 150 MB.   Actual 6143 MB    PassedChecking monitor: must be configured to display at least 256 colors.    Actual 16777216    PassedPreparing to launch Oracle Universal Installer from /tmp/OraInstall2012-12-29_09-28-08AM. Please wait ...[grid@node1 grid]$ Skip software updates Install any Configure Oracle Grid Infrastructure for a Cluster Advanced Installation add Simplified Chinese 不配置GNS,填写scan名称 add node2 如果之前没有配置ssh用户等效,也可以在这里配置 Validating remote binaries.. Remote binaries check succeeded 指定用于Public网络和Private网络的网络接口。进行所需更改以与下表中各值保持一致 配置ASM存储 +CRS  Use same passwords for these accounts 这里警告密码过于简单 Do not use Intelligent Platform Management Interface (IPMI) ASM使用的是UDEV绑定设备,没有使用asmlib,忽略这个警告 Install 使用root用户在node1,node2上执行以下脚本,这里使用 one by one方式 node1 [root@node1 ~]# /u01/app/oraInventory/orainstRoot.shChanging permissions of /u01/app/oraInventory.Adding read,write permissions for group.Removing read,write,execute permissions for world.Changing groupname of /u01/app/oraInventory to oinstall.The execution of the script is complete.[root@node1 ~]# /u01/app/11.2.0/grid/root.shPerforming root user operation for Oracle 11g The following environment variables are set as:    ORACLE_OWNER= grid    ORACLE_HOME=  /u01/app/11.2.0/gridEnter the full pathname of the local bin directory: [/usr/local/bin]:    Copying dbhome to /usr/local/bin ...   Copying oraenv to /usr/local/bin ...   Copying coraenv to /usr/local/bin ...Creating /etc/oratab file...Entries will be added to the /etc/oratab file as needed byDatabase Configuration Assistant when a database is createdFinished running generic part of root script.Now product-specific root actions will be performed.Using configuration parameter file: /u01/app/11.2.0/grid/crs/install/crsconfig_paramsCreating trace directoryUser ignored Prerequisites during installationOLR initialization - successful  root wallet  root wallet cert  root cert export  peer wallet  profile reader wallet  pa wallet  peer wallet keys  pa wallet keys  peer cert request  pa cert request  peer cert  pa cert  peer root cert TP  profile reader root cert TP  pa root cert TP  peer pa cert TP  pa peer cert TP  profile reader pa cert TP  profile reader peer cert TP  peer user cert  pa user certAdding Clusterware entries to upstartCRS-2672: Attempting to start 'ora.mdnsd' on 'node1'CRS-2676: Start of 'ora.mdnsd' on 'node1' succeededCRS-2672: Attempting to start 'ora.gpnpd' on 'node1'CRS-2676: Start of 'ora.gpnpd' on 'node1' succeededCRS-2672: Attempting to start 'ora.cssdmonitor' on 'node1'CRS-2672: Attempting to start 'ora.gipcd' on 'node1'CRS-2676: Start of 'ora.cssdmonitor' on 'node1' succeededCRS-2676: Start of 'ora.gipcd' on 'node1' succeededCRS-2672: Attempting to start 'ora.cssd' on 'node1'CRS-2672: Attempting to start 'ora.diskmon' on 'node1'CRS-2676: Start of 'ora.diskmon' on 'node1' succeededCRS-2676: Start of 'ora.cssd' on 'node1' succeededASM created and started successfully.Disk Group CRS created successfully.clscfg: -install mode specifiedSuccessfully accumulated necessary OCR keys.Creating OCR keys for user 'root', privgrp 'root'..Operation successful.CRS-4256: Updating the profileSuccessful addition of voting disk 4b4ef03676d84facbf55c02b8c058a07.Successfully replaced voting disk group with +CRS.CRS-4256: Updating the profileCRS-4266: Voting file(s) successfully replaced##  STATE    File Universal Id                File Name Disk group--  -----    -----------------                --------- --------- 1. ONLINE   4b4ef03676d84facbf55c02b8c058a07 (/dev/asm-diskb) [CRS]Located 1 voting disk(s).CRS-2672: Attempting to start 'ora.asm' on 'node1'CRS-2676: Start of 'ora.asm' on 'node1' succeededCRS-2672: Attempting to start 'ora.CRS.dg' on 'node1'CRS-2676: Start of 'ora.CRS.dg' on 'node1' succeededConfigure Oracle Grid Infrastructure for a Cluster ... succeeded[root@node1 ~]# node2 [root@node2 ~]# /u01/app/oraInventory/orainstRoot.shChanging permissions of /u01/app/oraInventory.Adding read,write permissions for group.Removing read,write,execute permissions for world.Changing groupname of /u01/app/oraInventory to oinstall.The execution of the script is complete.[root@node2 ~]# /u01/app/11.2.0/grid/root.shPerforming root user operation for Oracle 11g The following environment variables are set as:    ORACLE_OWNER= grid    ORACLE_HOME=  /u01/app/11.2.0/gridEnter the full pathname of the local bin directory: [/usr/local/bin]:    Copying dbhome to /usr/local/bin ...   Copying oraenv to /usr/local/bin ...   Copying coraenv to /usr/local/bin ...Creating /etc/oratab file...Entries will be added to the /etc/oratab file as needed byDatabase Configuration Assistant when a database is createdFinished running generic part of root script.Now product-specific root actions will be performed.Using configuration parameter file: /u01/app/11.2.0/grid/crs/install/crsconfig_paramsCreating trace directoryUser ignored Prerequisites during installationOLR initialization - successfulAdding Clusterware entries to upstartCRS-4402: The CSS daemon was started in exclusive mode but found an active CSS daemon on node node1, number 1, and is terminatingAn active cluster was found during exclusive startup, restarting to join the clusterConfigure Oracle Grid Infrastructure for a Cluster ... succeeded[root@node2 ~]# 安装程序将运行 Oracle 网络服务 (NETCA)、自动存储管理 (ASMCA) 和 Oracle 专用互连 (VIPCA) 的配置助手。OUI 执行的最后一步是运行集群验证实用程序 (CVU)。如果配置助手和 CVU 运行成功，可单击 [Next] 然后单击 [Close] 退出 OUI。如果 CVU 只报告了此错误，可放心忽略此检查并继续。 close 测试GI的安装 node1 [root@node1 ~]# ifconfigeth0      Link encap:Ethernet  HWaddr 00:0C:29:79:33:95            inet addr:192.168.1.51  Bcast:192.168.255.255  Mask:255.255.0.0          inet6 addr: fe80::20c:29ff:fe79:3395/64 Scope:Link          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1          RX packets:977978 errors:0 dropped:1345 overruns:0 frame:0          TX packets:2525875 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:1000           RX bytes:106995897 (102.0 MiB)  TX bytes:3573509233 (3.3 GiB)eth0:1    Link encap:Ethernet  HWaddr 00:0C:29:79:33:95            inet addr:192.168.1.151  Bcast:192.168.255.255  Mask:255.255.0.0          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1eth0:3    Link encap:Ethernet  HWaddr 00:0C:29:79:33:95            inet addr:192.168.1.58  Bcast:192.168.255.255  Mask:255.255.0.0          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1eth0:4    Link encap:Ethernet  HWaddr 00:0C:29:79:33:95            inet addr:192.168.1.59  Bcast:192.168.255.255  Mask:255.255.0.0          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1eth1      Link encap:Ethernet  HWaddr 00:0C:29:79:33:9F            inet addr:172.168.1.51  Bcast:172.168.255.255  Mask:255.255.0.0          inet6 addr: fe80::20c:29ff:fe79:339f/64 Scope:Link          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1          RX packets:728960 errors:0 dropped:1345 overruns:0 frame:0          TX packets:13833 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:1000           RX bytes:54104908 (51.5 MiB)  TX bytes:7561084 (7.2 MiB)eth1:1    Link encap:Ethernet  HWaddr 00:0C:29:79:33:9F            inet addr:169.254.201.146  Bcast:169.254.255.255  Mask:255.255.0.0          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1lo        Link encap:Local Loopback            inet addr:127.0.0.1  Mask:255.0.0.0          inet6 addr: ::1/128 Scope:Host          UP LOOPBACK RUNNING  MTU:16436  Metric:1          RX packets:13162 errors:0 dropped:0 overruns:0 frame:0          TX packets:13162 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:0           RX bytes:7783412 (7.4 MiB)  TX bytes:7783412 (7.4 MiB)[root@node1 ~]# ps -ef|egrep -i \"asm|listener\"grid     24390     1  0 10:03 ?        00:00:00 asm_pmon_+ASM1grid     24392     1  0 10:03 ?        00:00:00 asm_psp0_+ASM1grid     24394     1  1 10:03 ?        00:00:18 asm_vktm_+ASM1grid     24398     1  0 10:03 ?        00:00:00 asm_gen0_+ASM1grid     24400     1  0 10:03 ?        00:00:00 asm_diag_+ASM1grid     24402     1  0 10:03 ?        00:00:00 asm_ping_+ASM1grid     24404     1  0 10:03 ?        00:00:02 asm_dia0_+ASM1grid     24406     1  0 10:03 ?        00:00:02 asm_lmon_+ASM1grid     24408     1  0 10:03 ?        00:00:01 asm_lmd0_+ASM1grid     24410     1  0 10:03 ?        00:00:02 asm_lms0_+ASM1grid     24414     1  0 10:03 ?        00:00:00 asm_lmhb_+ASM1grid     24416     1  0 10:03 ?        00:00:00 asm_mman_+ASM1grid     24418     1  0 10:03 ?        00:00:00 asm_dbw0_+ASM1grid     24420     1  0 10:03 ?        00:00:00 asm_lgwr_+ASM1grid     24422     1  0 10:03 ?        00:00:00 asm_ckpt_+ASM1grid     24424     1  0 10:03 ?        00:00:00 asm_smon_+ASM1grid     24426     1  0 10:03 ?        00:00:00 asm_rbal_+ASM1grid     24428     1  0 10:03 ?        00:00:00 asm_gmon_+ASM1grid     24430     1  0 10:03 ?        00:00:00 asm_mmon_+ASM1grid     24432     1  0 10:03 ?        00:00:00 asm_mmnl_+ASM1grid     24434     1  0 10:03 ?        00:00:00 asm_lck0_+ASM1grid     24436     1  0 10:03 ?        00:00:00 oracle+ASM1 (DESCRIPTION=(LOCAL=YES)(ADDRESS=(PROTOCOL=beq)))grid     24466     1  0 10:03 ?        00:00:01 oracle+ASM1_ocr (DESCRIPTION=(LOCAL=YES)(ADDRESS=(PROTOCOL=beq)))grid     24471     1  0 10:03 ?        00:00:00 asm_asmb_+ASM1grid     24473     1  0 10:03 ?        00:00:00 oracle+ASM1_asmb_+asm1 (DESCRIPTION=(LOCAL=YES)(ADDRESS=(PROTOCOL=beq)))grid     24876     1  0 10:04 ?        00:00:00 oracle+ASM1 (DESCRIPTION=(LOCAL=YES)(ADDRESS=(PROTOCOL=beq)))grid     25269     1  0 10:05 ?        00:00:00 /u01/app/11.2.0/grid/bin/tnslsnr LISTENER_SCAN2 -inheritgrid     25283     1  0 10:05 ?        00:00:00 /u01/app/11.2.0/grid/bin/tnslsnr LISTENER_SCAN3 -inheritgrid     26105     1  0 10:15 ?        00:00:00 /u01/app/11.2.0/grid/bin/tnslsnr LISTENER -inheritgrid     28183 28182  0 10:21 ?        00:00:00 oracle+ASM1 (DESCRIPTION=(LOCAL=YES)(ADDRESS=(PROTOCOL=beq)))root     28263  2146  0 10:26 pts/2    00:00:00 egrep -i asm|listener node2 [root@node2 ~]# ifconfigeth0      Link encap:Ethernet  HWaddr 00:0C:29:5C:FC:76            inet addr:192.168.1.52  Bcast:192.168.255.255  Mask:255.255.0.0          inet6 addr: fe80::20c:29ff:fe5c:fc76/64 Scope:Link          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1          RX packets:3068626 errors:0 dropped:1348 overruns:0 frame:0          TX packets:185731 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:1000           RX bytes:3505670277 (3.2 GiB)  TX bytes:39520990 (37.6 MiB)eth0:1    Link encap:Ethernet  HWaddr 00:0C:29:5C:FC:76            inet addr:192.168.1.57  Bcast:192.168.255.255  Mask:255.255.0.0          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1eth0:2    Link encap:Ethernet  HWaddr 00:0C:29:5C:FC:76            inet addr:192.168.1.152  Bcast:192.168.255.255  Mask:255.255.0.0          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1eth1      Link encap:Ethernet  HWaddr 00:0C:29:5C:FC:80            inet addr:172.168.1.52  Bcast:172.168.255.255  Mask:255.255.0.0          inet6 addr: fe80::20c:29ff:fe5c:fc80/64 Scope:Link          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1          RX packets:729233 errors:0 dropped:1348 overruns:0 frame:0          TX packets:15630 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:1000           RX bytes:53620798 (51.1 MiB)  TX bytes:8883597 (8.4 MiB)eth1:1    Link encap:Ethernet  HWaddr 00:0C:29:5C:FC:80            inet addr:169.254.30.23  Bcast:169.254.255.255  Mask:255.255.0.0          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1lo        Link encap:Local Loopback            inet addr:127.0.0.1  Mask:255.0.0.0          inet6 addr: ::1/128 Scope:Host          UP LOOPBACK RUNNING  MTU:16436  Metric:1          RX packets:6049 errors:0 dropped:0 overruns:0 frame:0          TX packets:6049 errors:0 dropped:0 overruns:0 carrier:0          collisions:0 txqueuelen:0           RX bytes:2377782 (2.2 MiB)  TX bytes:2377782 (2.2 MiB)[root@node2 ~]# ps -ef|egrep -i \"asm|listener\"grid     21049     1  0 10:09 ?        00:00:00 asm_pmon_+ASM2grid     21051     1  0 10:09 ?        00:00:00 asm_psp0_+ASM2grid     21053     1  1 10:09 ?        00:00:14 asm_vktm_+ASM2grid     21057     1  0 10:09 ?        00:00:00 asm_gen0_+ASM2grid     21059     1  0 10:09 ?        00:00:00 asm_diag_+ASM2grid     21061     1  0 10:09 ?        00:00:00 asm_ping_+ASM2grid     21063     1  0 10:09 ?        00:00:01 asm_dia0_+ASM2grid     21065     1  0 10:09 ?        00:00:01 asm_lmon_+ASM2grid     21067     1  0 10:09 ?        00:00:00 asm_lmd0_+ASM2grid     21069     1  0 10:09 ?        00:00:02 asm_lms0_+ASM2grid     21073     1  0 10:09 ?        00:00:00 asm_lmhb_+ASM2grid     21075     1  0 10:09 ?        00:00:00 asm_mman_+ASM2grid     21077     1  0 10:09 ?        00:00:00 asm_dbw0_+ASM2grid     21079     1  0 10:09 ?        00:00:00 asm_lgwr_+ASM2grid     21081     1  0 10:09 ?        00:00:00 asm_ckpt_+ASM2grid     21083     1  0 10:09 ?        00:00:00 asm_smon_+ASM2grid     21085     1  0 10:09 ?        00:00:00 asm_rbal_+ASM2grid     21087     1  0 10:09 ?        00:00:00 asm_gmon_+ASM2grid     21089     1  0 10:09 ?        00:00:00 asm_mmon_+ASM2grid     21091     1  0 10:09 ?        00:00:00 asm_mmnl_+ASM2grid     21093     1  0 10:09 ?        00:00:00 asm_lck0_+ASM2grid     21095     1  0 10:09 ?        00:00:00 oracle+ASM2 (DESCRIPTION=(LOCAL=YES)(ADDRESS=(PROTOCOL=beq)))grid     21128     1  0 10:09 ?        00:00:00 oracle+ASM2_ocr (DESCRIPTION=(LOCAL=YES)(ADDRESS=(PROTOCOL=beq)))grid     21130     1  0 10:09 ?        00:00:00 asm_asmb_+ASM2grid     21132     1  0 10:09 ?        00:00:00 oracle+ASM2_asmb_+asm2 (DESCRIPTION=(LOCAL=YES)(ADDRESS=(PROTOCOL=beq)))grid     21271     1  0 10:09 ?        00:00:00 oracle+ASM2 (DESCRIPTION=(LOCAL=YES)(ADDRESS=(PROTOCOL=beq)))grid     21326     1  0 10:09 ?        00:00:00 /u01/app/11.2.0/grid/bin/tnslsnr LISTENER_SCAN1 -inheritgrid     22068     1  0 10:15 ?        00:00:00 /u01/app/11.2.0/grid/bin/tnslsnr LISTENER -inheritroot     23551  1979  0 10:26 pts/2    00:00:00 egrep -i asm|listener 检查 CRS 状态 [grid@node2 ~]$ crsctl check crsCRS-4638: Oracle High Availability Services is onlineCRS-4537: Cluster Ready Services is onlineCRS-4529: Cluster Synchronization Services is onlineCRS-4533: Event Manager is online 检查 Clusterware 资源 ,crs_stat命令在11gR2中不再推荐使用,推荐使用crsctl stat res -t [grid@node2 ~]$ crs_stat -tName           Type           Target    State     Host        ------------------------------------------------------------ora.CRS.dg     ora....up.type ONLINE    ONLINE    node1       ora....ER.lsnr ora....er.type ONLINE    ONLINE    node1       ora....N1.lsnr ora....er.type ONLINE    ONLINE    node2       ora....N2.lsnr ora....er.type ONLINE    ONLINE    node1       ora....N3.lsnr ora....er.type ONLINE    ONLINE    node1       ora.asm        ora.asm.type   ONLINE    ONLINE    node1       ora.cvu        ora.cvu.type   ONLINE    ONLINE    node1       ora.gsd        ora.gsd.type   OFFLINE   OFFLINE               ora....network ora....rk.type ONLINE    ONLINE    node1       ora....SM1.asm application    ONLINE    ONLINE    node1       ora....E1.lsnr application    ONLINE    ONLINE    node1       ora.node1.gsd  application    OFFLINE   OFFLINE               ora.node1.ons  application    ONLINE    ONLINE    node1       ora.node1.vip  ora....t1.type ONLINE    ONLINE    node1       ora....SM2.asm application    ONLINE    ONLINE    node2       ora....E2.lsnr application    ONLINE    ONLINE    node2       ora.node2.gsd  application    OFFLINE   OFFLINE               ora.node2.ons  application    ONLINE    ONLINE    node2       ora.node2.vip  ora....t1.type ONLINE    ONLINE    node2       ora.oc4j       ora.oc4j.type  ONLINE    ONLINE    node1       ora.ons        ora.ons.type   ONLINE    ONLINE    node1       ora.scan1.vip  ora....ip.type ONLINE    ONLINE    node2       ora.scan2.vip  ora....ip.type ONLINE    ONLINE    node1       ora.scan3.vip  ora....ip.type ONLINE    ONLINE    node1 [grid@node2 ~]$ crsctl stat res -t--------------------------------------------------------------------------------NAME           TARGET  STATE        SERVER                   STATE_DETAILS       --------------------------------------------------------------------------------Local Resources--------------------------------------------------------------------------------ora.CRS.dg               ONLINE  ONLINE       node1                                                       ONLINE  ONLINE       node2                                        ora.LISTENER.lsnr               ONLINE  ONLINE       node1                                                       ONLINE  ONLINE       node2                                        ora.asm               ONLINE  ONLINE       node1                    Started                            ONLINE  ONLINE       node2                    Started             ora.gsd               OFFLINE OFFLINE      node1                                                       OFFLINE OFFLINE      node2                                        ora.net1.network               ONLINE  ONLINE       node1                                                       ONLINE  ONLINE       node2                                        ora.ons               ONLINE  ONLINE       node1                                                       ONLINE  ONLINE       node2                                        --------------------------------------------------------------------------------Cluster Resources--------------------------------------------------------------------------------ora.LISTENER_SCAN1.lsnr      1        ONLINE  ONLINE       node2                                        ora.LISTENER_SCAN2.lsnr      1        ONLINE  ONLINE       node1                                        ora.LISTENER_SCAN3.lsnr      1        ONLINE  ONLINE       node1                                        ora.cvu      1        ONLINE  ONLINE       node1                                        ora.node1.vip      1        ONLINE  ONLINE       node1                                        ora.node2.vip      1        ONLINE  ONLINE       node2                                        ora.oc4j      1        ONLINE  ONLINE       node1                                        ora.scan1.vip      1        ONLINE  ONLINE       node2                                        ora.scan2.vip      1        ONLINE  ONLINE       node1                                        ora.scan3.vip      1        ONLINE  ONLINE       node1                      检查集群节点 [grid@node2 ~]$ olsnodes -n node1\t1node2\t2 检测CRS版本 [grid@node2 ~]$ crsctl query crs activeversionOracle Clusterware active version on the cluster is [11.2.0.3.0] 检查 Oracle 集群注册表 (OCR) [grid@node2 ~]$ ocrcheckStatus of Oracle Cluster Registry is as follows :\t Version                  :          3\t Total space (kbytes)     :     262120\t Used space (kbytes)      :       2588\t Available space (kbytes) :     259532\t ID                       : 1606856820\t Device/File Name         :       +CRS                                    Device/File integrity check succeeded                                    Device/File not configured                                    Device/File not configured                                    Device/File not configured                                    Device/File not configured\t Cluster registry integrity check succeeded\t Logical corruption check bypassed due to non-privileged user 检查votedisk [grid@node2 ~]$ crsctl query css votedisk##  STATE    File Universal Id                File Name Disk group--  -----    -----------------                --------- --------- 1. ONLINE   4b4ef03676d84facbf55c02b8c058a07 (/dev/asm-diskc) [CRS]Located 1 voting disk(s). 检查asm [grid@node2 ~]$ srvctl config asm -a ASM home: /u01/app/11.2.0/gridASM listener: LISTENERASM is enabled.[grid@node2 ~]$ srvctl status asm ASM is running on node2,node1 [grid@node2 ~]$ uname -px86_64[grid@node2 ~]$ sqlplus / as sysdbaSQL*Plus: Release 11.2.0.3.0 Production on Sat Dec 29 10:45:13 2012Copyright (c) 1982, 2011, Oracle.  All rights reserved.Connected to:Oracle Database 11g Enterprise Edition Release 11.2.0.3.0 - 64bit ProductionWith the Real Application Clusters and Automatic Storage Management optionsSQL> set linesize 100SQL> show parameter spfileNAME\t\t\t\t     TYPE\t\t    VALUE------------------------------------ ---------------------- ------------------------------spfile\t\t\t\t     string\t\t    +CRS/cluster-scan/asmparameter\t\t\t\t\t\t\t    file/registry.253.803296901SQL> select path from v$asm_disk;PATH----------------------------------------------------------------------------------------------------/dev/asm-diskg/dev/asm-diskf/dev/asm-diske/dev/asm-diskb/dev/asm-diskc/dev/asm-diskd6 rows selected. 至此GI安装完毕","title":"使用UDEV在Oracle Linux 6上安装Oracle 11g RAC(11.2.0.3) (四)"},{"content":"在我们迁移数据，或者进行同步数据的时候,对于应用变更频繁的表进行抽取数据，经常会碰到oracle需要读取回滚段，会导致很慢，有时候甚至会报ora01555错误， 比如我们有个表比较大是40G左右，就是一个月的按月分区数据，这个时候如果想尽快抽取数据到另外一个库，有几种方法： 方法1：      大家都知道的使用append，然后不写日志，parallel抽取方式: 代码类似如下: alter session enable parallel DML;ALTER SESSION SET db_file_multiblock_read_count=128;INSERT /*+append parallel(b 2)*/INTO OS_USER_SERVICE_HIS_1 b  SELECT /*+FULL(a) PARALLEL(A,2)*/   * FROM OS_USER_SERVICE_HIS A   WHERE CREATETIME >= TO_DATE('20110906', 'yyyymmdd'); 方法2：        开4个会话: 通过createtime逻辑上进行4个时间区间的并行处理：比如一个月的话，分成1会话处理第一周，然后一直到4会话处理第4周 ，当然你也可以再细分：1会话写循环一小时一小时处理。 方法3：       使用rowid并行： 这里我重要说下使用rowid并行的方法: 真实案例: create table ROWID_OS_USER_BEHAVIOR_201212(  ID        NUMBER,  ROWID_MIN VARCHAR2(32),  ROWID_MAX VARCHAR2(32),  FLAG      NUMBER); 首先创建rowid保存表: 获取远程库的data_object_id: SQL> select data_object_id from Dba_objects@mail139.localdomain where object_name='OS_USER_BEHAVIOR_MONTH'  and subobject_name='OS_USER_BEHAVIOR_MONTH2012M12'  2  ; DATA_OBJECT_ID--------------        218043 --获取远程库的最小，最大rowid: SQL> insert into rowid_os_user_behavior_201212(id,rowid_min,rowid_max,FLAG)  2    select rownum,  3          DBMS_ROWID.ROWID_CREATE@mail139.localdomain(1,218043,e.RELATIVE_FNO,e.BLOCK_ID,0),  4          DBMS_ROWID.ROWID_CREATE@mail139.localdomain(1,218043,e.RELATIVE_FNO,e.BLOCK_ID+e.BLOCKS-1,10000),  5          0  6          from dba_extents@mail139.localdomain e where e.segment_name='OS_USER_BEHAVIOR_MONTH'  7                                                      and e.owner='OSS01'  8                                                      and partition_name='OS_USER_BEHAVIOR_MONTH2012M12'  9  ; 659 rows inserted;commit; --将远程这个分区对应的extents范围的rowid放入表中: 插入完之后，查询结果如下: SQL> select * from rowid_os_user_behavior_201212 where flag =0 and rownum =1;           ID ROWID_MIN                        ROWID_MAX                              FLAG ---------- -------------------------------- -------------------------------- ----------        422 AAA1O7AAxAADDgJAAA               AAA1O7AAxAADFgICcQ                        0 编写拉数据存储过程:  如下: create or replace procedure p_ods_os_user_beha_month(i integer) is  vSTATEDATE         dbms_sql.NUMBER_Table;  vUSERNUMBER        dbms_sql.VARCHAR2_Table;  vSERVICEID         dbms_sql.NUMBER_Table;  vOPERTYPE          dbms_sql.NUMBER_Table;  vRECVCOUNT         dbms_sql.NUMBER_Table;  vSENDCOUNT         dbms_sql.NUMBER_Table;  vTOTALCOUNT        dbms_sql.NUMBER_Table;  vPRESENDCOUNT      dbms_sql.NUMBER_Table;  vENTERPRISEFLAG    dbms_sql.NUMBER_Table;  vENTERPRISESHEETNO dbms_sql.VARCHAR2_Table;  vCREATETIME        dbms_sql.DATE_Table;  vMODIFYTIME        dbms_sql.DATE_Table;  vPROVCODE          dbms_sql.NUMBER_Table;  vSERVICEITEM       dbms_sql.VARCHAR2_Table;  vCARDTYPE          dbms_sql.NUMBER_Table;  vAREACODE          dbms_sql.NUMBER_Table;  vBINDTYPEID        dbms_sql.NUMBER_Table;  vORDERTYPE         dbms_sql.NUMBER_Table;  vMAILSERVICEITEM   dbms_sql.VARCHAR2_Table;/*  vCounter           number := 1;*/  vCounter_out       number := 0;  cur_syncdata       sys_refcursor;begin  for x in (select *              from rowid_OS_USER_BEHAVIOR_201212             where mod(id, 4) = i  ---这里就是变量i;               and flag = 0) loop    begin      open cur_syncdata for        select /*+rowid(t))*/         STATEDATE,         USERNUMBER,         SERVICEID,         OPERTYPE,         RECVCOUNT,         SENDCOUNT,         TOTALCOUNT,         PRESENDCOUNT,         ENTERPRISEFLAG,         ENTERPRISESHEETNO,         CREATETIME,         MODIFYTIME,         PROVCODE,         SERVICEITEM,         CARDTYPE,         AREACODE,         BINDTYPEID,         ORDERTYPE,         MAILSERVICEITEM          from yefz.vw_os_user_behavior_mon1212@mail139.localdomain t         where rowid >= chartorowid(x.rowid_min)           and rowid <= chartorowid(x.rowid_max);      loop        begin          fetch cur_syncdata bulk collect            into vSTATEDATE, vUSERNUMBER, vSERVICEID, vOPERTYPE, vRECVCOUNT, vSENDCOUNT, vTOTALCOUNT, vPRESENDCOUNT, vENTERPRISEFLAG, vENTERPRISESHEETNO, vCREATETIME, vMODIFYTIME, vPROVCODE, vSERVICEITEM, vCARDTYPE, vAREACODE, vBINDTYPEID, vORDERTYPE, vMAILSERVICEITEM limit 5000;          forall row in 1 .. vUSERNUMBER.count()            insert into OS_USER_BEHAVIOR_MONTH_201212              (STATEDATE,               USERNUMBER,               SERVICEID,               OPERTYPE,               RECVCOUNT,               SENDCOUNT,               TOTALCOUNT,               PRESENDCOUNT,               ENTERPRISEFLAG,               ENTERPRISESHEETNO,               CREATETIME,               MODIFYTIME,               PROVCODE,               SERVICEITEM,               CARDTYPE,               AREACODE,               BINDTYPEID,               ORDERTYPE,               MAILSERVICEITEM)            values              (vSTATEDATE(row),               vUSERNUMBER(row),               vSERVICEID(row),               vOPERTYPE(row),               vRECVCOUNT(row),               vSENDCOUNT(row),               vTOTALCOUNT(row),               vPRESENDCOUNT(row),               vENTERPRISEFLAG(row),               vENTERPRISESHEETNO(row),               vCREATETIME(row),               vMODIFYTIME(row),               vPROVCODE(row),               vSERVICEITEM(row),               vCARDTYPE(row),               vAREACODE(row),               vBINDTYPEID(row),               vORDERTYPE(row),               vMAILSERVICEITEM(row));          vCounter_out := vCounter_out + sql%rowcount;          commit;          /*   if vCounter = 1000 then            begin              dbms_lock.sleep(3);              vCounter := 0;            end;          end if;*/          exit when cur_syncdata%notfound;        exception          when others then            dbms_output.put_line(sqlerrm);            rollback;            return;        end;      end loop;    end;    --更新处理的标记位：    update rowid_OS_USER_BEHAVIOR_201212 set flag = 1 where id = x.id;    commit;  end loop;  dbms_output.put_line('共处理' || vCounter_out || '条记录!');end; 然后开4个会话，分别传入0,1,2,3即可: 30G的数据，经过测试并行4个进程，大概40分钟可以拉完，这里的应用在于拉的数据是经常需要dml的数据，优势比较明显。    ","title":"通过rowid逻辑并行抽取数据"},{"content":"使用UDEV在Oracle Linux 6上安装Oracle 11g RAC(11.2.0.3) (一) 使用UDEV在Oracle Linux 6上安装Oracle 11g RAC(11.2.0.3) (二) 使用UDEV在Oracle Linux 6上安装Oracle 11g RAC(11.2.0.3) (三) 使用UDEV在Oracle Linux 6上安装Oracle 11g RAC(11.2.0.3) (四) 使用grid用户执行asmca,创建名为DATADG和FRADG的ASM磁盘组 create Exit 使用oracle用户在 Oracle Real Application Clusters 中安装 Oracle Database software 解压 p10404530_112030_Linux-x86-64_1of7.zip p10404530_112030_Linux-x86-64_2of7.zip [oracle@node1 database]$ ./runInstaller Starting Oracle Universal Installer...Checking Temp space: must be greater than 120 MB.   Actual 76592 MB    PassedChecking swap space: must be greater than 150 MB.   Actual 6134 MB    PassedChecking monitor: must be configured to display at least 256 colors.    Actual 16777216    PassedPreparing to launch Oracle Universal Installer from /tmp/OraInstall2012-12-29_11-05-25AM. Please wait ...[oracle@node1 database]$ Sikp Software Updates Install database software only Real Application Clusters database installation 如果之前没有配置oracle用户的ssh等效性,可以在这里配置,具体过程请看GI安装过程,这里不再演示 add Simplified Chinese Enterprises Edition 忽略DNS错误 install ssh node2 使用root用户在node1,node2上执行root.sh Exit 在任意node使用dbca创建集群化数据库 选择 Oracle Real Application Clusters database 验证集群化数据库已开启 [grid@node1 ~]$ crsctl stat res -t--------------------------------------------------------------------------------NAME           TARGET  STATE        SERVER                   STATE_DETAILS       --------------------------------------------------------------------------------Local Resources--------------------------------------------------------------------------------ora.CRS.dg               ONLINE  ONLINE       node1                                                       ONLINE  ONLINE       node2                                        ora.DATADG.dg               ONLINE  ONLINE       node1                                                       ONLINE  ONLINE       node2                                        ora.FRADG.dg               ONLINE  ONLINE       node1                                                       ONLINE  ONLINE       node2                                        ora.LISTENER.lsnr               ONLINE  ONLINE       node1                                                       ONLINE  ONLINE       node2                                        ora.asm               ONLINE  ONLINE       node1                    Started                            ONLINE  ONLINE       node2                    Started             ora.gsd               OFFLINE OFFLINE      node1                                                       OFFLINE OFFLINE      node2                                        ora.net1.network               ONLINE  ONLINE       node1                                                       ONLINE  ONLINE       node2                                        ora.ons               ONLINE  ONLINE       node1                                                       ONLINE  ONLINE       node2                                        --------------------------------------------------------------------------------Cluster Resources--------------------------------------------------------------------------------ora.LISTENER_SCAN1.lsnr      1        ONLINE  ONLINE       node2                                        ora.LISTENER_SCAN2.lsnr      1        ONLINE  ONLINE       node1                                        ora.LISTENER_SCAN3.lsnr      1        ONLINE  ONLINE       node1                                        ora.cvu      1        ONLINE  ONLINE       node1                                        ora.node1.vip      1        ONLINE  ONLINE       node1                                        ora.node2.vip      1        ONLINE  ONLINE       node2                                        ora.oc4j      1        ONLINE  ONLINE       node1                                        ora.scan1.vip      1        ONLINE  ONLINE       node2                                        ora.scan2.vip      1        ONLINE  ONLINE       node1                                        ora.scan3.vip      1        ONLINE  ONLINE       node1                                        ora.zhongwc.db      1        ONLINE  ONLINE       node1                    Open                      2        ONLINE  ONLINE       node2                    Open       检查集群的运行状况 [grid@node1 ~]$ crsctl check cluster CRS-4537: Cluster Ready Services is onlineCRS-4529: Cluster Synchronization Services is onlineCRS-4533: Event Manager is online[grid@node1 ~]$ 所有 Oracle 实例 [grid@node1 ~]$ srvctl status database -d zhongwcInstance zhongwc1 is running on node node1Instance zhongwc2 is running on node node2 单个 Oracle 实例 [grid@node1 ~]$ srvctl status instance -d zhongwc -i zhongwc1 Instance zhongwc1 is running on node node1 节点应用程序 [grid@node1 ~]$ srvctl status nodeappsVIP node1-vip is enabledVIP node1-vip is running on node: node1VIP node2-vip is enabledVIP node2-vip is running on node: node2Network is enabledNetwork is running on node: node1Network is running on node: node2GSD is disabledGSD is not running on node: node1GSD is not running on node: node2ONS is enabledONS daemon is running on node: node1ONS daemon is running on node: node2 节点应用程序 [grid@node1 ~]$ srvctl config nodeappsNetwork exists: 1/192.168.0.0/255.255.0.0/eth0, type staticVIP exists: /node1-vip/192.168.1.151/192.168.0.0/255.255.0.0/eth0, hosting node node1VIP exists: /node2-vip/192.168.1.152/192.168.0.0/255.255.0.0/eth0, hosting node node2GSD existsONS exists: Local port 6100, remote port 6200, EM port 2016 数据库配置 [grid@node1 ~]$ srvctl config database -d zhongwc -a Database unique name: zhongwcDatabase name: zhongwcOracle home: /u01/app/oracle/product/11.2.0/dbhome_1Oracle user: oracleSpfile: +DATADG/zhongwc/spfilezhongwc.oraDomain: Start options: openStop options: immediateDatabase role: PRIMARYManagement policy: AUTOMATICServer pools: zhongwcDatabase instances: zhongwc1,zhongwc2Disk Groups: DATADG,FRADGMount point paths: Services: Type: RACDatabase is enabledDatabase is administrator managed ASM 状态 [grid@node1 ~]$ srvctl status asm ASM is running on node2,node1 ASM 配置 [grid@node1 ~]$ srvctl config asm -a ASM home: /u01/app/11.2.0/gridASM listener: LISTENERASM is enabled. TNS 监听器状态 [grid@node1 ~]$ srvctl status listener Listener LISTENER is enabledListener LISTENER is running on node(s): node2,node1 TNS 监听器配置 [grid@node1 ~]$ srvctl config listener -a Name: LISTENERNetwork: 1, Owner: gridHome: <CRS home>  /u01/app/11.2.0/grid on node(s) node2,node1End points: TCP:1521 节点应用程序配置 VIP、GSD、ONS、监听器 [grid@node1 ~]$ srvctl config nodeapps -a -g -s -l Warning:-l option has been deprecated and will be ignored.Network exists: 1/192.168.0.0/255.255.0.0/eth0, type staticVIP exists: /node1-vip/192.168.1.151/192.168.0.0/255.255.0.0/eth0, hosting node node1VIP exists: /node2-vip/192.168.1.152/192.168.0.0/255.255.0.0/eth0, hosting node node2GSD existsONS exists: Local port 6100, remote port 6200, EM port 2016Name: LISTENERNetwork: 1, Owner: gridHome: <CRS home>  /u01/app/11.2.0/grid on node(s) node2,node1End points: TCP:1521 SCAN 状态 [grid@node1 ~]$ srvctl status scan SCAN VIP scan1 is enabledSCAN VIP scan1 is running on node node2SCAN VIP scan2 is enabledSCAN VIP scan2 is running on node node1SCAN VIP scan3 is enabledSCAN VIP scan3 is running on node node1[grid@node1 ~]$ SCAN 配置 [grid@node1 ~]$ srvctl config scan SCAN name: cluster-scan.localdomain, Network: 1/192.168.0.0/255.255.0.0/eth0SCAN VIP name: scan1, IP: /cluster-scan.localdomain/192.168.1.57SCAN VIP name: scan2, IP: /cluster-scan.localdomain/192.168.1.58SCAN VIP name: scan3, IP: /cluster-scan.localdomain/192.168.1.59[grid@node1 ~]$ 验证所有集群节点间的时钟同步 [grid@node1 ~]$ cluvfy comp clocksync -verbose  Verifying Clock Synchronization across the cluster nodes Checking if Clusterware is installed on all nodes...Check of Clusterware install passedChecking if CTSS Resource is running on all nodes...Check: CTSS Resource running on all nodes  Node Name                             Status                    ------------------------------------  ------------------------  node1                                 passed                  Result: CTSS resource check passedQuerying CTSS for time offset on all nodes...Result: Query of CTSS for time offset passedCheck CTSS state started...Check: CTSS state  Node Name                             State                     ------------------------------------  ------------------------  node1                                 Active                  CTSS is in Active state. Proceeding with check of clock time offsets on all nodes...Reference Time Offset Limit: 1000.0 msecsCheck: Reference Time Offset  Node Name     Time Offset               Status                    ------------  ------------------------  ------------------------  node1         0.0                       passed                  Time offset is within the specified limits on the following set of nodes: \"[node1]\" Result: Check of clock time offsets passedOracle Cluster Time Synchronization Services check passedVerification of Clock Synchronization across the cluster nodes was successful. [oracle@node1 ~]$ sqlplus / as sysdbaSQL*Plus: Release 11.2.0.3.0 Production on Sat Dec 29 14:30:08 2012Copyright (c) 1982, 2011, Oracle.  All rights reserved.Connected to:Oracle Database 11g Enterprise Edition Release 11.2.0.3.0 - 64bit ProductionWith the Partitioning, Real Application Clusters, Automatic Storage Management, OLAP,Data Mining and Real Application Testing optionsSQL> col host_name format a20SQL> set linesize 200SQL> select INSTANCE_NAME,HOST_NAME,VERSION,STARTUP_TIME,STATUS,ACTIVE_STATE,INSTANCE_ROLE,DATABASE_STATUS from gv$INSTANCE;  INSTANCE_NAME\t HOST_NAME\t      VERSION\t\tSTARTUP_TIME\t\tSTATUS\t     ACTIVE_ST INSTANCE_ROLE\t  DATABASE_STATUS---------------- -------------------- ----------------- ----------------------- ------------ --------- ------------------ -----------------zhongwc1\t node1.localdomain    11.2.0.3.0\t29-DEC-2012 13:55:55\tOPEN\t     NORMAL    PRIMARY_INSTANCE   ACTIVEzhongwc2\t node2.localdomain    11.2.0.3.0\t29-DEC-2012 13:56:07\tOPEN\t     NORMAL    PRIMARY_INSTANCE   ACTIVE [grid@node1 ~]$ sqlplus / as sysasmSQL*Plus: Release 11.2.0.3.0 Production on Sat Dec 29 14:31:04 2012Copyright (c) 1982, 2011, Oracle.  All rights reserved.Connected to:Oracle Database 11g Enterprise Edition Release 11.2.0.3.0 - 64bit ProductionWith the Real Application Clusters and Automatic Storage Management optionsSQL> select name from v$asm_diskgroup;NAME------------------------------------------------------------CRSDATADGFRADG 到此,使用UDEV在Oracle Linux 6上安装Oracle 11g RAC(11.2.0.3)完毕","title":"使用UDEV在Oracle Linux 6上安装Oracle 11g RAC(11.2.0.3) (五)"},{"content":"近期在单位上做业务数据分析，发现还是Excel用的直接，筛选、求和、分类等等也是不亦乐乎，但是发现一些函数的效率与SQL还是有着较大差距，甚至是天壤之别，故作文一篇，提供Excel中的SQL查询使用方式。 查询的工作表可以是当前工作簿中的，也可以是其他工作簿中的。例如，图1所示的“网站数据.xlsx”工作簿中，Sheet1表格存储的是网站访问信息统计，现在需要从Sheet1中获取浏览次数大于500的城市。                                 图1 Sheet1中存储的访问数据 可以在当前工作簿的其他表格中运行SQL查询，也可以新建一个工作簿，在本示例中选择当前工作簿的Sheet2表格，然后单击“获取外部数据”模块的“现有连接”按钮，在打开的“现有连接”对话框中单击“浏览更多”按钮，在打开的“选取数据源”对话框中定位到存储源数据的Excel工作簿文件─网站数据.xlsx，如图2所示。 图2 定位存储源数据的工作簿文件 单击“打开”按钮，打开如图3所示的“选择表格”对话框，勾选“数据首行包含列标题”复选框，选择Sheet1工作表。 单击“确定”按钮，将打开如图4所示的“导入数据”对话框，在“请选择该数据在工作簿中的显示方式”选项中选择“表”，“数据的放置位置”选择“现有工作表”并指定位置为A1单元格。   图3 “选择表格”对话框 图4 “导入数据”对话框 单击“属性”按钮将打开如图5所示的“连接属性”对话框，在“命令类型”下拉列表中选择“SQL”，在命令文本中输入SQL查询语句“SELECT * FROM [Sheet1$] WHERE 浏览次数>500”，其中“Sheet1”即指定的Sheet1工作表，当在SQL中引用Excel工作表时，需要在名称后面加上“$”符并将其包含在方括号内，“*”表示取出工作表中的全部字段，WHERE子句用于指定筛选条件，即浏览次数大于500。 图5 “连接属性”对话框 单击“确定”按钮返回到“导入数据”对话框，再次单击“确定”按钮即可看到查询结果，如图6所示。   图6 SQL查询结果","title":"Excel工作表之SQL查询方法"},{"content":"对于数据库来讲大多瓶颈都出现在IO问题上，所以现在SSD类的设备也才能大行其道。那数据库的IO这块有什么可以优化的吗？ 我这里大致谈一下我的看法，希望能达到一个抛砖引玉的效果。    这里谈一下数据库本身的配置方面    具体如下：    配置方面对于IO优化的原则：尽可能能缓存，减少读对数据库的随机IO的请求；同时减少写的随机IO的随时发生，利用各种buffer去缓存。下面来看一下这块的参数： innodb_buffer_pool_size : 这是Innodb最重要的一个配置参数，这个参数控制Innodb本身的缓大小，也影响到，多少数据能在缓存中。建议该参数的配置在物理内存的70％－80％之间。 innodb_flush_method: 这个控制Innodb的IO形为，什么:fsync, O_DSYNC之类的，这里不做过多介绍， 建议使用: O_DIRECT, 这样减少操作系统级别VFS的缓存使用内存过多和Innodb本身的buffer的缓存冲突，同时也算是给操作系统减少点压力。 innodb_io_capacity: 这个参数据控制Innodb checkpoint时的IO能力，一般可以按一块SAS 15000转的磁盘200个计算，6块盘的SAS做的Raid10这个值可以配到600即可。如果是普通的SATA一块盘只能按100算。(innodb-plugin, Percona有这个参数) innodb_max_dirty_pages_pct : 这个参数据控制脏页的比例如果是innodb_plugin或是MySQL5.5以上的版本，建议这个参数可以设制到75%-90%都行。如果是大量写入，而且写入的数据不是太活跃，可以考虑把这个值设的低一点。 如果写入或是更新的数据也就是热数据就可以考虑把这个值设为：95% innodb_log_file_size : 这个可以配置256M以上，建议有两个以前的日志文件(innodb_log_files_in_group). 如果对系统非常大写的情况下，也可以考虑用这个参数提高一下性能，把文件设的大一点，减少checkpiont的发生。 最大可以设制成：innodb_log_files_in_group * innodb_log_file_size < 512G(percona, MySQL 5.6) 建议设制成: 256M -> innodb_buffer_pool_size/innodb_log_file_in_group 即可。 innodb_log_buffer_size : 如果没在大事务，控制在8M-16M即可。    其它对IO有影响的参数(以5.6为准) innodb_adaptive_flushing 默认即可 innodb_change_buffer_max_size 如果是日值类服务，可以考虑把这个增值调到 50 innodb_change_buffering 默认即可 innodb_flush_neighors 默认是开的， 这个一定要开着，充分利用顺序IO去写数据。 innodb_lru_scan_depth: 默认即可 这个参数比较专业。 innodb_max_purge_lag 默认没启用，如果写入和读取都量大，可以保证读取优先，可以考虑使用这个功能。 innodb_random_read_ahead 默认没开启，属于一个比较活跃的参数，如果要用一定要多测试一下。 对用passport类应用可以考虑使用 innodb_read_ahead_threshold 默认开启：56 预读机制可以根据业务处理，如果是passprot可以考虑关闭。如果使用innodb_random_read_ahead,建议关闭这个功能 innodb_read_io_threads 默认为：4 可以考虑8 innodb_write_io_threads 默认为：4 可以考虑8 sync_binlog 默认即可： 0 innodb_rollback_segments 默认即可: 128    另外5.6的undo log也可以独立配置了，建议单独配置出来。","title":"Mysql Innodb 学习经验"},{"content":"1、原始脚本 Create_chn_From_Comment.vbs Option Explicit ValidationMode = True InteractiveMode = im_BatchDim mdl 'the current model'get the current active model Set mdl = ActiveModel If (mdl Is Nothing) Then MsgBox \"There is no current Model\" ElseIf Not mdl.IsKindOf(PdPDM.cls_Model) Then MsgBox \"The current model is not an Physical Data model.\" Else ProcessFolder mdl End If'This routine copy name into code for each table, each column and each view 'of the current folder Private sub ProcessFolder(folder) Dim Tab 'running table for each Tab in folder.tables if not tab.isShortcut then tab.name =  tab.commentDim col 'running column for each col in tab.columnsif len(col.comment)<>0 then   'add by nisjcol.name= MID(col.comment,instr(col.comment,\"-\")+1)end ifnext end if nextDim view 'running view for each view in folder.Views if not view.isShortcut then view.name =  view.commentend if next'go into the sub-packages Dim f 'running folder For Each f In folder.Packages if not f.IsShortcut then ProcessFolder f end if Next end sub  以上脚本可以实现一般的注释转化到Name，但对于注释中有空、有重复的问题，脚本运行时便会报错；所以需要进行相应的升级。 2、改进脚本之一 Create_chn_From_Comment(重复信息后缀行号).vbs Option Explicit ValidationMode = True InteractiveMode = im_BatchDim mdl 'the current model'get the current active model Set mdl = ActiveModel If (mdl Is Nothing) Then MsgBox \"There is no current Model\" ElseIf Not mdl.IsKindOf(PdPDM.cls_Model) Then MsgBox \"The current model is not an Physical Data model.\" Else ProcessFolder mdl End If'This routine copy name into code for each table, each column and each view 'of the current folder Private sub ProcessFolder(folder) Dim Tab 'running table for each Tab in folder.tables if not tab.isShortcut then tab.name =  tab.commentDim col 'running column Dim countcount=1for each col in tab.columnsOn Error Resume Next '忽略错误，继续执行if len(col.comment)<>0 then   'add by nisjcol.name= MID(col.comment,instr(col.comment,\"-\")+1)'On Error Resume Next '忽略错误，继续执行If Err.Number<>0 then col.name = \"重复的列名-\"&col.comment&countend ifOn Error Goto 0count = count + 1end ifnext end if nextDim view 'running view for each view in folder.Views if not view.isShortcut then view.name =  view.commentend if next'go into the sub-packages Dim f 'running folder For Each f In folder.Packages if not f.IsShortcut then ProcessFolder f end if Next end sub  3、改进脚本之二 Create_chn_From_Comment(重复信息后缀ObjectId).vbs Option Explicit ValidationMode = True InteractiveMode = im_BatchDim mdl 'the current model'get the current active model Set mdl = ActiveModel If (mdl Is Nothing) Then MsgBox \"There is no current Model\" ElseIf Not mdl.IsKindOf(PdPDM.cls_Model) Then MsgBox \"The current model is not an Physical Data model.\" Else ProcessFolder mdl End If'This routine copy name into code for each table, each column and each view 'of the current folder Private sub ProcessFolder(folder) Dim Tab 'running table for each Tab in folder.tables if not tab.isShortcut then tab.name =  tab.commentDim col 'running column for each col in tab.columnsOn Error Resume Next '忽略错误，继续执行if len(col.comment)<>0 then   'add by nisjcol.name= MID(col.comment,instr(col.comment,\"-\")+1)'On Error Resume Next '忽略错误，继续执行If Err.Number<>0 then col.name = \"重复的列名-\"&col.comment&\"-\"&col.ObjectIdend ifOn Error Goto 0end ifnext end if nextDim view 'running view for each view in folder.Views if not view.isShortcut then view.name =  view.commentend if next'go into the sub-packages Dim f 'running folder For Each f In folder.Packages if not f.IsShortcut then ProcessFolder f end if Next end sub  4、后记 (1)、在编码调试的过程中，可以查看帮助文档，如下图所示： 查找列及表的对象元素，在文档中搜索“Column Mapping”进行相应对象的查看。 (2)、脚本中进行相应的更改，也可以实现Name到Comment、Name到Code等，稍作修改即可。 (3)、在此VBS脚本中，主要用到了“On Error Resume Next '忽略错误，继续执行”等一些不知道VB语法；在编写的过程中请教了一些高手，用了半天也没搞好；经仔细分析发现“高手”技术很牛，但思路不清晰，逻辑搞不通；后来自己细想了一下，改了点东西，虽然不甚专业，但也能解决些问题。","title":"PowerDesigner中从注释生成Name的两个升级VBS脚本"},{"content":" 问题报错： ORA-19504: failed to create file \"/home/oracle/rman_test/119.                               cp\" ORA-27038: created file already exists   报错过程： RMAN> show all; RMAN configuration parameters are: CONFIGURE RETENTION POLICY TO REDUNDANCY 1; # default CONFIGURE BACKUP OPTIMIZATION OFF; # default CONFIGURE DEFAULT DEVICE TYPE TO DISK; # default CONFIGURE CONTROLFILE AUTOBACKUP OFF; # default CONFIGURE CONTROLFILE AUTOBACKUP FORMAT FOR DEVICE TYPE DISK                                TO '%F'; # default CONFIGURE DEVICE TYPE DISK PARALLELISM 1 BACKUP TYPE TO BACKU                               PSET; # default CONFIGURE DATAFILE BACKUP COPIES FOR DEVICE TYPE DISK TO 1; #                                default CONFIGURE ARCHIVELOG BACKUP COPIES FOR DEVICE TYPE DISK TO 1;                                # default CONFIGURE MAXSETSIZE TO UNLIMITED; # default CONFIGURE ENCRYPTION FOR DATABASE OFF; # default CONFIGURE ENCRYPTION ALGORITHM 'AES128'; # default CONFIGURE ARCHIVELOG DELETION POLICY TO NONE; # default CONFIGURE SNAPSHOT CONTROLFILE NAME TO '/u01/app/oracle/produ                               ct/10.2.0/db_1/dbs/snapcf_pacs2.f'; # default RMAN> RUN { ALLOCATE CHANNEL d1 TYPE disk; set limit channel d1 kbytes=10000; backup datafile 4 FORMAT '/home/oracle/rman_test/119.cp' ;} RMAN> 2> 3> 4> released channel: ORA_DISK_1 allocated channel: d1 channel d1: sid=146 devtype=DISK Starting backup at 29-DEC-12 channel d1: starting full datafile backupset channel d1: specifying datafile(s) in backupset input datafile fno=00004 name=/u01/app/oracle/oradata/pacs2/u                               sers01.dbf channel d1: starting piece 1 at 29-DEC-12 channel d1: finished piece 1 at 29-DEC-12 piece handle=/home/oracle/rman_test/119.cp tag=TAG20121229T16                               5316 comment=NONE channel d1: starting piece 2 at 29-DEC-12 released channel: d1 RMAN-00571: =================================================                               ========== RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS =====                               ========== RMAN-00571: =================================================                               ========== RMAN-03009: failure of backup command on d1 channel at 12/29/                               2012 16:53:20 ORA-19504: failed to create file \"/home/oracle/rman_test/119.                               cp\" ORA-27038: created file already exists Additional information: 1   login as: root root@192.168.174.10's password: Last login: Sat Dec 29 14:36:51 2012 from 192.168.174.100 [root@STPACS ~]# [root@STPACS ~]# [root@STPACS ~]# [root@STPACS ~]# [root@STPACS ~]# su - oracle [oracle@STPACS ~]$ cd /home/oracle [oracle@STPACS ~]$ ls archive_log_test     dump_test  rman_test  test_expall.dmp dbapp_hrexample.dmp  f5.cp      sqldr [oracle@STPACS ~]$ cd rman_test [oracle@STPACS rman_test]$ ls -al total 8 drwxr-xr-x  2 oracle oinstall 4096 Dec 29 16:53 . drwx------  8 oracle oinstall 4096 Dec 29 14:39 .. [oracle@STPACS rman_test]$ cd .. [oracle@STPACS ~]$ ls -al total 188428 drwx------  8 oracle oinstall      4096 Dec 29 14:39 . drwxr-xr-x  4 root   root          4096 Oct 27 11:59 ..     问题解决过程： 比较诡异，开始上网搜索，网上已经有网友遇到过这个问题，我上metalink上确实也查找到了相关资料，在Doc ID: 1082911.6 上，原文如下： Solution Description: ===================== Insert a %U into the format portion of the backup script in order to ensure a unique backup file name. Problem Explanation: ==================== These errors occur because a backup file name already exists by the name specified in you backup script. For instance, if you are using the line “allocate channel c1 type disk format ‘/oracle/database/rman/backup/df_%d_%p_%c’;”, df_%d_%p_%c formats the backupstring like so; df_ is simply a name. This could be any set of characters. In this case it means database full. %d_ is the database sid. %p_is the backup piece number within the backup set. %c_ specifies the copy number of the backup piece within a set of duplexed backup pieces. There needs to be a %U added to the format string. %U_ specifies a convenient shorthand that guarantees uniqueness in generated backup filenames. So, if the string were “db_%d_%U_%p_%c a unique name would be generated and it would not be necessary to either rename or move the backup file name prior to the next backup. If the format is changed to include the %U, for instance; allocate channel c1 type disk format ‘/oracle/database/rman/backup/df_%d_%U_%p_%c’; The backup file will automatically have a unique name generated like; df_JTG_0eblfm65_1_1_1_1 The next one would look like; df_JTG_0fblfm76_1_1_1_1 原来是rman要求我们增加%U参数，添加参数到脚本中后再次尝试备份，就正常备份了，过程如下： RMAN> RUN { ALLOCATE CHANNEL d1 TYPE disk; set limit channel d1 kbytes=10000; backup datafile 4 FORMAT '/home/oracle/rman_test/119.cp%U' ;}2> 3> 4> allocated channel: d1 channel d1: sid=146 devtype=DISK Starting backup at 29-DEC-12 channel d1: starting full datafile backupset channel d1: specifying datafile(s) in backupset input datafile fno=00004 name=/u01/app/oracle/oradata/pacs2/users01.dbf channel d1: starting piece 1 at 29-DEC-12 channel d1: finished piece 1 at 29-DEC-12 piece handle=/home/oracle/rman_test/119.cp0unu3e5l_1_1 tag=TAG20121229T170037 comment=NONE channel d1: starting piece 2 at 29-DEC-12 channel d1: finished piece 2 at 29-DEC-12 piece handle=/home/oracle/rman_test/119.cp0unu3e5l_2_1 tag=TAG20121229T170037 comment=NONE channel d1: backup set complete, elapsed time: 00:00:02 Finished backup at 29-DEC-12 released channel: d1 [oracle@STPACS rman_test]$ pwd /home/oracle/rman_test [oracle@STPACS rman_test]$ ls -al total 15676 drwxr-xr-x  2 oracle oinstall     4096 Dec 29 17:00 . drwx------  8 oracle oinstall     4096 Dec 29 14:39 .. -rw-r-----  1 oracle oinstall 10240000 Dec 29 17:00 119.cp0unu3e5l_1_1 -rw-r-----  1 oracle oinstall  5775360 Dec 29 17:00 119.cp0unu3e5l_2_1   总结： 这个问题在全新安装的ORACLE也同样遇到过这样的问题，所以备份集命名时最好直接加上%U参数，免得报错。    ","title":"ORA-19504与ORA-27038"},{"content":"最近一周在复习索引相关的东西，除了回顾concept，还在MOS上看到了一篇比较好的文档。分享给大家。 文档编号：[ID 30405.1] This article is only concerned with B*tree indexes which are currently the most commonly used.  The theory of B*tree indexes is beyond the scope of this article; for more  information refer to computer science texts dealing with data structures. 这篇文档只描述关于当前最常用的b*tree索引。b*tree索引的原理已经超过了本文档的范围。更多的信息可以去查看计算机的数据结构原理。 Format of Index Blocks ~~~~~~~~~~~~~~~~~~~~~~ 索引的结构（格式？） Within a B*tree index, index blocks are either branch blocks, the upper blocks  within the B*tree index, or leaf blocks, the lowest level index blocks. Branch blocks contain  index data that point to lower level index blocks. Leaf blocks contain every indexed data value and a corresponding ROWID used to locate the actual row. 在b*tree索引中，一共有两种索引块，一种是branch block（分支块），还有leaf block（叶块），一种是高level，一种低level的（低level，在索引底部）。branch block包含定位低等级的索引块（可能是branch block或者leaf block）的pointer 。leaf block包含每一个索引数据值和相应的rowid（用来定位真正的row）。 以下是一个索引块的分布情况：                Index Block Format |-----------------------------------------------------| |                                                     | |            Index Block Header             | |                                                     | ------------------------------------------------------| |                                                     | |  Space reserved for future updates   | |  and inserts of new rows with the     | |   appropriate key values                  | |                                                     | |-----------------------------------------------------| <- PCTFREE say 10 |                                                     | |             Index Key Data                  | |                                                     | |                                                     | |                                                     | |                                                     | |                                                     | |                                                     | |                                                     | |                                                     | |                                                     | |-----------------------------------------------------| B*tree Index Creation 创建b*tree索引 ~~~~~~~~~~~~~~~~~~~~~ When a B*tree index is created using the CREATE INDEX statement, the parameter PCTFREE can be specified.  PCTFREE specifies the percentage of space to leave  free for future updates and insertions to an index block. A value of 0 reserves no space for future inserts and updates. It allows the entire data area of the  block to be filled when the index is created. If PCTFREE is not specified, it defaults to 10. This value reserves 10% of each block for updates to existing key values, and inserts of new key values. 当一个btree 索引使用create index语句创建的时候，可以设置pctfree 参数。pctfree指定index block中为了未来更新或者新增索引数据时预留的存储空间百分比。如果设置为0，表示不会预留存储空间。它允许index block中的data area 所有的空间都填满 索引条目 。如果pctfree 没有被指定，那么它的默认值为10。它意味着每个index block中都会预留10%的存储空间，为未来的插入和更新预留。 Thus PCTFREE is only relevant at initial index creation. It causes optimal splitting of the B*-tree in preparation for subsequent growth. The idea is to do as much splitting as  possible during initial creation and avoid having to pay the penalty later during insertion into the table. This is what a high PCTFREE setting on an index gives you. However, if your inserted keys are monotonically increasing (say a date/time field) a PCTFREE=0 is best. Only the rightmost index leaf block will be inserted into, so there's no point leaving room in the other leaf blocks at creation time. 所以pctfree只与创建索引的时候相关。它会影响b tree索引 分裂（因为后面的数据增长）的效率。比较好的办法是让索引分裂发生在索引创建阶段（预留空间多，自然需要更多的索引分裂操作）如果数据不会有增长pctfree设置为0是最好的。但是如果未来会插入大量数据，那么设置pctfree为非零那么就会有效的减少索引分裂的情况。 Following index creation, an index block can accommodate keys up to the full available data area including space for ITLs. Thus an index block will not require splitting until the available data area is fully used. The bottom line is PCTFREE is not looked at once you pass the index creation phase.  One thing to remember is that each row in the index has only one correct block it can live in, based on the key value. 索引创建，可以填满它的data area （包括itl）。所以在索引块被填满之前，是不需要分裂的。每一行在 索引中，只在一个block上，基于它的 index key column value 。 Inserting an index entry after index creation 索引创建后插入一条 索引条目 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ After index creation, a new table row will create a new index entry. This entry is inserted into the appropriate index leaf block based on the index key values until the leaf block is full.  If on insert the index leaf block is full, then an index block split will occur putting half of the index entries into each new index leaf block. Within an index data block, space is reserved for the index block header. The rest of the block is available for index keys. 在索引创建之后，一个新的行插入到表中，会创建一个新的索引条目。这个条目插入到相关的索引叶块中。如果插入的索引叶块已经满了，那么索引块会发生分裂，将其一半的索引条目 放到新的索引叶块中。在索引数据块内部，空间只为索引块头保留。剩下的block space 都可以用来插入索引数据。 Where an index key value has multiple entries, these entries are made into the leaf block in ROWID order.  So all the blocks for the index key value are scanned in turn until an entry is found with a greater ROWID than the new row, and the row is inserted into that block (which may cause extra block splitting).  当一个索引键值拥有多个条目，这些条目内部按照rowid排列。所以拥有相同index key value的block都会被按照顺序被扫描，直到找到了一个大于新行的rowid。 The reason for this is for queries such as:         SELECT some_columns FROM table WHERE COL_A  = valueA and COL_B = valueB; If COL_A and COL_B both have non-unique indexes, then because the entries in each index are stored in ROWID order, it makes it easy to find the ROWID's that occur in both indexes.  Otherwise we would have to sort the ROWID's before we could find the ROWID's that occur in both indexes.  如上所示，如果谓词中的列都含有非唯一索引。那么因为每个索引条目中的数据都是按照rowid的顺序排列的。所以可以很简单进行查找操作。换句话说我们必须在使用之前先按照rowid 排序。（这个情况是基于索引数据插入的说明的） Updating an index entry 更新索引条目 ~~~~~~~~~~~~~~~~~~~~~~~ There is really no concept of an UPDATE to an index. When a table row is updated, the old index key is deleted and a new key inserted (at the correct location in the B*tree). 更新就是在leaf block中删除老的index entry 并且在新的leaf block中插入新的index entry 。 Deleting an index entry 删除索引条目 ~~~~~~~~~~~~~~~~~~~~~~~ When a index entry is to be deleted, the row is deleted from the index leaf block and the space within the index leaf block released to the block for further inserts with the appropriate key range.  If a leaf block has even one entry it is still part of the tree, hence only entries that belong in it positionally can be accommodated. Once a leaf block is completely empty it is put on the free list, at which point it can be used to service an index block split. 当一个索引条目被删除，相关的数据会从索引叶块中删除，并且在 索引叶块中的空间 会被释放。如果一个叶块中拥有哪怕一条记录，那么它依然属于这个btree 索引。一旦一个叶块完全空白，那么它会被放置于free list中。 Index Fragmentation ~~~~~~~~~~~~~~~~~~~ To ascertain index fragmentation, the following SQL statement can be used:     ANALYZE INDEX &&index_name VALIDATE STRUCTURE;     col name         heading 'Index Name'          format a30     col del_lf_rows  heading 'Deleted|Leaf Rows'   format 99999999     col lf_rows_used heading 'Used|Leaf Rows'      format 99999999     col ibadness     heading '% Deleted|Leaf Rows' format 999.99999     SELECT name,        del_lf_rows,        lf_rows - del_lf_rows lf_rows_used,        to_char(del_lf_rows / (lf_rows)*100,'999.99999') ibadness     FROM index_stats        where name = upper('&&index_name');     undefine index_name As a rule of thumb if 10-15% of the table data changes, then you should consider rebuilding the index.  索引碎片。10-15% 就需要考虑重建索引了。 B*Tree Balancing B*Tree 平衡操作 ~~~~~~~~~~~~~~~~ Oracle indexes are implemented as B* Trees which are always balanced. oracle index btree 通常是平衡的。 In an Oracle B*tree the root of the tree is at level 0. In a very small B*tree the root block can also be a Leaf block. 在oracle btree索引中，tree 的根节点 在level 0 。在一个非常小的b tree索引中，root block 也可能是leaf block 。 In most cases, blocks on levels 0 through N-2 (where N is the height of the tree) are Branch blocks. Branch blocks do not contain data, they simply contain separators which are used to navigate from the root block to the the Leaf blocks. 大多数情况下，level 在 n-2 （n=heigh）之上的都是 branch block （分支块）。分支块不包含rowid。它们只包含分隔符。 All Leaf blocks are at level N-1 in Oracle B*trees. All data stored in a B*tree is stored in the Leaf blocks. 所有的叶块都在 level N-1 。所有的数据存储在leaf block （叶块）中。 The definition of a 'Balanced Tree' is that all the data is on the same level. Which means that the path to all data in the tree is the same length. Since all the data is stored in Leaf blocks and all the Leaf blocks are on the same level the B*trees are always balanced. There is no way to unbalance a B* tree. “平衡树”的定义为，所有的数据在相同的level。它意味着 所有数据的访问路径，都是大致相同的。因为所有的数据存储在leaf block 并且所有的leaf block 在相同的level 上面，并且btree 通常是平衡的。没有办法去unbalance 一个 btree 。 Deletion of many rows in the B*Tree 删除B*Tree索引中大多数的行后… ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ If a table has 100,000 rows and 99,999 of 100,000 rows and index entries are  deleted.  How is the index balanced? 如果表中拥有100000行数据，并且其中99999行数据和索引条目被删除了，那么索引时怎样平衡的呢 ？ In this case the rows are deleted from the index, and the empty blocks inserted onto the index free list. These blocks are still part of the index and will need to be accessed when traversing the index.  在这里数据会从index中删除，并且空的blocks 会被插入到索引 free list中。这些blocks一直是这个索引的一部分，并且并且在检索数据的时候，依然需要访问这些块。 <p> Thus if an index has one entry in it, there is only one block (a root/leaf block) in the tree. When searching the tree only one block needs to be accessed to answer thequery. If you load a B* Tree with 100,000 rows and get a tree with say 3 Levels.  因此，如果一个索引只有一个条目，只有一个block，root branch block=leaf block 。访问的时候仅需要访问这个块即可。如果加载了数据，with 100000条，并且得到了tree with 3 levels 。 Levels zero and one are Branch blocks used to access the data in the Leaf blocks on level 2. When querying this tree you first access the root block using the search key to find correct Branch block in level one of the Tree.  level 0 和 1 是分支块branch block 用来取得leaf block中的数据（on level 2）。当查询这个tree ， 第一需要访问的是root 块，去查找 相应的 branch block （level 1） 。 Next you use the search key and the Branch block to find the correct Leaf block that should contain the key being sought. So it takes three block accesses to answer the same query. Now if 99,999 rows were deleted from the tree the rows are removed from the index but the index is not collapsed.  下一步，需要使用 需要查找的键值 和branch block 分支块去查找正确的 叶块。 所以需要访问3个块去相应查询。现在如果99999行数据被删除，但是索引没有收缩、合并。 In this case you still have a 3 level index to store the one row and it will still take three block accesses to access that row. The fact that we need three block accesses instead of one does not mean this tree is unbalanced. The tree is still balanced it just contains a lot of empty blocks. 在这种情况下，仍然需要3个级别的索引 去存储 这行数据，并且依然需要访问3个块才能够得到相应的数据。这意味着我们需要访问3个block 而不是一个block ，但是这并不意味着tree 不是平衡的tree 依然是平衡的 ，只是包含了一些 空块。 <\/p> The reason for doing this is that, when data is inserted into a Leaf block, and there is no room for the insert, a very expensive operation called a split occurs. The split creates a new Leaf block and possibly new Branch blocks as well to maintain the balance of the tree. The split operation is by far the most expensive operation that is done in the maintenance of B* trees so we go to great lengths to avoid them. By not collapsing the now unused levels out of the B*Trees after large deletes these levels (with splits) do not have to be recreated during future inserts. 索引分裂操作是为了维护btree索引的 平衡（这是一个非常耗费资源的操作）。如果不收缩未使用的levels block ，那么这些块中的空闲空间，则会在索引条目插入的时候用到，有效的减少了索引分裂操作。 If most of the rows in a table are going to be deleted, and not refilled soon after, it is advisable to drop the index, delete the rows, and then recreate the index. 如果表中大多数的行被删除，并且在短期内不会被重新加载。那么这个时候可以考虑重建索引，drop 掉 index ，然后recreate it 。 By dropping the index you save the index maintenance that needs to be done during the delete thus speeding up the delete. By recreating the index after  the delete you create an index of optimal height and with the Leaf blocks filled to an optimal level. 删除索引，可以让我们省去索引维护的事情，比如说删除索引中数据的操作会导致性能降低。在删除数据后重建索引，可以调整height ，将leaf block 放在一个合适的级别上。","title":"Oracle Database 中 B*Tree 索引内部维护"},{"content":"public static Integer getStock(String strdate, Long orgId, Long productId){      if(strdate==null||orgId==null||productId==null)    throw new IllegalArgumentException();   Integer stock = null;   //DataAccess da = DataAccessFactory.create(BPMConstant.ERP_DATABASE);   Connection conn=null;   CallableStatement fun = null;   try {    String callSQL = \"{?=call getstock(?,?,?)} \";    //Connection conn = da.getConnection();    conn=DBUtil.getConnection(BPMConstant.ERP_DATABASE);    fun = conn.prepareCall(callSQL);    fun.registerOutParameter(1, oracle.jdbc.OracleTypes.NUMBER);    fun.setString(2, strdate);    fun.setLong(3, orgId);    fun.setLong(4, productId);    fun.execute();    stock = fun.getInt(1);   }catch(Exception e){    e.printStackTrace();   }finally{    DBUtil.closeCallableStatement(fun);    DBUtil.closeConnection(conn);   }        return stock;     }","title":"java调用储存过程的方法"},{"content":"一、API例子 DATE_FORMAT(NOW(),'%b %d %Y %h:%i %p') DATE_FORMAT(NOW(),'%m-%d-%Y') DATE_FORMAT(NOW(),'%d %b %y') DATE_FORMAT(NOW(),'%d %b %Y %T:%f') Dec 29 2008 11:45 PM 12-29-2008 29 Dec 08 29 Dec 2008 16:25:46.635   二、现实中的例子 select DATE_FORMAT(SYSDATE(),'%Y-%m-%e %H:%i:%S') 2012-12-28 09:50:21 select DATE_FORMAT('2012-01-01','%Y-%m-%e %H:%i:%S') 2012-01-1 00:00:00   API地址:http://www.w3school.com.cn/sql/func_date_format.asp","title":"MySQL中DATA_FORMAT函数的用法"},{"content":"问题：dual是什么？ 回答： dual是一个系统表，不能删除或者修改其表结构。它的名称叫做“伪表”或者“哑表”。 查看其表结构： SQL> desc dual 名称        是否为空? 类型 ----------- -------- ----------- DUMMY                VARCHAR2(1) 其字段只有一个“dummy”，中文叫做“哑巴”。长度只有1。这个表结构只供参考。 问题：dual的作用是什么，如何使用？ 在Oracle中，使用dual的主要原因是为了计算表达式的值。如计算：99*99。 对dual表的操作只能是查询，其它如增删改或者修改表结构，都没有实际应用价值，不用研究。何况有可能会导致Oracle不使用。 如： select 99*99 from dual; 返回： 9801 也可以一次性计算多个表达式的值： 执行： select 9*9,1+1,1/null from dual; 返回： 9*9        1+1     1/NULL --- ---------- ---------- 81          2 注意，“1/null”的结果为null。因为在数据库中，任何值与null进行运算，其结果为null。 还有一个最常见的用途就是查询当前系统日期，对应函数是:sysdate，即“system date”。 代码： select sysdate from dual; 返回： SYSDATE ---------- 22-11月-10 为了更容易看懂，可以用to_char函数指定显式的格式。 select to_char(sysdate,'yyyy.mm.dd') as 当前日期 from dual; 返回： 当前日期 ---------- 2010.11.22 执行： select to_char(sysdate,'yyyy.mm.dd hh24:mi:ss') as 当前时间 from dual; 返回： 当前时间 ------------------- 2010.11.22 11:28:44 另外，在学习序列以后，就可以知道，查询序列的下一个值和当前值，通常也会用到dual表。 小结： ·dual表主要用于计算表达式。 ·表结构只供参数，实际返回的列数与表达式的个数有关 ·dual表只有可能返回一行，不可能返回多行。因为dual表并不是从表中取数据。","title":"dual在oracle中是什么?"},{"content":"redis的常用命令主要分为两个方面、一个是键值相关命令、一个是服务器相关命令 1、键值相关命令       keys * 取出当前所有的key       exists name 查看n是否有name这个key       del name 删除key name       expire confirm 100 设置confirm这个key100秒过期       ttl confirm 获取confirm 这个key的有效时长       select 0 选择到0数据库 redis默认的数据库是0~15一共16个数据库       move confirm 1 将当前数据库中的key移动到其他的数据库中，这里就是把confire这个key从当前数据库中移动到1中       persist confirm 移除confirm这个key的过期时间       randomkey 随机返回数据库里面的一个key       rename key2 key3 重命名key2 为key3       type key2 返回key的数据类型 2、服务器相关命令       ping PONG返回响应是否连接成功       echo 在命令行打印一些内容       select 0~15 编号的数据库       quit  /exit 退出客户端       dbsize 返回当前数据库中所有key的数量       info 返回redis的相关信息       config get dir/* 实时传储收到的请求       flushdb 删除当前选择数据库中的所有key       flushall 删除所有数据库中的数据库      ","title":"redis入门——redis常用命令"},{"content":"1.1             Designer Manager 1.1.1             Source 1.       可以在Source Analyzer 中定义四种类型的Source：Relational（Table ， View， Synonym）, Flat File（定长或者定界符分隔的文本文件）, XML File，COBOL Files； 2.       Relational Source的定义通常是通过ODBC来导入的； 3.       Flat File的定义通常是通过Wizard分析来源文本文件确定的； 4.       以上两种Source可以通过Data Previewer查看数据； 5.       也可以手工创建或者更改Source的定义；   1.1.2             Target 在Warehouse Designer中创建Target的方法有下面一些：从数据库导入，从文件导入，手工创建，从Source复制； 有三种Target：Relational， Flat File， XML File。 可以根椐Target的定义生成脚本用ODBC连接目标数据库创建实际的物理表；   1.1.3             Transformation 以下是常用的Transformation功能的简单的描述，第四课有相关用法的详细说明 Source Qualifier           从文本文件或者数据库读取数据； Normalizer                  行列转换，将一条记录的多列转成多条记录的一列； Aggregator                  执行统计操作； Union                          合并多个数据流； Router                         将一个数据流分成多个数据流； Expression                   计算表达式； Filter                            过滤数据； Sorter                          排序数据流； Update Strategy          确定更新策略（插入，更新，删除，拒绝）； Lookup                        根椐输入值到指定数据源中查找匹配记录并返回某个或某些栏位（分为连接的和非连接的）； Joiner                           连接多个数据流； Sequence Generator    产生序列号 Transaction Control    控制事务 Rank                               等级,取最大或者最小的N行数据(可以按组) Procedure                       存取过程,函数,包. Transformation有三种视图：图标，正常视图，编辑视图 表达式编辑器（Expression Editor），函数，校验（Validation） 表达式编辑器用于编辑计算语句或者条件语句； 在下面几种Transformation中出现：Expression，Aggregator，Rank，Router，Update Strategy，Transaction Control； 组成元素包括：常量，字符串，操作符，函数，Ports以及Unconnected Lookup的返回值； 可用的函数分为七大类：字符函数，转换函数，日期函数，数字函数，科学函数，特殊函数和测试函数； 点击OK或者Validation时都会对表达式进行解析验证； In Port ，Variable Port ，Out Port 以及I/O Port 只有下面三种Transformation能够使用变量端口：Aggregator， Expression， Rank； 变量端口可以在另外的变量端口中或者输出端口中引用，在变量端口的表达式中可以引用输入端口或者其它变量端口； 变量端口可以在数据流的不同行间传递数据； 变量端口执行隐式初始化：数字端口为零，字符端口为空字串，日期为1753-01-01； 端口赋值的顺序是：输入端口，变量端口，输出端口，其中变量端口因为可能存在相互依赖关系，所以他们出现的顺序和结果相关，依照出现的顺序进行求值； 默认值 对于输入Port以及输入输出Port ，默认值用于替代NULL值（系统自动设定的默认值为空）； 对于输出Port ，默认值用于替代表达式计算错误（包括数据类型转换错误，计算错误如除数为零，呼叫Error函数）（系统自动设定的默认值是ERROR('transformation error')）；比如可以使用 IIF( SALARY < 0, ERROR ('Error. Negative salary found. Row skipped.', EMP_SALARY )或者 IIF(1>0,TO_DATE('20060908','YYYYMMDD'),NULL)之类的表达式来代替ERROR('transformation error')   对于变量Port ，没有默认值； 如果默认值设成了Error(‘xxx’)，当出现NULL值（输入或者输入输出端口）或者表达式计算错误（输出端口）时，当前行被跳过，并在Session Log中作记录。 用户可定义的默认值包括NULL，常量，常量表达式，ERROR函数，ABORT函数； 有些Transformation的某些端口不允许使用默认值，这时这个栏位无法编辑； Source和Target使用对应数据库的本地数据类型，Transformation使用ANSI SQL-92数据类型，port相连时会发生数据类型隐式转换，转换不相容时会发生错误，也可以用相应的转换函数执行转换。 Reusable：在Transformation Developer窗口创建的Transformation都是可用重的，在Mapping Designer中创建的默认都是不可重用的，这个属性只可从不可重用改成可重用；   1.1.4             Mapping 要素：每个Mapping至少要有一个Source，一个Source Qualifier 和一个Target ，连接形成一个数据流，不能含有Transformation Error，并且要符合下面的数据流规则和端口连接规则； 数据流规则 每一个Source Qualifier开始一个数据流； Transformation能够将数据发送给多个transformation； Transformation 能够接受来自多个transformation的数据，如果这些transformation起源于同一个active transformation； Joiner和Union可以接受起源自多个active transformation的数据流； Port 连接规则： A.     数据类型相同或者相容； B.      不能将输出端口连到非输入端口上； C.     Source的输出端口只能连接到Source Qualifier的输入端口上； D.     不能将非输出端口连到其它端口上； Mapplet是可重用的Mapping片断； 参数，变量； A.     参数是Mapping中可以使用的常量，变量在会话成功执行后可以改变并保存在知识库中供下次运行时使用； B.      给参数或变量赋值的方法有三种：系统赋默认值，赋初始值，在参数文件中赋值； C.     参数或变量可以在下列地方使用：表达式，Source Qualifier（Filter ，User Defined Join ，Pre SQL ，Post SQL），Lookup Override Sql； D.    Mapping与Mapplet的参数或变量相互独立；   1.1.5             对象的导入导出 导入导出的中间媒介是XML文件； 除了在Designer， Workflow Manager中执行导入导出操作，还可以在Reporsitory Manager中执行导出操作； 可以进行导入导出的对象包括：Sources，Targets，Transformations，Mapplats，Mappings，Sessions，Worklets，Workflows，Session Config等等； 整个知识库的备份与恢复在知识库服务器管理平台中进行；  ","title":"Powercenter 基础知识介绍 - 2"},{"content":"    数据库的性能优化涉及到整个数据库运行环境的方方面面，诸如操作系统，Oracle自身，存储，网络等等几个大块。而操作系统则是Oracle稳定运行与最大化性能的基石。本文主要描述基于Linux系统下 Oracle 内核参数的配置。     校验下面的列表中显示的内核参数的值被设置为大于或等于下面所显示的最小值。     如果你的系统中下面的任意参数的当前值已经大于或高于下面列出的值，请不要做任何修改。   下面的步骤给出了如何去校验并设置这些参数的值。     通过执行下面的命令进行校验     /sbin/sysctl -a | egrep \"kernel.shmall|kernel.shmmax|kernel.shmmn|kernel.sem\"     然后比较下表所列出的值 注意：下表显示的是内核参数以及shell 限制所需的最小值。对于生产数据库，Oracle建议去调整这些值使得数据库性能达到最优。有关优化内核参数更多信息请参考操作系统相关文档。   Oracle 内核参数参考值 Parameter Minimum Value Recommended value File semmsl semmns semopm semmni 250 32000 100 128 Set only if those that are set by OS or other applications are lower /proc/sys/kernel/sem shmall 2097152 shmmax/page_size usually page_size=4 /proc/sys/kernel/shmall shmmax Minimum of the following values: ·       Half the size of the memory ·       4GB - 1 byte Note: The minimum value required for shmmax is 0.5 GB. However, Oracle recommends that you set the value of shmmax to 2.0 GB for optimum performance of the system. Half of RAM or if swap file is less then half of RAM the size of swap file /proc/sys/kernel/shmmax shmmni 4096 /proc/sys/kernel/shmmni file-max 512 * PROCESSES /proc/sys/fs/file-max ip_local_port_range Minimum:9000 Maximum: 65000 /proc/sys/net/ipv4/ip_local_port_range rmem_default 262144 /proc/sys/net/core/rmem_default rmem_max 4194304 /proc/sys/net/core/rmem_max wmem_default 262144 /proc/sys/net/core/wmem_default wmem_max 1048576 /proc/sys/net/core/wmem_max tcp_wmem 262144 /proc/sys/net/ipv4/tcp_wmem tcp_rmem 4194304 /proc/sys/net/ipv4/tcp_rmem   校验内核参数     按照下面的步骤去查看指定参数的值，如果有必要的话对其进行修改     执行下表中相应的命令来显示这些内核参数的值，并标记该参数的值是否需要修改。 Parameter Command semmsl, semmns, semopm, and semmni # /sbin/sysctl -a | grep sem This command displays the value of the semaphore parameters in the order listed. shmall, shmmax, and shmmni # /sbin/sysctl -a | grep shm This command displays the details of the shared memory segment sizes. file-max # /sbin/sysctl -a | grep file-max This command displays the maximum number of file handles. ip_local_port_range # /sbin/sysctl -a | grep ip_local_port_range This command displays a range of port numbers. rmem_default # /sbin/sysctl -a | grep rmem_default rmem_max # /sbin/sysctl -a | grep rmem_max wmem_default # /sbin/sysctl -a | grep wmem_default wmem_max # /sbin/sysctl -a | grep wmem_max tcp_wmem # /sbin/sysctl -a | grep tcp_wmem tcp_rmem # /sbin/sysctl -a | grep tcp_rmem   修改内核参数        如果上述查询的内核值小于最小值，按照下面的步骤进行修改：     使用任意的文本编辑器编辑/etc/sysctl.conf 文件， 添加或编辑下列类似的行：     注:仅仅修改你需要调整的参数。对于信号量参数 (kernel.sem)， 你必须指定所有的四个值。 如果当前的值大于最小值，那么使用或保留当前值。         fs.file-max = 512 * PROCESSES         kernel.shmall = 2097152         kernel.shmmax = 2147483648         kernel.shmmni = 4096         kernel.sem = 250 32000 100 128         or         kernel.sem = 250 256000 100 1024         net.ipv4.ip_local_port_range = 1024 65000         net.core.rmem_default = 4194304         net.core.rmem_max = 4194304         net.core.wmem_default = 262144         net.core.wmem_max = 262144         net.ipv4.tcp_wmem = 262144 262144 262144         net.ipv4.tcp_rmem = 4194304 4194304 4194304     注:参数shmmax 最小值是 0.5 GB。然而 Oracle 建议设置该参数的值到2GB去最大化系统性能。     在/etc/sysctl.conf文件里指定的这些参数值，重新启动系统后依然被保留。 然而在 SUSE Linux Enterprise Server 系统中，重新启动系统前输入下面的命令来确保系统启动时读到 /etc/sysctl.conf 文件：         # /sbin/chkconfig boot.sysctl on     输入下面的命令以使得当前修改的这些内核参数的值立即生效:         # /sbin/sysctl -p     上面的这个命令同时可以看到刚刚设置的参数及值，如果不正确再次编辑该文件并输入正确的值。     可以通过命令/sbin/sysctl -a 显示当前所有可用值.     在 SUSE 系统中，输入下面的命令使得系统读取/etc/sysctl.conf文件当系统启动的时候:         # /sbin/chkconfig boot.sysctl on     在 SUSE 系统中，你必须输入oinstall 组的gid作为参数 /proc/sys/vm/hugetlb_shm_group的值. 主要是为oinstall组内的成员授予许可去创建共享内存段     如下面的示例，oinstall组id为501         # echo 501 > /proc/sys/vm/hugetlb_shm_group     运行上述命令后，使用vi添加下列文本到 /etc/sysctl.conf，以允许 boot.sysctl 随操作系统启动时运行：         vm.hugetlb_shm_group=501     注:仅仅一个组能够被定义给vm.hugetlb_shm_group.     一旦在/etc/sysctl.conf 文件更新参数后，要么重新启动计算机或者运行命令 sysctl -p 激活 /etc/sysctl.conf 文件的新值，并使之生效。   为Oracle 用户设置shell限制     为提高oracle性能，必须为oracle用户增加下列shell限制:   Shell Limit    Item in limits.conf     Hard Limit Maximum number of open file descriptors    nofile 65536 Maximum number of processes available to a single user    nproc 16384     增加shell 限制:     添加下列行到/etc/security/limits.conf 文件:         oracle              soft    nproc   2047         oracle              hard    nproc   16384         oracle              soft    nofile  1024         oracle              hard    nofile  65536     添加或编辑/etc/pam.d/login 文件，当下面的条目不存在时：         session    required     pam_limits.so     取决于Oracle用户缺省的shell环境，为缺省的shell启动文件作下列更改：       对于Bourne, Bash, or Korn shell, 添加下列行到/etc/profile 文件 (SUSE Linux 则添加到/etc/profile.local):         if [ $USER = \"oracle\" ]; then                 if [ $SHELL = \"/bin/ksh\" ]; then                       ulimit -p 16384                       ulimit -n 65536                 else                       ulimit -u 16384 -n 65536                 fi         fi   原文出处：Oracle kernel parameters tuning on Linux    更多参考 有关Oracle RAC请参考      使用crs_setperm修改RAC资源的所有者及权限      使用crs_profile管理RAC资源配置文件      RAC 数据库的启动与关闭      再说 Oracle RAC services      Services in Oracle Database 10g      Migrate datbase from single instance to Oracle RAC      Oracle RAC 连接到指定实例      Oracle RAC 负载均衡测试(结合服务器端与客户端)      Oracle RAC 服务器端连接负载均衡(Load Balance)      Oracle RAC 客户端连接负载均衡(Load Balance)      ORACLE RAC 下非缺省端口监听配置(listener.ora tnsnames.ora)      ORACLE RAC 监听配置 (listener.ora tnsnames.ora)      配置 RAC 负载均衡与故障转移      CRS-1006 , CRS-0215 故障一例       基于Linux (RHEL 5.5) 安装Oracle 10g RAC      使用 runcluvfy 校验Oracle RAC安装环境 有关Oracle 网络配置相关基础以及概念性的问题请参考：      配置非默认端口的动态服务注册      配置sqlnet.ora限制IP访问Oracle      Oracle 监听器日志配置与管理      设置 Oracle 监听器密码(LISTENER)      配置ORACLE 客户端连接到数据库 有关基于用户管理的备份和备份恢复的概念请参考      Oracle 冷备份      Oracle 热备份      Oracle 备份恢复概念      Oracle 实例恢复      Oracle 基于用户管理恢复的处理      SYSTEM 表空间管理及备份恢复      SYSAUX表空间管理及恢复      Oracle 基于备份控制文件的恢复(unsing backup controlfile) 有关RMAN的备份恢复与管理请参考      RMAN 概述及其体系结构      RMAN 配置、监控与管理      RMAN 备份详解      RMAN 还原与恢复      RMAN catalog 的创建和使用      基于catalog 创建RMAN存储脚本      基于catalog 的RMAN 备份与恢复      RMAN 备份路径困惑      使用RMAN实现异机备份恢复(WIN平台)      使用RMAN迁移文件系统数据库到ASM      linux 下RMAN备份shell脚本      使用RMAN迁移数据库到异机 有关ORACLE体系结构请参考      Oracle 表空间与数据文件      Oracle 密码文件      Oracle 参数文件      Oracle 联机重做日志文件(ONLINE LOG FILE)      Oracle 控制文件(CONTROLFILE)      Oracle 归档日志      Oracle 回滚(ROLLBACK)和撤销(UNDO)      Oracle 数据库实例启动关闭过程      Oracle 10g SGA 的自动化管理      Oracle 实例和Oracle数据库(Oracle体系结构) ","title":"Linux 下 Oracle 内核参数优化"},{"content":"    RAC环境下的归档模式切换与单实例稍有不同，主要是共享存储所产生的差异。在这种情况下，我们可以将RAC数据库切换到非集群状态下，仅仅在一个实例上来实施归档模式切换即可完成RAC数据库的归档模式转换问题。本文主要描述了由非归档模式切换到归档模式，而由非归档切换的归档步骤相同，不再赘述。 1、主要步骤： 备份spfile，以防止参数修改失败导致数据库无法启动 修改集群参数cluster_database为false 启动单实例到mount状态 将数据库置于归档模式(alter database archivelog/noarchivelog) 修改集群参数cluster_database为true 关闭单实例 启动集群数据库2、环境  oracle@bo2dbp:~> cat /etc/issue Welcome to SUSE Linux Enterprise Server 10 SP3 (x86_64) - Kernel \\r (\\l). oracle@bo2dbp:~> sqlplus -v SQL*Plus: Release 10.2.0.3.0 - Production  使用asm存储方式存放归档日志3、修改集群数据库到归档模式 oracle@bo2dbp:~> export ORACLE_SID=ora10g1 oracle@bo2dbp:~> sqlplus / as sysdba SQL*Plus: Release 10.2.0.3.0 - Production on Mon Dec 24 16:53:18 2012 Copyright (c) 1982, 2006, Oracle.  All Rights Reserved. Connected to: Oracle Database 10g Release 10.2.0.3.0 - 64bit Production With the Real Application Clusters option SQL> archive log list;    -->查看当前数据库的归档模式 Database log mode              No Archive Mode          -->非归档模式 Automatic archival             Disabled Archive destination            USE_DB_RECOVERY_FILE_DEST Oldest online log sequence     59 Current log sequence           60 SQL> select instance_name,host_name,status from gv$instance; INSTANCE_NAME    HOST_NAME            STATUS ---------------- -------------------- ------------ ora10g1          bo2dbp               OPEN ora10g2          bo2dbs               OPEN SQL> show parameter cluster      -->查看集群的参数,cluster_database为true表示为集群数据库，否则，非集群数据库 NAME                                 TYPE        VALUE ------------------------------------ ----------- ------------------------------ cluster_database                     boolean     TRUE cluster_database_instances           integer     2 cluster_interconnects                string SQL> create pfile='/u01/oracle/db/dbs/ora10g_robin.ora' from spfile;  -->先备份spfile File created. SQL> alter system set cluster_database=false scope=spfile sid='*';  -->修改为非集群数据库，该参数为静态参数，需要使用scope=spfile System altered. oracle@bo2dbp:~> srvctl stop database -d ora10g                        -->关闭数据库 oracle@bo2dbp:~> srvctl start instance -d ora10g -i ora10g1 -o mount   -->启动单个实例到mount状态 oracle@bo2dbp:~> sqlplus / as sysdba SQL> select instance_name,status from v$instance; INSTANCE_NAME    STATUS ---------------- ------------ ora10g1          MOUNTED SQL> alter database archivelog;                                       -->改变数据库到归档模式 Database altered. SQL> alter system set cluster_database=true scope=spfile sid='*';    -->在将数据库改为集群模式 System altered. SQL> ho srvctl stop instance -d ora10g -i ora10g1                     -->关闭当前实例 SQL> ho srvctl start database -d ora10g                               -->启动集群数据库   SQL> archive log list; ORA-03135: connection lost contact SQL> conn / as sysdba Connected. SQL> archive log list;                                                -->查看归档模式 Database log mode              Archive Mode                           -->已经处于归档模式 Automatic archival             Enabled                                -->自动归档 Archive destination            USE_DB_RECOVERY_FILE_DEST              -->归档位置为参数DB_RECOVERY_FILE_DEST的值 Oldest online log sequence     60                                     -->下面是sequence相关信息    Next log sequence to archive   61 Current log sequence           61 SQL> show parameter db_recovery_file NAME                                 TYPE        VALUE ------------------------------------ ----------- ------------------------------ db_recovery_file_dest                string      +REV db_recovery_file_dest_size           big integer 2G4、归档验证  SQL> select inst_id,name,thread#,sequence#,status from gv$archived_log;  -->当前无任何归档日志 no rows selected SQL> alter system switch logfile;        -->在实例1上进行归档 System altered. SQL> col name format a65 SQL> select inst_id,name,thread#,sequence#,status from gv$archived_log;   -->查看到sequence为61的日志已经归档    INST_ID NAME                                                                 THREAD#  SEQUENCE# S ---------- ----------------------------------------------------------------- ---------- ---------- -    1 +REV/ora10g/archivelog/2012_12_24/thread_1_seq_61.459.802892953            1         61  SQL> select name,thread#,sequence#,status from v$archived_log;  -->下面是从实例级别的视图来查看 NAME                                                                 THREAD#  SEQUENCE# S ----------------------------------------------------------------- ---------- ---------- - +REV/ora10g/archivelog/2012_12_24/thread_1_seq_61.459.802892953            1         61 A SQL> conn system/oracle@ora10g2    -->连接到实例2 Connected.    SQL> show parameter instance_name; NAME                                 TYPE        VALUE ------------------------------------ ----------- ------------------------------ instance_name                        string      ora10g2 SQL> alter system switch logfile;   -->在实例2上进行归档 System altered. SQL> select inst_id,name,thread#,sequence#,status from gv$archived_log;   -->可以看到sequence为43的日志已经归档 -->注意这个视图查询时同一个归档日志除了出现在自身实例中外,对另外的实例也是可见的    INST_ID NAME                                                                 THREAD#  SEQUENCE# S ---------- ----------------------------------------------------------------- ---------- ---------- -    1 +REV/ora10g/archivelog/2012_12_24/thread_1_seq_61.459.802892953            1         61 A    1 +REV/ora10g/archivelog/2012_12_24/thread_2_seq_43.458.802893283            2         43 A    2 +REV/ora10g/archivelog/2012_12_24/thread_1_seq_61.459.802892953            1         61 A    2 +REV/ora10g/archivelog/2012_12_24/thread_2_seq_43.458.802893283            2         43 A -->查看日志的状态 -->注意这个v$log视图将两个实例上的组及状态都显示出来了 -->在这里用thread#来区分，thread#为1表示实例1上的日志组有1,2,且1处于current状态.thread#2类似.    SQL> select * from v$log;  GROUP#    THREAD#  SEQUENCE#      BYTES    MEMBERS ARC STATUS           FIRST_CHANGE# FIRST_TIM ---------- ---------- ---------- ---------- ---------- --- ---------------- ------------- ---------    1          1         62   52428800          2 NO  CURRENT                4314741 24-DEC-12    2          1         61   52428800          2 YES ACTIVE                 4312116 24-DEC-12    3          2         43   52428800          2 YES ACTIVE                 4312300 24-DEC-12    4          2         44   52428800          2 NO  CURRENT                4315097 24-DEC-12 -->Author: Robinson -->Blog  : http://blog.csdn.net/robinson_0612 -->归档当前日志,注意该命令在单实例下等同于alter system switch logfile -->在rac环境下则不同，那就是所有实例上的current日志都将会被归档    SQL> alter system archive log current; System altered. -->下面的查询正好验证了上面的描述 -->日志62与44正是刚刚上面的命令同时产生的归档日志    SQL> select inst_id,name,thread#,sequence#,status from gv$archived_log;    INST_ID NAME                                                                 THREAD#  SEQUENCE# S ---------- ----------------------------------------------------------------- ---------- ---------- -    2 +REV/ora10g/archivelog/2012_12_24/thread_1_seq_61.459.802892953            1         61 A    2 +REV/ora10g/archivelog/2012_12_24/thread_2_seq_43.458.802893283            2         43 A    2 +REV/ora10g/archivelog/2012_12_24/thread_2_seq_44.456.802894343            2         44 A    2 +REV/ora10g/archivelog/2012_12_24/thread_1_seq_62.457.802894341            1         62 A    1 +REV/ora10g/archivelog/2012_12_24/thread_1_seq_61.459.802892953            1         61 A    1 +REV/ora10g/archivelog/2012_12_24/thread_2_seq_43.458.802893283            2         43 A    1 +REV/ora10g/archivelog/2012_12_24/thread_2_seq_44.456.802894343            2         44 A    1 +REV/ora10g/archivelog/2012_12_24/thread_1_seq_62.457.802894341            1         62 A 8 rows selected. 更多参考 有关Oracle RAC请参考      使用crs_setperm修改RAC资源的所有者及权限      使用crs_profile管理RAC资源配置文件      RAC 数据库的启动与关闭      再说 Oracle RAC services      Services in Oracle Database 10g      Migrate datbase from single instance to Oracle RAC      Oracle RAC 连接到指定实例      Oracle RAC 负载均衡测试(结合服务器端与客户端)      Oracle RAC 服务器端连接负载均衡(Load Balance)      Oracle RAC 客户端连接负载均衡(Load Balance)      ORACLE RAC 下非缺省端口监听配置(listener.ora tnsnames.ora)      ORACLE RAC 监听配置 (listener.ora tnsnames.ora)      配置 RAC 负载均衡与故障转移      CRS-1006 , CRS-0215 故障一例       基于Linux (RHEL 5.5) 安装Oracle 10g RAC      使用 runcluvfy 校验Oracle RAC安装环境 有关Oracle 网络配置相关基础以及概念性的问题请参考：      配置非默认端口的动态服务注册      配置sqlnet.ora限制IP访问Oracle      Oracle 监听器日志配置与管理      设置 Oracle 监听器密码(LISTENER)      配置ORACLE 客户端连接到数据库 有关基于用户管理的备份和备份恢复的概念请参考      Oracle 冷备份      Oracle 热备份      Oracle 备份恢复概念      Oracle 实例恢复      Oracle 基于用户管理恢复的处理      SYSTEM 表空间管理及备份恢复      SYSAUX表空间管理及恢复      Oracle 基于备份控制文件的恢复(unsing backup controlfile) 有关RMAN的备份恢复与管理请参考      RMAN 概述及其体系结构      RMAN 配置、监控与管理      RMAN 备份详解      RMAN 还原与恢复      RMAN catalog 的创建和使用      基于catalog 创建RMAN存储脚本      基于catalog 的RMAN 备份与恢复      RMAN 备份路径困惑      使用RMAN实现异机备份恢复(WIN平台)      使用RMAN迁移文件系统数据库到ASM      linux 下RMAN备份shell脚本      使用RMAN迁移数据库到异机 有关ORACLE体系结构请参考      Oracle 表空间与数据文件      Oracle 密码文件      Oracle 参数文件      Oracle 联机重做日志文件(ONLINE LOG FILE)      Oracle 控制文件(CONTROLFILE)      Oracle 归档日志      Oracle 回滚(ROLLBACK)和撤销(UNDO)      Oracle 数据库实例启动关闭过程      Oracle 10g SGA 的自动化管理      Oracle 实例和Oracle数据库(Oracle体系结构) ","title":"RAC 环境下修改归档模式"},{"content":"oracle本身对表的导入导出方式有很多，oracle方式，sql方式，plsql方式等等，得到的文件后缀分别是dmp，sql和pde，这里这三种的好坏想必大家都多少有些了解了。   dmp是oracle原生导出文件，导入导出速度快，压缩率高，文件移植性和实用性好，方便备份还原等，需要时，导入导出即可。缺点是，只是应用于oracle数据库。   sql脚本文件呢，则是一种通用方式，导入导出速度较快，文件移植和实用性甚至超过dmp，因为它是.sql后缀的，所以它基本上能用应用于所有主流的数据库，只要有此sql文件，可通用于oracle，mssql，mysql等等。这个优点不巧也正是它的缺点，因为需通用于大部分主流数据库，所以它的sql文件里，只能保存通用类型，如oracle的大数据类型clob，blob在使用sql导入导出时，就会发生错误。遇到其他数据库的特定类型，也是如此。而且假使表比较多，数据量比较大的话，得到的相应的sql文件也比较多，不方便管理和使用。   pde方式，则使用的并不多见，使用也比较有局限性。     下面就开始正题，比如我现在在公司里，用公司数据库里的表，但是明天放假了，我想在家里做做项目的话，这时候，就需要用到oracle的表的导入导出了。即，从公司的数据库里导出表，然后带回家，导入到我的机器上面。   公司的oracle是10g，而我本机上的oracle是11g的r2版本。首先是导出表，我在公司的用户名和密码是rent/rent 权限是普通的读写权限，登录方式的normal。导出时，我是使用的PL/sql developer工具，导出方式为oracle导出dmp文件，使用的bin文件是10g的BIN目录下的exp.exe执行文件，导入到桌面为rent.dmp。   然后把自己的机器上的oracle11g服务打开，启动以sys方式登录，登录后，创建表空间为rent，用户名密码为rent/rent，用户的默认表空间为rent，给它权限为下面5个，connect ，dba，EXP_FULL_DATABASE ，IMP_FULL_DATABASE ，RESOURCE。一切就绪后注销登录，选择rent/rent用户登录，登录方式为normal。   最后打开dos，输入imp，提示输入用户名和密码，即输入我们的用户名和密码。后面提示要给出dmp文件的位置，这里我是在d盘的rent.dmp，于是我写入d:/rent.dmp。最后它就会自动开始导入了。   希望大家也能一次成功，值得注意的是，导入和导出时，需使用的可执行文件为exp.exe和imp.exe，这两个文件的版本一定要是相同的版本，比如我就是全部都用的10g的。不然的话，就会报错的。  ","title":"oracle导入导出表"},{"content":"开头语：SQL注入攻击的危害性很大。在讲解其防止办法之前，数据库管理员有必要先了解一下其攻击的原理。这有利于管理员采取有针对性的防治措施 -----解决方案-------------------------------------------------------- 过滤URL中的一些特殊字符，动态SQL语句使用PrepareStatement..  ------解决方案-------------------------------------------------------- 注入的方式就是在查询条件里加入SQL字符串. 可以检查一下提交的查询参数里是否包含SQL,但通常这样无益. 最好的办法是不要用拼接SQL字符串,可以用prepareStatement,参数用set方法进行填装  ------解决方案-------------------------------------------------------- sql注入形式：...where name=\"+name+\",这样的sql语句很容易sql注入，可以这样： jdbcTemplate.update(\"delete from userinfo where id=? and userId=?\", new Object[]{userInfo.getId(),userInfo.getUserId()}); 我的一些代码，望有用！  ------解决方案-------------------------------------------------------- Sql注入漏洞攻击：如1'or'1'='1 使用参数化查询避免 cmd.CommandText=\"select count(*) from 表名 where username=@a and password=@b\"; cmd.parameters.Add(new SqlParameter(\"a\",\"..\")); cmd.parameters.Add(new SqlParameter(\"b\",\"..\"));  ------解决方案-------------------------------------------------------- 恩，用框架，用jpa的pojo。。就没这种事情了 SSH2架构中 怎么防止SQL注入呢？还有其他相关安全问题怎么设计呢？ 目前的安全，只是对用户密码加密，前台jquery验证。 如何实现防止注入攻击还有我的页面有些隐藏域保存这当前登录用户的信息等信息。 用户查看页面源代码就可以查看到了。 有没好的解决方案呢？还有其他哪些要注意的地方呢？ Struts2 hibernate3 spring 3.0 sql server 2000 sp4 ------解决方案-------------------------------------------------------- 1：向 CA 购买证书，使用 HTTPS 进行通信，以保证在网络传输过程中是安全的 2：避免 XSS 注入（页面回显的 input text, input hidden 均过滤 <、>、\"、' 等字符等） 3：使用随机键盘或者安全控件防止键盘木马记录用户的输入 4：若要在 Cookie 中写入数据，尽量使用 Cookie 的 HttpOnly 属性 5：响应中设置一些诸如 X-Frame-Options、X-XSS-Protection 等高版本浏览器支持的 HTTP 头 6: 不管客户端是否做过数据校验，在服务端必须要有数据校验（长度、格式、是否必填等等） 7: SQL 语句采用 PreparedStatement 的填充参数方式，严禁使用字符串拼接 SQL 或者 HQL 语句 六个建议防止SQL注入式攻击 2009-04-01 14:38 SQL注入攻击的危害性很大。在讲解其防止办法之前，数据库管理员有必要先了解一下其攻击的原理。这有利于管理员采取有针对性的防治措施。 　　一、 SQL注入攻击的简单示例。 　　statement := \"SELECT * FROM Users WHERE Value= \" + a_variable + \" 　　上面这条语句是很普通的一条SQL语句，他主要实现的功能就是让用户输入一个员工编号然后查询处这个员工的信息。但是若这条语句被不法攻击者改装过后，就可能成为破坏数据的黑手。如攻击者在输入变量的时候，输入以下内容SA001’;drop table c_order--。那么以上这条SQL语句在执行的时候就变为了SELECT * FROM Users WHERE Value= ‘SA001’;drop table c_order--。 　　这条语句是什么意思呢?‘SA001’后面的分号表示一个查询的结束和另一条语句的开始。c_order后面的双连字符 指示当前行余下的部分只是一个注释，应该忽略。如果修改后的代码语法正确，则服务器将执行该代码。系统在处理这条语句时，将首先执行查询语句，查到用户编号为SA001 的用户信息。然后，数据将删除表C_ORDER(如果没有其他主键等相关约束，则删除操作就会成功)。只要注入的SQL代码语法正确，便无法采用编程方式来检测篡改。因此，必须验证所有用户输入，并仔细检查在您所用的服务器中执行构造 SQL命令的代码。 　　二、 SQL注入攻击原理。 　　可见SQL注入攻击的危害性很大。在讲解其防止办法之前，数据库管理员有必要先了解一下其攻击的原理。这有利于管理员采取有针对性的防治措施。 　　SQL注入是目前比较常见的针对数据库的一种攻击方式。在这种攻击方式中，攻击者会将一些恶意代码插入到字符串中。然后会通过各种手段将该字符串传递到SQLServer数据库的实例中进行分析和执行。只要这个恶意代码符合SQL语句的规则，则在代码编译与执行的时候，就不会被系统所发现。 　　SQL注入式攻击的主要形式有两种。一是直接将代码插入到与SQL命令串联在一起并使得其以执行的用户输入变量。上面笔者举的例子就是采用了这种方法。由于其直接与SQL语句捆绑，故也被称为直接注入式攻击法。二是一种间接的攻击方法，它将恶意代码注入要在表中存储或者作为原书据存储的字符串。在存储的字符串中会连接到一个动态的SQL命令中，以执行一些恶意的SQL代码。 　　注入过程的工作方式是提前终止文本字符串，然后追加一个新的命令。如以直接注入式攻击为例。就是在用户输入变量的时候，先用一个分号结束当前的语句。然后再插入一个恶意SQL语句即可。由于插入的命令可能在执行前追加其他字符串，因此攻击者常常用注释标记“—”来终止注入的字符串。执行时，系统会认为此后语句位注释，故后续的文本将被忽略，不背编译与执行。 　　三、 SQL注入式攻击的防治。 既然SQL注入式攻击的危害这么大，那么该如何来防治呢?下面这些建议或许对数据库管理员防治SQL注入式攻击有一定的帮助。 　　1、 普通用户与系统管理员用户的权限要有严格的区分。 　　如果一个普通用户在使用查询语句中嵌入另一个Drop Table语句，那么是否允许执行呢?由于Drop语句关系到数据库的基本对象，故要操作这个语句用户必须有相关的权限。在权限设计中，对于终端用户，即应用软件的使用者，没有必要给他们数据库对象的建立、删除等权限。那么即使在他们使用SQL语句中带有嵌入式的恶意代码，由于其用户权限的限制，这些代码也将无法被执行。故应用程序在设计的时候，最好把系统管理员的用户与普通用户区分开来。如此可以最大限度的减少注入式攻击对数据库带来的危害。 　　2、 强迫使用参数化语句。 　　如果在编写SQL语句的时候，用户输入的变量不是直接嵌入到SQL语句。而是通过参数来传递这个变量的话，那么就可以有效的防治SQL注入式攻击。也就是说，用户的输入绝对不能够直接被嵌入到SQL语句中。与此相反，用户的输入的内容必须进行过滤，或者使用参数化的语句来传递用户输入的变量。参数化的语句使用参数而不是将用户输入变量嵌入到SQL语句中。采用这种措施，可以杜绝大部分的SQL注入式攻击。不过可惜的是，现在支持参数化语句的数据库引擎并不多。不过数据库工程师在开发产品的时候要尽量采用参数化语句。 3、 加强对用户输入的验证。 　　总体来说，防治SQL注入式攻击可以采用两种方法，一是加强对用户输入内容的检查与验证;二是强迫使用参数化语句来传递用户输入的内容。在SQLServer数据库中，有比较多的用户输入内容验证工具，可以帮助管理员来对付SQL注入式攻击。测试字符串变量的内容，只接受所需的值。拒绝包含二进制数据、转义序列和注释字符的输入内容。这有助于防止脚本注入，防止某些缓冲区溢出攻击。测试用户输入内容的大小和数据类型，强制执行适当的限制与转换。这即有助于防止有意造成的缓冲区溢出，对于防治注入式攻击有比较明显的效果。 　　如可以使用存储过程来验证用户的输入。利用存储过程可以实现对用户输入变量的过滤，如拒绝一些特殊的符号。如以上那个恶意代码中，只要存储过程把那个分号过滤掉，那么这个恶意代码也就没有用武之地了。在执行SQL语句之前，可以通过数据库的存储过程，来拒绝接纳一些特殊的符号。在不影响数据库应用的前提下，应该让数据库拒绝包含以下字符的输入。如分号分隔符，它是SQL注入式攻击的主要帮凶。如注释分隔符。注释只有在数据设计的时候用的到。一般用户的查询语句中没有必要注释的内容，故可以直接把他拒绝掉，通常情况下这么做不会发生意外损失。把以上这些特殊符号拒绝掉，那么即使在SQL语句中嵌入了恶意代码，他们也将毫无作为。 　　故始终通过测试类型、长度、格式和范围来验证用户输入，过滤用户输入的内容。这是防止SQL注入式攻击的常见并且行之有效的措施。 　　4、 多多使用SQL Server数据库自带的安全参数。 　　为了减少注入式攻击对于SQL Server数据库的不良影响，在SQLServer数据库专门设计了相对安全的SQL参数。在数据库设计过程中，工程师要尽量采用这些参数来杜绝恶意的SQL注入式攻击。 　　如在SQL Server数据库中提供了Parameters集合。这个集合提供了类型检查和长度验证的功能。如果管理员采用了Parameters这个集合的话，则用户输入的内容将被视为字符值而不是可执行代码。即使用户输入的内容中含有可执行代码，则数据库也会过滤掉。因为此时数据库只把它当作普通的字符来处理。使用Parameters集合的另外一个优点是可以强制执行类型和长度检查，范围以外的值将触发异常。如果用户输入的值不符合指定的类型与长度约束，就会发生异常，并报告给管理员。如上面这个案例中，如果员工编号定义的数据类型为字符串型，长度为10个字符。而用户输入的内容虽然也是字符类型的数据，但是其长度达到了20个字符。则此时就会引发异常，因为用户输入的内容长度超过了数据库字段长度的限制。 　　5、 多层环境如何防治SQL注入式攻击? 　　在多层应用环境中，用户输入的所有数据都应该在验证之后才能被允许进入到可信区域。未通过验证过程的数据应被数据库拒绝，并向上一层返回一个错误信息。实现多层验证。对无目的的恶意用户采取的预防措施，对坚定的攻击者可能无效。更好的做法是在用户界面和所有跨信任边界的后续点上验证输入。如在客户端应用程序中验证数据可以防止简单的脚本注入。但是，如果下一层认为其输入已通过验证，则任何可以绕过客户端的恶意用户就可以不受限制地访问系统。故对于多层应用环境，在防止注入式攻击的时候，需要各层一起努力，在客户端与数据库端都要采用相应的措施来防治SQL语句的注入式攻击。","title":"防止SQL注入攻击的一些方法小结"},{"content":"有关于Oracle Linux 6的安装可以参考Oracle Linux 6 Installation。安装两台OL6分配两个网卡内存均为3G,hostname分别为node1和node2。 OS版本你也可以选择CentOS6或者是RHEL6,建议初次安装选择CentOS6/RHEL6。选择Oracle Linux6可以使用OL6提供的oracle-rdbms-server-11gR2-preinstall来简化oracle database software和grid infrastructure的安装,目前在RHEL6/OL6 Linux上认证的唯一数据库版本为11.2.0.3. oracle11gR2 RAC引入了SCANIP(集群的单客户端访问名称) 如果您曾经通过添加新节点来扩展 Oracle RAC（或者通过删除节点来缩小 RAC），更新每个客户端的 SQL*Net 或 JDBC 配置以反映这个新增或删除的节点！为解决此问题，Oracle 11g R2引入了一个新特性，即单客户端访问名称（简称为 SCAN）。SCAN 这个新特性为客户端提供了单一的主机名，用于访问集群中运行的 Oracle 数据库。如果您在集群中添加或删除节点，使用 SCAN 的客户端无需更改自己的 TNS 配置。无论集群包含哪些节点，SCAN 资源及其关联的 IP 地址提供了一个稳定的名称供客户端进行连接使用。在 Oracle Grid Infrastructure 安装过程的询问阶段，系统会要求您提供主机名和最多三个 IP 地址以便用于 SCAN 资源。为了获得较高的可用性和可伸缩性，Oracle 建议你对 SCAN 名称进行配置，以便解析为三个 IP 地址。SCAN 必须至少解析为一个地址。 SCAN 虚拟 IP 名称类似于节点的虚拟 IP 地址所使用的名称，如 node1-vip。然而，与虚拟 IP 不同的是，SCAN 与整个集群相关联，而不是与一个节点相关联，它可与多个 IP 地址相关联，而不是只与一个地址相关联。注意，SCAN 地址、虚拟 IP 地址和公共 IP 地址必须属于同一子网。 这里我在dns服务器中定义scanip,dns服务器ip为192.168.1.200。 以下操作在dns服务器上 安装bind等相关软件 [root@dns ~]# yum install bind bind-devel bind-chroot caching-nameserverLoaded plugins: fastestmirrorDetermining fastest mirrors * base: centos.ustc.edu.cn * extras: centos.ustc.edu.cn * updates: centos.ustc.edu.cnbase                                                                                                                                            | 1.1 kB     00:00     base/primary                                                                                                                                    | 1.2 MB     00:09     base                                                                                                                                                         3591/3591extras                                                                                                                                          | 2.1 kB     00:00     extras/primary_db                                                                                                                               | 207 kB     00:00     updates                                                                                                                                         | 1.9 kB     00:00     updates/primary_db                                                                                                                              | 1.0 MB     00:01     Setting up Install ProcessResolving Dependencies--> Running transaction check---> Package bind.x86_64 30:9.3.6-20.P1.el5_8.5 set to be updated--> Processing Dependency: bind-libs = 30:9.3.6-20.P1.el5_8.5 for package: bind---> Package bind-chroot.x86_64 30:9.3.6-20.P1.el5_8.5 set to be updated---> Package bind-devel.i386 30:9.3.6-20.P1.el5_8.5 set to be updated--> Processing Dependency: libbind9.so.0 for package: bind-devel--> Processing Dependency: libisccc.so.0 for package: bind-devel--> Processing Dependency: libdns.so.26 for package: bind-devel--> Processing Dependency: libisccfg.so.1 for package: bind-devel--> Processing Dependency: liblwres.so.9 for package: bind-devel--> Processing Dependency: libisc.so.15 for package: bind-devel---> Package bind-devel.x86_64 30:9.3.6-20.P1.el5_8.5 set to be updated---> Package caching-nameserver.x86_64 30:9.3.6-20.P1.el5_8.5 set to be updated--> Running transaction check--> Processing Dependency: bind-libs = 30:9.3.6-16.P1.el5 for package: bind-utils---> Package bind-libs.i386 30:9.3.6-20.P1.el5_8.5 set to be updated---> Package bind-libs.x86_64 30:9.3.6-20.P1.el5_8.5 set to be updated--> Running transaction check---> Package bind-utils.x86_64 30:9.3.6-20.P1.el5_8.5 set to be updated--> Finished Dependency ResolutionDependencies Resolved======================================================================================================================================================================= Package                                     Arch                            Version                                            Repository                        Size=======================================================================================================================================================================Installing: bind                                        x86_64                          30:9.3.6-20.P1.el5_8.5                             updates                          989 k bind-chroot                                 x86_64                          30:9.3.6-20.P1.el5_8.5                             updates                           47 k bind-devel                                  i386                            30:9.3.6-20.P1.el5_8.5                             updates                          2.8 M bind-devel                                  x86_64                          30:9.3.6-20.P1.el5_8.5                             updates                          2.8 M caching-nameserver                          x86_64                          30:9.3.6-20.P1.el5_8.5                             updates                           64 kInstalling for dependencies: bind-libs                                   i386                            30:9.3.6-20.P1.el5_8.5                             updates                          864 kUpdating for dependencies: bind-libs                                   x86_64                          30:9.3.6-20.P1.el5_8.5                             updates                          897 k bind-utils                                  x86_64                          30:9.3.6-20.P1.el5_8.5                             updates                          180 kTransaction Summary=======================================================================================================================================================================Install       6 Package(s)Upgrade       2 Package(s)Total download size: 8.5 MIs this ok [y/N]: yDownloading Packages:(1/8): bind-chroot-9.3.6-20.P1.el5_8.5.x86_64.rpm                                                                                               |  47 kB     00:00     (2/8): caching-nameserver-9.3.6-20.P1.el5_8.5.x86_64.rpm                                                                                        |  64 kB     00:00     (3/8): bind-utils-9.3.6-20.P1.el5_8.5.x86_64.rpm                                                                                                | 180 kB     00:00     (4/8): bind-libs-9.3.6-20.P1.el5_8.5.i386.rpm                                                                                                   | 864 kB     00:00     (5/8): bind-libs-9.3.6-20.P1.el5_8.5.x86_64.rpm                                                                                                 | 897 kB     00:00     (6/8): bind-9.3.6-20.P1.el5_8.5.x86_64.rpm                                                                                                      | 989 kB     00:00     (7/8): bind-devel-9.3.6-20.P1.el5_8.5.i386.rpm                                                                                                  | 2.8 MB     00:11     (8/8): bind-devel-9.3.6-20.P1.el5_8.5.x86_64.rpm                                                                                                | 2.8 MB     00:02     -----------------------------------------------------------------------------------------------------------------------------------------------------------------------Total                                                                                                                                  315 kB/s | 8.5 MB     00:27     warning: rpmts_HdrFromFdno: Header V3 DSA signature: NOKEY, key ID e8562897updates/gpgkey                                                                                                                                  | 1.5 kB     00:00     Importing GPG key 0xE8562897 \"CentOS-5 Key (CentOS 5 Official Signing Key) <centos-5-key@centos.org>\" from /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-5Is this ok [y/N]: yRunning rpm_check_debugRunning Transaction TestFinished Transaction TestTransaction Test SucceededRunning Transaction  Updating       : bind-libs                                                                                                                                      1/10   Installing     : bind                                                                                                                                           2/10   Installing     : bind-libs                                                                                                                                      3/10   Installing     : bind-chroot                                                                                                                                    4/10   Installing     : caching-nameserver                                                                                                                             5/10   Installing     : bind-devel                                                                                                                                     6/10   Updating       : bind-utils                                                                                                                                     7/10   Installing     : bind-devel                                                                                                                                     8/10   Cleanup        : bind-libs                                                                                                                                      9/10   Cleanup        : bind-utils                                                                                                                                    10/10 Installed:  bind.x86_64 30:9.3.6-20.P1.el5_8.5                   bind-chroot.x86_64 30:9.3.6-20.P1.el5_8.5                    bind-devel.i386 30:9.3.6-20.P1.el5_8.5              bind-devel.x86_64 30:9.3.6-20.P1.el5_8.5             caching-nameserver.x86_64 30:9.3.6-20.P1.el5_8.5            Dependency Installed:  bind-libs.i386 30:9.3.6-20.P1.el5_8.5                                                                                                                                Dependency Updated:  bind-libs.x86_64 30:9.3.6-20.P1.el5_8.5                                           bind-utils.x86_64 30:9.3.6-20.P1.el5_8.5                                          Complete! 修改配置文件,将localhost和127.0.0.1修改为any [root@dns ~]# cd /var/named/chroot/etc/[root@dns etc]# cp -p named.caching-nameserver.conf named.conf[root@dns etc]# cat named.conf //// named.caching-nameserver.conf//// Provided by Red Hat caching-nameserver package to configure the// ISC BIND named(8) DNS server as a caching only nameserver // (as a localhost DNS resolver only). //// See /usr/share/doc/bind*/sample/ for example named configuration files.//// DO NOT EDIT THIS FILE - use system-config-bind or an editor// to create named.conf - edits to this file will be lost on // caching-nameserver package upgrade.//options {\tlisten-on port 53 { any; };\tlisten-on-v6 port 53 { ::1; };\tdirectory \t\"/var/named\";\tdump-file \t\"/var/named/data/cache_dump.db\";        statistics-file \"/var/named/data/named_stats.txt\";        memstatistics-file \"/var/named/data/named_mem_stats.txt\";\t// Those options should be used carefully because they disable port\t// randomization\t// query-source    port 53;\t\t// query-source-v6 port 53;\tallow-query     { any; };\tallow-query-cache { any; };};logging {        channel default_debug {                file \"data/named.run\";                severity dynamic;        };};view localhost_resolver {\tmatch-clients \t   { any; };\tmatch-destinations { any; };\trecursion yes;\tinclude \"/etc/named.rfc1912.zones\";}; 配置反向解析zone文件解析scanip,在named.rfc1912.zones末尾加上 zone \"1.168.192.in-addr.arpa.\" IN { type master; file \"1.168.192.in-addr.arpa\"; allow-update { none; }; }; [root@dns etc]# cat named.rfc1912.zones // named.rfc1912.zones://// Provided by Red Hat caching-nameserver package //// ISC BIND named zone configuration for zones recommended by// RFC 1912 section 4.1 : localhost TLDs and address zones// // See /usr/share/doc/bind*/sample/ for example named configuration files.//zone \".\" IN {\ttype hint;\tfile \"named.ca\";};zone \"localdomain\" IN {\ttype master;\tfile \"localdomain.zone\";\tallow-update { none; };};zone \"localhost\" IN {\ttype master;\tfile \"localhost.zone\";\tallow-update { none; };};zone \"0.0.127.in-addr.arpa\" IN {\ttype master;\tfile \"named.local\";\tallow-update { none; };};zone \"0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa\" IN {        type master;\tfile \"named.ip6.local\";\tallow-update { none; };};zone \"255.in-addr.arpa\" IN {\ttype master;\tfile \"named.broadcast\";\tallow-update { none; };};zone \"0.in-addr.arpa\" IN {\ttype master;\tfile \"named.zero\";\tallow-update { none; };};zone \"1.168.192.in-addr.arpa.\" IN {\ttype master;\tfile \"1.168.192.in-addr.arpa\";\tallow-update { none; };}; 配置正,反向解析数据库文件,在反向解析文件中加入 57 IN PTR cluster-scan.localdomain. 58 IN PTR cluster-scan.localdomain. 59 IN PTR cluster-scan.localdomain. [root@dns etc]# cd /var/named/chroot/var/named/[root@dns named]# cp -p named.local 1.168.192.in-addr.arpa[root@dns named]# cat 1.168.192.in-addr.arpa $TTL\t86400@       IN      SOA     localhost. root.localhost.  (                                      1997022700 ; Serial                                      28800      ; Refresh                                      14400      ; Retry                                      3600000    ; Expire                                      86400 )    ; Minimum        IN      NS      localhost.1       IN      PTR     localhost.57\tIN\tPTR\tcluster-scan.localdomain.58\tIN\tPTR\tcluster-scan.localdomain.59\tIN\tPTR\tcluster-scan.localdomain. 在正向解析文件中加入 cluster-scan IN A 192.168.1.57 cluster-scan IN A 192.168.1.58 cluster-scan IN A 192.168.1.59 [root@dns named]# pwd/var/named/chroot/var/named[root@dns named]# cat localdomain.zone $TTL\t86400@\t\tIN SOA\tlocalhost root (\t\t\t\t\t42\t\t; serial (d. adams)\t\t\t\t\t3H\t\t; refresh\t\t\t\t\t15M\t\t; retry\t\t\t\t\t1W\t\t; expiry\t\t\t\t\t1D )\t\t; minimum\t        IN NS\t\tlocalhostlocalhost\tIN A\t\t127.0.0.1cluster-scan\tIN A\t\t192.168.1.57cluster-scan\tIN A\t\t192.168.1.58cluster-scan\tIN A\t\t192.168.1.59 启动dns [root@dns named]# /etc/init.d/named startStarting named:                                            [  OK  ] 到此dns服务器上的操作完毕。 在node1和node2的/etc/resolv.conf文件加上 nameserver 192.168.1.200 [root@node1 ~]# cat /etc/resolv.conf search localdomainnameserver 192.168.1.200nameserver 61.147.37.1 [root@node2 ~]# cat /etc/resolv.conf search localdomainnameserver 192.168.1.200nameserver 61.147.37.1 测试dns,node1和node2的hosts文件配置 #node1192.168.1.51     node1.localdomain         node1192.168.1.151    node1-vip.localdomain     node1-vip172.168.1.51     node1-priv.localdomain    node1-priv#node2192.168.1.52     node2.localdomain         node2192.168.1.152    node2-vip.localdomain     node2-vip172.168.1.52     node2-priv.localdomain    node2-priv#scanip192.168.1.57     cluster-scan.localdomain  cluster-scan192.168.1.58     cluster-scan.localdomain  cluster-scan192.168.1.59     cluster-scan.localdomain  cluster-scan node1 [root@node1 ~]# nslookup 192.168.1.57Server:\t\t192.168.1.200Address:\t192.168.1.200#5357.1.168.192.in-addr.arpa\tname = cluster-scan.localdomain.[root@node1 ~]# nslookup 192.168.1.58Server:\t\t192.168.1.200Address:\t192.168.1.200#5358.1.168.192.in-addr.arpa\tname = cluster-scan.localdomain.[root@node1 ~]# nslookup 192.168.1.59Server:\t\t192.168.1.200Address:\t192.168.1.200#5359.1.168.192.in-addr.arpa\tname = cluster-scan.localdomain.[root@node1 ~]# nslookup cluster-scanServer:\t\t192.168.1.200Address:\t192.168.1.200#53Name:\tcluster-scan.localdomainAddress: 192.168.1.58Name:\tcluster-scan.localdomainAddress: 192.168.1.59Name:\tcluster-scan.localdomainAddress: 192.168.1.57[root@node1 ~]# nslookup cluster-scan.localdomainServer:\t\t192.168.1.200Address:\t192.168.1.200#53Name:\tcluster-scan.localdomainAddress: 192.168.1.57Name:\tcluster-scan.localdomainAddress: 192.168.1.58Name:\tcluster-scan.localdomainAddress: 192.168.1.59 node2 [root@node2 ~]# nslookup 192.168.1.57Server:\t\t192.168.1.200Address:\t192.168.1.200#5357.1.168.192.in-addr.arpa\tname = cluster-scan.localdomain.[root@node2 ~]# nslookup 192.168.1.58Server:\t\t192.168.1.200Address:\t192.168.1.200#5358.1.168.192.in-addr.arpa\tname = cluster-scan.localdomain.[root@node2 ~]# nslookup 192.168.1.59Server:\t\t192.168.1.200Address:\t192.168.1.200#5359.1.168.192.in-addr.arpa\tname = cluster-scan.localdomain.[root@node2 ~]# nslookup cluster-scanServer:\t\t192.168.1.200Address:\t192.168.1.200#53Name:\tcluster-scan.localdomainAddress: 192.168.1.59Name:\tcluster-scan.localdomainAddress: 192.168.1.57Name:\tcluster-scan.localdomainAddress: 192.168.1.58[root@node2 ~]# nslookup cluster-scan.localdomainServer:\t\t192.168.1.200Address:\t192.168.1.200#53Name:\tcluster-scan.localdomainAddress: 192.168.1.58Name:\tcluster-scan.localdomainAddress: 192.168.1.59Name:\tcluster-scan.localdomainAddress: 192.168.1.57 dns测试通过","title":"使用UDEV在Oracle Linux 6上安装Oracle 11g RAC(11.2.0.3) (一)"},{"content":"长时间不操作页面后，再操作时程序就会报错，异常如下：   com.mysql.jdbc.exceptions.jdbc4.CommunicationsException:Communications link failure Thelast packet successfully received from the server was 8,064,672 millisecondsago. The last packet sent successfully to the server was 8,064,672 millisecondsago. at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) atsun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39) atsun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27) at java.lang.reflect.Constructor.newInstance(Constructor.java:513) at com.mysql.jdbc.Util.handleNewInstance(Util.java:409) at com.mysql.jdbc.SQLError.createCommunicationsException(SQLError.java:1122) at com.mysql.jdbc.MysqlIO.send(MysqlIO.java:3317) at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1941) at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2114) at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2696) atcom.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:2105) at com.mysql.jdbc.PreparedStatement.executeQuery(PreparedStatement.java:2264) at org.apache.commons.dbcp.DelegatingPreparedStatement.executeQuery(DelegatingPreparedStatement.java:96) atorg.apache.commons.dbcp.DelegatingPreparedStatement.executeQuery(DelegatingPreparedStatement.java:96) atorg.apache.commons.dbcp.DelegatingPreparedStatement.executeQuery(DelegatingPreparedStatement.java:96) ... Caused by: java.net.SocketException: Connection reset by peer: socket writeerror at java.net.SocketOutputStream.socketWrite0(Native Method) at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:92) at java.net.SocketOutputStream.write(SocketOutputStream.java:136) at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:65) at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:123) at com.mysql.jdbc.MysqlIO.send(MysqlIO.java:3298) ... 34 common frames omitted   原因是DBCP保持连接的超时时间比MySQL连接超时时间长。mysql配置中的wait_timeout值一定要大于等于连接池的idle_timeout值，否则mysql会在wait_timeout的时间后关闭连接，然而连接池还认为该连接可用，这样就会产生异常。   通过MySQL客户端连到服务器，查看目前的配置。   参考资料   1.      DBCP配置 http://commons.apache.org/dbcp/configuration.html http://wenku.baidu.com/view/06c94707de80d4d8d15a4f9a.html   2.      MySQL连接空闲超过8小时DBCP造成的异常如何解决 http://database.51cto.com/art/201107/276325.htm   3.      MySQL数据库连接超时(wait_timeout)问题的处理 http://sarin.iteye.com/blog/580311  ","title":"MySQL自动关闭连接导致DBCP报错"},{"content":"  count(1)与count(*)比较： 如果你的数据表没有主键，那么count(1)比count(*)快 如果有主键的话，那主键（联合主键）作为count的条件也比count(*)要快 如果你的表只有一个字段的话那count(*)就是最快的啦 count(*) count(1) 两者比较。主要还是要count(1)所相对应的数据字段。 如果count(1)是聚索引,id,那肯定是count(1)快。但是差的很小的。 因为count(*),自动会优化指定到那一个字段。所以没必要去count(?)，用count(*),sql会帮你完成优化的count详解：count(*)将返回表格中所有存在的行的总数包括值为null的行，然而count(列名)将返回表格中除去null以外的所有行的总数(有默认值的列也会被计入）.distinct 列名,得到的结果将是除去值为null和重复数据后的结果----------------------------------------------------------------------------------------------------------------举例演示如下:SQL> create table test2 (3 ename varchar2(10),4 sal number(4)5 );表已创建。SQL> insert into test values('fxe1',90);已创建 1 行。SQL> insert into test(ename) values('fxe2');已创建 1 行。SQL> insert into test(ename) values('fxe3');已创建 1 行。SQL> insert into test(ename) values('fxe4');已创建 1 行。SQL> insert into test values('fxe5',80);已创建 1 行。SQL> insert into test values('fxe6',80);已创建 1 行。SQL> select * from test;ENAME SAL---------- ----------fxe1 90fxe2fxe3fxe4fxe5 80fxe6 80SQL> select count(*) from test;COUNT(*)----------6SQL> select count(sal) from test;COUNT(SAL)----------3SQL> select count(distinct sal) from test;COUNT(DISTINCTSAL)------------------2SQL> select distinct sal from test;SAL----------8090   ","title":"Oracle 中count(1) 和count(*) 的区别"},{"content":"参考http://cycnet.blog.51cto.com/117809/812625 1：执行sudo apt-get install mysql-server my-client进行安装 2：安装过程中会弹出确认界面，使用tab键转到ok上，然后按enter即可 3：在安装过程中，会弹出一个界面要求输入mysql的root的密码，这里一定输入，省得安装后再设密码了 如果没设密码，那么mysql的root密码就是空了，安装完以后还可以再设置。 4：登录数据库命令：mysql -u root -p 回车后，输入我们前面所设的密码，就可以登录成功，如果前面没有设置那就是空，我们一般都要再root用户下进行操作，才有权限，建立表格等。 5：修改root密码 使用mysqladmin，这是前面声明的一个特例。  mysqladmin -u root -p password mypasswd  输入这个命令后，需要输入root的原密码，然后root的密码将改为mypasswd。  http://www.linuxdiyf.com/viewarticle.php?id=620 6：以root用户登录以后就可以进行mysql操作了 8：从本地文本文件导入数据 http://www.jb51.net/article/21117.htm 查了些资料才发现Load Data的权限不对，有两种方法可以解决： 1、通过在/etc/mysql/my.cnf文件中添加local-infile = 1来修改权限是的可以加载本地文件。当然也可以通过local-infile = 0来禁止掉。修改my.cnf后必须重启mysql。 2、通过启动时，>mysql -uroot -ppassword --local-infile = [0|1] 来修改权限。 9：常用mysql操作 一、库操作1、、创建数据库命令：create database <数据库名>例如：建立一个名为test的数据库mysql> create database test; 2、显示所有的数据库命令：show databasesmysql> show databases;3、删除数据库命令：drop database <数据库名>例如：删除名为 test的数据库mysql> drop database test;4、连接数据库命令： use <数据库名>例如：如果test数据库存在，尝试存取它：mysql> use test;屏幕提示：Database changed5、查看当前使用的数据库mysql> select database();6、当前数据库包含的表信息：mysql> show tables; 一、mysql服务操作 0、查看数据库版本 sql-> status; 1、net start mysql //启动mysql服务 2、net stop mysql //停止mysql服务　 3、mysql -h主机地址 -u用户名 －p用户密码 //进入mysql数据库 4、quit //退出mysql操作 5、mysqladmin -u用户名 -p旧密码 password 新密码 //更改密码 6、grant select on 数据库.* to 用户名@登录主机 identified by \"密码\" //增加新用户 exemple: 例2、增加一个用户test2密码为abc,让他只可以在localhost上登录，并可以对数据库mydb进行查询、插入、修改、删除的操作 （localhost指本地主机，即MYSQL数据库所在的那台主机），这样用户即使用知道test2的密码，他也无法从internet上直接访问数据 库，只能通过MYSQL主机上的web页来访问了。 grant select,insert,update,delete on mydb.* to test2@localhost identified by \"abc\"; 如果你不想test2有密码，可以再打一个命令将密码消掉。 grant select,insert,update,delete on mydb.* to test2@localhost identified by \"\"; 二、数据库操作 1、show databases; //列出数据库 2、use database_name //使用database_name数据库 3、create database data_name //创建名为data_name的数据库 4、drop database data_name //删除一个名为data_name的数据库 三、表操作 1、show databases;//列出所有数据库 use 数据库名; //到达某一数据库 show tables //列出所有表 create table tab_name( id int(10) not null auto_increment primary key, name varchar(40), pwd varchar(40) ) charset=gb2312; 创建一个名为tab_name的新表 2、drop table tab_name 删除名为tab_name的数据表 3、describe tab_name //显示名为tab_name的表的数据结构 4、show columns from tab_name //同上 5、delete from tab_name //将表tab_name中的记录清空 6、select * from tab_name //显示表tab_name中的记录 7、mysqldump -uUSER -pPASSWORD --no-data DATABASE TABLE > table.sql //复制表结构 四、修改表结构 1、 ALTER TABLE tab_name ADD PRIMARY KEY (col_name) 说明：更改表得的定义把某个栏位设为主键。 2、ALTER TABLE tab_name DROP PRIMARY KEY (col_name) 说明：把主键的定义删除 3、 alter table tab_name add col_name varchar(20); //在tab_name表中增加一个名为col_name的字段且类型为varchar(20) 4、alter table tab_name drop col_name //在tab_name中将col_name字段删除 5、alter table tab_name modify col_name varchar(40) not null //修改字段属性，注若加上not null则要求原字段下没有数据 SQL Server200下的写法是：Alter Table table_name Alter Column col_name varchar(30) not null; 6、如何修改表名：alter table tab_name rename to new_tab_name 7、如何修改字段名：alter table tab_name change old_col new_col varchar(40); //必须为当前字段指定数据类型等属性，否则不能修改 8、create table new_tab_name like old_tab_name //用一个已存在的表来建新表，但不包含旧表的数据 五、数据的备份与恢复 导入外部数据文本: 1.执行外部的sql脚本 当前数据库上执行:mysql < input.sql 指定数据库上执行:mysql [表名] < input.sql 2.数据传入命令 load data local infile \"[文件名]\" into table [表名]; 备份数据库：(dos下) mysqldump --opt school>school.bbb mysqldump -u [user] -p [password] databasename > filename (备份) mysql -u [user] -p [password] databasename < filename (恢复) 六、卸载 卸载mysql:sudo apt-get remove mysql-server mysql-client sudo apt-get autoremove //主键549830479    alter table tabelname add new_field_id int(5) unsigned default 0 not null auto_increment ,add primary key (new_field_id); //增加一个新列549830479    alter table t2 add d timestamp;alter table infos add ex tinyint not null default '0'; //删除列549830479    alter table t2 drop column c; //重命名列549830479    alter table t1 change a b integer; //改变列的类型549830479    alter table t1 change b b bigint not null;alter table infos change list list tinyint not null default '0'; //重命名表549830479    alter table t1 rename t2; 加索引549830479    mysql> alter table tablename change depno depno int(5) not null;mysql> alter table tablename add index 索引名 (字段名1[，字段名2 …]);mysql> alter table tablename add index emp_name (name); 加主关键字的索引549830479 mysql> alter table tablename add primary key(id); 加唯一限制条件的索引549830479   mysql> alter table tablename add unique emp_name2(cardnumber); 删除某个索引549830479    mysql>alter table tablename drop index emp_name; 修改表：549830479 增加字段：549830479    mysql> ALTER TABLE table_name ADD field_name field_type; 修改原字段名称及类型：549830479    mysql> ALTER TABLE table_name CHANGE old_field_name new_field_name field_type; 删除字段：549830479    mysql> ALTER TABLE table_name DROP field_name;","title":"linux下mysql安装和使用"},{"content":"      相同点：       truncate 和不带 where 子句的 delete,以及 drop 都会删除表内的数据       不同点：       1. truncate 和 delete 只删除数据不删除表的结构(定义)             drop 语句将删除表的结构被依赖的约束(constrain)、触发器(trigger)、索引(index);依赖于该表的存储过程/函数将保留,但是变为 invalid 状态。       2. delete 语句是数据库操作语言(dml),这个操作会放到 rollback segement 中,事务提交之后才生效;如果有相应的 trigger,执行的时候将被触发。          truncate、drop 是数据库定义语言(ddl),操作立即生效,原数据不放到 rollback segment 中,不能回滚,操作不触发 trigger。       3.delete 语句不影响表所占用的 extent,高水线(high watermark)保持原位置不动          显然drop 语句将表所占用的空间全部释放。          truncate 语句缺省情况下见空间释放到 minextents个 extent,除非使用reuse storage;truncate 会将高水线复位(回到最开始)。       4.速度,一般来说: drop> truncate > delete       5.安全性：小心使用 drop 和 truncate,尤其没有备份的时候.否则哭都来不及         使用上,想删除部分数据行用 delete,注意带上where子句. 回滚段要足够大.         想删除表,当然用 drop         想保留表而将所有数据删除,如果和事务无关,用truncate即可。如果和事务有关,或者想触发trigger,还是用delete。         如果是整理表内部的碎片,可以用truncate跟上reuse stroage,再重新导入/插入数据。","title":"SQL中drop,delete和truncate的异同"},{"content":"rman 迁移ASM到异机文件系统实战   环境说明： 源库：192.168.0.10 目标库：192.168.0.11   源库备份： RMAN> run { 2> allocate channel c1 device type disk; 3> allocate channel c2 device type disk; 4> backup database format '/home/oracle/full_database%U' include current controlfile; 5> sql 'alter system archive log current';  6> backup archivelog all format '/home/oracle/archivelog_%U'; 7> crosscheck backup; 8> delete noprompt obsolete; 9> release channel c1; 10> release channel c2; 11> }   复制备份集到备库： scp /home/oracle/full* oracle@192.168.0.11:/home/oracle/target_bk/ scp /home/oracle/archive* oracle@192.168.0.11:/home/oracle/target_bk/ [oracle@targetdb target_bk]$ ls archivelog_0rnu4jbf_1_1  full_database0nnu4ja0_1_1  full_database0pnu4jb4_1_1 archivelog_0snu4jbf_1_1  full_database0onu4ja0_1_1  full_database0qnu4jb5_1_1   目标库操作 [oracle@targetdb sourcedb]$ mkdir {a,b,c,u}dump [oracle@targetdb sourcedb]$ ls adump  bdump  cdump  udump   [oracle@targetdb oradata]$ mkdir sourcedb [oracle@targetdb oradata]$ ls sourcedb  [oracle@targetdb oradata]$ cd sourcedb/ [oracle@targetdb sourcedb]$ mkdir arch [oracle@targetdb sourcedb]$ ls arch   开始恢复： 因为还没有参数文件，先使用rman 无参数启动 export ORACLE_SID=sourcedb RMAN> startup nomount;      startup failed: ORA-01078: failure in processing system parameters LRM-00109: could not open parameter file '/u01/oracle/product/10.2.0/dbs/initsourcedb.ora'   starting Oracle instance without parameter file for retrival of spfile Oracle instance started   Total System Global Area     159383552 bytes   Fixed Size                     1218268 bytes Variable Size                 54528292 bytes Database Buffers             100663296 bytes Redo Buffers                   2973696 bytes   RMAN> exit   Recovery Manager complete.   Rman 默认启动了一个名字为DUMMY的实例 [oracle@targetdb target_bk]$ rman target / Recovery Manager: Release 10.2.0.1.0 - Production on Sun Dec 30 04:40:27 2012 Copyright (c) 1982, 2005, Oracle.  All rights reserved. connected to target database: DUMMY (not mounted) RMAN> [oracle@targetdb target_bk]$ ll -hr total 596M -rw-r--r-- 1 oracle oinstall  96K Dec 30 03:57 full_database0qnu4jb5_1_1 -rw-r--r-- 1 oracle oinstall 6.8M Dec 30 03:57 full_database0pnu4jb4_1_1 -rw-r--r-- 1 oracle oinstall 216M Dec 30 03:57 full_database0onu4ja0_1_1 -rw-r--r-- 1 oracle oinstall 373M Dec 30 03:57 full_database0nnu4ja0_1_1 -rw-r--r-- 1 oracle oinstall 2.5K Dec 30 03:56 archivelog_0snu4jbf_1_1 -rw-r--r-- 1 oracle oinstall 554K Dec 30 03:56 archivelog_0rnu4jbf_1_1   参数文件在哪个备份集呢？可以到原库上通过list backup 查看，有经验的查看备份集大小即可判断出。 [oracle@targetdb target_bk]$ rman target / Recovery Manager: Release 10.2.0.1.0 - Production on Sun Dec 30 04:41:43 2012 Copyright (c) 1982, 2005, Oracle.  All rights reserved. connected to target database: DUMMY (not mounted) RMAN> restore spfile from '/home/oracle/target_bk/full_database0qnu4jb5_1_1';   Starting restore at 30-DEC-12 using target database control file instead of recovery catalog allocated channel: ORA_DISK_1 channel ORA_DISK_1: sid=36 devtype=DISK channel ORA_DISK_1: autobackup found: /home/oracle/target_bk/full_database0qnu4jb5_1_1 channel ORA_DISK_1: SPFILE restore from autobackup complete Finished restore at 30-DEC-12   RMAN> shutdown immediate;   Oracle instance shut down   RMAN>   恢复控制文件 使用刚刚恢复出来的参数文件启库： [oracle@targetdb target_bk]$ rman target /   Recovery Manager: Release 10.2.0.1.0 - Production on Sun Dec 30 04:45:54 2012   Copyright (c) 1982, 2005, Oracle.  All rights reserved.   connected to target database (not started)   RMAN> startup nomount   Oracle instance started   Total System Global Area     167772160 bytes   Fixed Size                     1218316 bytes Variable Size                 75499764 bytes Database Buffers              88080384 bytes Redo Buffers                   2973696 bytes   RMAN>  restore controlfile to '/u01/oracle/oradata/sourcedb/controlfile01.ctl' from '/home/oracle/target_bk/full_database0pnu4jb4_1_1';   Starting restore at 30-DEC-12 using channel ORA_DISK_1   channel ORA_DISK_1: restoring control file channel ORA_DISK_1: restore complete, elapsed time: 00:00:01 Finished restore at 30-DEC-12   到sqlplus 下修改参数文件位置： SQL> show parameter control   NAME                                 TYPE        VALUE ------------------------------------ ----------- ------------------------------ control_file_record_keep_time        integer     7 control_files                        string      +DG1/sourcedb/controlfile/cont                                                  rol01.ctl, +DG1/sourcedb/contr                                                  olfile/control02.ctl   SQL> alter system set control_files='/u01/oracle/oradata/sourcedb/control01.ctl','/u01/oracle/oradata/sourcedb/control02.ctl' scope=spfile; System altered.     注册备份集中，如果备份集中放在和原库相同目录可以省略这一步： RMAN> catalog  start with '/home/oracle/target_bk/';   Starting implicit crosscheck backup at 30-DEC-12 using target database control file instead of recovery catalog allocated channel: ORA_DISK_1 channel ORA_DISK_1: sid=155 devtype=DISK Crosschecked 7 objects Finished implicit crosscheck backup at 30-DEC-12   Starting implicit crosscheck copy at 30-DEC-12 using channel ORA_DISK_1 Crosschecked 6 objects Finished implicit crosscheck copy at 30-DEC-12   searching for all files in the recovery area cataloging files... no files cataloged   searching for all files that match the pattern /home/oracle/target_bk/   List of Files Unknown to the Database ===================================== File Name: /home/oracle/target_bk/archivelog_0snu4jbf_1_1 File Name: /home/oracle/target_bk/full_database0pnu4jb4_1_1 File Name: /home/oracle/target_bk/full_database0nnu4ja0_1_1 File Name: /home/oracle/target_bk/full_database0onu4ja0_1_1 File Name: /home/oracle/target_bk/full_database0qnu4jb5_1_1 File Name: /home/oracle/target_bk/archivelog_0rnu4jbf_1_1   Do you really want to catalog the above files (enter YES or NO)? yes cataloging files... cataloging done   List of Cataloged Files ======================= File Name: /home/oracle/target_bk/archivelog_0snu4jbf_1_1 File Name: /home/oracle/target_bk/full_database0pnu4jb4_1_1 File Name: /home/oracle/target_bk/full_database0nnu4ja0_1_1 File Name: /home/oracle/target_bk/full_database0onu4ja0_1_1 File Name: /home/oracle/target_bk/full_database0qnu4jb5_1_1 File Name: /home/oracle/target_bk/archivelog_0rnu4jbf_1_1   恢复数据文件： run { allocate channel c1 device type disk; allocate channel c2 device type disk; set newname for datafile '+DG1/sourcedb/datafile/system01.dbf' to '/u01/oracle/oradata/sourcedb/system01.dbf'; set newname for datafile '+DG1/sourcedb/datafile/undotbs301.dbf' to '/u01/oracle/oradata/sourcedb/undotbs301.dbf'; set newname for datafile '+DG1/sourcedb/datafile/users01.dbf' to  '/u01/oracle/oradata/sourcedb/users01.dbf'; set newname for datafile  '+DG1/sourcedb/datafile/sysaux01.dbf' to '/u01/oracle/oradata/sourcedb/sysaux01.dbf'; set newname for datafile '+DG1/sourcedb/datafile/example01.dbf' to '/u01/oracle/oradata/sourcedb/example01.dbf'; set newname for datafile '+DG1/sourcedb/datafile/gguser.dbf' to '/u01/oracle/oradata/sourcedb/gguser.dbf'; restore database; switch datafile all; release channel c1; release channel c2; }     allocated channel: c1 channel c1: sid=155 devtype=DISK   allocated channel: c2 channel c2: sid=153 devtype=DISK   executing command: SET NEWNAME   executing command: SET NEWNAME   executing command: SET NEWNAME   executing command: SET NEWNAME   executing command: SET NEWNAME   executing command: SET NEWNAME   Starting restore at 30-DEC-12   channel c1: starting datafile backupset restore channel c1: specifying datafile(s) to restore from backup set restoring datafile 00001 to /u01/oracle/oradata/sourcedb/system01.dbf restoring datafile 00002 to /u01/oracle/oradata/sourcedb/undotbs301.dbf restoring datafile 00004 to /u01/oracle/oradata/sourcedb/users01.dbf channel c1: reading from backup piece /home/oracle/target_bk/full_database0nnu4ja0_1_1 channel c2: starting datafile backupset restore channel c2: specifying datafile(s) to restore from backup set restoring datafile 00003 to /u01/oracle/oradata/sourcedb/sysaux01.dbf restoring datafile 00005 to /u01/oracle/oradata/sourcedb/example01.dbf restoring datafile 00006 to /u01/oracle/oradata/sourcedb/gguser.dbf channel c2: reading from backup piece /home/oracle/target_bk/full_database0onu4ja0_1_1 channel c1: restored backup piece 1 piece handle=/home/oracle/target_bk/full_database0nnu4ja0_1_1 tag=TAG20121230T033424 channel c1: restore complete, elapsed time: 00:00:47 channel c2: restored backup piece 1 piece handle=/home/oracle/target_bk/full_database0onu4ja0_1_1 tag=TAG20121230T033424 channel c2: restore complete, elapsed time: 00:00:46 Finished restore at 30-DEC-12   datafile 1 switched to datafile copy input datafile copy recid=32 stamp=803367018 filename=/u01/oracle/oradata/sourcedb/system01.dbf datafile 2 switched to datafile copy input datafile copy recid=33 stamp=803367018 filename=/u01/oracle/oradata/sourcedb/undotbs301.dbf datafile 4 switched to datafile copy input datafile copy recid=34 stamp=803367018 filename=/u01/oracle/oradata/sourcedb/users01.dbf datafile 3 switched to datafile copy input datafile copy recid=35 stamp=803367018 filename=/u01/oracle/oradata/sourcedb/sysaux01.dbf datafile 5 switched to datafile copy input datafile copy recid=36 stamp=803367018 filename=/u01/oracle/oradata/sourcedb/example01.dbf datafile 6 switched to datafile copy input datafile copy recid=37 stamp=803367018 filename=/u01/oracle/oradata/sourcedb/gguser.dbf   released channel: c1   released channel: c2     RMAN> recover database;   Starting recover at 30-DEC-12 allocated channel: ORA_DISK_1 channel ORA_DISK_1: sid=155 devtype=DISK   starting media recovery   channel ORA_DISK_1: starting archive log restore to default destination channel ORA_DISK_1: restoring archive log archive log thread=1 sequence=12 channel ORA_DISK_1: reading from backup piece /home/oracle/target_bk/archivelog_0snu4jbf_1_1 channel ORA_DISK_1: restored backup piece 1 piece handle=/home/oracle/target_bk/archivelog_0snu4jbf_1_1 tag=TAG20121230T033511 channel ORA_DISK_1: restore complete, elapsed time: 00:00:02 channel ORA_DISK_1: starting archive log restore to default destination channel ORA_DISK_1: restoring archive log archive log thread=1 sequence=11 channel ORA_DISK_1: reading from backup piece /home/oracle/target_bk/archivelog_0rnu4jbf_1_1 channel ORA_DISK_1: restored backup piece 1 piece handle=/home/oracle/target_bk/archivelog_0rnu4jbf_1_1 tag=TAG20121230T033511 channel ORA_DISK_1: restore complete, elapsed time: 00:00:01 archive log filename=/u01/oracle/oradata/sourcedb/arch/1_11_803260244.dbf thread=1 sequence=11 archive log filename=/u01/oracle/oradata/sourcedb/arch/1_12_803260244.dbf thread=1 sequence=12 unable to find archive log archive log thread=1 sequence=13 RMAN-00571: =========================================================== RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS =============== RMAN-00571: =========================================================== RMAN-03002: failure of recover command at 12/30/2012 05:32:41 RMAN-06054: media recovery requesting unknown log: thread 1 seq 13 lowscn 743601   这里报找不到13号日志，因为在原库备份的时候13号日志还没归档，所以备份集中没有这个日志。   这里需要注意，因为控制文件记录的联机日志是放在ASM中，我们需要修改控制文件中联机日志的位置，可以通过rename 来修改，也可以通过重建控制文件来修改，这里我们使用重建控制文件： CREATE CONTROLFILE REUSE DATABASE \"SOURCEDB\" RESETLOGS FORCE LOGGING ARCHIVELOG     MAXLOGFILES 16     MAXLOGMEMBERS 3     MAXDATAFILES 100     MAXINSTANCES 8     MAXLOGHISTORY 292 LOGFILE   GROUP 1 '/u01/oracle/oradata/sourcedb/redo01.log'  SIZE 50M,   GROUP 2 '/u01/oracle/oradata/sourcedb/redo02.log'  SIZE 50M,   GROUP 3 '/u01/oracle/oradata/sourcedb/redo03.log'  SIZE 50M DATAFILE   '/u01/oracle/oradata/sourcedb/system01.dbf',   '/u01/oracle/oradata/sourcedb/undotbs301.dbf',   '/u01/oracle/oradata/sourcedb/sysaux01.dbf',   '/u01/oracle/oradata/sourcedb/users01.dbf',   '/u01/oracle/oradata/sourcedb/example01.dbf',   '/u01/oracle/oradata/sourcedb/gguser.dbf' CHARACTER SET ZHS16GBK ;   Alter database open resetlogs;   恢复完毕。  ","title":"rman 迁移ASM到异机文件系统实战"},{"content":"要点： 　　 Xml代码  数据库URL：jdbc:jtds:sqlserver://localhost:1433;DatabaseName=bid   　　驱动类：net.sourceforge.jtds.jdbc.Driver        　　----------------------------------------------------------------------- 　　对比： 　　//microsoft Java代码  Class.forName(\"com.microsoft.jdbc.sqlserver.SQLServerDriver\").newInstance();   String url = \"jdbc:microsoft:sqlserver://localhost:1433;DatabaseName=pubs\";   //jtds   Class.forName(\"net.sourceforge.jtds.jdbc.Driver\").newInstance();   String url = \"jdbc:jtds:sqlserver://localhost:1433;DatabaseName=pubs\";   //String url = \"jdbc:jtds:sqlserver://localhost:1433/pubs\";   String user = \"sa\";   String password = \"dog\";   Connection conn = DriverManager.getConnection(url, user, password);   Statement stmt = conn.createStatement(ResultSet.TYPE_SCROLL_SENSITIVE, ResultSet.CONCUR_UPDATABLE);   String sql = \"select top 10 * from titles\"; //titles为表名;   ResultSet rs = stmt.executeQuery(sql);    　　--------------------------------------------------------------------- 　　示例： 　　JAVA使用JTDS连接SQL2000问题 　　一般有以下几个方面： 　　1.WINDOWS防火墙屏蔽了1433端口 　　2.检查SQL2000是否使用的是1433端口 　　3.检查SQL2000是否升级到SP3以上版本（基本都是这个原因） 　　以下是使用JTDS连接SQL2000的代码段 　　连接SQL2000下的TheTest库 　　-------------------------------------------------------------- 　　public static Connection getConnection(){ Java代码  String dbDriver = \"net.sourceforge.jtds.jdbc.Driver\";   String strConnection = \"jdbc:jtds:sqlserver://localhost:1433/TheTest\";   String user = \"sa\";   String password = \"sa\";   Connection conn = null;   try{   //定义连接驱动   Class.forName(dbDriver);   }   catch(java.lang.ClassNotFoundException e){   System.err.println(\"DBconnection():\"+e.getMessage());   }   //--------连接SQL数据库------------------   try   {   conn = DriverManager.getConnection(strConnection,user,password);   }   catch(SQLException ex)   {   System.err.println(\"aq.executeQuery:\"+ex.getMessage());   }   return conn;   }   -----------------------以下为关闭连接--------------------------   public static void closeConnection(PreparedStatement ps,Connection conn,ResultSet rs){   try{   if (rs!=null){   rs.close();   }   if (ps!=null){   ps.close();   }   if (conn!=null){   conn.close();   }   }   catch(SQLException sqlerror){   sqlerror.printStackTrace();   }   }   public static void closeConnection(PreparedStatement ps,Connection conn){   try{   if (ps!=null){   ps.close();   }   if (conn!=null){   conn.close();   }   }   catch(SQLException sqlerror){   sqlerror.printStackTrace();   }   }   public static void closeConnection(Connection conn){   try{   if (conn!=null){   conn.close();   }   }   catch(SQLException sqlerror){   sqlerror.printStackTrace();   }   }  ","title":"用jtds连接SQL2008的方法"},{"content":"1 备份 @echo offset oracle_username=YOURORACLE_USERNAMEset oracle_password=YOUR_PASSWORDset local_tnsname=LOCAL_TNSNAMEset url=%oracle_username%/%oracle_password%if not %local_tnsname% == \"\" set url=%url%@%local_tnsname%rem 执行时请确保同一目录下无重名的文件exp %url% file=%oracle_username%.dmp log=%oracle_username%.log 将上述脚本保存为一个bat文件执行即可。脚本将local_tnsname指定的数据库中用户YOURORACLE_USERNAME的所有内容导出到YOURORACLE_USERNAME.dmp文件中，日志写到YOURORACLE_USERNAME.log中。 2 恢复 2.1 创建用户 第一步，把用户YOURORACLE_USERNAME（如果原来有此用户的话）彻底删除： DROP USER YOURORACLE_USERNAME CASCADE 第二步，创建表空间，根据需要设置YOUR_TABLESPACE，size和maxsize等。 create tablespace YOUR_TABLESPACEloggingdatafile 'D:\\oracle\\product\\10.2.0\\oradata\\YOUR_TABLESPACE.dbf'size 512mautoextend onnext 64m maxsize 1024mextent management local; 第三步，创建该用户 CREATE USER YOURORACLE_USERNAMEIDENTIFIED BY YOUR_PASSWORDDEFAULT TABLESPACE YOUR_TABLESPACETEMPORARY TABLESPACE TEMP 第四步，赋予权限 GRANT DBA TO YOURORACLE_USERNAME WITH ADMIN OPTION 2.2 用IMP恢复 命令行下执行此脚本 imp YOURORACLE_USERNAME/YOUR_PASSWORD@LOCAL_TNSNAME FILE=YOURORACLE_USERNAME.DMP LOG=YOURORACLE_USERNAME.LOG FULL=Y 3 其他相关内容 使用windows批处理调用sqlplus执行SQL语句： @echo offrem sqlplus username/password@service @mysql.sqlsqlplus YOURORACLE_USERNAME/YOUR_PASSWORD@LOCAL_TNSNAME @20121228.sqlexit其中20121228.sql是需要执行的sql脚本。 注：文中YOURORACLE_USERNAME，YOUR_PASSWORD以及LOCAL_TNSNAME需要使用时根据实际情况替换为特定的字符串。","title":"Oracle备份与恢复脚本"},{"content":"mysqldump是mysql用于转存储数据库的实用程序。它主要产生一个SQL脚本，其中包含从头重新创建数据库所必需的命令CREATE TABLE INSERT等。对于导出的文件，可使用SOURCE命令导入数据库。 使用mysqldump -?命令，可以查看mysqldump的具体参数及详细说明。下表是一些常见的选项： -A, --all-databases Dump all the databases. This will be same as --databases with all databases selected. 导出全部数据库 -Y, --all-tablespaces Dump all the tablespaces. 导出全部表空间 -y, --no-tablespaces Do not dump any tablespace information. 不导出任何表空间信息 --add-drop-database Add a 'DROP DATABASE' before each create. 每个数据库创建之前添加drop数据库语句 --add-drop-table Add a 'drop table' before each create. 每个数据表创建之前添加drop数据表语句。(默认为打开状态，使用--skip-add-drop-table取消选项) --add-locks Add locks around insert statements. 在每个表导出之前增加LOCK TABLES并且之后UNLOCK  TABLE。(默认为打开状态，使用--skip-add-locks取消选项) --allow-keywords Allow creation of column names that are keywords. 允许创建是关键词的列名字。 --character-sets-dir=name Directory where character sets are. 字符集文件的目录 -i, --comments Write additional information. 附加注释信息。默认为打开，可以用--skip-comments取消 --compatible=name Change the dump to be compatible with a given mode. By default tables are dumped in a format optimized for MySQL. Legal modes are: ansi, mysql323, mysql40, postgresql, oracle, mssql, db2, maxdb, no_key_options, no_table_options, no_field_options. One can use several modes separated by commas. Note: Requires MySQL server version 4.1.0 or higher. This option is ignored with earlier server versions. 导出的数据将和其它数据库或旧版本的MySQL 相兼容。值可以为ansi、mysql323、mysql40、postgresql、oracle、mssql、db2、maxdb、no_key_options、no_tables_options、no_field_options等。要使用几个值，用逗号将它们隔开。它并不保证能完全兼容，而是尽量兼容。 --compact Give less verbose output (useful for debugging). Disables structure comments and header/footer constructs.  Enables options --skip-add-drop-table --no-set-names --skip-disable-keys --skip-add-locks 导出更少的输出信息(用于调试)。去掉注释和头尾等结构。可以使用选项：--skip-add-drop-table  --skip-add-locks --skip-comments --skip-disable-keys -c, --complete-insert Use complete insert statements. 使用完整的insert语句(包含列名称)。这么做能提高插入效率，但是可能会受到max_allowed_packet参数的影响而导致插入失败。 -C, --compress Use compression in server/client protocol. 在客户端和服务器之间启用压缩传递所有信息 --create-options Include all MySQL specific create options. 在CREATE TABLE语句中包括所有MySQL特性选项。(默认为打开状态) -B, --databases To dump several databases. Note the difference in usage; In this case no tables are given. All name arguments are regarded as databasenames. 'USE db_name;' will be included in the output. 导出数据库。参数后面所有名字参量都被看作数据库名。 -#, --debug[=#] This is a non-debug version. Catch this and exit 输出debug信息，用于调试。 --debug-check Check memory and open file usage at exit. 检查内存和打开文件使用说明并退出。 --debug-info Print some debug info at exit. 输出调试信息并退出 --default-character-set=name Set the default character set. 设置默认字符集 --delayed-insert Insert rows with INSERT DELAYED; 采用延时插入方式（INSERT DELAYED）导出数据 --delete-master-logs Delete logs on master after backup. This automatically enables --master-data. master备份后删除日志. 这个参数将自动激活--master-data。 -K, --disable-keys '/*!40000 ALTER TABLE tb_name DISABLE KEYS */; and '/*!40000 ALTER TABLE tb_name ENABLE KEYS */; will be put in the output. 对于每个表，用/*!40000 ALTER TABLE tbl_name DISABLE KEYS */;和/*!40000 ALTER TABLE tbl_name ENABLE KEYS */;语句引用INSERT语句。这样可以更快地导入dump出来的文件，因为它是在插入所有行后创建索引的。该选项只适合MyISAM表，默认为打开状态。 -E, --events Dump events. 导出事件。 -e, --extended-insert Allows utilization of the new, much faster INSERT syntax. 使用具有多个VALUES列的INSERT语法。这样使导出文件更小，并加速导入时的速度。默认为打开状态，使用--skip-extended-insert取消选项。 --fields-terminated-by=name Fields in the textfile are terminated by ... 导出文件中忽略给定字段。与--tab选项一起使用，不能用于--databases和--all-databases选项 --fields-enclosed-by=name Fields in the importfile are enclosed by ... 输出文件中的各个字段用给定字符包裹。与--tab选项一起使用，不能用于--databases和--all-databases选项 --fields-optionally-enclosed-by=name Fields in the i.file are opt. enclosed by ... 输出文件中的各个字段用给定字符选择性包裹。与--tab选项一起使用，不能用于--databases和--all-databases选项 --fields-escaped-by=name Fields in the i.file are escaped by ... 输出文件中的各个字段忽略给定字符。与--tab选项一起使用，不能用于--databases和--all-databases选项 -F, --flush-logs Flush logs file in server before starting dump. Note that if you dump many databases at once (using the option --databases= or --all-databases), the logs will be flushed for each database dumped. The exception is when using --lock-all-tables or --master-data: in this case the logs will be flushed only once, corresponding to the moment all tables are locked. So if you want your dump and the log flush to happen at the same exact moment you should use --lock-all-tables or --master-data with --flush-logs 开始导出之前刷新日志。 --flush-privileges Emit a FLUSH PRIVILEGES statement after dumping the mysql database.  This option should be used any time the dump contains the mysql database and any other database that depends on the data in the mysql database for proper restore. 在导出mysql数据库之后，发出一条FLUSH  PRIVILEGES 语句。为了正确恢复，该选项应该用于导出mysql数据库和依赖mysql数据库数据的任何时候。 -f, --force Continue even if we get an sql-error. 在导出过程中忽略出现的SQL错误。 -?, --help Display this help message and exit. 显示帮助信息并退出。 --hex-blob Dump binary strings (BINARY, VARBINARY, BLOB) in hexadecimal format. 使用十六进制格式导出二进制字符串字段。如果有二进制数据就必须使用该选项。影响到的字段类型有BINARY、VARBINARY、BLOB。 -h, --host=name Connect to host. 需要导出的主机信息 --ignore-table=name Do not dump the specified table. To specify more than one table to ignore, use the directive multiple times, once for each table.  Each table must be specified with both database and table names, e.g. --ignore-table=database.table 不导出指定表。指定忽略多个表时，需要重复多次，每次一个表。每个表必须同时指定数据库和表名。例如：--ignore-table=database.table1 --ignore-table=database.table2 …… --insert-ignore Insert rows with INSERT IGNORE. 在插入行时使用INSERT IGNORE语句. --lines-terminated-by=name Lines in the i.file are terminated by ... 输出文件的每行用给定字符串划分。与--tab选项一起使用，不能用于--databases和--all-databases选项。 -x, --lock-all-tables Locks all tables across all databases. This is achieved by taking a global read lock for the duration of the whole dump. Automatically turns --single-transaction and --lock-tables off. 提交请求锁定所有数据库中的所有表，以保证数据的一致性。这是一个全局读锁，并且自动关闭--single-transaction 和--lock-tables 选项。 -l, --lock-tables Lock all tables for read. 开始导出前，锁定所有表。用READ  LOCAL锁定表以允许MyISAM表并行插入。对于支持事务的表例如InnoDB和BDB，--single-transaction是一个更好的选择，因为它根本不需要锁定表。 请注意当导出多个数据库时，--lock-tables分别为每个数据库锁定表。因此，该选项不能保证导出文件中的表在数据库之间的逻辑一致性。不同数据库表的导出状态可以完全不同。 --log-error=name Append warnings and errors to given file. 附加警告和错误信息到给定文件 --no-autocommit Wrap tables with autocommit/commit statements. 使用autocommit/commit 语句包裹表 -n, --no-create-db 'CREATE DATABASE /*!32312 IF NOT EXISTS*/ db_name;' will not be put in the output. The above line will be added otherwise, if --databases or --all-databases option was given.}. 只导出数据，而不添加CREATE DATABASE 语句 -t, --no-create-info Don't write table creation info. 只导出数据，而不添加CREATE TABLE 语句 -d, --no-data No row information. 不导出任何数据，只导出数据库表结构 --opt Same as --add-drop-table, --add-locks, --create-options, --quick, --extended-insert, --lock-tables, --set-charset, and --disable-keys. Enabled by default, disable with --skip-opt. 等同于--add-drop-table,  --add-locks, --create-options, --quick, --extended-insert, --lock-tables,  --set-charset, --disable-keys 该选项默认开启,  可以用--skip-opt禁用. --order-by-primary Sorts each table's rows by primary key, or first unique key, if such a key exists.  Useful when dumping a MyISAM table to be loaded into an InnoDB table, but will make the dump itself take considerably longer. 如果存在主键，或者第一个唯一键，对每个表的记录进行排序。在导出MyISAM表到InnoDB表时有效，但会使得导出工作花费很长时间。 -p, --password[=name] Password to use when connecting to server. If password is not given it's solicited on the tty. 连接数据库密码 -W, --pipe Use named pipes to connect to server. 使用命名管道连接mysql(windows系统可用) -P, --port=# Port number to use for connection. 连接数据库端口号 --protocol=name The protocol of connection (tcp,socket,pipe,memory). 使用的连接协议，包括：tcp, socket, pipe, memory. -q, --quick Don't buffer query, dump directly to stdout. 不缓冲查询，直接导出到标准输出。默认为打开状态，使用--skip-quick取消该选项。 -Q, --quote-names Quote table and column names with backticks (`). 使用（`）引起表和列名。默认为打开状态，使用--skip-quote-names取消该选项。 --replace Use REPLACE INTO instead of INSERT INTO. 使用REPLACE INTO 取代INSERT INTO. -r, --result-file=name Direct output to a given file. This option should be used in MSDOS, because it prevents new line '\\n' from being converted to '\\r\\n' (carriage return + line feed). 直接输出到指定文件中。该选项应该用在使用回车换行对（\\\\r\\\\n）换行的系统上（例如：DOS，Windows）。该选项确保只有一行被使用。 -R, --routines Dump stored routines (functions and procedures). 导出存储过程以及自定义函数。 --set-charset Add 'SET NAMES default_character_set' to the output. Enabled by default; suppress with --skip-set-charset. 添加'SET NAMES  default_character_set'到输出文件。默认为打开状态，使用--skip-set-charset关闭选项。 -O, --set-variable=name Change the value of a variable. Please note that this option is deprecated; you can set variables directly with --variable-name=value. 设置变量的值 --dump-date Put a dump date to the end of the output. 添加DUMP时间到输出末尾 --skip-opt Disable --opt. Disables --add-drop-table, --add-locks, --create-options, --quick, --extended-insert, --lock-tables, --set-charset, and --disable-keys. 禁用–opt选项. -S, --socket=name Socket file to use for connection. 指定连接mysql的socket文件位置，默认路径/tmp/mysql.sock -T, --tab=name Creates tab separated textfile for each table to given path. (creates .sql and .txt files). NOTE: This only works if mysqldump is run on the same machine as the mysqld daemon. 为每个表在给定路径创建tab分割的文本文件。注意：仅仅用于mysqldump和mysqld服务器运行在相同机器上。 --tables Overrides option --databases (-B). 覆盖--databases (-B)参数，指定需要导出的表名。 --triggers Dump triggers for each dumped table 导出触发器。该选项默认启用，用--skip-triggers禁用它。 --tz-utc SET TIME_ZONE='+00:00' at top of dump to allow dumping of TIMESTAMP data when a server has data in different time zones or data is being moved between servers with different time zones. 在导出顶部设置时区TIME_ZONE='+00:00' ，以保证在不同时区导出的TIMESTAMP 数据或者数据被移动其他时区时的正确性。 -u, --user=name User for login if not current user. 指定连接的用户名。 -v, --verbose Print info about the various stages. 输出多种平台信息。 -V, --version Output version information and exit. 输出mysqldump版本信息并退出 -w, --where=name Dump only selected records; QUOTES mandatory! 只转储给定的WHERE条件选择的记录。请注意如果条件包含命令解释符专用空格或字符，一定要将条件引用起来。 -X, --xml                               Dump a database as well formed XML. 导出XML格式. 示例： 1、导出数据库下某个表的结构 C:\\Users\\qxl>mysqldump -uroot -p -d mydb t_user 2、按条件只导出表中的数据 C:\\Users\\qxl>mysqldump -uroot -p \"--where=id<10\" -t mydb t_user","title":"MYSQL入门学习之十九：MYSQLDUMP命令参数详解"},{"content":"1 从其它数据库迁移到PPAS时可迁移的数据库对象间下表     2 安装ppas时会有安装migreation toolkit的选项，可以选择安装，也可以到www.enterprisedb.com下载安装   3 编辑/opt/PostgresPlus/9.2AS/etc/toolkit.properties linux-np3p:/opt/PostgresPlus/9.2AS # cat -netc/toolkit.properties    SRC_DB_URL=jdbc:oracle:thin:@192.168.1.127:1521:orcl    SRC_DB_USER=testuser    SRC_DB_PASSWORD=testuserpw        TARGET_DB_URL=jdbc:edb://localhost:5444/testdb1    TARGET_DB_USER=testuser    TARGET_DB_PASSWORD=123456 linux-np3p:/opt/PostgresPlus/9.2AS #   4 拷贝oracle的jdbc接口驱动到/opt/PortgresPlus/9.2AS/jre/lib/ext里面 注意要拷贝和jre版本对应的驱动程序   5 迁移 linux-np3p:/opt/PostgresPlus/9.2AS/bin #./runMTK.sh testuser 源数据库连接信息... 连接=jdbc:oracle:thin:@192.168.1.127:1521:orcl 用户 =TESTUSER 密码=****** 目标数据库连接信息... 连接=jdbc:edb://localhost:5444/testdb2 用户 =testuser 密码=****** 正在连接源Oracle数据库服务器... 正在连接目标EnterpriseDB数据库服务器... 正在导入 Redwood 架构 testuser... 正在创建架构...testuser 正在创建表... 正在创建表: TEST1 已创建 1 个表。 正在以 8 MB  批次大小加载表数据... 正在加载表: TEST1... [TEST1] 已迁移 2 行。 [TEST1] 表数据加载摘要: 时间总计 (秒): 0.375 行数总计: 2 数据加载摘要: 时间总计 (秒): 1.111 行数总计: 2 大小总计 (MB): 0.0   已成功导入架构testuser。   正在创建用户:TESTUSER 创建用户 TESTUSER 时发生错误   在迁移进程中有一至多个架构对象无法导入。有关更多详细信息，请参阅迁移输出信息。   迁移日志已保存到/root/.enterprisedb/migration-toolkit/logs   ******************** 迁移摘要 ******************** Tables: 1 来自 1 Users: 0 来自 1   全部对象: 2 成功计数: 1 失败计数: 1   失败对象列表 ====================== Users -------------------- 1. TESTUSER     *************************************************************   6 查询迁移结果 linux-np3p:/opt/PostgresPlus/9.2AS/bin #./psql -U testuser testdb1 用户 testuser 的口令： psql (9.2.0.1) 输入\"help\" 来获取帮助信息.   testdb2=# select * from test1;  id|    xname     ----+--------------   1 |test / gaga   2 |test ／ gaga (2 行记录)   testdb2=#   7 下面是runMTK.sh的内容，可以看到调用了工具edb-migrationtoolkit.jar # ---------------------------------------------------------------------------- # -- # -- Copyright (c) 2004-2012 - EnterpriseDBCorporation.  All Rights Reserved. # -- #----------------------------------------------------------------------------   /opt/PostgresPlus/9.2AS/jre/bin/java -Dprop=../etc/toolkit.properties-jar edb-migrationtoolkit.jar \"$@\"   8 下面是migreationtoolkit的帮助信息，列出了可选参数   linux-np3p:/opt/PostgresPlus/9.2AS #jre/bin/java -jar bin/edb-migrationtoolkit.jar -help   EnterpriseDB Migration Toolkit (Build 46)   用法: runMTK [-选项] SCHEMA   若未指定任何选项，则将导入完整的架构。   其中，选项包括: -help              显示应用程序的命令行用法。 -version   显示应用程序版本信息。 -verbose [on|off] 以标准输出显示应用程序日志消息 (默认值: on)。   -schemaOnly   只导入架构对象定义。 -dataOnly       只导入表数据。若指定了 -tables，则只导入所选表的数据。注意: 如果对目标表定义了任何外键约束，则此选项需与 -truncLoad 选项一起使用。   -sourcedbtype db_type The -sourcedbtypeoption specifies the source database type. db_type may be one of the followingvalues: mysql, oracle, sqlserver, sybase, postgresql, enterprisedb. db_type iscase-insensitive. By default, db_type is oracle. -targetdbtype db_type The -targetdbtypeoption specifies the target database type. db_type may be one of the followingvalues: oracle, sqlserver, postgresql, enterprisedb. db_type iscase-insensitive. By default, db_type is enterprisedb.   -allTables 导入所有表。 -tables LIST    导入以逗号分隔的表列表。 -constraints     导入表约束。 -indexes  导入表索引。 -triggers  导入表触发器。 -allViews 导入所有视图。 -views LIST    导入以逗号分隔的视图列表。 -allProcs  导入所有存储过程。 -procs LIST    导入以逗号分隔的存储过程列表。 -allFuncs 导入所有函数。 -funcs LIST    导入以逗号分隔的函数列表。 -allPackages    导入所有包。 -packages LIST 导入以逗号分隔的包列表。 -allSequences  导入所有序列。 -sequences LIST 导入以逗号分隔的序列列表。 -targetSchema NAME 目标架构的名称 (默认: 目标架构以源架构命名)。 -allDBLinks    导入所有数据库链接。 -allSynonyms  It enables the migration of all public and private synonyms from anOracle database to an Advanced Server database. If a synonym with the same name already exists in the target database,the existing synonym will be replaced with the migrated version. -allPublicSynonyms       It enables the migration of all public synonyms from an Oracledatabase to an Advanced Server database. If a synonym with the same name already exists in the target database,the existing synonym will be replaced with the migrated version. -allPrivateSynonyms      It enables the migration of all private synonyms from an Oracledatabase to an Advanced Server database. If a synonym with the same name already exists in the target database,the existing synonym will be replaced with the migrated version.   -dropSchema [true|false] 若架构已存在于目标数据库中，则删除此架构 (默认值: false)。 -truncLoad      此选项对目标表禁用任何约束，并且在导入新数据之前先截断表中的数据。此选项只能与 -dataOnly 一起使用。 -safeMode      使用纯 SQL 语句，以安全模式传输数据。 -copyDelimiter       在加载表数据时，指定一个字符作为复制命令中的分隔符。默认值为 \\t -batchSize      指定“批量插入”要使用的“批次大小”。有效值为 1-1000，默认批次大小为 1000，如果出现“内存不足”异常，则可以降低此值 -cpBatchSize   指定复制命令要使用的“批次大小”，以 MB 为单位。有效值大于 0，默认批次大小为 8 MB -fetchSize       指定提取大小 (每次应从结果集中提取的行数)。当数据表含有数百万个行，而您想避免发生内存不足错误时，可以使用此选项。 -filterProp      包含表 where 子句的属性文件。 -skipFKConst  跳过外键约束的迁移。 -skipCKConst 跳过检查约束条件的迁移。 -ignoreCheckConstFilter       在缺省的情况下MTK不从Sybase中迁移检查约束和缺省子句，使用这个选项可以关闭这个过滤功能。 -fastCopy       略过 WAL 日志记录，以优化方式执行 COPY 操作，默认情况下禁用。 -customColTypeMapping LIST     使用以分号分隔的列表表示的自定义类型映射，其中每个条目都使用 COL_NAME_REG_EXPR=TYPE 对来指定，例如 .*ID=INTEGER -customColTypeMappingFile PROP_FILE   由属性文件表示的自定义类型映射，其中每个条目都使用 COL_NAME_REG_EXPR=TYPE 对来指定，例如 .*ID=INTEGER -offlineMigration [DDL_PATH] 这将执行脱机迁移并将 DDL 脚本保存在文件中供以后执行。默认情况下，如果要求后跟-offlineMigration 选项以及自定义路径，则脚本文件将保存在用户主文件夹下。 -logDir LOG_PATH 指定用于保存日志文件的自定义路径。默认情况下，日志文件保存在工作目录中的“logs”文件夹下。 -copyViaDBLinkOra 此选项可用来通过使用 dblink_ora COPY 命令复制数据。此选项仅限用在从 Oracle 到 EnterpriseDB 迁移模式中。 -singleDataFile       Use single SQL file for offline data storage for all tables.This option cannot be used in COPY format. -allUsers 从源数据库导入所有用户和角色。 -users LIST 从源数据库导入选定用户/角色。LIST 是一个用逗号分隔的用户/角色名称列表，如 -users MTK,SAMPLE -allRules 从源数据库导入所有规则。 -rules LIST 从源数据库导入选定规则。 LIST 是一个用逗号分隔的名称列表，如 -rules high_sal_emp,low_sal_emp -allGroups 从源数据库导入所有组。 -groups LIST 从源数据库导入选定组。 LIST 是一个用逗号分隔的组名称列表，如 -groups acct_emp,mkt_emp -allDomains 从源数据库导入所有域、枚举和复合类型。 -domains LIST 从源数据库导入所选域、枚举和复合类型。 LIST 是一个用逗号分隔的域名称列表，如 -domainsd_email,d_dob, mood -objecttypes    导入用户定义的对象类型。 -replaceNullChar <CHAR> 如果空字符是列值得一部分，那么通过JDBC协议迁移数据就会失败.这个选项可以使用用户指定的字符来替代空字符串。 -importPartitionAsTable [LIST] 通过使用这个选项能够将Oracle中的分区表以常规表的形式导入到EnterpriseDB中。为了在所选择表集合上的应用规则，在选项后面应跟随以逗号分隔的表名列表。 -enableConstBeforeDataLoad 通过使用这个选项可以在数据导入前重新启用约束(和触发器).当要迁移的表在EnterpriseDB中对应的是一张分区表时，使用这个选项是非常有用的。 -checkFunctionBodies [true|false] 设置为 false 时，将禁用创建函数过程中的函数体验证，从而避免在函数包含向前参考时发生错误。 目标数据库为 Postgres/EnterpriseDB 时适用，默认值为 true。 -retryCount VALUE     指定 MTK 迁移由于跨架构相关性而失败的对象的重试次数。 VALUE 参数应该大于 0，默认值为 2。 -analyze 它将对目标 Postgres 或 Postgres Plus Advanced Server 数据库调用 ANALYZE 操作。 ANALYZE 收集用于有效查询计划的迁移表的统计信息。 -vacuumAnalyze    它将对目标 Postgres或 PostgresPlus Advanced Server 数据库调用 VACUUM 和 ANALYZE 操作。 VACUUM 回收非活动元组存储，ANALYZE 收集用于有效查询计划的迁移表的统计信息。 -loaderCount VALUE    指定并行执行数据加载的作业(线程)数目。 VALUE 参数应该大于 0，默认值为 1。   数据库连接信息: 应用程序将从文件toolkit.properties中读取源和目标数据库服务器的连接信息. 更多的信息参见MTK的自述文档.   linux-np3p:/opt/PostgresPlus/9.2AS #   9 如果看中午帮助信息有歧义就看下面的英文帮助信息吧 ot@host19.2AS]# jre/bin/java -jar bin/edb-migrationtoolkit.jar -help   EnterpriseDBMigration Toolkit (Build 46)   Usage: runMTK[-options] SCHEMA   If no option isspecified, the complete schema will be imported.   where optionsinclude: -help         Display the application command-lineusage. -version     Display the application versioninformation. -verbose[on|off] Display application log messages on standard output (default: on).   -schemaOnly     Import the schema object definitions only. -dataOnly  Import the table data only. When -tables is inplace, it imports data only for the selected tables. Note: If there are any FKconstraints defined on target tables, use -truncLoad option along with thisoption.   -sourcedbtypedb_type The -sourcedbtype option specifies the source database type. db_typemay be one of the following values: mysql, oracle, sqlserver, sybase,postgresql, enterprisedb. db_type is case-insensitive. By default, db_type isoracle. -targetdbtypedb_type The -targetdbtype option specifies the target database type. db_typemay be one of the following values: oracle, sqlserver, postgresql,enterprisedb. db_type is case-insensitive. By default, db_type is enterprisedb.   -allTables   Import all tables. -tables LIST      Import comma-separated list of tables. -constraints       Import the table constraints. -indexes     Import the table indexes. -triggers    Import the table triggers. -allViews   Import all Views. -views LIST      Import comma-separated list of Views. -allProcs    Import all stored procedures. -procs LIST      Import comma-separated list of storedprocedures. -allFuncs   Import all functions. -funcs LIST      Import comma-separated list of functions. -allPackages      Import all packages. -packages LISTImport comma-separated list of packages. -allSequences    Import all sequences. -sequences LISTImport comma-separated list of sequences. -targetSchemaNAME Name of the target schema (default: target schema is named after sourceschema). -allDBLinks      Import all Database Links. -allSynonyms    It enables the migration of all public andprivate synonyms from an Oracle database to an Advanced Server database.  If a synonym with the same name alreadyexists in the target database, the existing synonym will be replaced with themigrated version. -allPublicSynonyms  It enables the migration of all publicsynonyms from an Oracle database to an Advanced Server database.  If a synonym with the same name alreadyexists in the target database, the existing synonym will be replaced with themigrated version. -allPrivateSynonyms It enables the migration of all privatesynonyms from an Oracle database to an Advanced Server database.  If a synonym with the same name alreadyexists in the target database, the existing synonym will be replaced with themigrated version.   -dropSchema[true|false] Drop the schema if it already exists in the target database(default: false). -truncLoad It disables any constraints on target table andtruncates the data from the table before importing new data. This option canonly be used with -dataOnly. -safeMode  Transfer data in safe mode using plain SQLstatements. -copyDelimiter  Specify a single character to be used asdelimiter in copy command when loading table data. Default is \\t -batchSize  Specify the Batch Size to be used by the bulkinserts. Valid values are  1-1000,default batch size is 1000, reduce if you run into Out of Memory exception -cpBatchSize     Specify the Batch Size in MB, to be usedin the Copy Command. Valid value is > 0, default batch size is 8 MB -fetchSize  Specify fetch size in terms of number of rowsshould be fetched in result set at a time. This option can be used when tablescontain millions of rows and you want to avoid out of memory errors. -filterProp The properties file that contains table whereclause. -skipFKConst    Skip migration of FK constraints. -skipCKConst    Skip migration of Check constraints. -ignoreCheckConstFilter   By default MTK does not migrate Checkconstraints and Default clauses from Sybase, use this option to turn off thisfilter. -fastCopy   Bypass WAL logging to perform the COPYoperation in an optimized way, default disabled. -customColTypeMappingLIST Use custom type mapping representedby a semi-colon separated list, where each entry is specified usingCOL_NAME_REG_EXPR=TYPE pair. e.g. .*ID=INTEGER -customColTypeMappingFilePROP_FILE     The custom type mappingrepresented by a properties file, where each entry is specified usingCOL_NAME_REG_EXPR=TYPE pair. e.g. .*ID=INTEGER -offlineMigration[PATH] This performs offline migration and saves the DDL/DML scripts in filesfor a later execution. By default the script files will be saved under userhome folder, if required follow -offlineMigration option with a custom path. -logDirLOG_PATH Specify a custom path to save the log file. By default, on Linux thelogs will be saved under folder $HOME/.enterprisedb/migration-toolkit/logs. Incase of Windows logs will be saved under folder%HOMEDRIVE%%HOMEPATH%\\.enterprisedb\\migration-toolkit\\logs. -copyViaDBLinkOraThis option can be used to copy data using dblink_ora COPY commad. This optioncan only be used in Oracle to EnterpriseDB migration mode. -singleDataFile  Use single SQL file for offline data storagefor all tables. This option cannot be used in COPY format. -allUsersImport all users and roles from the source database. -users LISTImport the selected users/roles from the source database. LIST is acomma-separated list of user/role names e.g. -users MTK,SAMPLE -allRulesImport all rules from the source database. -rules LISTImport the selected rules from the source database. LIST is a comma-separatedlist of rule names e.g. -rules high_sal_emp,low_sal_emp -allGroupsImport all groups from the source database. -groups LISTImport the selected groups from the source database. LIST is a comma-separated listof group names e.g. -groups acct_emp,mkt_emp -allDomainsImport all domain, enumeration and composite types from the source database. -domains LISTImport the selected domain, enumeration and composite types from the sourcedatabase. LIST is a comma-separated list of domain names e.g. -domainsd_email,d_dob, mood -objecttypes      Import the user-defined object types. -replaceNullChar<CHAR> If null character is part of a column value, the data migrationfails over JDBC protocol. This option can be used to replace null characterwith a user-specified character. -importPartitionAsTable[LIST] Use this option to import Oracle Partitioned table as a normal table inEnterpriseDB. To apply the rule on a selected set of tables, follow the optionby a comma-separated list of table names. -enableConstBeforeDataLoadUse this option to re-enable constraints (and triggers) before data load. Thisis useful in the scenario when the migrated table is mapped to a partitiontable in EnterpriseDB. -checkFunctionBodies[true|false] When set to false, it disables validation of the function bodyduring function creation, this is to avoid errors if function contains forwardreferences. Applicable when target database is Postgres/EnterpriseDB, defaultis true. -retryCountVALUE  Specify the number of re-attemptsperformed by MTK to migrate objects that failed due to cross-schemadependencies. The VALUE parameter should be greater than 0, default is 2. -analyze    It invokes ANALYZE operation against a targetPostgres or Postgres Plus Advanced Server database. The ANALYZE collectsstatistics for the migrated tables that are utilized for efficient query plans. -vacuumAnalyze      It invokes VACUUM and ANALYZE operationsagainst a target Postgres or Postgres Plus Advanced Server database. The VACUUMreclaims dead tuple storage whereas ANALYZE collects statistics for themigrated tables that are utilized for efficient query plans. -loaderCountVALUE       Specify the number of jobs(threads) to perform data load in parallel. The VALUE parameter should begreater than 0, default is 1.   DatabaseConnection Information: The applicationwill read the connectivity information for the source and target databaseservers from toolkit.properties file. Refer to MTKreadme document for more information.  ","title":"PPAS命令行迁移工具"},{"content":"这是在做一个考试成绩统计时遇到的问题。假设有如表1所示的数据，其中包含了3个班级的考生成绩，如果是希望获取全部数据的前2名，可以使用TOP配合ORDER BY子句轻易实现，但是如果我们希望取出每个班级中的前2名呢？事情就不这么简单了。 SELECT TOP(2) *   FROM Students ORDER BY Achi DESC; 表1                                                                     考试成绩表 ClassID StuName Achi 1 张山 100 1 李明 90 1 王磊 95 2 孙科 100 2 赵强 80 2 王智 90 3 李海 95 下面的语句用于创建示例表： CREATE TABLE Students (ClassID int,  StuNamechar(10),  Achi int); INSERT INTO Students VALUES(1, '张山', 100),       (1, '李明', 90),       (1, '王磊', 95),       (2, '孙科', 100),       (2, '赵强', 80),       (2, '王智', 90),       (3, '李海', 95); 1.使用联接获取前几行 如果将Students表打开两次，将一个考生与其大于或等于自己成绩的考生联接，我们看看会得到什么样的结果。参考下面的语句： SELECT S1.*, S2.* FROM Students AS S1   INNER JOINStudents AS S2     ONS1.ClassID = S2.ClassID       ANDS2.Achi >= S1.Achi ORDER BY S1.ClassID, S1.Achi DESC; 结果如表2所示。 表2                                                                       联接结果 S1.ClassID S1.StuName S1.Achi S2.ClassID S2.StuName S2.Achi 1 张山      100 1 张山      100 1 王磊      95 1 张山      100 1 王磊      95 1 王磊      95 1 李明      90 1 张山      100 1 李明      90 1 李明      90 1 李明      90 1 王磊      95 2 孙科      100 2 孙科      100 2 王智      90 2 孙科      100 2 王智      90 2 王智      90 2 赵强      80 2 孙科      100 2 赵强      80 2 赵强      80 2 赵强      80 2 王智      90 3 李海      95 3 李海      95 从上表中可以看出，1班中的第1名张山有1条记录，第2名王磊有2条记录，第3名有3条记录。因此，我们可以使用下面的语句来获取每班中前2名的考生。查询结果如表3所示。 SELECT S1.ClassID, S1.Achi, MAX(S1.StuName) ASStuName FROM Students AS S1   INNER JOINStudents AS S2     ONS1.ClassID = S2.ClassID       ANDS2.Achi >= S1.Achi GROUP BY S1.ClassID, S1.Achi   HAVING COUNT(*) <=2 ORDER BY S1.ClassID, S1.Achi DESC; 表3                                                             每班中前2名的考生 ClassID Achi StuName 1 100 张山 1 95 王磊 2 100 孙科 2 90 王智 3 95 李海 2.使用窗口排名函数获取前几行 窗口计算是从SQLServer 2005开始提供的新技术，每一组数据被称为一个窗口，RANK( )和DENSE_RANK( )函数都可以按窗口进行排名计算，表4描述了这两种排名方式的差异。 表4                                        RANK( )和DENSE_RANK( )函数排名的差异 StuName Achi RANK( )排名 DENSE_RANK( )排名 张三 100 1 1 李四 100 1 1 王五 95 3 2 赵六 90 4 3 从表中可以看出，无论是RANK()还是DENSE_RANK()，相同的考试成绩排名值是相同的，张三和李四都是第1，也就是我们常说的并列第1。但是，两人之后的名次RANK( )和DENSE_RANK( )出现了差异，从两人并列第1的角度讲，他们两人之后的名次应当是第2，这是DENSE_RANK( )函数的排名方式，也称为密集排名，因为它的名次之间没有间隔；前面已经有2个人100分了，他们后面的人应当是第3个高分者，从这个角度理解，后面的名次应当是第3，这是RANK( )的排名方式。 例如，下面的语句按班级分组、按成绩降序密集排名，查询结果如表5所示。与上面使用联接获取前2名的方式相比，使用排名函数可以正确处理成绩并列现象。同样是获取成绩前2名，存在成绩并列时，使用排名函数从每个班级中取出的人数有可能超过2个。 SELECT ClassID, StuName, Achi,         DENSE_RANK() OVER(PARTITION BY ClassID ORDERBY Achi DESC) AS rank_rn FROM Students; 表5                                                                       排序结果 ClassID StuName Achi rank_rn 1 张山      100 1 1 王磊      95 2 1 李明      90 3 2 孙科      100 1 2 王智      90 2 2 赵强      80 3 3 李海      95 1 从上表可以看出，我们只要取出rank_rn小于或等于2的考生即可。下面是完整的查询语句，在性能方面，该语句要高于联接方式。 WITH StuRank(ClassID, StuName, Achi, rank_rn) AS (SELECT ClassID, StuName, Achi,        DENSE_RANK() OVER(PARTITION BY ClassID ORDER BY Achi DESC)  FROMStudents  )SELECT * FROMStuRank WHERE rank_rn <= 2;  ","title":"锋利的SQL：从分组中取前几行数据"},{"content":"一、准备工作 1、 下载mongoDB 下载地址：http://www.mongodb.org/downloads 选择合适你的版本 相关文档：http://www.mongodb.org/display/DOCS/Tutorial 2、 安装mongoDB A、 不解压模式： 将下载下来的mongoDB-xxx.zip打开，找到bin目录，运行mongod.exe就可以启动服务，默认端口27017，db保存的路径是系统C硬盘目录的根目录的/data/db目录。也就是说，如果你的mongoDB-xxx.zip在E盘，那么你需要在C盘下建立data/db目录。mongoDB不会帮你建立这个目录的。 然后运行mongo即可连接到test数据库，你就可以进行数据操作。运行help显示帮助命令行。 B、 解压模式 将下载下来的mongoDB-xxx.zip解压到任意目录，找到bin目录，运行mongod.exe就可以启动mongoDB，默认端口27017，db保存的路径是当前zip所在硬盘目录的根目录的/data/db目录。也就是说，如果你的mongoDB-xxx.zip在E盘，那么你需要在E盘下建立data/db目录。mongoDB不会帮你建立这个目录的。 然后运行mongo即可连接到test数据库，你就可以进行数据操作。运行help显示帮助命令行。 3、 简单测试 > 2+4 6 > db test > //第一次插入数据会创建数据库 Fri May 20 16:47:39 malformed UTF-8 character sequence at offset 27 error2:(shellhelp1) exec failed: malformed UTF-8 character sequence at offset 27 > db.foo.insert({id: 2011, userName: 'hoojo', age: 24, email: \"hoojo_@126.com\"}); > db.foo.find(); { \"_id\" : ObjectId(\"4dd62b0352a70cbe79e04f81\"), \"id\" : 2011, \"userName\" : \"hoojo\", \"age\" : 24, \"email\" : \"hoojo_@126.com\" } > 上面完成了简单运算，显示当前使用的数据库，以及添加数据、查询数据操作   二、DB shell数据操作 shell命令操作语法和JavaScript很类似，其实控制台底层的查询语句都是用JavaScript脚本完成操作的。 Ø 数据库   1、Help查看命令提示 help db.help(); db.yourColl.help(); db.youColl.find().help(); rs.help();   2、切换/创建数据库 >use yourDB; 当创建一个集合(table)的时候会自动创建当前数据库   3、查询所有数据库 show dbs;   4、删除当前使用数据库 db.dropDatabase();   5、从指定主机上克隆数据库 db.cloneDatabase(“127.0.0.1”); 将指定机器上的数据库的数据克隆到当前数据库   6、从指定的机器上复制指定数据库数据到某个数据库 db.copyDatabase(\"mydb\", \"temp\", \"127.0.0.1\"); 将本机的mydb的数据复制到temp数据库中   7、修复当前数据库 db.repairDatabase();   8、查看当前使用的数据库 db.getName(); db; db和getName方法是一样的效果，都可以查询当前使用的数据库   9、显示当前db状态 db.stats();   10、当前db版本 db.version();   11、查看当前db的链接机器地址 db.getMongo(); Ø Collection聚集集合   1、创建一个聚集集合（table） db.createCollection(“collName”, {size: 20, capped: 5, max: 100});   2、得到指定名称的聚集集合（table） db.getCollection(\"account\");   3、得到当前db的所有聚集集合 db.getCollectionNames();   4、显示当前db所有聚集索引的状态 db.printCollectionStats(); Ø 用户相关 1、添加一个用户 db.addUser(\"name\"); db.addUser(\"userName\", \"pwd123\", true); 添加用户、设置密码、是否只读   2、数据库认证、安全模式 db.auth(\"userName\", \"123123\");   3、显示当前所有用户 show users;   4、删除用户 db.removeUser(\"userName\"); Ø 其他 1、查询之前的错误信息 db.getPrevError();   2、清除错误记录 db.resetError();   三、Collection聚集集合操作 Ø 查看聚集集合基本信息   1、查看帮助 db.yourColl.help();   2、查询当前集合的数据条数 db.yourColl.count();   3、查看数据空间大小 db.userInfo.dataSize();   4、得到当前聚集集合所在的db db.userInfo.getDB();   5、得到当前聚集的状态 db.userInfo.stats();   6、得到聚集集合总大小 db.userInfo.totalSize();   7、聚集集合储存空间大小 db.userInfo.storageSize();   8、Shard版本信息 db.userInfo.getShardVersion()   9、聚集集合重命名 db.userInfo.renameCollection(\"users\"); 将userInfo重命名为users   10、删除当前聚集集合 db.userInfo.drop(); Ø 聚集集合查询 1、查询所有记录 db.userInfo.find(); 相当于：select * from userInfo; 默认每页显示20条记录，当显示不下的情况下，可以用it迭代命令查询下一页数据。注意：键入it命令不能带“；” 但是你可以设置每页显示数据的大小，用DBQuery.shellBatchSize = 50;这样每页就显示50条记录了。   2、查询去掉后的当前聚集集合中的某列的重复数据 db.userInfo.distinct(\"name\"); 会过滤掉name中的相同数据 相当于：select distict name from userInfo;   3、查询age = 22的记录 db.userInfo.find({\"age\": 22}); 相当于： select * from userInfo where age = 22;   4、查询age > 22的记录 db.userInfo.find({age: {$gt: 22}}); 相当于：select * from userInfo where age > 22;   5、查询age < 22的记录 db.userInfo.find({age: {$lt: 22}}); 相当于：select * from userInfo where age < 22;   6、查询age >= 25的记录 db.userInfo.find({age: {$gte: 25}}); 相当于：select * from userInfo where age >= 25;   7、查询age <= 25的记录 db.userInfo.find({age: {$lte: 25}});   8、查询age >= 23 并且 age <= 26 db.userInfo.find({age: {$gte: 23, $lte: 26}});   9、查询name中包含 mongo的数据 db.userInfo.find({name: /mongo/}); //相当于%% select * from userInfo where name like ‘%mongo%’;   10、查询name中以mongo开头的 db.userInfo.find({name: /^mongo/}); select * from userInfo where name like ‘mongo%’;   11、查询指定列name、age数据 db.userInfo.find({}, {name: 1, age: 1}); 相当于：select name, age from userInfo; 当然name也可以用true或false,当用ture的情况下河name:1效果一样，如果用false就是排除name，显示name以外的列信息。   12、查询指定列name、age数据, age > 25 db.userInfo.find({age: {$gt: 25}}, {name: 1, age: 1}); 相当于：select name, age from userInfo where age > 25;   13、按照年龄排序 升序：db.userInfo.find().sort({age: 1}); 降序：db.userInfo.find().sort({age: -1});   14、查询name = zhangsan, age = 22的数据 db.userInfo.find({name: 'zhangsan', age: 22}); 相当于：select * from userInfo where name = ‘zhangsan’ and age = ‘22’;   15、查询前5条数据 db.userInfo.find().limit(5); 相当于：select top 5 * from userInfo;   16、查询10条以后的数据 db.userInfo.find().skip(10); 相当于：select * from userInfo where id not in ( select top 10 * from userInfo );   17、查询在5-10之间的数据 db.userInfo.find().limit(10).skip(5); 可用于分页，limit是pageSize，skip是第几页*pageSize   18、or与 查询 db.userInfo.find({$or: [{age: 22}, {age: 25}]}); 相当于：select * from userInfo where age = 22 or age = 25;   19、查询第一条数据 db.userInfo.findOne(); 相当于：select top 1 * from userInfo; db.userInfo.find().limit(1);   20、查询某个结果集的记录条数 db.userInfo.find({age: {$gte: 25}}).count(); 相当于：select count(*) from userInfo where age >= 20;   21、按照某列进行排序 db.userInfo.find({sex: {$exists: true}}).count(); 相当于：select count(sex) from userInfo; Ø 索引 1、创建索引 db.userInfo.ensureIndex({name: 1}); db.userInfo.ensureIndex({name: 1, ts: -1});   2、查询当前聚集集合所有索引 db.userInfo.getIndexes();   3、查看总索引记录大小 db.userInfo.totalIndexSize();   4、读取当前集合的所有index信息 db.users.reIndex();   5、删除指定索引 db.users.dropIndex(\"name_1\");   6、删除所有索引索引 db.users.dropIndexes(); Ø 修改、添加、删除集合数据 1、添加 db.users.save({name: ‘zhangsan’, age: 25, sex: true}); 添加的数据的数据列，没有固定，根据添加的数据为准   2、修改 db.foo.update(criteria, objNew, upsert, multi)      criteria : update的查询条件，类似sql update查询内where后面的   objNew   : update的对象和一些更新的操作符（如$,$inc...）等，也可以理解为sql update查询内set后面的   upsert   : 这个参数的意思是，如果不存在update的记录，是否插入objNew,true为插入，默认是false，不插入。   multi    : mongodb默认是false,只更新找到的第一条记录，如果这个参数为true,就把按条件查出来多条记录全部更新。   db.users.update({age: 25}, {$set: {name: 'changeName'}}, false, true); 相当于：update users set name = ‘changeName’ where age = 25;   db.users.update({name: 'Lisi'}, {$inc: {age: 50}}, false, true); 相当于：update users set age = age + 50 where name = ‘Lisi’;   db.users.update({name: 'Lisi'}, {$inc: {age: 50}, $set: {name: 'hoho'}}, false, true); 相当于：update users set age = age + 50, name = ‘hoho’ where name = ‘Lisi’;   3、删除 db.users.remove({age: 132});   4、查询修改删除 db.users.findAndModify({     query: {age: {$gte: 25}},     sort: {age: -1},     update: {$set: {name: 'a2'}, $inc: {age: 2}},     remove: true });   db.runCommand({ findandmodify : \"users\",     query: {age: {$gte: 25}},     sort: {age: -1},     update: {$set: {name: 'a2'}, $inc: {age: 2}},     remove: true }); update 或 remove 其中一个是必须的参数; 其他参数可选。 参数 详解 默认值 query 查询过滤条件 {} sort 如果多个文档符合查询过滤条件，将以该参数指定的排列方式选择出排在首位的对象，该对象将被操作 {} remove 若为true，被选中对象将在返回前被删除 N/A update 一个 修改器对象 N/A new 若为true，将返回修改后的对象而不是原始对象。在删除操作中，该参数被忽略。 false fields 参见Retrieving a Subset of Fields (1.5.0+) All fields upsert 创建新对象若查询结果为空。 示例 (1.5.4+) false Ø 语句块操作 1、简单Hello World print(\"Hello World!\"); 这种写法调用了print函数，和直接写入\"Hello World!\"的效果是一样的；   2、将一个对象转换成json tojson(new Object()); tojson(new Object('a'));   3、循环添加数据 > for (var i = 0; i < 30; i++) { ... db.users.save({name: \"u_\" + i, age: 22 + i, sex: i % 2}); ... }; 这样就循环添加了30条数据，同样也可以省略括号的写法 > for (var i = 0; i < 30; i++) db.users.save({name: \"u_\" + i, age: 22 + i, sex: i % 2}); 也是可以的，当你用db.users.find()查询的时候，显示多条数据而无法一页显示的情况下，可以用it查看下一页的信息；   4、find 游标查询 >var cursor = db.users.find(); > while (cursor.hasNext()) {     printjson(cursor.next()); } 这样就查询所有的users信息，同样可以这样写 var cursor = db.users.find(); while (cursor.hasNext()) { printjson(cursor.next); } 同样可以省略{}号  5、forEach迭代循环 db.users.find().forEach(printjson); forEach中必须传递一个函数来处理每条迭代的数据信息   6、将find游标当数组处理 var cursor = db.users.find(); cursor[4]; 取得下标索引为4的那条数据 既然可以当做数组处理，那么就可以获得它的长度：cursor.length();或者cursor.count(); 那样我们也可以用循环显示数据 for (var i = 0, len = c.length(); i < len; i++) printjson(c[i]);   7、将find游标转换成数组 > var arr = db.users.find().toArray(); > printjson(arr[2]); 用toArray方法将其转换为数组   8、定制我们自己的查询结果 只显示age <= 28的并且只显示age这列数据 db.users.find({age: {$lte: 28}}, {age: 1}).forEach(printjson); db.users.find({age: {$lte: 28}}, {age: true}).forEach(printjson); 排除age的列 db.users.find({age: {$lte: 28}}, {age: false}).forEach(printjson);   9、forEach传递函数显示信息 db.things.find({x:4}).forEach(function(x) {print(tojson(x));}); 上面介绍过forEach需要传递一个函数，函数会接受一个参数，就是当前循环的对象，然后在函数体重处理传入的参数信息。","title":"mongoDB 入门"},{"content":"使用UDEV在Oracle Linux 6上安装Oracle 11g RAC(11.2.0.3) (一) 使用UDEV在Oracle Linux 6上安装Oracle 11g RAC(11.2.0.3) (二) 配置共享磁盘,本次实验环境是基于VMware ESXi 5搭建。 和vbox配置差不多,具体过程略,关闭node1,node2,说明一下需要注意的地方 SCSI控制器选择  LIS Logic并行,类型选择虚拟,虚拟磁盘可以在同一台服务器上共享,磁盘的虚拟设备节点选择1:1,1:2依次类推,这里添加了6块共享磁盘。 node1创建磁盘之后,node2选择已有磁盘,选择路径添加即可 在node1,和node2的vmx配置文件中添加以下语句,否则无法获取磁盘UUID disk.enableUUID = \"TRUE\"  scsi1:4.present = \"TRUE\"scsi1:4.fileName = \"/vmfs/volumes/4fd87396-c40232e5-5ae4-001e6719f392/zhongwc1/zhongwc1_4.vmdk\"scsi1:4.deviceType = \"scsi-hardDisk\"scsi1:5.present = \"TRUE\"   scsi1:5.fileName = \"/vmfs/volumes/4fd87396-c40232e5-5ae4-001e6719f392/zhongwc1/zhongwc1_5.vmdk\"scsi1:5.deviceType = \"scsi-hardDisk\"scsi1:6.present = \"TRUE\"   scsi1:6.fileName = \"/vmfs/volumes/4fd87396-c40232e5-5ae4-001e6719f392/zhongwc1/zhongwc1_6.vmdk\"scsi1:6.deviceType = \"scsi-hardDisk\"scsi0:13.present = \"FALSE\" scsi1:1.redo = \"\"                     scsi1:2.redo = \"\"         scsi1:3.redo = \"\"          scsi1:4.redo = \"\"                     scsi1:5.redo = \"\"         scsi1:6.redo = \"\"     scsi1.pciSlotNumber = \"35\"           disk.enableUUID = \"TRUE\"                启动node1,node2测试共享磁盘 node1 [root@node1 ~]# fdisk -lDisk /dev/sda: 107.4 GB, 107374182400 bytes255 heads, 63 sectors/track, 13054 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x000119e9   Device Boot      Start         End      Blocks   Id  System/dev/sda1   *           1          26      204800   83  LinuxPartition 1 does not end on cylinder boundary./dev/sda2              26         809     6291456   82  Linux swap / SolarisPartition 2 does not end on cylinder boundary./dev/sda3             809       13055    98360320   83  LinuxDisk /dev/sdb: 1073 MB, 1073741824 bytes255 heads, 63 sectors/track, 130 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/sdc: 1073 MB, 1073741824 bytes255 heads, 63 sectors/track, 130 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/sdd: 1073 MB, 1073741824 bytes255 heads, 63 sectors/track, 130 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/sde: 32.2 GB, 32212254720 bytes255 heads, 63 sectors/track, 3916 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/sdf: 32.2 GB, 32212254720 bytes255 heads, 63 sectors/track, 3916 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/sdg: 21.5 GB, 21474836480 bytes255 heads, 63 sectors/track, 2610 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000[root@node1 ~]# [root@node1 ~]# ls -l /dev/sd*brw-rw---- 1 root disk 8,  0 Dec 28 17:08 /dev/sdabrw-rw---- 1 root disk 8,  1 Dec 28 17:08 /dev/sda1brw-rw---- 1 root disk 8,  2 Dec 28 17:08 /dev/sda2brw-rw---- 1 root disk 8,  3 Dec 28 17:08 /dev/sda3brw-rw---- 1 root disk 8, 16 Dec 28 17:08 /dev/sdbbrw-rw---- 1 root disk 8, 32 Dec 28 17:08 /dev/sdcbrw-rw---- 1 root disk 8, 48 Dec 28 17:08 /dev/sddbrw-rw---- 1 root disk 8, 64 Dec 28 17:08 /dev/sdebrw-rw---- 1 root disk 8, 80 Dec 28 17:08 /dev/sdfbrw-rw---- 1 root disk 8, 96 Dec 28 17:08 /dev/sdg node2 [root@node2 ~]# fdisk -lDisk /dev/sda: 107.4 GB, 107374182400 bytes255 heads, 63 sectors/track, 13054 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x000ac6e9   Device Boot      Start         End      Blocks   Id  System/dev/sda1   *           1          26      204800   83  LinuxPartition 1 does not end on cylinder boundary./dev/sda2              26         809     6291456   82  Linux swap / SolarisPartition 2 does not end on cylinder boundary./dev/sda3             809       13055    98360320   83  LinuxDisk /dev/sdb: 1073 MB, 1073741824 bytes255 heads, 63 sectors/track, 130 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/sdc: 1073 MB, 1073741824 bytes255 heads, 63 sectors/track, 130 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/sdd: 1073 MB, 1073741824 bytes255 heads, 63 sectors/track, 130 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/sde: 32.2 GB, 32212254720 bytes255 heads, 63 sectors/track, 3916 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/sdf: 32.2 GB, 32212254720 bytes255 heads, 63 sectors/track, 3916 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000Disk /dev/sdg: 21.5 GB, 21474836480 bytes255 heads, 63 sectors/track, 2610 cylindersUnits = cylinders of 16065 * 512 = 8225280 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk identifier: 0x00000000[root@node2 ~]# ls -l /dev/sd*brw-rw---- 1 root disk 8,  0 Dec 28 17:08 /dev/sdabrw-rw---- 1 root disk 8,  1 Dec 28 17:08 /dev/sda1brw-rw---- 1 root disk 8,  2 Dec 28 17:08 /dev/sda2brw-rw---- 1 root disk 8,  3 Dec 28 17:08 /dev/sda3brw-rw---- 1 root disk 8, 16 Dec 28 17:08 /dev/sdbbrw-rw---- 1 root disk 8, 32 Dec 28 17:08 /dev/sdcbrw-rw---- 1 root disk 8, 48 Dec 28 17:08 /dev/sddbrw-rw---- 1 root disk 8, 64 Dec 28 17:08 /dev/sdebrw-rw---- 1 root disk 8, 80 Dec 28 17:08 /dev/sdfbrw-rw---- 1 root disk 8, 96 Dec 28 17:08 /dev/sdg 使用以下脚本获取共享磁盘的UUID,配置ASM共享存储 for i in b c d e f gdoecho \"KERNEL==\\\"sd*\\\", BUS==\\\"scsi\\\", PROGRAM==\\\"/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/\\$name\\\", RESULT==\\\"`/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/sd$i`\\\", NAME=\\\"asm-disk$i\\\", OWNER=\\\"grid\\\", GROUP=\\\"asmadmin\\\", MODE=\\\"0660\\\"\"done node1 [root@node1 ~]# cat /etc/udev/rules.d/99-oracle-asmdevices.rulesKERNEL==\"sd*\", BUS==\"scsi\", PROGRAM==\"/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/$name\", RESULT==\"36000c294347acba383e23ecbd43867c4\", NAME=\"asm-diskb\", OWNER=\"grid\", GROUP=\"asmadmin\", MODE=\"0660\"KERNEL==\"sd*\", BUS==\"scsi\", PROGRAM==\"/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/$name\", RESULT==\"36000c2913d3b49354c9d030816bd5de9\", NAME=\"asm-diskc\", OWNER=\"grid\", GROUP=\"asmadmin\", MODE=\"0660\"KERNEL==\"sd*\", BUS==\"scsi\", PROGRAM==\"/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/$name\", RESULT==\"36000c296cf9ff63b87e2903925bdec21\", NAME=\"asm-diskd\", OWNER=\"grid\", GROUP=\"asmadmin\", MODE=\"0660\"KERNEL==\"sd*\", BUS==\"scsi\", PROGRAM==\"/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/$name\", RESULT==\"36000c2952ef3147bf0c3efc345133b00\", NAME=\"asm-diske\", OWNER=\"grid\", GROUP=\"asmadmin\", MODE=\"0660\"KERNEL==\"sd*\", BUS==\"scsi\", PROGRAM==\"/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/$name\", RESULT==\"36000c296f16a22e6292edfb3ec3b1934\", NAME=\"asm-diskf\", OWNER=\"grid\", GROUP=\"asmadmin\", MODE=\"0660\"KERNEL==\"sd*\", BUS==\"scsi\", PROGRAM==\"/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/$name\", RESULT==\"36000c29ae38dfe96f6342cb2afd7f3fb\", NAME=\"asm-diskg\", OWNER=\"grid\", GROUP=\"asmadmin\", MODE=\"0660\" 将99-oracle-asmdevices.rules文件传输到node2上 [root@node1 ~]# scp /etc/udev/rules.d/99-oracle-asmdevices.rules node2:/etc/udev/rules.d/root@node2's password: 99-oracle-asmdevices.rules                                                                                                           100% 1296     1.3KB/s   00:00    [root@node1 ~]# 在node1,node2上重新启动udev [root@node1 ~]# start_udev Starting udev:                                             [  OK  ][root@node1 ~]# ll /dev/asm-disk*brw-rw---- 1 grid asmadmin 8, 16 Dec 28 17:22 /dev/asm-diskbbrw-rw---- 1 grid asmadmin 8, 32 Dec 28 17:22 /dev/asm-diskcbrw-rw---- 1 grid asmadmin 8, 48 Dec 28 17:22 /dev/asm-diskdbrw-rw---- 1 grid asmadmin 8, 64 Dec 28 17:22 /dev/asm-diskebrw-rw---- 1 grid asmadmin 8, 80 Dec 28 17:22 /dev/asm-diskfbrw-rw---- 1 grid asmadmin 8, 96 Dec 28 17:22 /dev/asm-diskg[root@node1 ~]# [root@node2 ~]# start_udev Starting udev:                                             [  OK  ][root@node2 ~]# ll /dev/asm-disk*brw-rw---- 1 grid asmadmin 8, 32 Dec 28 17:22 /dev/asm-diskbbrw-rw---- 1 grid asmadmin 8, 48 Dec 28 17:22 /dev/asm-diskcbrw-rw---- 1 grid asmadmin 8, 16 Dec 28 17:22 /dev/asm-diskdbrw-rw---- 1 grid asmadmin 8, 64 Dec 28 17:22 /dev/asm-diskebrw-rw---- 1 grid asmadmin 8, 80 Dec 28 17:22 /dev/asm-diskfbrw-rw---- 1 grid asmadmin 8, 96 Dec 28 17:22 /dev/asm-diskg 到此ASM共享存储配置完毕,未完待续。","title":"使用UDEV在Oracle Linux 6上安装Oracle 11g RAC(11.2.0.3) (三)"},{"content":"insert into employee    (name,age)    values    (\"wangwu\",19)    ; #插入值 alter table myt    drop myclomn #删除列 create database myd; #创建库drop database myd; #删除库use myd; 使用库create table myt; #创建表drop table myt; #删除表 create database employee(         id int(2) auto_increment primary key,         name varchar(20),         salary int(6),         start_date date         );  #例子，创建表  alter table add column telph int(9) desc employee; #查看表 alter table oldname rename to newname; #修改表名 select * from myt; 查看整个表","title":"mysql"},{"content":"MYSQL的所有字段使用大全，必读，身藏 1.mysql的数值类型 列类型                       需要的存储量  TINYINT                         1 字节  SMALLINT                      2 个字节  MEDIUMINT                   3 个字节  INT                                 4 个字节  INTEGER                       4 个字节  BIGINT                           8 个字节  FLOAT(X)                       4 如果 X < = 24 或 8 如果 25 < = X < = 53  FLOAT                            4 个字节  DOUBLE                         8 个字节  DOUBLE PRECISION     8 个字节  REAL                              8 个字节  DECIMAL(M,D)             M字节(D+2 , 如果M < D) MySQL 的数值数据类型可以大致划分为两个类别，一个是整数，另一个是浮点数或小数。许多不同的子类型对这些类别中的每一个都是可用的，每个子类型支持不同大小的数据，并且 MySQL 允许我们指定数值字段中的值是否有正负之分或者用零填补。 表列出了各种数值类型以及它们的允许范围和占用的内存空间。 类型 大小 范围（有符号） 范围（无符号） 用途 TINYINT 1字节 (-128，127) (0，255) 小整数值 SMALLINT 2字节 (-32768，32767) (0，65535) 大整数值 MEDIUMINT 3字节 (-8388 608，8388 607) (0，16777 215) 大整数值 INT或INTEGER 4字节 (-2147 483 648，2147 483 647) (0，4294 967 295) 大整数值 BIGINT 8字节 (-9233 372 036 854 775 808，9223 372 036 854 775 807) (0，18446 744 073 709 551 615) 极大整数值 FLOAT 4字节 (-3.402823 466 E+38，1.175494 351 E-38) 0，(1.175494 351 E-38，3.402823 466 351 E+38) 0，(1.175494 351 E-38，3.402823 466 E+38) 单精度浮点数值 DOUBLE 8字节 (1.797693 134 862 315 7 E+308，2.225073 858 507 201 4 E-308) 0，(2.225073 858 507 201 4 E-308，1.797693 134 862 315 7 E+308) 0，(2.225073 858 507 201 4 E-308，1.797693 134 862 315 7 E+308) 双精度 浮点数值 DECIMAL 对DECIMAL(M,D)，如果M>D，为M+2否则为D+2 依赖于M和D的值 依赖于M和D的值 小数值 INT 类型 　　在 MySQL 中支持的 5 个主要整数类型是 TINYINT，SMALLINT，MEDIUMINT，INT 和 BIGINT。这些类型在很大程度上是相同的，只有它们存储的值的大小是不相同的。 　　MySQL 以一个可选的显示宽度指示器的形式对 SQL 标准进行扩展，这样当从数据库检索一个值时，可以把这个值加长到指定的长度。例如，指定一个字段的类型为 INT(6)，就可以保证所包含数字少于 6 个的值从数据库中检索出来时能够自动地用空格填充。需要注意的是，使用一个宽度指示器不会影响字段的大小和它可以存储的值的范围。 　　万一我们需要对一个字段存储一个超出许可范围的数字，MySQL 会根据允许范围最接近它的一端截短后再进行存储。还有一个比较特别的地方是，MySQL 会在不合规定的值插入表前自动修改为 0。 　　UNSIGNED（未签署） 修饰符规定字段只保存正值。因为不需要保存数字的正、负符号，可以在储时节约一个“位”的空间。从而增大这个字段可以存储的值的范围。 　　ZEROFILL（零填充） 修饰符规定 0（不是空格）可以用来真补输出的值。使用这个修饰符可以阻止 MySQL 数据库存储负值。 FLOAT、DOUBLE 和 DECIMAL 类型 　　MySQL 支持的三个浮点类型是 FLOAT、DOUBLE 和 DECIMAL 类型。FLOAT 数值类型用于表示单精度浮点数值，而 DOUBLE 数值类型用于表示双精度浮点数值。 　　与整数一样，这些类型也带有附加参数：一个显示宽度指示器和一个小数点指示器。比如语句 FLOAT(7,3) 规定显示的值不会超过 7 位数字，小数点后面带有 3 位数字。 　　对于小数点后面的位数超过允许范围的值，MySQL 会自动将它四舍五入为最接近它的值，再插入它。 　　DECIMAL 数据类型用于精度要求非常高的计算中，这种类型允许指定数值的精度和计数方法作为选择参数。精度在这里指为这个值保存的有效数字的总个数，而计数方法表示小数点后数字的位数。比如语句 DECIMAL(7,3) 规定了存储的值不会超过 7 位数字，并且小数点后不超过 3 位。 　　忽略 DECIMAL 数据类型的精度和计数方法修饰符将会使 MySQL 数据库把所有标识为这个数据类型的字段精度设置为 10，计算方法设置为 0。 　　UNSIGNED(未签署) 和 ZEROFILL（零填充） 修饰符也可以被 FLOAT、DOUBLE 和 DECIMAL 数据类型使用。并且效果与 INT 数据类型相同。 2、日期和时间类型 列类型                  需要的存储量  DATE                        3 个字节  DATETIME                8 个字节  TIMESTAMP             4 个字节  TIME                         3 个字节  YEAR                        1 字节       在处理日期和时间类型的值时，MySQL 带有 5 个不同的数据类型可供选择。它们可以被分成简单的日期、时间类型，和混合日期、时间类型。根据要求的精度，子类型在每个分类型中都可以使用，并且 MySQL 带有内置功能可以把多样化的输入格式变为一个标准格式 类型 大小 范围（有符号） 范围（无符号） 用途 DATE 3字节 1000-01-01/9999-12-31 YYYY-MM-DD 日期值 TIME 3字节 '-838:59:59'/'838:59:59' HH:MM:SS 时间值或持续时间 YEAR 1字节 1901/2155 YYYY 年份值 DATETIME 8字节 1000-01-0100:00:00/9999-12-31 23:59:59 YYYY-MM-DDHH:MM:SS 混合日期和时间值 TIMESTAMP 8字节 1970-01-0100:00:00/2037 年某时 YYYYMMDDHHMMSS 混合日期和时间值，时间戳 DATE、TIME 和 TEAR 类型 　　MySQL 用 DATE 和 TEAR 类型存储简单的日期值，使用 TIME 类型存储时间值。这些类型可以描述为字符串或不带分隔符的整数序列。如果描述为字符串，DATE 类型的值应该使用连字号作为分隔符分开，而 TIME 类型的值应该使用冒号作为分隔符分开。 　　需要注意的是，没有冒号分隔符的 TIME 类型值，将会被 MySQL 理解为持续的时间，而不是时间戳。 　　MySQL 还对日期的年份中的两个数字的值，或是 SQL 语句中为 TEAR 类型输入的两个数字进行最大限度的通译。因为所有 TEAR 类型的值必须用 4 个数字存储。MySQL 试图将 2 个数字的年份转换为 4 个数字的值。把在 00-69 范围内的值转换到 2000-2069 范围内。把 70-99 范围内的值转换到 1970-1979 之内。如果 MySQL 自动转换后的值并不符合我们的需要，请输入 4 个数字表示的年份。 DATETIME 和 TIMESTAMP 类型 　　 除了日期和时间数据类型，MySQL 还支持 DATEYIME 和 TIMESTAMP 这两种混合类型。它们可以把日期和时间作为单个的值进行存储。这两种类型通常用于自动存储包含当前日期和时间的时间戳，并可在需要执行大量数据库事务和需要建立一个调试和审查用途的审计跟踪的应用程序中发挥良好作用。 　　如果我们对 TIMESTAMP 类型的字段没有明确赋值，或是被赋与了 null 值。MySQL 会自动使用系统当前的日期和时间来填充它。 3、字符串类型 列类型                                                    需要的存储量  CHAR(M)                                                M字节，1 <= M <= 255  VARCHAR(M)                                         L+1 字节, 在此L <= M和1 <= M <= 255  TINYBLOB, TINYTEXT                           L+1 字节, 在此L< 2 ^ 8  BLOB, TEXT                                            L+2 字节, 在此L< 2 ^ 16  MEDIUMBLOB, MEDIUMTEXT               L+3 字节, 在此L< 2 ^ 24  LONGBLOB, LONGTEXT                        L+4 字节, 在此L< 2 ^ 32  ENUM('value1','value2',...)                        1 或 2 个字节, 取决于枚举值的数目(最大值65535）  SET('value1','value2',...)                            1，2，3，4或8个字节, 取决于集合成员的数量(最多64个成员）       MySQL 提供了 8 个基本的字符串类型，可以存储的范围从简单的一个字符到巨大的文本块或二进制字符串数据。 类型 大小 用途 CHAR 0-255字节 定长字符串 VARCHAR 0-255字节 变长字符串 TINYBLOB 0-255字节 不超过255个字符的二进制字符串 BLOB 0-65535字节 二进制形式的长文本数据 MEDIUMBLOB 0-16777 215字节 二进制形式的中等长度文本数据 LOGNGBLOB 0-4294 967 295字节 二进制形式的极大文本数据 TINYTEXT 0-255字节 短文本字符串 TEXT 0-65535字节 长文本数据 MEDIUMTEXT 0-16777 215字节 中等长度文本数据 LONGTEXT 0-4294 967 295字节 极大文本数据 CHAR 和 VARCHAR 类型 　　CHAR 类型用于定长字符串，并且必须在圆括号内用一个大小修饰符来定义。这个大小修饰符的范围从 0-255。比指定长度大的值将被截短，而比指定长度小的值将会用空格作填补。 　　CHAR 类型可以使用 BINARY 修饰符。当用于比较运算时，这个修饰符使 CHAR 以二进制方式参于运算，而不是以传统的区分大小写的方式。 　　CHAR 类型的一个变体是 VARCHAR 类型。它是一种可变长度的字符串类型，并且也必须带有一个范围在 0-255 之间的指示器。CHAR 和 VARCHGAR 不同之处在于 MuSQL 数据库处理这个指示器的方式：CHAR 把这个大小视为值的大小，不长度不足的情况下就用空格补足。而 VARCHAR 类型把它视为最大值并且只使用存储字符串实际需要的长度（增加一个额外字节来存储字符串本身的长度）来存储值。所以短于指示器长度的 VARCHAR 类型不会被空格填补，但长于指示器的值仍然会被截短。 　　因为 VARCHAR 类型可以根据实际内容动态改变存储值的长度，所以在不能确定字段需要多少字符时使用 VARCHAR 类型可以大大地节约磁盘空间、提高存储效率。 　　VARCHAR 类型在使用 BINARY 修饰符时与 CHAR 类型完全相同。 TEXT 和 BLOB 类型 　　对于字段长度要求超过 255 个的情况下，MySQL 提供了 TEXT 和 BLOB 两种类型。根据存储数据的大小，它们都有不同的子类型。这些大型的数据用于存储文本块或图像、声音文件等二进制数据类型。 　　TEXT 和 BLOB 类型在分类和比较上存在区别。BLOB 类型区分大小写，而 TEXT 不区分大小写。大小修饰符不用于各种 BLOB 和 TEXT 子类型。比指定类型支持的最大范围大的值将被自动截短。 3、复合类型 　　MySQL 还支持两种复合数据类型 ENUM 和 SET，它们扩展了 SQL 规范。虽然这些类型在技术上是字符串类型，但是可以被视为不同的数据类型。一个 ENUM 类型只允许从一个集合中取得一个值；而 SET 类型允许从一个集合中取得任意多个值。 ENUM 类型 　　ENUM 类型因为只允许在集合中取得一个值，有点类似于单选项。在处理相互排拆的数据时容易让人理解，比如人类的性别。ENUM 类型字段可以从集合中取得一个值或使用 null 值，除此之外的输入将会使 MySQL 在这个字段中插入一个空字符串。另外如果插入值的大小写与集合中值的大小写不匹配，MySQL 会自动使用插入值的大小写转换成与集合中大小写一致的值。 　　 ENUM 类型在系统内部可以存储为数字，并且从 1 开始用数字做索引。一个 ENUM 类型最多可以包含 65536 个元素，其中一个元素被 MySQL 保留，用来存储错误信息，这个错误值用索引 0 或者一个空字符串表示。 　　MySQL 认为 ENUM 类型集合中出现的值是合法输入，除此之外其它任何输入都将失败。这说明通过搜索包含空字符串或对应数字索引为 0 的行就可以很容易地找到错误记录的位置。 SET 类型 　　SET 类型与 ENUM 类型相似但不相同。SET 类型可以从预定义的集合中取得任意数量的值。并且与 ENUM 类型相同的是任何试图在 SET 类型字段中插入非预定义的值都会使 MySQL 插入一个空字符串。如果插入一个即有合法的元素又有非法的元素的记录，MySQL 将会保留合法的元素，除去非法的元素。 　　一个 SET 类型最多可以包含 64 项元素。在 SET 元素中值被存储为一个分离的“位”序列，这些“位”表示与它相对应的元素。“位”是创建有序元素集合的一种简单而有效的方式。并且它还去除了重复的元素，所以 SET 类型中不可能包含两个相同的元素。 　　希望从 SET 类型字段中找出非法的记录只需查找包含空字符串或二进制值为 0 的行。","title":"设计数据库必读 mysql 字段大全 大小 范围 用途 区别"},{"content":"MySql查询随机几条数据 想到了  Max  RAND  这几个函数 用以下2种办法都可以实现查询。  速度还行。 我的 IT技术资源库   http://www.itlib.tk/ 几十万数据左右， 没有什么问题。 转载注明出处：http://blog.csdn.net/yjflinchong/article/details/8444417 SELECT * FROM `news` WHERE id >= (SELECT floor(RAND() * (SELECT MAX(id) FROM `news`))) LIMIT 10; SELECT * FROM `news` AS t1 JOIN (SELECT ROUND(RAND() * ((SELECT MAX(id) FROM `news`)-(SELECT MIN(id) FROM `news`))+(SELECT MIN(id) FROM `news`)) AS id) AS t2 WHERE t1.id >= t2.id  LIMIT 10;","title":"MySql查询随机几条数据"},{"content":"安装环境： OS: Oracle linux 5.6 JDK: jdk1.6.0_18 Hadoop: hadoop-0.20.2 Hbase: hbase-0.90.5   安装准备： 1.       Jdk环境已安装：版本为1.6以上 2.       hadoop环境已安装：完全分布模式安装如下 http://blog.csdn.net/lichangzai/article/details/8206834 3.       hbase版本选择 Hbase 版本必需与 Hadoop版本匹配，否则会安装失败或不能正常使用。关于两者何种版本能正常匹配，可以看官方文档或在网上搜寻安装的成功案例。   4.       hbase软件下载 http://mirror.bjtu.edu.cn/apache/hbase/hbase-0.90.5/     安装概述： l         配置hosts，确保涉及的主机名均可以解析为ip l         编辑hbase-env.xml l         编辑hbase-site.xml l         编辑regionservers文件 l         把Hbase复制到其它节点 l         启动Hbase l         验证启动   安装步骤： 1.       配置hosts 此步在配置hadoop时已经完成，如下： [root@gc ~]$ cat /etc/hosts # Do not remove the following line, or various programs # that require network functionality will fail. 127.0.0.1               localhost.localdomain localhost ::1             localhost6.localdomain6 localhost6 192.168.2.101           rac1.localdomain rac1 192.168.2.102           rac2.localdomain rac2 192.168.2.100           gc.localdomain gc   2.       拷贝并解压安装包 [grid@gc ~]$ pwd /home/grid [grid@gc ~]$ tar -xzvf hbase-0.90.5.tar.gz   3.       替换hadoop核心jar包 主要目的是防止因为hbase和hadoop版本不同出现兼容问题，造成hmaster启动异常 $ pwd /home/grid/hbase-0.90.5/lib $ mv hadoop-core-0.20-append-r1056497.jar hadoop-core-0.20-append-r1056497.jar.bak $ cp /home/grid/hadoop-0.20.2/hadoop-0.20.2-core.jar /home/grid/hbase-0.90.5/lib/ $ chmod 775 hadoop-0.20.2-core.jar   4.       编辑hbase-env.xml [grid@gc conf]$ pwd /home/grid/hbase-0.90.5/conf [grid@gc conf]$ vi hbase-env.sh # 添加如下内容 # The java implementation to use.  Java 1.6 required. export JAVA_HOME=/usr/java/jdk1.6.0_18 # Extra Java CLASSPATH elements.  Optional. export HBASE_CLASSPATH=/home/grid/hadoop-0.20.2/conf # Where log files are stored.  $HBASE_HOME/logs by default. export HBASE_LOG_DIR=${HBASE_HOME}/logs # Tell HBase whether it should manage it's own instance of Zookeeper or not. export HBASE_MANAGES_ZK=true   5.       编辑hbase-site.xml [grid@gc conf]$ vi hbase-site.xml # 添加如下内容 <property> <name>hbase.rootdir<\/name> #设置hbase数据库存放数据的目录 <value>hdfs://gc:9000/hbase<\/value> <\/property> <property> <name>hbase.cluster.distributed<\/name>  #打开hbase分布模式 <value>true<\/value> <\/property> <property> <name>hbase.master<\/name> #指定hbase集群主控节点 <value>gc:60000<\/value> <\/property> <property> <name>hbase.zookeeper.quorum<\/name> <value>gc,rac1,rac2<\/value> #指定zookeeper集群节点名,因为是由zookeeper表决算法决定的 <\/property> <property> <name>hbase.zookeeper.property.dataDir<\/name> #指zookeeper集群data目录 <value>/home/grid/hbase-0.90.5/zookeeper<\/value> <\/property>   6.       编辑regionservers文件 [grid@gc conf]$ cat regionservers # 把localhost改为如下 rac1 rac2   7.       将修改的hbase目录同步其它节点 --分别同步到rac1,rac2两节点 [grid@gc ~]$ scp -r hbase-0.90.5 rac1:/home/grid/ [grid@gc ~]$ scp -r hbase-0.90.5 rac2:/home/grid/   8.       启动/关闭Hbase数据库集群 --启动hbase之前必需检查hadoop是否已经启动 [grid@gc ~]$ hadoop-0.20.2/bin/hadoop dfsadmin -report Configured Capacity: 45702094848 (42.56 GB) Present Capacity: 3562618880 (3.32 GB) DFS Remaining: 3562348544 (3.32 GB) DFS Used: 270336 (264 KB) DFS Used%: 0.01% Under replicated blocks: 4 Blocks with corrupt replicas: 0 Missing blocks: 0   ------------------------------------------------- Datanodes available: 2 (2 total, 0 dead)   Name: 192.168.2.101:50010 Decommission Status : Normal Configured Capacity: 22851047424 (21.28 GB) DFS Used: 135168 (132 KB) Non DFS Used: 20131606528 (18.75 GB) DFS Remaining: 2719305728(2.53 GB) DFS Used%: 0% DFS Remaining%: 11.9% Last contact: Tue Dec 25 09:40:14 CST 2012     Name: 192.168.2.102:50010 Decommission Status : Normal Configured Capacity: 22851047424 (21.28 GB) DFS Used: 135168 (132 KB) Non DFS Used: 22007869440 (20.5 GB) DFS Remaining: 843042816(803.99 MB) DFS Used%: 0% DFS Remaining%: 3.69% Last contact: Tue Dec 25 09:40:13 CST 2012   --启动Hbase集群 ----在gc master节点 [grid@gc ~]$ hbase-0.90.5/bin/start-hbase.sh rac2: starting zookeeper, logging to /home/grid/hbase-0.90.5/bin/../logs/hbase-grid-zookeeper-rac2.localdomain.out gc: starting zookeeper, logging to /home/grid/hbase-0.90.5/bin/../logs/hbase-grid-zookeeper-gc.localdomain.out rac1: starting zookeeper, logging to /home/grid/hbase-0.90.5/bin/../logs/hbase-grid-zookeeper-rac1.localdomain.out starting master, logging to /home/grid/hbase-0.90.5/bin/../logs/hbase-grid-master-gc.localdomain.out rac1: starting regionserver, logging to /home/grid/hbase-0.90.5/bin/../logs/hbase-grid-regionserver-rac1.localdomain.out rac2: starting regionserver, logging to /home/grid/hbase-0.90.5/bin/../logs/hbase-grid-regionserver-rac2.localdomain.out   --可以看到多出两个hbase进程 [grid@gc ~]$ jps 2718 HQuorumPeer 6875 JobTracker 6799 SecondaryNameNode 8129 org.eclipse.equinox.launcher_1.1.1.R36x_v20101122_1400.jar 2864 Jps 6651 NameNode 2772 HMaster   --rac1,rac2 slave节点 [grid@rac1 ~]$ jps 23663 HRegionServer 3736 DataNode 23585 HQuorumPeer 23737 Jps 3840 TaskTracker   [grid@rac2 ~]$ jps 10579 TaskTracker 29735 HQuorumPeer 29897 Jps 10480 DataNode 29812 HRegionServer   --通过浏览器验证: http://192.168.2.100:60010/master.jsp   --关闭hbase集群 [grid@gc hbase-0.90.5]$ bin/stop-hbase.sh stopping hbase................... gc: stopping zookeeper. rac2: stopping zookeeper. rac1: stopping zookeeper.   命令行操作： 1.       常用hbase命令 --进入habase [grid@gc ~]$ hbase-0.90.5/bin/hbase shell HBase Shell; enter 'help<RETURN>' for list of supported commands. Type \"exit<RETURN>\" to leave the HBase Shell Version 0.90.5, r1212209, Fri Dec  9 05:40:36 UTC 2011 hbase(main):001:0>   --查看数据库状态 hbase(main):002:0> status 2 servers, 0 dead, 1.0000 average load   --查询数据库版本 hbase(main):004:0> version 0.90.5, r1212209, Fri Dec  9 05:40:36 UTC 2011   --帮助命令 hbase(main):003:0> help HBase Shell, version 0.90.5, r1212209, Fri Dec  9 05:40:36 UTC 2011 Type 'help \"COMMAND\"', (e.g. 'help \"get\"' -- the quotes are necessary) for help on a specific command. Commands are grouped. Type 'help \"COMMAND_GROUP\"', (e.g. 'help \"general\"') for help on a command group.   COMMAND GROUPS:   Group name: general   Commands: status, version     Group name: ddl   Commands: alter, create, describe, disable, drop, enable, exists, is_disabled, is_enabled, list     Group name: dml   Commands: count, delete, deleteall, get, get_counter, incr, put, scan, truncate     Group name: tools   Commands: assign, balance_switch, balancer, close_region, compact, flush, major_compact, move, split, unassign, zk_dump     Group name: replication   Commands: add_peer, disable_peer, enable_peer, remove_peer, start_replication, stop_replication   SHELL USAGE: Quote all names in HBase Shell such as table and column names.  Commas delimit command parameters.  Type <RETURN> after entering a command to run it. Dictionaries of configuration used in the creation and alteration of tables are Ruby Hashes. They look like this:     {'key1' => 'value1', 'key2' => 'value2', ...}   and are opened and closed with curley-braces.  Key/values are delimited by the '=>' character combination.  Usually keys are predefined constants such as NAME, VERSIONS, COMPRESSION, etc.  Constants do not need to be quoted.  Type 'Object.constants' to see a (messy) list of all constants in the environment.   If you are using binary keys or values and need to enter them in the shell, use double-quote'd hexadecimal representation. For example:     hbase> get 't1', \"key\\x03\\x3f\\xcd\"   hbase> get 't1', \"key\\003\\023\\011\"   hbase> put 't1', \"test\\xef\\xff\", 'f1:', \"\\x01\\x33\\x40\"   The HBase shell is the (J)Ruby IRB with the above HBase-specific commands added. For more on the HBase Shell, see http://hbase.apache.org/docs/current/book.html   2.       Hbase数据库操作命令 --创建表 resume表逻辑模型： 行键 时间戳 列族binfo 列族edu 列族work lichangzai T2 binfo:age=’1980-1-1’     T3 binfo:sex=’man’     T5   edu:mschool=’rq no.1’   T6   edu:university=’qhddx’   T7     work:company1=’12580’ changfei T10 binfo:age=’1986-2-1’     T11   edu:university=’bjdx’   T12     work:company1=’LG’ …… Tn         --创建表 hbase(main):005:0> create 'resume','binfo','edu','work' 0 row(s) in 16.5710 seconds   --列出表 hbase(main):006:0> list TABLE                                                                                                                                                         resume                                                                                                                                                       1 row(s) in 1.6080 seconds   --查看表结构 hbase(main):007:0> describe 'resume' DESCRIPTION                                                                                           ENABLED                                                 {NAME => 'resume', FAMILIES => [{NAME => 'binfo', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', C true                                                    OMPRESSION => 'NONE', VERSIONS => '3', TTL => '2147483647', BLOCKSIZE => '65536', IN_MEMORY => 'fals                                                         e', BLOCKCACHE => 'true'}, {NAME => 'edu', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESS                                                         ION => 'NONE', VERSIONS => '3', TTL => '2147483647', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLO                                                          CKCACHE => 'true'}, {NAME => 'work', BLOOMFILTER => 'NONE', REPLICATION_SCOPE => '0', COMPRESSION =>                                                          'NONE', VERSIONS => '3', TTL => '2147483647', BLOCKSIZE => '65536', IN_MEMORY => 'false', BLOCKCACH                                                         E => 'true'}]}                                                                                                                                              1 row(s) in 1.8590 seconds   --添加列族 hbase(main):014:0> disable 'resume'                          0 row(s) in 4.2630 seconds hbase(main):015:0> alter 'resume',name='f1' 0 row(s) in 4.6990 seconds   --删除列族 hbase(main):017:0> alter 'resume',{NAME=>'f1',METHOD=>'delete'} 0 row(s) in 1.1390 seconds --或是 hbase(main):021:0> alter 'resume','delete' => 'f1' 0 row(s) in 1.9310 seconds hbase(main):022:0> enable 'resume' 0 row(s) in 5.9060 seconds     注意： （1）       ddl命令是区分大小写的，像ddl中的alter,create, drop, enable等都必需用小写。而{}中的属性名都必需用大写。 （2）       alter、drop表之前必需在先禁用(disabel)表，修改完后再启用表(enable)表，否则会报错   --查询禁用状态 hbase(main):024:0> is_disabled 'resume' false                                                                                                                                                        0 row(s) in 0.4930 seconds   hbase(main):021:0> is_enabled 'resume' true                                                                                                                                                         0 row(s) in 0.2450 seconds   --删除表 hbase(main):015:0> create 't1','f1' 0 row(s) in 15.3730 seconds   hbase(main):016:0> disable 't1' 0 row(s) in 6.4840 seconds   hbase(main):017:0> drop 't1' 0 row(s) in 7.3730 seconds   --查询表是否存在 hbase(main):018:0> exists 'resume' Table resume does exist                                                                                                                                       0 row(s) in 2.3900 seconds   hbase(main):019:0> exists 't1' Table t1 does not exist                                                                                                                                       0 row(s) in 1.3270 seconds   --插入数据 put 'resume','lichangzai','binfo:age','1980-1-1' put 'resume','lichangzai','binfo:sex','man' put 'resume','lichangzai','edu:mschool','rq no.1' put 'resume','lichangzai','edu:university','qhddx' put 'resume','lichangzai','work:company1','12580' put 'resume','lichangzai','work:company2','china mobile' put 'resume','lichangzai','binfo:site','blog.csdn.net/lichangzai' put 'resume','lichangzai','binfo:mobile','13712345678' put 'resume','changfei','binfo:age','1986-2-1' put 'resume','changfei','edu:university','bjdx' put 'resume','changfei','work:company1','LG' put 'resume','changfei','binfo:mobile','13598765401' put 'resume','changfei','binfo:site','hi.baidu/lichangzai'   --获取一行键的所有数据 hbase(main):014:0> get 'resume','lichangzai' COLUMN                                   CELL                                                                                                                 binfo:age                               timestamp=1356485720612, value=1980-1-1                                                                              binfo:mobile                            timestamp=1356485865523, value=13712345678                                                                            binfo:sex                               timestamp=1356485733603, value=man                                                                                   binfo:site                              timestamp=1356485859806, value=blog.csdn.net/lichangzai                                                              edu:mschool                             timestamp=1356485750361, value=rq no.1                                                                               edu:university                          timestamp=1356485764211, value=qhddx                                                                                 work:company1                           timestamp=1356485837743, value=12580                                                                                  work:company2                           timestamp=1356485849365, value=china mobile                                                                         8 row(s) in 2.1090 seconds   注意：必须通过行键Row Key来查询数据   --获取一个行键，一个列族的所有数据 hbase(main):015:0> get 'resume','lichangzai','binfo' COLUMN                                   CELL                                                                                                                 binfo:age                               timestamp=1356485720612, value=1980-1-1                                                                              binfo:mobile                            timestamp=1356485865523, value=13712345678                                                                            binfo:sex                               timestamp=1356485733603, value=man                                                                                   binfo:site                              timestamp=1356485859806, value=blog.csdn.net/lichangzai                                                             4 row(s) in 1.6010 seconds   --获取一个行键，一个列族中一个列的所有数据 hbase(main):017:0> get 'resume','lichangzai','binfo:sex'  COLUMN                                   CELL                                                                                                                  binfo:sex                               timestamp=1356485733603, value=man                                                                                  1 row(s) in 0.8980 seconds   --更新一条记录 hbase(main):018:0> put 'resume','lichangzai','binfo:mobile','13899999999' 0 row(s) in 1.7640 seconds   hbase(main):019:0> get 'resume','lichangzai','binfo:mobile' COLUMN                                   CELL                                                                                                                  binfo:mobile                            timestamp=1356486691591, value=13899999999                                                                          1 row(s) in 1.5710 seconds   注意：更新实质就是插入一条带有时间戳的记录，get查询时只显示最新时间的记录   --通过timestamp来获取数据 ------查询最新的时间戳的数据 hbase(main):020:0> get 'resume','lichangzai',{COLUMN=>'binfo:mobile',TIMESTAMP=>1356486691591} COLUMN                                   CELL                                                                                                                  binfo:mobile                            timestamp=1356486691591, value=13899999999                                                                          1 row(s) in 0.4060 seconds   ------查之前（即删除）时间戳的数据 hbase(main):021:0> get 'resume','lichangzai',{COLUMN=>'binfo:mobile',TIMESTAMP=>1356485865523}             COLUMN                                   CELL                                                                                                                  binfo:mobile                            timestamp=1356485865523, value=13712345678                                                                          1 row(s) in 0.7780 seconds   --全表扫描 hbase(main):022:0> scan 'resume' ROW                                      COLUMN+CELL                                                                                                          changfei                                column=binfo:age, timestamp=1356485874056, value=1986-2-1                                                             changfei                                column=binfo:mobile, timestamp=1356485897477, value=13598765401                                                      changfei                                column=binfo:site, timestamp=1356485906106, value=hi.baidu/lichangzai                                                changfei                                column=edu:university, timestamp=1356485880977, value=bjdx                                                            changfei                                column=work:company1, timestamp=1356485888939, value=LG                                                              lichangzai                              column=binfo:age, timestamp=1356485720612, value=1980-1-1                                                            lichangzai                              column=binfo:mobile, timestamp=1356486691591, value=13899999999                                                      lichangzai                              column=binfo:sex, timestamp=1356485733603, value=man                                                                 lichangzai                              column=binfo:site, timestamp=1356485859806, value=blog.csdn.net/lichangzai                                            lichangzai                              column=edu:mschool, timestamp=1356485750361, value=rq no.1                                                           lichangzai                              column=edu:university, timestamp=1356485764211, value=qhddx                                                          lichangzai                              column=work:company1, timestamp=1356485837743, value=12580                                                           lichangzai                              column=work:company2, timestamp=1356485849365, value=china mobile                                                   2 row(s) in 3.6300 seconds   --删除指定行键的列族字段 hbase(main):023:0> put 'resume','changfei','binfo:sex','man' 0 row(s) in 1.2630 seconds   hbase(main):024:0> delete 'resume','changfei','binfo:sex' 0 row(s) in 0.5890 seconds   hbase(main):026:0> get 'resume','changfei','binfo:sex' COLUMN                                   CELL                                                                                                                 0 row(s) in 0.5560 seconds   --删除整行 hbase(main):028:0> create 't1','f1','f2' 0 row(s) in 8.3950 seconds   hbase(main):029:0> put 't1','a','f1:col1','xxxxx' 0 row(s) in 2.6790 seconds   hbase(main):030:0> put 't1','a','f1:col2','xyxyx' 0 row(s) in 0.5130 seconds   hbase(main):031:0> put 't1','b','f2:cl1','ppppp' 0 row(s) in 1.2620 seconds   hbase(main):032:0> deleteall 't1','a' 0 row(s) in 1.2030 seconds   hbase(main):033:0> get 't1','a' COLUMN                                   CELL                                                                                                                 0 row(s) in 0.8980 seconds   --查询表中有多少行 hbase(main):035:0> count 'resume' 2 row(s) in 2.8150 seconds hbase(main):036:0> count 't1'    1 row(s) in 0.9500 seconds   --清空表 hbase(main):037:0> truncate 't1' Truncating 't1' table (it may take a while):  - Disabling table...  - Dropping table...  - Creating table... 0 row(s) in 21.0060 seconds   注意：Truncate表的处理过程：由于Hadoop的HDFS文件系统不允许直接修改，所以只能先删除表在重新创建已达到清空表的目的     3.             遇到的问题 问题： 在刚配置完成hbase安装后，各节点进程还正常，可是过一小段时间后，master节点的HMaster进程就自已停止了。 之后再重新启动master节点后，就出现了下面的问题 --master节点缺少HMaster进程 [grid@gc bin]$ ./start-hbase.sh rac1: starting zookeeper, logging to /home/grid/hbase-0.90.5/bin/../logs/hbase-grid-zookeeper-rac1.localdomain.out rac2: starting zookeeper, logging to /home/grid/hbase-0.90.5/bin/../logs/hbase-grid-zookeeper-rac2.localdomain.out gc: starting zookeeper, logging to /home/grid/hbase-0.90.5/bin/../logs/hbase-grid-zookeeper-gc.localdomain.out starting master, logging to /home/grid/hbase-0.90.5/bin/../logs/hbase-grid-master-gc.localdomain.out rac2: starting regionserver, logging to /home/grid/hbase-0.90.5/bin/../logs/hbase-grid-regionserver-rac2.localdomain.out rac1: starting regionserver, logging to /home/grid/hbase-0.90.5/bin/../logs/hbase-grid-regionserver-rac1.localdomain.out [grid@gc bin]$ jps 3871 NameNode 4075 JobTracker 8853 Jps 4011 SecondaryNameNode 8673 HQuorumPeer --两slave节点rac1,rac2进程正常 [grid@rac1 bin]$ jps 10353 HQuorumPeer 10576 Jps 6457 DataNode 6579 TaskTracker 10448 HRegionServer [grid@rac2 ~]$ jps 10311 HQuorumPeer 10534 Jps 6426 DataNode 6546 TaskTracker 10391 HRegionServer 下面是部分日志 --master节点gc的日志 [grid@gc logs]$ tail -100f hbase-grid-master-gc.localdomain.log 2012-12-25 15:23:45,842 INFO org.apache.zookeeper.ClientCnxn: Opening socket connection to server gc/192.168.2.100:2181 2012-12-25 15:23:45,853 INFO org.apache.zookeeper.ClientCnxn: Socket connection established to gc/192.168.2.100:2181, initiating session 2012-12-25 15:23:45,861 INFO org.apache.zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x0, likely server has closed socket, closing socket connection and attempting reconnect 2012-12-25 15:23:46,930 INFO org.apache.zookeeper.ClientCnxn: Opening socket connection to server rac1/192.168.2.101:2181 2012-12-25 15:23:47,167 WARN org.apache.zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect java.net.ConnectException: Connection refused         at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)         at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:574)         at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1119) 2012-12-25 15:23:48,251 INFO org.apache.zookeeper.ClientCnxn: Opening socket connection to server rac2/192.168.2.102:2181 2012-12-25 15:23:48,362 INFO org.apache.zookeeper.ZooKeeper: Session: 0x0 closed 2012-12-25 15:23:48,362 INFO org.apache.zookeeper.ClientCnxn: EventThread shut down 2012-12-25 15:23:48,367 ERROR org.apache.hadoop.hbase.master.HMasterCommandLine: Failed to start master java.lang.RuntimeException: Failed construction of Master: class org.apache.hadoop.hbase.master.HMaster         at org.apache.hadoop.hbase.master.HMaster.constructMaster(HMaster.java:1065)         at org.apache.hadoop.hbase.master.HMasterCommandLine.startMaster(HMasterCommandLine.java:142)         at org.apache.hadoop.hbase.master.HMasterCommandLine.run(HMasterCommandLine.java:102)         at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)         at org.apache.hadoop.hbase.util.ServerCommandLine.doMain(ServerCommandLine.java:76)         at org.apache.hadoop.hbase.master.HMaster.main(HMaster.java:1079) Caused by: org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase         at org.apache.zookeeper.KeeperException.create(KeeperException.java:90)         at org.apache.zookeeper.KeeperException.create(KeeperException.java:42)         at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:809)         at org.apache.zookeeper.ZooKeeper.exists(ZooKeeper.java:837)         at org.apache.hadoop.hbase.zookeeper.ZKUtil.createAndFailSilent(ZKUtil.java:931)         at org.apache.hadoop.hbase.zookeeper.ZooKeeperWatcher.<init>(ZooKeeperWatcher.java:134)         at org.apache.hadoop.hbase.master.HMaster.<init>(HMaster.java:219)         at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)         at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)         at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)         at java.lang.reflect.Constructor.newInstance(Constructor.java:513)         at org.apache.hadoop.hbase.master.HMaster.constructMaster(HMaster.java:1060)          [grid@gc logs]$ tail -100f hbase-grid-zookeeper-gc.localdomain.log 2012-12-25 15:23:57,380 WARN org.apache.zookeeper.server.quorum.QuorumCnxManager: Cannot open channel to 2 at election address rac2/192.168.2.102:3888 java.net.ConnectException: Connection refused       at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)       at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:574)       at sun.nio.ch.SocketAdaptor.connect(SocketAdaptor.java:100)         at org.apache.zookeeper.server.quorum.QuorumCnxManager.connectOne(QuorumCnxManager.java:366)         at org.apache.zookeeper.server.quorum.QuorumCnxManager.toSend(QuorumCnxManager.java:335)         at org.apache.zookeeper.server.quorum.FastLeaderElection$Messenger$WorkerSender.process(FastLeaderElection.java:360)         at org.apache.zookeeper.server.quorum.FastLeaderElection$Messenger$WorkerSender.run(FastLeaderElection.java:333)         at java.lang.Thread.run(Thread.java:619) ....... 2012-12-25 15:23:57,670 INFO org.apache.zookeeper.server.ZooKeeperServer: Server environment:user.home=/home/grid 2012-12-25 15:23:57,671 INFO org.apache.zookeeper.server.ZooKeeperServer: Server environment:user.dir=/home/grid/hbase-0.90.5 2012-12-25 15:23:57,679 INFO org.apache.zookeeper.server.ZooKeeperServer: Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 180000 datadir /home/grid/hbase-0.90.5/zookeeper/version-2 snapdir /home/grid/hbase-0.90.5/zookeeper/version-2 2012-12-25 15:23:58,118 WARN org.apache.zookeeper.server.quorum.Learner: Unexpected exception, tries=0, connecting to rac1/192.168.2.101:2888 java.net.ConnectException: Connection refused       at java.net.PlainSocketImpl.socketConnect(Native Method)       at java.net.PlainSocketImpl.doConnect(PlainSocketImpl.java:333)       at java.net.PlainSocketImpl.connectToAddress(PlainSocketImpl.java:195)       at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:182)       at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:366)       at java.net.Socket.connect(Socket.java:525)       at org.apache.zookeeper.server.quorum.Learner.connectToLeader(Learner.java:212)       at org.apache.zookeeper.server.quorum.Follower.followLeader(Follower.java:65)       at org.apache.zookeeper.server.quorum.QuorumPeer.run(QuorumPeer.java:644)        at 2012-12-25 15:24:00,886 INFO org.apache.zookeeper.server.quorum.Learner: Getting a snapshot from leader 2012-12-25 15:24:00,897 INFO org.apache.zookeeper.server.quorum.Learner: Setting leader epoch 9 2012-12-25 15:24:01,051 INFO org.apache.zookeeper.server.persistence.FileTxnSnapLog: Snapshotting: 900000000 2012-12-25 15:24:03,218 INFO org.apache.zookeeper.server.NIOServerCnxn: Accepted socket connection from /192.168.2.101:12397 2012-12-25 15:24:03,377 INFO org.apache.zookeeper.server.NIOServerCnxn: Client attempting to establish new session at /192.168.2.101:12397 2012-12-25 15:24:03,396 WARN org.apache.zookeeper.server.quorum.Learner: Got zxid 0x900000001 expected 0x1 2012-12-25 15:24:03,400 INFO org.apache.zookeeper.server.persistence.FileTxnLog: Creating new log file: log.900000001 2012-12-25 15:24:03,470 INFO org.apache.zookeeper.server.NIOServerCnxn: Established session 0x3bd0f2560e0000 with negotiated timeout 180000 for client /192.168.2.101:12397 2012-12-25 15:24:07,057 INFO org.apache.zookeeper.server.NIOServerCnxn: Accepted socket connection from /192.168.2.102:52300 2012-12-25 15:24:07,690 INFO org.apache.zookeeper.server.NIOServerCnxn: Client attempting to establish new session at /192.168.2.102:52300 2012-12-25 15:24:07,712 INFO org.apache.zookeeper.server.NIOServerCnxn: Established session 0x3bd0f2560e0001 with negotiated timeout 180000 for client /192.168.2.102:52300 2012-12-25 15:24:10,016 INFO org.apache.zookeeper.server.quorum.FastLeaderElection: Notification: 2 (n.leader), 34359738398 (n.zxid), 1 (n.round), LOOKING (n.state), 2 (n.sid), FOLLOWING (my state) 2012-12-25 15:24:30,422 INFO org.apache.zookeeper.server.quorum.FastLeaderElection: Notification: 2 (n.leader), 34359738398 (n.zxid), 2 (n.round), LOOKING (n.state), 2 (n.sid), FOLLOWING (my state) 2012-12-25 15:24:30,423 INFO org.apache.zookeeper.server.quorum.FastLeaderElection: Notification: 2 (n.leader), 34359738398 (n.zxid), 2 (n.round), LOOKING (n.state), 2 (n.sid), FOLLOWING (my state) --slave节点rac2的日志 [grid@rac2 logs]$ tail -100f hbase-grid-regionserver-rac2.localdomain.log 2012-12-25 15:23:46,939 INFO org.apache.zookeeper.ClientCnxn: Opening socket connection to server rac1/192.168.2.101:2181 2012-12-25 15:23:47,154 INFO org.apache.zookeeper.ClientCnxn: Socket connection established to rac1/192.168.2.101:2181, initiating session 2012-12-25 15:23:47,453 INFO org.apache.zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x0, likely server has closed socket, closing socket connection and attempting reconnect 2012-12-25 15:23:47,977 INFO org.apache.zookeeper.ClientCnxn: Opening socket connection to server gc/192.168.2.100:2181 2012-12-25 15:23:48,354 INFO org.apache.zookeeper.ClientCnxn: Socket connection established to gc/192.168.2.100:2181, initiating session 2012-12-25 15:23:49,583 INFO org.apache.zookeeper.ClientCnxn: Session establishment complete on server gc/192.168.2.100:2181, sessionid = 0x3bd0f2560e0001, negotiated timeout = 180000 2012-12-25 15:23:52,052 INFO org.apache.hadoop.hbase.regionserver.ShutdownHook: Installed shutdown hook thread: Shutdownhook:regionserver60020   解决方法 禁用IPV6，将/etc/hosts文件里面的：：1 localhost那一行删掉重启 [grid@rac1 ~]$ cat /etc/hosts 127.0.0.1       localhost.localdomain localhost # ::1           localhost6.localdomain6 localhosti6 192.168.2.101   rac1.localdomain        rac1 192.168.2.102   rac2.localdomain        rac2 192.168.2.100   gc.localdomain  gc   Hbase故障解决： http://wiki.apache.org/hadoop/Hbase/Troubleshooting       参考了这名网友的文章： http://chfpdxx.blog.163.com/blog/static/29542296201241411325789/","title":"hadoop学习笔记之-hbase完全分布模式安装"},{"content":"#readingimport MySQLdbdb= MySQLdb.connect(host=\"localhost\", user=\"python-test\", passwd=\"python\",db=\"python-test\")#连接cursor = db.cursor()stmt = \"SELECT * from books\"cursor.execute(stmt)#执行动作rows = cursor.fetchall ()for row in rows:    print \"Row: \"    for col in row :        print \"Column: %s\" % (col)    print \"End of Row\"print \"Number of rows returned: %d\" % cursor.rowcountcursor.close()db.close() #关闭 #updatingimport MySQLdbimport MySQLdb.cursorsdef get_column_name( data, prompt, names ) :    value=-1    while value == -1:        idx = 1        for col in data :            print str(idx) + \": \" + col            names.append( col )            idx = idx + 1        value = int( raw_input(prompt) )        if value < 1 or value >= idx :            value = -1    return valueconn = MySQLdb.Connect(host='localhost',user='root',passwd='',db='dragon') #连接cursor = conn.cursor(cursorclass=MySQLdb.cursors.DictCursor)cursor.execute(\"SELECT * FROM books\")data = cursor.fetchone()names = []old_value = get_column_name( data, \"Which column do you want to change records for? \", names )names = []new_value = get_column_name( data, \"Which column do you want to change records to? \", names )old_val = raw_input(\"What value do you want to change for \" + names[old_value-1] + \": \")new_val = raw_input(\"What value do you want to change to for \" + names[new_value-1] + \": \")stmt = \"UPDATE books SET \" + names[new_value-1] + \" = '\"+ new_val + \"' WHERE \" + names[old_value-1] + \" = '\" + old_val + \"'\"print stmtcursor.execute(stmt)print \"Rows affected: \" + str(cursor.rowcount)cursor.close()conn.commit()conn.close() #writingimport MySQLdbdb= MySQLdb.connect(host=\"localhost\", user=\"python-test\", passwd=\"python\",db=\"python-test\")try:    title = raw_input(\"Please enter a book title: \")    if title == \"\" :        exit    author = raw_input(\"Please enter the author's name: \")    pubdate = int( raw_input(\"Enter the publication year: \") )except:    print \"Invalid value\"    exitprint \"Title: [\" + title + \"]\"print \"Author: [\"+ author + \"]\"print \"Publication Date: \" + str(pubdate)cursor = db.cursor()stmt = \"INSERT INTO Books (BookName, BookAuthor, PublicationDate) VALUES ('\"stmt = stmt + titlestmt = stmt + \"', '\"stmt = stmt + authorstmt = stmt + \"', \"stmt = stmt + str(pubdate)stmt = stmt + \")\"cursor.execute(stmt)print \"Record added!\"cursor.close ()db.commit ()","title":"mysqldb"},{"content":"最近在整一个网站，论坛采用phpbb3，主页嘛想用自己的，于是去找了下phpbb3的passport，似乎不怎么好使 于是去phpbb的官网找，找到一些2009，2010年的来文章，不太好用，或者说我对phpbb的理解还没到那个地步 对于$template不太会用，有熟悉的可以参考下： https://blog.phpbb.com/2009/11/09/how-to-display-posts-and-topics-on-external-pages/ 关于$template的使用： https://wiki.phpbb.com/Tutorial.Template_syntax 后来实在没有办法，就继续去谷歌搜，后来找到了一个办法，就是自己直接读数据库的办法 参考网址如下： https://www.phpbb.com/community/viewtopic.php?f=72&t=586994 上面的网站已经说的很清楚了，我这里再重新说一下自己完成的过程，呵呵，盗取吧 首先我的论坛是 http://localhost/phpbb3/index.php 我在phpbb3的目录下新建了一个testphpbb文件夹，并在该文件夹下面新建了一个testlasttopic.php <? include_once (\"forum/config.php\");   $mysql_connection = mysql_connect ($dbhost, $dbuser, $dbpasswd) or die (\"Connection failed\");   mysql_select_db ($dbname) or die (\"Selecting database failed\");   $query = \"SELECT topic_id,topic_title FROM phpbb3_topics order by topic_id desc limit 10\";   $res   = mysql_query($query);   while($data = @mysql_fetch_array($res))   {    echo \" <a href=\\\"forum/viewtopic.php?t=\".$data[\"topic_id\"].\"\\\">\".$data['topic_title'].\"<\/a><br>\";   }?>这里包含了一个config.php的头文件，该文件的路径是在根目录下，所以使用 ../config.php 然后这里的 $query = \"SELECT topic_id,topic_title FROM phpbb3_topics order by topic_id desc limit 10\";应该要改改查询的表命，我对应的表名是 phpbb_topics，那么所有代码如下： <?php   require_once(\"../config.php\");   $mysql_connection = mysql_connect ($dbhost, $dbuser, $dbpasswd) or die (\"Connection failed\");   mysql_select_db ($dbname) or die (\"Selecting database failed\");   $query = \"SELECT topic_id,topic_title FROM phpbb_topics order by topic_id desc limit 10\";   $res   = mysql_query($query);      while($data = @mysql_fetch_array($res))   {    echo \" <a href=\\\"../viewtopic.php?t=\".$data[\"topic_id\"].\"\\\">\".$data['topic_title'].\"<\/a><br>\";   }?>这样就可以获得你想要的最近发表的10篇主题了 如果想要更多的，可以根据自己的需要查询不同的表，获取不同的内容来完成自己的需要。 做了嵌入式之后，突然做网站，然后很多朋友问我最近在干嘛的时候，我说我在做网站，结果得到的一大堆鄙视 哈哈，其实吧，自己有自己的需要嘛，做网站咋啦，我想做我需要的.... 接下来继续整phpbb跟主页的自动登陆，session的结合可能更有意思...哈哈 (已经找到方法了，至于方法嘛，明天再继续写下篇吧，搜国外的内容就是好解决问题，偶尔对gfw有些郁闷)","title":"PHPBB3获取最近发表的文章"},{"content":"DB2 自增长列测试 1当想将表中一列修改为自动增长时，可用下面命令： Alter table  <table name>  alter column <column name>  set not null Alter table <table name> alter column <column name> set generated always as identity (start with 1,increment by 1) 上面命令是在改一表中列的属性时，在网上找到的很有用。 2当修改表中一列自动增长的开始值时，可用下面的命令： ALTER TABLE <talbe_name> ALTER COLUMN <column name> RESTART WITH 18;   测试： CREATE TABLE customer_orders_t (    order_id  INT NOT NULL  GENERATED ALWAYS AS IDENTITY       (START WITH 1         INCREMENT BY 1         MINVALUE 1         NO MAXVALUE        NO CYCLE        NO CACHE        ORDER),    order_date         DATE NOT NULL,    cust_id           INT NOT NULL,    product_id         INT NOT NULL,    quantity           INT NOT NULL,    price              DECIMAL(10,2)         NOT NULL,    status             CHAR(9)         NOT NULL,    PRIMARY KEY (order_date, order_id)) 注：该列中的以及它本身的 IDENTITY 属性并没有保证所生成的序列值是唯一的。 但是， PRIMARY KEY 约束保证了表中行的唯一性。 为了确保只将自动生成的值插入标识列，他们指定了 GENERATED ALWAYS 子句。 使用最后一个生成的 order_id 来确定多少数据 选项 NO CACHE 和 ORDER 确保了在系统故障的情况下，不废弃未使用的标识值。   测试1  插入数据 insert into customer_orders_t values (default,current date,12,12,12,10.2,'2') --成功 insert into customer_orders_t values (1,current date,12,12,12,10.2,'2') -- 报错  因为：IDENTITY字段不允许指定值 --解决方案  ALTER TABLE customer_orders_t         ALTER COLUMN order_id         SET GENERATED BY DEFAULT --创建orders_seq对象  CREATE SEQUENCE orders_seq         AS INT         START WITH 1         INCREMENT BY 1         MINVALUE 1         NO MAXVALUE    NO CYCLE    NO CACHE    ORDER --插入数据 INSERT INTO customer_orders_t VALUES (NEXT VALUE FOR orders_seq, CURRENT DATE,12,12,12,10.2,'2')   1、命令行取sequence soc.nico_qian的下一个值：  db2 \"values next value for soc.nico_qian\" 2、命令行重置sequence soc.nico_qian：  db2 \"alter sequence soc.nico_qian restart\"，重置后的值默认为创建SEQUENCE时的MINVALUE 3、命令行以指定值22重置sequence soc.nico_qian：  db2 \"alter sequence soc.nico_qian restart with 22\" 4、命令行重置表KS.CHECK_CONDITION的IDENTITY字段初始值为20：  db2 \"ALTER TABLE KS.CHECK_CONDITION ALTER COLUMN identity_column_name RESTART WITH 20\" 5、如果sequence被以命令行的方式重置，那么用到这个sequence的嵌入式C程序代码的绑定包  　　的VALID字段会被修改为N，那么在下一次这个代码被调用的时候，DB2会自动重新绑定 　　 此代码的绑定包，这个动作会给应用程序带来不可预知的后果，比如：如果这段代码是在很 　　 频繁的被用到的时间段内被重新绑定，那么极易造成死锁。 　　 同样的问题会出现在IDENTITY字段上。     DB2自增加字段表 导入导出 测试  CREATE TABLE EMPLOYEE ( SERIALNUMBER BIGINT NOT NULL    GENERATED ALWAYS AS IDENTITY    (START WITH 1, INCREMENT BY 1),    FIRSTNAME CHAR(64),    LASTNAME CHAR(64),    SALARY   DECIMAL(10, 2),    PRIMARY KEY (SERIALNUMBER))  CREATE TABLE EMPLOYEE1( SERIALNUMBER BIGINT NOT NULL    GENERATED ALWAYS AS IDENTITY    (START WITH 1, INCREMENT BY 1),    FIRSTNAME CHAR(64),    LASTNAME CHAR(64),    SALARY   DECIMAL(10, 2),    PRIMARY KEY (SERIALNUMBER)) select * from EMPLOYEE; select * from EMPLOYEE1; identityignore 忽略自增identitymissing 自动生成自增identityoverride 使用自增 insert into db2admin.EMPLOYEE(FIRSTNAME,LASTNAME,SALARY)values ( 'A','AA',1); insert into db2admin.EMPLOYEE(FIRSTNAME,LASTNAME,SALARY)values ( 'B','BB',2); insert into db2admin.EMPLOYEE(FIRSTNAME,LASTNAME,SALARY)values ( 'C','CC',3); --TEST 全量导出 db2 export to D:\\PRODUCTION.ixf of ixf select * from db2admin.EMPLOYEE --直接插入 报错 --不允许插入 db2 load CLIENT from D:\\PRODUCTION.ixf of ixf replace into  db2admin.EMPLOYEE1 NONRECOVERABLE db2 import from D:\\PRODUCTION.ixf of ixf    insert into db2admin.EMPLOYEE1 --identityignore 忽略源自增字段 方式插入 --插入正常 db2 load CLIENT from D:\\PRODUCTION.ixf of ixf  modified by identityignore replace into  db2admin.EMPLOYEE1 NONRECOVERABLE db2 import from D:\\PRODUCTION.ixf of ixf  modified by identityignore   commitcount 1000  insert into db2admin.EMPLOYEE1 --identitymissing 自动生成目标自增字段方式插入  --插入错位 db2 load CLIENT from D:\\PRODUCTION.ixf of ixf  modified by identitymissing  replace into  db2admin.EMPLOYEE1 NONRECOVERABLE db2 import from D:\\PRODUCTION.ixf of ixf  modified by identitymissing    commitcount 1000  insert into db2admin.EMPLOYEE1 --identityoverride 使用源自增字段方式插入   OK db2 load CLIENT from D:\\PRODUCTION.ixf of ixf  modified by identityoverride  replace into  db2admin.EMPLOYEE1  NONRECOVERABLE --TEST  部分导出 db2 export to D:\\PRODUCTION_1.ixf of ixf select FIRSTNAME,LASTNAME,SALARY from db2admin.EMPLOYEE --部分直接插入 OK db2 load CLIENT from D:\\PRODUCTION_1.ixf of ixf replace into  db2admin.EMPLOYEE1( FIRSTNAME,LASTNAME,SALARY) NONRECOVERABLE db2 import from D:\\PRODUCTION_1.ixf of ixf  insert into  db2admin.EMPLOYEE1( FIRSTNAME,LASTNAME,SALARY) --部分忽略源自增字段直接插入 OK db2 load CLIENT from D:\\PRODUCTION_1.ixf of ixf  modified by identityignore replace into  db2admin.EMPLOYEE1( FIRSTNAME,LASTNAME,SALARY) NONRECOVERABLE db2 import from D:\\PRODUCTION_1.ixf of ixf  modified by identityignore   commitcount 1000  insert into db2admin.EMPLOYEE1( FIRSTNAME,LASTNAME,SALARY) --identitymissing 自动生成目标自增字段方式插入   OK db2 load CLIENT from D:\\PRODUCTION_1.ixf of ixf  modified by identitymissing  replace into  db2admin.EMPLOYEE1( FIRSTNAME,LASTNAME,SALARY) NONRECOVERABLE db2 import from D:\\PRODUCTION_1.ixf of ixf  modified by identitymissing    commitcount 1000  insert into db2admin.EMPLOYEE1( FIRSTNAME,LASTNAME,SALARY) --identityoverride 自动生成自增方式插入   --缺少字段错误 db2 load CLIENT from D:\\PRODUCTION_1.ixf of ixf  modified by identityoverride  replace into  db2admin.EMPLOYEE1( FIRSTNAME,LASTNAME,SALARY) NONRECOVERABLE  ","title":"DB2 自增长列导入、导出测试"},{"content":"如何添加节点Oracle 10g RAC 添加节点 目前RAC环境如下,先要删除racdb3 SQL> select INSTANCE_NAME,HOST_NAME,VERSION,STARTUP_TIME,STATUS,ACTIVE_STATE,INSTANCE_ROLE,DATABASE_STATUS from gv$INSTANCE;INSTANCE_NAME\t HOST_NAME  VERSION\t      STARTUP_TIME\t      STATUS\t   ACTIVE_ST INSTANCE_ROLE\tDATABASE_STATUS---------------- ---------- ----------------- ----------------------- ------------ --------- ------------------ -----------------racdb1\t\t racnode1   10.2.0.5.0\t      27-DEC-2012 14:52:55    OPEN\t   NORMAL    PRIMARY_INSTANCE\tACTIVEracdb3\t\t racnode3   10.2.0.5.0\t      27-DEC-2012 15:21:09    OPEN\t   NORMAL    PRIMARY_INSTANCE\tACTIVEracdb2\t\t racnode2   10.2.0.5.0\t      27-DEC-2012 15:19:52    OPEN\t   NORMAL    PRIMARY_INSTANCE\tACTIVESQL> exitDisconnected from Oracle Database 10g Enterprise Edition Release 10.2.0.5.0 - 64bit ProductionWith the Partitioning, Real Application Clusters, OLAP, Data Miningand Real Application Testing options[oracle@racnode1 ~]$ crs_stat -tName           Type           Target    State     Host        ------------------------------------------------------------ora.racdb.db   application    ONLINE    ONLINE    racnode2    ora....b1.inst application    ONLINE    ONLINE    racnode1    ora....b2.inst application    ONLINE    ONLINE    racnode2    ora....b3.inst application    ONLINE    ONLINE    racnode3    ora.....zwc.cs application    ONLINE    ONLINE    racnode1    ora....db1.srv application    ONLINE    ONLINE    racnode1    ora....SM1.asm application    ONLINE    ONLINE    racnode1    ora....E1.lsnr application    ONLINE    ONLINE    racnode1    ora....de1.gsd application    ONLINE    ONLINE    racnode1    ora....de1.ons application    ONLINE    ONLINE    racnode1    ora....de1.vip application    ONLINE    ONLINE    racnode1    ora....SM2.asm application    ONLINE    ONLINE    racnode2    ora....E2.lsnr application    ONLINE    ONLINE    racnode2    ora....de2.gsd application    ONLINE    ONLINE    racnode2    ora....de2.ons application    ONLINE    ONLINE    racnode2    ora....de2.vip application    ONLINE    ONLINE    racnode2    ora....SM3.asm application    ONLINE    ONLINE    racnode3    ora....E3.lsnr application    ONLINE    ONLINE    racnode3    ora....de3.gsd application    ONLINE    ONLINE    racnode3    ora....de3.ons application    ONLINE    ONLINE    racnode3    ora....de3.vip application    ONLINE    ONLINE    racnode3 停止racdb3的instance [oracle@racnode1 ~]$ srvctl stop instance -d racdb -i racdb3[oracle@racnode1 ~]$ crs_stat -tName           Type           Target    State     Host        ------------------------------------------------------------ora.racdb.db   application    ONLINE    ONLINE    racnode2    ora....b1.inst application    ONLINE    ONLINE    racnode1    ora....b2.inst application    ONLINE    ONLINE    racnode2    ora....b3.inst application    OFFLINE   OFFLINE               ora.....zwc.cs application    ONLINE    ONLINE    racnode1    ora....db1.srv application    ONLINE    ONLINE    racnode1    ora....SM1.asm application    ONLINE    ONLINE    racnode1    ora....E1.lsnr application    ONLINE    ONLINE    racnode1    ora....de1.gsd application    ONLINE    ONLINE    racnode1    ora....de1.ons application    ONLINE    ONLINE    racnode1    ora....de1.vip application    ONLINE    ONLINE    racnode1    ora....SM2.asm application    ONLINE    ONLINE    racnode2    ora....E2.lsnr application    ONLINE    ONLINE    racnode2    ora....de2.gsd application    ONLINE    ONLINE    racnode2    ora....de2.ons application    ONLINE    ONLINE    racnode2    ora....de2.vip application    ONLINE    ONLINE    racnode2    ora....SM3.asm application    ONLINE    ONLINE    racnode3    ora....E3.lsnr application    ONLINE    ONLINE    racnode3    ora....de3.gsd application    ONLINE    ONLINE    racnode3    ora....de3.ons application    ONLINE    ONLINE    racnode3    ora....de3.vip application    ONLINE    ONLINE    racnode3    dbca删除racdb3 racdb3选择Not Used 可以看到racdb3的inst已经删除 [oracle@racnode1 ~]$ crs_stat -tName           Type           Target    State     Host        ------------------------------------------------------------ora.racdb.db   application    ONLINE    ONLINE    racnode2    ora....b1.inst application    ONLINE    ONLINE    racnode1    ora....b2.inst application    ONLINE    ONLINE    racnode2    ora.....zwc.cs application    ONLINE    ONLINE    racnode1    ora....db1.srv application    ONLINE    ONLINE    racnode1    ora....SM1.asm application    ONLINE    ONLINE    racnode1    ora....E1.lsnr application    ONLINE    ONLINE    racnode1    ora....de1.gsd application    ONLINE    ONLINE    racnode1    ora....de1.ons application    ONLINE    ONLINE    racnode1    ora....de1.vip application    ONLINE    ONLINE    racnode1    ora....SM2.asm application    ONLINE    ONLINE    racnode2    ora....E2.lsnr application    ONLINE    ONLINE    racnode2    ora....de2.gsd application    ONLINE    ONLINE    racnode2    ora....de2.ons application    ONLINE    ONLINE    racnode2    ora....de2.vip application    ONLINE    ONLINE    racnode2    ora....SM3.asm application    ONLINE    ONLINE    racnode3    ora....E3.lsnr application    ONLINE    ONLINE    racnode3    ora....de3.gsd application    ONLINE    ONLINE    racnode3    ora....de3.ons application    ONLINE    ONLINE    racnode3    ora....de3.vip application    ONLINE    ONLINE    racnode3    删除racdb3的asm instance [oracle@racnode1 ~]$ srvctl stop asm -n racnode3[oracle@racnode1 ~]$ srvctl remove asm -n racnode3 racdb3的asm已经删除 [oracle@racnode1 ~]$ crs_stat -tName           Type           Target    State     Host        ------------------------------------------------------------ora.racdb.db   application    ONLINE    ONLINE    racnode2    ora....b1.inst application    ONLINE    ONLINE    racnode1    ora....b2.inst application    ONLINE    ONLINE    racnode2    ora.....zwc.cs application    ONLINE    ONLINE    racnode1    ora....db1.srv application    ONLINE    ONLINE    racnode1    ora....SM1.asm application    ONLINE    ONLINE    racnode1    ora....E1.lsnr application    ONLINE    ONLINE    racnode1    ora....de1.gsd application    ONLINE    ONLINE    racnode1    ora....de1.ons application    ONLINE    ONLINE    racnode1    ora....de1.vip application    ONLINE    ONLINE    racnode1    ora....SM2.asm application    ONLINE    ONLINE    racnode2    ora....E2.lsnr application    ONLINE    ONLINE    racnode2    ora....de2.gsd application    ONLINE    ONLINE    racnode2    ora....de2.ons application    ONLINE    ONLINE    racnode2    ora....de2.vip application    ONLINE    ONLINE    racnode2    ora....E3.lsnr application    ONLINE    ONLINE    racnode3    ora....de3.gsd application    ONLINE    ONLINE    racnode3    ora....de3.ons application    ONLINE    ONLINE    racnode3    ora....de3.vip application    ONLINE    ONLINE    racnode3  netca删除监听 lsnr资源已经删除 [oracle@racnode1 ~]$ crs_stat -tName           Type           Target    State     Host        ------------------------------------------------------------ora.racdb.db   application    ONLINE    ONLINE    racnode2    ora....b1.inst application    ONLINE    ONLINE    racnode1    ora....b2.inst application    ONLINE    ONLINE    racnode2    ora.....zwc.cs application    ONLINE    ONLINE    racnode1    ora....db1.srv application    ONLINE    ONLINE    racnode1    ora....SM1.asm application    ONLINE    ONLINE    racnode1    ora....E1.lsnr application    ONLINE    ONLINE    racnode1    ora....de1.gsd application    ONLINE    ONLINE    racnode1    ora....de1.ons application    ONLINE    ONLINE    racnode1    ora....de1.vip application    ONLINE    ONLINE    racnode1    ora....SM2.asm application    ONLINE    ONLINE    racnode2    ora....E2.lsnr application    ONLINE    ONLINE    racnode2    ora....de2.gsd application    ONLINE    ONLINE    racnode2    ora....de2.ons application    ONLINE    ONLINE    racnode2    ora....de2.vip application    ONLINE    ONLINE    racnode2    ora....de3.gsd application    ONLINE    ONLINE    racnode3    ora....de3.ons application    ONLINE    ONLINE    racnode3    ora....de3.vip application    ONLINE    ONLINE    racnode3 更新oraInventory racnode1 [oracle@racnode1 bin]$ cd $ORACLE_HOME/oui/bin[oracle@racnode1 bin]$ ./runInstaller -updateNodeList ORACLE_HOME=$ORACLE_HOME \"CLUSTER_NODES=racnode1,racnode2\"Starting Oracle Universal Installer...No pre-requisite checks found in oraparam.ini, no system pre-requisite checks will be executed.The inventory pointer is located at /etc/oraInst.locThe inventory is located at /u01/app/oracle/oraInventory'UpdateNodeList' was successful.racnode3 [oracle@racnode3 bin]$ ./runInstaller -updateNodeList ORACLE_HOME=$ORACLE_HOME \"CLUSTER_NODES=racnode3\" -localStarting Oracle Universal Installer...No pre-requisite checks found in oraparam.ini, no system pre-requisite checks will be executed.The inventory pointer is located at /etc/oraInst.locThe inventory is located at /u01/app/oracle/oraInventory'UpdateNodeList' was successful. 在racnode3删除oracle database software [oracle@racnode3 bin]$ ./runInstaller -deinstallStarting Oracle Universal Installer...No pre-requisite checks found in oraparam.ini, no system pre-requisite checks will be executed.Preparing to launch Oracle Universal Installer from /tmp/OraInstall2012-12-27_05-33-49PM. Please wait ...[oracle@racnode3 bin]$ Oracle Universal Installer, Version 10.2.0.5.0 ProductionCopyright (C) 1999, 2010, Oracle. All rights reserved. 删除nodeapps gsd,ons,vip [oracle@racnode1 bin]$ srvctl  stop nodeapps -n racnode3[oracle@racnode1 ~]$ su - rootPassword: [root@racnode1 ~]# export ORACLE_HOME=/u01/app/oracle/product/10.2.0/db_1[root@racnode1 ~]# cd /u01/app/oracle/product/10.2.0/db_1/bin[root@racnode1 bin]# ./srvctl remove nodeapps -n racnode3Please confirm that you intend to remove the node-level applications on node racnode3 (y/[n]) y[root@racnode1 bin]# su - oracle[oracle@racnode1 ~]$ crs_stat -tName           Type           Target    State     Host        ------------------------------------------------------------ora.racdb.db   application    ONLINE    ONLINE    racnode2    ora....b1.inst application    ONLINE    ONLINE    racnode1    ora....b2.inst application    ONLINE    ONLINE    racnode2    ora.....zwc.cs application    ONLINE    ONLINE    racnode1    ora....db1.srv application    ONLINE    ONLINE    racnode1    ora....SM1.asm application    ONLINE    ONLINE    racnode1    ora....E1.lsnr application    ONLINE    ONLINE    racnode1    ora....de1.gsd application    ONLINE    ONLINE    racnode1    ora....de1.ons application    ONLINE    ONLINE    racnode1    ora....de1.vip application    ONLINE    ONLINE    racnode1    ora....SM2.asm application    ONLINE    ONLINE    racnode2    ora....E2.lsnr application    ONLINE    ONLINE    racnode2    ora....de2.gsd application    ONLINE    ONLINE    racnode2    ora....de2.ons application    ONLINE    ONLINE    racnode2    ora....de2.vip application    ONLINE    ONLINE    racnode2    [oracle@racnode1 ~]$ 使用root用户在racnode3关闭cluster [root@racnode3 ~]# cd /u01/app/oracle/product/10.2.0/crs/install[root@racnode3 install]# ./rootdelete.sh CRS-0210: Could not find resource 'ora.racnode3.ons'.CRS-0210: Could not find resource 'ora.racnode3.vip'.CRS-0210: Could not find resource 'ora.racnode3.gsd'.Shutting down Oracle Cluster Ready Services (CRS):Dec 27 17:50:39.554 | INF | daemon shutting downStopping resources. This could take several minutes.Successfully stopped CRS resources.Stopping CSSD.Shutting down CSS daemon.Shutdown request successfully issued.Shutdown has begun. The daemons should exit soon.Checking to see if Oracle CRS stack is down...Oracle CRS stack is not running.Oracle CRS stack is down now.Removing script for Oracle Cluster Ready servicesUpdating ocr file for downgradeCleaning up SCR settings in '/etc/oracle/scls_scr'Cleaning up Network socket directories[root@racnode3 install]# 在racnode1使用root删除racnode3 [oracle@racnode1 ~]$ olsnodes -n -iracnode1\t1\tracnode1-vipracnode2\t2\tracnode2-vipracnode3\t3\t<none>[oracle@racnode1 ~]$ su - rootPassword: [root@racnode1 ~]# cd /u01/app/oracle/product/10.2.0/crs/install[root@racnode1 install]# ./rootdeletenode.sh racnode3 3CRS nodeapps are deleted successfullyclscfg: EXISTING configuration version 3 detected.clscfg: version 3 is 10G Release 2.Node deletion operation successful.'racnode3' deleted successfully 在racnode1删除racnode3的clusterware [oracle@racnode1 ~]$ cd $ORA_CRS_HOME/oui/bin[oracle@racnode1 bin]$ ./runInstaller -updateNodeList ORACLE_HOME=$ORA_CRS_HOME \"CLUSTER_NODES=racnode1,racnode2\" CRS=TRUEStarting Oracle Universal Installer...No pre-requisite checks found in oraparam.ini, no system pre-requisite checks will be executed.The inventory pointer is located at /etc/oraInst.locThe inventory is located at /u01/app/oracle/oraInventory'UpdateNodeList' was successful. 在racnode3更新oraInventory [oracle@racnode3 ~]$ cd $ORA_CRS_HOME/oui/bin[oracle@racnode3 bin]$ ./runInstaller -updateNodeList ORACLE_HOME=$ORA_CRS_HOME \"CLUSTER_NODES=racnode3\" CRS=TRUE -localStarting Oracle Universal Installer...No pre-requisite checks found in oraparam.ini, no system pre-requisite checks will be executed.The inventory pointer is located at /etc/oraInst.locThe inventory is located at /u01/app/oracle/oraInventory'UpdateNodeList' was successful. 在racnode3上删除clusterware [oracle@racnode3 ~]$ cd $ORA_CRS_HOME/oui/bin[oracle@racnode3 bin]$ ./runInstaller -deinstallStarting Oracle Universal Installer...No pre-requisite checks found in oraparam.ini, no system pre-requisite checks will be executed.Preparing to launch Oracle Universal Installer from /tmp/OraInstall2012-12-27_06-04-51PM. Please wait ...[oracle@racnode3 bin]$ Oracle Universal Installer, Version 10.2.0.5.0 ProductionCopyright (C) 1999, 2010, Oracle. All rights reserved. 最后删除相关目录,asm,oraInventory,init等","title":"Oracle 10g RAC 删除节点"},{"content":"Step By Step Configuring Oracle 10gR2 (10.2.0.5) 3-Nodes RAC to Single Dataguard DG配置参考上面链接。主库环境是3-nodes的 RAC,保证实例racdb1正常运行,关闭racdb2和racdb3实例。 备库至于mount状态。 [oracle@standby arch]$ sqlplus / as sysdbaSQL*Plus: Release 10.2.0.5.0 - Production on Thu Dec 27 14:18:02 2012Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.Connected to:Oracle Database 10g Enterprise Edition Release 10.2.0.5.0 - 64bit ProductionWith the Partitioning, OLAP, Data Mining and Real Application Testing optionsSQL> set line 200SQL> select dbid,name,switchover_status,db_unique_name,database_role,open_mode,current_scn from v$database;      DBID NAME      SWITCHOVER_STATUS\t  DB_UNIQUE_NAME\t\t DATABASE_ROLE\t  OPEN_MODE  CURRENT_SCN---------- --------- -------------------- ------------------------------ ---------------- ---------- ----------- 800157471 RACDB     SESSIONS ACTIVE\t  standby\t\t\t PHYSICAL STANDBY MOUNTED\t 1167683SQL> 主库停止racdb2,racdb3实例 [oracle@racnode1 ~]$ srvctl stop instance -d racdb -i racdb2[oracle@racnode1 ~]$ srvctl stop instance -d racdb -i racdb3[oracle@racnode1 ~]$ crs_stat -tName           Type           Target    State     Host        ------------------------------------------------------------ora.racdb.db   application    ONLINE    ONLINE    racnode2    ora....b1.inst application    ONLINE    ONLINE    racnode1    ora....b2.inst application    OFFLINE   OFFLINE               ora....b3.inst application    OFFLINE   OFFLINE               ora.....zwc.cs application    ONLINE    ONLINE    racnode1    ora....db1.srv application    ONLINE    ONLINE    racnode1    ora....SM1.asm application    ONLINE    ONLINE    racnode1    ora....E1.lsnr application    ONLINE    ONLINE    racnode1    ora....de1.gsd application    ONLINE    ONLINE    racnode1    ora....de1.ons application    ONLINE    ONLINE    racnode1    ora....de1.vip application    ONLINE    ONLINE    racnode1    ora....SM2.asm application    ONLINE    ONLINE    racnode2    ora....E2.lsnr application    ONLINE    ONLINE    racnode2    ora....de2.gsd application    ONLINE    ONLINE    racnode2    ora....de2.ons application    ONLINE    ONLINE    racnode2    ora....de2.vip application    ONLINE    ONLINE    racnode2    ora....SM3.asm application    ONLINE    ONLINE    racnode3    ora....E3.lsnr application    ONLINE    ONLINE    racnode3    ora....de3.gsd application    ONLINE    ONLINE    racnode3    ora....de3.ons application    ONLINE    ONLINE    racnode3    ora....de3.vip application    ONLINE    ONLINE    racnode3    在主库确定switchover状态,如果是to standby说明可以正常切换,如果是session active可以加上with session shutdown语句执行 SQL> select instance_name from v$instance;INSTANCE_NAME----------------racdb1SQL> select current_scn,protection_mode,database_role,force_logging,open_mode,switchover_status from v$database;CURRENT_SCN PROTECTION_MODE\t DATABASE_ROLE\t  FOR OPEN_MODE  SWITCHOVER_STATUS----------- -------------------- ---------------- --- ---------- --------------------    1188246 MAXIMUM PERFORMANCE  PRIMARY\t  YES READ WRITE SESSIONS ACTIVE 将RAC主库切换为备库角色 SQL> select instance_name from v$instance;INSTANCE_NAME----------------racdb1SQL> select current_scn,protection_mode,database_role,force_logging,open_mode,switchover_status from v$database;CURRENT_SCN PROTECTION_MODE\t DATABASE_ROLE\t  FOR OPEN_MODE  SWITCHOVER_STATUS----------- -------------------- ---------------- --- ---------- --------------------    1188294 MAXIMUM PERFORMANCE  PRIMARY\t  YES READ WRITE SESSIONS ACTIVESQL> alter database commit to switchover to physical standby with session shutdown;Database altered.SQL> select open_mode from v$database;select open_mode from v$database                      *ERROR at line 1:ORA-01507: database not mounted 启动racdb1到mount SQL> shutdown immediateORA-01507: database not mountedORACLE instance shut down.SQL> startup mountORACLE instance started.Total System Global Area  599785472 bytesFixed Size\t\t    2098112 bytesVariable Size\t\t  201329728 bytesDatabase Buffers\t  390070272 bytesRedo Buffers\t\t    6287360 bytesDatabase mounted.SQL> set line 200SQL> select dbid,name,switchover_status,db_unique_name,database_role,open_mode,current_scn from v$database;      DBID NAME      SWITCHOVER_STATUS\t  DB_UNIQUE_NAME\t\t DATABASE_ROLE\t  OPEN_MODE  CURRENT_SCN---------- --------- -------------------- ------------------------------ ---------------- ---------- ----------- 800157471 RACDB     SESSIONS ACTIVE\t  racdb \t\t\t PHYSICAL STANDBY MOUNTED\t 1188349 确认原备库single database的switchover状态,如果是to primary说明可以正常切换,如果是session active可以加上with session shutdown语句执行 SQL> show parameter instance_nameNAME\t\t\t\t     TYPE\t VALUE------------------------------------ ----------- ------------------------------instance_name\t\t\t     string\t standbySQL> select dbid,name,switchover_status,db_unique_name,database_role,open_mode,current_scn from v$database;      DBID NAME      SWITCHOVER_STATUS\t  DB_UNIQUE_NAME\t\t DATABASE_ROLE\t  OPEN_MODE  CURRENT_SCN---------- --------- -------------------- ------------------------------ ---------------- ---------- ----------- 800157471 RACDB     TO PRIMARY \t  standby\t\t\t PHYSICAL STANDBY MOUNTED\t 1188349 切换原来备库为主库角色 SQL> alter database commit to switchover to primary;Database altered.SQL> select dbid,name,switchover_status,db_unique_name,database_role,open_mode,current_scn from v$database;      DBID NAME      SWITCHOVER_STATUS\t  DB_UNIQUE_NAME\t\t DATABASE_ROLE\t  OPEN_MODE  CURRENT_SCN---------- --------- -------------------- ------------------------------ ---------------- ---------- ----------- 800157471 RACDB     TO STANDBY \t  standby\t\t\t PRIMARY\t  MOUNTED\t       0 切换完成,验证日志传输,数据同步 在现备库racdb1操作 SQL> shutdown immediateDatabase closed.Database dismounted.ORACLE instance shut down.SQL> startup nomountORACLE instance started.Total System Global Area  599785472 bytesFixed Size\t\t    2098112 bytesVariable Size\t\t  201329728 bytesDatabase Buffers\t  390070272 bytesRedo Buffers\t\t    6287360 bytesSQL> alter database mount standby database;Database altered.SQL> alter database recover managed standby database using current logfile disconnect from session;Database altered. 在现主库standby创建表空间 SQL> alter database open;Database altered.SQL> alter system switch logfile;System altered.SQL> create tablespace test003 datafile size 10M autoextend on;Tablespace created. 在现备库racdb1查看,test003已经同步过来 SQL> alter database mount standby database;Database altered.SQL> alter database recover managed standby database using current logfile disconnect from session;Database altered.SQL> select name from v$datafile;NAME--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+DATADG/racdb/datafile/system.269.802972261+DATADG/racdb/datafile/undotbs1.256.802972267+DATADG/racdb/datafile/sysaux.265.802972263+DATADG/racdb/datafile/users.257.802972267+DATADG/racdb/datafile/example.258.802972265+DATADG/racdb/datafile/undotbs2.259.802972265+DATADG/racdb/datafile/undotbs3.264.802972269+DATADG/racdb/datafile/test.281.803129599+DATADG/racdb/datafile/test003.282.8031410599 rows selected.现备库alert.log RFS[2]: Archived Log: '/u01/app/oracle/arch/1_66_802540708.dbf'Thu Dec 27 14:44:15 CST 2012Media Recovery Log /u01/app/oracle/arch/1_66_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/1_67_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/1_68_802540708.dbfMedia Recovery Waiting for thread 1 sequence 69 (in transit)Thu Dec 27 14:44:18 CST 2012Recovery of Online Redo Log: Thread 1 Group 8 Seq 69 Reading mem 0  Mem# 0: +DATADG/racdb/onlinelog/group_8.273.803122441  Mem# 1: +FLASHDG/racdb/onlinelog/group_8.268.803122445Successfully added datafile 9 to media recoveryDatafile #9: '+DATADG/racdb/datafile/test003.282.803141059' 在现主库standby创建表,insert几条数据 SQL> show parameter instance_nameNAME\t\t\t\t     TYPE\t VALUE------------------------------------ ----------- ------------------------------instance_name\t\t\t     string\t standbySQL> conn hr/Enter password: Connected.SQL> create table t_test003 (tid number(3) primary key,tname varchar2(30)) tablespace test003;Table created.SQL> insert into t_test003 values(1,'switchover OK!');1 row created.SQL> commit;Commit complete. 在现备库racdb1查看数据是否同步 SQL> alter database recover managed standby database cancel;Database altered.SQL> alter database open;Database altered.SQL> select open_mode from v$database union all select instance_name from v$instance;OPEN_MODE----------------READ ONLYracdb1SQL> conn hrEnter password: Connected.SQL> desc t_test003 Name\t\t   Null?    Type ----------------- -------- ------------ TID\t\t   NOT NULL NUMBER(3) TNAME\t\t\t    VARCHAR2(30)SQL> select * from t_test003;       TID TNAME---------- ------------------------------\t 1 switchover OK! 在现主库standby删除test003表空间 SQL> drop tablespace test003 including contents and datafiles;Tablespace dropped. 在现备库racdb1查看是否删除 SQL> select name from v$datafile;NAME--------------------------------------------------------------------------------+DATADG/racdb/datafile/system.269.802972261+DATADG/racdb/datafile/undotbs1.256.802972267+DATADG/racdb/datafile/sysaux.265.802972263+DATADG/racdb/datafile/users.257.802972267+DATADG/racdb/datafile/example.258.802972265+DATADG/racdb/datafile/undotbs2.259.802972265+DATADG/racdb/datafile/undotbs3.264.802972269+DATADG/racdb/datafile/test.281.8031295998 rows selected.alert.log RFS[1]: Archived Log: '/u01/app/oracle/arch/1_69_802540708.dbf'RFS[1]: Archived Log: '/u01/app/oracle/arch/1_70_802540708.dbf'Thu Dec 27 14:58:36 CST 2012Media Recovery Log /u01/app/oracle/arch/1_69_802540708.dbfRecovery deleting file #9:'+DATADG/racdb/datafile/test003.282.803141059' from controlfile.Deleted Oracle managed file +DATADG/racdb/datafile/test003.282.803141059Recovery dropped tablespace 'TEST003'Media Recovery Log /u01/app/oracle/arch/1_70_802540708.dbfMedia Recovery Waiting for thread 1 sequence 71 racdb1和standby角色还原 在standby操作 SQL> show parameter instance_nameNAME\t\t\t\t     TYPE\t VALUE------------------------------------ ----------- ------------------------------instance_name\t\t\t     string\t standbySQL> shutdown immediateDatabase closed.Database dismounted.ORACLE instance shut down.SQL> startupORACLE instance started.Total System Global Area  599785472 bytesFixed Size\t\t    2098112 bytesVariable Size\t\t  163580992 bytesDatabase Buffers\t  427819008 bytesRedo Buffers\t\t    6287360 bytesDatabase mounted.Database opened.SQL> select dbid,name,switchover_status,db_unique_name,database_role,open_mode,current_scn from v$database;      DBID NAME      SWITCHOVER_STATUS\t  DB_UNIQUE_NAME\t\t DATABASE_ROLE\t  OPEN_MODE  CURRENT_SCN---------- --------- -------------------- ------------------------------ ---------------- ---------- ----------- 800157471 RACDB     TO STANDBY \t  standby\t\t\t PRIMARY\t  READ WRITE\t 1190295 启动racdb2,racdb3到mount SQL> select dbid,name,switchover_status,db_unique_name,database_role,open_mode,current_scn from gv$database;      DBID NAME      SWITCHOVER_STATUS\t  DB_UNIQUE_NAME\t\t DATABASE_ROLE\t  OPEN_MODE  CURRENT_SCN---------- --------- -------------------- ------------------------------ ---------------- ---------- ----------- 800157471 RACDB     SESSIONS ACTIVE\t  racdb \t\t\t PHYSICAL STANDBY MOUNTED\t 1190108 800157471 RACDB     SESSIONS ACTIVE\t  racdb \t\t\t PHYSICAL STANDBY MOUNTED\t 1190108 800157471 RACDB     SESSIONS ACTIVE\t  racdb \t\t\t PHYSICAL STANDBY MOUNTED\t 1190108SQL> !crs_stat -tName           Type           Target    State     Host        ------------------------------------------------------------ora.racdb.db   application    ONLINE    ONLINE    racnode2    ora....b1.inst application    ONLINE    ONLINE    racnode1    ora....b2.inst application    ONLINE    ONLINE    racnode2    ora....b3.inst application    ONLINE    ONLINE    racnode3    ora.....zwc.cs application    ONLINE    OFFLINE               ora....db1.srv application    ONLINE    OFFLINE               ora....SM1.asm application    ONLINE    ONLINE    racnode1    ora....E1.lsnr application    ONLINE    ONLINE    racnode1    ora....de1.gsd application    ONLINE    ONLINE    racnode1    ora....de1.ons application    ONLINE    ONLINE    racnode1    ora....de1.vip application    ONLINE    ONLINE    racnode1    ora....SM2.asm application    ONLINE    ONLINE    racnode2    ora....E2.lsnr application    ONLINE    ONLINE    racnode2    ora....de2.gsd application    ONLINE    ONLINE    racnode2    ora....de2.ons application    ONLINE    ONLINE    racnode2    ora....de2.vip application    ONLINE    ONLINE    racnode2    ora....SM3.asm application    ONLINE    ONLINE    racnode3    ora....E3.lsnr application    ONLINE    ONLINE    racnode3    ora....de3.gsd application    ONLINE    ONLINE    racnode3    ora....de3.ons application    ONLINE    ONLINE    racnode3    ora....de3.vip application    ONLINE    ONLINE    racnode3 在standby操作 SQL> select dbid,name,switchover_status,db_unique_name,database_role,open_mode,current_scn from v$database;      DBID NAME      SWITCHOVER_STATUS\t  DB_UNIQUE_NAME\t\t DATABASE_ROLE\t  OPEN_MODE  CURRENT_SCN---------- --------- -------------------- ------------------------------ ---------------- ---------- ----------- 800157471 RACDB     TO STANDBY \t  standby\t\t\t PRIMARY\t  READ WRITE\t 1190421SQL> alter database commit to switchover to physical standby;Database altered.SQL> select open_mode from v$database;select open_mode from v$database                      *ERROR at line 1:ORA-01507: database not mountedSQL> shutdown immediateORA-01507: database not mountedORACLE instance shut down.SQL> startup nomountORACLE instance started.Total System Global Area  599785472 bytesFixed Size\t\t    2098112 bytesVariable Size\t\t  163580992 bytesDatabase Buffers\t  427819008 bytesRedo Buffers\t\t    6287360 bytesSQL> alter database mount standby database;Database altered.SQL> select dbid,name,switchover_status,db_unique_name,database_role,open_mode,current_scn from v$database;      DBID NAME      SWITCHOVER_STATUS\t  DB_UNIQUE_NAME\t\t DATABASE_ROLE\t  OPEN_MODE  CURRENT_SCN---------- --------- -------------------- ------------------------------ ---------------- ---------- ----------- 800157471 RACDB     TO PRIMARY \t  standby\t\t\t PHYSICAL STANDBY MOUNTED\t 1190459 在racdb1操作,停止racdb2,racdb3实例,切换为主库角色 SQL>  select dbid,name,switchover_status,db_unique_name,database_role,open_mode,current_scn from v$database;      DBID NAME      SWITCHOVER_STATUS\t  DB_UNIQUE_NAME\t\t DATABASE_ROLE\t  OPEN_MODE  CURRENT_SCN---------- --------- -------------------- ------------------------------ ---------------- ---------- ----------- 800157471 RACDB     SESSIONS ACTIVE\t  racdb \t\t\t PHYSICAL STANDBY MOUNTED\t 1190459SQL> alter database commit to switchover to primary with session shutdown;alter database commit to switchover to primary with session shutdown*ERROR at line 1:ORA-38777: database must not be started in any other instance.SQL> !srvctl stop instance -d racdb -i racdb2SQL> !srvctl stop instance -d racdb -i racdb3SQL>  select dbid,name,switchover_status,db_unique_name,database_role,open_mode,current_scn from v$database;      DBID NAME      SWITCHOVER_STATUS\t  DB_UNIQUE_NAME\t\t DATABASE_ROLE\t  OPEN_MODE  CURRENT_SCN---------- --------- -------------------- ------------------------------ ---------------- ---------- ----------- 800157471 RACDB     SESSIONS ACTIVE\t  racdb \t\t\t PHYSICAL STANDBY MOUNTED\t 1190459SQL> !crs_stat -tName           Type           Target    State     Host        ------------------------------------------------------------ora.racdb.db   application    ONLINE    ONLINE    racnode2    ora....b1.inst application    ONLINE    ONLINE    racnode1    ora....b2.inst application    OFFLINE   OFFLINE               ora....b3.inst application    OFFLINE   OFFLINE               ora.....zwc.cs application    ONLINE    OFFLINE               ora....db1.srv application    ONLINE    OFFLINE               ora....SM1.asm application    ONLINE    ONLINE    racnode1    ora....E1.lsnr application    ONLINE    ONLINE    racnode1    ora....de1.gsd application    ONLINE    ONLINE    racnode1    ora....de1.ons application    ONLINE    ONLINE    racnode1    ora....de1.vip application    ONLINE    ONLINE    racnode1    ora....SM2.asm application    ONLINE    ONLINE    racnode2    ora....E2.lsnr application    ONLINE    ONLINE    racnode2    ora....de2.gsd application    ONLINE    ONLINE    racnode2    ora....de2.ons application    ONLINE    ONLINE    racnode2    ora....de2.vip application    ONLINE    ONLINE    racnode2    ora....SM3.asm application    ONLINE    ONLINE    racnode3    ora....E3.lsnr application    ONLINE    ONLINE    racnode3    ora....de3.gsd application    ONLINE    ONLINE    racnode3    ora....de3.ons application    ONLINE    ONLINE    racnode3    ora....de3.vip application    ONLINE    ONLINE    racnode3    SQL> alter database commit to switchover to primary with session shutdown;Database altered.SQL>  select dbid,name,switchover_status,db_unique_name,database_role,open_mode,current_scn from v$database;      DBID NAME      SWITCHOVER_STATUS\t  DB_UNIQUE_NAME\t\t DATABASE_ROLE\t  OPEN_MODE  CURRENT_SCN---------- --------- -------------------- ------------------------------ ---------------- ---------- ----------- 800157471 RACDB     SESSIONS ACTIVE\t  racdb \t\t\t PRIMARY\t  MOUNTED\t       0 启动RAC所有instance SQL> !srvctl start instance -d racdb -i racdb2SQL> !srvctl start instance -d racdb -i racdb3SQL> !srvctl start service -d racdb -s zwcPRKP-1062 : Service zwc is already running.SQL> !crs_stat -tName           Type           Target    State     Host        ------------------------------------------------------------ora.racdb.db   application    ONLINE    ONLINE    racnode2    ora....b1.inst application    ONLINE    ONLINE    racnode1    ora....b2.inst application    ONLINE    ONLINE    racnode2    ora....b3.inst application    ONLINE    ONLINE    racnode3    ora.....zwc.cs application    ONLINE    ONLINE    racnode1    ora....db1.srv application    ONLINE    ONLINE    racnode2    ora....SM1.asm application    ONLINE    ONLINE    racnode1    ora....E1.lsnr application    ONLINE    ONLINE    racnode1    ora....de1.gsd application    ONLINE    ONLINE    racnode1    ora....de1.ons application    ONLINE    ONLINE    racnode1    ora....de1.vip application    ONLINE    ONLINE    racnode1    ora....SM2.asm application    ONLINE    ONLINE    racnode2    ora....E2.lsnr application    ONLINE    ONLINE    racnode2    ora....de2.gsd application    ONLINE    ONLINE    racnode2    ora....de2.ons application    ONLINE    ONLINE    racnode2    ora....de2.vip application    ONLINE    ONLINE    racnode2    ora....SM3.asm application    ONLINE    ONLINE    racnode3    ora....E3.lsnr application    ONLINE    ONLINE    racnode3    ora....de3.gsd application    ONLINE    ONLINE    racnode3    ora....de3.ons application    ONLINE    ONLINE    racnode3    ora....de3.vip application    ONLINE    ONLINE    racnode3    SQL> alter database open;Database altered.SQL>  select dbid,name,switchover_status,db_unique_name,database_role,open_mode,current_scn from v$database;      DBID NAME      SWITCHOVER_STATUS\t  DB_UNIQUE_NAME\t\t DATABASE_ROLE\t  OPEN_MODE  CURRENT_SCN---------- --------- -------------------- ------------------------------ ---------------- ---------- ----------- 800157471 RACDB     SESSIONS ACTIVE\t  racdb \t\t\t PRIMARY\t  READ WRITE\t 1191263 切换完成,验证同步 在racdb1上 SQL> create tablespace test004 datafile size 10m;Tablespace created.SQL> create tablespace test005 datafile size 10m;Tablespace created.SQL> create tablespace test006 datafile size 10m;Tablespace created. 在standby上验证 SQL> alter database recover managed standby database using current logfile disconnect from session;Database altered.alert.log Waiting for all non-current ORLs to be archived...Clearing online redo logfile 1 +DATADG/standby/onlinelog/group_1.273.803060123Clearing online log 1 of thread 1 sequence number 82Deleted Oracle managed file +DATADG/standby/onlinelog/group_1.273.803060123Thu Dec 27 15:29:16 CST 2012Completed: alter database recover managed standby database using current logfile disconnect from sessionThu Dec 27 15:29:16 CST 2012Clearing online redo logfile 1 completeClearing online redo logfile 2 +DATADG/standby/onlinelog/group_2.274.803060125Clearing online log 2 of thread 1 sequence number 82Deleted Oracle managed file +DATADG/standby/onlinelog/group_2.274.803060125Clearing online redo logfile 2 completeMedia Recovery Log /u01/app/oracle/arch/1_75_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/1_76_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/2_39_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/1_77_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/2_40_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/3_33_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/3_34_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/1_78_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/1_79_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/1_80_802540708.dbfMedia Recovery Waiting for thread 2 sequence 41 (in transit)Thu Dec 27 15:29:21 CST 2012Recovery of Online Redo Log: Thread 2 Group 14 Seq 41 Reading mem 0  Mem# 0: +DATADG/standby/onlinelog/group_14.267.803059831Media Recovery Waiting for thread 3 sequence 35 (in transit)Thu Dec 27 15:29:21 CST 2012Recovery of Online Redo Log: Thread 3 Group 17 Seq 35 Reading mem 0  Mem# 0: +DATADG/standby/onlinelog/group_17.270.803059869Media Recovery Log /u01/app/oracle/arch/1_81_802540708.dbfSuccessfully added datafile 9 to media recoveryDatafile #9: '+DATADG/standby/datafile/test004.281.803143763'Media Recovery Waiting for thread 1 sequence 82 (in transit)Thu Dec 27 15:29:23 CST 2012Recovery of Online Redo Log: Thread 1 Group 11 Seq 82 Reading mem 0  Mem# 0: +DATADG/standby/onlinelog/group_11.264.803059801Thu Dec 27 15:29:48 CST 2012Successfully added datafile 10 to media recoveryDatafile #10: '+DATADG/standby/datafile/test005.282.803143787'Thu Dec 27 15:30:11 CST 2012Successfully added datafile 11 to media recoveryDatafile #11: '+DATADG/standby/datafile/test006.283.803143811' SQL> select name from v$datafile;NAME------------------------------------------------------------------------------------------------------------------------------------------------------+DATADG/standby/datafile/system.257.803059147+DATADG/standby/datafile/undotbs1.259.803059147+DATADG/standby/datafile/sysaux.261.803059163+DATADG/standby/datafile/users.263.803059163+DATADG/standby/datafile/example.258.803059147+DATADG/standby/datafile/undotbs2.262.803059163+DATADG/standby/datafile/undotbs3.260.803059149+DATADG/standby/datafile/test.279.803129613+DATADG/standby/datafile/test004.281.803143763+DATADG/standby/datafile/test005.282.803143787+DATADG/standby/datafile/test006.283.803143811 在racdb1上drop刚刚创建的表空间 SQL> drop tablespace test004 including contents and datafiles;Tablespace dropped.SQL> drop tablespace test005 including contents and datafiles;Tablespace dropped.SQL> drop tablespace test006 including contents and datafiles;Tablespace dropped. 在standby上验证同步 SQL> select name from v$datafile;NAME------------------------------------------------------------------------------------------------------------------------------------------------------+DATADG/standby/datafile/system.257.803059147+DATADG/standby/datafile/undotbs1.259.803059147+DATADG/standby/datafile/sysaux.261.803059163+DATADG/standby/datafile/users.263.803059163+DATADG/standby/datafile/example.258.803059147+DATADG/standby/datafile/undotbs2.262.803059163+DATADG/standby/datafile/undotbs3.260.803059149+DATADG/standby/datafile/test.279.803129613alert.log Thu Dec 27 15:32:35 CST 2012Recovery deleting file #9:'+DATADG/standby/datafile/test004.281.803143763' from controlfile.Deleted Oracle managed file +DATADG/standby/datafile/test004.281.803143763Recovery dropped tablespace 'TEST004'Thu Dec 27 15:32:48 CST 2012Recovery deleting file #10:'+DATADG/standby/datafile/test005.282.803143787' from controlfile.Deleted Oracle managed file +DATADG/standby/datafile/test005.282.803143787Recovery dropped tablespace 'TEST005'Recovery deleting file #11:'+DATADG/standby/datafile/test006.283.803143811' from controlfile.Deleted Oracle managed file +DATADG/standby/datafile/test006.283.803143811Recovery dropped tablespace 'TEST006' 至此switchover结束,最后再把zwc服务拉回到racdb1 [oracle@racnode1 ~]$ srvctl relocate service -d racdb -s zwc -i racdb2 -t racdb1[oracle@racnode1 ~]$ sqlplus / as sysdbaSQL*Plus: Release 10.2.0.5.0 - Production on Thu Dec 27 15:36:34 2012Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.Connected to:Oracle Database 10g Enterprise Edition Release 10.2.0.5.0 - 64bit ProductionWith the Partitioning, Real Application Clusters, OLAP, Data Miningand Real Application Testing optionsSQL> show parameter service_nameNAME\t\t\t\t     TYPE\t VALUE------------------------------------ ----------- ------------------------------service_names\t\t\t     string\t zwcSQL> set linesize 150SQL> alter session set nls_date_format='yyyy-mm-dd hh24:mi:ss';Session altered.SQL> select INSTANCE_NAME,HOST_NAME,VERSION,STARTUP_TIME,STATUS,ACTIVE_STATE,INSTANCE_ROLE,DATABASE_STATUS from gv$INSTANCE;INSTANCE_NAME\t HOST_NAME  VERSION\t      STARTUP_TIME\t  STATUS       ACTIVE_ST INSTANCE_ROLE\t    DATABASE_STATUS---------------- ---------- ----------------- ------------------- ------------ --------- ------------------ -----------------racdb1\t\t racnode1   10.2.0.5.0\t      2012-12-27 14:52:55 OPEN\t       NORMAL\t PRIMARY_INSTANCE   ACTIVEracdb3\t\t racnode3   10.2.0.5.0\t      2012-12-27 15:21:09 OPEN\t       NORMAL\t PRIMARY_INSTANCE   ACTIVEracdb2\t\t racnode2   10.2.0.5.0\t      2012-12-27 15:19:52 OPEN\t       NORMAL\t PRIMARY_INSTANCE   ACTIVE","title":"Oracle 10gR2 (10.2.0.5) 3-Nodes RAC to Single Dataguard Switchover"},{"content":"在学习oracle的时候，想把执行过的命令和结果记录下来，但是使用SQLPLUS每次save也不是办法,每次手动spool又挺麻烦，于是自己制作了一个SQLPLUS的BAT脚本来实现自动SPOOL到文件里面 脚本内容 @echo offcolor 0aecho ***********自定义SQLPLUS**************echo ***可自动输出日期格式LOG到指定位置****echo *********Created by Cryking***********echo *************2012.12.25***************sqlplus \"/as sysdba\" @d:\\script\\autospool.sqlexit --其中autospool.sql内容如下: set feedback offset trimspool onset term offcolumn dt1 new_value filenameSELECT TO_CHAR(SYSDATE,'YYYYMMDD') dt1 FROM DUAL;SPOOL D:\\练习\\study&&filename..TXT APPEND 每次就运行脚本来启动SQLPLUS，这样就不用每次都手动SPOOL一下了，呵呵，脚本比较简单 本来想直接加在login.sql里的,但是指定文件名的时候出现问题，也就是说登录SQLPLUS就执行了login.sql这个脚本了，此时还未连接数据库，不能使用SELECT ... FROM DUAL,如果在login.sql中加上conn ..连接数据库又会产生递归问题,所以最终也没想出什么方法能在login.sql这里实现自动spool,如果有高手会,还请指点一下。。。  ","title":"[SQLPLUS]自动保存执行过的SQL"},{"content":"使用UDEV在Oracle Linux 6上安装Oracle 11g RAC(11.2.0.3) (一) 在所有node上创建oracle,grid用户,创建相关目录 [root@node2 ~]# groupadd -g 1000 oinstall [root@node2 ~]# groupadd -g 1200 asmadmin[root@node2 ~]# groupadd -g 1201 asmdba [root@node2 ~]# groupadd -g 1202 asmoper [root@node2 ~]# useradd -m -u 1100 -g oinstall -G asmadmin,asmdba,asmoper -d /home/grid -s /bin/bash -c \"Grid Infrastructure Owner\" grid[root@node2 ~]# groupadd -g 1300 dba[root@node2 ~]# groupadd -g 1301 oper[root@node2 ~]# useradd -m -u 1101 -g oinstall -G dba,oper,asmdba -d /home/oracle -s /bin/bash -c \"Oracle Software Owner\" oracle[root@node2 ~]# mkdir -p /u01/app/grid[root@node2 ~]# mkdir -p /u01/app/11.2.0/grid[root@node2 ~]# chown -R grid:oinstall /u01[root@node2 ~]# mkdir -p /u01/app/oracle[root@node2 ~]# chown oracle:oinstall /u01/app/oracle[root@node2 ~]# chmod -R 775 /u01[root@node2 ~]# passwd oracleChanging password for user oracle.New password: BAD PASSWORD: it is based on a dictionary wordBAD PASSWORD: is too simpleRetype new password: passwd: all authentication tokens updated successfully.[root@node2 ~]# passwd gridChanging password for user grid.New password: BAD PASSWORD: it is too shortBAD PASSWORD: is too simpleRetype new password: passwd: all authentication tokens updated successfully.[root@node2 ~]# id oracle -auid=1101(oracle) gid=1000(oinstall) groups=1000(oinstall),1201(asmdba),1300(dba),1301(oper)[root@node2 ~]# id grid -auid=1100(grid) gid=1000(oinstall) groups=1000(oinstall),1200(asmadmin),1201(asmdba),1202(asmoper) 安装相关rpm包,配置系统内核参数,这里我使用的是OL6提供的oracle-rdbms-server-11gR2-preinstall [root@node2 ~]# yum -y install oracle-rdbms-server-11gR2-preinstallLoaded plugins: refresh-packagekit, securityol6_UEK_latest                                                                                                                                  | 1.2 kB     00:00     ol6_UEK_latest/primary                                                                                                                          | 5.0 MB     00:14     ol6_UEK_latest                                                                                                                                                 120/120ol6_latest                                                                                                                                      | 1.4 kB     00:00     ol6_latest/primary                                                                                                                              |  24 MB     01:07     ol6_latest                                                                                                                                                 18391/18391Setting up Install ProcessResolving Dependencies--> Running transaction check---> Package oracle-rdbms-server-11gR2-preinstall.x86_64 0:1.0-6.el6 will be installed--> Processing Dependency: gcc-c++ for package: oracle-rdbms-server-11gR2-preinstall-1.0-6.el6.x86_64--> Processing Dependency: gcc for package: oracle-rdbms-server-11gR2-preinstall-1.0-6.el6.x86_64--> Processing Dependency: libaio-devel for package: oracle-rdbms-server-11gR2-preinstall-1.0-6.el6.x86_64--> Processing Dependency: libstdc++-devel for package: oracle-rdbms-server-11gR2-preinstall-1.0-6.el6.x86_64--> Processing Dependency: glibc-devel for package: oracle-rdbms-server-11gR2-preinstall-1.0-6.el6.x86_64--> Processing Dependency: compat-libstdc++-33 for package: oracle-rdbms-server-11gR2-preinstall-1.0-6.el6.x86_64--> Processing Dependency: ksh for package: oracle-rdbms-server-11gR2-preinstall-1.0-6.el6.x86_64--> Processing Dependency: compat-libcap1 for package: oracle-rdbms-server-11gR2-preinstall-1.0-6.el6.x86_64--> Running transaction check---> Package compat-libcap1.x86_64 0:1.10-1 will be installed---> Package compat-libstdc++-33.x86_64 0:3.2.3-69.el6 will be installed---> Package gcc.x86_64 0:4.4.6-4.el6 will be installed--> Processing Dependency: cpp = 4.4.6-4.el6 for package: gcc-4.4.6-4.el6.x86_64--> Processing Dependency: cloog-ppl >= 0.15 for package: gcc-4.4.6-4.el6.x86_64---> Package gcc-c++.x86_64 0:4.4.6-4.el6 will be installed--> Processing Dependency: libmpfr.so.1()(64bit) for package: gcc-c++-4.4.6-4.el6.x86_64---> Package glibc-devel.x86_64 0:2.12-1.80.el6_3.6 will be installed--> Processing Dependency: glibc-headers = 2.12-1.80.el6_3.6 for package: glibc-devel-2.12-1.80.el6_3.6.x86_64--> Processing Dependency: glibc = 2.12-1.80.el6_3.6 for package: glibc-devel-2.12-1.80.el6_3.6.x86_64--> Processing Dependency: glibc-headers for package: glibc-devel-2.12-1.80.el6_3.6.x86_64---> Package ksh.x86_64 0:20100621-16.el6 will be installed---> Package libaio-devel.x86_64 0:0.3.107-10.el6 will be installed---> Package libstdc++-devel.x86_64 0:4.4.6-4.el6 will be installed--> Running transaction check---> Package cloog-ppl.x86_64 0:0.15.7-1.2.el6 will be installed--> Processing Dependency: libppl_c.so.2()(64bit) for package: cloog-ppl-0.15.7-1.2.el6.x86_64--> Processing Dependency: libppl.so.7()(64bit) for package: cloog-ppl-0.15.7-1.2.el6.x86_64---> Package cpp.x86_64 0:4.4.6-4.el6 will be installed---> Package glibc.x86_64 0:2.12-1.80.el6 will be updated--> Processing Dependency: glibc = 2.12-1.80.el6 for package: glibc-common-2.12-1.80.el6.x86_64---> Package glibc.x86_64 0:2.12-1.80.el6_3.6 will be an update---> Package glibc-headers.x86_64 0:2.12-1.80.el6_3.6 will be installed--> Processing Dependency: kernel-headers >= 2.2.1 for package: glibc-headers-2.12-1.80.el6_3.6.x86_64--> Processing Dependency: kernel-headers for package: glibc-headers-2.12-1.80.el6_3.6.x86_64---> Package mpfr.x86_64 0:2.4.1-6.el6 will be installed--> Running transaction check---> Package glibc-common.x86_64 0:2.12-1.80.el6 will be updated---> Package glibc-common.x86_64 0:2.12-1.80.el6_3.6 will be an update---> Package kernel-uek-headers.x86_64 0:2.6.32-300.39.2.el6uek will be installed---> Package ppl.x86_64 0:0.10.2-11.el6 will be installed--> Finished Dependency ResolutionDependencies Resolved======================================================================================================================================================================= Package                                                  Arch                       Version                                      Repository                      Size=======================================================================================================================================================================Installing: oracle-rdbms-server-11gR2-preinstall                     x86_64                     1.0-6.el6                                    ol6_latest                      15 kInstalling for dependencies: cloog-ppl                                                x86_64                     0.15.7-1.2.el6                               ol6_latest                      93 k compat-libcap1                                           x86_64                     1.10-1                                       ol6_latest                      17 k compat-libstdc++-33                                      x86_64                     3.2.3-69.el6                                 ol6_latest                     183 k cpp                                                      x86_64                     4.4.6-4.el6                                  ol6_latest                     3.7 M gcc                                                      x86_64                     4.4.6-4.el6                                  ol6_latest                      10 M gcc-c++                                                  x86_64                     4.4.6-4.el6                                  ol6_latest                     4.7 M glibc-devel                                              x86_64                     2.12-1.80.el6_3.6                            ol6_latest                     970 k glibc-headers                                            x86_64                     2.12-1.80.el6_3.6                            ol6_latest                     600 k kernel-uek-headers                                       x86_64                     2.6.32-300.39.2.el6uek                       ol6_latest                     716 k ksh                                                      x86_64                     20100621-16.el6                              ol6_latest                     684 k libaio-devel                                             x86_64                     0.3.107-10.el6                               ol6_latest                      13 k libstdc++-devel                                          x86_64                     4.4.6-4.el6                                  ol6_latest                     1.5 M mpfr                                                     x86_64                     2.4.1-6.el6                                  ol6_latest                     156 k ppl                                                      x86_64                     0.10.2-11.el6                                ol6_latest                     1.3 MUpdating for dependencies: glibc                                                    x86_64                     2.12-1.80.el6_3.6                            ol6_latest                     3.8 M glibc-common                                             x86_64                     2.12-1.80.el6_3.6                            ol6_latest                      14 MTransaction Summary=======================================================================================================================================================================Install      15 Package(s)Upgrade       2 Package(s)Total download size: 43 MDownloading Packages:(1/17): cloog-ppl-0.15.7-1.2.el6.x86_64.rpm                                                                                                     |  93 kB     00:00     (2/17): compat-libcap1-1.10-1.x86_64.rpm                                                                                                        |  17 kB     00:00     (3/17): compat-libstdc++-33-3.2.3-69.el6.x86_64.rpm                                                                                             | 183 kB     00:00     (4/17): cpp-4.4.6-4.el6.x86_64.rpm                                                                                                              | 3.7 MB     00:12     (5/17): gcc-4.4.6-4.el6.x86_64.rpm                                                                                                              |  10 MB     00:28     (6/17): gcc-c++-4.4.6-4.el6.x86_64.rpm                                                                                                          | 4.7 MB     00:13     (7/17): glibc-2.12-1.80.el6_3.6.x86_64.rpm                                                                                                      | 3.8 MB     00:10     (8/17): glibc-common-2.12-1.80.el6_3.6.x86_64.rpm                                                                                               |  14 MB     00:40     (9/17): glibc-devel-2.12-1.80.el6_3.6.x86_64.rpm                                                                                                | 970 kB     00:02     (10/17): glibc-headers-2.12-1.80.el6_3.6.x86_64.rpm                                                                                             | 600 kB     00:02     (11/17): kernel-uek-headers-2.6.32-300.39.2.el6uek.x86_64.rpm                                                                                   | 716 kB     00:02     (12/17): ksh-20100621-16.el6.x86_64.rpm                                                                                                         | 684 kB     00:02     (13/17): libaio-devel-0.3.107-10.el6.x86_64.rpm                                                                                                 |  13 kB     00:00     (14/17): libstdc++-devel-4.4.6-4.el6.x86_64.rpm                                                                                                 | 1.5 MB     00:04     (15/17): mpfr-2.4.1-6.el6.x86_64.rpm                                                                                                            | 156 kB     00:00     (16/17): oracle-rdbms-server-11gR2-preinstall-1.0-6.el6.x86_64.rpm                                                                              |  15 kB     00:00     (17/17): ppl-0.10.2-11.el6.x86_64.rpm                                                                                                           | 1.3 MB     00:03     -----------------------------------------------------------------------------------------------------------------------------------------------------------------------Total                                                                                                                                  329 kB/s |  43 MB     02:12     warning: rpmts_HdrFromFdno: Header V3 RSA/SHA256 Signature, key ID ec551f03: NOKEYRetrieving key from http://public-yum.oracle.com/RPM-GPG-KEY-oracle-ol6Importing GPG key 0xEC551F03: Userid: \"Oracle OSS group (Open Source Software group) <build@oss.oracle.com>\" From  : http://public-yum.oracle.com/RPM-GPG-KEY-oracle-ol6Running rpm_check_debugRunning Transaction TestTransaction Test SucceededRunning Transaction  Installing : libstdc++-devel-4.4.6-4.el6.x86_64                                                                                                                 1/19   Updating   : glibc-2.12-1.80.el6_3.6.x86_64                                                                                                                     2/19   Updating   : glibc-common-2.12-1.80.el6_3.6.x86_64                                                                                                              3/19   Installing : mpfr-2.4.1-6.el6.x86_64                                                                                                                            4/19   Installing : cpp-4.4.6-4.el6.x86_64                                                                                                                             5/19   Installing : compat-libcap1-1.10-1.x86_64                                                                                                                       6/19   Installing : ksh-20100621-16.el6.x86_64                                                                                                                         7/19   Installing : compat-libstdc++-33-3.2.3-69.el6.x86_64                                                                                                            8/19   Installing : ppl-0.10.2-11.el6.x86_64                                                                                                                           9/19   Installing : cloog-ppl-0.15.7-1.2.el6.x86_64                                                                                                                   10/19   Installing : kernel-uek-headers-2.6.32-300.39.2.el6uek.x86_64                                                                                                  11/19   Installing : glibc-headers-2.12-1.80.el6_3.6.x86_64                                                                                                            12/19   Installing : glibc-devel-2.12-1.80.el6_3.6.x86_64                                                                                                              13/19   Installing : gcc-4.4.6-4.el6.x86_64                                                                                                                            14/19   Installing : gcc-c++-4.4.6-4.el6.x86_64                                                                                                                        15/19   Installing : libaio-devel-0.3.107-10.el6.x86_64                                                                                                                16/19   Installing : oracle-rdbms-server-11gR2-preinstall-1.0-6.el6.x86_64                                                                                             17/19   Cleanup    : glibc-2.12-1.80.el6.x86_64                                                                                                                        18/19   Cleanup    : glibc-common-2.12-1.80.el6.x86_64                                                                                                                 19/19   Verifying  : compat-libcap1-1.10-1.x86_64                                                                                                                       1/19   Verifying  : ksh-20100621-16.el6.x86_64                                                                                                                         2/19   Verifying  : glibc-common-2.12-1.80.el6_3.6.x86_64                                                                                                              3/19   Verifying  : gcc-4.4.6-4.el6.x86_64                                                                                                                             4/19   Verifying  : libaio-devel-0.3.107-10.el6.x86_64                                                                                                                 5/19   Verifying  : oracle-rdbms-server-11gR2-preinstall-1.0-6.el6.x86_64                                                                                              6/19   Verifying  : gcc-c++-4.4.6-4.el6.x86_64                                                                                                                         7/19   Verifying  : glibc-headers-2.12-1.80.el6_3.6.x86_64                                                                                                             8/19   Verifying  : libstdc++-devel-4.4.6-4.el6.x86_64                                                                                                                 9/19   Verifying  : compat-libstdc++-33-3.2.3-69.el6.x86_64                                                                                                           10/19   Verifying  : glibc-2.12-1.80.el6_3.6.x86_64                                                                                                                    11/19   Verifying  : mpfr-2.4.1-6.el6.x86_64                                                                                                                           12/19   Verifying  : kernel-uek-headers-2.6.32-300.39.2.el6uek.x86_64                                                                                                  13/19   Verifying  : cpp-4.4.6-4.el6.x86_64                                                                                                                            14/19   Verifying  : glibc-devel-2.12-1.80.el6_3.6.x86_64                                                                                                              15/19   Verifying  : ppl-0.10.2-11.el6.x86_64                                                                                                                          16/19   Verifying  : cloog-ppl-0.15.7-1.2.el6.x86_64                                                                                                                   17/19   Verifying  : glibc-2.12-1.80.el6.x86_64                                                                                                                        18/19   Verifying  : glibc-common-2.12-1.80.el6.x86_64                                                                                                                 19/19 Installed:  oracle-rdbms-server-11gR2-preinstall.x86_64 0:1.0-6.el6                                                                                                              Dependency Installed:  cloog-ppl.x86_64 0:0.15.7-1.2.el6                  compat-libcap1.x86_64 0:1.10-1 compat-libstdc++-33.x86_64 0:3.2.3-69.el6 cpp.x86_64 0:4.4.6-4.el6                  gcc.x86_64 0:4.4.6-4.el6                           gcc-c++.x86_64 0:4.4.6-4.el6   glibc-devel.x86_64 0:2.12-1.80.el6_3.6    glibc-headers.x86_64 0:2.12-1.80.el6_3.6  kernel-uek-headers.x86_64 0:2.6.32-300.39.2.el6uek ksh.x86_64 0:20100621-16.el6   libaio-devel.x86_64 0:0.3.107-10.el6      libstdc++-devel.x86_64 0:4.4.6-4.el6      mpfr.x86_64 0:2.4.1-6.el6                          ppl.x86_64 0:0.10.2-11.el6    Dependency Updated:  glibc.x86_64 0:2.12-1.80.el6_3.6                                               glibc-common.x86_64 0:2.12-1.80.el6_3.6                                              Complete! sysctl.conf [root@node2 ~]# cat /etc/sysctl.conf# Kernel sysctl configuration file for Red Hat Linux## For binary values, 0 is disabled, 1 is enabled.  See sysctl(8) and# sysctl.conf(5) for more details.# Controls IP packet forwardingnet.ipv4.ip_forward = 0# Controls source route verificationnet.ipv4.conf.default.rp_filter = 1# Do not accept source routingnet.ipv4.conf.default.accept_source_route = 0# Controls the System Request debugging functionality of the kernelkernel.sysrq = 0# Controls whether core dumps will append the PID to the core filename.# Useful for debugging multi-threaded applications.kernel.core_uses_pid = 1# Controls the use of TCP syncookiesnet.ipv4.tcp_syncookies = 1# Disable netfilter on bridges.net.bridge.bridge-nf-call-ip6tables = 0net.bridge.bridge-nf-call-iptables = 0net.bridge.bridge-nf-call-arptables = 0# Controls the default maxmimum size of a mesage queuekernel.msgmnb = 65536# Controls the maximum size of a message, in byteskernel.msgmax = 65536# Controls the maximum shared segment size, in bytes# Controls the maximum number of shared memory segments, in pages# oracle-rdbms-server-11gR2-preinstall setting for fs.file-max is 6815744fs.file-max = 6815744# oracle-rdbms-server-11gR2-preinstall setting for kernel.sem is '250 32000 100 128'kernel.sem = 250 32000 100 128# oracle-rdbms-server-11gR2-preinstall setting for kernel.shmmni is 4096kernel.shmmni = 4096# oracle-rdbms-server-11gR2-preinstall setting for kernel.shmall is 1073741824 on x86_64# oracle-rdbms-server-11gR2-preinstall setting for kernel.shmall is 2097152 on i386kernel.shmall = 1073741824# oracle-rdbms-server-11gR2-preinstall setting for kernel.shmmax is 4398046511104 on x86_64# oracle-rdbms-server-11gR2-preinstall setting for kernel.shmmax is 4294967295 on i386kernel.shmmax = 4398046511104# oracle-rdbms-server-11gR2-preinstall setting for net.core.rmem_default is 262144net.core.rmem_default = 262144# oracle-rdbms-server-11gR2-preinstall setting for net.core.rmem_max is 4194304net.core.rmem_max = 4194304# oracle-rdbms-server-11gR2-preinstall setting for net.core.wmem_default is 262144net.core.wmem_default = 262144# oracle-rdbms-server-11gR2-preinstall setting for net.core.wmem_max is 1048576net.core.wmem_max = 1048576# oracle-rdbms-server-11gR2-preinstall setting for fs.aio-max-nr is 1048576fs.aio-max-nr = 1048576# oracle-rdbms-server-11gR2-preinstall setting for net.ipv4.ip_local_port_range is 9000 65500net.ipv4.ip_local_port_range = 9000 65500 x86_64 修改了numa=off [root@node2 ~]# cat /etc/grub.conf # grub.conf generated by anaconda## Note that you do not have to rerun grub after making changes to this file# NOTICE:  You have a /boot partition.  This means that#          all kernel and initrd paths are relative to /boot/, eg.#          root (hd0,0)#          kernel /vmlinuz-version ro root=/dev/sda3#          initrd /initrd-[generic-]version.img#boot=/dev/sdadefault=0timeout=5splashimage=(hd0,0)/grub/splash.xpm.gzhiddenmenutitle Oracle Linux Server-uek (2.6.39-200.24.1.el6uek.x86_64)\troot (hd0,0)\tkernel /vmlinuz-2.6.39-200.24.1.el6uek.x86_64 ro root=UUID=8adc03e5-e7c8-42c9-a1e8-aae4bc1d2647 rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16   KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet numa=off\tinitrd /initramfs-2.6.39-200.24.1.el6uek.x86_64.imgtitle Oracle Linux Server (2.6.32-279.el6.x86_64)\troot (hd0,0)\tkernel /vmlinuz-2.6.32-279.el6.x86_64 ro root=UUID=8adc03e5-e7c8-42c9-a1e8-aae4bc1d2647 rd_NO_LUKS rd_NO_LVM LANG=en_US.UTF-8 rd_NO_MD SYSFONT=latarcyrheb-sun16 crashkernel=auto  KEYBOARDTYPE=pc KEYTABLE=us rd_NO_DM rhgb quiet numa=off\tinitrd /initramfs-2.6.32-279.el6.x86_64.img grid用户的配置需要自行加上,复制oracle用户的即可 [root@node2 ~]# tail -40 /etc/security/limits.conf#@faculty        hard    nproc           50#ftp             hard    nproc           0#@student        -       maxlogins       4# End of file# oracle-rdbms-server-11gR2-preinstall setting for nofile soft limit is 1024oracle   soft   nofile    1024# oracle-rdbms-server-11gR2-preinstall setting for nofile hard limit is 65536oracle   hard   nofile    65536# oracle-rdbms-server-11gR2-preinstall setting for nproc soft limit is 2047oracle   soft   nproc    2047# oracle-rdbms-server-11gR2-preinstall setting for nproc hard limit is 16384oracle   hard   nproc    16384# oracle-rdbms-server-11gR2-preinstall setting for stack soft limit is 10240KBoracle   soft   stack    10240# oracle-rdbms-server-11gR2-preinstall setting for stack hard limit is 32768KBoracle   hard   stack    32768# oracle-rdbms-server-11gR2-preinstall setting for nofile soft limit is 1024grid   soft   nofile    1024# oracle-rdbms-server-11gR2-preinstall setting for nofile hard limit is 65536grid   hard   nofile    65536# oracle-rdbms-server-11gR2-preinstall setting for nproc soft limit is 2047grid   soft   nproc    2047# oracle-rdbms-server-11gR2-preinstall setting for nproc hard limit is 16384grid   hard   nproc    16384# oracle-rdbms-server-11gR2-preinstall setting for stack soft limit is 10240KBgrid   soft   stack    10240# oracle-rdbms-server-11gR2-preinstall setting for stack hard limit is 32768KBgrid   hard   stack    32768 配置oracle和grid的ssh用户等效性,也可以在安装过程中配置 在node1和node2上使用oracle用户和grid执行以下操作,在家目录下生成.ssh目录 [root@node1 ~]# su - oracle[oracle@node1 ~]$ ssh-keygen -t rsaGenerating public/private rsa key pair.Enter file in which to save the key (/home/oracle/.ssh/id_rsa): Created directory '/home/oracle/.ssh'.Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/oracle/.ssh/id_rsa.Your public key has been saved in /home/oracle/.ssh/id_rsa.pub.The key fingerprint is:38:4e:6f:b0:fc:7e:f2:c0:00:67:13:79:ef:2a:a5:e8 oracle@node1.localdomainThe key's randomart image is:+--[ RSA 2048]----+|      ..         ||      ...        ||    . +. .       ||     + o  .      ||      * S.       ||     + B. .      ||     .+o=.       ||    . ooo..      ||   .E  oo+.      |+-----------------+[oracle@node1 ~]$ ssh-keygen -t dsaGenerating public/private dsa key pair.Enter file in which to save the key (/home/oracle/.ssh/id_dsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/oracle/.ssh/id_dsa.Your public key has been saved in /home/oracle/.ssh/id_dsa.pub.The key fingerprint is:42:77:1b:2e:24:1d:ec:cf:88:4a:3f:37:f0:b3:b2:cd oracle@node1.localdomainThe key's randomart image is:+--[ DSA 1024]----+|       ..        ||       ...       ||      o.+ o      ||     . +.o o     ||      ..S+o      ||    . o...o      ||   . o o         ||    . +o=        ||      .=E+       |+-----------------+[oracle@node1 ~]$ su - gridPassword: [grid@node1 ~]$ ssh-keygen -t rsaGenerating public/private rsa key pair.Enter file in which to save the key (/home/grid/.ssh/id_rsa): Created directory '/home/grid/.ssh'.Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/grid/.ssh/id_rsa.Your public key has been saved in /home/grid/.ssh/id_rsa.pub.The key fingerprint is:c2:e6:ee:b5:b6:c5:14:1a:78:e9:96:97:d9:0b:a1:13 grid@node1.localdomainThe key's randomart image is:+--[ RSA 2048]----+|                 ||       . .       ||      . E o      ||     . o * *     ||      + S * .    ||     o o = . .   ||      . . o .    ||     . ..o       ||     .o.o.       |+-----------------+[grid@node1 ~]$ ssh-keygen -t dsaGenerating public/private dsa key pair.Enter file in which to save the key (/home/grid/.ssh/id_dsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/grid/.ssh/id_dsa.Your public key has been saved in /home/grid/.ssh/id_dsa.pub.The key fingerprint is:d3:36:e8:54:10:84:a8:c6:59:6d:24:5f:3d:90:48:9d grid@node1.localdomainThe key's randomart image is:+--[ DSA 1024]----+|    .=o=**       ||    oo=.E.o      || . + ..   ..     ||  =      +       || .      S +      ||       o o .     ||        .        ||                 ||                 |+-----------------+ 在node1上配置 [oracle@node1 ~]$ cd .ssh/[oracle@node1 .ssh]$ cat id_dsa.pub  >> authorized_keys[oracle@node1 .ssh]$ cat id_rsa.pub  >> authorized_keys[oracle@node1 .ssh]$ ssh node2 cat ~/.ssh/id_dsa.pub >> authorized_keysThe authenticity of host 'node2 (192.168.1.52)' can't be established.RSA key fingerprint is 09:78:b3:fd:8d:a5:9a:a4:d8:fc:98:bd:e3:5e:80:3b.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added 'node2,192.168.1.52' (RSA) to the list of known hosts.oracle@node2's password: [oracle@node1 .ssh]$ ssh node2 cat ~/.ssh/id_rsa.pub >> authorized_keys oracle@node2's password: [oracle@node1 .ssh]$ scp authorized_keys node2:~/.sshoracle@node2's password: authorized_keys                                                                                                                      100% 2040     2.0KB/s   00:00    [oracle@node1 .ssh]$ su - gridPassword: [grid@node1 ~]$ cd .ssh/[grid@node1 .ssh]$ cat id_dsa.pub  >> authorized_keys[grid@node1 .ssh]$ cat id_rsa.pub  >> authorized_keys[grid@node1 .ssh]$ ssh node2 cat ~/.ssh/id_dsa.pub >> authorized_keysThe authenticity of host 'node2 (192.168.1.52)' can't be established.RSA key fingerprint is 09:78:b3:fd:8d:a5:9a:a4:d8:fc:98:bd:e3:5e:80:3b.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added 'node2,192.168.1.52' (RSA) to the list of known hosts.grid@node2's password: [grid@node1 .ssh]$ ssh node2 cat ~/.ssh/id_rsa.pub >> authorized_keysgrid@node2's password: [grid@node1 .ssh]$ scp authorized_keys node2:~/.sshgrid@node2's password: authorized_keys                                                                                                                      100% 2032     2.0KB/s   00:00    [grid@node1 .ssh]$ 在node1和node2上进行验证 [oracle@node1 ~]$ ssh node1-priv date;ssh node2-priv dateFri Dec 28 15:44:41 CST 2012Fri Dec 28 15:44:41 CST 2012[oracle@node1 ~]$ ssh node1 date;ssh node2 dateFri Dec 28 15:44:43 CST 2012Fri Dec 28 15:44:43 CST 2012[oracle@node1 ~]$ su - gridPassword: [grid@node1 ~]$ ssh node1 date;ssh node2 dateFri Dec 28 15:44:48 CST 2012Fri Dec 28 15:44:49 CST 2012[grid@node1 ~]$ ssh node1-priv date;ssh node2-priv dateFri Dec 28 15:44:50 CST 2012Fri Dec 28 15:44:50 CST 2012[grid@node1 ~]$ [oracle@node2 ~]$ ssh node1-priv date;ssh node2-priv dateFri Dec 28 15:46:56 CST 2012Fri Dec 28 15:46:56 CST 2012[oracle@node2 ~]$ ssh node1 date;ssh node2 dateFri Dec 28 15:46:58 CST 2012Fri Dec 28 15:46:58 CST 2012[oracle@node2 ~]$ su - gridPassword: [grid@node2 ~]$ ssh node1 date;ssh node2 dateFri Dec 28 15:47:02 CST 2012Fri Dec 28 15:47:02 CST 2012[grid@node2 ~]$ ssh node1-priv date;ssh node2-priv dateFri Dec 28 15:47:03 CST 2012Fri Dec 28 15:47:03 CST 2012 配置oracle和grid用户的环境变量 node1上oracle用户 [oracle@node1 ~]$ cat .bash_profile # .bash_profile# Get the aliases and functionsif [ -f ~/.bashrc ]; then\t. ~/.bashrcfi# User specific environment and startup programsPATH=$PATH:$HOME/binexport PATHalias ls=\"ls -FA\"ORACLE_SID=zhongwc1; export ORACLE_SIDORACLE_UNQNAME=zhongwc; export ORACLE_UNQNAMEJAVA_HOME=/usr/local/java; export JAVA_HOMEORACLE_BASE=/u01/app/oracle; export ORACLE_BASEORACLE_HOME=$ORACLE_BASE/product/11.2.0/dbhome_1; export ORACLE_HOMEORACLE_PATH=/u01/app/common/oracle/sql; export ORACLE_PATHORACLE_TERM=xterm; export ORACLE_TERMNLS_DATE_FORMAT=\"DD-MON-YYYY HH24:MI:SS\"; export NLS_DATE_FORMATTNS_ADMIN=$ORACLE_HOME/network/admin; export TNS_ADMINORA_NLS11=$ORACLE_HOME/nls/data; export ORA_NLS11DISPLAY=192.168.2.224:0.0; export DISPLAYNLS_LANG=AMERICAN_AMERICA.ZHS16GBK; export NLS_LANGPATH=.:${JAVA_HOME}/bin:${PATH}:$HOME/bin:$ORACLE_HOME/binPATH=${PATH}:/usr/bin:/bin:/usr/bin/X11:/usr/local/binPATH=${PATH}:/u01/app/common/oracle/binexport PATHLD_LIBRARY_PATH=$ORACLE_HOME/libLD_LIBRARY_PATH=${LD_LIBRARY_PATH}:$ORACLE_HOME/oracm/libLD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/lib:/usr/lib:/usr/local/libexport LD_LIBRARY_PATHCLASSPATH=$ORACLE_HOME/JRECLASSPATH=${CLASSPATH}:$ORACLE_HOME/jlibCLASSPATH=${CLASSPATH}:$ORACLE_HOME/rdbms/jlibCLASSPATH=${CLASSPATH}:$ORACLE_HOME/network/jlibexport CLASSPATHTHREADS_FLAG=native; export THREADS_FLAGexport TEMP=/tmpexport TMPDIR=/tmpumask 022alias sqlplus=\"rlwrap sqlplus\"alias rman=\"rlwrap rman\"alias ggsci=\"rlwrap ggsci\"alias logdump=\"rlwrap logdump\"alias asmcmd=\"rlwrap asmcmd\"alias base=\"cd $ORACLE_BASE\"alias home=\"cd $ORACLE_HOME\" node1上grid用户 [grid@node1 ~]$ cat .bash_profile # .bash_profile# Get the aliases and functionsif [ -f ~/.bashrc ]; then\t. ~/.bashrcfi# User specific environment and startup programsPATH=$PATH:$HOME/binexport PATHalias ls=\"ls -FA\"ORACLE_SID=+ASM1; export ORACLE_SIDJAVA_HOME=/usr/local/java; export JAVA_HOMEORACLE_BASE=/u01/app/grid; export ORACLE_BASEORACLE_HOME=/u01/app/11.2.0/grid; export ORACLE_HOMEORACLE_PATH=/u01/app/oracle/common/oracle/sql; export ORACLE_PATHORACLE_TERM=xterm; export ORACLE_TERMNLS_DATE_FORMAT=\"DD-MON-YYYY HH24:MI:SS\"; export NLS_DATE_FORMATTNS_ADMIN=$ORACLE_HOME/network/admin; export TNS_ADMINORA_NLS11=$ORACLE_HOME/nls/data; export ORA_NLS11DISPLAY=192.168.2.224:0.0; export DISPLAYNLS_LANG=AMERICAN_AMERICA.ZHS16GBK; export NLS_LANGPATH=.:${JAVA_HOME}/bin:${PATH}:$HOME/bin:$ORACLE_HOME/binPATH=${PATH}:/usr/bin:/bin:/usr/bin/X11:/usr/local/binPATH=${PATH}:/u01/app/common/oracle/binexport PATHLD_LIBRARY_PATH=$ORACLE_HOME/libLD_LIBRARY_PATH=${LD_LIBRARY_PATH}:$ORACLE_HOME/oracm/libLD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/lib:/usr/lib:/usr/local/libexport LD_LIBRARY_PATHCLASSPATH=$ORACLE_HOME/JRECLASSPATH=${CLASSPATH}:$ORACLE_HOME/jlibCLASSPATH=${CLASSPATH}:$ORACLE_HOME/rdbms/jlibCLASSPATH=${CLASSPATH}:$ORACLE_HOME/network/jlibexport CLASSPATHTHREADS_FLAG=native; export THREADS_FLAGexport TEMP=/tmpexport TMPDIR=/tmpumask 022alias sqlplus=\"rlwrap sqlplus\"alias rman=\"rlwrap rman\"alias ggsci=\"rlwrap ggsci\"alias logdump=\"rlwrap logdump\"alias asmcmd=\"rlwrap asmcmd\"alias base=\"cd $ORACLE_BASE\"alias home=\"cd $ORACLE_HOME\" 在node2上需要将oracle用户的ORACLE_SID改为zhongwc2,grid用户的ORACLE_SID改为+ASM2","title":"使用UDEV在Oracle Linux 6上安装Oracle 11g RAC(11.2.0.3) (二)"},{"content":"1.版本号。 SQL> select * from v$version; BANNER ---------------------------------------------------------------- Oracle Database 10g Enterprise Edition Release 10.2.0.1.0 - Prod PL/SQL Release 10.2.0.1.0 - Production CORE 10.2.0.1.0 Production TNS for Linux: Version 10.2.0.1.0 - Production NLSRTL Version 10.2.0.1.0 - Production 2.查看是否设置了闪回 SQL> select flashback_on ,name from v$database; FLASHBACK_ON       NAME ------------------ --------- NO                 ORCL 3.设置闪回功能  要在mount 状态 shutdown immediate startup mount alter database flashback on; alter database open; 4.查看是否设置成功 SQL> select flashback_on,name from v$database; FLASHBACK_ON       NAME ------------------ --------- YES                ORCL    ","title":"oracle 10G闪回功能的打开"},{"content":"1              Install & Concept 1.1             Powercenter 的安装，架构，组件及其主要功能； 1.       安装Powercenter 7.12,8.11客户端，知识库服务器及Informatica服务器件； 需要指定注册码;在本机上建立供测试用的的Informatica Server； 2.       7.12的Windows的一台机器上只能装一个这样的Server，建立时需要指定关联的库；除了需要指定注册码外，还需要指定数据库连接许可码； 知识库服务器没有关联的名称，只有端口，指定密码； 4.       用知识库管理器（Repository Manager）添加已存在的知识库服务器； 添加知识库时，指定知识库名称和登入用记户，连接时还需指定密码以及知识库的IP和端口； 5.       用知识库服务器管理平台（Repository Server Administration Console）连接，管理知识库服务器以及创建新的知识库以及删除知识库； 添加时指定知识库服务器所在机器名（或者IP）和端口，登入时再输入密码； 登入后可以在当前的知识库服务器上创建新的知识库（新建的知识库有两个默认的用户，没有文件夹）， 也可以对已经存在的知识库作如下管理操作：启动，关闭知识库，备份与恢复，查看当前连接，当前锁及活动日志，向用户发布消息等等；   1.2             服务器端组件及相互关系： 知识库是元数据的集合，存放在数据库中，可以使用多种数据库作为知识库（包含的数据库对象包括表OPB_XXX，索引和视图REP_XXX）；具体原数据表说明可以参考后面介绍. 知识库服务器用来控制各个组件（Designer， Workflow， Informatica Server等）对知识库的存取； Informatica Server用来控制Workflow的实际运行； 机器的某个端口上可以建立一个知识库服务器； 一个知识库服务器管理一到多个知识库； 一个知识库与一到多个Informatica Server关联；   1.3             客户端组件及相互关系： Designer用来设计Mapping（包含Source—数据源，Transformation—数据处理和Target—目标，与ETL<extract, transform and load>一一对应）； Session是Mapping的实例化（相关的数据库对象或者文件都要指定正确的连接方式或者目录）； Workflow Manager用来组织一个或多个Session来实际运行； Workflow Monitor用来监控Workflow的运行；   1.4             组件关系图 2              Repository & Designer manager 2.1             Repository Manager 用户，组和权限 用户名和一个密码对应，组没有密码； 一个用户属于一到多个组； 默认有两个用户（Administrator，另一个用户与知识库同名）和两个组（Administrators，Public）； 权限可以赋给用户，也可以赋给组，有八种权限（Browse Repository，Use Designer，Use Repository Manager，Use Workflow Manager，Administer Repository，Administer Server，Super User，Workflow Operator，许多权限需要和文件夹权限结合使用，详细说明可参考帮助文档）； 用户成功登录后可以更改密码； 用户被Disable后不能够登入； 默认的用户和组的权限无法更改，也无法删除这些用户与组或更改用户的组； 文件夹 文件夹是Powercenter对象的集合，文件夹有如下属性：名称，属主，所属组，状态，权限许可，是否可共享； 文件夹的权限许可分为三种：Read（查看文件夹中的所有对象）， Write（在文件夹中创建对象以及更改文件夹中已有的对象） Execute（执行或排程文件夹中的Workflow）； 不同用户对文件夹的权限分为三类：属主，所属组，知识库，可以对这三类用户设置权限许可； 当文件夹可共享时，可以在其它文件夹中创建对这个文件夹中对象的捷径或者复制这些对象，这个属性设为共享后就不可再更改回来； 对象锁和用户连接 知识库管理锁来控制对知识库的并发更新； 因为网络故障或者Powercenter客户端或者服务器的异常关闭，可能会出现一些遗留锁或者遗留连接，需要管理员手工关闭；   附Powercenter知识库: 学习Informatica：元数据库 Informatica所有的元数据信息均以数据库表的方式存到了元数据库中。当然Infa本身工具提供了很多的人性化的功能，使我们在开发时可以很方便的进行操作，但人们的需求总是万变的，需要方便的取到自己需要的信息，那就需要我们对他的元数据库有很深的了解。 Informatica通过表和视图给我们提供着所有的信息，在此将通过一个系列的帖子，将大部分常见的，且非常有用的表及视图介绍一下。基于这些东西，我们即可以根据不同的需求查出自己需要的数据，也可以开发一些辅助的Infa应用程序。 OPB_ATTR: INFORMATICA(Designer,Workflow等)设计时及服务器设置的所有属性项的名称，当前值及 该属性项的简要说明 例如：ATTR_NAME:Tracing Level ATTR_VALUE:2 ATTR_COMMENT:Amount of detail in the session log 用途：可以通过该表快速查看到设计或设置时碰到的一些属性项的用途与说明 OPB_ATTR_CATEGORY: INFORMATICA各属性项的分类及说明 例如：CATEGORY_NAME:Files and Directories DESCRIPTION:Attributes related to file names and directory locations 用途：查看上表所提的属性项的几种分类及说明 OPB_CFG_ATTR: WORKFLOW MANAGER中的各个Folder下的Session Configuration的配置数据，每个配置对应表中一组Config_Id相同的数据，一组配置数据共23条 例如：ATTR_ID:221 ATTR_VALUE:$PMBadFileDir 用途：查看所有的SessionConfiguration的配置项及值，并方便的进行各个不同Folder间的配置异同比较 OPB_CNX: WORKFLOW MANAGER中关于源、目标数据库连接的定义，包括Relational Connection,Queue Connection,Loader Connection等 例如：OBJECT_NAME:Orace_Source USER_NAME:oral USER_PASSWORD:`?53S{$+*$*[X] CONNECT_STRING:Oratest 用途：查看在WorkFlow Manager中进行配置的所有连接及其配置数据   OPB_CNX_ATTR: 上表所记录的所有数据库连接的一些相关属性值，一种属性值一条数据。例如对于Relational Connection类的连接，有附加三个属性，对应该表则有三条记录，分别记录其Rollback Segment, Environment SQL, Enable Parallel Mode的属性值，分别对应ATTR_ID为10,11,12 例如：OBJECT_ID:22 ATTR_ID:10 ATTR_VALUE:1（代表Enable Parallel Mode为选中） VERSION_NUMBER:1 用途：查看所有配置好的连接的相关属性值，及一些环境SQL及回滚段设置，方便统一查看及比较 OPB_DBD: INFORMATICA DESIGNER中所有导入的源的属性及位置 例如：DBSID:37 DBDNAM:DSS_VIEW ROOTID:37 用途：关联查看所有源的属性 OPB_DBDS: INFORMATICA MAPPING中所引用的源，即Mapping与上表中源的对应关系 例如： MAPPING_ID:3 DBD_ID:4 VERSION_NUMBER:1 用途：查看一个定义了的源被哪些Mapping引用过，作为他的源或给出Mapping名，根据OPB_MAPPING表关联，可以查看该Mapping引用到哪些源 OPB_EXPRESSION: INFORMATICA DESIGNER 中所有定义了的表达式 例如：WIDGET_ID:1003 EXPRESSION:DECODE(IIF(TYPE_PLAN != '05',1,0),1,QTY_GROSS,0) 用途:通过与OPB_WIDGET表关联,查看整个元数据库中的所有Expression转换模块中的表达式定义 OPB_EXTN_ATTR: WORKFLOW MANAGER中的 Edit Tasks时的Mapping页中，选中Targets时，其相关属性的设置值。每个属性值一条记录。 例如：ATTR_ID:2 ATTR_VALUE:ora_test1.bad 用途：通过关联直接查看所有Session的相关目标表数据加载设置 OPB_FILE_DESC: INFORMATICA中所有文本文件的读入规则定义，如分隔符等 例如：STR_DELIMITER:11, FLD_DELIMITER:9,44,0 CODE_PAGE:936 用途：查看系统中不同的文本的规则定义Informatica的元数据包括了我们在开发与配置时所碰到的所有数据，当然理论上我们可以通过直接修改数据库值来更改设置，但列出这些表的用途，仅是给大家一个查看信息的简便方法，即使对元数据库很熟了，也强烈建议不要直接修改元数据表的值，而应该通过Informatica工具来进行更改。 OPB_GROUPS: INFORMATICA中所有组的定义 例如：GROUP_ID:2 GROUP_NAME:Administrators 用途：查看当前系统中所设置的所有组 Informatica的元数据包括了我们在开发与配置时所碰到的所有数据，当然理论上我们可以通过直接修改数据库值来更改设置，但列出这些表的用途，仅是给大家一个查看信息的简便方法，即使对元数据库很熟了，也强烈建议不要直接修改元数据表的值，而应该通过Informatica工具来进行更改。 OPB_GROUPS: INFORMATICA中所有组的定义 例如：GROUP_ID:2 GROUP_NAME:Administrators 用途：查看当前系统中所设置的所有组 OPB_MAPPING: INFORMATICA中所有Mapping的存储，并存储着Mapping的一些如最后一次存储时间、说明等属性信息例如：MAPPING_NAME:m_PM_COUNT_BILL MAPPING_ID:1521 LAST_SAVED:03/27/2006 20:00:24 用途：这张表的用途非常大，可以通过本表数据的查询，得出如某个时间以后修改过的所 有Mapping，所有失效了的Mapping，这个表的更大作用是和其他表作关联，得出 更多Mapping相关的信息 OPB_MAP_PARMVAR: INFORMATICA中Mapping的所有参数的定义，及其初始值等相关信息 例如：MAPPING_ID:1538 PV_NAME:$$DP_ENABLE_RAND_SAMPLING PV_DEFAULT:0 用途：查看系统作所设置的所有参数信息，与OPB_MAPPING关联可以根据所给出的 Mapping名查看该Mapping下所设置的所有参数信息 OPB_METAEXT_VAL: IINFORMATICA元数据扩展信息，记录了在设计中，所扩展的所有元数据相关信息 以下是某个Session的元数据扩展 例如：METAEXT_NAME:COMMENT OBJECT_TYPE:68(Session) PM_VALUE:The Link's Main Table,Design by Jack 用途：查看在设计中所有扩展了的元数据信息，通过关联可以查看指定对象的元数据扩展信 息，帮助集中查看了解设计过程中的一些信息 OPB_OBJECT_TYPE: INFORMATICA设计中所有对象的定义表 例如：OBJECT_TYPE_ID:1 OBJECT_TYPE_NAME:Source Definition 用途：可以查看到现在INFOMATICA所定义了的所有对象，可作为其他表的关联维表，查看某个对象的所有相关信息 OPB_PARTITION_DEF: SESSION中所有的PARTITION定义 例如：SESSION_ID:2578 PARTITION_NAME:Partition #1 用途：通过关联，根据Session的名称，查出该Session所包含的所有Partition设置 OPB_REPOSIT: INFORMATICA REP服务器配置相关信息 例如： DATAVERSION: 5002 PEPOSIT_NAME:hnsever 用途：查看INFORMATICA REP服务器配置信息   OPB_REPOSIT_INFO: INFORMATICA REP数据库连接配置信息 例如： REPOSITORY_NAME: TEST-REP DB_USER:infa_user DB_NATIVE_CONNECT:infa_conn HOSTNAME:hnsever PORTNUM:5001 用途：查看INFORMATICA REP服务器数据库连接配置信息   OPB_SCHEDULER: WORKFLOW中的所有SCHEDULER设置信息表 例如：SCHEDULER_ID:81 SCHEDULER_NAME:Scheduler_DAY_10 START_TIME:3/13/2005/00/20 用途：该表记录了所有的SCHEDULER信息，以及它的各项属性设置，方便整体进行考虑各个SCHEDULER间的调度配合 OPB_SERVER_INFO: INFORMATICA SEVER 服务器配置信息 例如：SERVER_NAME:INFA_SEVER TIMEOUT:300 HOSTNAME:hnsever PORT_NO:4001 IP_ADDRESS:196.125.13.1 用途：查看INFORMATICA SEVER服务器配置信息 OPB_SESSION: WORKFLOW中的所有Session，记录了Session与Mapping的对应关系及Session相关的一 些基本属性 例如：SESSION_ID:11 MAPPING_ID:3 用途：查看Session与Mapping对应关系，通过关联得出Session名与Mapping名的对应 OPB_SESSION: WORKFLOW中的所有Session，记录了Session与Mapping的对应关系及Session相关的一 些基本属性 例如：SESSION_ID:11 MAPPING_ID:3 用途：查看Session与Mapping对应关系，通过关联得出Session名与Mapping名的对应 OPB_SESSION_CONFIG: 记录了WORKFLOW中所有Session的Config配置信息 例如：CONFIG_NAME:default_session_config COMMENTS:Default session configuration object 用途：查看当前系统中所有配置了的Session Config信息 OPB_SESS_FILE_REF: INFORMATICA抽取过程中的所有Flat File与Session的相关关系定义 例如： SESSION_ID: 682 FILE_ID:66 用途：查看整个系统中的Flat File源的相关情况 OPB_SESS_FILE_VALS: 系统中所有Flat File文件的具体情况，包括文件名、路径等 例如： SESSION_ID: 1560 FILE_NAME: PTM_LU_CHILD.txt DIR_NAME: $PMSourceFileDirPTM 用途：通过关联可以查看到Session相关的Flat文件名及其路径，以及查看系统所有相关Flat文件及统计 OPB_SESS_TASK_LOG: 这是INFORMATICA对于Session运行的所有日志的信息记录，并且记录下Session的出错情况。 例如：INSTANCE_ID:6 MAPPING_NAME:m_ASSET_SUB_ACCOUNT LOG_FILE:C:Program Files......s_ASSET_SUB_ACCOUNT.log FIRST_ERROR_MSG:No errors encountered. 用途：这是在查Session运行情况的最终要的表之一，可以最简便的得到Session是否运行正常及当初错时的首个错误简要信息，以及日志文件 的位置 OPB_SRC: INFORMATICA DESIGNER中所定义的所有源 例如：SRC_ID:12 SUBJ_ID:27 FILE_NAME:AM_EQP_ASSESS SOURCE_NAME:AM_EQP_ASSESS 用途：通过Subj_Id的关联，可以查出每个Folder中所有定义了的源 OPB_SRC_FLD: INFORMATICA中源表的所有字段的定义 例如：FLDID:82 SRC_ID:12 SRC_NAME:FLAG_ID 用途：关联上表，得出该源表的所有字段，及其定义和相关属性值 OPB_SRV_LOC_VARS: INFORMATICA系统服务器配置中，所有的系统变量及变量的当前值 例如：VAR_ID:13 VAR_NAME:$PMRootDir VAR_VALUE:D:Program FilesInformatica PowerCenter 7.1.1Server  用途：查看当前服务器的所有系统变量及其当前值 OPB_SUBJECT: INFORMATICA中所有主题定义，即所有Folder的定义及相关属性 例如：SUBJ_NAME:OAM SUBJ_ID:2 GROUP_ID:3 用途：Folder的ID是其他很多表的外键，作为其他表的关联，可以查看该Folder下的所有相关对象信息 OPB_SWIDGET_INST: 记录一个Session中所用到的Mapping引用到的所有对象及其相关属性，即细到每个转化模块一条记录 例如：SESSION_ID:11 MAPPING_ID:3 INSTANCE_NAME:LKP_OTHER_CHECK11 PARTITION_TYPE:1 用途：查看每个Session所引用到的所有对象，及其当前的属性值 OPB_SWIDGINST_LOG: INFORMATICA运行后，所有运行了的Session中相关源及目标对象的运行日志，即运行的时间，抽取的数据成功条数等 例如：TASK_INSTANCE_ID:92 PARTITION_ID:1 PARTITION_NAME:Partition#1 WIDGET_NAME:SQ_SHIFT_CODE APPLIED_ROWS:723 START_TIME:2004-11-4 8:48:12 END_TIME:2004-11-4 8:48:31 用途：这是INFORMATICA运行后，对每个对象的运行情况的最详细的日志记录，对于数据正确性的检查，性能的调优等有着很重要的参考价值 OPB_SWIDG_GROUP: 在INFORMATICA DESIGNER中Union_Transformation模块上的所有Group的定义表 例如：SESSION_ID:1410 GROUP_NAME:PM_GROUP1 用途：该表单独记录了Union_Transformation模块上所有设置了的Group，可以通过关联查出一个Session上所有的Union Group定义 OPB_TABLE_GROUP: 在INFORMATICA DESIGNER 中Router Transformation模块上的所有Group的定义表. 例如：OBJECT_ID:3409             ATTR_VALUE: FROM_ID = 'xx' 用途：该表单独记录了Router Transformation模块上所有设置了的Group，以及Group的分组条件，可以通过关联查处出一个Mapping中Route r 的所有分组设置及其分组条件 OPB_TARG: 在INFORMATICA DESIGNER中所有目标表的定义 OPB_TABLE_GROUP: 在INFORMATICA DESIGNER中Router Transformation模块上的所有Group的定义表. 例如：OBJECT_ID:3409             ATTR_VALUE: FROM_ID='xx' 用途：该表单独记录了RouterTransformation模块上所有设置了的Group，以及Group的分组条件，可以通过关联查处出一个Mapping中Router的 所有分组设置及其分组条件 OPB_TARG: 在INFORMATICA DESIGNER中所有目标表的定义 例如：TARGET_ID:3             SUBJ_ID:2             TARGET_NAME:HAM_DEPT 用途：该表存储了所有的目标表定义，通过关联可以查出某个Folder下所有的目标表定义 OPB_TARGINDEX: 在INFORMATICA中对目标表，可进行Index的定义，该表存储了所有目标表Index的定义 例如：TARGET_ID:1626             INDEXNAME: IDX_AUDIT 用途：查出所有在INFORMATICA中进行的Index定义，及相关目标表信息 OPB_TARGINDEXFLD: INFORMATICA中目标表上进行了Index定义的相关的所有字段 例如：INDEXID:6             FLDNAME: AREC_BILL_ID 用途：进行关联查出在INFORMATICA中进行了Index定义的表及其字段   OPB_TARG_FLD: INFORMATICA中所有目标表的字段信息 例如：TARGET_ID:131             TARGET_NAME:CHECK_PROPERTY 用途：查看目标表的所有字段信息，或给出字段名，查找该字段在那些目标表中出现过 OPB_TASK: WORKFLOW中所有Task的记录，包括Session，Worklet，WorkFlow等 例如：TASK_ID:1717             TASK_NAME:s_OAM_LOG_ARR 用途：该表是Workflow关于Task的记录的主表，通过关联可以查出某个folder下所包含的所有Workflow、Worklet、Task等，以及查出一个 Workflow下的所有Task OPB_TASK_ATTR: 该表记录了Task的所有属性值，每个属性一条记录 例如：ATTR_ID:2             ATTR_VALUE:s_AM_ASSET_TYPE.log 用途：查看相关Task的属性设置，查找系统中同一属性设置的所有Task OPB_TASK_INST: Task实例表，与OPB_TASK表信息类似，但该表主要突出的是Workflow与Task的关系，而OPB_TASK表是Task的基表 例如：WORKFLOW_ID:9             INSTANCE_NAME: s_USED_KIND 用途：查找一个Workflow下的所有Task信息 OPB_TASK_INST_RUN: 该表记录了所有Task每次运行的日志信息，包括当前的运行起始时间，服务名等 例如：INSTANCE_NAME:s_ASSET_ACCOUNT             START_TIME:2004-11-3 15:20:01             END_TIME:2004-11-3 15:20:08             SERVER_NAME:ETL-SVR 用途：该表记录了Task每次运行的日志信息，其中关于时间的信息对于性能调优有着极其重要的作用，也可以观察同一个Task，一段时间的运 行效果，评估服务器的运行情况等 OPB_TASK_VAL_LIST: 该表记录了某些Task中的属性值，例如Command Task中的Command值 例如：TASK_ID:2990             PM_VALUE:DEL “D:FILE_LIST.TXT”             VAL_NAME:DELETE 用途：可以查看当前系统中设置的任务属性值，也可查看所有的Command的命令值 OPB_USERS: 该表记录了Rep Manager中所设置的所有用户，及其相关属性 例如：USER_ID:5             USER_NAME:DEMO             USER_PASSWD:hG63\"4$7.`             USER_PRIVILEGES1:79 用途：可以查看系统中INFORMATICA所定义了的所有用户及相关属性 OPB_USER_GROUPS: 该表记录了Rep Manager中用户与组的关系 例如：USER_ID:2             GROUP_ID:3 用途：查看一个组中存在哪些用户，或关联出每个用户到底属于哪个组 OPB_VALIDATE: 该表纪录Designer或Workflow Manager中设计开发时，所有Validate的信息 例如：OBJECT_ID:4             INV_COMMENTS:Replaced source [V_RCT_CREDIT] during import. 用途：查看同一个对象的历史Validate信息，查看对象的修改历程 OPB_VERSION_PROPS: 该表纪录了系统中各种对象的当前版本信息，最后的修改时间。包括最小到各个Mapping中的各个模块的当前版本信息。 OPB_VALIDATE: 该表纪录Designer或Workflow Manager中设计开发时，所有Validate的信息 例如：OBJECT_ID:4             INV_COMMENTS:Replaced source [V_RCT_CREDIT] during import. 用途：查看同一个对象的历史Validate信息，查看对象的修改历程 OPB_VERSION_PROPS: 该表纪录了系统中各种对象的当前版本信息，最后的修改时间。包括最小到各个Mapping中的各个模块的当前版本信息。 例如：OBJECT_ID: 5             OBJECT_NAME: FLT_CLM_BDL             LAST_SAVED: 08/20/2006 22:52:29 用途：查看系统中各模块对象的最后更改时间。 OPB_WFLOW_VAR: 该表纪录了Workflow的中，各个系统变量的定义，是Workflow设计过程中，所有各模块间系统变量的设计纪录 例如：SUBJECT_ID:2             VAR_NAME:ErrorMsg             VAR_DESC:Error message for this task's execution                      LAST_SAVED:         08/20/2006 22:38:41 用途：查看Workflow中相应的系统变量的设计 OPB_WIDGET: 该表是所有Mapping中的所有转换模块的基础信息表，记录了每个转换模块的基础信息 例如：WIDGET_NAME:AGG_PIM_RES             WIDGET_TYPE:9             IS_REUSABLE:0 用途：可以与其他表进行关联，按条件查出需要各个基础的转换模块 OPB_WIDGET_ATTR: 该表是OPB_WIDGET的子表，记录了每一个转换模块的各种属性值。一个模块的一个属性占一条记录。 例如：WIDGET_ID: 2             WIDGET_TYPE:11             ATTR_VALUE:$PMCacheDir 用途：该表纪录了所有的转换模块的所有属性值，是在做某属性查找时非常有用的一个基础表，通过与其他表的关联即可得出同一设置的所有 转换模块的信息 OPB_WIDGET_FIELD: 该表纪录了各个转换模块中所有字段的定义 例如：WIDGET_ID:4             FIELD_NAME:IN_PL_CD             WGT_PREC:10             WGT_DATATYPE:12 用途：可以实现对某个字段名称的统计与查找 OPB_WORKFLOW: 该表是Workflow定义的一个基表，记录下Workflow的关系信息 例如：WORKFLOW_ID:6             SERVER_ID:0             SCHEDULER_ID:3 用途：该表主要可以用于作关于Workflow的各种相关查找的关联表 REP_DB_TYPES: 该表记录了INFA所支持的数据库的类型 例如：DATYPE_NUM:3             DATYPE_NAME:ORACLE 用途：该表是系统的一个基础代码表，用于显示INFA所支持的所有数据库类型 REP_FLD_DATATYPE: 该表记录了INFA所支持的各种数据类型以及INFA所支持的各种数据库的数据类型 例如：DTYPE_NUM:3001             DTYPE_NAME:char             DTYPE_DATABASE:ORACLE 用途：该表是系统的一个基础代码表，用于显示INFA所支持的所有数据类型 REP_SRC_KEY_TYPES: 该表记录了INFA在源定义中所设定的所有键值类型 例如：KEYTYPE_NUM:1             KEYTYPE_NAME:PRIMARY KEY 用途：该表是系统的一个基础代码表，用于显示INFA源设计中，所有支持的键值类型 REP_TARG_KEY_TYPES: 该表记录了INFA在目标定义中所设定的所有键值类型 例如：KEYTYPE_NUM:2             KEYTYPE_NAME:FOREIGN KEY 用途：该表是系统的一个基础代码表，用于显示INFA目标设计中，所有支持的键值类型   REP_TARG_TYPE: 该表记录了INFA的目标表类型 例如：TARGET_TYPE:1             TYPE_NAME:DIMENSION 用途：表是系统的一个基础代码表，用于显示INFA设计中，所有支持的目标表类型","title":"Powercenter 基础知识介绍 - 1"},{"content":"Redis 是一个高性能的key-value数据库。 redis的出现，很大程度补偿了memcached这类keyvalue存储的不足，在部 分场合可以对关系数据库起到很好的补充作用。它提供了Python，Ruby，Erlang，PHP客户端，使用很方便。 性能测试结果： SET操作每秒钟 110000 次，GET操作每秒钟 81000 次，服务器配置如下： Linux 2.6, Xeon X3320 2.5Ghz. stackoverflow 网站使用 Redis 做为缓存服务器。 所以我们要看看他具体是什么东西 1、到官网去下载一个redis，http://redis.io 现在最新的版本是2.6.7 2、在linux上面安装redis，这里我用的是ubuntu-server-12.04版本       ①、用tar zxvf 解压 下载好的 redis-2.6.7.tar.gz       ②、进入redis cd redis-2.6.7       ③、执行 make 命令，然后就开始刷刷的make了，不过有的linux版本可能没有安装gcc这时候就会报错(gcc: Command not found),这样就多了一步       ④、sudo apt-get install gcc 其实就是安装上一个gcc,自己去下载也行，别的版本的linux用yum一下,只是安装起来简单,之后再make一下就可以了       ⑤、再进入src目录,make install       ⑥、和java一软件一样，我习惯性的把他们放在了opt的java下面又创建了一个redis的文件夹，为了方便管理我把make好的文件mv到了redis文件下，具体路径 mv redis.conf /opt/java/redis/etc/ mv mkreleasehdr.sh redis-benchmark redis-check-aof redis-check-dump redis-cli redis-server /opt/java/redis/bin       ⑦、然后运行server,不过运行是需要配置文件的 /opt/java/redis/bin/redis-server/opt/java/redis/etc/redis.conf       ⑧、好的，这样就能看到他的运行端口6379了，我们用下面的命令链接客户端 /opt/java/redis/bin/redis-cli             用pkill或者 kill-9来关闭也行       ⑨、但是这样起到会占一个session，没有办法做别的操作，所以去配置文件里面修改一个(redis.conf)详细conf配置文档(百度文库) daemonize yes               再启动就好了，可以检查一下进程 ps -ef | grep redis             查看一下端口号 netstat -tunpl | grep 6379          3、睡一觉明天看看这个高性能的东西具体的操作 资料下载 Redis入门手册（中文）.pdf","title":"redis入门——安装"},{"content":"今天做到这里的时候顺便看了一下集群，看看那redis和mysql集群的效果，原来做apache+tomcat负载均衡的时候就用的服务器，因为初学弄得有些紧张，毕竟服务器要是骨折了什么的可兜不住，这次做了一个折磨自己的决定，在自己电脑上面跑起来4个server不就可以了吗？没事的话还可以做做hadoop的试验，正好算法老师说要讲mapreduce 于是在我的VMware上面安装了4个server(两个ubuntu-server两个server03(CentOS不能ifconfig解决方法))、我的每一个server内存有点小，是384M的，不过这样跑起来的时候我也有点吃不消了，凑合着来吧。 ip地址是挨着的，我这里分别是192.168.15.129~132、子网掩码、默认网关都是一样的，但是我的虚拟机彼此之间是ping不通的 查了一些资料有的说是MAC的地址问题，于是又了解了一个新东西，MAC地址(百度百科),虽然后来发现不是这个问题 通过ipconfig/all或者是ifconfig查看一下我的虚拟机们的MAC地址不是一样的，所以排除了这个问题(如果安装虚拟机系统的时候是拷贝的别的虚拟系统文件可能导致这个问题，我是苦逼的4个一个一个安装的) 突然想到的防火墙，我已经打开远程例外了，但是不知道是不是这个的原因，直接关闭了防火墙，果真可以了，于是我查了一下，找到了upnp 框架(百度百科)，大概是有关tcp/ip和udp的家伙，而我没有把他例外了，我把他也例外了就没有这些问题了，当然在linux-server本来就没有这个问题，我安装上防火墙把22端口例外了就能远程和访问了。 哇，怎么说也算有自己的集群了，明天还有一个考试，先睡了。 VMware Workstation(虚拟机) v9.0.1 官方正式版下载(其实不汉化也挺好的) vmware workstation 9 注册机下载 vmware环境下的机群搭建与应用.pdf","title":"redis入门——VMware 环境下的机群搭建与应用"},{"content":"    之前整理了2篇Oracle 10gRAC的启动与关闭相关的文章，参考： Oracle 10gRAC 启动与关闭 http://blog.csdn.net/tianlesoftware/article/details/5349003   Oracle RAC 常用维护工具和命令 http://blog.csdn.net/tianlesoftware/article/details/5358573   一．启动和停止集群    在Oracle 11gR2 下的RAC，架构发生了变化。CRS的信息也是放在ASM 实例里的，所以要关asm,必须关闭crs, 如果还使用了acfs的话，一关crs那么acfs里的信息也不能访问了，所以一般不重启机器，不轻易关crs, 其他的service可以根据自己的需要去stop/start。   注意： 11g RAC 开启资源相对比较慢(即使命令后面显示的资源都start succeeded,通过crs_stat -t查看都不一定online), 需要耐心并查看log。       在Oracle 11gR2 里引入了Oracle Restart的特性，其用来管理Cluster Resource。关于Oracle Restart，参考我的Blog： Oracle 11g 新特性 -- Oracle Restart 说明 http://blog.csdn.net/tianlesoftware/article/details/8435670   1.1 使用crsctl stop has/crsctl stopcrs 用root用户，在Oracle11gR2中停止和启动集群的命令如下： #crsctl stop has [-f] #crsctl start has   注意：     对于crsctl stop has 只有一个可选的参数就是-f，该命令只能停执行该命令服务器上的HAS.而不能停所有节点上的。所以要把RAC 全部停掉，需要在所有节点执行该命令。   下面的2个命令：使用crs 和 使用has 效果是完全一样的： #crsctl stop crs [-f] #crsctl start crs     示例： --停止HAS [root@rac1 bin]# ./crsctl stophas CRS-2791:Starting shutdown of Oracle High Availability Services-managed resources on'rac1' CRS-2673:Attempting to stop 'ora.crsd' on 'rac1' CRS-2790:Starting shutdown of Cluster Ready Services-managed resources on 'rac1' CRS-2673:Attempting to stop 'ora.LISTENER_SCAN1.lsnr' on 'rac1' CRS-2673:Attempting to stop 'ora.OCRVOTING.dg' on 'rac1' CRS-2673:Attempting to stop 'ora.sdd.db' on 'rac1' CRS-2673:Attempting to stop 'ora.LISTENER.lsnr' on 'rac1' CRS-2673:Attempting to stop 'ora.oc4j' on 'rac1' CRS-2673:Attempting to stop 'ora.cvu' on 'rac1' CRS-2677: Stopof 'ora.LISTENER_SCAN1.lsnr' on 'rac1' succeeded CRS-2673:Attempting to stop 'ora.scan1.vip' on 'rac1' CRS-2677: Stopof 'ora.LISTENER.lsnr' on 'rac1' succeeded CRS-2673:Attempting to stop 'ora.rac1.vip' on 'rac1' CRS-2677: Stopof 'ora.rac1.vip' on 'rac1' succeeded CRS-2672:Attempting to start 'ora.rac1.vip' on 'rac2' CRS-2677: Stopof 'ora.scan1.vip' on 'rac1' succeeded CRS-2672:Attempting to start 'ora.scan1.vip' on 'rac2' CRS-2676:Start of 'ora.scan1.vip' on 'rac2' succeeded CRS-2676:Start of 'ora.rac1.vip' on 'rac2' succeeded CRS-2672:Attempting to start 'ora.LISTENER_SCAN1.lsnr' on 'rac2' CRS-2677: Stopof 'ora.sdd.db' on 'rac1' succeeded CRS-2673:Attempting to stop 'ora.DATA.dg' on 'rac1' CRS-2673:Attempting to stop 'ora.FRA.dg' on 'rac1' CRS-2676:Start of 'ora.LISTENER_SCAN1.lsnr' on 'rac2' succeeded CRS-2677: Stopof 'ora.FRA.dg' on 'rac1' succeeded CRS-2677: Stopof 'ora.DATA.dg' on 'rac1' succeeded CRS-2677: Stopof 'ora.oc4j' on 'rac1' succeeded CRS-2672:Attempting to start 'ora.oc4j' on 'rac2' CRS-2677: Stopof 'ora.cvu' on 'rac1' succeeded CRS-2672:Attempting to start 'ora.cvu' on 'rac2' CRS-2676:Start of 'ora.cvu' on 'rac2' succeeded CRS-2677: Stopof 'ora.OCRVOTING.dg' on 'rac1' succeeded CRS-2673:Attempting to stop 'ora.asm' on 'rac1' CRS-2677: Stopof 'ora.asm' on 'rac1' succeeded CRS-2676:Start of 'ora.oc4j' on 'rac2' succeeded CRS-2673:Attempting to stop 'ora.ons' on 'rac1' CRS-2677: Stopof 'ora.ons' on 'rac1' succeeded CRS-2673:Attempting to stop 'ora.net1.network' on 'rac1' CRS-2677: Stopof 'ora.net1.network' on 'rac1' succeeded CRS-2792:Shutdown of Cluster Ready Services-managed resources on 'rac1' has completed CRS-2677: Stopof 'ora.crsd' on 'rac1' succeeded CRS-2673:Attempting to stop 'ora.mdnsd' on 'rac1' CRS-2673:Attempting to stop 'ora.ctssd' on 'rac1' CRS-2673:Attempting to stop 'ora.evmd' on 'rac1' CRS-2673:Attempting to stop 'ora.asm' on 'rac1' CRS-2677: Stopof 'ora.evmd' on 'rac1' succeeded CRS-2677: Stopof 'ora.mdnsd' on 'rac1' succeeded CRS-2677: Stopof 'ora.ctssd' on 'rac1' succeeded CRS-2677: Stopof 'ora.asm' on 'rac1' succeeded CRS-2673:Attempting to stop 'ora.cluster_interconnect.haip' on 'rac1' CRS-2677: Stopof 'ora.cluster_interconnect.haip' on 'rac1' succeeded CRS-2673:Attempting to stop 'ora.cssd' on 'rac1' CRS-2677: Stopof 'ora.cssd' on 'rac1' succeeded CRS-2673:Attempting to stop 'ora.crf' on 'rac1' CRS-2677: Stopof 'ora.crf' on 'rac1' succeeded CRS-2673:Attempting to stop 'ora.gipcd' on 'rac1' CRS-2677: Stopof 'ora.gipcd' on 'rac1' succeeded CRS-2673:Attempting to stop 'ora.gpnpd' on 'rac1' CRS-2677: Stopof 'ora.gpnpd' on 'rac1' succeeded CRS-2793:Shutdown of Oracle High Availability Services-managed resources on 'rac1' hascompleted CRS-4133:Oracle High Availability Services has been stopped. [root@rac1bin]#   注意：        我这里测试的是Oracle11gR2的环境，我们在节点1上执行该命令，只把节点1上的进程停了，而把相关的资源转移到我们的节点2上了，因此也证实了我们上面的说的，该命令只争对当前服务器有效。   --启动HAS： [root@rac1bin]# ./crsctl start has CRS-4123:Oracle High Availability Services has been started. [root@rac1bin]#   从上面看只是启动了HAS。实际上后面会把Oracle Restart 管理的资源都会启动。这个可以使用crs_stat命令来进程验证，不过Oracle 11g的进程启动过程比较慢，需要耐心等待。   [root@rac1u01]# sh crs_stat.sh Name                           Target     State     Host      ---------------------------------------- ---------  -------   ora.DATA.dg                    ONLINE     ONLINE    rac1      ora.FRA.dg                     ONLINE     ONLINE    rac1      ora.LISTENER.lsnr              ONLINE     ONLINE    rac1      ora.LISTENER_SCAN1.lsnr        ONLINE     ONLINE    rac2      ora.OCRVOTING.dg               ONLINE     ONLINE    rac1      ora.asm                        ONLINE     ONLINE    rac1      ora.cvu                        ONLINE     ONLINE    rac2      ora.gsd                        OFFLINE    OFFLINE              ora.net1.network               ONLINE     ONLINE    rac1      ora.oc4j                       ONLINE     ONLINE    rac2      ora.ons                        ONLINE     ONLINE    rac1      ora.rac1.ASM1.asm              ONLINE     ONLINE    rac1      ora.rac1.LISTENER_RAC1.lsnr    ONLINE    ONLINE     rac1      ora.rac1.gsd                   OFFLINE    OFFLINE              ora.rac1.ons                   ONLINE     ONLINE    rac1      ora.rac1.vip                   ONLINE     ONLINE    rac1      ora.rac2.ASM2.asm              ONLINE     ONLINE    rac2      ora.rac2.LISTENER_RAC2.lsnr    ONLINE    ONLINE     rac2      ora.rac2.gsd                   OFFLINE    OFFLINE              ora.rac2.ons                   ONLINE     ONLINE    rac2      ora.rac2.vip                   ONLINE     ONLINE    rac2      ora.scan1.vip                  ONLINE     ONLINE    rac2      ora.sdd.db                     ONLINE     ONLINE    rac2       1.2 使用crsctl stop cluster [-all]… 该命令的语法如下： crsctl stop cluster [[-all]|[-n<server>[...]]] [-f] crsctl start cluster [[-all]|[-n<server>[...]]]   与1.1 节最大的不同，该参数支持的选项更多，可以同时操控所有的节点。如果不指定参数，那么只对当前节点有效。   如： [root@rac1 ~]# ./crsctl start cluster -n rac1 rac2   --停止当前节点集群： [root@rac1 bin]# ./crsctl stop cluster CRS-2673: Attempting to stop 'ora.crsd' on'rac1' CRS-2790: Starting shutdown of ClusterReady Services-managed resources on 'rac1' CRS-2673: Attempting to stop'ora.LISTENER.lsnr' on 'rac1' CRS-2673: Attempting to stop'ora.OCRVOTING.dg' on 'rac1' CRS-2673: Attempting to stop 'ora.sdd.db'on 'rac1' CRS-2677: Stop of 'ora.LISTENER.lsnr' on'rac1' succeeded CRS-2673: Attempting to stop 'ora.rac1.vip'on 'rac1' CRS-2677: Stop of 'ora.rac1.vip' on 'rac1'succeeded CRS-2672: Attempting to start'ora.rac1.vip' on 'rac2' CRS-2677: Stop of 'ora.sdd.db' on 'rac1'succeeded CRS-2673: Attempting to stop 'ora.DATA.dg'on 'rac1' CRS-2673: Attempting to stop 'ora.FRA.dg'on 'rac1' CRS-2676: Start of 'ora.rac1.vip' on 'rac2'succeeded CRS-2677: Stop of 'ora.FRA.dg' on 'rac1'succeeded CRS-2677: Stop of 'ora.DATA.dg' on 'rac1'succeeded CRS-2677: Stop of 'ora.OCRVOTING.dg' on'rac1' succeeded CRS-2673: Attempting to stop 'ora.asm' on'rac1' CRS-2677: Stop of 'ora.asm' on 'rac1'succeeded CRS-2673: Attempting to stop 'ora.ons' on'rac1' CRS-2677: Stop of 'ora.ons' on 'rac1'succeeded CRS-2673: Attempting to stop'ora.net1.network' on 'rac1' CRS-2677: Stop of 'ora.net1.network' on'rac1' succeeded CRS-2792: Shutdown of Cluster ReadyServices-managed resources on 'rac1' has completed CRS-2677: Stop of 'ora.crsd' on 'rac1'succeeded CRS-2673: Attempting to stop 'ora.ctssd' on'rac1' CRS-2673: Attempting to stop 'ora.evmd' on'rac1' CRS-2673: Attempting to stop 'ora.asm' on'rac1' CRS-2677: Stop of 'ora.evmd' on 'rac1'succeeded CRS-2677: Stop of 'ora.ctssd' on 'rac1'succeeded CRS-2677: Stop of 'ora.asm' on 'rac1'succeeded CRS-2673: Attempting to stop'ora.cluster_interconnect.haip' on 'rac1' CRS-2677: Stop of'ora.cluster_interconnect.haip' on 'rac1' succeeded CRS-2673: Attempting to stop 'ora.cssd' on'rac1' CRS-2677: Stop of 'ora.cssd' on 'rac1'succeeded [root@rac1 bin]#   这里只停了节点1，相关进程全飘到节点2了，如下： [root@rac2 u01]# sh crs_stat.sh Name                           Target     State     Host      ------------------------------ -------------------  -------   ora.DATA.dg                    ONLINE     ONLINE    rac2      ora.FRA.dg                     ONLINE     ONLINE    rac2      ora.LISTENER.lsnr              ONLINE     ONLINE    rac2      ora.LISTENER_SCAN1.lsnr        ONLINE     ONLINE    rac2      ora.OCRVOTING.dg               ONLINE     ONLINE    rac2      ora.asm                        ONLINE     ONLINE    rac2      ora.cvu                        ONLINE     ONLINE    rac2      ora.gsd                        OFFLINE    OFFLINE              ora.net1.network               ONLINE     ONLINE    rac2      ora.oc4j                       ONLINE     ONLINE    rac2      ora.ons                        ONLINE     ONLINE    rac2      ora.rac1.ASM1.asm              ONLINE     OFFLINE              ora.rac1.LISTENER_RAC1.lsnr    ONLINE    OFFLINE              ora.rac1.gsd                   OFFLINE    OFFLINE              ora.rac1.ons                   ONLINE     OFFLINE              ora.rac1.vip                   ONLINE     ONLINE    rac2      ora.rac2.ASM2.asm              ONLINE     ONLINE    rac2      ora.rac2.LISTENER_RAC2.lsnr    ONLINE    ONLINE     rac2      ora.rac2.gsd                   OFFLINE    OFFLINE              ora.rac2.ons                   ONLINE     ONLINE    rac2      ora.rac2.vip                   ONLINE     ONLINE    rac2      ora.scan1.vip                  ONLINE     ONLINE    rac2      ora.sdd.db                     ONLINE     ONLINE    rac2        --启用当前节点： [root@rac1 bin]#./crsctl start cluster CRS-2672: Attempting to start'ora.cssdmonitor' on 'rac1' CRS-2676: Start of 'ora.cssdmonitor' on'rac1' succeeded CRS-2672: Attempting to start 'ora.cssd' on'rac1' CRS-2672: Attempting to start 'ora.diskmon'on 'rac1' CRS-2676: Start of 'ora.diskmon' on 'rac1'succeeded CRS-2676: Start of 'ora.cssd' on 'rac1'succeeded CRS-2672: Attempting to start 'ora.ctssd'on 'rac1' CRS-2672: Attempting to start'ora.cluster_interconnect.haip' on 'rac1' CRS-2676: Start of 'ora.ctssd' on 'rac1'succeeded CRS-2672: Attempting to start 'ora.evmd' on'rac1' CRS-2676: Start of 'ora.evmd' on 'rac1'succeeded CRS-2676: Start of'ora.cluster_interconnect.haip' on 'rac1' succeeded CRS-2672: Attempting to start 'ora.asm' on'rac1' CRS-2676: Start of 'ora.asm' on 'rac1'succeeded CRS-2672: Attempting to start 'ora.crsd' on'rac1' CRS-2676: Start of 'ora.crsd' on 'rac1'succeeded [root@rac1 bin]#   1.3 检查集群的状态   --简单的输出: [root@rac1 bin]# ./crsctl check cluster [root@rac1 bin]# ./crsctl check crs   --详细的信息: # crs_stat -t     使用crsctl check crs命令，如下： [root@rac1 bin]# ./crsctl check crs CRS-4638: Oracle High Availability Servicesis online CRS-4537: Cluster Ready Services is online CRS-4529: Cluster Synchronization Servicesis online CRS-4533: Event Manager is online   [root@rac1 bin]# ./crsctl check cluster CRS-4537: Cluster Ready Services is online CRS-4529: Cluster Synchronization Servicesis online CRS-4533: Event Manager is online   二．停止和启动Resource     在第一节中，看到直接停止集群，相关的Resource 也会被停止。 但一些实际情况下，我们操作更多的是对某些资源的操作。具体就是使用SRVCTL 命令   1.1. 官网说明 SRVCTL Command Reference for Oracle Restart http://docs.oracle.com/cd/E11882_01/server.112/e25494/restart005.htm   查看命令帮助： Srvclt –h   这个命令显示的结果太长，不好查看，可以进一步的查看帮助：   --使用-h： [grid@rac1 ~]$ srvctl start -h   The SRVCTL start command starts, OracleClusterware enabled, non-running objects.   Usage: srvctl start database -d<db_unique_name> [-o <start_options>] [-n <node>] Usage: srvctl start instance -d <db_unique_name>{-n <node_name> [-i <inst_name>] | -i <inst_name_list>} [-o<start_options>] Usage: srvctl start service -d<db_unique_name> [-s \"<service_name_list>\" [-n<node_name> | -i <inst_name>] ] [-o <start_options>] Usage: srvctl start nodeapps [-n <node_name>][-g] [-v] Usage: srvctl start vip { -n<node_name> | -i <vip_name> } [-v] Usage: srvctl start asm [-n<node_name>] [-o <start_options>] Usage: srvctl start listener [-l<lsnr_name>] [-n <node_name>] Usage: srvctl start scan [-i<ordinal_number>] [-n <node_name>] Usage: srvctl start scan_listener [-n<node_name>] [-i <ordinal_number>] Usage: srvctl start oc4j [-v] Usage: srvctl start home -o<oracle_home> -s <state_file> -n <node_name> Usage: srvctl start filesystem -d<volume_device> [-n <node_name>] Usage: srvctl start diskgroup -g<dg_name> [-n \"<node_list>\"] Usage: srvctl start gns [-l<log_level>] [-n <node_name>] [-v] Usage: srvctl start cvu [-n<node_name>] For detailed help on each command andobject and its options use:  srvctl <command> <object> -h   --或者命令不敲全： [grid@rac1 ~]$ srvctl database Usage: srvctl <command><object> [<options>]    commands:enable|disable|start|stop|relocate|status|add|remove|modify|getenv|setenv|unsetenv|config|convert|upgrade    objects: database|instance|service|nodeapps|vip|network|asm|diskgroup|listener|srvpool|server|scan|scan_listener|oc4j|home|filesystem|gns|cvu For detailed help on each command andobject and its options use:  srvctl <command> -h or  srvctl <command> <object> -h   1.2 示例 1.2.1 检查集群状态 [grid@rac1 ~]$ crsctl check cluster CRS-4537: Cluster Ready Services is online CRS-4529: Cluster Synchronization Servicesis online CRS-4533: Event Manager is online   1.2.2 所有Oracle实例（数据库状态） [grid@rac1 ~]$ srvctl status database -dsdd       Instance sdd1 is running on node rac1 Instance sdd2 is running on node rac2   1.2.3 检查单个实例状态 [grid@rac1 ~]$ srvctl status instance -dsdd -i sdd1 Instance sdd1 is running on node rac1 [grid@rac1 ~]$   1.2.4节点应用程序状态 [grid@rac1 ~]$ srvctl status nodeapps VIP rac1-vip is enabled VIP rac1-vip is running on node: rac1 VIP rac2-vip is enabled VIP rac2-vip is running on node: rac2 Network is enabled Network is running on node: rac1 Network is running on node: rac2 GSD is disabled GSD is not running on node: rac1 GSD is not running on node: rac2 ONS is enabled ONS daemon is running on node: rac1 ONS daemon is running on node: rac2     1.2.5 列出所有的配置数据库 [grid@rac1 ~]$ srvctl config database sdd   1.2.6 数据库配置 [grid@rac1 ~]$ srvctl config database -dsdd -a Database unique name: sdd Database name: sdd Oracle home: /u01/app/oracle/11.2.0/db_1 Oracle user: oracle Spfile: +DATA/sdd/spfilesdd.ora Domain: Start options: open Stop options: immediate Database role: PRIMARY Management policy: AUTOMATIC Server pools: sdd Database instances: sdd1,sdd2 Disk Groups: DATA,FRA Mount point paths: Services: Type: RAC Database is enabled Database is administrator managed   1.2.7 ASM状态以及ASM配置 [grid@rac1 ~]$ srvctl status asm ASM is running on rac2,rac1   [grid@rac1 ~]$ srvctl status asm -a ASM is running on rac2,rac1 ASM is enabled.   1.2.8 TNS监听器状态以及配置 [grid@rac1 ~]$ srvctl status listener Listener LISTENER is enabled Listener LISTENER is running on node(s):rac2,rac1   [grid@rac1 ~]$ srvctl config listener -a Name: LISTENER Network: 1, Owner: grid Home: <CRS home>  /u01/app/grid/11.2.0 on node(s) rac2,rac1 End points: TCP:1521     1.2.8 SCAN状态以及配置 [grid@rac1 ~]$ srvctl status scan SCAN VIP scan1 is enabled SCAN VIP scan1 is running on node rac1   [grid@rac1 ~]$ srvctl config scan SCAN name: rac-scan, Network:1/192.168.16.0/255.255.255.0/eth0 SCAN VIP name: scan1, IP:/rac-scan/192.168.16.207   1.2.9 VIP各个节点的状态以及配置 [grid@rac1 ~]$ srvctl status vip -n rac1 VIP rac1-vip is enabled VIP rac1-vip is running on node: rac1   [grid@rac1 ~]$ srvctl status vip -n rac2 VIP rac2-vip is enabled VIP rac2-vip is running on node: rac2   [grid@rac1 ~]$ srvctl config vip -n rac1 VIP exists: /rac1-vip/192.168.16.201/192.168.16.0/255.255.255.0/eth0,hosting node rac1   [grid@rac1 ~]$ srvctl config vip -n rac2 VIP exists:/rac2-vip/192.168.16.203/192.168.16.0/255.255.255.0/eth0, hosting node rac2 [grid@rac1 ~]$   1.2.10 节点应用程序配置（VIP、GSD、ONS、监听器） [grid@rac1 ~]$ srvctl config nodeapps -a -g-s -l Warning:-l option has been deprecated andwill be ignored. Network exists:1/192.168.16.0/255.255.255.0/eth0, type static VIP exists:/rac1-vip/192.168.16.201/192.168.16.0/255.255.255.0/eth0, hosting node rac1 VIP exists:/rac2-vip/192.168.16.203/192.168.16.0/255.255.255.0/eth0, hosting node rac2 GSD exists ONS exists: Local port 6100, remote port6200, EM port 2016 Name: LISTENER Network: 1, Owner: grid Home: <CRS home>  /u01/app/grid/11.2.0 on node(s) rac2,rac1 End points: TCP:1521   1.3 语法简汇 1.3.1 数据库与实例 srvctl config database # 列出安装的数据库 srvctl config database -d rac -a # 检查数据库相关的信息 srvctlstatus database -d RAC # 检查数据库的状态 srvctl status instance -d RAC -i rac1 # 检查指定实例的状态 srvctl config asm -a # ASM配置 srvctl status asm # ASM的状态 srvctl start database -d rac # 启动数据库 srvctl stop database -d rac # 关闭数据库 srvctl start instance -d rac -i rac1 # 启动指定的实例 srvctl stop instance -d rac -i rac2 # 关闭指定实例   1.3.2 网络相关的命令   srvctl status listener # 检查TNS listener的状态 srvctl config scan # SCAN的配置 srvctl status scan # SCAN listener状态, 包含当前运行节点的信息 # 检查VIP的配置及状态 srvctl status vip -n rac1 srvctl config vip -n rac1   1.3.3 查看各资源状态(nodeapps节点应用程序，ASM实例，数据库等)   [root@db02 u01]# crs_stat -t         Name           Type           Target   State     Host        ------------------------------------------------------------ ora.DATA.dg    ora....up.type ONLINE    ONLINE   db02  ora.FRA.dg     ora....up.type ONLINE    ONLINE   db02  ora....ER.lsnr ora....er.type ONLINE    ONLINE   db02  ora....N1.lsnr ora....er.type ONLINE    ONLINE   db02  ora....N2.lsnr ora....er.type ONLINE    ONLINE   db02  ora....N3.lsnr ora....er.type ONLINE    ONLINE   db02  ora.OCR.dg     ora....up.type ONLINE    ONLINE   db02  ora.asm       ora.asm.type   ONLINE   ONLINE    db02  ora....-01.vip ora....t1.type ONLINE    ONLINE   db02  ora....SM2.asm application    ONLINE   ONLINE    db02  ora....02.lsnr application    ONLINE   ONLINE    db02  ora....-02.gsd application    OFFLINE  OFFLINE               ora....-02.ons application    ONLINE   ONLINE    db02  ora....-02.vip ora....t1.type ONLINE    ONLINE   db02  ora.cvu        ora.cvu.type   ONLINE   ONLINE    db02  ora.gsd        ora.gsd.type   OFFLINE  OFFLINE               ora....network ora....rk.type ONLINE    ONLINE   db02  ora.oc4j       ora.oc4j.type  ONLINE   ONLINE    db02  ora.ons        ora.ons.type   ONLINE   ONLINE    db02  ora.orcl.db    ora....se.type ONLINE    ONLINE   db02  ora....taf.svc ora....ce.type ONLINE    ONLINE   db02  ora.scan1.vip  ora....ip.type ONLINE    ONLINE   db02  ora.scan2.vip  ora....ip.type ONLINE    ONLINE   db02  ora.scan3.vip  ora....ip.type ONLINE    ONLINE   db02     在11g R2中，默认 oc4j和gsd资源是 disable的；oc4j 是用于WLM 的一个资源, WLM在 11.2.0.2 才可用；gsd是 CRS 用于跟 9i RAC 进行通信的一个模块,是为了向后兼容才保留的，不影响性能；建议不要刪除, 也不要尝试开启他们, 忽略即可。   ora.gsd  is OFFLINE by default ifthere is no 9i database in the cluster. ora.oc4j is OFFLINE in 11.2.0.1 as DatabaseWorkload Management(DBWLM) is unavailable.  these can be ignored in11gR2 RAC.   状态检查也可以使用如下命令： crsctl stat resource –t 或者 crsctl stat resource   更多内容参考： Oracle 11gR2RAC 进程说明 http://blog.csdn.net/tianlesoftware/article/details/6009962   1.3.4 综合 1、通过SRVCTL命令来start/stop/check所有的实例:  srvctl start|stop|status database -d<db_name>   2、start/stop指定的实例： srvctl start|stop|statusinstance -d <db_name> -i <instance_name>   3、列出当前RAC下所有的  srvctl config database -d <db_name>   4、start/stop/check 所有的nodeapps，比如：VIP, GSD, listener, ONS：  srvctl start|stop|status nodeapps -n<node_name>   5、如果你使用ASM，srvctl也可以start/stop ASM实例：   srvctl start|stop asm -n <node_name>[-i <asm_inst_name>] [-o<oracle_home>]   6、可以获取所有的环境信息：  srvctl getenv database -d <db_name> [-i<instance_name>]   7、设置全局环境和变量： srvctl setenv database -d<db_name> -t LANG=en   8、从OCR中删除已有的数据库：   srvctl remove database -d <db_name>   9、向OCR中添加一个数据库的实例：  srvctl add instance -d <db_name> -i<instance_name> -n <node1>  srvctl add instance -d <db_name> -i<instance_name> -n <node2>     其他的相关操作参考： Oracle 10gRAC OCR 和 VotingDisk 的备份与恢复 http://blog.csdn.net/tianlesoftware/article/details/5467273   Oracle RACASM disk header 备份 恢复 与 重建 示例说明 http://blog.csdn.net/tianlesoftware/article/details/6743677   Oracle 使用BBED 查看 ASM Disk Header 内容 http://blog.csdn.net/tianlesoftware/article/details/6739369         --------------------------------------------------------------------------------------- 版权所有，文章允许转载，但必须以链接方式注明源地址，否则追究法律责任! Skype:    tianlesoftware QQ:       tianlesoftware@gmail.com Email:    tianlesoftware@gmail.com Blog:     http://blog.csdn.net/tianlesoftware Weibo:    http://weibo.com/tianlesoftware Twitter:  http://twitter.com/tianlesoftware Facebook: http://www.facebook.com/tianlesoftware Linkedin: http://cn.linkedin.com/in/tianlesoftware","title":"Oracle 11gR2 RAC 常用维护操作 说明"},{"content":"一．  OHASD 说明 Oracle 的Restart 特性是Oracle 11g里的新特性，在讲这个特性之前先看一下Oracle 11g RAC的进程。之前的Blog 有说明。 Oracle 11gR2RAC 进程说明 http://blog.csdn.net/tianlesoftware/article/details/6009962   Oracle 11gR2 中对CRSD资源进行了重新分类： Local Resources 和 Cluster Resources。    [grid@rac2 ~]$ crsctl stat res -t -------------------------------------------------------------------------------- NAME           TARGET  STATE       SERVER                  STATE_DETAILS       -------------------------------------------------------------------------------- Local Resources -------------------------------------------------------------------------------- ora.DATA.dg                ONLINE  ONLINE      rac1                                                        ONLINE  ONLINE      rac2                                         ora.FRA.dg                ONLINE  ONLINE      rac1                                                        ONLINE  ONLINE      rac2                                         ora.LISTENER.lsnr                ONLINE  ONLINE      rac1                                                        ONLINE  ONLINE      rac2                                         ora.OCRVOTING.dg                ONLINE  ONLINE      rac1                                                         ONLINE  ONLINE      rac2                                         ora.asm                ONLINE  ONLINE      rac1                    Started                            ONLINE  ONLINE      rac2                    Started             ora.gsd                OFFLINE OFFLINE      rac1                                                        OFFLINE OFFLINE      rac2                                         ora.net1.network                ONLINE  ONLINE      rac1                                                         ONLINE  ONLINE      rac2                                         ora.ons                ONLINE  ONLINE      rac1                                                        ONLINE  ONLINE      rac2                                         -------------------------------------------------------------------------------- Cluster Resources -------------------------------------------------------------------------------- ora.LISTENER_SCAN1.lsnr      1        ONLINE  ONLINE      rac1                                         ora.cvu      1        ONLINE  ONLINE      rac1                                         ora.oc4j      1        ONLINE  ONLINE      rac1                                          ora.rac1.vip      1        ONLINE  ONLINE      rac1                                         ora.rac2.vip      1        ONLINE  ONLINE      rac2                                         ora.scan1.vip      1        ONLINE  ONLINE      rac1                                         ora.sdd.db      1        ONLINE  ONLINE      rac1                     Open                     2        ONLINE  ONLINE      rac2                     Open                [grid@rac2 ~]$       在之前的Blog中，提到Oracle 的命令有分层。 Oracle RAC 常用维护工具和命令 http://blog.csdn.net/tianlesoftware/article/details/5358573   对应起来： Local Resources 属于应用层， Cluster Resources 属于集群层。   我们这里要说的Oracle Restart 就是对Cluster Resource的一个管理。   在Oracle 10g RAC 安装时，在运行root.sh时，会在/etc/inittab文件的最后加入ora.crs,ora.cssd,ora.evmd 三个进程。 这样以后每次系统启动时，Clusterware 也会自动启动，其中EVMD和CRSD 两个进程如果出现异常，则系统会自动重启这两个进程，如果是CSSD 进程异常，系统会立即重启。   而在Oracle 11gR2中，只会将ohasd 写入/etc/inittab 文件。   官网对OHASD 的说明： Oracle High Availability Services Daemon(OHASD) ：This process anchors the lower part of the Oracle Clusterwarestack, which consists of processes that facilitate cluster operations.   可以使用如下命令查看OHASD管理的资源： [grid@rac2 ~]$ crsctl stat res -init -t     [grid@rac2 ~]$ ps -ef|grep ohasd root     1057     1  0 Dec21 ?        00:00:00 /bin/sh /etc/init.d/init.ohasdrun root     2274     1  0 Dec21 ?        00:22:53/u01/app/grid/11.2.0/bin/ohasd.bin reboot       二．  Oracle Restart 说明 2.1 说明 官网的文档如下： About Oracle Restart http://docs.oracle.com/cd/E11882_01/server.112/e10595/restart001.htm   Oracle Restartimproves the availability of your Oracle database. When you install OracleRestart, various Oracle components can be automatically restarted after ahardware or software failure or whenever your database host computer restarts.     --Oracle Restart 能提高数据库的可用性，当安装了Oracle Restart 之后，在系统出现硬件或者软件问题，或者主机重启之后，OracleRestart 管理的组件都能自动的进行启动。   Oracle Restart 管理的组件如下表： Component Notes Database instance Oracle Restart can accommodate multiple databases on a single host computer. Oracle Net listener - Database services Does not include the default service created upon installation because it is automatically managed by Oracle Database, and does not include any default services created during database creation. Oracle Automatic Storage Management (Oracle ASM) instance - Oracle ASM disk groups Restarting a disk group means mounting it. Oracle Notification Services (ONS) In a standalone server environment, ONS can be used in Oracle Data Guard installations for automating failover of connections between primary and standby database through Fast Application Notification (FAN). ONS is a service for sending FAN events to integrated clients upon failover.       OracleRestart 会周期性的检查和监控这些组件的状态，如果发现某个组件fail，那么就会shutdown并restart 该组件。     Oracle Restart 只能用于not-cluster的环境。 对于Oracle RAC 环境，Oracle Clusterware 会提供automatically restart的功能。     对于非集群环境，只需要安装OracleGrid Infrastructure，在安装的时候选择“仅安装网格基础结构软件”，然后运行如下脚本来安装Oracle Restart： $GRID_HOME/crs/install/roothas.pl       如果是先安装了Oracle Restart，然后使用dbca创建了实例，那么DBCA会自动的把Oracle 添加到OracleRestart的配置里。 当DBCA启动数据库时，数据库会和其他组件（如disk group）之间建立依赖关系，然后Oracle Restart 开始管理数据库。       当安装了Oracle Restart 后，一些Create操作会自动的创建Oracle 的Compents并将其自动的添加到Oracle Restart configuration中。 这类操作如下表所示： Create Operation Created Component Automatically Added to Oracle Restart Configuration? Create a database with OUI or DBCA Yes Create a database with the CREATE DATABASE SQL statement No Create an Oracle ASM instance with OUI, DBCA, or ASMCA Yes Create a disk group (any method) Yes Add a listener with NETCA Yes Create a database service with SRVCTL Yes Create a database service by modifying the SERVICE_NAMES initialization parameter No Create a database service with DBMS_SERVICE.CREATE_SERVICE No Create a standby database No     同样，一些delete/drop/remove操作也会自动的从Oracle Restart Configuration中进行更新，具体如下表： Operation Deleted Component Automatically Removed from Oracle Restart Configuration? Delete a database with DBCA Yes Delete a database by removing database files with operating system commands No Delete a listener with NETCA Yes Drop an Oracle ASM disk group (any method) Yes Delete a database service with SRVCTL Yes Delete a database service by any other means No     Oracle Restart 由OHASD 进程来管理。 这个就是第一节介绍OHASD的原因。 对于standalone server，使用OHASD 来管理Oracle Restart ，并且不需要CRSD进程的支持。 可以使用OHASD管理的组件如下： 1.CSSD: This is used for Group Services as it was inprevious releases (when it was installed using “localconfig add“) 2.ASM Instance :if Automatic Storage Management is used. 3.ASM Disk Groups: if Automatic Storage Management is used. 4.Listeners 5.Database Instances 6.Database Services 7.ONS/EONS :Used for automatic failover of connections  usingFast Application Notification (FAN) in a Data Guard environment   OHASD  是一个后台的守护进程，其可用来启动和监控OracleRestart 进程。 该进程由/etc/init.d/ohasd 脚本来初始化，并有root用户来执行ohasd.bin 来启动。     使用Oracle Restart 有如下好处： 1.  Automatic resource startup atboot time without using shell scripts or the Oracle supplied dbstart and dbshut scripts. 2.  Resources are started in thecorrect sequence based on dependencies in the OLR（Oracle Local Resource）. 3.  Resources are also monitored by ohasd foravailability and may be restarted in place if they fail. 4.  Role managed services for DataGuard. 5.  Consistency of command lineinterfaced tools using crsctl and srvctl as is done withclusters.     2.2 使用CRSCTL 命令管理Oracle Restart Stack   官网的说明如下： Stopping and Restarting Oracle Restart forMaintenance Operations http://docs.oracle.com/cd/E11882_01/server.112/e10595/restart004.htm   CRSCTL Command Reference http://docs.oracle.com/cd/E11882_01/server.112/e25494/restart006.htm   CRSCTL 命令可选参数： Command Description check Displays the Oracle Restart status. config Displays the Oracle Restart configuration. disable Disables automatic restart of Oracle Restart. enable Enables automatic restart of Oracle Restart. start Starts Oracle Restart. stop Stops Oracle Restart.     注： 以下操作需要已root用户执行   2.2.1 手工停止Oracle Restart: crsctl stop has [-f]  注意：该命令只争对当前服务器有效。 [root@rac1 bin]# ./crsctl stop has CRS-2791: Starting shutdown of Oracle HighAvailability Services-managed resources on 'rac1' CRS-2673: Attempting to stop 'ora.crsd' on'rac1' CRS-2790: Starting shutdown of ClusterReady Services-managed resources on 'rac1' CRS-2673: Attempting to stop 'ora.LISTENER_SCAN1.lsnr'on 'rac1' CRS-2673: Attempting to stop'ora.OCRVOTING.dg' on 'rac1' CRS-2673: Attempting to stop 'ora.sdd.db'on 'rac1' CRS-2673: Attempting to stop'ora.LISTENER.lsnr' on 'rac1' CRS-2673: Attempting to stop 'ora.oc4j' on'rac1' CRS-2673: Attempting to stop 'ora.cvu' on'rac1' CRS-2677: Stop of 'ora.LISTENER_SCAN1.lsnr'on 'rac1' succeeded CRS-2673: Attempting to stop'ora.scan1.vip' on 'rac1' CRS-2677: Stop of 'ora.LISTENER.lsnr' on'rac1' succeeded CRS-2673: Attempting to stop 'ora.rac1.vip'on 'rac1' CRS-2677: Stop of 'ora.rac1.vip' on 'rac1'succeeded CRS-2672: Attempting to start'ora.rac1.vip' on 'rac2' CRS-2677: Stop of 'ora.scan1.vip' on 'rac1'succeeded CRS-2672: Attempting to start 'ora.scan1.vip'on 'rac2' CRS-2676: Start of 'ora.scan1.vip' on'rac2' succeeded CRS-2676: Start of 'ora.rac1.vip' on 'rac2'succeeded CRS-2672: Attempting to start'ora.LISTENER_SCAN1.lsnr' on 'rac2' CRS-2677: Stop of 'ora.sdd.db' on 'rac1'succeeded CRS-2673: Attempting to stop 'ora.DATA.dg'on 'rac1' CRS-2673: Attempting to stop 'ora.FRA.dg'on 'rac1' CRS-2676: Start of'ora.LISTENER_SCAN1.lsnr' on 'rac2' succeeded CRS-2677: Stop of 'ora.FRA.dg' on 'rac1'succeeded CRS-2677: Stop of 'ora.DATA.dg' on 'rac1'succeeded CRS-2677: Stop of 'ora.oc4j' on 'rac1'succeeded CRS-2672: Attempting to start 'ora.oc4j' on'rac2' CRS-2677: Stop of 'ora.cvu' on 'rac1'succeeded CRS-2672: Attempting to start 'ora.cvu' on'rac2' CRS-2676: Start of 'ora.cvu' on 'rac2'succeeded CRS-2677: Stop of 'ora.OCRVOTING.dg' on'rac1' succeeded CRS-2673: Attempting to stop 'ora.asm' on'rac1' CRS-2677: Stop of 'ora.asm' on 'rac1'succeeded CRS-2676: Start of 'ora.oc4j' on 'rac2'succeeded CRS-2673: Attempting to stop 'ora.ons' on'rac1' CRS-2677: Stop of 'ora.ons' on 'rac1'succeeded CRS-2673: Attempting to stop'ora.net1.network' on 'rac1' CRS-2677: Stop of 'ora.net1.network' on'rac1' succeeded CRS-2792: Shutdown of Cluster ReadyServices-managed resources on 'rac1' has completed CRS-2677: Stop of 'ora.crsd' on 'rac1'succeeded CRS-2673: Attempting to stop 'ora.mdnsd' on'rac1' CRS-2673: Attempting to stop 'ora.ctssd' on'rac1' CRS-2673: Attempting to stop 'ora.evmd' on'rac1' CRS-2673: Attempting to stop 'ora.asm' on'rac1' CRS-2677: Stop of 'ora.evmd' on 'rac1'succeeded CRS-2677: Stop of 'ora.mdnsd' on 'rac1'succeeded CRS-2677: Stop of 'ora.ctssd' on 'rac1'succeeded CRS-2677: Stop of 'ora.asm' on 'rac1'succeeded CRS-2673: Attempting to stop'ora.cluster_interconnect.haip' on 'rac1' CRS-2677: Stop of'ora.cluster_interconnect.haip' on 'rac1' succeeded CRS-2673: Attempting to stop 'ora.cssd' on'rac1' CRS-2677: Stop of 'ora.cssd' on 'rac1'succeeded CRS-2673: Attempting to stop 'ora.crf' on'rac1' CRS-2677: Stop of 'ora.crf' on 'rac1'succeeded CRS-2673: Attempting to stop 'ora.gipcd' on'rac1' CRS-2677: Stop of 'ora.gipcd' on 'rac1'succeeded CRS-2673: Attempting to stop 'ora.gpnpd' on'rac1' CRS-2677: Stop of 'ora.gpnpd' on 'rac1'succeeded CRS-2793: Shutdown of Oracle HighAvailability Services-managed resources on 'rac1' has completed CRS-4133: Oracle High Availability Serviceshas been stopped. [root@rac1 bin]#   注意：        我这里测试的是Oracle11gR2的环境，我们在节点1上执行该命令，只把节点1上的进程停了，而把相关的资源转移到我们的节点2上了，因此也证实了我们上面的说的，该命令只争对当前服务器有效。   2.2.2 启动HAS [root@rac1 bin]# ./crsctl start has CRS-4123: Oracle High Availability Serviceshas been started. [root@rac1 bin]#   从上面看只是启动了HAS。实际上后面会把Oracle Restart 管理的资源都会启动。这个可以使用crs_stat 命令来进程验证，不过Oracle 11g的进程启动过程比较慢，需要耐心等待。   [root@rac1 u01]# shcrs_stat.sh Name                           Target     State     Host      ------------------------------ -------------------  -------   ora.DATA.dg                    ONLINE     ONLINE    rac1      ora.FRA.dg                     ONLINE    ONLINE     rac1      ora.LISTENER.lsnr              ONLINE     ONLINE    rac1      ora.LISTENER_SCAN1.lsnr        ONLINE     ONLINE    rac2      ora.OCRVOTING.dg               ONLINE     ONLINE    rac1      ora.asm                        ONLINE     ONLINE    rac1      ora.cvu                        ONLINE     ONLINE    rac2      ora.gsd                        OFFLINE    OFFLINE              ora.net1.network               ONLINE     ONLINE    rac1      ora.oc4j                       ONLINE     ONLINE    rac2      ora.ons                        ONLINE     ONLINE    rac1      ora.rac1.ASM1.asm              ONLINE     ONLINE    rac1      ora.rac1.LISTENER_RAC1.lsnr    ONLINE    ONLINE     rac1      ora.rac1.gsd                   OFFLINE    OFFLINE              ora.rac1.ons                   ONLINE     ONLINE    rac1      ora.rac1.vip                   ONLINE     ONLINE    rac1      ora.rac2.ASM2.asm              ONLINE     ONLINE    rac2      ora.rac2.LISTENER_RAC2.lsnr    ONLINE    ONLINE     rac2      ora.rac2.gsd                   OFFLINE    OFFLINE              ora.rac2.ons                   ONLINE     ONLINE    rac2      ora.rac2.vip                   ONLINE     ONLINE    rac2      ora.scan1.vip                  ONLINE     ONLINE    rac2      ora.sdd.db                     ONLINE     ONLINE    rac2       2.2.3 禁用HAS（Restart）在server 重启后的自动启动 [root@rac1 bin]# ./crsctl disable has CRS-4621: Oracle High Availability Servicesautostart is disabled. [root@rac1 bin]#   2.2.4 查看HAS（Restart）的状态 [root@rac1 bin]# ./crsctl config has CRS-4621: Oracle High Availability Servicesautostart is disabled.   2.2.5 启用HAS（Restart）在server 重启后的自启动 [root@rac1 bin]# ./crsctl enable has CRS-4622: Oracle High Availability Servicesautostart is enabled.   --查看has的状态，验证刚才命令的效果： [root@rac1 bin]# ./crsctl config has CRS-4622: Oracle High Availability Servicesautostart is enabled. [root@rac1 bin]#   2.2.6 查看Restart 当前状态 [root@rac1 bin]# ./crsctl check has CRS-4638: Oracle High Availability Servicesis online     2.2.7 查看Oracle Restart 中由OHASD管理的resource 状态 [root@rac1 bin]# ./crsctl stat res -t -------------------------------------------------------------------------------- NAME           TARGET  STATE       SERVER                  STATE_DETAILS       -------------------------------------------------------------------------------- Local Resources -------------------------------------------------------------------------------- ora.DATA.dg                ONLINE  ONLINE      rac1                                                        ONLINE  ONLINE      rac2                                         ora.FRA.dg                ONLINE  ONLINE      rac1                                                        ONLINE  ONLINE      rac2                                         ora.LISTENER.lsnr                ONLINE  ONLINE      rac1                                                         ONLINE  ONLINE      rac2                                         ora.OCRVOTING.dg                ONLINE  ONLINE      rac1                                                        ONLINE  ONLINE      rac2                                          ora.asm                ONLINE  ONLINE      rac1                    Started                            ONLINE  ONLINE      rac2                    Started             ora.gsd                OFFLINE OFFLINE      rac1                                                         OFFLINE OFFLINE      rac2                                         ora.net1.network                ONLINE  ONLINE      rac1                                                        ONLINE  ONLINE      rac2                                          ora.ons                ONLINE  ONLINE      rac1                                                        ONLINE  ONLINE      rac2                                         -------------------------------------------------------------------------------- Cluster Resources -------------------------------------------------------------------------------- ora.LISTENER_SCAN1.lsnr      1        ONLINE  ONLINE      rac2                                         ora.cvu      1        ONLINE  ONLINE      rac2                                         ora.oc4j      1        ONLINE  ONLINE      rac2                                         ora.rac1.vip      1        ONLINE  ONLINE      rac1                                          ora.rac2.vip      1        ONLINE  ONLINE      rac2                                         ora.scan1.vip      1        ONLINE  ONLINE      rac2                                         ora.sdd.db      1        ONLINE  ONLINE      rac1                     Open                     2        ONLINE  ONLINE      rac2                     Open                [root@rac1 bin]#     2.3 使用SRVCTL 命令管理Restart（OHASD） 可以手工的使用SRVCTL 命令来管理Oracle Restart。从Oracle Restart 配置里添加或者删除一些组件。当我们手工的添加一个组件到到Oracle Restart，并使用SRVCTL启用该组件，那么Oracle Restart 就开始管理该组件，并根据需要决定是否对该组件进行重启。   官方文档的说明如下： SRVCTL Command Reference for Oracle Restart http://docs.oracle.com/cd/E11882_01/server.112/e25494/restart005.htm   Configuring OracleRestart http://docs.oracle.com/cd/E11882_01/server.112/e10595/restart002.htm     SRVCTL命令主要有如下选项： Command Description add Adds a component to the Oracle Restart configuration. config Displays the Oracle Restart configuration for a component. disable Disables management by Oracle Restart for a component. enable Reenables management by Oracle Restart for a component. getenv Displays environment variables in the Oracle Restart configuration for a database, Oracle ASM instance, or listener. modify Modifies the Oracle Restart configuration for a component. remove Removes a component from the Oracle Restart configuration. setenv Sets environment variables in the Oracle Restart configuration for a database, Oracle ASM instance, or listener. start Starts the specified component. status Displays the running status of the specified component. stop Stops the specified component. unsetenv Unsets environment variables in the Oracle Restart configuration for a database, Oracle ASM instance, or listener.     --This example adds thedatabase with the DB_UNIQUE_NAME dbcrm: srvctl add database -d dbcrm -o/u01/app/oracle/product/11.2.0/dbhome_1   --This example adds thesame database and also establishes a dependency between the database and thedisk groups DATA and RECOVERY. srvctl add database -d dbcrm -o/u01/app/oracle/product/11.2.0/dbhome_1  -a \"DATA,RECOVERY\"   --The following commandadds a listener (named LISTENER) running out of the database Oracle homeand listening on TCP port 1522: srvctl add listener -p TCP:1522 -o /u01/app/oracle/product/11.2.0/dbhome_1   注意srvctl命令中的config 选项，其是用来限制相关Resource 信息的： [grid@rac1 ~]$ srvctl config asm -a ASM home: /u01/app/grid/11.2.0 ASM listener: LISTENER ASM is enabled. [grid@rac1 ~]$   这里srvctl 命令是非常常用的。在2.1 节里也说明了，有些操作会自动的把相关的resource 添加到Restart里，从而来进行监控，但有些操作不会添加到Restart里，这就需要我们手工的来进行添加。         最后一天，如果已经安装过了Restart，如果机器名称发生了改变，就需要重新配置Oracle Restart，具体参考MOS 文档：[ID986740.1]。           --------------------------------------------------------------------------------------- 版权所有，文章允许转载，但必须以链接方式注明源地址，否则追究法律责任! Skype:    tianlesoftware QQ:       tianlesoftware@gmail.com Email:    tianlesoftware@gmail.com Blog:     http://blog.csdn.net/tianlesoftware Weibo:    http://weibo.com/tianlesoftware Twitter:  http://twitter.com/tianlesoftware Facebook: http://www.facebook.com/tianlesoftware Linkedin: http://cn.linkedin.com/in/tianlesoftware","title":"Oracle 11g 新特性 -- Oracle Restart 说明"},{"content":" 最近ERP系统升级，同时进行的时候SQL2000 升级到SQL2008 用户在反应查询库存明细表，选择某个仓库的时候提示如下错误信息：   在排除了程序和触发器造成的影响后，微软给出了解释：http://support.microsoft.com/kb/962900/ 查询本机器的版本还是RTM。 版本号与补丁对应图：   下载对应86或者64的SP补丁，从低版本按顺序打补丁。   打完补丁，测试结果一切正常。打补丁前请事先做好数据库的完整备份！    ","title":"[MSSQL]试图将非可空值的列的值设置为 NULL"},{"content":"今天早上醒来在 Hacker News 上发布了 EDBC 的信息，没想到一下子被顶到首页上去了！大家都去围观一下，嘿嘿~ http://news.ycombinator.com/item?id=4967432","title":"EDBC居然被顶到Hacker News的首页！"},{"content":"最近有些闲，看完了concept突然有种空虚的感觉。闲话不多说。 用PLSQL写了一个打印日历的功能。 create or replace package display_date is  procedure display_spec_mon (year number , month number)  ;end ; create or replace package body display_date is  type t_conv_mon is table of varchar2(10) ;  conv_mon t_conv_mon := t_conv_mon() ;  procedure display_title (year number , month number)   is  begin    dbms_output.put_line(year||'.'||conv_mon(month)) ;    dbms_output.put_line(lpad(' ',21,'-')) ;    dbms_output.put_line('Su Mo Tu We Th Fr Sa');  end  ;  procedure display_spec_mon (year number , month number)   is    current_mon date ;     current_line varchar2(21) ;  begin--    dbms_output.put_line (year||lpad(month||'',2,'0')||'01') ;    display_title (year,month) ;    current_mon := to_date(year||lpad(month||'',2,'0')||'01','yyyymmdd') ;    for i in 1 .. (add_months(current_mon,1)-current_mon) loop       if i = 1 then        current_line := current_line || (lpad(' ',(to_char(current_mon+i-1,'D')-1)*3,'-- '));       end if ;      current_line := current_line || rpad(i||'',3,' ');      if length(current_line)>=21 then         dbms_output.put_line(current_line) ;        current_line := '' ;      end if ;    end loop ;    dbms_output.put_line(current_line) ;  end ;    begin  conv_mon.extend(12);  conv_mon(1) :=  'January' ;  conv_mon(2) :=  'February' ;    conv_mon(3) :=  'Marcy' ;  conv_mon(4) :=  'April' ;    conv_mon(5) :=  'May' ;  conv_mon(6) :=  'June' ;    conv_mon(7) :=  'July' ;  conv_mon(8) :=  'August' ;    conv_mon(9) :=  'September' ;  conv_mon(10) := 'October' ;    conv_mon(11) :=  'November' ;  conv_mon(12) :=  'December' ;end ; 执行结果： _sys@DAVID> exec display_date.display_spec_mon(2013,10) ;2013.October--------------------Su Mo Tu We Th Fr Sa-- -- 1  2  3  4  56  7  8  9  10 11 1213 14 15 16 17 18 1920 21 22 23 24 25 2627 28 29 30 31PL/SQL procedure successfully completed._sys@DAVID> exec display_date.display_spec_mon(2012,12) ;2012.December--------------------Su Mo Tu We Th Fr Sa-- -- -- -- -- -- 12  3  4  5  6  7  89  10 11 12 13 14 1516 17 18 19 20 21 2223 24 25 26 27 28 2930 31PL/SQL procedure successfully completed.","title":"使用PLSQL 打印日历"},{"content":"一、普通查询 这是OracleText比较普遍且常用的应用场景。创建OracleText中Context类型的索引，生成大量的关键词，用于加快类似于普通的like ‘%xx%’操作速度，或者查询一些比较大的文档。可以使用contains函数进行数据检索。缺点：比较依赖于关键词和文档格式。有时可能不太准确。 以下为简单示例，这里不必多说，只是简单查询场景： 1.创建表 create table normal_context( id number , contentclob ) ; 2.初始化数据 insert into normal_context values(1 , ' Use thisindex to build a                                  textretrieval application                                  when your text consists                                  of largecoherent                                  documents.You can                                  indexdocuments of                                  differentformats such as                                  MS Word, HTMLor                                  plain text.                                  You cancustomize the                                  index in avariety of                                  ways.                                  This index typerequires                                 CTX_DDL.SYNC_INDEX                                  after DML onbase table.') ;insert into normal_context values(2 ,'Use thisindex type for                                better mixed query                                performance.Typically,                                with this indextype,                                you index small                                documents ortext                               fragments.Other                                columns in thebase                                table, such asitem                                names, prices,and                                descriptionscan be                                included in the indexto                                improve mixedquery                                performance.                                This index typeis                                transactional,                                automaticallyupdating                                itself afterDML to base                                table. No CTX_                               DDL.SYNC_INDEXis                                necessary.') ;  insert into normal_context values(3 , ' UseCTXRULEindex to                                  build adocument                                 classification or routing                                  application.This index                                  is created on a table of                                  queries,where the                                  queriesdefine the                                 classification or routing                                  criteria.') ;insert into normal_context values(4 , ' Createthis index when                                  you need tospeed up                                 existsNode()queries                                  on anXMLTypecolumn.') ; 3.初始化索引 CREATE INDEX idx_normal_content ONnormal_context(content) INDEXTYPE IS CTXSYS.CONTEXT ; 3.1. context类型的全文索引在基表数据更改的时候需要使用下面的命令同步全文索引 exec CTX_DDL.SYNC_INDEX('idx_normal_content') ; 4.查询 _dexter@FAKE> SELECT SCORE(1), id, contentFROM normal_context WHERE CONTAINS(content, 'classification', 1) > 0;  SCORE(1)         ID CONTENT---------- ------------------------------------------------------------------------------------------       10          3  Use CTXRULEindex to                                                        build a document                                                       classification or routing                                                       application. This index                                                       is created on a table of                                                       queries, where the                                                       queries define the                                                       classification or routing                                                       criteria. _dexter@FAKE> SELECT SCORE(1), id, contentFROM normal_context WHERE CONTAINS(content, 'small documents', 1) > 0;  SCORE(1)         ID CONTENT---------- ---------- --------------------------------------------------------------------------------        5          2 Use this index typefor                                                     better mixed query                                                     performance. Typically,                                                     with this index type,                                                     you index small                                                     documents or text                                                      fragments. Other                                                     columns in the base                                                     table, such as item                                                     names, prices, and                                                     descriptions can be                                                     included in the index to                                                     improve mixed query                                                      performance.                                                     This index type is                                                     transactional,                                                     automatically updating                                                     itself after DML to base                                                     table. No CTX_                                                     DDL.SYNC_INDEXis                                                      necessary.        二、目录信息 Ctxcat(context catelog) 索引为事务维护，也就是说更改数据的时候会更新索引，不需要像context类型的全文索引一样每次更改数据后执行CTX_DDL.SYNC_INDEX刷新操作。   下面一个具体需求，丁丁网上书城客户抱怨，查询图书的速度非常之缓慢。已经达到了无法忍受的程度，so，丁丁书城运营总监东东给开发组下了死命令，1周内完成任务，提升查询的性能。首席架构师康康发现，用户经常使用的查询操作是按照书名查询，并且按照价格降序排列。于是命令程序员梆梆进行了如下测试： 1. 创建表 create table catelog_bookstore(id         number , title      varchar2(100) , description varchar2(4000), author     varchar2(100) , price      number , pubdate    date ) ; 2.初始化数据 insert into catelog_bookstore values(1,'Oracle Database 9i/10g/11g编程艺术：深入数据库体系结构（第二版）', 'DBA必备良书','ThomasKyte',109,to_date('201101','yyyymm')) ;insert into catelog_bookstore values(2,'DBA的思想天空：感悟Oracle数据库本职', '始祖级人物倾情奉献','白鳝，储学荣',89,to_date('201210','yyyymm'));insert into catelog_bookstore values(3,'让Oracle跑的更快：Oracle10g 性能分析与优化思路', '不必多说的绝佳之作','谭怀远',59,to_date('201008','yyyymm'));insert into catelog_bookstore values(4,'PL/SQL最佳实践', '引导开发思维','StevenFeuerstein',48,to_date('200902','yyyymm')) ;insert into catelog_bookstore values(5,'剑破冰山：Oracle PL/SQL开发艺术', '国内少有的PL/SQL书籍，作者功底，国内首屈一指','梁敬斌、王保强、怀晓明 等',69,to_date('201101','yyyymm'));commit ; 3.定义subindex EXEC CTX_DDL.create_index_set('price_set');EXEC CTX_DDL.ADD_INDEX('price_set','price'); 4. 创建 ctxcat 索引，with index set。 CREATE INDEX catelog_bookstore_title ONcatelog_bookstore(title) INDEXTYPE IS CTXSYS.CTXCATPARAMETERS ('index set price_set'); 5.查询 _dexter@FAKE> SELECT title,price FROMcatelog_bookstore WHERE CATSEARCH(title, 'Oracle', 'order by price')> 0; TITLE                                                                      PRICE--------------------------------------------------------------------------------让Oracle跑的更快：Oracle 10g 性能分析与优化思路                                59剑破冰山：OraclePL/SQL开发艺术                                               69DBA的思想天空：感悟Oracle数据库本职                                            89Oracle Database 9i/10g/11g编程艺术：深入数据库体系结构（第二版）              109    _dexter@FAKE> SELECT title,price FROMcatelog_bookstore WHERE CATSEARCH(title, 'PL/SQL', 'price > 48 ')> 0; TITLE                                                                      PRICE--------------------------------------------------------------------------------剑破冰山：OraclePL/SQL开发艺术                                                69   测试结论，使用全文索引，查询性能得到了大量的提升。于是乎，风风火火的重构任务开始了…   三、文档分类 典型使用：创建规则表，根据关键词，对文档进行分类操作。比较适合对比较大的文档进行分类的操作。索引类型：ctxsys.ctxrule 用于将文档分类的应用，简易流程图如下所示： 上图显示的是一个典型的分类应用的处理流程： 1.     应用程序接收 document 文档流（比如说java 中的io流）。 2.     DB-A执行match操作，查看文档的分类情况。 3.     根据文档的分类，进行相应的处理。执行入库操作文档库 DB-B，或者email 给 user 。操作根据具体业务而定。   下面是一个具体的需求，数据库表中存有大量的文本类型数据，需要进行整理，分类。因为使用了clob字段存储文本数据，所以这项任务变成了，时间耗费长，精力耗费多的任务。但是因为有了Oracle Text 中的ctxsys.ctxrule类型索引，这一切变的简单之极。以下为比较好理解的简单示例：   1.创建表 create table doc_table (doc_id number primary key not null,title varchar2(4000),text clob); create table doc_rules (catid number primary key not null,category varchar2(100),query varchar2(2000)); create table doc_id_cat (doc_id number,catid number); 2. 初始化数据，这里使用sqlldr将笔者的一些txt文档加载到数据库中。 --ctl LOAD DATAINFILE 'D:\\loader.dat'INTO TABLE doc_tableREPLACEFIELDS TERMINATED BY '@'(doc_id INTEGER external,title CHAR,text_file FILLER CHAR,text LOBFILE(text_file) TERMINATED BY EOF) --datfile 1@ACID@D:\\ldr_text\\ACID.txt2@bbed小结@D:\\ldr_text\\bbed小结.txt3@Pending statistics@D:\\ldr_text\\Pendingstatistics.txt4@PLSQL分页@D:\\ldr_text\\PLSQL分页.txt5@Temporary Tablespace@D:\\ldr_text\\TemporaryTablespace.txt6@Oracle 订阅 rss源@d:\\ldr_text\\Oracle订阅 rss源.txt7@PLSQL打印日历@d:\\ldr_text\\PLSQL打印日历.txt D:\\>sqlldr userid=dexter/xiaojuncontrol=d:\\ldrctl.ctl SQL*Loader: Release 11.2.0.1.0- Production on Tue Dec 25 22:05:52 2012 Copyright (c) 1982, 2009, Oracle and/or itsaffiliates.  All rights reserved. Commit point reached - logical record count 7 初始化规则表 insert into doc_rulesvalues  (1,  'transaction',  'transaction or 事务 or 原子性 or 一致性 or 隔离性 or 持久性');insert into doc_rulesvalues  (2,  'oracle',   'oracleor plsql or PL/SQL or temporarytablespace or 11g or 10g or 9i');insert into doc_rulesvalues  (3, '闲', 'rss or 懒人表 or 更新rss'); insert into doc_rules values (4, 'internal','bbed or 16进制 or kdbr'); commit ; 3.创建索引 （So easy） create index idx_doc_rules on doc_rules(query)indextype is ctxsys.ctxrule; 4.文档分类 dexter@ORCL> select doc_id , catid, title,category  from doc_rules , doc_tablewhere matches(query, text) > 0 order by 1,2 ;    DOC_ID      CATID TITLE                          CATEGORY---------- ---------------------------------------- ------------------------------        1          1 ACID                           transaction        1          2 ACID                           oracle        2          2 bbed小结                       oracle        2          4 bbed小结                       internal        3          2 Pendingstatistics             oracle        4          2 PLSQL分页                      oracle        5          1 TemporaryTablespace           transaction        5          2 TemporaryTablespace           oracle        6          3 Oracle 订阅 rss源              闲        7          2 PLSQL打印日历                  oracle 10 rows selected.   完成任务   insert into doc_id_catselect doc_id,catid from doc_rules,doc_tablewhere matches(query, text) > 0 ; commit;   文档与分类信息匹配情况如下表所示：   Title\\Cat 关键字 ACID bbed小结 Pending statistics PLSQL分页 Temporary Tablespace Oracle 订阅 rss源 PLSQL打印日历 transaction 事务       事务     oracle oracle 10g PL/SQL plsql oracle   PL/SQL internal   bbed           闲           更新rss       想了解更详细的内容，可以参考官方文档 Oracle® Text Application Developer's Guide Oracle® Text Reference","title":"Oracle Text 全文索引 几种典型应用场景"},{"content":"大概的步骤(前提归档日志可用和闪回功能开启)         关闭数据库         启动数据库到mount状态(exclusive模式)         闪回至某个时间点，SCN或log sequence number         使用resetlogs打开数据库 一、时间戳闪回 1.在bb用户一下有一个test表        SQL> conn bb/bb;        Connected.     SQL> select * from test;              A       ----------             333 2.查看当前系统的时间 SQL> select to_char(sysdate,'yyyy-mm-dd hh24:mi:ss') tm from dual; TM ------------------- 2012-12-27 22:16:20 3.删除用户 SQL> drop user bb cascade; User dropped. 4.关闭数据库 shutdown immediate 5.启动到mount状态下 startup monut 6.执行闪回 SQL> flashback database to timestamp to_timestamp('2012-12-27 22:16:20','yyyy-mm-dd hh24:mi:ss'); 7. 用resetlogs打开数据库 alter database open resetlogs; 8.检查结果 SQL> select * from bb.test;          A ----------        333 9.成功。   二、基于scn闪回   1.查看当前的scn号 SQL> select current_scn from v$database; CURRENT_SCN -----------      863054 2删除测试表 drop table bb.test; 3.手动执行检查点 alter system checkpoint; SQL> select file#,checkpoint_change# from v$datafile;      FILE# CHECKPOINT_CHANGE# ---------- ------------------          1             863080          2             863080          3             863080          4             863080          5             863080          6             863080          9             863080 4.关闭数据库 shutdown immediate; 5.到mount状态下 startup mount; 6.闪回 SQL> flashback database to scn 863054; Flashback complete. 7.打开数据库 alter database open resetlogs; 8。检查结果 SQL> select * from bb.test;          A ----------        333 三、基于闪回点 SQL> create table t(id int,col varchar2(20));   --创建表t               SQL> insert into t values(1,'ABC');               SQL> insert into t values(2,'DEF');               SQL> commit;               SQL> create restore point bef_damage;    --创建闪回点               SQL> insert into t values(3,'GHI');               SQL> select ora_rowscn,id,col from t;   --查看表t的记录               ORA_ROWSCN         ID COL             ---------- ---------- --------------------                1874406          1 ABC                1874406          2 DEF                1874406          3 GHI                               SQL> shutdown immediate;                         SQL> startup mount exclusive;                         SQL> flashback database to restore point bef_damage;  --实施时点闪回                         SQL> alter database open resetlogs;                         SQL> select * from t;   --闪回成功后，闪回点之后的数据丢失                       ID COL             ---------- --------------------                      1 ABC                      2 DEF   跟闪回有关的视图 v$flashback_database_log; v$flashback_database_stat; v$recovery_file_dest;    ","title":"flashback database闪回"},{"content":"Operating System:Oracle Linux 5.7 x86_64 Oracle version:10.2.0.5 RAC Primary database 192.168.1.51            racnode1 192.168.1.151           racnode1-vip 172.168.1.51            racnode1-priv 192.168.1.52            racnode2 192.168.1.152           racnode2-vip 172.168.1.52            racnode2-priv 192.168.1.53            racnode3 192.168.1.153           racnode3-vip 172.168.1.53            racnode3-priv Single Standby database 192.168.1.59            standby 主库是一台3nodes的10g RAC,备库准备使用单实例数据库存储使用ASM 需要在standby机器上安装oracle database software并升级至10.2.0.5,安装过程略 RAC 信息 SQL> alter session set nls_date_format='yyyy-mm-dd hh24:mi:ss';Session altered.SQL> select INSTANCE_NAME,HOST_NAME,VERSION,STARTUP_TIME,STATUS,ACTIVE_STATE,INSTANCE_ROLE,DATABASE_STATUS from gv$INSTANCE;INSTANCE_NAME\t HOST_NAME   VERSION\t       STARTUP_TIME\t   STATUS\tACTIVE_ST INSTANCE_ROLE      DATABASE_STATUS---------------- ----------- ----------------- ------------------- ------------ --------- ------------------ -----------------racdb2\t\t racnode2    10.2.0.5.0        2012-12-25 16:08:08 OPEN \tNORMAL\t  PRIMARY_INSTANCE   ACTIVEracdb1\t\t racnode1    10.2.0.5.0        2012-12-25 16:08:07 OPEN \tNORMAL\t  PRIMARY_INSTANCE   ACTIVEracdb3\t\t racnode3    10.2.0.5.0        2012-12-25 16:08:08 OPEN \tNORMAL\t  PRIMARY_INSTANCE   ACTIVESQL> select dbid,name,created,log_mode,db_unique_name from gv$database;      DBID NAME      CREATED\t\t LOG_MODE     DB_UNIQUE_NAME---------- --------- ------------------- ------------ ------------------------------ 800157471 RACDB     2012-12-20 15:58:23 ARCHIVELOG   racdb 800157471 RACDB     2012-12-20 15:58:23 ARCHIVELOG   racdb 800157471 RACDB     2012-12-20 15:58:23 ARCHIVELOG   racdbSQL> select name from v$datafile;NAME----------------------------------------------------------------------------------------------------------------------------------------------------------------+DATADG/racdb/datafile/system.269.802972261+DATADG/racdb/datafile/undotbs1.256.802972267+DATADG/racdb/datafile/sysaux.265.802972263+DATADG/racdb/datafile/users.257.802972267+DATADG/racdb/datafile/example.258.802972265+DATADG/racdb/datafile/undotbs2.259.802972265+DATADG/racdb/datafile/undotbs3.264.8029722697 rows selected.SQL> select name from v$controlfile;NAME----------------------------------------------------------------------------------------------------------------------------------------------------------------+DATADG/racdb/controlfile/current.260.802540703+FLASHDG/racdb/controlfile/current.256.802540705SQL> select member from v$logfile;MEMBER----------------------------------------------------------------------------------------------------------------------------------------------------------------+DATADG/racdb/onlinelog/group_2.262.802540719+FLASHDG/racdb/onlinelog/group_2.258.802540725+DATADG/racdb/onlinelog/group_1.261.802540709+FLASHDG/racdb/onlinelog/group_1.257.802540715+DATADG/racdb/onlinelog/group_3.266.802541097+FLASHDG/racdb/onlinelog/group_3.259.802541105+DATADG/racdb/onlinelog/group_4.267.802541113+FLASHDG/racdb/onlinelog/group_4.260.802541123+DATADG/racdb/onlinelog/group_5.270.802888327+FLASHDG/racdb/onlinelog/group_5.279.802888333+DATADG/racdb/onlinelog/group_6.271.802888337MEMBER----------------------------------------------------------------------------------------------------------------------------------------------------------------+FLASHDG/racdb/onlinelog/group_6.280.80288834312 rows selected.SQL> select * from v$log;    GROUP#    THREAD#  SEQUENCE#      BYTES    MEMBERS ARC STATUS\t    FIRST_CHANGE# FIRST_TIME---------- ---------- ---------- ---------- ---------- --- ---------------- ------------- -------------------\t 1\t    1\t      23   52428800\t     2 NO  CURRENT\t\t  1026686 2012-12-26 11:16:41\t 2\t    1\t      22   52428800\t     2 YES INACTIVE\t\t  1026647 2012-12-26 11:16:24\t 3\t    2\t      13   52428800\t     2 YES INACTIVE\t\t  1026657 2012-12-26 11:16:26\t 4\t    2\t      14   52428800\t     2 NO  CURRENT\t\t  1026688 2012-12-26 11:16:42\t 5\t    3\t       7   52428800\t     2 NO  CURRENT\t\t  1026664 2012-12-26 11:16:39\t 6\t    3\t       6   52428800\t     2 YES INACTIVE\t\t  1026655 2012-12-26 11:16:266 rows selected. [oracle@racnode1 ~]$ crs_stat -t Name           Type           Target    State     Host        ------------------------------------------------------------ora.racdb.db   application    ONLINE    ONLINE    racnode2    ora....b1.inst application    ONLINE    ONLINE    racnode1    ora....b2.inst application    ONLINE    ONLINE    racnode2    ora....b3.inst application    ONLINE    ONLINE    racnode3    ora.....zwc.cs application    ONLINE    ONLINE    racnode1    ora....db1.srv application    ONLINE    ONLINE    racnode1    ora....SM1.asm application    ONLINE    ONLINE    racnode1    ora....E1.lsnr application    ONLINE    ONLINE    racnode1    ora....de1.gsd application    ONLINE    ONLINE    racnode1    ora....de1.ons application    ONLINE    ONLINE    racnode1    ora....de1.vip application    ONLINE    ONLINE    racnode1    ora....SM2.asm application    ONLINE    ONLINE    racnode2    ora....E2.lsnr application    ONLINE    ONLINE    racnode2    ora....de2.gsd application    ONLINE    ONLINE    racnode2    ora....de2.ons application    ONLINE    ONLINE    racnode2    ora....de2.vip application    ONLINE    ONLINE    racnode2    ora....SM3.asm application    ONLINE    ONLINE    racnode3    ora....E3.lsnr application    ONLINE    ONLINE    racnode3    ora....de3.gsd application    ONLINE    ONLINE    racnode3    ora....de3.ons application    ONLINE    ONLINE    racnode3    ora....de3.vip application    ONLINE    ONLINE    racnode3    [oracle@racnode1 ~]$ crs_stat -lsName           Owner          Primary PrivGrp          Permission  -----------------------------------------------------------------ora.racdb.db   oracle         oinstall                 rwxrwxr--ora....b1.inst oracle         oinstall                 rwxrwxr--ora....b2.inst oracle         oinstall                 rwxrwxr--ora....b3.inst oracle         oinstall                 rwxrwxr--ora.....zwc.cs oracle         oinstall                 rwxrwxr--ora....db1.srv oracle         oinstall                 rwxrwxr--ora....SM1.asm oracle         oinstall                 rwxrwxr--ora....E1.lsnr oracle         oinstall                 rwxrwxr--ora....de1.gsd oracle         oinstall                 rwxr-xr--ora....de1.ons oracle         oinstall                 rwxr-xr--ora....de1.vip root           oinstall                 rwxr-xr--ora....SM2.asm oracle         oinstall                 rwxrwxr--ora....E2.lsnr oracle         oinstall                 rwxrwxr--ora....de2.gsd oracle         oinstall                 rwxr-xr--ora....de2.ons oracle         oinstall                 rwxr-xr--ora....de2.vip root           oinstall                 rwxr-xr--ora....SM3.asm oracle         oinstall                 rwxrwxr--ora....E3.lsnr oracle         oinstall                 rwxrwxr--ora....de3.gsd oracle         oinstall                 rwxr-xr--ora....de3.ons oracle         oinstall                 rwxr-xr--ora....de3.vip root           oinstall                 rwxr-xr-- [oracle@racnode1 admin]$ cat tnsnames.ora# tnsnames.ora Network Configuration File: /u01/app/oracle/product/10.2.0/db_1/network/admin/tnsnames.ora# Generated by Oracle configuration tools.RACDB1 =  (DESCRIPTION =    (ADDRESS = (PROTOCOL = TCP)(HOST = racnode1-vip)(PORT = 1521))    (CONNECT_DATA =      (SERVER = DEDICATED)      (SERVICE_NAME = racdb)      (INSTANCE_NAME = racdb1)    )  )RACDB =  (DESCRIPTION =    (ADDRESS = (PROTOCOL = TCP)(HOST = racnode1-vip)(PORT = 1521))    (ADDRESS = (PROTOCOL = TCP)(HOST = racnode2-vip)(PORT = 1521))    (ADDRESS = (PROTOCOL = TCP)(HOST = racnode3-vip)(PORT = 1521))    (LOAD_BALANCE = yes)    (CONNECT_DATA =      (SERVER = DEDICATED)      (SERVICE_NAME = racdb)    )  )LISTENERS_RACDB =  (ADDRESS_LIST =    (ADDRESS = (PROTOCOL = TCP)(HOST = racnode1-vip)(PORT = 1521))    (ADDRESS = (PROTOCOL = TCP)(HOST = racnode2-vip)(PORT = 1521))    (ADDRESS = (PROTOCOL = TCP)(HOST = racnode3-vip)(PORT = 1521))  )ZWC =  (DESCRIPTION =    (ADDRESS = (PROTOCOL = TCP)(HOST = racnode1-vip)(PORT = 1521))    (ADDRESS = (PROTOCOL = TCP)(HOST = racnode2-vip)(PORT = 1521))    (ADDRESS = (PROTOCOL = TCP)(HOST = racnode3-vip)(PORT = 1521))    (LOAD_BALANCE = yes)    (CONNECT_DATA =      (SERVER = DEDICATED)      (SERVICE_NAME = zwc)      (FAILOVER_MODE =        (TYPE = SELECT)        (METHOD = BASIC)        (RETRIES = 180)        (DELAY = 5)      )    )  )RACDB3 =  (DESCRIPTION =    (ADDRESS = (PROTOCOL = TCP)(HOST = racnode3-vip)(PORT = 1521))    (CONNECT_DATA =      (SERVER = DEDICATED)      (SERVICE_NAME = racdb)      (INSTANCE_NAME = racdb3)    )  )RACDB2 =  (DESCRIPTION =    (ADDRESS = (PROTOCOL = TCP)(HOST = racnode2-vip)(PORT = 1521))    (CONNECT_DATA =      (SERVER = DEDICATED)      (SERVICE_NAME = racdb)      (INSTANCE_NAME = racdb2)    )  ) 在standby 服务器创建用户用户组 groupadd -g 501 oinstall groupadd -g 502 dba groupadd -g 503 oper useradd -m -u 501 -g oinstall -G dba,oper -d /home/oracle -s /bin/bash -c \"Oracle Software Owner\" oracle mkdir -p /u01/app/oracle chown -R oracle:oinstall /u01/app chmod -R 775 /u01/app 配置oracle用户环境变量 alias ls=\"ls -FA\"export JAVA_HOME=/usr/local/javaexport ORACLE_BASE=/u01/app/oracleexport ORACLE_HOME=$ORACLE_BASE/product/10.2.0/db_1export ORACLE_PATH=$ORACLE_BASE/common/oracle/sql:.:$ORACLE_HOME/rdbms/adminexport CV_JDKHOME=/usr/local/java                                         export ORACLE_SID=standbyexport PATH=.:${JAVA_HOME}/bin:${PATH}:$HOME/bin:$ORACLE_HOME/bin:$ORA_CRS_HOME/binexport PATH=${PATH}:/usr/bin:/bin:/usr/bin/X11:/usr/local/binexport PATH=${PATH}:$ORACLE_BASE/common/oracle/binexport ORACLE_TERM=xtermexport TNS_ADMIN=$ORACLE_HOME/network/adminexport ORA_NLS10=$ORACLE_HOME/nls/dataexport NLS_DATE_FORMAT=\"DD-MON-YYYY HH24:MI:SS\"export DISPLAY=192.168.2.224:0.0export NLS_LANG=AMERICAN_AMERICA.ZHS16GBKexport LD_LIBRARY_PATH=$ORACLE_HOME/libexport LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:$ORACLE_HOME/oracm/libexport LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/lib:/usr/lib:/usr/local/libexport CLASSPATH=$ORACLE_HOME/JREexport CLASSPATH=${CLASSPATH}:$ORACLE_HOME/jlibexport CLASSPATH=${CLASSPATH}:$ORACLE_HOME/rdbms/jlibexport CLASSPATH=${CLASSPATH}:$ORACLE_HOME/network/jlibexport THREADS_FLAG=nativeexport TEMP=/tmpexport TMPDIR=/tmp 安装相关rpm包,配置系统内核参数,这里我使用的是Oracle Linux 5提供的oracle-validated 配置listener和tnsnames [oracle@standby admin]$ cat listener.ora # listener.ora Network Configuration File: /u01/app/oracle/product/10.2.0/db_1/network/admin/listener.ora# Generated by Oracle configuration tools.SID_LIST_LISTENER =  (SID_LIST =    (SID_DESC =      (GLOBAL_DBNAME = standby)      (ORACLE_HOME = /u01/app/oracle/product/10.2.0/db_1)      (SID_NAME = standby)    )  )LISTENER =  (DESCRIPTION =    (ADDRESS = (PROTOCOL = TCP)(HOST = standby)(PORT = 1521))  )[oracle@standby admin]$ cat tnsnames.ora # tnsnames.ora Network Configuration File: /u01/app/oracle/product/10.2.0/db_1/network/admin/tnsnames.ora# Generated by Oracle configuration tools.STANDBY =  (DESCRIPTION =    (ADDRESS_LIST =      (ADDRESS = (PROTOCOL = TCP)(HOST = standby)(PORT = 1521))    )    (CONNECT_DATA =      (SERVICE_NAME = standby)    )  )[oracle@standby admin]$ [oracle@standby admin]$ lsnrctl startLSNRCTL for Linux: Version 10.2.0.5.0 - Production on 26-DEC-2012 14:02:11Copyright (c) 1991, 2010, Oracle.  All rights reserved.Starting /u01/app/oracle/product/10.2.0/db_1/bin/tnslsnr: please wait...TNSLSNR for Linux: Version 10.2.0.5.0 - ProductionSystem parameter file is /u01/app/oracle/product/10.2.0/db_1/network/admin/listener.oraLog messages written to /u01/app/oracle/product/10.2.0/db_1/network/log/listener.logListening on: (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=standby)(PORT=1521)))Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=standby)(PORT=1521)))STATUS of the LISTENER------------------------Alias                     LISTENERVersion                   TNSLSNR for Linux: Version 10.2.0.5.0 - ProductionStart Date                26-DEC-2012 14:02:11Uptime                    0 days 0 hr. 0 min. 0 secTrace Level               offSecurity                  ON: Local OS AuthenticationSNMP                      OFFListener Parameter File   /u01/app/oracle/product/10.2.0/db_1/network/admin/listener.oraListener Log File         /u01/app/oracle/product/10.2.0/db_1/network/log/listener.logListening Endpoints Summary...  (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=standby)(PORT=1521)))Services Summary...Service \"standby\" has 1 instance(s).  Instance \"standby\", status UNKNOWN, has 1 handler(s) for this service...The command completed successfully 配置ASM存储,这里使用Linux的UDEV [root@standby ~]# cat /etc/udev/rules.d/99-oracle-asmdevices.rules KERNEL==\"sd*\", BUS==\"scsi\", PROGRAM==\"/sbin/scsi_id -g -u -s %p\", RESULT==\"36000c29188bfef12f9950965ac870971\", NAME=\"asm-diskb\", OWNER=\"oracle\", GROUP=\"oinstall\", MODE=\"0660\"KERNEL==\"sd*\", BUS==\"scsi\", PROGRAM==\"/sbin/scsi_id -g -u -s %p\", RESULT==\"36000c292f3719ad39d579ab6427a959c\", NAME=\"asm-diskc\", OWNER=\"oracle\", GROUP=\"oinstall\", MODE=\"0660\"[root@standby ~]# start_udev Starting udev:                                             [  OK  ][root@standby ~]# ls -l /dev/asm-disk*brw-rw---- 1 oracle oinstall 8, 16 Dec 26 14:24 /dev/asm-diskbbrw-rw---- 1 oracle oinstall 8, 32 Dec 26 14:24 /dev/asm-diskc[root@standby ~]# 使用dbca创建ASM实例 使用root用户执行 /u01/app/oracle/product/10.2.0/db_1/bin/localconfig add [root@standby ~]# /u01/app/oracle/product/10.2.0/db_1/bin/localconfig add/etc/oracle does not exist. Creating it now.Successfully accumulated necessary OCR keys.Creating OCR keys for user 'root', privgrp 'root'..Operation successful.Configuration for local CSS has been initializedAdding to inittab Startup will be queued to init within 30 seconds.Checking the status of new Oracle init process...Expecting the CRS daemons to be up within 600 seconds.CSS is active on these nodes.\tstandbyCSS is active on all nodes.Oracle CSS service is installed and running under init(1M) [root@standby ~]# ps -ef|grep ASMoracle    6505     1  0 14:32 ?        00:00:00 asm_pmon_+ASMoracle    6507     1  0 14:32 ?        00:00:00 asm_psp0_+ASMoracle    6509     1  0 14:32 ?        00:00:00 asm_mman_+ASMoracle    6511     1  0 14:32 ?        00:00:00 asm_dbw0_+ASMoracle    6513     1  0 14:32 ?        00:00:00 asm_lgwr_+ASMoracle    6515     1  0 14:32 ?        00:00:00 asm_ckpt_+ASMoracle    6517     1  0 14:32 ?        00:00:00 asm_smon_+ASMoracle    6519     1  0 14:32 ?        00:00:00 asm_rbal_+ASMoracle    6521     1  0 14:32 ?        00:00:00 asm_gmon_+ASMoracle    6525     1  0 14:32 ?        00:00:00 oracle+ASM (DESCRIPTION=(LOCAL=YES)(ADDRESS=(PROTOCOL=beq)))root      6535  3686  0 14:33 pts/3    00:00:00 grep ASM 访问ASM实例 [oracle@standby ~]$ export ORACLE_SID=+ASM[oracle@standby ~]$ sqlplus / as sysdbaSQL*Plus: Release 10.2.0.5.0 - Production on Wed Dec 26 14:37:19 2012Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.Connected to:Oracle Database 10g Enterprise Edition Release 10.2.0.5.0 - 64bit ProductionWith the Partitioning, OLAP, Data Mining and Real Application Testing optionsSQL> show parameter asmNAME\t\t\t\t     TYPE------------------------------------ ----------------------VALUE------------------------------asm_diskgroups\t\t\t     stringDATADGasm_diskstring\t\t\t     string/dev/asm*asm_power_limit \t\t     integer1SQL> show parameter spfileNAME\t\t\t\t     TYPE------------------------------------ ----------------------VALUE------------------------------spfile\t\t\t\t     string/u01/app/oracle/product/10.2.0/db_1/dbs/spfile+ASM.oraSQL> select path from v$asm_disk;PATH--------------------------------------------------------------------------------/dev/asm-diskb/dev/asm-diskcSQL> 配置主库本地归档路径 SQL> alter system set log_archive_dest_1='location=/u01/app/oracle/arch valid_for=(all_logfiles,all_roles) db_unique_name=racdb' sid='racdb1';System altered.SQL> alter system set log_archive_dest_1='location=/u01/app/oracle/arch valid_for=(all_logfiles,all_roles) db_unique_name=racdb' sid='racdb2';System altered.SQL> alter system set log_archive_dest_1='location=/u01/app/oracle/arch valid_for=(all_logfiles,all_roles) db_unique_name=racdb' sid='racdb3';System altered. 执行主库全备份,控制文件备份,将备份文件scp到standby的/u01/app/oracle/backup下 [oracle@racnode1 ~]$ rman target /Recovery Manager: Release 10.2.0.5.0 - Production on Wed Dec 26 14:50:02 2012Copyright (c) 1982, 2007, Oracle.  All rights reserved.connected to target database: RACDB (DBID=800157471)RMAN> run{2> configure channel 1 device type disk connect sys/oracle@racdb1;3> configure channel 2 device type disk connect sys/oracle@racdb2;4> configure channel 3 device type disk connect sys/oracle@racdb3;5> backup database format '/u01/app/oracle/backup/%d_FULLBAK_%T_%u_s%s_p%p' tag 'FULLBAK'6> plus archivelog;7> }using target database control file instead of recovery catalogold RMAN configuration parameters:CONFIGURE CHANNEL 1 DEVICE TYPE DISK CONNECT '*';new RMAN configuration parameters:CONFIGURE CHANNEL 1 DEVICE TYPE DISK CONNECT '*';new RMAN configuration parameters are successfully storedold RMAN configuration parameters:CONFIGURE CHANNEL 2 DEVICE TYPE DISK CONNECT '*';new RMAN configuration parameters:CONFIGURE CHANNEL 2 DEVICE TYPE DISK CONNECT '*';new RMAN configuration parameters are successfully storedold RMAN configuration parameters:CONFIGURE CHANNEL 3 DEVICE TYPE DISK CONNECT '*';new RMAN configuration parameters:CONFIGURE CHANNEL 3 DEVICE TYPE DISK CONNECT '*';new RMAN configuration parameters are successfully storedStarting backup at 26-DEC-2012 14:50:36current log archivedallocated channel: ORA_DISK_1channel ORA_DISK_1: sid=843 instance=racdb1 devtype=DISKallocated channel: ORA_DISK_2channel ORA_DISK_2: sid=848 instance=racdb2 devtype=DISKallocated channel: ORA_DISK_3channel ORA_DISK_3: sid=844 instance=racdb3 devtype=DISKchannel ORA_DISK_1: starting archive log backupsetchannel ORA_DISK_1: specifying archive log(s) in backup setinput archive log thread=1 sequence=23 recid=45 stamp=803055040channel ORA_DISK_1: starting piece 1 at 26-DEC-2012 14:50:50channel ORA_DISK_2: starting archive log backupsetchannel ORA_DISK_2: specifying archive log(s) in backup setinput archive log thread=2 sequence=14 recid=44 stamp=803055040channel ORA_DISK_2: starting piece 1 at 26-DEC-2012 14:50:51channel ORA_DISK_3: starting archive log backupsetchannel ORA_DISK_3: specifying archive log(s) in backup setinput archive log thread=3 sequence=7 recid=43 stamp=803055038channel ORA_DISK_3: starting piece 1 at 26-DEC-2012 14:50:51channel ORA_DISK_1: finished piece 1 at 26-DEC-2012 14:50:54piece handle=+FLASHDG/racdb/backupset/2012_12_26/annnf0_tag20121226t145048_0.283.803055051 tag=TAG20121226T145048 comment=NONEchannel ORA_DISK_1: backup set complete, elapsed time: 00:00:05channel ORA_DISK_2: finished piece 1 at 26-DEC-2012 14:50:54piece handle=+FLASHDG/racdb/backupset/2012_12_26/annnf0_tag20121226t145048_0.278.803055051 tag=TAG20121226T145048 comment=NONEchannel ORA_DISK_2: backup set complete, elapsed time: 00:00:05channel ORA_DISK_3: finished piece 1 at 26-DEC-2012 14:50:54piece handle=+FLASHDG/racdb/backupset/2012_12_26/annnf0_tag20121226t145048_0.277.803055051 tag=TAG20121226T145048 comment=NONEchannel ORA_DISK_3: backup set complete, elapsed time: 00:00:05Finished backup at 26-DEC-2012 14:50:54Starting backup at 26-DEC-2012 14:50:54using channel ORA_DISK_1using channel ORA_DISK_2using channel ORA_DISK_3channel ORA_DISK_1: starting full datafile backupsetchannel ORA_DISK_1: specifying datafile(s) in backupsetinput datafile fno=00001 name=+DATADG/racdb/datafile/system.269.802972261channel ORA_DISK_1: starting piece 1 at 26-DEC-2012 14:50:55channel ORA_DISK_2: starting full datafile backupsetchannel ORA_DISK_2: specifying datafile(s) in backupsetinput datafile fno=00003 name=+DATADG/racdb/datafile/sysaux.265.802972263input datafile fno=00006 name=+DATADG/racdb/datafile/undotbs2.259.802972265input datafile fno=00004 name=+DATADG/racdb/datafile/users.257.802972267channel ORA_DISK_2: starting piece 1 at 26-DEC-2012 14:50:56channel ORA_DISK_3: starting full datafile backupsetchannel ORA_DISK_3: specifying datafile(s) in backupsetinput datafile fno=00005 name=+DATADG/racdb/datafile/example.258.802972265input datafile fno=00002 name=+DATADG/racdb/datafile/undotbs1.256.802972267input datafile fno=00007 name=+DATADG/racdb/datafile/undotbs3.264.802972269channel ORA_DISK_3: starting piece 1 at 26-DEC-2012 14:51:05channel ORA_DISK_1: finished piece 1 at 26-DEC-2012 14:51:36piece handle=/u01/app/oracle/backup/RACDB_FULLBAK_20121226_0kntr9ef_s20_p1 tag=FULLBAK comment=NONEchannel ORA_DISK_1: backup set complete, elapsed time: 00:00:41channel ORA_DISK_2: finished piece 1 at 26-DEC-2012 14:51:44piece handle=/u01/app/oracle/backup/RACDB_FULLBAK_20121226_0lntr9ef_s21_p1 tag=FULLBAK comment=NONEchannel ORA_DISK_2: backup set complete, elapsed time: 00:00:49channel ORA_DISK_3: finished piece 1 at 26-DEC-2012 14:51:44piece handle=/u01/app/oracle/backup/RACDB_FULLBAK_20121226_0mntr9eg_s22_p1 tag=FULLBAK comment=NONEchannel ORA_DISK_3: backup set complete, elapsed time: 00:00:48Finished backup at 26-DEC-2012 14:51:43Starting backup at 26-DEC-2012 14:51:44current log archivedusing channel ORA_DISK_1using channel ORA_DISK_2using channel ORA_DISK_3channel ORA_DISK_1: starting archive log backupsetchannel ORA_DISK_1: specifying archive log(s) in backup setinput archive log thread=1 sequence=24 recid=47 stamp=803055105channel ORA_DISK_1: starting piece 1 at 26-DEC-2012 14:51:49channel ORA_DISK_3: starting archive log backupsetchannel ORA_DISK_3: specifying archive log(s) in backup setinput archive log thread=3 sequence=8 recid=48 stamp=803055106channel ORA_DISK_3: starting piece 1 at 26-DEC-2012 14:51:50channel ORA_DISK_1: finished piece 1 at 26-DEC-2012 14:51:50piece handle=+FLASHDG/racdb/backupset/2012_12_26/annnf0_tag20121226t145149_0.275.803055109 tag=TAG20121226T145149 comment=NONEchannel ORA_DISK_1: backup set complete, elapsed time: 00:00:01channel ORA_DISK_3: finished piece 1 at 26-DEC-2012 14:51:51piece handle=+FLASHDG/racdb/backupset/2012_12_26/annnf0_tag20121226t145149_0.273.803055111 tag=TAG20121226T145149 comment=NONEchannel ORA_DISK_3: backup set complete, elapsed time: 00:00:01channel ORA_DISK_1: starting archive log backupsetchannel ORA_DISK_1: specifying archive log(s) in backup setinput archive log thread=2 sequence=15 recid=46 stamp=803055105channel ORA_DISK_1: starting piece 1 at 26-DEC-2012 14:51:52channel ORA_DISK_1: finished piece 1 at 26-DEC-2012 14:51:53piece handle=+FLASHDG/racdb/backupset/2012_12_26/annnf0_tag20121226t145149_0.272.803055113 tag=TAG20121226T145149 comment=NONEchannel ORA_DISK_1: backup set complete, elapsed time: 00:00:02Finished backup at 26-DEC-2012 14:51:53Starting Control File and SPFILE Autobackup at 26-DEC-2012 14:51:53piece handle=/u01/app/oracle/backup/c-800157471-20121226-00 comment=NONEFinished Control File and SPFILE Autobackup at 26-DEC-2012 14:52:00RMAN> RMAN> backup device type disk format '/u01/app/oracle/backup/standby_ctl_%U' current controlfile for standby;Starting backup at 26-DEC-2012 15:48:17using target database control file instead of recovery catalogallocated channel: ORA_DISK_1channel ORA_DISK_1: sid=848 instance=racdb1 devtype=DISKallocated channel: ORA_DISK_2channel ORA_DISK_2: sid=845 instance=racdb2 devtype=DISKallocated channel: ORA_DISK_3channel ORA_DISK_3: sid=847 instance=racdb3 devtype=DISKchannel ORA_DISK_1: starting full datafile backupsetchannel ORA_DISK_1: specifying datafile(s) in backupsetincluding standby control file in backupsetchannel ORA_DISK_1: starting piece 1 at 26-DEC-2012 15:48:21channel ORA_DISK_1: finished piece 1 at 26-DEC-2012 15:48:24piece handle=/u01/app/oracle/backup/standby_ctl_0rntrcq3_1_1 tag=TAG20121226T154819 comment=NONEchannel ORA_DISK_1: backup set complete, elapsed time: 00:00:05Finished backup at 26-DEC-2012 15:48:24 创建备库口令文件,也可以拷贝rac1的口令文件rename下 [oracle@standby ~]$ orapwd file=$ORACLE_HOME/dbs/orapwstandby entries=5 force=y password=oracle 配置主备库各实例的tnsnames,内容大致一样,从库中去掉LISTENERS_RACDB配置项 [oracle@standby ~]$ cat $ORACLE_HOME/network/admin/tnsnames.ora# tnsnames.ora Network Configuration File: /u01/app/oracle/product/10.2.0/db_1/network/admin/tnsnames.ora# Generated by Oracle configuration tools.RACDB1 =  (DESCRIPTION =    (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.1.151)(PORT = 1521))    (CONNECT_DATA =      (SERVER = DEDICATED)      (SERVICE_NAME = racdb)      (INSTANCE_NAME = racdb1)    )  )RACDB =  (DESCRIPTION =    (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.1.151)(PORT = 1521))    (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.1.152)(PORT = 1521))    (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.1.153)(PORT = 1521))    (LOAD_BALANCE = yes)    (CONNECT_DATA =      (SERVER = DEDICATED)      (SERVICE_NAME = racdb)    )  )ZWC =  (DESCRIPTION =    (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.1.151)(PORT = 1521))    (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.1.152)(PORT = 1521))    (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.1.153)(PORT = 1521))    (LOAD_BALANCE = yes)    (CONNECT_DATA =      (SERVER = DEDICATED)      (SERVICE_NAME = zwc)      (FAILOVER_MODE =        (TYPE = SELECT)        (METHOD = BASIC)        (RETRIES = 180)        (DELAY = 5)      )    )  )RACDB3 =  (DESCRIPTION =    (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.1.153)(PORT = 1521))    (CONNECT_DATA =      (SERVER = DEDICATED)      (SERVICE_NAME = racdb)      (INSTANCE_NAME = racdb3)    )  )RACDB2 =  (DESCRIPTION =    (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.1.152)(PORT = 1521))    (CONNECT_DATA =      (SERVER = DEDICATED)      (SERVICE_NAME = racdb)      (INSTANCE_NAME = racdb2)    )  )STANDBY =  (DESCRIPTION =    (ADDRESS_LIST =      (ADDRESS = (PROTOCOL = TCP)(HOST = standby)(PORT = 1521))    )    (CONNECT_DATA =      (SERVICE_NAME = standby)    )  ) 测试从库访问主库 [oracle@standby ~]$ sqlplus /nologSQL*Plus: Release 10.2.0.5.0 - Production on Wed Dec 26 15:17:31 2012Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.SQL> conn sys@racdb as sysdbaEnter password: Connected.SQL> conn sys@racdb1 as sysdbaEnter password: Connected.SQL> conn sys@racdb2 as sysdbaEnter password: Connected.SQL> conn sys@racdb3 as sysdbaEnter password: Connected.SQL> conn sys@zwc as sysdbaEnter password: Connected.SQL> Disconnected from Oracle Database 10g Enterprise Edition Release 10.2.0.5.0 - 64bit ProductionWith the Partitioning, Real Application Clusters, OLAP, Data Miningand Real Application Testing options[oracle@standby ~]$ 从主库创建备库的pfile create pfile='/u01/app/oracle/backup/initstandby.ora' from spfile; 修改参数文件 [oracle@standby backup]$ mkdir -p /u01/app/oracle/admin/standby/udump[oracle@standby backup]$ mkdir -p /u01/app/oracle/admin/standby/cdump[oracle@standby backup]$ mkdir -p /u01/app/oracle/admin/standby/bdump[oracle@standby backup]$ mkdir -p /u01/app/oracle/admin/standby/adump[oracle@standby backup]$ export ORACLE_SID=+ASM[oracle@standby backup]$ sqlplus / as sysdbaSQL*Plus: Release 10.2.0.5.0 - Production on Wed Dec 26 15:41:41 2012Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.Connected to:Oracle Database 10g Enterprise Edition Release 10.2.0.5.0 - 64bit ProductionWith the Partitioning, OLAP, Data Mining and Real Application Testing optionsSQL> alter diskgroup datadg add directory '+DATADG/standby';Diskgroup altered. [oracle@standby dbs]$ cat initstandby.ora *.audit_file_dest='/u01/app/oracle/admin/standby/adump'*.background_dump_dest='/u01/app/oracle/admin/standby/bdump'*.cluster_database=false*.compatible='10.2.0.5.0'*.control_files='+DATADG/standby/controlfile'*.core_dump_dest='/u01/app/oracle/admin/standby/cdump'*.db_block_size=8192*.db_create_file_dest='+DATADG'*.db_domain=''*.db_file_multiblock_read_count=16*.db_name='racdb'*.db_unique_name='standby'*.job_queue_processes=10*.local_listener=''*.log_archive_format='%t_%s_%r.dbf'*.nls_language='SIMPLIFIED CHINESE'*.open_cursors=300*.pga_aggregate_target=199229440*.processes=800*.remote_login_passwordfile='exclusive'*.sessions=885*.sga_target=597688320*.undo_management='AUTO'*.user_dump_dest='/u01/app/oracle/admin/standby/udump'*.log_archive_config='dg_config=(racdb,standby)'*.log_archive_dest_1='location=/u01/app/oracle/arch valid_for=(all_logfiles,all_roles) db_unique_name=standby'*.log_archive_dest_2='service=racdb1 lgwr sync valid_for=(online_logfiles,primary_roles) db_unique_name=racdb'*.log_archive_dest_state_1='enable'*.log_archive_dest_state_2='enable'*.thread=1*.undo_tablespace='UNDOTBS1'*.standby_file_management='AUTO'*.fal_server='racdb1','racdb2'*.fal_client='standby'*.service_names='standby'*.db_file_name_convert='+DATADG/racdb/','+DATADG/standby/'*.log_file_name_convert='+DATADG/racdb/','+DATADG/standby/','+FLASHDG/racdb/','+DATADG/standby/'[oracle@standby dbs]$ 启动备库到nomount,恢复备库 restore controlfile [oracle@standby dbs]$ sqlplus / as sysdbaSQL*Plus: Release 10.2.0.5.0 - Production on Wed Dec 26 15:53:19 2012Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.Connected to an idle instance.SQL> startup nomountORACLE instance started.Total System Global Area  599785472 bytesFixed Size\t\t    2098112 bytesVariable Size\t\t  163580992 bytesDatabase Buffers\t  427819008 bytesRedo Buffers\t\t    6287360 bytesSQL> exitDisconnected from Oracle Database 10g Enterprise Edition Release 10.2.0.5.0 - 64bit ProductionWith the Partitioning, OLAP, Data Mining and Real Application Testing options[oracle@standby dbs]$ rman target /Recovery Manager: Release 10.2.0.5.0 - Production on Wed Dec 26 15:53:26 2012Copyright (c) 1982, 2007, Oracle.  All rights reserved.connected to target database: racdb (not mounted)RMAN> restore standby controlfile from '/u01/app/oracle/backup/standby_ctl_0rntrcq3_1_1';Starting restore at 26-DEC-2012 15:53:30using target database control file instead of recovery catalogallocated channel: ORA_DISK_1channel ORA_DISK_1: sid=871 devtype=DISKchannel ORA_DISK_1: restoring control filechannel ORA_DISK_1: restore complete, elapsed time: 00:00:08output filename=+DATADG/standby/controlfile/standby_ctlFinished restore at 26-DEC-2012 15:53:40 restore standby database RMAN> alter database mount;database mountedreleased channel: ORA_DISK_1RMAN> run{2> allocate channel c1 device type disk;3> allocate channel c2 device type disk;4> restore database;5> release channel c1;6> release channel c2;7> }allocated channel: c1channel c1: sid=871 devtype=DISKallocated channel: c2channel c2: sid=870 devtype=DISKStarting restore at 26-DEC-2012 15:59:06channel c1: starting datafile backupset restorechannel c1: specifying datafile(s) to restore from backup setrestoring datafile 00001 to +DATADG/standby/datafile/system.269.802972261channel c1: reading from backup piece /u01/app/oracle/backup/RACDB_FULLBAK_20121226_0kntr9ef_s20_p1channel c2: starting datafile backupset restorechannel c2: specifying datafile(s) to restore from backup setrestoring datafile 00002 to +DATADG/standby/datafile/undotbs1.256.802972267restoring datafile 00005 to +DATADG/standby/datafile/example.258.802972265restoring datafile 00007 to +DATADG/standby/datafile/undotbs3.264.802972269channel c2: reading from backup piece /u01/app/oracle/backup/RACDB_FULLBAK_20121226_0mntr9eg_s22_p1channel c2: restored backup piece 1piece handle=/u01/app/oracle/backup/RACDB_FULLBAK_20121226_0mntr9eg_s22_p1 tag=FULLBAKchannel c2: restore complete, elapsed time: 00:00:15channel c2: starting datafile backupset restorechannel c2: specifying datafile(s) to restore from backup setrestoring datafile 00003 to +DATADG/standby/datafile/sysaux.265.802972263restoring datafile 00004 to +DATADG/standby/datafile/users.257.802972267restoring datafile 00006 to +DATADG/standby/datafile/undotbs2.259.802972265channel c2: reading from backup piece /u01/app/oracle/backup/RACDB_FULLBAK_20121226_0lntr9ef_s21_p1channel c1: restored backup piece 1piece handle=/u01/app/oracle/backup/RACDB_FULLBAK_20121226_0kntr9ef_s20_p1 tag=FULLBAKchannel c1: restore complete, elapsed time: 00:00:23channel c2: restored backup piece 1piece handle=/u01/app/oracle/backup/RACDB_FULLBAK_20121226_0lntr9ef_s21_p1 tag=FULLBAKchannel c2: restore complete, elapsed time: 00:00:23Finished restore at 26-DEC-2012 15:59:45released channel: c1released channel: c2 [oracle@standby ~]$ sqlplus / as sysdbaSQL*Plus: Release 10.2.0.5.0 - Production on Wed Dec 26 16:04:46 2012Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.Connected to:Oracle Database 10g Enterprise Edition Release 10.2.0.5.0 - 64bit ProductionWith the Partitioning, OLAP, Data Mining and Real Application Testing optionsSQL> set linesize 200SQL> select dbid,name,switchover_status,db_unique_name,database_role,open_mode,current_scn from v$database;      DBID NAME      SWITCHOVER_STATUS\t  DB_UNIQUE_NAME\t\t DATABASE_ROLE\t  OPEN_MODE  CURRENT_SCN---------- --------- -------------------- ------------------------------ ---------------- ---------- ----------- 800157471 RACDB     SESSIONS ACTIVE\t  standby\t\t\t PHYSICAL STANDBY MOUNTED\t 1044439 创建备库standby logfile SQL> select * from v$log;    GROUP#    THREAD#  SEQUENCE#      BYTES    MEMBERS ARC STATUS\t    FIRST_CHANGE# FIRST_TIME---------- ---------- ---------- ---------- ---------- --- ---------------- ------------- -----------------------\t 1\t    1\t      25   52428800\t     2 NO  CURRENT\t\t  1039974 26-DEC-2012 14:51:44\t 2\t    1\t      24   52428800\t     2 YES INACTIVE\t\t  1039911 26-DEC-2012 14:50:38\t 3\t    2\t      15   52428800\t     2 YES INACTIVE\t\t  1039909 26-DEC-2012 14:50:38\t 4\t    2\t      16   52428800\t     2 NO  CURRENT\t\t  1039976 26-DEC-2012 14:51:44\t 5\t    3\t       9   52428800\t     2 NO  CURRENT\t\t  1039979 26-DEC-2012 14:51:46\t 6\t    3\t       8   52428800\t     2 YES INACTIVE\t\t  1039906 26-DEC-2012 14:50:386 rows selected.SQL> select * from v$logfile;    GROUP# STATUS  TYPE    MEMBER\t\t\t\t\t\t     IS_---------- ------- ------- --------------------------------------------------------- ---\t 2\t   ONLINE  +DATADG/standby/onlinelog/group_2.262.802540719\t     NO\t 2\t   ONLINE  +DATADG/standby/onlinelog/group_2.258.802540725\t     YES\t 1\t   ONLINE  +DATADG/standby/onlinelog/group_1.261.802540709\t     NO\t 1\t   ONLINE  +DATADG/standby/onlinelog/group_1.257.802540715\t     YES\t 3\t   ONLINE  +DATADG/standby/onlinelog/group_3.266.802541097\t     NO\t 3\t   ONLINE  +DATADG/standby/onlinelog/group_3.259.802541105\t     YES\t 4\t   ONLINE  +DATADG/standby/onlinelog/group_4.267.802541113\t     NO\t 4\t   ONLINE  +DATADG/standby/onlinelog/group_4.260.802541123\t     YES\t 5\t   ONLINE  +DATADG/standby/onlinelog/group_5.270.802888327\t     NO\t 5\t   ONLINE  +DATADG/standby/onlinelog/group_5.279.802888333\t     YES\t 6\t   ONLINE  +DATADG/standby/onlinelog/group_6.271.802888337\t     NO\t 6\t   ONLINE  +DATADG/standby/onlinelog/group_6.280.802888343\t     YES12 rows selected. SQL> alter database add standby logfile thread 1 group 11 size 50M,group 12 size 50M,group 13 size 50M;Database altered.SQL> alter database add standby logfile thread 2 group 14 size 50M,group 15 size 50M,group 16 size 50M;Database altered.SQL> alter database add standby logfile thread 3 group 17 size 50M,group 18 size 50M,group 19 size 50M;Database altered. SQL> select * from v$standby_log;    GROUP# DBID \t\t\t\t       THREAD#\tSEQUENCE#      BYTES\t   USED ARC STATUS     FIRST_CHANGE# FIRST_TIME \t     LAST_CHANGE# LAST_TIME---------- ---------------------------------------- ---------- ---------- ---------- ---------- --- ---------- ------------- ----------------------- ------------ -----------------------\t11 UNASSIGNED\t\t\t\t\t     1\t\t0   52428800\t    512 YES UNASSIGNED\t\t   0\t\t\t\t\t0\t12 UNASSIGNED\t\t\t\t\t     1\t\t0   52428800\t    512 YES UNASSIGNED\t\t   0\t\t\t\t\t0\t13 UNASSIGNED\t\t\t\t\t     1\t\t0   52428800\t    512 YES UNASSIGNED\t\t   0\t\t\t\t\t0\t14 UNASSIGNED\t\t\t\t\t     2\t\t0   52428800\t    512 YES UNASSIGNED\t\t   0\t\t\t\t\t0\t15 UNASSIGNED\t\t\t\t\t     2\t\t0   52428800\t    512 YES UNASSIGNED\t\t   0\t\t\t\t\t0\t16 UNASSIGNED\t\t\t\t\t     2\t\t0   52428800\t    512 YES UNASSIGNED\t\t   0\t\t\t\t\t0\t17 UNASSIGNED\t\t\t\t\t     3\t\t0   52428800\t    512 YES UNASSIGNED\t\t   0\t\t\t\t\t0\t18 UNASSIGNED\t\t\t\t\t     3\t\t0   52428800\t    512 YES UNASSIGNED\t\t   0\t\t\t\t\t0\t19 UNASSIGNED\t\t\t\t\t     3\t\t0   52428800\t    512 YES UNASSIGNED\t\t   0\t\t\t\t\t09 rows selected. 备库开启redo apply [oracle@standby ~]$ sqlplus / as sysdbaSQL*Plus: Release 10.2.0.5.0 - Production on Wed Dec 26 16:14:59 2012Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.Connected to:Oracle Database 10g Enterprise Edition Release 10.2.0.5.0 - 64bit ProductionWith the Partitioning, OLAP, Data Mining and Real Application Testing optionsSQL> alter database recover managed standby database using current logfile disconnect from session;Database altered.SQL> select sequence#,name,first_time,next_time,applied from v$archived_log;no rows selectedSQL> select dbid,name,switchover_status,db_unique_name,database_role,open_mode,current_scn from v$database;      DBID NAME      SWITCHOVER_STATUS\t  DB_UNIQUE_NAME\t\t DATABASE_ROLE\t  OPEN_MODE  CURRENT_SCN---------- --------- -------------------- ------------------------------ ---------------- ---------- ----------- 800157471 RACDB     SESSIONS ACTIVE\t  standby\t\t\t PHYSICAL STANDBY MOUNTED\t 1044439 SQL> create spfile from pfile;File created. 观察备库的alter.log,发现正在等待rac1 sequence为24的archivelog [oracle@standby ~]$ tail -f /u01/app/oracle/admin/standby/bdump/alert_standby.log ORA-00312: 联机日志 6 线程 3: '+DATADG/standby/onlinelog/group_6.280.802888343'ORA-17503: ksfdopn: 2 未能打开文件 +DATADG/standby/onlinelog/group_6.280.802888343ORA-15173: entry 'group_6.280.802888343' does not exist in directory 'onlinelog'ORA-00312: 联机日志 6 线程 3: '+DATADG/standby/onlinelog/group_6.271.802888337'ORA-17503: ksfdopn: 2 未能打开文件 +DATADG/standby/onlinelog/group_6.271.802888337ORA-15173: entry 'group_6.271.802888337' does not exist in directory 'onlinelog'Deleted Oracle managed file +DATADG/standby/onlinelog/group_6.271.802888337Deleted Oracle managed file +DATADG/standby/onlinelog/group_6.280.802888343Clearing online redo logfile 6 completeMedia Recovery Waiting for thread 1 sequence 24 配置主库参数 SQL> alter system set log_archive_dest_2='service=standby lgwr sync valid_for=(online_logfiles,primary_role) db_unique_name=standby' sid='*';System altered.SQL> alter system set log_archive_dest_state_2='enable';System altered.SQL> alter system set log_archive_config='dg_config=(racdb,standby)' sid='*';System altered.SQL> alter system set fal_server='standby' sid='*';System altered.SQL> alter system set fal_client='racdb1' sid='*';System altered.SQL> alter system set fal_client='racdb1' sid='racdb1';System altered.SQL> alter system set fal_client='racdb2' sid='racdb2';System altered.SQL> alter system set fal_client='racdb3' sid='racdb3';System altered. SQL> alter system set standby_file_management=AUTO;System altered. 在主库多次切换日志,发现都没有传输到备库,查看主库alert.log发现如下信息 ORA-16047: 目标设置和备用之间的 DGID 不匹配 Wed Dec 26 16:33:36 CST 2012 PING[ARC1]: Heartbeat failed to connect to standby 'standby'. Error is 16047. Wed Dec 26 16:35:12 CST 2012 看意思是指log_archive_config参数不对,我检查了主备库的这个参数,发现是没有问题的 我记得在配置single dataguard的时候db_unique_name默认等于db_name,故这里没有在主库配置db_unique_name这个参数。问题就是出在这里 在主库配置db_unique_name参数重启RAC实例 SQL> alter system set db_unique_name='racdb' scope=spfile;System altered.SQL> exitDisconnected from Oracle Database 10g Enterprise Edition Release 10.2.0.5.0 - 64bit ProductionWith the Partitioning, Real Application Clusters, OLAP, Data Miningand Real Application Testing options[oracle@racnode1 backup]$ srvctl stop database -d racdb[oracle@racnode1 backup]$ srvctl start database -d racdb[oracle@racnode1 backup]$ srvctl start service -d racdb -s zwc 主库 SQL> show parameter log_archive_configNAME\t\t\t\t     TYPE\t VALUE------------------------------------ ----------- ------------------------------log_archive_config\t\t     string\t dg_config=(racdb,standby)SQL> show parameter db_unique_nameNAME\t\t\t\t     TYPE\t VALUE------------------------------------ ----------- ------------------------------db_unique_name\t\t\t     string\t racdbSQL> 备库 SQL> show parameter log_archive_configNAME\t\t\t\t     TYPE\t VALUE------------------------------------ ----------- ------------------------------log_archive_config\t\t     string\t dg_config=(racdb,standby)SQL> show parameter db_unique_nameNAME\t\t\t\t     TYPE\t VALUE------------------------------------ ----------- ------------------------------db_unique_name\t\t\t     string\t standby 主库的alert.log SUCCESS: diskgroup DATADG was mountedSUCCESS: diskgroup FLASHDG was mountedThu Dec 27 08:57:15 CST 2012Setting recovery target incarnation to 2Thu Dec 27 08:57:15 CST 2012Successful mount of redo thread 1, with mount id 800695506Thu Dec 27 08:57:15 CST 2012Database mounted in Shared Mode (CLUSTER_DATABASE=TRUE)Completed: ALTER DATABASE   MOUNTThu Dec 27 08:57:21 CST 2012ALTER DATABASE OPENPicked broadcast on commit scheme to generate SCNsThu Dec 27 08:57:21 CST 2012LGWR: STARTING ARCH PROCESSESARC0 started with pid=24, OS id=4436Thu Dec 27 08:57:21 CST 2012ARC0: Archival startedARC1: Archival startedLGWR: STARTING ARCH PROCESSES COMPLETEARC1 started with pid=25, OS id=4438LNSb started with pid=26, OS id=4440Thu Dec 27 08:57:28 CST 2012******************************************************************LGWR: Setting 'active' archival for destination LOG_ARCHIVE_DEST_2******************************************************************LNSb started with pid=26, OS id=4477Thu Dec 27 08:57:32 CST 2012LGWR: Standby redo logfile selected for thread 1 sequence 38 for destination LOG_ARCHIVE_DEST_2Thu Dec 27 08:57:32 CST 2012Thread 1 advanced to log sequence 38 (thread open)Thread 1 opened at log sequence 38  Current log# 2 seq# 38 mem# 0: +DATADG/racdb/onlinelog/group_2.262.802540719  Current log# 2 seq# 38 mem# 1: +FLASHDG/racdb/onlinelog/group_2.258.802540725Successful open of redo thread 1Thu Dec 27 08:57:32 CST 2012MTTR advisory is disabled because FAST_START_MTTR_TARGET is not setThu Dec 27 08:57:32 CST 2012SMON: enabling cache recoveryThu Dec 27 08:57:32 CST 2012ARC0: Becoming the 'no FAL' ARCHARC0: Becoming the 'no SRL' ARCHThu Dec 27 08:57:32 CST 2012ARC1: Becoming the heartbeat ARCHThu Dec 27 08:57:35 CST 2012Redo Shipping Client Connected as PUBLIC-- Connected User is ValidThu Dec 27 08:57:43 CST 2012Successfully onlined Undo Tablespace 1.Thu Dec 27 08:57:43 CST 2012SMON: enabling tx recoveryThu Dec 27 08:57:43 CST 2012Database Characterset is ZHS16GBKOpening with internal Resource Manager plan replication_dependency_tracking turned off (no async multimaster replication found)Starting background process QMNCQMNC started with pid=27, OS id=4663Thu Dec 27 08:58:05 CST 2012Completed: ALTER DATABASE OPENThu Dec 27 08:58:14 CST 2012ARC1: Standby redo logfile selected for thread 1 sequence 37 for destination LOG_ARCHIVE_DEST_2Thu Dec 27 08:58:18 CST 2012Redo Shipping Client Connected as PUBLIC-- Connected User is ValidRedo Shipping Client Connected as PUBLIC-- Connected User is ValidThu Dec 27 08:59:20 CST 2012ALTER SYSTEM SET service_names='zwc' SCOPE=MEMORY SID='racdb1';Thu Dec 27 09:07:14 CST 2012LGWR: Standby redo logfile selected for thread 1 sequence 39 for destination LOG_ARCHIVE_DEST_2Thu Dec 27 09:07:14 CST 2012Thread 1 advanced to log sequence 39 (LGWR switch)  Current log# 1 seq# 39 mem# 0: +DATADG/racdb/onlinelog/group_1.261.802540709  Current log# 1 seq# 39 mem# 1: +FLASHDG/racdb/onlinelog/group_1.257.802540715Thu Dec 27 09:07:51 CST 2012LGWR: Standby redo logfile selected for thread 1 sequence 40 for destination LOG_ARCHIVE_DEST_2Thu Dec 27 09:07:51 CST 2012Thread 1 advanced to log sequence 40 (LGWR switch)  Current log# 2 seq# 40 mem# 0: +DATADG/racdb/onlinelog/group_2.262.802540719  Current log# 2 seq# 40 mem# 1: +FLASHDG/racdb/onlinelog/group_2.258.802540725Thu Dec 27 09:08:10 CST 2012ALTER SYSTEM SET service_names='zwc','racdb' SCOPE=MEMORY SID='racdb1';Thu Dec 27 09:08:36 CST 2012Thread 1 cannot allocate new log, sequence 41Checkpoint not complete  Current log# 2 seq# 40 mem# 0: +DATADG/racdb/onlinelog/group_2.262.802540719  Current log# 2 seq# 40 mem# 1: +FLASHDG/racdb/onlinelog/group_2.258.802540725LGWR: Standby redo logfile selected for thread 1 sequence 41 for destination LOG_ARCHIVE_DEST_2Thu Dec 27 09:08:40 CST 2012Thread 1 advanced to log sequence 41 (LGWR switch)  Current log# 1 seq# 41 mem# 0: +DATADG/racdb/onlinelog/group_1.261.802540709  Current log# 1 seq# 41 mem# 1: +FLASHDG/racdb/onlinelog/group_1.257.802540715Thu Dec 27 09:12:24 CST 2012Thread 1 cannot allocate new log, sequence 42Checkpoint not complete  Current log# 1 seq# 41 mem# 0: +DATADG/racdb/onlinelog/group_1.261.802540709  Current log# 1 seq# 41 mem# 1: +FLASHDG/racdb/onlinelog/group_1.257.802540715LGWR: Standby redo logfile selected for thread 1 sequence 42 for destination LOG_ARCHIVE_DEST_2Thu Dec 27 09:12:28 CST 2012Thread 1 advanced to log sequence 42 (LGWR switch)  Current log# 2 seq# 42 mem# 0: +DATADG/racdb/onlinelog/group_2.262.802540719  Current log# 2 seq# 42 mem# 1: +FLASHDG/racdb/onlinelog/group_2.258.802540725Thu Dec 27 09:13:05 CST 2012LGWR: Standby redo logfile selected for thread 1 sequence 43 for destination LOG_ARCHIVE_DEST_2Thu Dec 27 09:13:05 CST 2012Thread 1 advanced to log sequence 43 (LGWR switch)  Current log# 1 seq# 43 mem# 0: +DATADG/racdb/onlinelog/group_1.261.802540709  Current log# 1 seq# 43 mem# 1: +FLASHDG/racdb/onlinelog/group_1.257.802540715 备库的alert.log ARC1: Thread not mountedThu Dec 27 08:48:50 CST 2012Successful mount of redo thread 1, with mount id 800697579Thu Dec 27 08:48:50 CST 2012Physical Standby Database mounted.Completed: alter database mount standby databaseThu Dec 27 08:49:09 CST 2012alter database recover managed standby database using current logfile disconnect from sessionThu Dec 27 08:49:09 CST 2012Attempt to start background Managed Standby Recovery process (standby)MRP0 started with pid=19, OS id=15411Thu Dec 27 08:49:09 CST 2012MRP0: Background Managed Standby Recovery process started (standby)Managed Standby Recovery starting Real Time Apply parallel recovery started with 2 processesThu Dec 27 08:49:14 CST 2012Waiting for all non-current ORLs to be archived...Media Recovery Waiting for thread 1 sequence 24Thu Dec 27 08:49:15 CST 2012Completed: alter database recover managed standby database using current logfile disconnect from sessionThu Dec 27 08:57:03 CST 2012Using STANDBY_ARCHIVE_DEST parameter default value as /u01/app/oracle/archRedo Shipping Client Connected as PUBLIC-- Connected User is ValidRFS[1]: Assigned to RFS process 15448RFS[1]: Identified database type as 'physical standby'Primary database is in MAXIMUM PERFORMANCE modePrimary thread 1 already marked as open; setting 'closed'Primary thread 2 already marked as open; setting 'closed'Primary thread 3 already marked as open; setting 'closed'Thu Dec 27 08:57:03 CST 2012RFS LogMiner: Client disabled from further notificationRedo Shipping Client Connected as PUBLIC-- Connected User is ValidRFS[2]: Assigned to RFS process 15450RFS[2]: Identified database type as 'physical standby'Primary database is in MAXIMUM PERFORMANCE modePrimary database is in MAXIMUM PERFORMANCE modeRFS[2]: Successfully opened standby log 17: '+DATADG/standby/onlinelog/group_17.270.803059869'Thu Dec 27 08:57:15 CST 2012Redo Shipping Client Connected as PUBLIC-- Connected User is ValidRFS[3]: Assigned to RFS process 15454RFS[3]: Identified database type as 'physical standby'RFS[3]: Successfully opened standby log 18: '+DATADG/standby/onlinelog/group_18.271.803059871'Thu Dec 27 08:57:24 CST 2012Redo Shipping Client Connected as PUBLIC-- Connected User is ValidRFS[4]: Assigned to RFS process 15456RFS[4]: Identified database type as 'physical standby'Primary database is in MAXIMUM PERFORMANCE modeRedo Shipping Client Connected as PUBLIC-- Connected User is ValidRFS[5]: Assigned to RFS process 15458RFS[5]: Identified database type as 'physical standby'Primary database is in MAXIMUM PERFORMANCE modePrimary database is in MAXIMUM PERFORMANCE modeRFS[5]: Successfully opened standby log 11: '+DATADG/standby/onlinelog/group_11.264.803059801'Thu Dec 27 08:57:35 CST 2012Fetching gap sequence in thread 1, gap sequence 24-36Thu Dec 27 08:57:35 CST 2012Redo Shipping Client Connected as PUBLIC-- Connected User is ValidRFS[6]: Assigned to RFS process 15460RFS[6]: Identified database type as 'physical standby'Primary database is in MAXIMUM PERFORMANCE modeRedo Shipping Client Connected as PUBLIC-- Connected User is ValidRFS[7]: Assigned to RFS process 15462RFS[7]: Identified database type as 'physical standby'Primary database is in MAXIMUM PERFORMANCE modePrimary database is in MAXIMUM PERFORMANCE modeRFS[7]: Successfully opened standby log 14: '+DATADG/standby/onlinelog/group_14.267.803059831'Thu Dec 27 08:57:47 CST 2012Redo Shipping Client Connected as PUBLIC-- Connected User is ValidRFS[8]: Assigned to RFS process 15464RFS[8]: Identified database type as 'physical standby'RFS[8]: Archived Log: '/u01/app/oracle/arch/1_24_802540708.dbf'RFS[8]: Archived Log: '/u01/app/oracle/arch/1_25_802540708.dbf'RFS[8]: Archived Log: '/u01/app/oracle/arch/1_26_802540708.dbf'RFS[8]: Archived Log: '/u01/app/oracle/arch/1_27_802540708.dbf'RFS[8]: Archived Log: '/u01/app/oracle/arch/1_28_802540708.dbf'RFS[8]: Archived Log: '/u01/app/oracle/arch/1_29_802540708.dbf'Thu Dec 27 08:57:59 CST 2012RFS[8]: Archived Log: '/u01/app/oracle/arch/1_30_802540708.dbf'RFS[8]: Archived Log: '/u01/app/oracle/arch/1_31_802540708.dbf'Thu Dec 27 08:58:06 CST 2012Redo Shipping Client Connected as PUBLIC-- Connected User is ValidRFS[9]: Assigned to RFS process 15468RFS[9]: Identified database type as 'physical standby'Thu Dec 27 08:58:06 CST 2012RFS[8]: Archived Log: '/u01/app/oracle/arch/1_32_802540708.dbf'Thu Dec 27 08:58:06 CST 2012RFS[9]: Successfully opened standby log 15: '+DATADG/standby/onlinelog/group_15.268.803059833'Thu Dec 27 08:58:07 CST 2012RFS[8]: Archived Log: '/u01/app/oracle/arch/1_33_802540708.dbf'RFS[8]: Archived Log: '/u01/app/oracle/arch/1_34_802540708.dbf'RFS[8]: Archived Log: '/u01/app/oracle/arch/1_35_802540708.dbf'RFS[8]: Archived Log: '/u01/app/oracle/arch/1_36_802540708.dbf'RFS[8]: Successfully opened standby log 12: '+DATADG/standby/onlinelog/group_12.265.803059803'Thu Dec 27 08:58:18 CST 2012Media Recovery Log /u01/app/oracle/arch/1_24_802540708.dbfMedia Recovery Waiting for thread 2 sequence 15Fetching gap sequence in thread 2, gap sequence 15-18Thu Dec 27 08:58:19 CST 2012RFS[8]: Archived Log: '/u01/app/oracle/arch/2_15_802540708.dbf'Thu Dec 27 08:58:33 CST 2012RFS[9]: Archived Log: '/u01/app/oracle/arch/2_16_802540708.dbf'RFS[9]: Archived Log: '/u01/app/oracle/arch/2_17_802540708.dbf'RFS[9]: Archived Log: '/u01/app/oracle/arch/2_18_802540708.dbf'Thu Dec 27 08:58:49 CST 2012Media Recovery Log /u01/app/oracle/arch/2_15_802540708.dbfMedia Recovery Waiting for thread 3 sequence 8Fetching gap sequence in thread 3, gap sequence 8-12Thu Dec 27 08:59:06 CST 2012RFS[3]: Archived Log: '/u01/app/oracle/arch/3_8_802540708.dbf'RFS[3]: Archived Log: '/u01/app/oracle/arch/3_9_802540708.dbf'RFS[3]: Archived Log: '/u01/app/oracle/arch/3_10_802540708.dbf'RFS[3]: Archived Log: '/u01/app/oracle/arch/3_11_802540708.dbf'RFS[3]: Archived Log: '/u01/app/oracle/arch/3_12_802540708.dbf'Thu Dec 27 08:59:19 CST 2012Media Recovery Log /u01/app/oracle/arch/3_8_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/1_25_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/2_16_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/3_9_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/1_26_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/1_27_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/1_28_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/3_10_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/1_29_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/2_17_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/1_30_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/1_31_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/3_11_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/1_32_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/2_18_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/1_33_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/1_34_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/3_12_802540708.dbfThu Dec 27 08:59:30 CST 2012Media Recovery Log /u01/app/oracle/arch/1_35_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/2_19_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/1_36_802540708.dbfThu Dec 27 09:00:02 CST 2012Media Recovery Log /u01/app/oracle/arch/1_37_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/3_13_802540708.dbfMedia Recovery Waiting for thread 3 sequence 14 (in transit)Thu Dec 27 09:00:04 CST 2012Recovery of Online Redo Log: Thread 3 Group 17 Seq 14 Reading mem 0  Mem# 0: +DATADG/standby/onlinelog/group_17.270.803059869Media Recovery Waiting for thread 1 sequence 38 (in transit)Thu Dec 27 09:00:04 CST 2012Recovery of Online Redo Log: Thread 1 Group 11 Seq 38 Reading mem 0  Mem# 0: +DATADG/standby/onlinelog/group_11.264.803059801Media Recovery Waiting for thread 2 sequence 20 (in transit)Thu Dec 27 09:00:04 CST 2012Recovery of Online Redo Log: Thread 2 Group 14 Seq 20 Reading mem 0  Mem# 0: +DATADG/standby/onlinelog/group_14.267.803059831Thu Dec 27 09:07:14 CST 2012Primary database is in MAXIMUM PERFORMANCE modeRFS[5]: Successfully opened standby log 11: '+DATADG/standby/onlinelog/group_11.264.803059801'Thu Dec 27 09:07:15 CST 2012Media Recovery Log /u01/app/oracle/arch/1_38_802540708.dbfThu Dec 27 09:07:26 CST 2012Media Recovery Waiting for thread 1 sequence 39 (in transit)Thu Dec 27 09:07:26 CST 2012Recovery of Online Redo Log: Thread 1 Group 11 Seq 39 Reading mem 0  Mem# 0: +DATADG/standby/onlinelog/group_11.264.803059801Thu Dec 27 09:07:51 CST 2012Primary database is in MAXIMUM PERFORMANCE modeRFS[5]: Successfully opened standby log 11: '+DATADG/standby/onlinelog/group_11.264.803059801'Thu Dec 27 09:07:52 CST 2012Primary database is in MAXIMUM PERFORMANCE modeRFS[2]: Successfully opened standby log 17: '+DATADG/standby/onlinelog/group_17.270.803059869'Thu Dec 27 09:07:55 CST 2012Media Recovery Log /u01/app/oracle/arch/3_14_802540708.dbfMedia Recovery Log /u01/app/oracle/arch/1_39_802540708.dbfMedia Recovery Waiting for thread 1 sequence 40 (in transit)Thu Dec 27 09:07:58 CST 2012Recovery of Online Redo Log: Thread 1 Group 11 Seq 40 Reading mem 0  Mem# 0: +DATADG/standby/onlinelog/group_11.264.803059801Media Recovery Waiting for thread 3 sequence 15 (in transit)Thu Dec 27 09:07:58 CST 2012Recovery of Online Redo Log: Thread 3 Group 17 Seq 15 Reading mem 0  Mem# 0: +DATADG/standby/onlinelog/group_17.270.803059869Thu Dec 27 09:08:40 CST 2012Primary database is in MAXIMUM PERFORMANCE modeRFS[5]: Successfully opened standby log 11: '+DATADG/standby/onlinelog/group_11.264.803059801'Thu Dec 27 09:08:41 CST 2012Media Recovery Log /u01/app/oracle/arch/1_40_802540708.dbfThu Dec 27 09:08:43 CST 2012Primary database is in MAXIMUM PERFORMANCE modeRFS[7]: Successfully opened standby log 14: '+DATADG/standby/onlinelog/group_14.267.803059831'Thu Dec 27 09:08:44 CST 2012Media Recovery Log /u01/app/oracle/arch/2_20_802540708.dbfMedia Recovery Waiting for thread 1 sequence 41 (in transit)Thu Dec 27 09:08:53 CST 2012Recovery of Online Redo Log: Thread 1 Group 11 Seq 41 Reading mem 0  Mem# 0: +DATADG/standby/onlinelog/group_11.264.803059801Media Recovery Waiting for thread 2 sequence 21 (in transit)Thu Dec 27 09:08:59 CST 2012Recovery of Online Redo Log: Thread 2 Group 14 Seq 21 Reading mem 0  Mem# 0: +DATADG/standby/onlinelog/group_14.267.803059831Thu Dec 27 09:12:29 CST 2012Primary database is in MAXIMUM PERFORMANCE modeRFS[5]: Successfully opened standby log 11: '+DATADG/standby/onlinelog/group_11.264.803059801'Thu Dec 27 09:12:30 CST 2012Media Recovery Log /u01/app/oracle/arch/1_41_802540708.dbfThu Dec 27 09:12:42 CST 2012Media Recovery Waiting for thread 1 sequence 42 (in transit)Thu Dec 27 09:12:42 CST 2012Recovery of Online Redo Log: Thread 1 Group 11 Seq 42 Reading mem 0  Mem# 0: +DATADG/standby/onlinelog/group_11.264.803059801Thu Dec 27 09:13:06 CST 2012Primary database is in MAXIMUM PERFORMANCE modeRFS[5]: Successfully opened standby log 11: '+DATADG/standby/onlinelog/group_11.264.803059801'Thu Dec 27 09:13:08 CST 2012Media Recovery Log /u01/app/oracle/arch/1_42_802540708.dbfThu Dec 27 09:13:08 CST 2012Primary database is in MAXIMUM PERFORMANCE modeRFS[2]: Successfully opened standby log 17: '+DATADG/standby/onlinelog/group_17.270.803059869'Thu Dec 27 09:13:08 CST 2012Media Recovery Log /u01/app/oracle/arch/3_15_802540708.dbfMedia Recovery Waiting for thread 1 sequence 43 (in transit)Thu Dec 27 09:13:11 CST 2012Recovery of Online Redo Log: Thread 1 Group 11 Seq 43 Reading mem 0  Mem# 0: +DATADG/standby/onlinelog/group_11.264.803059801Thu Dec 27 09:13:23 CST 2012Media Recovery Waiting for thread 3 sequence 16 (in transit)Thu Dec 27 09:13:23 CST 2012Recovery of Online Redo Log: Thread 3 Group 17 Seq 16 Reading mem 0  Mem# 0: +DATADG/standby/onlinelog/group_17.270.803059869可以看到日志全部传输过来了 在主库创建standby logfile,为了switchover之后原RAC primary database和single physical standby database角色变换后新的standby database可以正常应用日志 SQL> select * from v$logfile;    GROUP# STATUS  TYPE    MEMBER\t\t\t\t\t      IS_---------- ------- ------- -------------------------------------------------- ---\t 2\t   ONLINE  +DATADG/racdb/onlinelog/group_2.262.802540719      NO\t 2\t   ONLINE  +FLASHDG/racdb/onlinelog/group_2.258.802540725     YES\t 1\t   ONLINE  +DATADG/racdb/onlinelog/group_1.261.802540709      NO\t 1\t   ONLINE  +FLASHDG/racdb/onlinelog/group_1.257.802540715     YES\t 3\t   ONLINE  +DATADG/racdb/onlinelog/group_3.266.802541097      NO\t 3\t   ONLINE  +FLASHDG/racdb/onlinelog/group_3.259.802541105     YES\t 4\t   ONLINE  +DATADG/racdb/onlinelog/group_4.267.802541113      NO\t 4\t   ONLINE  +FLASHDG/racdb/onlinelog/group_4.260.802541123     YES\t 5\t   ONLINE  +DATADG/racdb/onlinelog/group_5.270.802888327      NO\t 5\t   ONLINE  +FLASHDG/racdb/onlinelog/group_5.279.802888333     YES\t 6\t   ONLINE  +DATADG/racdb/onlinelog/group_6.271.802888337      NO\t 6\t   ONLINE  +FLASHDG/racdb/onlinelog/group_6.280.802888343     YES12 rows selected.SQL> select * from v$log;    GROUP#    THREAD#  SEQUENCE#      BYTES    MEMBERS ARC STATUS\t    FIRST_CHANGE# FIRST_TIME---------- ---------- ---------- ---------- ---------- --- ---------------- ------------- -----------------------\t 1\t    1\t      43   52428800\t     2 NO  CURRENT\t\t  1154512 27-DEC-2012 09:13:05\t 2\t    1\t      42   52428800\t     2 YES INACTIVE\t\t  1154455 27-DEC-2012 09:12:28\t 3\t    2\t      21   52428800\t     2 NO  CURRENT\t\t  1154041 27-DEC-2012 09:08:43\t 4\t    2\t      20   52428800\t     2 YES INACTIVE\t\t  1152090 27-DEC-2012 08:57:39\t 5\t    3\t      15   52428800\t     2 YES INACTIVE\t\t  1153073 27-DEC-2012 09:07:52\t 6\t    3\t      16   52428800\t     2 NO  CURRENT\t\t  1154577 27-DEC-2012 09:13:086 rows selected.SQL> alter database add standby logfile thread 1 group 7 size 50M,group 8 size 50M,group 9 size 50M;Database altered.SQL> alter database add standby logfile thread 2 group 10 size 50M,group 11 size 50M,group 12 size 50M;Database altered.SQL> alter database add standby logfile thread 3 group 13 size 50M,group 14 size 50M,group 15 size 50M;Database altered.SQL> select * from v$logfile;    GROUP# STATUS  TYPE    MEMBER\t\t\t\t\t      IS_---------- ------- ------- -------------------------------------------------- ---\t 2\t   ONLINE  +DATADG/racdb/onlinelog/group_2.262.802540719      NO\t 2\t   ONLINE  +FLASHDG/racdb/onlinelog/group_2.258.802540725     YES\t 1\t   ONLINE  +DATADG/racdb/onlinelog/group_1.261.802540709      NO\t 1\t   ONLINE  +FLASHDG/racdb/onlinelog/group_1.257.802540715     YES\t 3\t   ONLINE  +DATADG/racdb/onlinelog/group_3.266.802541097      NO\t 3\t   ONLINE  +FLASHDG/racdb/onlinelog/group_3.259.802541105     YES\t 4\t   ONLINE  +DATADG/racdb/onlinelog/group_4.267.802541113      NO\t 4\t   ONLINE  +FLASHDG/racdb/onlinelog/group_4.260.802541123     YES\t 5\t   ONLINE  +DATADG/racdb/onlinelog/group_5.270.802888327      NO\t 5\t   ONLINE  +FLASHDG/racdb/onlinelog/group_5.279.802888333     YES\t 6\t   ONLINE  +DATADG/racdb/onlinelog/group_6.271.802888337      NO\t 6\t   ONLINE  +FLASHDG/racdb/onlinelog/group_6.280.802888343     YES\t 7\t   STANDBY +DATADG/racdb/onlinelog/group_7.272.803122431      NO\t 7\t   STANDBY +FLASHDG/racdb/onlinelog/group_7.271.803122435     YES\t 8\t   STANDBY +DATADG/racdb/onlinelog/group_8.273.803122441      NO\t 8\t   STANDBY +FLASHDG/racdb/onlinelog/group_8.268.803122445     YES\t 9\t   STANDBY +DATADG/racdb/onlinelog/group_9.274.803122449      NO\t 9\t   STANDBY +FLASHDG/racdb/onlinelog/group_9.264.803122453     YES\t10\t   STANDBY +DATADG/racdb/onlinelog/group_10.275.803122477     NO\t10\t   STANDBY +FLASHDG/racdb/onlinelog/group_10.282.803122483    YES\t11\t   STANDBY +DATADG/racdb/onlinelog/group_11.276.803122487     NO\t11\t   STANDBY +FLASHDG/racdb/onlinelog/group_11.281.803122493    YES\t12\t   STANDBY +DATADG/racdb/onlinelog/group_12.277.803122497     NO\t12\t   STANDBY +FLASHDG/racdb/onlinelog/group_12.276.803122501    YES\t13\t   STANDBY +DATADG/racdb/onlinelog/group_13.278.803122527     NO\t13\t   STANDBY +FLASHDG/racdb/onlinelog/group_13.274.803122531    YES\t14\t   STANDBY +DATADG/racdb/onlinelog/group_14.279.803122537     NO\t14\t   STANDBY +FLASHDG/racdb/onlinelog/group_14.270.803122541    YES\t15\t   STANDBY +DATADG/racdb/onlinelog/group_15.280.803122545     NO\t15\t   STANDBY +FLASHDG/racdb/onlinelog/group_15.269.803122551    YES30 rows selected.SQL> select * from v$log;    GROUP#    THREAD#  SEQUENCE#      BYTES    MEMBERS ARC STATUS\t    FIRST_CHANGE# FIRST_TIME---------- ---------- ---------- ---------- ---------- --- ---------------- ------------- -----------------------\t 1\t    1\t      43   52428800\t     2 NO  CURRENT\t\t  1154512 27-DEC-2012 09:13:05\t 2\t    1\t      42   52428800\t     2 YES INACTIVE\t\t  1154455 27-DEC-2012 09:12:28\t 3\t    2\t      21   52428800\t     2 NO  CURRENT\t\t  1154041 27-DEC-2012 09:08:43\t 4\t    2\t      20   52428800\t     2 YES INACTIVE\t\t  1152090 27-DEC-2012 08:57:39\t 5\t    3\t      15   52428800\t     2 YES INACTIVE\t\t  1153073 27-DEC-2012 09:07:52\t 6\t    3\t      16   52428800\t     2 NO  CURRENT\t\t  1154577 27-DEC-2012 09:13:086 rows selected.SQL> select * from v$standby_log;    GROUP# DBID \t\t\t\t       THREAD#\tSEQUENCE#      BYTES\t   USED ARC STATUS     FIRST_CHANGE# FIRST_TIME \t     LAST_CHANGE# LAST_TIME---------- ---------------------------------------- ---------- ---------- ---------- ---------- --- ---------- ------------- ----------------------- ------------ -----------------------\t 7 UNASSIGNED\t\t\t\t\t     1\t\t0   52428800\t    512 YES UNASSIGNED\t\t   0\t\t\t\t\t0\t 8 UNASSIGNED\t\t\t\t\t     1\t\t0   52428800\t    512 YES UNASSIGNED\t\t   0\t\t\t\t\t0\t 9 UNASSIGNED\t\t\t\t\t     1\t\t0   52428800\t    512 YES UNASSIGNED\t\t   0\t\t\t\t\t0\t10 UNASSIGNED\t\t\t\t\t     2\t\t0   52428800\t    512 YES UNASSIGNED\t\t   0\t\t\t\t\t0\t11 UNASSIGNED\t\t\t\t\t     2\t\t0   52428800\t    512 YES UNASSIGNED\t\t   0\t\t\t\t\t0\t12 UNASSIGNED\t\t\t\t\t     2\t\t0   52428800\t    512 YES UNASSIGNED\t\t   0\t\t\t\t\t0\t13 UNASSIGNED\t\t\t\t\t     3\t\t0   52428800\t    512 YES UNASSIGNED\t\t   0\t\t\t\t\t0\t14 UNASSIGNED\t\t\t\t\t     3\t\t0   52428800\t    512 YES UNASSIGNED\t\t   0\t\t\t\t\t0\t15 UNASSIGNED\t\t\t\t\t     3\t\t0   52428800\t    512 YES UNASSIGNED\t\t   0\t\t\t\t\t09 rows selected. 还需配置standby_file_management,db_file_name_convert,log_file_name_convert这三个参数,谁能告诉我为什么后面两个参数不给修改? 只好生成pfile,通过修改pfile启动实例重新生成spfile SQL> alter system set standby_file_management='AUTO' sid='*';System altered.SQL> alter system set db_file_name_convert='+DATADG/standby/','+DATADG/racdb/' sid='*' scope=spfile;alter system set db_file_name_convert='+DATADG/standby/','+DATADG/racdb/' sid='*' scope=spfile                 *ERROR at line 1:ORA-02096: specified initialization parameter is not modifiable with this optionSQL> alter system set log_file_name_convert='+DATADG/standby/','+DATADG/racdb/','+DATADG/standby/','+FLASHDG/racdb/' sid='*' scope=spfile;alter system set log_file_name_convert='+DATADG/standby/','+DATADG/racdb/','+DATADG/standby/','+FLASHDG/racdb/' sid='*' scope=spfile                 *ERROR at line 1:ORA-02095: specified initialization parameter cannot be modified 修改pfile后使用以下命令创建spfile,然后重启rac实例 create spfile='+DATADG/racdb/spfileracdb.ora' from pfile='/tmp/rac1.ora'; srvctl stop/start database -d racdb 测试dataguard数据同步 主库创建表空间 [oracle@racnode1 ~]$ sqlplus / as sysdbaSQL*Plus: Release 10.2.0.5.0 - Production on Thu Dec 27 10:24:14 2012Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.Connected to:Oracle Database 10g Enterprise Edition Release 10.2.0.5.0 - 64bit ProductionWith the Partitioning, Real Application Clusters, OLAP, Data Miningand Real Application Testing optionsSQL> create tablespace zhongwc datafile size 10M autoextend on;Tablespace created. 备库查看是否同步 ASMCMD [+datadg/standby/datafile] > ls -lType      Redund  Striped  Time             Sys  NameDATAFILE  MIRROR  COARSE   DEC 27 08:00:00  Y    EXAMPLE.258.803059147DATAFILE  MIRROR  COARSE   DEC 27 08:00:00  Y    SYSAUX.261.803059163DATAFILE  MIRROR  COARSE   DEC 27 08:00:00  Y    SYSTEM.257.803059147DATAFILE  MIRROR  COARSE   DEC 27 08:00:00  Y    UNDOTBS1.259.803059147DATAFILE  MIRROR  COARSE   DEC 27 08:00:00  Y    UNDOTBS2.262.803059163DATAFILE  MIRROR  COARSE   DEC 27 08:00:00  Y    UNDOTBS3.260.803059149DATAFILE  MIRROR  COARSE   DEC 27 08:00:00  Y    USERS.263.803059163DATAFILE  MIRROR  COARSE   DEC 27 10:00:00  Y    ZHONGWC.279.803125553 SQL> select name from v$datafile;NAME--------------------------------------------------------------------------------+DATADG/standby/datafile/system.257.803059147+DATADG/standby/datafile/undotbs1.259.803059147+DATADG/standby/datafile/sysaux.261.803059163+DATADG/standby/datafile/users.263.803059163+DATADG/standby/datafile/example.258.803059147+DATADG/standby/datafile/undotbs2.262.803059163+DATADG/standby/datafile/undotbs3.260.803059149+DATADG/standby/datafile/zhongwc.279.8031255538 rows selected.备库alert.log Media Recovery Log /u01/app/oracle/arch/1_55_802540708.dbfMedia Recovery Waiting for thread 1 sequence 56 (in transit)Thu Dec 27 10:17:01 CST 2012Recovery of Online Redo Log: Thread 1 Group 11 Seq 56 Reading mem 0  Mem# 0: +DATADG/standby/onlinelog/group_11.264.803059801Thu Dec 27 10:25:53 CST 2012Successfully added datafile 8 to media recoveryDatafile #8: '+DATADG/standby/datafile/zhongwc.279.803125553' 在主库创建表,insert几条数据 SQL> conn hr/Enter password: Connected.SQL> create table t_zhongwc (tid number(3) primary key,tname varchar2(20)) tablespace zhongwc;Table created.SQL> insert into t_zhongwc values(1,'rac to single dg');1 row created.SQL> insert into t_zhongwc values(2,'zhongwc');1 row created.SQL> commit;Commit complete.SQL> 备库停止日志应用,打开数据库,可以看见数据已经同步过去 [oracle@standby arch]$ sqlplus / as sysdbaSQL*Plus: Release 10.2.0.5.0 - Production on Thu Dec 27 10:31:50 2012Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.Connected to:Oracle Database 10g Enterprise Edition Release 10.2.0.5.0 - 64bit ProductionWith the Partitioning, OLAP, Data Mining and Real Application Testing optionsSQL> alter database recover managed standby database cancel;Database altered.SQL> alter database open;Database altered.SQL> select open_mode from v$database;OPEN_MODE----------READ ONLYSQL> conn hr/Enter password: Connected.SQL> desc t_zhongwc Name\t\t\t\t\t   Null?    Type ----------------------------------------- -------- ---------------------------- TID\t\t\t\t\t   NOT NULL NUMBER(3) TNAME\t\t\t\t\t\t    VARCHAR2(20)SQL> select * from t_zhongwc  2  /       TID TNAME---------- --------------------\t 1 rac to single dg\t 2 zhongwc 测试在主库删除zhongwc表空间 [oracle@racnode1 ~]$ sqlplus / as sysdbaSQL*Plus: Release 10.2.0.5.0 - Production on Thu Dec 27 10:43:07 2012Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.Connected to:Oracle Database 10g Enterprise Edition Release 10.2.0.5.0 - 64bit ProductionWith the Partitioning, Real Application Clusters, OLAP, Data Miningand Real Application Testing optionsSQL> drop tablespace zhongwc including contents and datafiles;Tablespace dropped. 备库上查看,已经同步 [oracle@standby arch]$ sqlplus / as sysdbaSQL*Plus: Release 10.2.0.5.0 - Production on Thu Dec 27 10:44:47 2012Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.Connected to:Oracle Database 10g Enterprise Edition Release 10.2.0.5.0 - 64bit ProductionWith the Partitioning, OLAP, Data Mining and Real Application Testing optionsSQL> select name from v$datafile;NAME--------------------------------------------------------------------------------+DATADG/standby/datafile/system.257.803059147+DATADG/standby/datafile/undotbs1.259.803059147+DATADG/standby/datafile/sysaux.261.803059163+DATADG/standby/datafile/users.263.803059163+DATADG/standby/datafile/example.258.803059147+DATADG/standby/datafile/undotbs2.262.803059163+DATADG/standby/datafile/undotbs3.260.8030591497 rows selected. ASMCMD [+datadg/standby/datafile] > ls -lType      Redund  Striped  Time             Sys  NameDATAFILE  MIRROR  COARSE   DEC 27 10:00:00  Y    EXAMPLE.258.803059147DATAFILE  MIRROR  COARSE   DEC 27 10:00:00  Y    SYSAUX.261.803059163DATAFILE  MIRROR  COARSE   DEC 27 10:00:00  Y    SYSTEM.257.803059147DATAFILE  MIRROR  COARSE   DEC 27 10:00:00  Y    UNDOTBS1.259.803059147DATAFILE  MIRROR  COARSE   DEC 27 10:00:00  Y    UNDOTBS2.262.803059163DATAFILE  MIRROR  COARSE   DEC 27 10:00:00  Y    UNDOTBS3.260.803059149DATAFILE  MIRROR  COARSE   DEC 27 10:00:00  Y    USERS.263.803059163备库alert.log Recovery of Online Redo Log: Thread 1 Group 11 Seq 61 Reading mem 0  Mem# 0: +DATADG/standby/onlinelog/group_11.264.803059801Thu Dec 27 10:43:49 CST 2012Recovery deleting file #8:'+DATADG/standby/datafile/zhongwc.279.803125553' from controlfile.Deleted Oracle managed file +DATADG/standby/datafile/zhongwc.279.803125553Recovery dropped tablespace 'ZHONGWC' 到此为止Configuring Oracle 10gR2 (10.2.0.5) 3-Nodes RAC to Single Dataguard搭建测试完毕","title":"Step By Step Configuring Oracle 10gR2 (10.2.0.5) 3-Nodes RAC to Single Dataguard"},{"content":"对于一些数据量较大的系统，面临的问题除了是查询效率低下，还有一个很重要的问题就是插入时间长。当导入的数据量较大时，插入操作耗费的时间相当可观。因此，提高大数据量系统的MySQL insert效率是很有必要的。 1. 一条SQL语句插入多条数据。 常用的插入语句如： INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) VALUES ('0', 'userid_0', 'content_0', 0);  INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) VALUES ('1', 'userid_1', 'content_1', 1);修改成： INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) VALUES     ('0', 'userid_0', 'content_0', 0), ('1', 'userid_1', 'content_1', 1);Java实现： Connection connection = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/test\",\"root\",\"123\");// 关闭自动提交，默认情况下每执行一条sql提交一次connection.setAutoCommit(false);PreparedStatement statement = connection.prepareStatement(\"INSERT INTO insert_table VALUES(?, ?)\"); //记录1statement.setString(1, \"2012-12-27 11:11:11\"); statement.setString(2, \"userid_0\"); statement.setString(3, \"content_0\"); statement.setInt(4, 0); statement.addBatch(); //记录2statement.setString(1, \"2012-12-27 12:12:12\"); statement.setString(2, \"userid_1\"); statement.setString(3, \"content_1\"); statement.setInt(4, 1);statement.addBatch(); //记录3statement.setString(1, \"2012-12-27 13:13:13\"); statement.setString(2, \"userid_2\"); statement.setString(3, \"content_2\"); statement.setInt(4, 2); statement.addBatch(); //批量执行上面3条语句. int [] counts = statement.executeBatch(); //Commit connection.commit(); 修改后的插入操作能够提高程序的插入效率。这里第二种SQL执行效率高的主要原因有两个，一是减少SQL语句解析的操作， 只需要解析一次就能进行数据的插入操作，二是SQL语句较短，可以减少网络传输的IO。 性能： 这里提供一些测试对比数据，分别是进行单条数据的导入与转化成一条SQL语句进行导入，分别测试1百、1千、1万条数据记录。 记录数 单条数据插入 多条数据插入 1百 0.149s 0.011s 1千 1.231s 0.047s 1万 11.678s 0.218s 2. 在事务中进行插入处理。 把插入修改成： START TRANSACTION;  INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) VALUES ('0', 'userid_0', 'content_0', 0);  INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) VALUES ('1', 'userid_1', 'content_1', 1);  ...  COMMIT;使用事务可以提高数据的插入效率，这是因为进行一个INSERT操作时，MySQL内部会建立一个事务，在事务内进行真正插入处理。通过使用事务可以减少数据库执行插入语句时多次“创建事务，提交事务”的消耗，所有插入都在执行后才进行提交操作。 性能： 这里也提供了测试对比，分别是不使用事务与使用事务在记录数为1百、1千、1万的情况。 记录数 不使用事务 使用事务 1百 0.149s 0.033s 1千 1.231s 0.115s 1万 11.678s 1.050s 性能测试： 这里提供了同时使用上面两种方法进行INSERT效率优化的测试。即多条数据合并为同一个SQL，并且在事务中进行插入。 记录数 单条数据插入 合并数据+事务插入 1万 0m15.977s 0m0.309s 10万 1m52.204s 0m2.271s 100万 18m31.317s 0m23.332s 从测试结果可以看到，insert的效率大概有50倍的提高，这个一个很客观的数字。 注意事项： 1. SQL语句是有长度限制，在进行数据合并在同一SQL中务必不能超过SQL长度限制，通过max_allowed_packe配置可以修改，默认是1M。 2. 事务需要控制大小，事务太大可能会影响执行的效率。MySQL有innodb_log_buffer_size配置项，超过这个值会日志会使用磁盘数据，这时，效率会有所下降。所以比较好的做法是，在事务大小达到配置项数据级前进行事务提交。 参考：  http://blog.csdn.net/tigernorth/article/details/8094277","title":"MySQL插入语句insert性能优化"},{"content":"redis的数据类型有:string、hashes、lists、sets，sorted sets 1、string类型:                           set、get添加键值对获得键值对、如果多次赋值会覆盖掉原来的value                           setnx会自动判断是否存在，如果存在返回0不存在返回1，并且不会覆盖原来的value                           setex设置失效时间(毫秒)setex color 10 red                           setrange设置第几个开始替换setrange email 6 163.com                           mset 设置多个key-value mset k1 v1 k2 v2                           msetnx具体情况和setnx类似，设置多个的时候返回成功的个数                           getset设置一个key的value并且返回一个key的原来的值                           getrange返回第几个到第几个getrange email 0 5                           mget 获得多个key-value的值 mget k1 k2                           incr自动步增incr key6                           incrby自动规定步增incrby key6 5、incrby key6 -5                           decr同上自减                           decrby同上自减                           append指定的key追加value，返回生成字符串长度                           strlen查看字符串长度 2、hashes类型:相对较节省空间(具体的意思同上)                          hset user1 username admin 设置key 可以覆盖                          hsetnx user2 username admin 设置不重复keys                          hmset user3 username admin password admin age 2 state 2  多个设置                          hmget user3 username password age state 多个获得                          hincrby user3 age 19 自增                          hexists user3 username 查看字段是佛存在                          hlen user3 查看hash的长度                          hdel user3 age 删除hash里面对应的名字的value                          hkeys user3 返回所有的keys                          hvals user3  返回所有的values                          hgetall user3 同时返回keys的values 3、lists类型(相对于队列和栈)                          lpust mylistname1 2 3 放入 、先进后出                          lrange mylistname 0 -1从0取到尾                          rpust mylistname1 2 3 放入 、先进先出                          lrange mylistname 0 -1从0取到尾                          linsert mylistname before one two 从尾到顶元素的之前插入                          lset mylistname 0 four 改变下标为0的元素、对于lpush内容是从上向下递增标注下标的                          lrem mylistname 2 two 在mylistname这个list中删除value为two的两个数据                          ltrim mylistname 1 -1 保留mylistname里面从第一个元素到第二个元素的内容、别的元素全部删除                          lpop mylistname 从头部弹出元素                          rpop mylistname 从尾部弹出一个元素                              rpoplpush mylistname1 mylistname2 从第一个尾部弹出一个元素放入第二个头部                          lindex mylistname 1 取得索引value                          llen mylistname 取得list的长度  4、sets集合、很类似于数学上学习的集合                          sadd mysetname values1 插上set里面的value                          smembers mysetname 查看mysetname里面的value                          srem mysetname values1 删除values1 的值                          spop mysetname 随即弹出一个数                          sdiff mysetname1 mysetname 2 返回两个set的差集谁在前面把谁作为参照物                          sdiffstore mysetname3 mysetname2 mysetname1 把2 和1 的不同存入到3中                          sinter mysetname1 mysetname2 返回两个set的交集                          sinterstore mysetname3 mysetname2 mysetname1 返回两个set的交集放到3里面                          sunion mysetname2 mysetname1 返回两个set的并集                          sunionstore mysetname3 mysetname2 mysetname1 返回两个set的并集，存储到3中、关键在上面的这些操作都可以有≥两个参数                          smove mysetname1 mysetname2 three 把1中的three元素剪切到2中                          scard mysetname 返回set里面的元素个数                          sismember mysetname one 判断one是不是集合的元素                          srandmember mysetname 随即返回一个元素 5、sorted sets 有序集合                          zadd myzsetname 1 one插入有序集合，并且指定顺序                          zrange myzsetname 0 -1 [withscores] 全部取出，并且显示顺序号                          zrem myzsetname one 删除元素                          zincrby  myzsetname 2 one 添加元素，自动增长                          zrank myzsetname one 根据索引从小到大排序，然后显示索引值(这个可以做访问量什么的排名之类的)                          zrevrank myzsetname one 和上面的意思一样，但是是scores从打到小排序                          zrangebyscore myzsetname 0 -1 withscores 从一定区间里面按照scores返回                          zcount myzsetname2 3 返回2 3中间的所有的数量                          zremrangebyrank myzsetnage 2 3 删除2 和3 位置，按照索引来删除","title":"redis入门——redis的数据类型"},{"content":"通过dbc.allrights表中的UserName列，DatabaseName列，TableName列和AccessRight列的查询可以获取指定用于对于指定数据库中指定表的操作权限。可用于在执行某条SQL语句之前，判定当前用户是否有执行此语句的权限，在权限不足时还可以尝试自动授权（不太安全，执行完应当revoke）等措施。 AccessRight列缩写词对应列表（共40个）： AccessRight 含义 AF ALTER FUNCTION AP ALTER PROCEDURE AS ABORT SESSION CD CREATE DATABASE CF CREATE FUNCTION CG CREATE TRIGGER CM CREATE MACRO CO CREATE PROFILE CP CHECKPOINT CR CREATE ROLE CT CREATE TABLE CU CREATE USER CV CREATE VIEW D DELETE DD DROP DATABASE DF DROP FUNCTION DG DROP TRIGGER DM DROP MACRO DO DROP PROFILE DP DUMP DR DROP ROLE DT DROP TABLE DU DROP USER DV DROP VIEW E EXECUTE EF EXECUTE FUNCTION I INSERT IX INDEX MR MONITOR RESOURCE MS MONITOR SESSION PC CREATE PROCEDURE PD DROP PROCEDURE PE EXECUTE PROCEDURE RO REPLICATION OVERRIDE R RETRIEVE/SELECT RF REFERENCE RS RESTORE SS SET SESSION RATE SR SET RESOURCE RATE U UPDATE 示例SQL语句： select username, databasename, tablename, accessright from dbc.allrights     where databasename='systemfe' and username='dbc' and tablename='opt_ras_table';上述语句的执行结果为： *** Query completed. 12 rows found. 4 columns returned.*** Total elapsed time was 1 second. UserName                        DatabaseName                    TableName                       AccessRight------------------------------  ------------------------------  ------------------------------  -----------DBC                             SystemFe                        opt_ras_table                   DTDBC                             SystemFe                        opt_ras_table                   UDBC                             SystemFe                        opt_ras_table                   DGDBC                             SystemFe                        opt_ras_table                   RFDBC                             SystemFe                        opt_ras_table                   RSDBC                             SystemFe                        opt_ras_table                   RDBC                             SystemFe                        opt_ras_table                   IDBC                             SystemFe                        opt_ras_table                   CGDBC                             SystemFe                        opt_ras_table                   STDBC                             SystemFe                        opt_ras_table                   DPDBC                             SystemFe                        opt_ras_table                   DDBC                             SystemFe                        opt_ras_table                   IX 如下的SQL语句可以自动构建出授予权限的SQL语句（即GRANT语句）： SEL  TRIM(username)  ,TRIM(databasename) ,TRIM(tablename) ,'GRANT '|| CASE  WHEN AccessRight = 'AF ' THEN 'ALTER FUNCTION'  WHEN AccessRight = 'AP ' THEN 'ALTER PROCEDURE'  WHEN AccessRight = 'AS ' THEN 'ABORT SESSION' WHEN AccessRight = 'CD ' THEN 'CREATE DATABASE' WHEN AccessRight = 'CF ' THEN 'CREATE FUNCTION' WHEN AccessRight = 'CG ' THEN 'CREATE TRIGGER' WHEN AccessRight = 'CM ' THEN 'CREATE MACRO' WHEN AccessRight = 'CO ' THEN 'CREATE PROFILE' WHEN AccessRight = 'CP ' THEN 'CHECKPOINT' WHEN AccessRight = 'CR ' THEN 'CREATE ROLE' WHEN AccessRight = 'CT ' THEN 'CREATE TABLE' WHEN AccessRight = 'CU ' THEN 'CREATE USER' WHEN AccessRight = 'CV ' THEN 'CREATE VIEW' WHEN AccessRight = 'D ' THEN 'DELETE' WHEN AccessRight = 'DD ' THEN 'DROP DATABASE' WHEN AccessRight = 'DF ' THEN 'DROP FUNCTION' WHEN AccessRight = 'DG ' THEN 'DROP TRIGGER' WHEN AccessRight = 'DM ' THEN 'DROP MACRO' WHEN AccessRight = 'DO ' THEN 'DROP PROFILE' WHEN AccessRight = 'DP ' THEN 'DUMP' WHEN AccessRight = 'DR ' THEN 'DROP ROLE' WHEN AccessRight = 'DT ' THEN 'DROP TABLE' WHEN AccessRight = 'DU ' THEN 'DROP USER' WHEN AccessRight = 'DV ' THEN 'DROP VIEW' WHEN AccessRight = 'E ' THEN 'EXECUTE' WHEN AccessRight = 'EF ' THEN 'EXECUTE FUNCTION' WHEN AccessRight = 'I ' THEN 'INSERT' WHEN AccessRight = 'IX ' THEN 'INDEX' WHEN AccessRight = 'MR ' THEN 'MONITOR RESOURCE' WHEN AccessRight = 'MS ' THEN 'MONITOR SESSION' WHEN AccessRight = 'PC ' THEN 'CREATE PROCEDURE' WHEN AccessRight = 'PD ' THEN 'DROP PROCEDURE' WHEN AccessRight = 'PE ' THEN 'EXECUTE PROCEDURE' WHEN AccessRight = 'RO ' THEN 'REPLICATION OVERRIDE' WHEN AccessRight = 'R ' THEN 'RETRIEVE/SELECT' WHEN AccessRight = 'RF ' THEN 'REFERENCE' WHEN AccessRight = 'RS ' THEN 'RESTORE' WHEN AccessRight = 'SS ' THEN 'SET SESSION RATE' WHEN AccessRight = 'SR ' THEN 'SET RESOURCE RATE' WHEN AccessRight = 'U ' THEN 'UPDATE' END || ' ON '||TRIM(databasename)||'.'||TRIM(tablename)||' to '||TRIM(username)||';' AS PermissionFROM dbc.AllRightsWHERE DatabaseName = 'DBNAME' and USERNAME = 'LOGGEDINUSERNAME' AND TABLENAME = 'TABLENAME';","title":"查看Teradata数据库用户对于表的操作权限"},{"content":"有谁是研究数据发布中的隐私保护问题的,来相互交流下啊~~","title":"数据发布中的隐私保护问题"},{"content":"详见原文博客链接地址：关于dbwr/lgwr的一点知识","title":"关于dbwr/lgwr的一点知识"},{"content":"这是在做一个客户管理系统时遇到的问题，公司每年需要按销售区域评选出购买量最大的客户进行单独奖励。区域划分使用地域编码起止区间方式，例如，华东地区的起止编码是10001～10003，在10001、10002、10003区域的客户都隶属于华东地区。下面是创建示例的代码，Area表中存放着区域划分范围，Sales存放着每个区域中客户的购买信息。 CREATE TABLE Areas (area_name char(25) NOT NULL,  start_codeint NOT NULL,  end_codeint NOT NULL,  CHECK(start_code <= end_code)); CREATE TABLE Sales (sale_id int,  cust_namechar(15),  cust_codeint,  sale_amtdecimal (8,2));   INSERT INTO Areas VALUES ('华东', 10001, 10003),        ('华南', 10004, 10006),        ('华北', 10007, 10009); INSERT INTO Sales VALUES (1, '张三', 10001, 1000.00),        (2, '张三', 10002, 1000.00),        (3, '李四', 10001, 4000.00),        (4, '王五', 10005, 1000.00),        (5, '王五', 10006, 2000.00),        (6, '赵六', 10004, 1500.00); 要统计出每个区域中购买量最大的客户，我们首先想到的是使用GROUP BY子句进行分类汇总，参考下面的语句： SELECT A.area_name, S.cust_name, SUM(S.sale_amt)AS sale_amt FROM Areas AS A   JOIN SalesAS S     ONS.cust_code BETWEEN A.start_code AND A.end_code GROUP BY A.area_name, S.cust_name ORDER BY area_name;       表19-12                                        使用GROUP BY按区域、客户分类汇总结果 area_name cust_name sale_amt 华东 李四 4000.00 华东 张三 2000.00 华南 王五 3000.00 华南 赵六 1500.00 从上表可以看出，在华东地区李四的购买量最大，华南地区王五的购买量最大。如果仅统计每地区的最大销售额，不考虑客户名称，完全可以在上表的基础上使用类似下面的语句： SELECT area_name, MAX(sale_amt) FROM [表19-21] GROUP BY area_name; 下面的语句将GROUP BY分组统计封装在CTE中，然后将CTE打开两次，取出每区域中购买量最大的客户。查询结果如表19-13所示。 WITH CTE (area_name, cust_name, sale_amt) AS (SELECT A.area_name, S.cust_name,SUM(S.sale_amt)     FROMAreas AS A       JOINSales AS S         ONS.cust_code BETWEEN A.start_code AND A.end_code     GROUP BYA.area_name, S.cust_name) SELECT C1.area_name, C1.cust_name, C1.sale_amt FROM CTE AS C1 WHERE C1.sale_amt = (SELECT MAX(C2.sale_amt)                      FROM CTE AS C2                      WHERE C2.area_name =C1.area_name); 表19-13                                                                       查询结果 area_name cust_name sale_amt 华南                     王五           3000.00 华东                     李四           4000.00  ","title":"锋利的SQL:地域范围内最大数统计"},{"content":"以下是频繁用到的Sqlite函数，内容格式相对固定，封装一下有助于提高开发效率（^_^至少提高Codeeer的效率了） 而且，我发现Sqlite中文资料比较少，起码相对其他找起来要复杂些，服务一下大众~ 我没有封装读取部分，因为数据库读取灵活性太大，封装起来难度也大，而且就算封装好了，也难以应付所有情况，还是建议根据实际情况设计代码逻辑。 解释下，为啥代码中的注释基本都用英文写了，因为这段时间在学双拼- -。可是还不太熟悉，打字超慢，而且Code的时候容易打断思路，好在~英文不多，而且这些都看不懂的话你……你要向我解释一下你是怎么一路学到数据库的 0。0 创建 /// <summary>/// Creat New Sqlite File/// <\/summary>/// <param name=\"NewTable\">New Table Name<\/param>/// <param name=\"NewWords\">Words list of the New Table<\/param>/// <returns>IsSuccessful<\/returns>public static bool Creat(string DataSource, string NewTable, List<string> NewWords){    try    {        //Creat Data File        SQLiteConnection.CreateFile(DataSource);        //Creat Table        using (DbConnection conn = SQLiteFactory.Instance.CreateConnection())        {            //Connect            conn.ConnectionString = \"Data Source=\" + DataSource;            conn.Open();            //Creat            string Bazinga = \"create table [\" + NewTable + \"] (\";            foreach (string Words in NewWords)            {                Bazinga += \"[\" + Words + \"] BLOB COLLATE NOCASE,\";            }            //Set Primary Key            //The Top item from the \"NewWords\"            Bazinga += @\"PRIMARY KEY ([\" + NewWords[0] + \"]))\";            DbCommand cmd = conn.CreateCommand();            cmd.Connection = conn;            cmd.CommandText = Bazinga;            cmd.ExecuteNonQuery();        }        return true;    }    catch (Exception E)    {        MessageBox.Show(E.Message, \"提示\", MessageBoxButtons.OK, MessageBoxIcon.Information);        return false;    }} 删除 /// <summary>/// Delete Date/// <\/summary>/// <param name=\"DataSource\"><\/param>/// <param name=\"TargetTable\"><\/param>/// <param name=\"Word\"><\/param>/// <param name=\"Value\"><\/param>/// <returns><\/returns>public static bool Delete(string DataSource, string TargetTable, string Word, string Value){    try    {        //Connect        using (DbConnection conn = SQLiteFactory.Instance.CreateConnection())        {            conn.ConnectionString = \"Data Source=\" + DataSource;            conn.Open();            DbCommand cmd = conn.CreateCommand();            cmd.Connection = conn;            //Delete            cmd.CommandText = \"Delete From \" + TargetTable + \" where [\" + Word + \"] = '\" + Value + \"'\";            cmd.ExecuteNonQuery();        }        return true;    }    catch (Exception E)    {        MessageBox.Show(E.Message, \"提示\", MessageBoxButtons.OK, MessageBoxIcon.Information);        return false;    }} 插入 这里要说明下，因为存在多字段同时插入的情况（何止存在，很普遍- -。没见过谁的数据库像意大利面条一样） 在这里设计了Insert结构用以储存字段和值的关系（曾考虑过用数组的办法实现，可是那玩意不太方便调用，瞅着挺抽象的，不太好用，如果有更好的建议，欢迎留言~） /// <summary>/// Use to format Insert column's value/// <\/summary>public struct InsertBag{    public string ColumnName;    public string Value;    public InsertBag(string Column, string value)    {        ColumnName = Column;        Value = value;    }}以下为插入模块的主函数： /// <summary>/// Insert Data/// <\/summary>/// <param name=\"DataSource\"><\/param>/// <param name=\"TargetTable\"><\/param>/// <param name=\"InsertBags\">struck of InsertBag<\/param>/// <returns><\/returns>public static bool Insert(string DataSource, string TargetTable, List<InsertBag> InsertBags){    try    {        using (DbConnection conn = SQLiteFactory.Instance.CreateConnection())        {            //Connect Database            conn.ConnectionString = \"Data Source=\" + DataSource;            conn.Open();            //Deal InsertBags            StringBuilder ColumnS = new StringBuilder();            StringBuilder ValueS = new StringBuilder();            for (int i = 0; i < InsertBags.Count; i++)            {                ColumnS.Append(InsertBags[i].ColumnName + \",\");                ValueS.Append(\"'\" + InsertBags[i].Value + \"',\");            }            if (InsertBags.Count == 0)            {                throw new Exception(\"InsertBag 数据包为空，睁大你的狗眼……\");            }            else            {                //Drop the last \",\" from the ColumnS and ValueS                ColumnS = ColumnS.Remove(ColumnS.Length - 1, 1);                ValueS = ValueS.Remove(ValueS.Length - 1, 1);            }            //Insert            DbCommand cmd = conn.CreateCommand();            cmd.CommandText = \"insert into [\" + TargetTable + \"] (\" + ColumnS.ToString() + \") values (\" + ValueS.ToString() + \")\";            cmd.ExecuteNonQuery();            return true;        }    }    catch (Exception E)    {        MessageBox.Show(E.Message, \"提示\", MessageBoxButtons.OK, MessageBoxIcon.Information);        return false;    }}目测有点复杂呢，来个Demo，有必要说下，“W2”和“W44”是已经设计好的字段，而“TableTest”是已经添加好的表段 List<Sqlite.InsertBag> Lst = new List<Sqlite.InsertBag>();Lst.Add(new Sqlite.InsertBag(\"W2\", \"222222222\"));Lst.Add(new Sqlite.InsertBag(\"W44\", \"4444444\"));Sqlite.Insert(@\"D:\\1.Sql3\", \"TableTest\", Lst); 表段获取 /// <summary>/// Get Tables From Sqlite/// <\/summary>/// <returns>list of Tables<\/returns>public static List<string> GetTables(string DataSource){    List<string> ResultLst = new List<string>();    using (SQLiteConnection conn = new SQLiteConnection(\"Data Source=\" + DataSource))    {        conn.Open();        using (SQLiteCommand tablesGet = new SQLiteCommand(\"SELECT name from sqlite_master where type='table'\", conn))        {            using (SQLiteDataReader tables = tablesGet.ExecuteReader())            {                while (tables.Read())                {                    try                    {                        ResultLst.Add(tables[0].ToString());                    }                    catch (Exception E)                    {                        MessageBox.Show(E.Message, \"提示\", MessageBoxButtons.OK, MessageBoxIcon.Information);                    }                }            }        }    }    return ResultLst;} 字段获取 /// <summary>/// Get Words From Table->Sqlite/// <\/summary>/// <param name=\"TargetTable\">Target Table<\/param>/// <returns>list of Words<\/returns>public static List<string> GetWords(string DataSource,string TargetTable){    List<string> WordsLst = new List<string>();    using (SQLiteConnection conn = new SQLiteConnection(\"Data Source=\" + DataSource))    {        conn.Open();        using (SQLiteCommand tablesGet = new SQLiteCommand(@\"SELECT * FROM \" + TargetTable, conn))        {            using (SQLiteDataReader Words = tablesGet.ExecuteReader())            {                try                {                    for (int i = 0; i < Words.FieldCount; i++)                    {                        WordsLst.Add(Words.GetName(i));                    }                }                catch (Exception E)                {                    MessageBox.Show(E.Message, \"提示\", MessageBoxButtons.OK, MessageBoxIcon.Information);                }            }        }    }    return WordsLst;}","title":"Sqlite 常用函数封装：创建，删除，插入，表段、字段获取"},{"content":"SQL 按组汇总内容 1. 原始数据 语文        90 数学        80 英语        100 要求实现 语文    数学     英语 90      80       100 实现方法： select sum(case when kemu  ='语文' then score end) as 语文,        sum(case when kemu  ='数学' then score end) as 数学,   sum(case when kemu  ='英语' then score end) 英语  from t_testcore1 1. 原始数据 语文        50 数学        60 英语        100   要求实现 语文    数学     英语 及格     不及格       优秀 （60一下不及格，60-80及格，80以上优秀） 实现方法： select (case when   ( sum(case when kemu  ='语文' then score end)) <60 then '不及格'  when  ( sum(case when kemu  ='语文' then score end)) between 60 and 80  then '及格'  when ( sum(case when kemu  ='语文' then score end)) >80 then '优秀' end)  as 语文,  (case when  (  sum(case when kemu  ='数学' then score end)) <60 then '不及格'   when  (  sum(case when kemu  ='数学' then score end))between 60 and 80 then '及格'   when  (  sum(case when kemu  ='数学' then score end)) >80 then '优秀'  end )  as 数学, ( case when( sum(case when kemu  ='英语' then score end))<60 then '不及格'   when( sum(case when kemu  ='英语' then score end))between 60 and 80 then '及格'   when( sum(case when kemu  ='英语' then score end)) >80 then '优秀' end )    as 英语  from t_testcore1     表结构： student     kemu  fenshu student1    语文    80 student1    数学    90 student1    英语    85 student2    语文    85 student2    数学    92 student2    英语    82   变成： student  语文    数学   英语 student1   80     90     85 student2   85     92     82 select class, sum(case when kemu ='语文' then score end) as 语文, sum(case when kemu ='数学' then score end) as 数学, sum(case when kemu ='英语' then score end) as 英语 from t_testscore group by class case when的作用就是一个条件选择语句,根据不同的要求显示不同的内容,格式是这样的case        when [选择条件]        then [结果1]        else [结果2]        end    其中[选择条件]也可以放在case之后。    举例1：表temp的字段是[rq]--日期,[shengfu]--胜负。    select rq,    sum(case when shengfu='胜' then 1 else 0 end)'胜',    sum(case when shengfu='负' then 1 else 0 end)'负'    from temp    group by rq;    举例2：表user的字段为id,username,password select id, (case username when 'admin' then 'root' when 'Tite' then '帅哥' when 'Ant' then '美女' else '不帅' end) '管理员' from user order by id;    注意：else后面如果没有添加处理的时候,那么没有判断的条件将输出NULL     ，用一个SQL语句完成不同条件的分组。   Select  country, sum(case when sex=’1’ then population else 0 end) as 男，-------男性人口               Sum(case when sex=’2’ then population else 0 end) as 女             ----------女性人口 From  table group by country         已知数据按照另外一种方式进行分组，分析。 有如下数据:(为了看得更清楚，我并没有使用国家代码，而是直接用国家名作为Primary Key) 根据这个国家人口数据，统计亚洲和北美洲的人口数量。应该得到下面这个结果。 SELECT  SUM(population),  CASE country  WHEN '中国' THEN '亚洲'    WHEN '印度' THEN '亚洲'    WHEN '日本' THEN '亚洲'    WHEN '美国' THEN '北美洲'    WHEN '加拿大'  THEN '北美洲'    WHEN '墨西哥'  THEN '北美洲'  ELSE '其他' END  FROM    Table_A  GROUP BY CASE country  WHEN '中国' THEN '亚洲'  WHEN '印度' THEN '亚洲' WHEN '日本' THEN '亚洲'  WHEN '美国' THEN '北美洲'  WHEN '加拿大'   THEN '北美洲'  WHEN '墨西哥'   THEN '北美洲'  ELSE '其他' END;          六，在Case函数中使用合计函数 假设有下面一个表 学号(std_id) 课程ID(class_id) 课程名(class_name) 主修flag（main_class_flg) 100 1 经济学 Y 100 2 历史学 N 200 2 历史学 N 200 3 考古学 Y 200 4 计算机 N 300 4 计算机 N 400 5 化学 N 500 6 数学 N    有的学生选择了同时修几门课程(100,200)也有的学生只选择了一门课程(300,400,500)。选修多门课程的学生，要选择一门课程作为主修，主修flag里面写入 Y。只选择一门课程的学生，主修flag为N(实际上要是写入Y的话，就没有下面的麻烦事了，为了举例子，还请多多包含)。 现在我们要按照下面两个条件对这个表进行查询 1.只选修一门课程的人，返回那门课程的ID 2.选修多门课程的人，返回所选的主课程ID 简单的想法就是，执行两条不同的SQL语句进行查询。 条件1 --条件1：只选择了一门课程的学生  SELECT std_id, MAX(class_id) AS main_class  FROM Studentclass  GROUP BY std_id  HAVING COUNT(*) = 1;  执行结果1 STD_ID   MAIN_class   300      4  400      5  500      6  条件2 --条件2：选择多门课程的学生  SELECT std_id, class_id AS main_class  FROM Studentclass  WHERE main_class_flg = 'Y' ;  执行结果2 STD_ID  MAIN_class    100     1  200     3  如果使用Case函数，我们只要一条SQL语句就可以解决问题，具体如下所示 SELECT  std_id,  CASE WHEN COUNT(*) = 1  --只选择一门课程的学生的情况  THEN MAX(class_id)  ELSE MAX(CASE WHEN main_class_flg = 'Y'  THEN class_id  ELSE NULL END  )  END AS main_class  FROM Studentclass  GROUP BY std_id;  运行结果 STD_ID   MAIN_class  100      1  200      3  300      4  400      5  500      6  通过在Case函数中嵌套Case函数，在合计函数中使用Case函数等方法，我们可以轻松的解决这个问题。使用Case函数给我们带来了更大的自由度。 最后提醒一下使用Case函数的新手注意不要犯下面的错误 CASE col_1  WHEN  1    THEN 'Right'  WHEN  NULL THEN 'Wrong'  END  在这个语句中When Null这一行总是返回unknown，所以永远不会出现Wrong的情况。因为这句实际表达的意思是 WHEN col_1 = NULL，这是一个错误的用法，这个时候我们应该选择用WHEN col_1 IS NULL。    七、小结    select 与 case结合使用最大的好处有两点，一是在显示查询结果时可以灵活的组织格式，二是有效避免了多次对同一个表或几个表的访问。   下面举个简单的例子来说明。例如表 students(id, name ,birthday, sex, grade)，要求按每个年级统计男生和女生的数量各是多少，统计结果的表头为，年级，男生数量，女生数量。如果不用select case when，为了将男女数量并列显示，统计起来非常麻烦，先确定年级信息，再根据年级取男生数和女生数，而且很容易出错。 用select case when写法如下： SELECT grade, COUNT (CASE WHEN sex = 1 THEN 1                                  ELSE NULL                         END) 男生数,                COUNT (CASE WHEN sex = 2 THEN 1                             ELSE NULL                        END) 女生数 FROM students GROUP BY grade; ----------------------------------------- select  s as '类别', count(s) as '人数' from ( select score , case  when (score<60)then '不及格' when (score>60)then '及格' end as s from  t )a group by a.s     练习： select grade as 年级，count(case when sex=1 then 1 else null) 男生数                       count(case when sex=2 then1 else null) 女生数 from students group by grade     select s as 类别，count(case when score<60 then 1 else null)不及格                   count(case when score>60 then 1 else null)及格 from t group by s","title":"一些sql语句练习"},{"content":"--源表 table_t   a                b 广东         广州 广东         深圳 广西         南宁 广西         北海 --sql select a,WMSYS.WM_CONCAT(b) b from table_t group by a   --结果表   a                     b 广东          广州,深圳 广西          南宁,北海   --------- 注：仅供参考，自由扩展，希望能对有需要的人有所帮助。","title":"oracle 10g 根据a列中相同的值，获取将对应的B列中各个值合并的结果集。（使a,b形成类似父子关系）"},{"content":" 存储提纲    存储提纲被设计用来提供稳定的执行计划，以消除执行环境或者对象统计信息的改变造成的影响。因此，这个特性也被称作计划稳定性。具体的讲，存储提纲是一个提示的集合，更精确地说，所有这些提示强制查询优化器为一个给定的SQL语句，稳定地产生一个特殊的执行计划。但实践中，遗憾的是，即使使用存储提纲，还是可能观察到执行计划的改变。存储提纲不是总能提供一个稳定的执行计划，Oracle 11g自身就证实了这一点，从这个版本起，不再赞成使用存储提纲，而是推荐SQL计划基线。    存储纲要的主要使用的情况：        stored outline 就是把一个SQL语句的执行计划固定下来。比如说你SQL执行计划在测试库里运行很好，但是在生产库走了另外一个执行计划，可以把测试库的stored outline导出放到正式库中！让正式库的sql语句按照测试库的执行计划来走！          1.为避免在升级后某些sql出现严重性能下降而且在短时间内不能优化的情况，我们可以使用outline的功能将原生产库中的sql执行计划实施在新的数据库上。          2.为避免SQL的执行计划在统计数据不准确的情况（如未能及时收集表或索引的统计信息）下导致变化从而引起的性能降低。          3.避免大规模分布实施的应用出现数据库版本、配置等区别引起的优化器产生不同的执行计划。         4.某些Bug引起优化器生成较差的执行计划。在bug修复前我们可以使用outline来强制SQL的执行计划的正确。Outline的机制是将所需要的执行计划的hint保存在outline的表中。 当执行SQL时，Oracle会与outline中的SQL比较，如果该SQL有保存的outline，则通过保存的hint生成执行计划。  Outline的使用注意事项         1．Outln用户是一个非常重要的系统用户，其重要性跟sys，system一样。在任何情况下都不建议用户删除outln，否则会引起数据库错误。         2．优化器通过Outline生成执行计划前提是outline内所有hint都有效的。如：索引没有创建的前提下，索引的hint是失效的，导致该SQL的outline计划不会被使用。         3．参数Cursor_sharing=force时不能使用outline。         4．literial sql的共享程度不高，Outline针对绑定变量的sql较好。针对literial sql的情况，需要每条sql都生成outline。         5．创建outline需要有create any outline的权限。          6．要注意从CBO的角度来看，数据库表和索引的统计信息是随着数据量的变化而不断改变的。固定的执行计划在某些时段并不一定是最优的执行计划。所以outline的使用是要根据具体情况来决定的。    Outline维护          停止db使用outline功能：                alter system set use_stored_outlines=false;          disable/enable具体outline：                alter outline ol_name disable;                alter outline ol_name enable;         删除：outline category：          outline相关视图：               dba_outlines               dba_outline_hints  该视图列出outline的hints内容          检查outline是否存在：                select  name, category, owner from dba_outlines;        SQL计划基线         可以认为SQL计划基线是存储提纲的一个改进版本，事实上，SQL 计划基线不仅和存储提纲有许多相同的特性，而且也和存储提纲一样被设计用来提供稳定的执行计划，以防执行环境和对象统计信息的改变对执行计划产生影响。此外，和存储提纲类似，‘臼也可以在不修改语句的情况下调优应用程序。注意在Orade 文档中，维持执行计划的稳定性是SQL 计划基线唯一被提及的用途．由于某些未知的原因，对于也可以在不修改应用程序的情况下使用它来更改当前执行计划（涉及一条给定SQL 语句）的用法，并未提及。 SQL 计划基线是什么         SQL计划基线是一个与SQL语句相关联的对象，它被设计用来影响查询优化器产生执行计划时的决定。具体地讲，SQL计划基线主要是一个提示的集合。基本上，SQL计划基线就是用来迫使查询优化器为一条给定的SQL语句产生个特定的、稳定的执行计划。 SQL计划基线的优点之一是它应用到一条特定的SQL语句，但在使用它的时候，SQL语句自身不需要进行修改。事实上，SQL计划基线存储在数据字典中，并且查询优化器会自动选择它们．首先，SQL语句以传统的方法执行换句话说，就是要杳询优化器在没有SQL计划基线支持的条件下产生执行计划。然后，对SQL语句进行标准化，使其不区分大小写而且不受空白的影响。为标准化后的SQL语句计算生成一个签名。然后，基于此签名查询数据字典。只要发现可接受的（信任的）并且又有相同签名的SQL计划基线可用，就检查它以确定要优化的SQL语句和此SQL计划基线所指的SQL语句是否一致。这一步十分必要，因为签名是一个哈希值，因此，有可能会发生哈希冲突。如果检测是成功的，SQL计划基线中的提示将被放入执行计划的生成过程里。注意：如果有多个可用的SQL计划基线，查询优化器会选择代价最小的那个。 捕获SQL计划基线       有多种方法可用来捕获SQL计划基线。基本上，它们都是由数据库引擎自动创建或数据库管理员手动创建。下面的3 小节将分别介绍这3 种主要方法。 自动捕获        当动态初始化参数optlmlzer_capture_sql_plan_baselines设置为true的时候，查询优化器将自动创建一个新的SQL计划基线。这个初始化参数被默认设置为FALSE，可以在系统级和会话级修改它。当自动捕获开启后，查询优化器为每条重复执行过（就是至少执行过两次）的SQL 语句存储一个新的SQL 计划基线。为此．它会将每条SQL 语句的签名插入一个日志中，以便于管理。这意味着当一条SQL语句第一次执行的时候，仅把它的签名插入日志。然后，当第二次执行相同的语句的时候，如果不存在与此语句相对应的SQL计划基线，就新建一个并存储起来。如果与SQL语句相对应的SQL计划基线已经存在，查询优化器仍然会对比当前的执行计划和基于此SQL计划基线的执行计划。如果它们不匹配，那么这个描述当前执行计划的新的SQL计划基线将被存储。然而就像你在前面见到的，不能直接使用当前的执行计划。查询优化器被强制使用在SQL 计划基线的辅助下产生的执行计划。","title":"存储提纲与SQL计划基线"},{"content":"详细方法见：http://www.rongsen.com.cn/article/SQLSERVER/2012/0408/16818.html","title":"sql2008数据库转入到SQL2005数据库方法"},{"content":"今天又遇到了这个问题，实际情况如下： 1、数据库日志过大，160G，导致硬盘空间满； 2、数据库日志对我没有，不需要保存；   处理过程： 1、将数据库的模式由“完整”改为“简单”； 2、完整备份数据库；（这时不会备份日志） 3、收缩数据库； OK。","title":"SQL Server 2008 收缩数据库日志"},{"content":"1. 【启动停止服务】  //启动停止监听  lsnrctl start;          lsnrctl stop;  //启动停止服务   sqlplus orcl as sysdba;        //登录   >shutdown immediate;   >STARTUP;   或者      ps -ef|grep ora_dbw0_$ORACLE_SID      kill -9  进程号 2. 【修改字符集】   select userenv('language') from dual;  //查看字符集            、      SQL> conn sys/sys as sysdba;     SQL> shutdown immediate;     SQL> STARTUP MOUNT;     SQL> ALTER SESSION SET SQL_TRACE=TRUE;     SQL> ALTER SYSTEM ENABLE RESTRICTED SESSION;     SQL> ALTER SYSTEM SET JOB_QUEUE_PROCESSES=0;     SQL> ALTER SYSTEM SET AQ_TM_PROCESSES=0;     SQL> Alter database open;     SQL> ALTER DATABASE CHARACTER SET ZHS16GBK;   SQL> ALTER DATABASE character set INTERNAL_USE ZHS16GBK; //强转      SQL>shutdown immediate;   SQL>STARTUP; 3.【导入导出】 某用户所有表 imp mapabc_mobilemap/mapabc_mobilemap fromuser=mapabc_mobilemap file=/home/oracle/qqtdatabase1215.dmp; exp mapabc_mobilemap/mapabc_mobilemap file==/home/oracle/qqtdatabase1215.dmp; 某用户指定表 exp mapabc_mobilemap/mapabc_mobilemap tables=(tianjin_boss_base) file=D:/123test/tianjin_boss_base1130Old.dmp; 4.【创建删除表空间】 --创建临时表空间 create temporary tablespace QQT_TEMP tempfile '/home/oracle/app/oradata/orcl/qqt_temp.dbf' size 50m   autoextend on  next 50m maxsize 20480m  extent management local; --创建用户表空间 create tablespace QQT   logging   datafile '/home/oracle/app/oradata/orcl/qqt_data.dbf' size 50m   autoextend on   next 50m maxsize 20480m   extent management local;   --创建用户并制定表空间 create user mapabc_mobilemap identified by mapabc_mobilemap default tablespace QQT temporary tablespace QQT_TEMP; --给用户授予权限 grant connect,resource,dba to mapabc_mobilemap; --删除表空间 drop user mapabc_mobilemap cascade; DROP TABLESPACE QQT INCLUDING CONTENTS AND DATAFILES; DROP TABLESPACE QQT_TEMP INCLUDING CONTENTS AND DATAFILES; 5.【卸载Oracle 11g】 1.使用SQL*PLUS停止数据库 [oracle@OracleTest oracle]$ sqlplus /nolog SQL> connect / as sysdba SQL> shutdown [immediate] SQL> exit 2.停止Listener [oracle@OracleTest oracle]$ lsnrctl stop 3.停止HTTP服务 [root@OracleTest /root]# service httpd stop 4.用su或者重新登录到root(如想重新安装可以保留oracle用户，省得输入环境变量了) 5.将安装目录删除 [root@OracleTest /root]# rm -rf /u01/app/oracle/ 6.将/usr/bin下的文件删除 [root@OracleTest /root]# rm /usr/local/bin/dbhome [root@OracleTest /root]# rm /usr/local/bin/oraenv [root@OracleTest /root]# rm /usr/local/bin/coraenv 7.将/etc/oratab删除 [root@OracleTest /root]# rm /etc/oratab 8.将/etc/oraInst.loc删除 [root@OracleTest /root]# rm /etc/oraInst.loc 9.将oracle用户删除(若要重新安装,可以不删除) [root@OracleTest /root]# userdel –r oracle 10.将用户组删除(若要重新安装,可以不删除) [root@OracleTest /root]# groupdel oinstall [root@OracleTest /root]# groupdel dba 11.将启动服务删除 [root@OracleTest /root]# chkconfig --del dbora 到此为止重启后，你的Linux系统下的Oracle数据库已完全删除了！！！ 以上是CentOS5.4+Oracle 11g的环境。","title":"oracle11g 启动停止服务,修改字符集,导入导出,创建删除表空间,卸载oracle等"},{"content":"今天，群里有人说出这样的问题，修改pg_log日志后，系统将不再生成pg_log日志，后来分析了下，可能是由于通过vim修改pg_log日志，修改了文件的inode值，原有的文件已经不存在了，所以不会产生新的日志到文件中。   其实影响不大，因为第二天会产生新的日志，就会继续创建日志了；   这里可以通过设置log_file_mode = 0400；来限制只读。(通过实验发现该参数没有效果，设置之后，重启数据库，文件权限还是0600，哈哈 毕竟还是要让自己可写，要不然日志怎么产生呢。。。起码postgresql没有把自己堵死的bug。。)","title":"postgresql9.1.3的pg_log问题"},{"content":"你要登陆oracle需要用户权限，你要创建表需要表空间，为了授权方便你需要创建角色 1、首先用管理员权限的用户登录oracle数据库  sqlplus /nolog;登录oracle不打印日志，节省空间和加快反应速度 conn（或connect） sys/change_on_install as sysdba; 2、创建表空间 create tablespace 表空间名 logging datafile 'E:\\data.dbf' size 30m autoextend on next 32m maxsize 2048m extend management local; 删除表空间（保存该表空间不在使用状态） drop tablespace 表空间名 3、创建角色 create role 角色名 identified by 角色密码 受权限给角色（可以授角色给另外一个角色，也可以授权限给角色） grant resouces,connect,dba to 角色名 删除角色（保存不在使用状态） drop role 角色名 4、创建用户 create user  用户名 identified by 用户密码 default tablespace 表空间名; 授权限给用户 grant 刚创建的角色名 to 用户名 或者grant connect,dba,resouces to 用户名 伤处用户 drop user 用户名","title":"oracle 创建用户、表空间、角色"},{"content":"安装环境                      Linux服务器：SuSe10 sp2 64位                      Oracle服务器：Oracle11gR2 64位 系统要求 Linux安装Oracle系统要求   系统要求 说明 内存 必须高于1G的物理内存 交换空间 一般为内存的2倍，例如：1G的内存可以设置swap 分区为3G大小 硬盘 5G以上    2.修改操作系统核心参数 在Root用户下执行以下步骤： 1）修改用户的SHELL的限制，修改/etc/security/limits.conf文件 输入命令：vi /etc/security/limits.conf，按i键进入编辑模式，将下列内容加入该文件。 oracle   soft    nproc    2047 oracle   hard    nproc    16384 oracle   soft    nofile     1024 oracle   hard    nofile    65536 编辑完成后按Esc键，输入“:wq”存盘退出   2）修改/etc/pam.d/login 文件，输入命令：vi  /etc/pam.d/login，按i键进入编辑模式，将下列内容加入该文件。 session   required    /lib/security/pam_limits.so session   required    pam_limits.so 编辑完成后按Esc键，输入“:wq”存盘退出   3）修改linux内核，修改/etc/sysctl.conf文件，输入命令:vi  /etc/sysctl.conf ，按i键进入编辑模式，将下列内容加入该文件 fs.file-max = 6815744 fs.aio-max-nr = 1048576 kernel.shmall = 2097152 kernel.shmmax = 2147483648 kernel.shmmni = 4096 kernel.sem = 250 32000 100 128 net.ipv4.ip_local_port_range = 9000 65500 net.core.rmem_default = 4194304 net.core.rmem_max = 4194304 net.core.wmem_default = 262144 net.core.wmem_max = 1048576 编辑完成后按Esc键，输入“:wq”存盘退出   4）要使 /etc/sysctl.conf 更改立即生效，执行以下命令。 输入：sysctl  -p 显示如下： linux:~ # sysctl -p net.ipv4.icmp_echo_ignore_broadcasts = 1 net.ipv4.conf.all.rp_filter = 1 fs.file-max = 6815744 fs.aio-max-nr = 1048576 kernel.shmall = 2097152 kernel.shmmax = 2147483648 kernel.shmmni = 4096 kernel.sem = 250 32000 100 128 net.ipv4.ip_local_port_range = 9000 65500 net.core.rmem_default = 4194304 net.core.rmem_max = 4194304 net.core.wmem_default = 262144 net.core.wmem_max = 1048576   5）编辑 /etc/profile ，输入命令：vi  /etc/profile，按i键进入编辑模式，将下列内容加入该文件。 if [ $USER = \"oracle\" ]; then if [ $SHELL = \"/bin/ksh\" ]; then   ulimit -p 16384   ulimit -n 65536 else   ulimit -u 16384 -n 65536 fi fi 编辑完成后按Esc键，输入“:wq”存盘退出   6）创建相关用户和组，作为软件安装和支持组的拥有者。 创建用户，输入命令： groupadd  oinstall groupadd  dba 创建Oracle用户和密码,输入命令： useradd -g oinstall -g dba -m oracle passwd  oracle 然后会让你输入密码，密码任意输入2次，但必须保持一致，回车确认   7）创建数据库软件目录和数据文件存放目录，目录的位置，根据自己的情况来定，注意磁盘空间即可，这里我把其放到oracle用户下,例如： 输入命令： mkdir /home/oracle/app mkdir /home/oracle/app/oracle mkdir /home/oracle/app/oradata mkdir /home/oracle/app/oracle/product   8)更改目录属主为Oracle用户所有，输入命令：   chown -R oracle:oinstall /home/oracle/app   9)配置oracle用户的环境变量，首先，切换到新创建的oracle用户下, 输入：su – oracle  ，然后直接在输入 ： vi .bash_profile 按i编辑 .bash_profile,进入编辑模式，增加以下内容： umask 022 export ORACLE_BASE=/home/oracle/app export ORACLE_HOME=$ORACLE_BASE/oracle/product/11.2.0/dbhome_1 export ORACLE_SID=orcl export PATH=$PATH:$HOME/bin:$ORACLE_HOME/bin export LD_LIBRARY_PATH=$ORACLE_HOME/lib:/usr/lib export NLS_LANG=american_america.ZHS16GBK 编辑完成后按Esc键，输入“:wq”存盘退出 安装过程 1） 当上述系统要求操作全部完成后，注销系统，在图形界面以Oracle用户登陆。首先将下载的Oracle安装包复制到linux中，推荐用Xmanager 或其他ftp工具拷贝。    打开一个终端，运行unzip命令解压oracle安装文件，如： 输入命令： unzip  linux.x64_11gR2_database_1of2.zip  unzip  linux.x64_11gR2_database_2of2.zip  解压完成后 cd 进入其解压后的目录database 输入命令： cd  database 使用ls命令可以查看解压后database所包含的文件，如下图： 2） 执行安装，输入命令：./runInstaller  或./runInstaller -responseFile /home/oracle/database/response/db_install.rsp 3)  根据弹出安装窗口进行安装(安装过程中需要的依赖包可以到我的资源中下载,或到 http://rpm.pbone.net/   (下载).","title":"Linux下安装Oracle11g服务器"},{"content":"今天更新了之前的 Emacs-CGI，把其中的数据库连接模块拎出来，作为一的独立的项目：EDBC（Emacs-Lisp Database Connectivity）。项目地址：https://github.com/redraiment/edbc 文档地址：https://github.com/redraiment/edbc/wiki 现在通过抽象，edbc.el 就是定义了一个框架，规范了 elisp 中程序访问各种数据库的简洁、统一的接口。目前已经支持 MySQL 和 Sqlite 两种。并且，参考 edbc-mysql.el 能非常方便支持其他数据库！ 下面是访问 Sqlite 的样例： (edbc-with-connect ((url \"users.db\"))  (let ((id 1)        (name \"Joe\")        (nickname \"redraiment\"))    ; Purge table    (edbc delete from users)    ; Equals insert into users (id, name) values (1, 'Joe') on sqlite    (edbc insert into users (id, name) values (:id, :name))    ; Equals update users set name = 'redraiment' where id = 1 on sqlite    (edbc update users set name = :nickname where id = :(identity id))    ; Returns (((\"id\" . \"1\") (\"name\" . \"redraiment\")))    (edbc select * from users)))","title":"EDBC（Emacs-Lisp Database Connectivity）"},{"content":"实现功能： 订阅Oracle开发 板块的rss ，根据Title 排重 入库。 1. 创建rss源表以及序列。 create table rss_itpub (id number ,                            title varchar2(2000) ,                            link varchar2(2000) ,                           description varchar2(2000) ,                           category varchar2(2000) ,                           author varchar2(2000) ,                            pubDate date ,                           enclosure varchar2(4000) ,                           other varchar2(4000)                            ) ;create sequence seq_rss_itpub ; 2. 创建包 create or replace package xml_type_util is  /*    用于刷新rss_dataguru表中的数据（更新rss源）    exec xml_type_util.refresh_rss_table ;  */  procedure refresh_rss_table ;end ;/create or replace package body xml_type_util is  --rss表rss_dataguru  type t_rss_tb_list is table of rss_itpub%rowtype ;  --private function   function convert_to_DOMDocument (xmlclob  clob)  return xmldom.DOMDocument   is    parser                    xmlparser.PARSER;    result_document           xmldom.DOMDocument;  begin--    dbms_output.put_line(dbms_lob.Getlength(xmlclob)) ;    parser := xmlparser.newParser;    xmlparser.parseClob(parser, xmlclob);    result_document := xmlparser.getDocument(parser);    --set free    xmlparser.freeParser(parser);    return result_document ;  end ;  --private function 2  function parse_xml_to_record (doc xmldom.DOMDocument) return t_rss_tb_list is    lenUnit       integer;    lenItem       integer;    unitNodes     xmldom.DOMNodeList;    itemNodes     xmldom.DOMNodeList;    tempNode_unit xmldom.DOMNode;    tempNode      xmldom.DOMNode;    name          varchar2(1000);    value         varchar2(1000);    rss_tb_list   t_rss_tb_list := t_rss_tb_list() ;  begin    unitNodes := xmldom.getElementsByTagName(doc, 'item');    lenUnit   := xmldom.getLength(unitNodes);    rss_tb_list.extend(lenUnit) ;    dbms_output.put_line(lenUnit) ;    FOR i in 0 .. lenUnit - 1 LOOP     tempNode_unit := xmldom.item( unitNodes, i );         itemNodes:=xmldom.getChildNodes(tempNode_unit);      lenItem := xmldom.getLength( itemNodes );     rss_tb_list(i+1).id := seq_rss_itpub.nextval ;     --遍历子元素，暂时没有找到更好的方法，使用case when 还可以获取其他异常情况，放到other字段中     FOR j in 0..lenItem-1 LOOP         tempNode := xmldom.item( itemNodes, j );                  name := xmldom.getNodeName(tempNode);         value := xmldom.getNodeValue(xmldom.getFirstChild(tempNode));         case name          when 'title' then           rss_tb_list(i+1).title := value ;         when 'link' then           rss_tb_list(i+1).link  := value ;         when 'description' then           rss_tb_list(i+1).description := value ;         when 'category' then           rss_tb_list(i+1).category := value ;         when 'author' then           rss_tb_list(i+1).author := value ;         when 'pubDate' then           --value : Mon, 24 Dec 2012 10:58:00 +0000 regexp_replace 截取字符串 因为默认显示的是0时区时间，北京为东八区，需要加8个小时           rss_tb_list(i+1).pubDate := TO_DATE(regexp_replace(value,'.*, |\\+.+',''),'dd MON YYYY hh24:mi:ss')+8/24 ;         --附件信息         when 'enclosure' then            value := xmldom.getAttribute(xmldom.makeElement(tempNode),'url') ;           rss_tb_list(i+1).enclosure:=value ;         --其他信息，未处理的元素信息         else            rss_tb_list(i+1).other := rss_tb_list(i+1).other || ','||name||'@'||value ;         end case ;         --DBMS_output.PUT_LINE(i||j||name||value);       end loop;    end loop;    --free    xmldom.freeDocument(doc);    return rss_tb_list ;  end ;  --主函数  procedure refresh_rss_table is    --Oracle 开发 rss 地址    v_blog_url varchar2(4000) := 'http://www.itpub.net/forum.php?mod=rss'                                 ||chr(38)||'fid=3'||chr(38)||                                 'auth=004clZR9P033xjFZsM%2FJe2jTbI5m3ObYbosefQZAy11tziIeN1967GnsmVY1c34d' ;        clobs clob ;    doc xmldom.DOMDocument  ;    rss_s t_rss_tb_list ;  begin--    DBMS_LOB.CREATETEMPORARY(clobs, true);    clobs := httpuritype(v_blog_url).getClob; --获取目标url的xml内容    If Dbms_Lob.Getlength(clobs) Is Null or Dbms_Lob.Getlength(clobs) = 0 Then      --判断url是否存在      raise_application_error(-20999, 'No xml.');    End If;    doc := convert_to_DOMDocument(clobs) ;    rss_s := parse_xml_to_record(doc) ;    --如果存在相同的title，不做操作，如果表中不存在，则执行插入操作    forall i in 1 .. rss_s.last        execute immediate '      merge into rss_itpub r       using (select :1 as title ,                     :2 as link ,                     :3 as description ,                     :4 as category ,                     :5 as author ,                     :6 as pubDate,                    :7 as enclosure ,                     :8 as other ,                    :9 as id from dual )l      on (r.title=l.title)       when not matched then       insert (title,link,description,category,author,pubDate,enclosure,other,id)             values (l.title,l.link,l.description,l.category,l.author,l.pubDate,l.enclosure,l.other,l.id)'             using  rss_s(i).title,rss_s(i).link,rss_s(i).description,rss_s(i).category,rss_s(i).author,                    rss_s(i).pubDate,rss_s(i).enclosure,rss_s(i).other,rss_s(i).id ;      commit ;  end ;end;/ 3.执行 SQL> exec xml_type_util_2.refresh_rss_table ; PL/SQL procedure successfully completed 4.查询 附录ORA-24247解决办法 执行前三步 1 .create aclbegindbms_network_acl_admin.create_acl (acl => 'connect_to_world_acl.xml',description => 'CONNECT_TO_WORLD_ACL' ,principal => 'DEXTER',       is_grant => true,privilege => 'resolve');end;/commit ;2. 指定权限begindbms_network_acl_admin.add_privilege (acl => 'connect_to_world_acl.xml',principal => 'DEXTER',is_grant => true,privilege => 'connect');end;/commit ;3. 指派aclbegindbms_network_acl_admin.assign_acl(acl => 'connect_to_world_acl.xml',host => '*');end;/commit ;4. 查询select host, lower_port, upper_port, acl from dba_network_acls;select acl,       principal,       privilege,       is_grant,       to_char(start_date, 'dd-mon-yyyy') as start_date,       to_char(end_date, 'dd-mon-yyyy') as end_date  from dba_network_acl_privileges;select any_path from resource_view where any_path like '/sys/acls/%.xml';5. 删除BEGINDBMS_NETWORK_ACL_ADMIN.drop_acl (acl => 'connect_to_world_acl.xml');COMMIT;END;/ 如果想要订阅其他板块，只需要修改v_blog_url 参数即可。","title":"使用PLSQL 订阅 itpub rss源"},{"content":"====================================================== 最近在自学PL/SQL高级编程，了解到对象类型（OBJECT TYPE）。 特意搜索了一下10G官方文档，下面不才基于此进行拓展： ======================================================= 1. 介绍 Object-oriented programming is especially suited for building reusable components and complex applications. 尤其适合于构建可重用的部件和复杂的应用程序的面向对象的编程。 In PL/SQL, object-oriented programming is based on object types. 在PL / SQL，面向对象的程序设计是基于对象类型。 They let you model real-world objects, separate interfaces and implementation details, and store object-oriented data persistently in the database. 他们坚持让你模拟现实世界的对象，单独的接口和实现细节，面向对象的数据和存储在数据库中。 2. PL / SQL的声明和初始化对象 对象的类型可以代表任何真实世界的实体。例如，一个对象的类型可以代表一个学生，银行帐户，电脑屏幕上 ，合理数量，或数据结构，如队列，堆栈，或列表。 CREATE OR REPLACE TYPE address_typ AS OBJECT (       street          VARCHAR2(30),                            city            VARCHAR2(20),       state           CHAR(2),                                   postal_code     VARCHAR2(6)          ); CREATE OR REPLACE TYPE employee_typ AS OBJECT(       employee_id       NUMBER(6),       first_name        VARCHAR2(20),       last_name         VARCHAR2(25),       email             VARCHAR2(25),       phone_number      VARCHAR2(25),       hire_date         DATE,       job_id            VARCHAR2(25),                                                          salary            NUMBER(8,2),                     commission_pct    NUMBER(2,2),                                                          manager_id        NUMBER(6),                                                          department_id     NUMBER(4),                                                          address           address_typ                                                          MAP MEMBER FUNCTION get_idno RETURN NUMBER,                                                          MEMBER PROCEDURE display_address(SELF IN OUT NOCOPY employee_typ)       );                                               --创建对象体 CREATE TYPE BODY employee_typ AS  MAP MEMBER FUNCTION get_idno RETURN NUMBER IS  BEGIN    RETURN employee_id;  END;  MEMBER PROCEDURE display_address ( SELF IN OUT NOCOPY employee_typ ) IS  BEGIN    DBMS_OUTPUT.PUT_LINE(first_name || ' '  || last_name);    DBMS_OUTPUT.PUT_LINE(address.street);    DBMS_OUTPUT.PUT_LINE(address.city || ', '  || address.state || ' ' ||                         address.postal_code);     END;END; --持久化对象 CREATE TABLE employee_tab OF employee_typ;CREATE TYPE  emp_typ as table of employee_typ; 3.  在PL/SQL块中声明对象： DECLARE  emp employee_typ; -- emp is atomically nullBEGIN-- call the constructor for employee_typ  emp := employee_typ(315, 'Francis', 'Logan', 'FLOGAN',        '555.777.2222', to_date('2012-12-24', 'yyyy-mm-dd'), 'SA_MAN', 11000, .15, 101, 110,         address_typ('376 Mission', 'San Francisco', 'CA', '94222'));  DBMS_OUTPUT.PUT_LINE(emp.first_name || ' ' || emp.last_name); -- display details  emp.display_address();  -- call object method to display detailsEND; 4.  PL/SQL如何处理未初始化的对象： DECLARE  emp employee_typ; -- emp is atomically nullBEGIN  IF emp IS NULL THEN DBMS_OUTPUT.PUT_LINE('emp is NULL #1'); END IF;  IF emp.employee_id IS NULL THEN     DBMS_OUTPUT.PUT_LINE('emp.employee_id is NULL #1');  END IF;  emp.employee_id := 330;  IF emp IS NULL THEN DBMS_OUTPUT.PUT_LINE('emp is NULL #2'); END IF;  IF emp.employee_id IS NULL THEN    DBMS_OUTPUT.PUT_LINE('emp.employee_id is NULL #2');  END IF;  emp := employee_typ(NULL, NULL, NULL, NULL,        NULL, NULL, NULL, NULL, NULL, NULL, NULL,         address_typ(NULL, NULL, NULL, NULL));  -- emp := NULL; -- this would have made the following IF statement TRUE  IF emp IS NULL THEN DBMS_OUTPUT.PUT_LINE('emp is NULL #3'); END IF;  IF emp.employee_id IS NULL THEN    DBMS_OUTPUT.PUT_LINE('emp.employee_id is NULL #3');  END IF;EXCEPTION   WHEN ACCESS_INTO_NULL THEN     DBMS_OUTPUT.PUT_LINE('Cannot assign value to NULL object');END; 5. 在PL/SQL中操纵对象： 5.1.调用对象构造器和方法（Calling Object Constructors and Methods） DECLARE  emp employee_typ;BEGIN  INSERT INTO employee_tab VALUES (employee_typ(310, 'Evers', 'Boston', 'EBOSTON',   '555.111.2222', to_date('2012-12-24', 'yyyy-mm-dd'), 'SA_REP', 9000, .15, 101, 110,    address_typ('123 Main', 'San Francisco', 'CA', '94111')) );  INSERT INTO employee_tab VALUES (employee_typ(320, 'Martha', 'Dunn', 'MDUNN',    '555.111.3333', to_date('2012-11-5', 'yyyy-mm-dd'), 'AC_MGR', 12500, 0, 101, 110,    address_typ('123 Broadway', 'Redwood City', 'CA', '94065')) );END; 5.2  更新和删除对象： DECLARE  emp employee_typ;BEGIN  INSERT INTO employee_tab VALUES (employee_typ(370, 'Robert', 'Myers', 'RMYERS',   '555.111.2277', to_date('2012-3-7', 'yyyy-mm-dd'), 'SA_REP', 8800, .12, 101, 110,    address_typ('540 Fillmore', 'San Francisco', 'CA', '94011')) );  UPDATE employee_tab e SET e.address.street = '1040 California'     WHERE e.employee_id = 370;  DELETE FROM employee_tab e WHERE e.employee_id = 310;END; 6.  通过REF修饰符操纵对象： DECLARE  emp           employee_typ;  emp_ref   REF employee_typ;  emp_name      VARCHAR2(50);BEGIN  SELECT REF(e) INTO emp_ref FROM employee_tab e WHERE e.employee_id = 370;-- the following assignment raises an error, not allowed in PL/SQL-- emp_name := emp_ref.first_name || ' ' || emp_ref.last_name;-- emp := DEREF(emp_ref); not allowed, cannot use DEREF in procedural statements  SELECT DEREF(emp_ref) INTO emp FROM DUAL; -- use dummy table DUAL  emp_name := emp.first_name || ' ' || emp.last_name;  DBMS_OUTPUT.PUT_LINE(emp_name);END; 7. 定义相当于PL/SQL集合类型的SQL类型（Defining SQL Types Equivalent to PL/SQL Collection Types） 7.1 定义嵌套表： --建嵌套表类型 CREATE TYPE CourseList AS TABLE OF VARCHAR2(10)  -- define type --建对象类型 CREATE TYPE student AS OBJECT (  -- create object    id_num  INTEGER(4),    name    VARCHAR2(25),    address VARCHAR2(35),    status  CHAR(2),    courses CourseList);  -- declare nested table as attribute --建立嵌套表类型表 CREATE TABLE sophomores of student   NESTED TABLE courses STORE AS courses_nt; --插入数据 insert into sophomores values(1,'dylan','CARL STREET','ACTIVE',        CourseList('MATH1020')       ); --查询 SELECT  a.*, b.* from  sophomores a, TABLE(a.courses) b; select /*+ nested_table_get_refs */ * from courses_nt t; 7.2 定义数组： -- 声明数组类型（Each project has a 16-character code name） -- We will store up to 50 projects at a time in a database column. CREATE TYPE ProjectList AS VARRAY(50) OF VARCHAR2(16); --创建表 CREATE TABLE dept_projects (  -- create database table    dept_id  NUMBER(2),    name     VARCHAR2(15),    budget   NUMBER(11,2), -- Each department can have up to 50 projects.    projects ProjectList); --插入数据：   INSERT INTO dept_projects     VALUES(60, 'Security', 750400,       ProjectList('New Badges', 'Track Computers', 'Check Exits')); 8.  在动态SQL中使用对象： 8.1 定义对象类型person_typ和数组类型hobbies_var,并创建报TEAMS: CREATE TYPE person_typ AS OBJECT (name VARCHAR2(25), age NUMBER);CREATE TYPE hobbies_var AS VARRAY(10) OF VARCHAR2(25);CREATE OR REPLACE PACKAGE teams   AUTHID CURRENT_USER AS   PROCEDURE create_table (tab_name VARCHAR2);   PROCEDURE insert_row (tab_name VARCHAR2, p person_typ, h hobbies_var);   PROCEDURE print_table (tab_name VARCHAR2);END;CREATE OR REPLACE PACKAGE BODY teams AS   PROCEDURE create_table (tab_name VARCHAR2) IS   BEGIN      EXECUTE IMMEDIATE 'CREATE TABLE ' || tab_name ||                        ' (pers person_typ, hobbs hobbies_var)';   END;   PROCEDURE insert_row (      tab_name VARCHAR2,      p person_typ,      h hobbies_var) IS   BEGIN      EXECUTE IMMEDIATE 'INSERT INTO ' || tab_name ||         ' VALUES (:1, :2)' USING p, h;   END;   PROCEDURE print_table (tab_name VARCHAR2) IS      TYPE  refcurtyp IS REF CURSOR;      v_cur refcurtyp;      p     person_typ;      h     hobbies_var;   BEGIN      OPEN v_cur FOR 'SELECT pers, hobbs FROM ' || tab_name;      LOOP         FETCH v_cur INTO p, h;         EXIT WHEN v_cur%NOTFOUND;         -- print attributes of 'p' and elements of 'h'         DBMS_OUTPUT.PUT_LINE('Name: ' || p.name || ' - Age: ' || p.age);         FOR i IN h.FIRST..h.LAST         LOOP           DBMS_OUTPUT.PUT_LINE('Hobby(' || i || '): ' || h(i));         END LOOP;      END LOOP;      CLOSE v_cur;   END;END; 8.2 调用TEAMS包中的存储过程： DECLARE   team_name VARCHAR2(15);BEGIN   team_name := 'Notables';   TEAMS.create_table(team_name);   TEAMS.insert_row(team_name, person_typ('John', 31),      hobbies_var('skiing', 'coin collecting', 'tennis'));   TEAMS.insert_row(team_name, person_typ('Mary', 28),      hobbies_var('golf', 'quilting', 'rock climbing', 'fencing'));   TEAMS.print_table(team_name);END; ================================================= output: Name: John - Age: 31 Hobby(1): skiing Hobby(2): coin collecting Hobby(3): tennis Name: Mary - Age: 28 Hobby(1): golf Hobby(2): quilting Hobby(3): rock climbing Hobby(4): fencing PL/SQL 过程已成功完成。 ======================== Powered  By  Dylan ========================","title":"Oracle TYPE OBJECT详解"},{"content":"Oracle 10g RAC RMAN backup Example  Closed database and delete datafile [oracle@racnode1 backup]$ srvctl stop database -d racdb[oracle@racnode1 backup]$ asmcmdASMCMD> lsDATADG/FLASHDG/ASMCMD> cd datadgASMCMD> lsRACDB/ASMCMD> cd racdbASMCMD> lsCONTROLFILE/DATAFILE/ONLINELOG/PARAMETERFILE/TEMPFILE/spfileracdb.oraASMCMD> cd PARAMETERFILEASMCMD> lsspfile.268.802541131ASMCMD> cd ..ASMCMD> cd datafileASMCMD> lsEXAMPLE.264.802540751SYSAUX.257.802540615SYSTEM.256.802540615UNDOTBS1.258.802540615UNDOTBS2.265.802540981UNDOTBS3.269.802888323USERS.259.802540615ASMCMD> rm EXAMPLE.264.802540751ASMCMD> rm *You may delete multiple files and/or directories. Are you sure? (y/n) yASMCMD> lsasmcmd: entry 'datafile' does not exist in directory '+datadg/racdb/'ASMCMD> Start racnode1, racnode2, racnode3 instance to mount state [oracle@racnode1 ~]$ sqlplus / as sysdbaSQL*Plus: Release 10.2.0.5.0 - Production on Tue Dec 25 15:47:31 2012Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.Connected to an idle instance.SQL> startupORACLE instance started.Total System Global Area  599785472 bytesFixed Size\t\t    2098112 bytesVariable Size\t\t  201329728 bytesDatabase Buffers\t  390070272 bytesRedo Buffers\t\t    6287360 bytesDatabase mounted.ORA-01157: cannot identify/lock data file 1 - see DBWR trace fileORA-01110: data file 1: '+DATADG/racdb/datafile/system.256.802540615'SQL> [oracle@racnode2 ~]$ sqlplus / as sysdbaSQL*Plus: Release 10.2.0.5.0 - Production on Tue Dec 25 15:47:55 2012Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.Connected to an idle instance.SQL> startupORACLE instance started.Total System Global Area  599785472 bytesFixed Size\t\t    2098112 bytesVariable Size\t\t  197135424 bytesDatabase Buffers\t  394264576 bytesRedo Buffers\t\t    6287360 bytesDatabase mounted.ORA-01157: cannot identify/lock data file 1 - see DBWR trace fileORA-01110: data file 1: '+DATADG/racdb/datafile/system.256.802540615'SQL> [oracle@racnode3 ~]$ sqlplus / as sysdbaSQL*Plus: Release 10.2.0.5.0 - Production on Tue Dec 25 15:48:11 2012Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.Connected to an idle instance.SQL> startupORACLE instance started.Total System Global Area  599785472 bytesFixed Size\t\t    2098112 bytesVariable Size\t\t  163580992 bytesDatabase Buffers\t  427819008 bytesRedo Buffers\t\t    6287360 bytesDatabase mounted.ORA-01157: cannot identify/lock data file 1 - see DBWR trace fileORA-01110: data file 1: '+DATADG/racdb/datafile/system.256.802540615'SQL> recovery database [oracle@racnode1 backup]$ rman target /Recovery Manager: Release 10.2.0.5.0 - Production on Tue Dec 25 16:01:30 2012Copyright (c) 1982, 2007, Oracle.  All rights reserved.connected to target database: RACDB (DBID=800157471, not open)RMAN> run{2> restore database;3> recover database;4> alter database open;5> }Starting restore at 2012-12-25 16:01:47using target database control file instead of recovery catalogallocated channel: ORA_DISK_1channel ORA_DISK_1: sid=861 instance=racdb1 devtype=DISKallocated channel: ORA_DISK_2channel ORA_DISK_2: sid=868 instance=racdb2 devtype=DISKallocated channel: ORA_DISK_3channel ORA_DISK_3: sid=861 instance=racdb3 devtype=DISKchannel ORA_DISK_1: starting datafile backupset restorechannel ORA_DISK_1: specifying datafile(s) to restore from backup setrestoring datafile 00001 to +DATADG/racdb/datafile/system.269.802972261channel ORA_DISK_1: reading from backup piece /u01/app/oracle/backup/RACDB_LVL0_20121225_01ntomb3_s1_p1channel ORA_DISK_2: starting datafile backupset restorechannel ORA_DISK_2: specifying datafile(s) to restore from backup setrestoring datafile 00003 to +DATADG/racdb/datafile/sysaux.265.802972263restoring datafile 00004 to +DATADG/racdb/datafile/users.257.802972267restoring datafile 00006 to +DATADG/racdb/datafile/undotbs2.259.802972265channel ORA_DISK_2: reading from backup piece /u01/app/oracle/backup/RACDB_LVL0_20121225_02ntomb3_s2_p1channel ORA_DISK_3: starting datafile backupset restorechannel ORA_DISK_3: specifying datafile(s) to restore from backup setrestoring datafile 00002 to +DATADG/racdb/datafile/undotbs1.256.802972267restoring datafile 00005 to +DATADG/racdb/datafile/example.258.802972265restoring datafile 00007 to +DATADG/racdb/datafile/undotbs3.264.802972269channel ORA_DISK_3: reading from backup piece /u01/app/oracle/backup/RACDB_LVL0_20121225_03ntomb3_s3_p1channel ORA_DISK_3: restored backup piece 1piece handle=/u01/app/oracle/backup/RACDB_LVL0_20121225_03ntomb3_s3_p1 tag=DB_INC0channel ORA_DISK_3: restore complete, elapsed time: 00:01:24channel ORA_DISK_1: restored backup piece 1piece handle=/u01/app/oracle/backup/RACDB_LVL0_20121225_01ntomb3_s1_p1 tag=DB_INC0channel ORA_DISK_1: restore complete, elapsed time: 00:01:50channel ORA_DISK_2: restored backup piece 1piece handle=/u01/app/oracle/backup/RACDB_LVL0_20121225_02ntomb3_s2_p1 tag=DB_INC0channel ORA_DISK_2: restore complete, elapsed time: 00:01:49Finished restore at 2012-12-25 16:03:45Starting recover at 2012-12-25 16:03:45using channel ORA_DISK_1using channel ORA_DISK_2using channel ORA_DISK_3channel ORA_DISK_1: starting incremental datafile backupset restorechannel ORA_DISK_1: specifying datafile(s) to restore from backup setdestination for restore of datafile 00001: +DATADG/racdb/datafile/system.269.802972261channel ORA_DISK_1: reading from backup piece /u01/app/oracle/backup/RACDB_LVL1_20121225_0anton25_s10_p1channel ORA_DISK_2: starting incremental datafile backupset restorechannel ORA_DISK_2: specifying datafile(s) to restore from backup setdestination for restore of datafile 00003: +DATADG/racdb/datafile/sysaux.265.802972263destination for restore of datafile 00004: +DATADG/racdb/datafile/users.257.802972267destination for restore of datafile 00006: +DATADG/racdb/datafile/undotbs2.259.802972265channel ORA_DISK_2: reading from backup piece /u01/app/oracle/backup/RACDB_LVL1_20121225_0bnton25_s11_p1channel ORA_DISK_3: starting incremental datafile backupset restorechannel ORA_DISK_3: specifying datafile(s) to restore from backup setdestination for restore of datafile 00002: +DATADG/racdb/datafile/undotbs1.256.802972267destination for restore of datafile 00005: +DATADG/racdb/datafile/example.258.802972265destination for restore of datafile 00007: +DATADG/racdb/datafile/undotbs3.264.802972269channel ORA_DISK_3: reading from backup piece /u01/app/oracle/backup/RACDB_LVL1_20121225_0cnton25_s12_p1channel ORA_DISK_1: restored backup piece 1piece handle=/u01/app/oracle/backup/RACDB_LVL1_20121225_0anton25_s10_p1 tag=DB_INC1channel ORA_DISK_1: restore complete, elapsed time: 00:00:00channel ORA_DISK_2: restored backup piece 1piece handle=/u01/app/oracle/backup/RACDB_LVL1_20121225_0bnton25_s11_p1 tag=DB_INC1channel ORA_DISK_2: restore complete, elapsed time: 00:00:02channel ORA_DISK_3: restored backup piece 1piece handle=/u01/app/oracle/backup/RACDB_LVL1_20121225_0cnton25_s12_p1 tag=DB_INC1channel ORA_DISK_3: restore complete, elapsed time: 00:00:02starting media recoveryarchive log thread 1 sequence 20 is already on disk as file /u01/app/oracle/arch/1_20_802540708.dbfchannel ORA_DISK_1: starting archive log restore to default destinationchannel ORA_DISK_1: restoring archive logarchive log thread=1 sequence=19channel ORA_DISK_1: reading from backup piece /u01/app/oracle/backup/RACDB_ARCH_20121225_0dnton3c_s13_p1channel ORA_DISK_2: starting archive log restore to default destinationchannel ORA_DISK_3: starting archive log restore to default destinationchannel ORA_DISK_2: restoring archive logarchive log thread=2 sequence=11channel ORA_DISK_2: reading from backup piece /u01/app/oracle/backup/RACDB_ARCH_20121225_0enton3c_s14_p1channel ORA_DISK_3: restoring archive logarchive log thread=3 sequence=4channel ORA_DISK_3: reading from backup piece /u01/app/oracle/backup/RACDB_ARCH_20121225_0fnton3c_s15_p1channel ORA_DISK_1: restored backup piece 1piece handle=/u01/app/oracle/backup/RACDB_ARCH_20121225_0dnton3c_s13_p1 tag=ARCH_INC1channel ORA_DISK_1: restore complete, elapsed time: 00:00:01archive log filename=/u01/app/oracle/arch/1_19_802540708.dbf thread=1 sequence=19media recovery complete, elapsed time: 00:00:05channel ORA_DISK_2: restored backup piece 1piece handle=/u01/app/oracle/backup/RACDB_ARCH_20121225_0enton3c_s14_p1 tag=ARCH_INC1channel ORA_DISK_2: restore complete, elapsed time: 00:00:06channel ORA_DISK_3: restored backup piece 1piece handle=/u01/app/oracle/backup/RACDB_ARCH_20121225_0fnton3c_s15_p1 tag=ARCH_INC1channel ORA_DISK_3: restore complete, elapsed time: 00:00:06Finished recover at 2012-12-25 16:03:58database openedRMAN> validate [oracle@racnode1 ~]$ srvctl start service -d racdb -s zwc[oracle@racnode1 ~]$ sqlplus /nologSQL*Plus: Release 10.2.0.5.0 - Production on Tue Dec 25 16:12:08 2012Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.SQL> conn hr/hr@racdbConnected.SQL> conn hr/hr@racdb1Connected.SQL> conn hr/hr@racdb2Connected.SQL> conn hr/hr@racdb3Connected.SQL> select to_char(sysdate,'yyyy-mm-dd hh24:mi:ss') dt from dual;DT-------------------2012-12-25 16:12:36SQL> SQL> !crs_stat -t -vName           Type           R/RA   F/FT   Target    State     Host        ----------------------------------------------------------------------ora.racdb.db   application    0/0    0/1    ONLINE    ONLINE    racnode2    ora....b1.inst application    0/5    0/0    ONLINE    ONLINE    racnode1    ora....b2.inst application    0/5    0/0    ONLINE    ONLINE    racnode2    ora....b3.inst application    0/5    0/0    ONLINE    ONLINE    racnode3    ora.....zwc.cs application    0/0    0/1    ONLINE    ONLINE    racnode1    ora....db1.srv application    0/0    0/0    ONLINE    ONLINE    racnode1    ora....SM1.asm application    0/5    0/0    ONLINE    ONLINE    racnode1    ora....E1.lsnr application    0/5    0/0    ONLINE    ONLINE    racnode1    ora....de1.gsd application    0/5    0/0    ONLINE    ONLINE    racnode1    ora....de1.ons application    0/3    0/0    ONLINE    ONLINE    racnode1    ora....de1.vip application    0/0    0/0    ONLINE    ONLINE    racnode1    ora....SM2.asm application    0/5    0/0    ONLINE    ONLINE    racnode2    ora....E2.lsnr application    0/5    0/0    ONLINE    ONLINE    racnode2    ora....de2.gsd application    0/5    0/0    ONLINE    ONLINE    racnode2    ora....de2.ons application    0/3    0/0    ONLINE    ONLINE    racnode2    ora....de2.vip application    0/0    0/0    ONLINE    ONLINE    racnode2    ora....SM3.asm application    0/5    0/0    ONLINE    ONLINE    racnode3    ora....E3.lsnr application    0/5    0/0    ONLINE    ONLINE    racnode3    ora....de3.gsd application    0/5    0/0    ONLINE    ONLINE    racnode3    ora....de3.ons application    0/3    0/0    ONLINE    ONLINE    racnode3    ora....de3.vip application    0/0    0/0    ONLINE    ONLINE    racnode3    SQL> select INSTANCE_NAME,HOST_NAME,VERSION,TO_CHAR(STARTUP_TIME,'YYYY-MM-DD HH24:MI:SS') DT,STATUS,ACTIVE_STATE,INSTANCE_ROLE,DATABASE_STATUS from gv$INSTANCE;INSTANCE_NAME\t HOST_NAME  VERSION\t      DT\t\t  STATUS       ACTIVE_ST INSTANCE_ROLE\t    DATABASE_STATUS---------------- ---------- ----------------- ------------------- ------------ --------- ------------------ -----------------racdb2\t\t racnode2   10.2.0.5.0\t      2012-12-25 16:08:08 OPEN\t       NORMAL\t PRIMARY_INSTANCE   ACTIVEracdb1\t\t racnode1   10.2.0.5.0\t      2012-12-25 16:08:07 OPEN\t       NORMAL\t PRIMARY_INSTANCE   ACTIVEracdb3\t\t racnode3   10.2.0.5.0\t      2012-12-25 16:08:08 OPEN\t       NORMAL\t PRIMARY_INSTANCE   ACTIVE","title":"Oracle 10g RAC RMAN recovery Example"},{"content":"架构图 Replication原理    Mysql 的 Replication 是一个异步的复制过程，从一个MySQL节点（称之为Master）复制到另一个MySQL节点（称之Slave）。在 Master 与 Slave 之间的实现整个复制过程主要由三个线程来完成，其中两个线程（SQL 线程和 I/O 线程）在 Slave 端，另外一个线程（I/O 线程）在 Master 端。     要实现 MySQL 的 Replication ，首先必须打开 Master 端的 Binary Log，因为整个复制过程实际上就是 Slave 从 Master 端获取该日志然后再在自己身上完全顺序的执行日志中所记录的各种操作。     看上去MySQL的Replication原理非常简单，总结一下：       * 每个从仅可以设置一个主。      * 主在执行sql之后，记录二进制log文件（bin-log）。      * 从连接主，并从主获取binlog，存于本地relay-log，并从上次记住的位置起执行sql，一旦遇到错误则停止同步。      从这几条Replication原理来看，可以有这些推论：       * 主从间的数据库不是实时同步，就算网络连接正常，也存在瞬间，主从数据不一致。      * 如果主从的网络断开，从会在网络正常后，批量同步。      * 如果对从进行修改数据，那么很可能从在执行主的bin-log时出现错误而停止同步，这个是很危险的操作。所以一般情况下，非常小心的修改从上的数据。      * 一个衍生的配置是双主，互为主从配置，只要双方的修改不冲突，可以工作良好。      * 如果需要多主的话，可以用环形配置，这样任意一个节点的修改都可以同步到所有节点。      主从设置     因为原理比较简单，所以Replication从MySQL 3就支持，并在所有平台下可以工作，多个MySQL节点甚至可以不同平台，不同版本，不同局域网。做Replication配置包括用户和my.ini（linux下为my.cnf）两处设置。     首先在主MySQL节点上，为slave创建一个用户：     GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'slave'@'192.168.1.10' IDENTIFIED BY 'slave';     实际上，为支持主从动态同步，或者手动切换，一般都是在所有主从节点上创建好这个用户。然后就是MySQL本身的配置了，这需要修改my.cnf或者my.ini文件。在mysqld这一节下面增加：     server-id=1     auto-increment-increment=2      auto-increment-offset=1      log-bin      binlog-do-db=mstest      binlog_format=mixed     master-host=192.168.1.62     master-user=slave      master-password=slave      replicate-do-db=mstest     上面这两段设置，前一段是为主而设置，后一段是为从设置的。也就是说在两个MySQL节点上，各加一段就好。binlog-do-db和 replicate-do-db就是设置相应的需要做同步的数据库了，auto-increment-increment和auto- increment-offset是为了支持双主而设置的（参考下一节），在只做主从的时候，也可以不设置。     双主的设置     从原理论来看MySQL也支持双主的设置，即两个MySQL节点互为主备，不过虽然理论上，双主只要数据不冲突就可以工作的很好，但实际情况中还 是很容发生数据冲突的，比如在同步完成之前，双方都修改同一条记录。因此在实际中，最好不要让两边同时修改。即逻辑上仍按照主从的方式工作。但双主的设置 仍然是有意义的，因为这样做之后，切换主备会变的很简单。因为在出现故障后，如果之前配置了双主，则直接切换主备会很容易。    双主在设置时，只需将上面的一段设置复制一份，分别写入两个MySQL节点的配置文件，但要修改相应的server-id，auto- increment-offset和master-host。auto-increment-offset就是为了让双主同时在一张表中进行添加操作时不 会出现id冲突，所以在两个节点上auto-increment-offset设置为不同的值就好。  另：不要忘了，在两个节点上都为对方创建用户。  应用层的负载均衡  本文只介绍了MySQL自身的Repilication配置，在上面的图中也可以看出，有了Replication，还需要应用层（或者中间件）做一个负载均衡，这样才能最大程度发挥MySQL Replication的优势，这些将在以后探讨。 Mysql的 Replication 是一个异步的复制过程，从一个 Mysql instace(我们称之为 Master)复制到另一个 Mysql instance(我们称之 Slave)。在 Master 与 Slave 之间的实现整个复制过程主要由三个线程来完成，其中两个线程(Sql线程和IO线程)在 Slave 端，另外一个线程(IO线程)在 Master 端。 　　要实现 MySQL 的 Replication ，首先必须打开 Master 端的Binary Log(mysql-bin.xxxxxx)功能，否则无法实现。因为整个复制过程实际上就是Slave从Master端获取该日志然后再在自己身上完全 顺序的执行日志中所记录的各种操作。打开 MySQL 的 Binary Log 可以通过在启动 MySQL Server 的过程中使用 “—log-bin” 参数选项，或者在 my.cnf 配置文件中的 mysqld 参数组([mysqld]标识后的参数部分)增加 “log-bin” 参数项。 　　MySQL 复制的基本过程如下： 　　1. Slave 上面的IO线程连接上 Master，并请求从指定日志文件的指定位置(或者从最开始的日志)之后的日志内容; 　 　2. Master 接收到来自 Slave 的 IO 线程的请求后，通过负责复制的 IO 线程根据请求信息读取指定日志指定位置之后的日志信息，返回给 Slave 端的 IO 线程。返回信息中除了日志所包含的信息之外，还包括本次返回的信息在 Master 端的 Binary Log 文件的名称以及在 Binary Log 中的位置; 　　3. Slave 的 IO 线程接收到信息后，将接收到的日志内容依次写入到 Slave 端的Relay Log文件(mysql-relay-bin.xxxxxx)的最末端，并将读取到的Master端的bin-log的文件名和位置记录到master- info文件中，以便在下一次读取的时候能够清楚的高速Master“我需要从某个bin-log的哪个位置开始往后的日志内容，请发给我” 　 　4. Slave 的 SQL 线程检测到 Relay Log 中新增加了内容后，会马上解析该 Log 文件中的内容成为在 Master 端真实执行时候的那些可执行的 Query 语句，并在自身执行这些 Query。这样，实际上就是在 Master 端和 Slave 端执行了同样的 Query，所以两端的数据是完全一样的。","title":"Mysql主从同步架构图和原理"},{"content":"mysql主从热备有2种配置方式,备份某些库或者忽略备份某些库,建议选择后者 master机器 以下是代码片段： vi my.cnf,添加下面的   log-bin   server-id       = 1   #sql-bin-update-same   binlog-do-db=mysql   //备份的数据库名,可以添加多个或者  slave机器 以下是代码片段： log-bin   server-id       = 2   #sql-bin-update-same   master-host=192.168.8.201   master-user=backup   master-password=123456   master-port=3306   master-connect-retry=10   replicate-do-db=mysql   #log-slave-updates   或者 master机器 以下是代码片段： server-id       = 1   expire-logs-days = 7   binlog-ignore-db=test  slave机器 以下是代码片段： server-id       = 2   master-host=192.168.8.201   master-user=backup   master-password=123456   master-port=3306   master-connect-retry=10   expire-logs-days = 7   replicate-ignore-db=test   在master机器上面授权: 以下是代码片段： mysql>GRANT all ON *.* TO backup@192.168.8.202 IDENTIFIED BY \"123456\";  到此为止配置完成了(第一次配置需要重启mysql),剩下的工作就是再主从热备开始前保持主从的数据完全一致: 对于myisam的表,直接把master机器mysql/data目录下面的所有文件同步到slave机器对应的目录即可 对应innodb的表,不能直接同步文件,需要用mysqldump导出数据,然后在slave机器上面导入即可 注意在同步数据期间,master机器锁表成只读模式: 以下是代码片段： mysql>flush tables with read lock;  这期间主从mysql都可以不停,数据同步完毕之后,再master机器上查看mysqlbinglog和偏移量,例如: 以下是代码片段： mysql> show master status;   +---------------------+----------+--------------+------------------+   | File                | Position | Binlog_Do_DB | Binlog_Ignore_DB |   +---------------------+----------+--------------+------------------+   | mysql-bin.000012    |  4117873 |              | test             |   +---------------------+----------+--------------+------------------+  然后在slave机器上面修改成对应的日志文件和偏移量即可: 以下是代码片段： mysql>slave stop;   mysql> CHANGE MASTER TO       ->     MASTER_LOG_FILE=’mysql-bin.000012’,       ->     MASTER_LOG_POS=4117873;   mysql>slave start;   最后master解锁:  以下是代码片段： mysql> unlock tables;  至此mysql主从热备就可以正常工作了. 还有一种简单的方法,但是必须要停止mysql: 删除master机器下面的所有日志文件,删除slave机器的所有日志文件和relay-log.info及master.info 然后同步数据保持主从数据一致,最后先启动slave的mysql后启动master的mysql即可. 附录: 关于innodb的独享表空间存储(解决ibdata1超大的问题) 配置my.cnf 加入 innodb_file_per_table 以下是代码片段： [mysqld]   innodb_file_per_table InnoDB管理数据库文件的方式比较独特，它使用 tablespace 来管理数据文件。当使用 Per-Table Tablespaces，也就是每个InnoDB表都使用单独的tablespace时，数据文件的管理方式和MyISAM类型的表差不多，在这种情况下，每个数据库表都对应到一个数据文件，当分表比较多时，数据库文件也会比较多；相反,当没有启用Per-Table Tablespaces，则所有的InnoDB表的数据存在同一个tablespace中，tablespace对应到一系列的数据文件，此时，我们必须指定数据库文件的路径和大小，仅有最后一个文件可以是自动扩展的，其它的必须是固定大小(比如2G)。由于InnoDB的数据文件只会增长不会收缩(即使删除数据或者drop表),所以当前面指定的固定大小的文件写满了之后，最后一个自动扩展的文件就会一直增长而导致一个超大的文件的出现，这对于有最大文件限制的系统上就会导致问题。 我同时了遇到磁盘分区写满和最后一个数据文件超大的问题，根据MySQL手册中对InnoDB数据文件维护的说明： 1. 对于最后一个文件超大的问题，可以计算出最后一个文件的大小(按M计算的大小取整，即字节数除以1024^2)，然后修改配置，把最后一个文件大小设置为该值，然后在其后继续追加新的数据文件。 2. 对于磁盘写满的问题，可以把新的数据文件配置到其它分区，或者把以后的文件mv到其它分区，在配置文件中写数据文件的全路径 由于配置文件中指定的数据文件的大小和数据文件每次增长的大小都以M来指定，所以最后一个文件按M计算应该得到一个整数，一般不存在小数舍入取整的问题。 转移数据文件到其他分区应该用mv而不是cp，因为mv不会改变数据文件的创建时间，MySQL在启动时会比对log文件和数据文件的时间戳，如果两者不一致，则会启动失败。 相关配置选项 1. 使用Per-table tablespace 以下是代码片段： [mysqld]   innodb_file_per_table 2. 配置数据文件到不同分区 以下是代码片段： innodb_data_home_dir = /   innodb_data_file_path = data1/ibdata1:10M;data2/ibdata2:10M:autoextend ","title":"mysql主从热备"},{"content":"SSIS以及ETL介绍 ETL的选择 SSIS 导入和导出工具 T-SQL BCP实用工具 复制 什么是SSIS SSIS是SQLServer的一个组件，作为SQLServer最重要的ETL操作平台，包含了控制流引擎和数据流引擎。SSIS最小的但是是包（package），包可以单独部署。比包更大的是SSIS项目，一个项目可以包含多个包，项目可以部署到SSIS Catalog。SQLServer 2000版本的DTS包不能直接升级到package，SQLServer 2005 以及以后的版本都可以使用向导升级工具来生成新版本的包。 浏览源数据 为什么要浏览源数据 理解业务数据 业务数据需要展现的内容是什么 怎样注释业务值和代码 业务实体之间的关系 检查源数据 数据的数据类型以及长度 数据的大小以及疏散程度 数据质量问题 实施数据流 链接管理器（connection manager） 能链接到一个数据源或者数据目标 桥接器（ADO.NET，OLE DB，等） 连接字符串 验证 项目级别或者是包的级别 项目级别的管理器 可以供项目内所有的对象使用 在解决方案浏览器里面显示 包级别的管理器 供包内的对象使用 只在包内显示 数据流 在大多数的SSIS包中，数据流都是最重要的环节。在数据流中，我们可以对数据进行转换，清洗以及加载。大致可以分为6类处理 行的转换 行组的转换 分割和连接转换 审计 数据清洗 自定义操作 优化数据流的效率 优化查询 仅查询需要的行和列 避免不必要的排序 尽量使用已排序的数据 把IsSorted属性设置为可用 配置控件属性 缓存的大小 临时文件储存 并行 优化模式  ","title":"数据仓库实施之三 使用SSIS创建ETL解决方案"},{"content":"Database Version: 10.2.0.5 3nodes Verify the databases are in archivelog mode and archive destination racnode1 [oracle@racnode1 arch]$ sqlplus / as sysdbaSQL*Plus: Release 10.2.0.5.0 - Production on Tue Dec 25 14:31:03 2012Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.Connected to:Oracle Database 10g Enterprise Edition Release 10.2.0.5.0 - 64bit ProductionWith the Partitioning, Real Application Clusters, OLAP, Data Miningand Real Application Testing optionsSQL> archive log listDatabase log mode\t       Archive ModeAutomatic archival\t       EnabledArchive destination\t       /u01/app/oracle/archOldest online log sequence     17Next log sequence to archive   18Current log sequence\t       18 racnode2 [oracle@racnode2 arch]$ sqlplus / as sysdbaSQL*Plus: Release 10.2.0.5.0 - Production on Tue Dec 25 14:32:17 2012Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.Connected to:Oracle Database 10g Enterprise Edition Release 10.2.0.5.0 - 64bit ProductionWith the Partitioning, Real Application Clusters, OLAP, Data Miningand Real Application Testing optionsSQL> archive log listDatabase log mode\t       Archive ModeAutomatic archival\t       EnabledArchive destination\t       /u01/app/oracle/archOldest online log sequence     9Next log sequence to archive   10Current log sequence\t       10 racnode3 [oracle@racnode3 arch]$ sqlplus / as sysdbaSQL*Plus: Release 10.2.0.5.0 - Production on Tue Dec 25 14:32:43 2012Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.Connected to:Oracle Database 10g Enterprise Edition Release 10.2.0.5.0 - 64bit ProductionWith the Partitioning, Real Application Clusters, OLAP, Data Miningand Real Application Testing optionsSQL> archive log listDatabase log mode\t       Archive ModeAutomatic archival\t       EnabledArchive destination\t       /u01/app/oracle/archOldest online log sequence     2Next log sequence to archive   3Current log sequence\t       3 Verify connectivity to the target nodes and catalog if used [oracle@racnode3 arch]$ sqlplus /nologSQL*Plus: Release 10.2.0.5.0 - Production on Tue Dec 25 14:34:59 2012Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.SQL> conn sys/oracle@racdb1 as sysdbaConnected.SQL> conn sys/oracle@racdb2 as sysdbaConnected.SQL> conn sys/oracle@racdb3 as sysdbaConnected.SQL> conn sys/oracle@racdb as sysdbaConnected.SQL> Connect using RMAN to verify and set the controlfile persistent configuration [oracle@racnode1 backup]$ rman target /Recovery Manager: Release 10.2.0.5.0 - Production on Tue Dec 25 14:40:45 2012Copyright (c) 1982, 2007, Oracle.  All rights reserved.connected to target database: RACDB (DBID=800157471)RMAN> show all;using target database control file instead of recovery catalogRMAN configuration parameters are:CONFIGURE RETENTION POLICY TO REDUNDANCY 1; # defaultCONFIGURE BACKUP OPTIMIZATION OFF; # defaultCONFIGURE DEFAULT DEVICE TYPE TO DISK; # defaultCONFIGURE CONTROLFILE AUTOBACKUP OFF; # defaultCONFIGURE CONTROLFILE AUTOBACKUP FORMAT FOR DEVICE TYPE DISK TO '%F'; # defaultCONFIGURE DEVICE TYPE DISK PARALLELISM 1 BACKUP TYPE TO BACKUPSET; # defaultCONFIGURE DATAFILE BACKUP COPIES FOR DEVICE TYPE DISK TO 1; # defaultCONFIGURE ARCHIVELOG BACKUP COPIES FOR DEVICE TYPE DISK TO 1; # defaultCONFIGURE MAXSETSIZE TO UNLIMITED; # defaultCONFIGURE ENCRYPTION FOR DATABASE OFF; # defaultCONFIGURE ENCRYPTION ALGORITHM 'AES128'; # defaultCONFIGURE ARCHIVELOG DELETION POLICY TO NONE; # defaultCONFIGURE SNAPSHOT CONTROLFILE NAME TO '/u01/app/oracle/product/10.2.0/db_1/dbs/snapcf_racdb1.f'; # defaultRMAN> In this example, using PARALLELISM 3 as 3 nodes are used.The PARALLELISM will than automaticly start 3 channels and will use the related CONFIGURE CHANNEL for additional clauses. RMAN> configure retention policy to redundancy 3;new RMAN configuration parameters:CONFIGURE RETENTION POLICY TO REDUNDANCY 3;new RMAN configuration parameters are successfully storedRMAN> configure controlfile autobackup on;new RMAN configuration parameters:CONFIGURE CONTROLFILE AUTOBACKUP ON;new RMAN configuration parameters are successfully storedRMAN> configure controlfile autobackup format for device type disk to '/u01/app/oracle/backup/%F';new RMAN configuration parameters:CONFIGURE CONTROLFILE AUTOBACKUP FORMAT FOR DEVICE TYPE DISK TO '/u01/app/oracle/backup/%F';new RMAN configuration parameters are successfully storedRMAN> configure device type disk parallelism 3;new RMAN configuration parameters:CONFIGURE DEVICE TYPE DISK PARALLELISM 3 BACKUP TYPE TO BACKUPSET;new RMAN configuration parameters are successfully storedRMAN> configure channel 1 device type disk connect sys/oracle@racdb1;new RMAN configuration parameters:CONFIGURE CHANNEL 1 DEVICE TYPE DISK CONNECT '*';new RMAN configuration parameters are successfully storedRMAN> configure channel 2 device type disk connect sys/oracle@racdb2;new RMAN configuration parameters:CONFIGURE CHANNEL 2 DEVICE TYPE DISK CONNECT '*';new RMAN configuration parameters are successfully storedRMAN> configure channel 3 device type disk connect 'sys/oracle@racdb3';new RMAN configuration parameters:CONFIGURE CHANNEL 3 DEVICE TYPE DISK CONNECT '*';new RMAN configuration parameters are successfully storedRMAN>  RMAN> show all;RMAN configuration parameters are:CONFIGURE RETENTION POLICY TO REDUNDANCY 3;CONFIGURE BACKUP OPTIMIZATION OFF; # defaultCONFIGURE DEFAULT DEVICE TYPE TO DISK; # defaultCONFIGURE CONTROLFILE AUTOBACKUP ON;CONFIGURE CONTROLFILE AUTOBACKUP FORMAT FOR DEVICE TYPE DISK TO '/u01/app/oracle/backup/%F';CONFIGURE DEVICE TYPE DISK PARALLELISM 3 BACKUP TYPE TO BACKUPSET;CONFIGURE DATAFILE BACKUP COPIES FOR DEVICE TYPE DISK TO 1; # defaultCONFIGURE ARCHIVELOG BACKUP COPIES FOR DEVICE TYPE DISK TO 1; # defaultCONFIGURE CHANNEL 1 DEVICE TYPE DISK CONNECT '*';CONFIGURE CHANNEL 2 DEVICE TYPE DISK CONNECT '*';CONFIGURE CHANNEL 3 DEVICE TYPE DISK CONNECT '*';CONFIGURE MAXSETSIZE TO UNLIMITED; # defaultCONFIGURE ENCRYPTION FOR DATABASE OFF; # defaultCONFIGURE ENCRYPTION ALGORITHM 'AES128'; # defaultCONFIGURE ARCHIVELOG DELETION POLICY TO NONE; # defaultCONFIGURE SNAPSHOT CONTROLFILE NAME TO '/u01/app/oracle/product/10.2.0/db_1/dbs/snapcf_racdb1.f'; # defaultRMAN> backup incremental level 0 [oracle@racnode1 backup]$ rman target /Recovery Manager: Release 10.2.0.5.0 - Production on Tue Dec 25 15:09:42 2012Copyright (c) 1982, 2007, Oracle.  All rights reserved.connected to target database: RACDB (DBID=800157471)RMAN> run{2> configure retention policy to redundancy 3;3> configure controlfile autobackup on;4> configure controlfile autobackup format for device type disk to '/u01/app/oracle/backup/%F';5> configure device type disk parallelism 3;6> configure channel 1 device type disk connect sys/oracle@racdb1;7> configure channel 2 device type disk connect sys/oracle@racdb2;8> configure channel 3 device type disk connect sys/oracle@racdb3;9> configure maxsetsize to unlimited;10> backup incremental level 011> format '/u01/app/oracle/backup/%d_LVL0_%T_%u_s%s_p%p' tag 'DB_INC0'12> database;13> backup archivelog all format '/u01/app/oracle/backup/%d_ARCH_%T_%u_s%s_p%p' tag 'ARCH_INC0'14> delete input;15> }using target database control file instead of recovery catalogold RMAN configuration parameters:CONFIGURE RETENTION POLICY TO REDUNDANCY 3;new RMAN configuration parameters:CONFIGURE RETENTION POLICY TO REDUNDANCY 3;new RMAN configuration parameters are successfully storedold RMAN configuration parameters:CONFIGURE CONTROLFILE AUTOBACKUP ON;new RMAN configuration parameters:CONFIGURE CONTROLFILE AUTOBACKUP ON;new RMAN configuration parameters are successfully storedold RMAN configuration parameters:CONFIGURE CONTROLFILE AUTOBACKUP FORMAT FOR DEVICE TYPE DISK TO '/u01/app/oracle/backup/%F';new RMAN configuration parameters:CONFIGURE CONTROLFILE AUTOBACKUP FORMAT FOR DEVICE TYPE DISK TO '/u01/app/oracle/backup/%F';new RMAN configuration parameters are successfully storedold RMAN configuration parameters:CONFIGURE DEVICE TYPE DISK PARALLELISM 3 BACKUP TYPE TO BACKUPSET;new RMAN configuration parameters:CONFIGURE DEVICE TYPE DISK PARALLELISM 3 BACKUP TYPE TO BACKUPSET;new RMAN configuration parameters are successfully storedold RMAN configuration parameters:CONFIGURE CHANNEL 1 DEVICE TYPE DISK CONNECT '*';new RMAN configuration parameters:CONFIGURE CHANNEL 1 DEVICE TYPE DISK CONNECT '*';new RMAN configuration parameters are successfully storedold RMAN configuration parameters:CONFIGURE CHANNEL 2 DEVICE TYPE DISK CONNECT '*';new RMAN configuration parameters:CONFIGURE CHANNEL 2 DEVICE TYPE DISK CONNECT '*';new RMAN configuration parameters are successfully storedold RMAN configuration parameters:CONFIGURE CHANNEL 3 DEVICE TYPE DISK CONNECT '*';new RMAN configuration parameters:CONFIGURE CHANNEL 3 DEVICE TYPE DISK CONNECT '*';new RMAN configuration parameters are successfully storedold RMAN configuration parameters:CONFIGURE MAXSETSIZE TO UNLIMITED;new RMAN configuration parameters:CONFIGURE MAXSETSIZE TO UNLIMITED;new RMAN configuration parameters are successfully storedStarting backup at 25-DEC-2012 15:12:32allocated channel: ORA_DISK_1channel ORA_DISK_1: sid=845 instance=racdb1 devtype=DISKallocated channel: ORA_DISK_2channel ORA_DISK_2: sid=855 instance=racdb2 devtype=DISKallocated channel: ORA_DISK_3channel ORA_DISK_3: sid=848 instance=racdb3 devtype=DISKchannel ORA_DISK_1: starting incremental level 0 datafile backupsetchannel ORA_DISK_1: specifying datafile(s) in backupsetinput datafile fno=00001 name=+DATADG/racdb/datafile/system.256.802540615channel ORA_DISK_1: starting piece 1 at 25-DEC-2012 15:12:35channel ORA_DISK_2: starting incremental level 0 datafile backupsetchannel ORA_DISK_2: specifying datafile(s) in backupsetinput datafile fno=00003 name=+DATADG/racdb/datafile/sysaux.257.802540615input datafile fno=00006 name=+DATADG/racdb/datafile/undotbs2.265.802540981input datafile fno=00004 name=+DATADG/racdb/datafile/users.259.802540615channel ORA_DISK_2: starting piece 1 at 25-DEC-2012 15:12:35channel ORA_DISK_3: starting incremental level 0 datafile backupsetchannel ORA_DISK_3: specifying datafile(s) in backupsetinput datafile fno=00005 name=+DATADG/racdb/datafile/example.264.802540751input datafile fno=00002 name=+DATADG/racdb/datafile/undotbs1.258.802540615input datafile fno=00007 name=+DATADG/racdb/datafile/undotbs3.269.802888323channel ORA_DISK_3: starting piece 1 at 25-DEC-2012 15:12:36channel ORA_DISK_3: finished piece 1 at 25-DEC-2012 15:13:01piece handle=/u01/app/oracle/backup/RACDB_LVL0_20121225_03ntomb3_s3_p1 tag=DB_INC0 comment=NONEchannel ORA_DISK_3: backup set complete, elapsed time: 00:00:26channel ORA_DISK_1: finished piece 1 at 25-DEC-2012 15:13:46piece handle=/u01/app/oracle/backup/RACDB_LVL0_20121225_01ntomb3_s1_p1 tag=DB_INC0 comment=NONEchannel ORA_DISK_1: backup set complete, elapsed time: 00:01:11channel ORA_DISK_2: finished piece 1 at 25-DEC-2012 15:13:47piece handle=/u01/app/oracle/backup/RACDB_LVL0_20121225_02ntomb3_s2_p1 tag=DB_INC0 comment=NONEchannel ORA_DISK_2: backup set complete, elapsed time: 00:01:12Finished backup at 25-DEC-2012 15:13:46Starting backup at 25-DEC-2012 15:13:50current log archivedusing channel ORA_DISK_1using channel ORA_DISK_2using channel ORA_DISK_3channel ORA_DISK_3: starting archive log backupsetchannel ORA_DISK_3: specifying archive log(s) in backup setinput archive log thread=3 sequence=3 recid=29 stamp=802970034channel ORA_DISK_3: starting piece 1 at 25-DEC-2012 15:13:56channel ORA_DISK_1: starting archive log backupsetchannel ORA_DISK_1: specifying archive log(s) in backup setinput archive log thread=1 sequence=15 recid=22 stamp=802967112channel ORA_DISK_1: starting piece 1 at 25-DEC-2012 15:13:56channel ORA_DISK_2: starting archive log backupsetchannel ORA_DISK_2: specifying archive log(s) in backup setinput archive log thread=2 sequence=10 recid=28 stamp=802970033channel ORA_DISK_2: starting piece 1 at 25-DEC-2012 15:13:57channel ORA_DISK_3: finished piece 1 at 25-DEC-2012 15:13:57piece handle=/u01/app/oracle/backup/RACDB_ARCH_20121225_06ntomdk_s6_p1 tag=ARCH_INC0 comment=NONEchannel ORA_DISK_3: backup set complete, elapsed time: 00:00:01channel ORA_DISK_3: deleting archive log(s)archive log filename=/u01/app/oracle/arch/3_3_802540708.dbf recid=29 stamp=802970034channel ORA_DISK_1: finished piece 1 at 25-DEC-2012 15:13:58piece handle=/u01/app/oracle/backup/RACDB_ARCH_20121225_04ntomdk_s4_p1 tag=ARCH_INC0 comment=NONEchannel ORA_DISK_1: backup set complete, elapsed time: 00:00:02channel ORA_DISK_1: deleting archive log(s)archive log filename=/u01/app/oracle/arch/1_15_802540708.dbf recid=22 stamp=802967112channel ORA_DISK_2: finished piece 1 at 25-DEC-2012 15:13:59piece handle=/u01/app/oracle/backup/RACDB_ARCH_20121225_05ntomdk_s5_p1 tag=ARCH_INC0 comment=NONEchannel ORA_DISK_2: backup set complete, elapsed time: 00:00:03channel ORA_DISK_2: deleting archive log(s)archive log filename=/u01/app/oracle/arch/2_10_802540708.dbf recid=28 stamp=802970033channel ORA_DISK_1: starting archive log backupsetchannel ORA_DISK_1: specifying archive log(s) in backup setinput archive log thread=1 sequence=18 recid=27 stamp=802970031channel ORA_DISK_1: starting piece 1 at 25-DEC-2012 15:13:58channel ORA_DISK_1: finished piece 1 at 25-DEC-2012 15:13:59piece handle=/u01/app/oracle/backup/RACDB_ARCH_20121225_07ntomdm_s7_p1 tag=ARCH_INC0 comment=NONEchannel ORA_DISK_1: backup set complete, elapsed time: 00:00:01channel ORA_DISK_1: deleting archive log(s)archive log filename=/u01/app/oracle/arch/1_18_802540708.dbf recid=27 stamp=802970031channel ORA_DISK_1: starting archive log backupsetchannel ORA_DISK_1: specifying archive log(s) in backup setinput archive log thread=1 sequence=16 recid=24 stamp=802967124input archive log thread=1 sequence=17 recid=25 stamp=802967126channel ORA_DISK_1: starting piece 1 at 25-DEC-2012 15:14:01channel ORA_DISK_1: finished piece 1 at 25-DEC-2012 15:14:02piece handle=/u01/app/oracle/backup/RACDB_ARCH_20121225_08ntomdo_s8_p1 tag=ARCH_INC0 comment=NONEchannel ORA_DISK_1: backup set complete, elapsed time: 00:00:02channel ORA_DISK_1: deleting archive log(s)archive log filename=/u01/app/oracle/arch/1_16_802540708.dbf recid=24 stamp=802967124archive log filename=/u01/app/oracle/arch/1_17_802540708.dbf recid=25 stamp=802967126Finished backup at 25-DEC-2012 15:14:02Starting Control File and SPFILE Autobackup at 25-DEC-2012 15:14:02piece handle=/u01/app/oracle/backup/c-800157471-20121225-00 comment=NONEFinished Control File and SPFILE Autobackup at 25-DEC-2012 15:14:09RMAN> backup incremental level 1 RMAN> run{2> configure retention policy to redundancy 3;3> configure controlfile autobackup on;4> configure controlfile autobackup format for device type disk to '/u01/app/oracle/backup/%F';5> configure device type disk parallelism 3;6> configure channel 1 device type disk connect sys/oracle@racdb1;7> configure channel 2 device type disk connect sys/oracle@racdb2;8> configure channel 3 device type disk connect sys/oracle@racdb3;9> configure maxsetsize to unlimited;10> backup incremental level 111> format '/u01/app/oracle/backup/%d_LVL1_%T_%u_s%s_p%p' tag 'DB_INC1'12> database;13> backup archivelog all format '/u01/app/oracle/backup/%d_ARCH_%T_%u_s%s_p%p' tag 'ARCH_INC1'14> delete input;15> crosscheck backupset;16> delete noprompt expired backup;17> delete noprompt obsolete;18> }old RMAN configuration parameters:CONFIGURE RETENTION POLICY TO REDUNDANCY 3;new RMAN configuration parameters:CONFIGURE RETENTION POLICY TO REDUNDANCY 3;new RMAN configuration parameters are successfully storedold RMAN configuration parameters:CONFIGURE CONTROLFILE AUTOBACKUP ON;new RMAN configuration parameters:CONFIGURE CONTROLFILE AUTOBACKUP ON;new RMAN configuration parameters are successfully storedold RMAN configuration parameters:CONFIGURE CONTROLFILE AUTOBACKUP FORMAT FOR DEVICE TYPE DISK TO '/u01/app/oracle/backup/%F';new RMAN configuration parameters:CONFIGURE CONTROLFILE AUTOBACKUP FORMAT FOR DEVICE TYPE DISK TO '/u01/app/oracle/backup/%F';new RMAN configuration parameters are successfully storedold RMAN configuration parameters:CONFIGURE DEVICE TYPE DISK PARALLELISM 3 BACKUP TYPE TO BACKUPSET;new RMAN configuration parameters:CONFIGURE DEVICE TYPE DISK PARALLELISM 3 BACKUP TYPE TO BACKUPSET;new RMAN configuration parameters are successfully storedreleased channel: ORA_DISK_1released channel: ORA_DISK_2released channel: ORA_DISK_3old RMAN configuration parameters:CONFIGURE CHANNEL 1 DEVICE TYPE DISK CONNECT '*';new RMAN configuration parameters:CONFIGURE CHANNEL 1 DEVICE TYPE DISK CONNECT '*';new RMAN configuration parameters are successfully storedold RMAN configuration parameters:CONFIGURE CHANNEL 2 DEVICE TYPE DISK CONNECT '*';new RMAN configuration parameters:CONFIGURE CHANNEL 2 DEVICE TYPE DISK CONNECT '*';new RMAN configuration parameters are successfully storedold RMAN configuration parameters:CONFIGURE CHANNEL 3 DEVICE TYPE DISK CONNECT '*';new RMAN configuration parameters:CONFIGURE CHANNEL 3 DEVICE TYPE DISK CONNECT '*';new RMAN configuration parameters are successfully storedold RMAN configuration parameters:CONFIGURE MAXSETSIZE TO UNLIMITED;new RMAN configuration parameters:CONFIGURE MAXSETSIZE TO UNLIMITED;new RMAN configuration parameters are successfully storedStarting backup at 25-DEC-2012 15:24:50allocated channel: ORA_DISK_1channel ORA_DISK_1: sid=845 instance=racdb1 devtype=DISKallocated channel: ORA_DISK_2channel ORA_DISK_2: sid=855 instance=racdb2 devtype=DISKallocated channel: ORA_DISK_3channel ORA_DISK_3: sid=848 instance=racdb3 devtype=DISKchannel ORA_DISK_1: starting incremental level 1 datafile backupsetchannel ORA_DISK_1: specifying datafile(s) in backupsetinput datafile fno=00001 name=+DATADG/racdb/datafile/system.256.802540615channel ORA_DISK_1: starting piece 1 at 25-DEC-2012 15:24:53channel ORA_DISK_2: starting incremental level 1 datafile backupsetchannel ORA_DISK_2: specifying datafile(s) in backupsetinput datafile fno=00003 name=+DATADG/racdb/datafile/sysaux.257.802540615input datafile fno=00006 name=+DATADG/racdb/datafile/undotbs2.265.802540981input datafile fno=00004 name=+DATADG/racdb/datafile/users.259.802540615channel ORA_DISK_2: starting piece 1 at 25-DEC-2012 15:24:53channel ORA_DISK_3: starting incremental level 1 datafile backupsetchannel ORA_DISK_3: specifying datafile(s) in backupsetinput datafile fno=00005 name=+DATADG/racdb/datafile/example.264.802540751input datafile fno=00002 name=+DATADG/racdb/datafile/undotbs1.258.802540615input datafile fno=00007 name=+DATADG/racdb/datafile/undotbs3.269.802888323channel ORA_DISK_3: starting piece 1 at 25-DEC-2012 15:25:02channel ORA_DISK_1: finished piece 1 at 25-DEC-2012 15:25:05piece handle=/u01/app/oracle/backup/RACDB_LVL1_20121225_0anton25_s10_p1 tag=DB_INC1 comment=NONEchannel ORA_DISK_1: backup set complete, elapsed time: 00:00:12channel ORA_DISK_2: finished piece 1 at 25-DEC-2012 15:25:20piece handle=/u01/app/oracle/backup/RACDB_LVL1_20121225_0bnton25_s11_p1 tag=DB_INC1 comment=NONEchannel ORA_DISK_2: backup set complete, elapsed time: 00:00:27channel ORA_DISK_3: finished piece 1 at 25-DEC-2012 15:25:20piece handle=/u01/app/oracle/backup/RACDB_LVL1_20121225_0cnton25_s12_p1 tag=DB_INC1 comment=NONEchannel ORA_DISK_3: backup set complete, elapsed time: 00:00:27Finished backup at 25-DEC-2012 15:25:20Starting backup at 25-DEC-2012 15:25:24current log archivedusing channel ORA_DISK_1using channel ORA_DISK_2using channel ORA_DISK_3channel ORA_DISK_1: starting archive log backupsetchannel ORA_DISK_1: specifying archive log(s) in backup setinput archive log thread=1 sequence=19 recid=30 stamp=802970726channel ORA_DISK_1: starting piece 1 at 25-DEC-2012 15:25:33channel ORA_DISK_2: starting archive log backupsetchannel ORA_DISK_2: specifying archive log(s) in backup setinput archive log thread=2 sequence=11 recid=31 stamp=802970726channel ORA_DISK_2: starting piece 1 at 25-DEC-2012 15:25:33channel ORA_DISK_3: starting archive log backupsetchannel ORA_DISK_3: specifying archive log(s) in backup setinput archive log thread=3 sequence=4 recid=32 stamp=802970727channel ORA_DISK_3: starting piece 1 at 25-DEC-2012 15:25:34channel ORA_DISK_1: finished piece 1 at 25-DEC-2012 15:25:34piece handle=/u01/app/oracle/backup/RACDB_ARCH_20121225_0dnton3c_s13_p1 tag=ARCH_INC1 comment=NONEchannel ORA_DISK_1: backup set complete, elapsed time: 00:00:02channel ORA_DISK_1: deleting archive log(s)archive log filename=/u01/app/oracle/arch/1_19_802540708.dbf recid=30 stamp=802970726channel ORA_DISK_2: finished piece 1 at 25-DEC-2012 15:25:34piece handle=/u01/app/oracle/backup/RACDB_ARCH_20121225_0enton3c_s14_p1 tag=ARCH_INC1 comment=NONEchannel ORA_DISK_2: backup set complete, elapsed time: 00:00:02channel ORA_DISK_2: deleting archive log(s)archive log filename=/u01/app/oracle/arch/2_11_802540708.dbf recid=31 stamp=802970726channel ORA_DISK_3: finished piece 1 at 25-DEC-2012 15:25:34piece handle=/u01/app/oracle/backup/RACDB_ARCH_20121225_0fnton3c_s15_p1 tag=ARCH_INC1 comment=NONEchannel ORA_DISK_3: backup set complete, elapsed time: 00:00:02channel ORA_DISK_3: deleting archive log(s)archive log filename=/u01/app/oracle/arch/3_4_802540708.dbf recid=32 stamp=802970727Finished backup at 25-DEC-2012 15:25:34Starting Control File and SPFILE Autobackup at 25-DEC-2012 15:25:34piece handle=/u01/app/oracle/backup/c-800157471-20121225-01 comment=NONEFinished Control File and SPFILE Autobackup at 25-DEC-2012 15:25:41using channel ORA_DISK_1using channel ORA_DISK_2using channel ORA_DISK_3crosschecked backup piece: found to be 'AVAILABLE'backup piece handle=/u01/app/oracle/backup/RACDB_LVL0_20121225_01ntomb3_s1_p1 recid=3 stamp=802969955crosschecked backup piece: found to be 'AVAILABLE'backup piece handle=/u01/app/oracle/backup/RACDB_ARCH_20121225_04ntomdk_s4_p1 recid=5 stamp=802970036crosschecked backup piece: found to be 'AVAILABLE'backup piece handle=/u01/app/oracle/backup/RACDB_ARCH_20121225_07ntomdm_s7_p1 recid=7 stamp=802970038crosschecked backup piece: found to be 'AVAILABLE'backup piece handle=/u01/app/oracle/backup/RACDB_ARCH_20121225_08ntomdo_s8_p1 recid=8 stamp=802970041crosschecked backup piece: found to be 'AVAILABLE'backup piece handle=/u01/app/oracle/backup/c-800157471-20121225-00 recid=9 stamp=802970045crosschecked backup piece: found to be 'AVAILABLE'backup piece handle=/u01/app/oracle/backup/RACDB_LVL1_20121225_0anton25_s10_p1 recid=10 stamp=802970693crosschecked backup piece: found to be 'AVAILABLE'backup piece handle=/u01/app/oracle/backup/RACDB_ARCH_20121225_0dnton3c_s13_p1 recid=13 stamp=802970733crosschecked backup piece: found to be 'AVAILABLE'backup piece handle=/u01/app/oracle/backup/c-800157471-20121225-01 recid=16 stamp=802970736Crosschecked 8 objectscrosschecked backup piece: found to be 'AVAILABLE'backup piece handle=/u01/app/oracle/backup/RACDB_LVL0_20121225_02ntomb3_s2_p1 recid=2 stamp=802969956crosschecked backup piece: found to be 'AVAILABLE'backup piece handle=/u01/app/oracle/backup/RACDB_ARCH_20121225_05ntomdk_s5_p1 recid=6 stamp=802970037crosschecked backup piece: found to be 'AVAILABLE'backup piece handle=/u01/app/oracle/backup/RACDB_LVL1_20121225_0bnton25_s11_p1 recid=12 stamp=802970702crosschecked backup piece: found to be 'AVAILABLE'backup piece handle=/u01/app/oracle/backup/RACDB_ARCH_20121225_0enton3c_s14_p1 recid=14 stamp=802970733Crosschecked 4 objectscrosschecked backup piece: found to be 'AVAILABLE'backup piece handle=/u01/app/oracle/backup/RACDB_LVL0_20121225_03ntomb3_s3_p1 recid=1 stamp=802969965crosschecked backup piece: found to be 'AVAILABLE'backup piece handle=/u01/app/oracle/backup/RACDB_ARCH_20121225_06ntomdk_s6_p1 recid=4 stamp=802970036crosschecked backup piece: found to be 'AVAILABLE'backup piece handle=/u01/app/oracle/backup/RACDB_LVL1_20121225_0cnton25_s12_p1 recid=11 stamp=802970706crosschecked backup piece: found to be 'AVAILABLE'backup piece handle=/u01/app/oracle/backup/RACDB_ARCH_20121225_0fnton3c_s15_p1 recid=15 stamp=802970734Crosschecked 4 objectsusing channel ORA_DISK_1using channel ORA_DISK_2using channel ORA_DISK_3RMAN retention policy will be applied to the commandRMAN retention policy is set to redundancy 3using channel ORA_DISK_1using channel ORA_DISK_2using channel ORA_DISK_3no obsolete backups foundRMAN> summary RMAN> list backupset;List of Backup Sets===================BS Key  Type LV Size       Device Type Elapsed Time Completion Time     ------- ---- -- ---------- ----------- ------------ --------------------1       Incr 0  66.25M     DISK        00:00:24     25-DEC-2012 15:12:59        BP Key: 1   Status: AVAILABLE  Compressed: NO  Tag: DB_INC0        Piece Name: /u01/app/oracle/backup/RACDB_LVL0_20121225_03ntomb3_s3_p1  List of Datafiles in backup set 1  File LV Type Ckp SCN    Ckp Time             Name  ---- -- ---- ---------- -------------------- ----  2    0  Incr 930970     25-DEC-2012 15:12:42 +DATADG/racdb/datafile/undotbs1.258.802540615  5    0  Incr 930970     25-DEC-2012 15:12:42 +DATADG/racdb/datafile/example.264.802540751  7    0  Incr 930970     25-DEC-2012 15:12:42 +DATADG/racdb/datafile/undotbs3.269.802888323BS Key  Type LV Size       Device Type Elapsed Time Completion Time     ------- ---- -- ---------- ----------- ------------ --------------------2       Incr 0  263.96M    DISK        00:01:05     25-DEC-2012 15:13:40        BP Key: 2   Status: AVAILABLE  Compressed: NO  Tag: DB_INC0        Piece Name: /u01/app/oracle/backup/RACDB_LVL0_20121225_02ntomb3_s2_p1  List of Datafiles in backup set 2  File LV Type Ckp SCN    Ckp Time             Name  ---- -- ---- ---------- -------------------- ----  3    0  Incr 930964     25-DEC-2012 15:12:35 +DATADG/racdb/datafile/sysaux.257.802540615  4    0  Incr 930964     25-DEC-2012 15:12:35 +DATADG/racdb/datafile/users.259.802540615  6    0  Incr 930964     25-DEC-2012 15:12:35 +DATADG/racdb/datafile/undotbs2.265.802540981BS Key  Type LV Size       Device Type Elapsed Time Completion Time     ------- ---- -- ---------- ----------- ------------ --------------------3       Incr 0  370.38M    DISK        00:01:07     25-DEC-2012 15:13:42        BP Key: 3   Status: AVAILABLE  Compressed: NO  Tag: DB_INC0        Piece Name: /u01/app/oracle/backup/RACDB_LVL0_20121225_01ntomb3_s1_p1  List of Datafiles in backup set 3  File LV Type Ckp SCN    Ckp Time             Name  ---- -- ---- ---------- -------------------- ----  1    0  Incr 930959     25-DEC-2012 15:12:35 +DATADG/racdb/datafile/system.256.802540615BS Key  Size       Device Type Elapsed Time Completion Time     ------- ---------- ----------- ------------ --------------------4       693.00K    DISK        00:00:01     25-DEC-2012 15:13:57        BP Key: 4   Status: AVAILABLE  Compressed: NO  Tag: ARCH_INC0        Piece Name: /u01/app/oracle/backup/RACDB_ARCH_20121225_06ntomdk_s6_p1  List of Archived Logs in backup set 4  Thrd Seq     Low SCN    Low Time             Next SCN   Next Time  ---- ------- ---------- -------------------- ---------- ---------  3    3       926740     25-DEC-2012 14:25:27 931028     25-DEC-2012 15:13:53BS Key  Size       Device Type Elapsed Time Completion Time     ------- ---------- ----------- ------------ --------------------5       3.30M      DISK        00:00:01     25-DEC-2012 15:13:57        BP Key: 5   Status: AVAILABLE  Compressed: NO  Tag: ARCH_INC0        Piece Name: /u01/app/oracle/backup/RACDB_ARCH_20121225_04ntomdk_s4_p1  List of Archived Logs in backup set 5  Thrd Seq     Low SCN    Low Time             Next SCN   Next Time  ---- ------- ---------- -------------------- ---------- ---------  1    15      892350     25-DEC-2012 11:24:17 926723     25-DEC-2012 14:25:11BS Key  Size       Device Type Elapsed Time Completion Time     ------- ---------- ----------- ------------ --------------------6       791.50K    DISK        00:00:02     25-DEC-2012 15:13:58        BP Key: 6   Status: AVAILABLE  Compressed: NO  Tag: ARCH_INC0        Piece Name: /u01/app/oracle/backup/RACDB_ARCH_20121225_05ntomdk_s5_p1  List of Archived Logs in backup set 6  Thrd Seq     Low SCN    Low Time             Next SCN   Next Time  ---- ------- ---------- -------------------- ---------- ---------  2    10      926728     25-DEC-2012 14:25:14 931026     25-DEC-2012 15:13:52BS Key  Size       Device Type Elapsed Time Completion Time     ------- ---------- ----------- ------------ --------------------7       1.43M      DISK        00:00:01     25-DEC-2012 15:13:59        BP Key: 7   Status: AVAILABLE  Compressed: NO  Tag: ARCH_INC0        Piece Name: /u01/app/oracle/backup/RACDB_ARCH_20121225_07ntomdm_s7_p1  List of Archived Logs in backup set 7  Thrd Seq     Low SCN    Low Time             Next SCN   Next Time  ---- ------- ---------- -------------------- ---------- ---------  1    18      926737     25-DEC-2012 14:25:26 931023     25-DEC-2012 15:13:51BS Key  Size       Device Type Elapsed Time Completion Time     ------- ---------- ----------- ------------ --------------------8       3.50K      DISK        00:00:01     25-DEC-2012 15:14:01        BP Key: 8   Status: AVAILABLE  Compressed: NO  Tag: ARCH_INC0        Piece Name: /u01/app/oracle/backup/RACDB_ARCH_20121225_08ntomdo_s8_p1  List of Archived Logs in backup set 8  Thrd Seq     Low SCN    Low Time             Next SCN   Next Time  ---- ------- ---------- -------------------- ---------- ---------  1    16      926723     25-DEC-2012 14:25:11 926734     25-DEC-2012 14:25:23  1    17      926734     25-DEC-2012 14:25:23 926737     25-DEC-2012 14:25:26BS Key  Type LV Size       Device Type Elapsed Time Completion Time     ------- ---- -- ---------- ----------- ------------ --------------------9       Full    14.67M     DISK        00:00:04     25-DEC-2012 15:14:06        BP Key: 9   Status: AVAILABLE  Compressed: NO  Tag: TAG20121225T151402        Piece Name: /u01/app/oracle/backup/c-800157471-20121225-00  Control File Included: Ckp SCN: 931040       Ckp time: 25-DEC-2012 15:14:02  SPFILE Included: Modification time: 25-DEC-2012 14:23:24BS Key  Type LV Size       Device Type Elapsed Time Completion Time     ------- ---- -- ---------- ----------- ------------ --------------------10      Incr 1  128.00K    DISK        00:00:09     25-DEC-2012 15:25:02        BP Key: 10   Status: AVAILABLE  Compressed: NO  Tag: DB_INC1        Piece Name: /u01/app/oracle/backup/RACDB_LVL1_20121225_0anton25_s10_p1  List of Datafiles in backup set 10  File LV Type Ckp SCN    Ckp Time             Name  ---- -- ---- ---------- -------------------- ----  1    1  Incr 931568     25-DEC-2012 15:24:53 +DATADG/racdb/datafile/system.256.802540615BS Key  Type LV Size       Device Type Elapsed Time Completion Time     ------- ---- -- ---------- ----------- ------------ --------------------11      Incr 1  232.00K    DISK        00:00:21     25-DEC-2012 15:25:14        BP Key: 11   Status: AVAILABLE  Compressed: NO  Tag: DB_INC1        Piece Name: /u01/app/oracle/backup/RACDB_LVL1_20121225_0cnton25_s12_p1  List of Datafiles in backup set 11  File LV Type Ckp SCN    Ckp Time             Name  ---- -- ---- ---------- -------------------- ----  2    1  Incr 931576     25-DEC-2012 15:25:03 +DATADG/racdb/datafile/undotbs1.258.802540615  5    1  Incr 931576     25-DEC-2012 15:25:03 +DATADG/racdb/datafile/example.264.802540751  7    1  Incr 931576     25-DEC-2012 15:25:03 +DATADG/racdb/datafile/undotbs3.269.802888323BS Key  Type LV Size       Device Type Elapsed Time Completion Time     ------- ---- -- ---------- ----------- ------------ --------------------12      Incr 1  208.00K    DISK        00:00:21     25-DEC-2012 15:25:14        BP Key: 12   Status: AVAILABLE  Compressed: NO  Tag: DB_INC1        Piece Name: /u01/app/oracle/backup/RACDB_LVL1_20121225_0bnton25_s11_p1  List of Datafiles in backup set 12  File LV Type Ckp SCN    Ckp Time             Name  ---- -- ---- ---------- -------------------- ----  3    1  Incr 931570     25-DEC-2012 15:24:53 +DATADG/racdb/datafile/sysaux.257.802540615  4    1  Incr 931570     25-DEC-2012 15:24:53 +DATADG/racdb/datafile/users.259.802540615  6    1  Incr 931570     25-DEC-2012 15:24:53 +DATADG/racdb/datafile/undotbs2.265.802540981BS Key  Size       Device Type Elapsed Time Completion Time     ------- ---------- ----------- ------------ --------------------13      38.00K     DISK        00:00:02     25-DEC-2012 15:25:34        BP Key: 13   Status: AVAILABLE  Compressed: NO  Tag: ARCH_INC1        Piece Name: /u01/app/oracle/backup/RACDB_ARCH_20121225_0dnton3c_s13_p1  List of Archived Logs in backup set 13  Thrd Seq     Low SCN    Low Time             Next SCN   Next Time  ---- ------- ---------- -------------------- ---------- ---------  1    19      931023     25-DEC-2012 15:13:51 931599     25-DEC-2012 15:25:25BS Key  Size       Device Type Elapsed Time Completion Time     ------- ---------- ----------- ------------ --------------------14      58.00K     DISK        00:00:02     25-DEC-2012 15:25:34        BP Key: 14   Status: AVAILABLE  Compressed: NO  Tag: ARCH_INC1        Piece Name: /u01/app/oracle/backup/RACDB_ARCH_20121225_0enton3c_s14_p1  List of Archived Logs in backup set 14  Thrd Seq     Low SCN    Low Time             Next SCN   Next Time  ---- ------- ---------- -------------------- ---------- ---------  2    11      931026     25-DEC-2012 15:13:52 931601     25-DEC-2012 15:25:26BS Key  Size       Device Type Elapsed Time Completion Time     ------- ---------- ----------- ------------ --------------------15      5.00K      DISK        00:00:02     25-DEC-2012 15:25:34        BP Key: 15   Status: AVAILABLE  Compressed: NO  Tag: ARCH_INC1        Piece Name: /u01/app/oracle/backup/RACDB_ARCH_20121225_0fnton3c_s15_p1  List of Archived Logs in backup set 15  Thrd Seq     Low SCN    Low Time             Next SCN   Next Time  ---- ------- ---------- -------------------- ---------- ---------  3    4       931028     25-DEC-2012 15:13:53 931604     25-DEC-2012 15:25:26BS Key  Type LV Size       Device Type Elapsed Time Completion Time     ------- ---- -- ---------- ----------- ------------ --------------------16      Full    14.67M     DISK        00:00:04     25-DEC-2012 15:25:38        BP Key: 16   Status: AVAILABLE  Compressed: NO  Tag: TAG20121225T152534        Piece Name: /u01/app/oracle/backup/c-800157471-20121225-01  Control File Included: Ckp SCN: 931613       Ckp time: 25-DEC-2012 15:25:34  SPFILE Included: Modification time: 25-DEC-2012 14:23:24RMAN> RMAN> list backupset summary;List of Backups===============Key     TY LV S Device Type Completion Time      #Pieces #Copies Compressed Tag------- -- -- - ----------- -------------------- ------- ------- ---------- ---1       B  0  A DISK        25-DEC-2012 15:12:59 1       1       NO         DB_INC02       B  0  A DISK        25-DEC-2012 15:13:40 1       1       NO         DB_INC03       B  0  A DISK        25-DEC-2012 15:13:42 1       1       NO         DB_INC04       B  A  A DISK        25-DEC-2012 15:13:57 1       1       NO         ARCH_INC05       B  A  A DISK        25-DEC-2012 15:13:57 1       1       NO         ARCH_INC06       B  A  A DISK        25-DEC-2012 15:13:58 1       1       NO         ARCH_INC07       B  A  A DISK        25-DEC-2012 15:13:59 1       1       NO         ARCH_INC08       B  A  A DISK        25-DEC-2012 15:14:01 1       1       NO         ARCH_INC09       B  F  A DISK        25-DEC-2012 15:14:06 1       1       NO         TAG20121225T15140210      B  1  A DISK        25-DEC-2012 15:25:02 1       1       NO         DB_INC111      B  1  A DISK        25-DEC-2012 15:25:14 1       1       NO         DB_INC112      B  1  A DISK        25-DEC-2012 15:25:14 1       1       NO         DB_INC113      B  A  A DISK        25-DEC-2012 15:25:34 1       1       NO         ARCH_INC114      B  A  A DISK        25-DEC-2012 15:25:34 1       1       NO         ARCH_INC115      B  A  A DISK        25-DEC-2012 15:25:34 1       1       NO         ARCH_INC116      B  F  A DISK        25-DEC-2012 15:25:38 1       1       NO         TAG20121225T152534RMAN> RMAN> list backup by file;List of Datafile Backups========================File Key     TY LV S Ckp SCN    Ckp Time             #Pieces #Copies Compressed Tag---- ------- -  -- - ---------- -------------------- ------- ------- ---------- ---1    10      B  1  A 931568     25-DEC-2012 15:24:53 1       1       NO         DB_INC1     3       B  0  A 930959     25-DEC-2012 15:12:35 1       1       NO         DB_INC02    11      B  1  A 931576     25-DEC-2012 15:25:03 1       1       NO         DB_INC1     1       B  0  A 930970     25-DEC-2012 15:12:42 1       1       NO         DB_INC03    12      B  1  A 931570     25-DEC-2012 15:24:53 1       1       NO         DB_INC1     2       B  0  A 930964     25-DEC-2012 15:12:35 1       1       NO         DB_INC04    12      B  1  A 931570     25-DEC-2012 15:24:53 1       1       NO         DB_INC1     2       B  0  A 930964     25-DEC-2012 15:12:35 1       1       NO         DB_INC05    11      B  1  A 931576     25-DEC-2012 15:25:03 1       1       NO         DB_INC1     1       B  0  A 930970     25-DEC-2012 15:12:42 1       1       NO         DB_INC06    12      B  1  A 931570     25-DEC-2012 15:24:53 1       1       NO         DB_INC1     2       B  0  A 930964     25-DEC-2012 15:12:35 1       1       NO         DB_INC07    11      B  1  A 931576     25-DEC-2012 15:25:03 1       1       NO         DB_INC1     1       B  0  A 930970     25-DEC-2012 15:12:42 1       1       NO         DB_INC0List of Archived Log Backups============================Thrd Seq     Low SCN    Low Time             BS Key  S #Pieces #Copies Compressed Tag---- ------- ---------- -------------------- ------- - ------- ------- ---------- ---1    15      892350     25-DEC-2012 11:24:17 5       A 1       1       NO         ARCH_INC01    16      926723     25-DEC-2012 14:25:11 8       A 1       1       NO         ARCH_INC01    17      926734     25-DEC-2012 14:25:23 8       A 1       1       NO         ARCH_INC01    18      926737     25-DEC-2012 14:25:26 7       A 1       1       NO         ARCH_INC01    19      931023     25-DEC-2012 15:13:51 13      A 1       1       NO         ARCH_INC12    10      926728     25-DEC-2012 14:25:14 6       A 1       1       NO         ARCH_INC02    11      931026     25-DEC-2012 15:13:52 14      A 1       1       NO         ARCH_INC13    3       926740     25-DEC-2012 14:25:27 4       A 1       1       NO         ARCH_INC03    4       931028     25-DEC-2012 15:13:53 15      A 1       1       NO         ARCH_INC1List of Control File Backups============================CF Ckp SCN Ckp Time             BS Key  S #Pieces #Copies Compressed Tag---------- -------------------- ------- - ------- ------- ---------- ---931613     25-DEC-2012 15:25:34 16      A 1       1       NO         TAG20121225T152534931040     25-DEC-2012 15:14:02 9       A 1       1       NO         TAG20121225T151402List of SPFILE Backups======================Modification Time    BS Key  S #Pieces #Copies Compressed Tag-------------------- ------- - ------- ------- ---------- ---25-DEC-2012 14:23:24 16      A 1       1       NO         TAG20121225T15253425-DEC-2012 14:23:24 9       A 1       1       NO         TAG20121225T151402RMAN> RMAN> list backup of database;List of Backup Sets===================BS Key  Type LV Size       Device Type Elapsed Time Completion Time     ------- ---- -- ---------- ----------- ------------ --------------------1       Incr 0  66.25M     DISK        00:00:24     25-DEC-2012 15:12:59        BP Key: 1   Status: AVAILABLE  Compressed: NO  Tag: DB_INC0        Piece Name: /u01/app/oracle/backup/RACDB_LVL0_20121225_03ntomb3_s3_p1  List of Datafiles in backup set 1  File LV Type Ckp SCN    Ckp Time             Name  ---- -- ---- ---------- -------------------- ----  2    0  Incr 930970     25-DEC-2012 15:12:42 +DATADG/racdb/datafile/undotbs1.258.802540615  5    0  Incr 930970     25-DEC-2012 15:12:42 +DATADG/racdb/datafile/example.264.802540751  7    0  Incr 930970     25-DEC-2012 15:12:42 +DATADG/racdb/datafile/undotbs3.269.802888323BS Key  Type LV Size       Device Type Elapsed Time Completion Time     ------- ---- -- ---------- ----------- ------------ --------------------2       Incr 0  263.96M    DISK        00:01:05     25-DEC-2012 15:13:40        BP Key: 2   Status: AVAILABLE  Compressed: NO  Tag: DB_INC0        Piece Name: /u01/app/oracle/backup/RACDB_LVL0_20121225_02ntomb3_s2_p1  List of Datafiles in backup set 2  File LV Type Ckp SCN    Ckp Time             Name  ---- -- ---- ---------- -------------------- ----  3    0  Incr 930964     25-DEC-2012 15:12:35 +DATADG/racdb/datafile/sysaux.257.802540615  4    0  Incr 930964     25-DEC-2012 15:12:35 +DATADG/racdb/datafile/users.259.802540615  6    0  Incr 930964     25-DEC-2012 15:12:35 +DATADG/racdb/datafile/undotbs2.265.802540981BS Key  Type LV Size       Device Type Elapsed Time Completion Time     ------- ---- -- ---------- ----------- ------------ --------------------3       Incr 0  370.38M    DISK        00:01:07     25-DEC-2012 15:13:42        BP Key: 3   Status: AVAILABLE  Compressed: NO  Tag: DB_INC0        Piece Name: /u01/app/oracle/backup/RACDB_LVL0_20121225_01ntomb3_s1_p1  List of Datafiles in backup set 3  File LV Type Ckp SCN    Ckp Time             Name  ---- -- ---- ---------- -------------------- ----  1    0  Incr 930959     25-DEC-2012 15:12:35 +DATADG/racdb/datafile/system.256.802540615BS Key  Type LV Size       Device Type Elapsed Time Completion Time     ------- ---- -- ---------- ----------- ------------ --------------------10      Incr 1  128.00K    DISK        00:00:09     25-DEC-2012 15:25:02        BP Key: 10   Status: AVAILABLE  Compressed: NO  Tag: DB_INC1        Piece Name: /u01/app/oracle/backup/RACDB_LVL1_20121225_0anton25_s10_p1  List of Datafiles in backup set 10  File LV Type Ckp SCN    Ckp Time             Name  ---- -- ---- ---------- -------------------- ----  1    1  Incr 931568     25-DEC-2012 15:24:53 +DATADG/racdb/datafile/system.256.802540615BS Key  Type LV Size       Device Type Elapsed Time Completion Time     ------- ---- -- ---------- ----------- ------------ --------------------11      Incr 1  232.00K    DISK        00:00:21     25-DEC-2012 15:25:14        BP Key: 11   Status: AVAILABLE  Compressed: NO  Tag: DB_INC1        Piece Name: /u01/app/oracle/backup/RACDB_LVL1_20121225_0cnton25_s12_p1  List of Datafiles in backup set 11  File LV Type Ckp SCN    Ckp Time             Name  ---- -- ---- ---------- -------------------- ----  2    1  Incr 931576     25-DEC-2012 15:25:03 +DATADG/racdb/datafile/undotbs1.258.802540615  5    1  Incr 931576     25-DEC-2012 15:25:03 +DATADG/racdb/datafile/example.264.802540751  7    1  Incr 931576     25-DEC-2012 15:25:03 +DATADG/racdb/datafile/undotbs3.269.802888323BS Key  Type LV Size       Device Type Elapsed Time Completion Time     ------- ---- -- ---------- ----------- ------------ --------------------12      Incr 1  208.00K    DISK        00:00:21     25-DEC-2012 15:25:14        BP Key: 12   Status: AVAILABLE  Compressed: NO  Tag: DB_INC1        Piece Name: /u01/app/oracle/backup/RACDB_LVL1_20121225_0bnton25_s11_p1  List of Datafiles in backup set 12  File LV Type Ckp SCN    Ckp Time             Name  ---- -- ---- ---------- -------------------- ----  3    1  Incr 931570     25-DEC-2012 15:24:53 +DATADG/racdb/datafile/sysaux.257.802540615  4    1  Incr 931570     25-DEC-2012 15:24:53 +DATADG/racdb/datafile/users.259.802540615  6    1  Incr 931570     25-DEC-2012 15:24:53 +DATADG/racdb/datafile/undotbs2.265.802540981RMAN> RMAN> list backup of archivelog all;List of Backup Sets===================BS Key  Size       Device Type Elapsed Time Completion Time     ------- ---------- ----------- ------------ --------------------4       693.00K    DISK        00:00:01     25-DEC-2012 15:13:57        BP Key: 4   Status: AVAILABLE  Compressed: NO  Tag: ARCH_INC0        Piece Name: /u01/app/oracle/backup/RACDB_ARCH_20121225_06ntomdk_s6_p1  List of Archived Logs in backup set 4  Thrd Seq     Low SCN    Low Time             Next SCN   Next Time  ---- ------- ---------- -------------------- ---------- ---------  3    3       926740     25-DEC-2012 14:25:27 931028     25-DEC-2012 15:13:53BS Key  Size       Device Type Elapsed Time Completion Time     ------- ---------- ----------- ------------ --------------------5       3.30M      DISK        00:00:01     25-DEC-2012 15:13:57        BP Key: 5   Status: AVAILABLE  Compressed: NO  Tag: ARCH_INC0        Piece Name: /u01/app/oracle/backup/RACDB_ARCH_20121225_04ntomdk_s4_p1  List of Archived Logs in backup set 5  Thrd Seq     Low SCN    Low Time             Next SCN   Next Time  ---- ------- ---------- -------------------- ---------- ---------  1    15      892350     25-DEC-2012 11:24:17 926723     25-DEC-2012 14:25:11BS Key  Size       Device Type Elapsed Time Completion Time     ------- ---------- ----------- ------------ --------------------6       791.50K    DISK        00:00:02     25-DEC-2012 15:13:58        BP Key: 6   Status: AVAILABLE  Compressed: NO  Tag: ARCH_INC0        Piece Name: /u01/app/oracle/backup/RACDB_ARCH_20121225_05ntomdk_s5_p1  List of Archived Logs in backup set 6  Thrd Seq     Low SCN    Low Time             Next SCN   Next Time  ---- ------- ---------- -------------------- ---------- ---------  2    10      926728     25-DEC-2012 14:25:14 931026     25-DEC-2012 15:13:52BS Key  Size       Device Type Elapsed Time Completion Time     ------- ---------- ----------- ------------ --------------------7       1.43M      DISK        00:00:01     25-DEC-2012 15:13:59        BP Key: 7   Status: AVAILABLE  Compressed: NO  Tag: ARCH_INC0        Piece Name: /u01/app/oracle/backup/RACDB_ARCH_20121225_07ntomdm_s7_p1  List of Archived Logs in backup set 7  Thrd Seq     Low SCN    Low Time             Next SCN   Next Time  ---- ------- ---------- -------------------- ---------- ---------  1    18      926737     25-DEC-2012 14:25:26 931023     25-DEC-2012 15:13:51BS Key  Size       Device Type Elapsed Time Completion Time     ------- ---------- ----------- ------------ --------------------8       3.50K      DISK        00:00:01     25-DEC-2012 15:14:01        BP Key: 8   Status: AVAILABLE  Compressed: NO  Tag: ARCH_INC0        Piece Name: /u01/app/oracle/backup/RACDB_ARCH_20121225_08ntomdo_s8_p1  List of Archived Logs in backup set 8  Thrd Seq     Low SCN    Low Time             Next SCN   Next Time  ---- ------- ---------- -------------------- ---------- ---------  1    16      926723     25-DEC-2012 14:25:11 926734     25-DEC-2012 14:25:23  1    17      926734     25-DEC-2012 14:25:23 926737     25-DEC-2012 14:25:26BS Key  Size       Device Type Elapsed Time Completion Time     ------- ---------- ----------- ------------ --------------------13      38.00K     DISK        00:00:02     25-DEC-2012 15:25:34        BP Key: 13   Status: AVAILABLE  Compressed: NO  Tag: ARCH_INC1        Piece Name: /u01/app/oracle/backup/RACDB_ARCH_20121225_0dnton3c_s13_p1  List of Archived Logs in backup set 13  Thrd Seq     Low SCN    Low Time             Next SCN   Next Time  ---- ------- ---------- -------------------- ---------- ---------  1    19      931023     25-DEC-2012 15:13:51 931599     25-DEC-2012 15:25:25BS Key  Size       Device Type Elapsed Time Completion Time     ------- ---------- ----------- ------------ --------------------14      58.00K     DISK        00:00:02     25-DEC-2012 15:25:34        BP Key: 14   Status: AVAILABLE  Compressed: NO  Tag: ARCH_INC1        Piece Name: /u01/app/oracle/backup/RACDB_ARCH_20121225_0enton3c_s14_p1  List of Archived Logs in backup set 14  Thrd Seq     Low SCN    Low Time             Next SCN   Next Time  ---- ------- ---------- -------------------- ---------- ---------  2    11      931026     25-DEC-2012 15:13:52 931601     25-DEC-2012 15:25:26BS Key  Size       Device Type Elapsed Time Completion Time     ------- ---------- ----------- ------------ --------------------15      5.00K      DISK        00:00:02     25-DEC-2012 15:25:34        BP Key: 15   Status: AVAILABLE  Compressed: NO  Tag: ARCH_INC1        Piece Name: /u01/app/oracle/backup/RACDB_ARCH_20121225_0fnton3c_s15_p1  List of Archived Logs in backup set 15  Thrd Seq     Low SCN    Low Time             Next SCN   Next Time  ---- ------- ---------- -------------------- ---------- ---------  3    4       931028     25-DEC-2012 15:13:53 931604     25-DEC-2012 15:25:26RMAN> RMAN> list backup of controlfile;List of Backup Sets===================BS Key  Type LV Size       Device Type Elapsed Time Completion Time     ------- ---- -- ---------- ----------- ------------ --------------------9       Full    14.67M     DISK        00:00:04     25-DEC-2012 15:14:06        BP Key: 9   Status: AVAILABLE  Compressed: NO  Tag: TAG20121225T151402        Piece Name: /u01/app/oracle/backup/c-800157471-20121225-00  Control File Included: Ckp SCN: 931040       Ckp time: 25-DEC-2012 15:14:02BS Key  Type LV Size       Device Type Elapsed Time Completion Time     ------- ---- -- ---------- ----------- ------------ --------------------16      Full    14.67M     DISK        00:00:04     25-DEC-2012 15:25:38        BP Key: 16   Status: AVAILABLE  Compressed: NO  Tag: TAG20121225T152534        Piece Name: /u01/app/oracle/backup/c-800157471-20121225-01  Control File Included: Ckp SCN: 931613       Ckp time: 25-DEC-2012 15:25:34RMAN>","title":"Oracle 10g RAC RMAN backup Example"},{"content":"前言： 相信大家都用过这两种类型，可能觉得它们两个太像了，好像没有什么区别，用这两个都可以存文字和数字还有空格和标点符号。在设计数据库的时候，也的确不太能区分什么时候用CHAR，什么时候用VARCHAR. 今天就详细的查看和测试了一下这两个字段，并记录下来了。相信也会给大家一个很好的参考。 －－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－－ CHAR和VARCHAR类型类似，但它们保存和检索的方式不同。它们的最大长度和是否尾部空格被保留等方面也不同。在存储或检索过程中不进行大小写转换。 CHAR和VARCHAR类型声明的长度表示你想要保存的最大字符数。例如，CHAR(30)可以占用30个字符。 CHAR列的长度固定为创建表时声明的长度。长度可以为从0到255的任何值。当保存CHAR值时，在它们的右边填充空格以达到指定的长度。当检索到CHAR值时，尾部的空格被删除掉。在存储或检索过程中不进行大小写转换。 VARCHAR列中的值为可变长字符串。长度可以指定为0到65,535之间的值。(VARCHAR的最大有效长度由最大行大小和使用的字符集确定。整体最大长度是65,532字节）。 同CHAR对比，VARCHAR值保存时只保存需要的字符数，另加一个字节来记录长度(如果列声明的长度超过255，则使用两个字节)。 VARCHAR值保存时不进行填充。当值保存和检索时尾部的空格仍保留，符合标准SQL。 如果分配给CHAR或VARCHAR列的值超过列的最大长度，则对值进行裁剪以使其适合。如果被裁掉的字符不是空格，则会产生一条警告。如果裁剪非空格字符，则会造成错误(而不是警告)并通过使用严格SQL模式禁用值的插入。参见5.3.2节，“SQL服务器模式”。 下面的表显示了将各种字符串值保存到CHAR(4)和VARCHAR(4)列后的结果，说明了CHAR和VARCHAR之间的差别： 值 CHAR(4) 存储需求 VARCHAR(4) 存储需求 '' '    ' 4个字节 '' 1个字节 'ab' 'ab  ' 4个字节 'ab ' 3个字节 'abcd' 'abcd' 4个字节 'abcd' 5个字节 'abcdefgh' 'abcd' 4个字节 'abcd' 5个字节 请注意上表中最后一行的值只适用不使用严格模式时；如果MySQL运行在严格模式，超过列长度不的值不保存，并且会出现错误。 从CHAR(4)和VARCHAR(4)列检索的值并不总是相同，因为检索时从CHAR列删除了尾部的空格。通过下面的例子说明该差别： mysql> CREATE TABLE vc (v VARCHAR(4), c CHAR(4)); Query OK, 0 rows affected (0.02 sec) mysql> INSERT INTO vc VALUES ('ab  ', 'ab  '); Query OK, 1 row affected (0.00 sec) mysql> SELECT CONCAT(v, '+'), CONCAT(c, '+') FROM vc; +----------------+----------------+ | CONCAT(v, '+') | CONCAT(c, '+') | +----------------+----------------+ | ab  +          | ab+            | +----------------+----------------+ 1 row in set (0.00 sec) 根据分配给列的字符集校对规则对CHAR和VARCHAR列中的值进行排序和比较。 请注意所有MySQL校对规则属于PADSPACE类。这说明在MySQL中的所有CHAR和VARCHAR值比较时不需要考虑任何尾部空格。例如： mysql> CREATE TABLE names (myname CHAR(10), yourname VARCHAR(10)); Query OK, 0 rows affected (0.09 sec) mysql> INSERT INTO names VALUES ('Monty ', 'Monty '); Query OK, 1 row affected (0.00 sec) mysql> SELECT myname = 'Monty  ', yourname = 'Monty  ' FROM names; +--------------------+----------------------+ | myname = 'Monty  ' | yourname = 'Monty  ' | +--------------------+----------------------+ |                  1 |                    1 | +--------------------+----------------------+ 1 row in set (0.00 sec) 请注意所有MySQL版本均如此，并且它不受SQL服务器模式的影响。 对于尾部填充字符被裁剪掉或比较时将它们忽视掉的情形，如果列的索引需要唯一的值，在列内插入一个只是填充字符数不同的值将会造成复制键值错误。 CHAR BYTE是CHAR BINARY的别名。这是为了保证兼容性。 ASCII属性为CHAR列分配latin1字符集。UNICODE属性分配ucs2字符集。 总结来说： 在MySQL数据库中，用的最多的字符型数据类型就是Varchar和Char.。这两种数据类型虽然都是用来存放字符型数据，但是无论从结构还是从数据的保存方式来看，两者相差很大。而且其具体的实现方式，还依赖与存储引擎。我这里就以大家最常用的MYISAM存储引擎为例，谈谈这两种数据类型的差异。在后续建议中，也是针对这种存储类型而言的。 　　这里首先需要明白的一点是，这两种数据类型，无论采用哪一种存储引起，系统存储数据的方式都是不同的。正是因为如此，我们才有必要研究两者的不同。然后在合适的情况下，采用恰当的方式。了解这一点之后，我们再来看后续的内容。 　　Varchar往往用来保存可变长度的字符串。简单的说，我们只是给其固定了一个最大值，然后系统会根据实际存储的数据量来分配合适的存储空间。为此相比CHAR字符数据而言，其能够比固定长度类型占用更少的存储空间。不过在实际工作中，由于某系特殊的原因，会在这里设置例外。如管理员可以根据需要指定ROW_FORMAT=FIXED选项。利用这个选项来创建MyISAM表的话，系统将会为每一行使用固定长度的空间。此时会造成存储空间的损耗。通常情况下，VARCHAR数据类型能够节约磁盘空间，为此往往认为其能够提升数据库的性能。不过这里需要注意的是，这往往是一把双刃剑。其在提升性能的同时，往往也会产生一些副作用。如因为其长度是可变的，为此在数据进行更新时可能会导致一些额外的工作。如在更改前，其字符长度是10位(Varchar规定的最长字符数假设是50位)，此时系统就只给其分配10个存储的位置(假设不考虑系统自身的开销)。更改后，其数据量达到了20位。由于没有超过最大50位的限制，为此数据库还是允许其存储的。只是其原先的存储位置已经无法满足其存储的需求。此时系统就需要进行额外的操作。如根据存储引擎不同，有的会采用拆分机制，而有的则会采用分页机制。 　　CHAR数据类型与VARCHAR数据类型不同，其采用的是固定长度的存储方式。简单的说，就是系统总为其分配最大的存储空间。当数据保存时，即使其没有达到最大的长度，系统也会为其分配这么多的存储空间。显然，这种存储方式会造成磁盘空间的浪费。这里笔者需要提醒的一点是，当字符位数不足时，系统并不会采用空格来填充。相反，如果在保存CHAR值的时候，如果其后面有空值，系统还会自动过滤其空格。而在进行数据比较时，系统又会将空格填充到字符串的末尾。 　　显然，VARCHAR与CHAR两种字符型数据类型相比，最大的差异就是前者是可变长度，而后者则是固定长度。在存储时，前者会根据实际存储的数据来分配最终的存储空间。而后者则不管实际存储数据的长度，都是根据CHAR规定的长度来分配存储空间。这是否意味着CHAR的数据类型劣于VARCHAR呢?其实不然。否则的话，就没有必要存在CHAR字符类型了。虽然VARCHAR数据类型可以节省存储空间，提高数据处理的效率。但是其可变长度带来的一些负面效应，有时候会抵消其带来的优势。为此在某些情况下，还是需要使用Char数据类型。 项目建议 　　根据上面的分析，我们知道VARCHAR数据类型是一把双刃剑，其在带来性能提升的同时，也可能会存在着一些额外的消耗。我们在评估到底是使用VARCHAR数据类型还是采用CHAR数据类型时，就需要进行均衡。在实际项目中，我们会考量如下情况。 　　一是根据字符的长度来判断。如某个字段，像人的名字，其最长的长度也是有限的。如我们给其分配18个字符长度即可。此时虽然每个人的名字长度有可能不同，但是即使为其分配了固定长度的字符类型，即18个字符长度，最后浪费的空间也不是很大。而如果采用NVARCHAR数据类型时，万一以后需要改名，而原先的存储空间不足用来容纳新的值，反而会造成一些额外的工作。在这种情况下，进行均衡时，会认为采用CHAR固定长度的数据类型更好。在实际项目中，如果某个字段的字符长度比较短此时一般是采用固定字符长度。 　　二是考虑其长度的是否相近。如果某个字段其长度虽然比较长，但是其长度总是近似的，如一般在90个到100个字符之间，甚至是相同的长度。此时比较适合采用CHAR字符类型。比较典型的应用就是MD5哈希值。当利用MD5哈希值来存储用户密码时，就非常使用采用CHAR字符类型。因为其长度是相同的。另外，像用来存储用户的身份证号码等等，一般也建议使用CHAR类型的数据。 　　另外请大家考虑一个问题，CHAR(1)与VARCHAR(1)两这个定义，会有什么区别呢?虽然这两个都只能够用来保存单个的字符，但是VARCHAR要比CHAR多占用一个存储位置。这主要是因为使用VARCHAR数据类型时，会多用1个字节用来存储长度信息。这个管理上的开销CHAR字符类型是没有的。 　　三是从碎片角度进行考虑。使用CHAR字符型时，由于存储空间都是一次性分配的。为此某个字段的内容，其都是存储在一起的。单从这个角度来讲，其不存在碎片的困扰。而可变长度的字符数据类型，其存储的长度是可变的。当其更改前后数据长度不一致时，就不可避免的会出现碎片的问题。故使用可变长度的字符型数据时，数据库管理员要时不时的对碎片进行整理。如执行数据库导出导入作业，来消除碎片。 　　四是即使使用Varchar数据类型，也不能够太过于慷慨。这是什么意思呢?如现在用户需要存储一个地址信息。根据评估，只要使用100个字符就可以了。但是有些数据库管理员会认为，反正Varchar数据类型是根据实际的需要来分配长度的。还不如给其大一点的呢。为此他们可能会为这个字段一次性分配200个字符的存储空间。这VARCHAR(100)与VARCHAR(200)真的相同吗?结果是否定的。虽然他们用来存储90个字符的数据，其存储空间相同。但是对于内存的消耗是不同的。对于VARCHAR数据类型来说，硬盘上的存储空间虽然都是根据实际字符长度来分配存储空间的，但是对于内存来说，则不是。其时使用固定大小的内存块来保存值。简单的说，就是使用字符类型中定义的长度，即200个字符空间。显然，这对于排序或者临时表(这些内容都需要通过内存来实现)作业会产生比较大的不利影响。所以如果某些字段会涉及到文件排序或者基于磁盘的临时表时，分配VARCHAR数据类型时仍然不能够太过于慷慨。还是要评估实际需要的长度，然后选择一个最长的字段来设置字符长度。如果为了考虑冗余，可以留10%左右的字符长度。千万不能认为其为根据实际长度来分配存储空间，而随意的分配长度，或者说干脆使用最大的字符长度。 补充 在MySQL中用来判断是否需要进行对据列类型转换的规则 　　１、在一个数据表里，如果每一个数据列的长度都是固定的，那么每一个数据行的长度也将是固定的． 　　２、只要数据表里有一个数据列的长度的可变的，那么各数据行的长度都是可变的． 　　３、如果某个数据表里的数据行的长度是可变的，那么，为了节约存储空间，MySQL会把这个数据表里的固定长度类型的数据列转换为相应的可变长度类型． 例外：长度小于４个字符的char数据列不会被转换为varchar类型 　　对于MyISAM表，尽量使用Char，对于那些经常需要修改而容易形成碎片的myisam和isam数据表就更是如此，它的缺点就是占用磁盘空间； 　　对于InnoDB表，因为它的数据行内部存储格式对固定长度的数据行和可变长度的数据行不加区分（所有数据行共用一个表头部分，这个标头部分存放着指向各有关数据列的指针），所以使用char类型不见得会比使用varchar类型好。事实上，因为char类型通常要比varchar类型占用更多的空间，所以从减少空间占用量和减少磁盘i/o的角度，使用varchar类型反而更有利. 文章2： 字符应该是最常见的一种了，但似乎各个数据库都有所不同，比如oracle中就有啥varchar2之类。不过mysql似乎最多的还是集中在char和varchar上。 说说区别。char是固定长度的，而varchar会根据具体的长度来使用存储空间。比如char(255)和varchar(255)，在存储字符串\"hello world\"的时候，char会用一块255的空间放那个11个字符，而varchar就不会用255个，他先计算长度后只用11个再加上计算的到字符串长度信息，一般1-2个byte来，这样varchar在存储不确定长度的时候会大大减少存储空间。 如此看来varchar比char聪明多了，那char有用武之地吗？还是很不少优势的。 一，存储很短的信息，比如门牌号码101，201……这样很短的信息应该用char，因为varchar还要占个byte用于存储信息长度，本来打算节约存储的现在得不偿失。 二，固定长度的。比如使用uuid作为主键，那用char应该更合适。因为他固定长度，varchar动态根据长度的特性就消失了，而且还要占个长度信息。 三，十分频繁改变的column。因为varchar每次存储都要有额外的计算，得到长度等工作，如果一个非常频繁改变的，那就要有很多的精力用于计算，而这些对于char来说是不需要的。 还有一个关于varchar的问题是，varchar他既然可以自动适应存储空间，那我varchar(8)和varchar(255)存储应该都是一样的，那每次表设计的时候往大的方向去好了，免得以后不够用麻烦。这个思路对吗？答案是否定的。mysql会把表信息放到内存中（查询第一次后，就缓存住了，linux下很明显，但windows下似乎没有，不知道为啥），这时内存的申请是按照固定长度来的，如果varchar很大就会有问题。所以还是应该按需索取。 总结：仔细看DZ的数据表，定长的字段基本还都是用char....   详细出处参考：http://www.jb51.net/article/23575.htm","title":"MySQL 深入剖析 char varchar 类型，有了VARCHAR，为什么还要有CHAR？"},{"content":"一下的判断条件，以null为列： 【sqlserver】： sqlserver 认为 null 最小。 升序排列：null 值默认排在最前。 要想排后面，则：order by case when col is null then 1 else 0 end ,col 降序排列：null 值默认排在最后。 要想排在前面，则：order   by case when col is null then 0 else 1 end , col desc  【oracle】： oracle认为 null 最大。 升序排列，默认情况下，null值排后面。 降序排序，默认情况下，null值排前面。 有几种办法改变这种情况： （1）用 nvl 函数或decode 函数 将null转换为一特定值 （2）用case语法将null转换为一特定值（oracle9i以后版本支持。和sqlserver类似）： order by (case mycol when null then ’北京漂客’     else   mycol   end) （3）使用nulls first 或者nulls last 语法。 这是oracle专门用来null值排序的语法。 nulls first ：将null排在最前面。如：select * from mytb order by mycol nulls first null last ：将null排在最后面。如：select * from mytb order by mycol nulls last","title":"sqlserver,oracle 排序order by"},{"content":"今天遇到一个问题，数据库有几张表的数据被清除了。因为数据是昨天晚上被删除的，当时没有用户访问，所以根据日志备份就可以将数据还原，没有数据损失。但是是谁删除了数据呢？   在2008之前有很多工具都可以分析数据库的在线日志和备份文件，但是支持2008以及更高版本的不是很多。这里我是用了ApexSQL Log 2011，关于ApexSQL Log 2011的功能：   ApexSQL Log is a SQL Server Transaction Log reader that allows viewing transaction log data in read-friendly format. Audit and undo SQL database changes of your choosing. Determine who changed the data and when the change occurred. Read the transaction log to find out who created, changed or dropped a database object   这个正好是我所需要的，而且有14天的免费试用版，功能也没有限制。下载之后安装，然后打开在线日志同时选择了问题发生之后的日志文件进行分析，轻松的找出了当时执行的语句。结果并不是我们想象的数据删除，而是应用程序的某个功能被同时无误使用了，结果导致数据库表被DROP然后重新创建。   选择在线日志和备份文件界面如图：     有一个缺点是显示栏位有点少，如果能够显示当时执行的应用程序名称就更完美了。不过，对于数据库日志分析确实是一款不错的产品。        ","title":"使用ApexSQL Log 分析数据库在线日志及数据库备份"},{"content":"1、在Tools/Model Options...菜单中，选择Naming Convention选项的Name To Code选项卡，如下图所示： 2、在Conversion_script:中输入“.convert_name(%Name%,\"_\",\"'-/ '\")”转换代码。 其中：\"_\"是要被替换成的元素，\"'-/ '\"是要替换的元素，这里指“-”，“/”，“ ”。 意思是遇到中横、斜杠和空格将其替换成竖下划线；%Name%代表映射中的Name。 3、打开Conversion table的文件选择按钮，可以选择映射文件。 该文件是EXCEL格式，有样表，可以自行定义。 4、打开属性按钮，可以查看映射的内容，如下图所示： 5、以上步骤配置好以后，在新建表或添加字段时，就可以根据映射填写Name自动生成符合要求的Code了。 6、感想： 设置好以后，该配置仅对以后新生成的表或新添加的字段有用，所以必须在模型建立之初就将相应的映射规划建立好(对于个别字段建模时可以点击Code的“=”进行更新，但很明显这并不适合于大批量操作)；Name如是映射中的两个中文词语组成则需要在Name中添加空格或其他分隔符才能将Code映射成功，如，“行业类型”需要写成“行业 类型”。 本文配置简单，方便好用。但在初试的时候，Conversion_script却不知道如何去写，在此过程中得到了Bobby Luo的热心帮助，非常感谢。 帮助邮件原文： 应该是 .convert_name(%Name%,\"_\",\"'-/'\") http://infocenter.sybase.com/help/index.jsp?topic=/com.sybase.stf.powerdesigner.eclipse.docs_15.0.0/html/bwug/bwugp343.htm  你在google中搜索 \"powerdesigner convert_name\" 可以找得到，百度搜索技术资料不行===== 回复前原始邮件 =====  ","title":"PowerDesigner代码关联名称映射设置"},{"content":"到metalink上下载p8202632_10205_LINUX.zip补丁，上传到服务器。下面进行升级：   1.停止RAC [oracle@b87 ~]$ srvctl stop database -d racdb        [oracle@b87 ~]$ srvctl stop asm -n b87 [oracle@b87 ~]$ srvctl stop asm -n b88 [oracle@b87 ~]$ srvctl stop listener -n b87 [oracle@b87 ~]$ srvctl stop listener -n b88     [oracle@b87 ~]$ crs_stat -t Name           Type           Target    State    Host        ------------------------------------------------------------ ora....SM1.asm application    OFFLINE  OFFLINE               ora....87.lsnr application    OFFLINE  OFFLINE               ora.b87.gsd    application    ONLINE   ONLINE    b87         ora.b87.ons   application    ONLINE    ONLINE   b87         ora.b87.vip   application    ONLINE    ONLINE   b87         ora....SM2.asm application    OFFLINE  OFFLINE               ora....88.lsnr application    OFFLINE  OFFLINE               ora.b88.gsd   application    ONLINE    ONLINE   b88         ora.b88.ons   application    ONLINE    ONLINE   b88         ora.b88.vip   application    ONLINE    ONLINE   b88         ora.racdb.db  application    OFFLINE   OFFLINE               ora....b1.inst application    OFFLINE  OFFLINE               ora....b2.inst application    OFFLINE  OFFLINE        2.解压包 unzip p8202632_10205_LINUX.zip   [root@b87 opt]# cd Disk1/ [root@b87 Disk1]# ls install patch_note.htm  response  runInstaller stage   3.开始升级clusterware [oracle@b87 Disk1]$ ./runInstaller Starting Oracle Universal Installer...   Checking installer requirements...   Checking operating system version: must be redhat-3,SuSE-9, SuSE-10, redhat-4, redhat-5, redhat-6, UnitedLinux-1.0, asianux-1,asianux-2, asianux-3, enterprise-4, enterprise-5 or SuSE-11                                       Passed     All installer requirements met.   Preparing to launch Oracle Universal Installer from/tmp/OraInstall2012-12-25_02-26-20PM. Please wait ...[oracle@b87 Disk1]$ OracleUniversal Installer, Version 10.2.0.5.0 Production Copyright (C) 1999, 2010, Oracle. All rights reserved.                                 欢迎界面，选择NEXT   这里注意，现在我们是升级CLUSTERWARE集群软件，选择相应的目录（CRS_HOME） 看清楚，不要选择（ORACLE_HOME），选好后NEXT.   保持默认，next   检测环境，通过后，next，我在这一步报内核参数不对，按照提示修改相关参数即可，最后别忘记sysctl –p.   安装之前的概要，选择安装。   安装进行中，持续30分钟左右。   安装结束，提示在所有节点运行脚本：   先在第一个节点上运行： [root@b87 ~]# /opt/u01/oracle/product/crs/bin/crsctlstop crs Stopping resources. Successfully stopped CRS resources Stopping CSSD. Shutting down CSS daemon. Shutdown request successfully issued.   [root@b87 ~]#/opt/u01/oracle/product/crs/install/root102.sh Creating pre-patch directory for saving pre-patchclusterware files Completed patching clusterware files to/opt/u01/oracle/product/crs Relinking some shared libraries. Relinking of patched files is complete. WARNING: directory '/opt/u01/oracle/product' is notowned by root WARNING: directory '/opt/u01/oracle' is not owned byroot WARNING: directory '/opt/u01' is not owned by root Preparing to recopy patched init and RC scripts. Recopying init and RC scripts. Startup will be queued to init within 30 seconds. Starting up the CRS daemons. Waiting for the patched CRS daemons to start.   This may take a while on some systems. . 10205 patch successfully applied. clscfg: EXISTING configuration version 3 detected. clscfg: version 3 is 10G Release 2. Successfully deleted 1 values from OCR. Successfully deleted 1 keys from OCR. Successfully accumulated necessary OCR keys. Using ports: CSS=49895 CRS=49896 EVMC=49898 andEVMR=49897. node <nodenumber>: <nodename> <privateinterconnect name> <hostname> node 1: b87 b87-priv b87 Creating OCR keys for user 'root', privgrp 'root'.. Operation successful. clscfg -upgrade completed successfully Creating'/opt/u01/oracle/product/crs/install/paramfile.crs' with data used for CRSconfiguration Setting CRS configuration values in/opt/u01/oracle/product/crs/install/paramfile.crs   在第二个节点上运行： [root@b88 ~]# /opt/u01/oracle/product/crs/bin/crsctlstop crs Stopping resources. Successfully stopped CRS resources Stopping CSSD. Shutting down CSS daemon. Shutdown request successfully issued.     [root@b88 ~]#/opt/u01/oracle/product/crs/install/root102.sh Creating pre-patch directory for saving pre-patchclusterware files Completed patching clusterware files to/opt/u01/oracle/product/crs Relinking some shared libraries. Relinking of patched files is complete. WARNING: directory '/opt/u01/oracle/product' is notowned by root WARNING: directory '/opt/u01/oracle' is not owned byroot WARNING: directory '/opt/u01' is not owned by root Preparing to recopy patched init and RC scripts. Recopying init and RC scripts. Startup will be queued to init within 30 seconds. Starting up the CRS daemons. Waiting for the patched CRS daemons to start.   This may takea while on some systems. . 10205 patch successfully applied. clscfg: EXISTING configuration version 3 detected. clscfg: version 3 is 10G Release 2. Successfully deleted 1 values from OCR. Successfully deleted 1 keys from OCR. Successfully accumulated necessary OCR keys. Using ports: CSS=49895 CRS=49896 EVMC=49898 andEVMR=49897. node <nodenumber>: <nodename> <privateinterconnect name> <hostname> node 2: b88 b88-priv b88 Creating OCR keys for user 'root', privgrp 'root'.. Operation successful. clscfg -upgrade completed successfully Creating'/opt/u01/oracle/product/crs/install/paramfile.crs' with data used for CRSconfiguration Setting CRS configuration values in /opt/u01/oracle/product/crs/install/paramfile.crs 到此clusterware升级完成，crs已经重启，下面我们开始升级数据库软件。   4.升级database software 在升级clusterware的时候，升级结束的时候会启动CRS服务。但是在升级数据库的时候要关闭这些服务，命令如下（以下关闭命令也是正常关闭RAC的方法）： [oracle@b88 ~]$ srvctl stop database -d racdb [oracle@b88 ~]$ srvctl stop service -d racdb [oracle@b88 ~]$ srvctl stop asm -n b87 [oracle@b88 ~]$ srvctl stop asm -n b88 [oracle@b88 ~]$ srvctl stop listener -n b87 [oracle@b88 ~]$ srvctl stop listener -n b88   开始升级数据库软件，还是运行补丁包下的runInstaller [oracle@b87 Disk1]$ ./runInstaller Starting Oracle Universal Installer...   Checking installer requirements...   Checking operating system version: must be redhat-3,SuSE-9, SuSE-10, redhat-4, redhat-5, redhat-6, UnitedLinux-1.0, asianux-1,asianux-2, asianux-3, enterprise-4, enterprise-5 or SuSE-11                                       Passed     All installer requirements met.   Preparing to launch Oracle Universal Installer from/tmp/OraInstall2012-12-25_03-19-06PM. Please wait ...[oracle@b87 Disk1]$ OracleUniversal Installer, Version 10.2.0.5.0 Production Copyright (C) 1999, 2010, Oracle. All rights reserved.   首先出来欢迎界面，next。   像升级CLUSTERWARE一样，这一步注意选择oracle_home，next。   默认是让你加入metalink,我这里不选，next。   保持默认即可，next。   检测环境，next。   安装前的概要文件，选择install.   升级过程中，持续30分钟左右。   安装完成，提示在所有节点用root执行脚本。 在节点1上执行： [root@b87 ~]# /opt/u01/oracle/product/10.2.0.1/root.sh Running Oracle 10g root.sh script...   The following environment variables are set as:    ORACLE_OWNER= oracle    ORACLE_HOME= /opt/u01/oracle/product/10.2.0.1   Enter the full pathname of the local bin directory:[/usr/local/bin]: The file \"dbhome\" already exists in/usr/local/bin.  Overwrite it? (y/n) [n]: y    Copyingdbhome to /usr/local/bin ... The file \"oraenv\" already exists in/usr/local/bin.  Overwrite it? (y/n) [n]: y    Copyingoraenv to /usr/local/bin ... The file \"coraenv\" already exists in/usr/local/bin.  Overwrite it? (y/n) [n]: y    Copyingcoraenv to /usr/local/bin ...   Entries will be added to the /etc/oratab file asneeded by Database Configuration Assistant when a database iscreated Finished running generic part of root.sh script. Now product-specific root actions will be performed. 在节点2上执行 [root@b88 ~]# /opt/u01/oracle/product/10.2.0.1/root.sh Running Oracle 10g root.sh script...   The following environment variables are set as:    ORACLE_OWNER= oracle    ORACLE_HOME= /opt/u01/oracle/product/10.2.0.1   Enter the full pathname of the local bin directory:[/usr/local/bin]: The file \"dbhome\" already exists in/usr/local/bin.  Overwrite it? (y/n) [n]: y    Copyingdbhome to /usr/local/bin ... The file \"oraenv\" already exists in/usr/local/bin.  Overwrite it? (y/n) [n]: y    Copyingoraenv to /usr/local/bin ... The file \"coraenv\" already exists in/usr/local/bin.  Overwrite it? (y/n) [n]: y    Copyingcoraenv to /usr/local/bin ...   Entries will be added to the /etc/oratab file asneeded by Database Configuration Assistant when a database iscreated Finished running generic part of root.sh script. Now product-specific root actions will be performed. 到此，数据库软件的升级完成。下面开始升级数据库（这里数据库是指库文件）。   5.升级database 先启动相关应用（启动ASM,监听即可，实例可以不启动。如果使用脚本升级，实例需要启动到nomount,我们这里介绍使用DBUA进行升级，DBUA会帮助我们启动实例，我们不需要干预）。 启动ASM和监听 [oracle@b88 ~]$ srvctl start asm -n b87 [oracle@b88 ~]$ srvctl start asm -n b88 [oracle@b88 ~]$ srvctl start listener -n b87 [oracle@b88 ~]$ srvctl start listener -n b88 [oracle@b88 ~]$ crs_stat -t -v Name          Type           R/RA   F/FT  Target    State     Host        ---------------------------------------------------------------------- ora....SM1.asm application    0/5   0/0    ONLINE    ONLINE   b87         ora....87.lsnr application    0/5   0/0    ONLINE    ONLINE   b87         ora.b87.gsd   application    0/5    0/0   ONLINE    ONLINE    b87         ora.b87.ons   application    0/3    0/0   ONLINE    ONLINE    b87         ora.b87.vip   application    0/0    0/0   ONLINE    ONLINE    b87         ora....SM2.asm application    0/5   0/0    ONLINE    ONLINE   b88         ora....88.lsnr application    0/5   0/0    ONLINE    ONLINE   b88         ora.b88.gsd   application    0/5    0/0   ONLINE    ONLINE    b88         ora.b88.ons   application    0/3    0/0   ONLINE    ONLINE    b88         ora.b88.vip   application    0/0    0/0   ONLINE    ONLINE    b88         ora.racdb.db  application    0/1    0/1   OFFLINE   OFFLINE               ora....b1.inst application    0/5   0/0    OFFLINE   OFFLINE               ora....b2.inst application    0/5   0/0    OFFLINE   OFFLINE   在一个节点上运行dbua即可： [oracle@b87 Disk1]$ dbua   欢迎界面，next。   选择Upgrade a database,next.   输入sys和密码，next。   这里是选择是否编译无效对象，以及选择用多少个CPU来进行并行编译无效对象。从而加快编译速度，我们服务器是虚拟化只配了2个CPU，这里我们选2，下面是询问是否在编译时关闭归档，因为在编译的时候数据库会产生很多日志，这时候如果是归档，会影响速度，我们选择关闭归档（等数据库升级完成后，归档会自动开启）。   指定闪回区，next。   安装前的概要，finish.   升级过程中，持续1个小时左右。 到此数据库的升级完成，下面我们进行验证。 验证： [oracle@b87 ~]$ sqlplus /nolog SQL*Plus: Release 10.2.0.5.0 - Production on Tue Dec25 18:23:07 2012   Copyright (c) 1982, 2010, Oracle.  All Rights Reserved.   SQL> conn / as sysdba Connected. SQL> set line 150 pages 1000 SQL> select * from gv$instance;      INST_IDINSTANCE_NUMBER INSTANCE_NAME   HOST_NAME                                                       VERSION           STARTUP_TIME ---------- --------------- ------------------------------------------------------------------------------------------------- ------------ STATUS       PAR   THREAD# ARCHIVE LOG_SWITCH_WAIT LOGINS     SHU DATABASE_STATUS   INSTANCE_ROLE      ACTIVE_ST BLO ------------ --- ---------- ------- ------------------------- --- ----------------- ------------------ --------- ---          1               1 racdb1           b87                                                             10.2.0.5.0        25-DEC-12 OPEN        YES          1 STARTED                 ALLOWED    NO ACTIVE           PRIMARY_INSTANCE   NORMAL    NO            2               2 racdb2           b88                                                             10.2.0.5.0        25-DEC-12 OPEN        YES          2 STARTED                 ALLOWED    NO ACTIVE           PRIMARY_INSTANCE   NORMAL    NO   SQL>  colstatus for a10 SQL> col version for a15 SQL> col comp_name for a35 SQL> select comp_name,version,status fromdba_registry;   COMP_NAME                           VERSION         STATUS ----------------------------------- ------------------------- Oracle Enterprise Manager           10.2.0.5.0      VALID Spatial                             10.2.0.5.0      VALID Oracle interMedia                   10.2.0.5.0      VALID OLAP Catalog                        10.2.0.5.0      VALID Oracle XML Database                 10.2.0.5.0      VALID Oracle Text                         10.2.0.5.0      VALID Oracle Expression Filter            10.2.0.5.0      VALID Oracle Rule Manager                 10.2.0.5.0      VALID Oracle Workspace Manager            10.2.0.5.0      VALID Oracle Data Mining                  10.2.0.5.0      VALID Oracle Database Catalog Views       10.2.0.5.0      VALID Oracle Database Packages and Types  10.2.0.5.0      VALID JServer JAVA Virtual Machine        10.2.0.5.0      VALID Oracle XDK                          10.2.0.5.0      VALID Oracle Database Java Packages       10.2.0.5.0      VALID OLAP Analytic Workspace             10.2.0.5.0      VALID Oracle OLAP API                     10.2.0.5.0      VALID Oracle Real Application Clusters    10.2.0.5.0      VALID     SQL> select * fromv$version;   BANNER ---------------------------------------------------------------- Oracle Database 10gEnterprise Edition Release 10.2.0.5.0 - Prod PL/SQL Release 10.2.0.5.0 -Production CORE    10.2.0.5.0      Production TNS for Linux: Version10.2.0.5.0 - Production NLSRTL Version 10.2.0.5.0 -Production  ","title":"Redhat 5.5 Orcle RAC 数据库 从10.2.0.1升级到 10.2.0.5"},{"content":"由于可以在SQL Server进程上面运行.NET程序集，为了满足特殊的计算方式。所以用CLR代码创建用户自定义函数： 步骤笔记如下： 1）VS里面新建类库，写好里面的函数【里面的参数和返回参数类型要用数据库对应的类型】 2）然后用CREATE ASSEMBLY TESTNAME FROM '目录\\Test.dll' WITH PERMISSION_SET = SAFE --DROP ASSEMBLY TESTNAME 3）创建函数CREATE FUNCTION 函数名(@name NVARCHAR(12)) RETURNS NVARCHAR(30) AS EXTERNAL NAME [TESTNAME].[自定义类].自定义方法 --DROP FUNCTION   函数名 4）测试是否成功SELECT DBO. 函数名(N'唐')","title":"SQL Server自定义函数"},{"content":"oracle数据库连接hang，出现了两个listener，一个是另一个子进程 处理过程如下 1，出现问题时，用户连接hang住，出现两个listener，现有连接无问题 $ ps -ef|grep lsnr   oracle 26327     1  0 12月 24  ?         5:34 /oracle/product/10.2.0.1/bin/tnslsnr LISTENER -inherit   oracle 16352 12931  1 10:44:26 pts/4     0:00 grep lsnr   oracle 28413 26327  0 21:40:46 ?         0:00 /oracle/product/10.2.0.1/bin/tnslsnr LISTENER -inherit   patrol 29576 29575  0 21:45:19 ?         0:00 /oracle/product/10.2.0.1/bin/lsnrctl stat LISTENER 2，为快速恢复问题，杀掉进程 $ kill -9 26327 3，重启 $ lsnrctl start LSNRCTL for HPUX: Version 10.2.0.1.0 - Production on 26-DEC-2012 10:44:54 Copyright (c) 1991, 2005, Oracle.  All rights reserved. Starting /oracle/product/10.2.0.1/bin/tnslsnr: please wait... TNSLSNR for HPUX: Version 10.2.0.1.0 - Production System parameter file is /oracle/product/10.2.0.1/network/admin/listener.ora Log messages written to /oracle/product/10.2.0.1/network/log/listener.log Listening on: (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=rps02)(PORT=1521))) Listening on: (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=EXTPROC0))) Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=rps02)(PORT=1521))) STATUS of the LISTENER ------------------------ Alias                     LISTENER Version                   TNSLSNR for HPUX: Version 10.2.0.1.0 - Production Start Date                26-DEC-2012 10:44:56 Uptime                    0 days 0 hr. 0 min. 0 sec Trace Level               off Security                  ON: Local OS Authentication SNMP                      ON Listener Parameter File   /oracle/product/10.2.0.1/network/admin/listener.ora Listener Log File         /oracle/product/10.2.0.1/network/log/listener.log Listening Endpoints Summary...   (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=rps02)(PORT=1521)))   (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=EXTPROC0))) Services Summary... Service \"PLSExtProc\" has 1 instance(s).   Instance \"PLSExtProc\", status UNKNOWN, has 1 handler(s) for this service... The command completed successfully 4，恢复正常，只有一个listener $ $ ps -ef|grep lsnr   oracle 16503     1  0 10:44:56 ?         0:00 /oracle/product/10.2.0.1/bin/tnslsnr LISTENER -inherit   oracle 17637 12931  1 10:48:17 pts/4     0:00 grep lsnr $ 5，后续查询metalink，基本确定为bug，需打oracle  Patch 4518443 详见文件Intermittent TNS Listener Hang, New Child Listener Process Forked [ID 340091.1] 除了打补丁，oracle给出的其它解决方案是 a,修改listener.ora文件 SUBSCRIBE_FOR_NODE_DOWN_EVENT_<listener_name>=OFF b,移动ons.config文件 cd $ORACLE_HOME/opmn/conf mv ons.config ons.config.ori 6，更详细的原因见参考metalink文档 In this Document     Description     Occurrence     Symptoms     Workaround     Patches     History     References Applies to: Oracle Net Services - Version 10.1.0.3.0 to 10.2.0.2.0 [Release 10.1 to 10.2] Information in this document applies to any platform. All new connections via TNS listener hang, no errors reported Checked for relevance on 05-FEB-2010. ***Checked for relevance on 27-nov-2012*** Description Intermittently the TNS listener hangs and new connections to the database are not possible. Occurrence The issue is that the TNS listener can hang under load if a second spawned listener process is not closed (remains persistent). Secondary listener processes are not unusual, depending on traffic as well as when the OS grep snapshot is taken. However, a persistent secondary process (longer than say 5 second) is not normal and may be a result of this referenced problem. TNS listener can hang at any time and effect standalone or RAC systems Symptoms Listener process can also consume high amount of CPU Child TNS listener process is seen when doing a ps on the listener process, eg.: $ ps -ef | grep tnslsnr ora10g 8909 1 0 Sep 15 ? 902:44 /u05/10GHOME/DBHOME/bin/tnslsnr sales -inherit ora10g 22685 8909 0 14:19:23 ? 0:00 /u05/10GHOME/DBHOME/bin/tnslsnr sales -inherit Killing the child process allows new connections to work until the problem reoccurs Workaround Issue is fixed in 10.2.0.3 Patch Set Oracle Support recommends patching to 10.2.0.5 as this the lastest release - OR - Apply Patch 4518443 for the problem (if a patch is available) - OR - As a workaround, two steps should be done: 1. The following parameter can be added to listener.ora SUBSCRIBE_FOR_NODE_DOWN_EVENT_<listener_name>=OFF Where <listener_name> should be replaced with the actual listener name configured in the LISTENER.ORA file. This parameter is to be placed by itself on an empty line / at the end of file. For example, if the listener name is LISTENER (default), the parameter would be: SUBSCRIBE_FOR_NODE_DOWN_EVENT_LISTENER=OFF 2. Locate the ons.config file in the 10g(rdbms) home and rename it to something else. For example: cd $ORACLE_HOME/opmn/conf mv ons.config ons.config.orig The listener needs to be restarted after these changes. This will both prevent the listener from registering against ONS (Oracle Notification Services), which is the area affected by bug:4518443, as well as disable ONS itself. For more information on ONS, please refer to the specific Oracle documentation, for example, for 10.2, see the Oracle10g Release 2 Oracle Clusterware and Oracle Real Application Clusters Administration and Deployment Guide. Please note, that adding the SUBSCRIBE_FOR_NODE_DOWN_EVENT_<listener_name> to listener.ora file on RAC and disabling the ONS file, will mean that FAN (fast application notification) will not be possible. See Note 220970.1 RAC: Frequently Asked Questions for further information on FAN. Therefore, if you have a RAC configuration, then apply the patch and do not disable ONS or FAN. Also, please note that this might happen with ANY 10g installation, whether it is RAC related or not, and whether there is an Oracle Application installation or not. Patches Apply Patch 4518443 for the problem (if a patch is available) 参考文档： 《Intermittent TNS Listener Hang, New Child Listener Process Forked [ID 340091.1]》","title":"oracle数据库连接hang，出现了两个listener"},{"content":"一、在utf8的mysql下 得到中文‘游客’的gbk下的16进制编码 mysql> SELECT hex(CONVERT( '游客' USING gbk ));       -> D3CEBFCD 反推gbk的16进制编码，取回中文 mysql> SELECT CONVERT( unhex('d3cebfcd') USING gbk);       -> ’游客' 从gbk的16进制编码直接转成utf8的16进制编码 mysql> SELECT HEX(CONVERT(CONVERT( unhex('d3cebfcd') USING gbk) USING utf8));       -> 'E6B8B8E5AEA2' 二、如果在gbk的mysql环境下 得到中文‘游客’的gbk下的16进制编码 mysql> SELECT hex('游客');       -> D3CEBFCD 反推gbk的16进制编码，取回中文 mysql> unhex('d3cebfcd') ;       -> ’游客' 原理知道了，就可以写个小程序来替换进行转编码了。不过特别提醒在文本里16进制必须在头部加上0x，例如：0xD3CEBFCD才能正常使用。  ","title":"MYSQL 转换编码的解决方法"},{"content":"1. 使用对象资源管理器自动或手动增缩用户数据库 2. T-sql 语句           1）增大容量：                      use doublian                      go                      alter database doublian                      modify file                      (                         name = 'F:\\doublian.mdf',                          size = 30MB                       )      --不知道为什么一直通过不去，   出现这样的问题               2） 减小数据库文件的大小T-sql语句      例子：将数据库student的空间缩减至最小容量：       use student       go       dbcc shrinkdatabase('student')       go       总结：增大数据库有三种方法： 1. 设置数据库为自动增长方式 2. 直接修改数据库的数据文件或日志文件的大小 3. 在数据库中增加新的次要数据文件或日志文件          缩减数据库的方式也有三种方法： 1. 设置数据库为自动收缩AUTO_SHRINK数据库选项实现 2. 收缩整个数据库的容量，可以通过DBCC SHRINKDATABASE命令完成。 3. 收缩指定的数据文件。可以通过DBCC SHRINKFILE命令来完成。","title":"sql sever 2005 管理用户数据库"},{"content":"今天把原来的ubuntu11.10删掉重新安装了12.04，然后重新安装oracle，PL/SQL Developer。安装PL/SQL Developer之后，直接使用，已经没有以前存在的按钮变黑之类的问题。安装过程主要根据这篇文章：Installing PL/SQLDeveloper under Wine in Ubuntu。 那篇文章有些步骤不需要了，因此记录一下自己的安装过程。 首先当然是安装wine，我采用这种方式安装最新版： sudo add-apt-repository ppa:ubuntu-wine/ppa sudo apt-get update sudo apt-get install wine1.5 装好之后看了一下小版本，1.5.19。 然后下载oracle instant client, 从这里：Instant Client Downloadsfor Microsoft Windows (32-bit)，我下的Version 11.2.0.3.0Instant Client Package - Basic: All files required to run OCI, OCCI, and JDBC-OCI application， 大小51,149,941 bytes。 下载的同时就可以打开terminal做以下工作： cd ~/.wine/drive_c mkdir -p oracle/bin mkdir -p oracle/network/admin 然后把oracle server下面的tnsnames.ora复制过来（我这里有读权限）： cp $ORACLE_HOME/network/admin/tnsnames.ora  ./oracle/network/admin 上面提到的文章里面把listener.ora也拿过来了，其实没必要。 搞完之后执行regedit打开注册表： wine regedit 在注册表编辑器里头，进入到 HKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\Session Manager\\Environment， (1)找到PATH, 原来已经存在，它的值是C:\\windows\\system32;C:\\windows;C:\\windows\\system32\\wbem，加上c:\\oracle\\bin，就是变成： C:\\windows\\system32;C:\\windows;C:\\windows\\system32\\wbem;c:\\oracle\\bin (2)增加一个注册表项，鼠标右键点空白处，选New --> String Value，名称为ORACLE_HOME,  值为c:\\oracle 上面的文章中没有提这个，一开始我没加这项，运行pl/sql developer的时候会报oci.dll找不到的错误，不过还好错误信息中会显示ORACLE_HOME（当然是ubuntu里面的ORACLE_HOME路径)，从而提供了一点解决思路。 (3)增加另外一项：名称TNS_ADMIN，值为c:\\oracle\\network\\admin 搞完这些，oracle client也该下载完了。解压到~/.wine/drive_c/oracle/bin下面，注意如果解压出来的时候如果带了一个目录instantclient_11_2，需要把这一层目录去掉，就是要把解压出来的文件直接放到bin下面。 最后一步，安装pl/sql developer，在文件浏览器（Nautilus）找到安装文件（比如我的是plsqldev802.exe)，右键点击，选择Open With Wine Windows Program Loader,  就开始和windows上一样安装了，安装时会缺省安装在Program Files (x86)。会有一个提示，说是oracle的一个bug会使得带空格的安装目录导致oracle不work，没理它，继续装就OK。 然后就可以enjoy it了。","title":"ubuntu 12.04LTS + wine 1.5上安装&使用PL/SQL Developer-已经相当完美"},{"content":"事情是这样的，在Windows的mysql5.5 ，我想修改一个表的索引，于是执行 ALTER TABLE practice_log DROP INDEX ix_practice_log_userid;ALTER TABLE practice_log ADD INDEX ix_practice_log_userid(userid,practicetime); 但是报错：unable drop index 。。。：  needed in a foreign key constraint 于是，强行把外键约束检查关闭： SET FOREIGN_KEY_CHECKS=0;ALTER TABLE practice_log DROP INDEX ix_practice_log_userid;ALTER TABLE practice_log ADD INDEX ix_practice_log_userid(userid,practicetime)SET FOREIGN_KEY_CHECKS=1; 索引修改成功。 但是，问题来了。。。。。 重启数据库后，表 practice_log 不见了！ 删除表practice_log，报错：表不存在； 建表，报错：表已存在！ 这应该是mysql的bug。 解决办法：不要用SET FOREIGN_KEY_CHECKS=0;老老实实得删掉外键约束吧，再修改索引，搞定。 另外，约束影响性能，尽量不要用。","title":"mysql 修改索引时，外键约束造成的奇怪问题"},{"content":"--0.建立表和数据(这里只是临时用一下方便显示，你自己用真实表)DECLARE @SpecDate TABLE(\tID UNIQUEIDENTIFIER,\tTheDate DATETIME NOT NULL,\tFlag  INT NOT NULL\t--1. 工作日，0. 休息)INSERT INTO @SpecDate select NEWID(),'2013-1-1',0 UNIONselect NEWID(),'2013-1-2',0 UNIONselect NEWID(),'2013-1-3',0 UNIONselect NEWID(),'2013-1-5',1 UNIONselect NEWID(),'2013-1-6',1SELECT * FROM @SpecDate ORDER BY TheDate DESC--1. 求某天之后的3个工作日DECLARE @beginDate DATETIME\t-- 开始日期DECLARE @result TABLE(\t\t-- 最终结果\tDT     DATETIME)DECLARE @count INT\t\t\t-- 结果中有几条记录DECLARE @maxCount INT\t\t-- 最多允许有几天SET @beginDate='2012-12-31'SET @count = 0SET @maxCount = 3DECLARE @tempDate DATETIME,@weekday INTSET @tempDate=DATEADD(DAY,1,@beginDate)WHILE (@count<@maxCount)BEGIN\t--如果特殊日期表中存在，而且此日期为工作日，插入临时表\tIF EXISTS( SELECT 1 FROM @SpecDate WHERE DATEDIFF(DAY,@tempDate,TheDate)=0 AND FLAG=1)\t\tBEGIN\t\t\tINSERT INTO @result SELECT @tempDate\t\t\tSET @count=@count+1\t\tEND\t--否则如果此日期在配置表中也不是休息日(没有特殊设置)\tELSE IF NOT EXISTS( SELECT 1 FROM @SpecDate WHERE DATEDIFF(DAY,@tempDate,TheDate)=0 AND FLAG=0)\tBEGIN\t\t--求得星期数\t\tSET @weekday = Datepart(weekday, @tempDate + @@DateFirst - 1)\t\t--如果不是周六周日，也将其保存\t\tIF (@weekday!=6 OR @weekday!=7)\t\tBEGIN\t\t\tINSERT INTO @result SELECT @tempDate\t\t\tSET @count=@count+1\t\tEND\tEND\t-- 往后推一天\tSET @tempDate=DATEADD(DAY,1,@tempDate)ENDSELECT * FROM @result ORDER BY DT","title":"求某天之后的三个工作日"},{"content":"create proc getid(@id int,@name varchar(50))ASset nocount ondeclare @no int…SQL语句… declare的含义是定义一个存储过程中使用的变量，与AS之前括号中的变量不一样。括号之中的变量id和name是外部编程中使用的变量。其实有点像是函数内部变量和外部变量，可以这么理解。 顺便说下 set nocount on。当没必要返回给客户端“n 行受到影响”消息时，在存储过程的开始应设置 SET NOCOUNT ON，提高网络性能。","title":"存储过程中的declare"},{"content":"一、定义输出参数 1、定义输出参数 mysql> delimiter //                                                               <--delimiter与 //有空格   --> mysql>  create procedure sp_search_customer2     ->  (in p_nam varchar(20),     ->  out p_cnt int)                                                               <--  p_cnt 为输出参数 -->     ->  begin     ->  if p_nam is null or p_nam=\"\" then     ->  select * from customer;     -> else     -> select * from customer where nam like p_nam;     -> end if;     -> select found_rows() into p_cnt;                             <-- found_rows() 取得前一条select语句中检索出的记录件数，然后使用select·····into命令将记录件数设置到                                                                                                    变量p_cnt中 -->     -> end     -> // Query OK, 0 rows affected (1.03 sec) delimiter; 2、调用存储过程 mysql> call sp_search_customer2('s%',@num);     <-- 指定out/outin类型的参数时，在参数头部加上@，处理结果将保存到out型变量num中-->     +-------+------+------------+------+ | mid   | nam  | birth      | sex  | +-------+------+------------+------+ | N0008 | san  | 1990-09-23 | 1    | | N0009 | san  | 1990-09-23 | 0    | +-------+------+------------+------+ 2 rows in set (3.76 sec) Query OK, 1 row affected (3.77 sec) 3、显示处理结果 mysql> select @num;                            <--使用select @num显示变量--> +------+ | @num | +------+ |    2 | +------+ 1 row in set (0.00 sec) 二、使用if命令实现多重条件分支 1、建立存储过程 mysql> delimiter // mysql> create procedure sp_search_employee(in p_depart int)     -> begin     -> if p_depart=1 then     -> select fname,lname,depart from employee where depart='研究部';     -> elseif p_depart=2 then     -> select fname,lname,depart from employee where depart='AC部';     -> elseif p_depart=3 then     -> select fname,lname,depart from employee where depart='IT部';     -> elseif p_depart=4 then     -> select fname,lname,depart from employee where depart='人事部';     -> elseif p_depart=5 then     -> select fname,lname,depart from employee where depart='经理部';     -> end if;     ->end     -> //     Query OK, 0 row affected (3.77 sec) 2、调用存储过程 mysql> call sp_search_employee(3); +-------+-------+--------+ | fname | lname | depart | +-------+-------+--------+ | 度    | 王    | IT部   | | 殊    | 方    | IT部   | | 小    | 王    | IT部   | | 操    | 曹    | IT部   | +-------+-------+--------+ 4 rows in set (0.00 sec) Query OK, 0 rows affected (0.03 sec) 三、使用case命令使用多重条件分支 1、创建存储过程 mysql> delimiter // mysql> create procedure sp_search_employee2(in p_depart int)     -> begin     -> case p_depart     -> when 1 then     ->  select fname,lname,depart from employee where depart='研究部';     -> when 2 then     ->  select fname,lname,depart from employee where depart='AC部';     -> when 3 then     ->  select fname,lname,depart from employee where depart='IT部';     -> when 4 then     ->  select fname,lname,depart from employee where depart='人事部';     -> else     ->  select fname,lname,depart from employee where depart='经理部';     -> end case;     -> end     -> // Query OK, 0 rows affected (0.00 sec) 2、调用存储过程 mysql> call sp_search_employee2(3); +-------+-------+--------+ | fname | lname | depart | +-------+-------+--------+ | 度    | 王    | IT部   | | 殊    | 方    | IT部   | | 小    | 王    | IT部   | | 操    | 曹    | IT部   | +-------+-------+--------+ 4 rows in set (0.00 sec) Query OK, 0 rows affected (0.03 sec) 四、使用循环语句","title":"创建存储过程的要点"},{"content":"Service Registry 已经迁移到 Hibernate Core 4.0 的用户(非JPA)可能已经注意到，以前大家熟知的构造 SessionFactory 的方法已经不推荐使用了：        Configuration configuration = new Configuration();    SessionFactory sf = configuration.buildSessionFactory(); 在 Hibernate ORM 4 里面推荐的方式是 org.hibernate.cfg.Configuration#buildSessionFactory(ServiceRegistry serviceRegistry), 需要先构造一个 ServiceRegistry 对象。 那么, 神马是 ServiceRegistry? 顾名思义, ServiceRegistry 是 Service 的注册表, 它为Service提供了一个统一的加载 / 初始化 / 存放 / 获取机制. 首先来看看一个整体的类图: 整个 ServiceRegistry 结构和我们大家了解的 Classloader 的代理结构类似, 只不过和 Classloader 的首先代理给父节点，父节点找不到再从本级的 Classloader 中查找的策略不同，ServiceRegistry 是先从本级节点查找，找不到再去父亲中查找。 可以看到hibernate里面的 ServiceRegistry实际上是由三层(范围)组成的: BootstrapServiceRegistry 主要提供 Classloading 和 Service loading 服务, 供全局使用. ServiceRegistry 标准的ServiceRegistry, 同样服务于全局, 在初始化这个Registry中的服务的时候,可能需要使用到BootstrapServiceRegistry中的服务. SessionFactoryServiceRegistry 于SessionFactory相关联(一对一的关系), 这里面的Services在初始化的时候需要访问SessionFactory. 所以, BootstrapServiceRegistry 中主要包括全局都要使用的基础服务, 而 ServiceRegistry 主要包括在 BootstrapServiceRegistry 之上的, 和Hibernate 相关的服务, 例如配置文件解析, JDBC, JNDI 等. 而, SessionFactoryServiceRegistry 则是和sessionfactory相关的了, 包括2LC的region factory, event listener等. 这里面的层级关系, 对于 service registry的client来说是完全透明的, 你可以直接调用getService 去获取你需要的service, 而不用去关心你在哪个层级上, 如同 classloader. Service 那么，什么是 Service ? 简单的来说，Service 就是一个功能，它由一个接口(Service Role)和一个实现类组成. Service 在Hibernate里面并不是一个新的概念，在以前的版本里面，我们已经有了这些东西，而这次，是通过把这些服务的提供者(类)，给抽取成一个个的Service,从而可以用统一的方式进行访问/加载/初始化等. 下图列出了所有的Hibernate中内置的Services, 详细介绍请参考: Building ServiceRegistry 在本文的开头即说过, 现在标准的构造一个SessionFactory的做法是传递一个ServiceRegistry实例给Configuration#buildSessionFactory方法, 那么, 这里就需要我们首先创建一个 ServiceRegistry的实例. 最简单的做法是:     StandardServiceRegistryBuilder serviceRegistryBuilder = new StandardServiceRegistryBuilder();    ServiceRegistry serviceRegistry = serviceRegistryBuilder.build();    SessionFactory sf = configuration.buildSessionFactory(serviceRegistry); 让我们来继续分析这里面究竟发生了什么. 如上文所介绍的, ServiceRegistry是一个代理结构, 那么, 实际上是需要分别创建 BootstrapServiceRegistry, ServiceRegistry 和 SessionFactoryServiceRegistry. BootstrapServiceRegistry org.hibernate.service.ServiceRegistryBuilder 有两个构造函数, 一个是接受一个 BootstrapServiceRegistry实例作为参数, 另外一个是无参的, 在内部自己构造一个 org.hibernate.boot.registry.internal.BootstrapServiceRegistryImpl的实例. 如同上面所讲的, 事实上我们是先build了一个 BootstrapServiceRegistry 的. 而Hibernate也如你所愿的提供了 org.hibernate.boot.registry.BootstrapServiceRegistryBuilder. 通过这个builder类, 我们可以通过调用如下的方法来对一些基础服务进行扩展: with(Integrator integrator) with(ClassLoader classLoader) withStrategySelector (关于这里的扩展的详细解释敬请期待下一篇) 现在我们有了 BootstrapServiceRegistryBuilder 和 ServiceRegistryBuilder , 那么很自然的, 会想到是不是也有一个 SessionFactoryServiceRegistryBuilder 呢? 很遗憾, 没有! 是的, 不过我们提供了 org.hibernate.service.spi.SessionFactoryServiceRegistryFactory, 它是一个位于 ServiceRegistry 中的标准service. 这主要是因为它的全部工作就是创建一个没啥意思的 org.hibernate.service.internal.SessionFactoryServiceRegistryImpl 实例, 也没啥可扩展的地方, 所以自然也就不需要一个builder了. 那么, 如果你非得要替换到这个默认的实现, 或者, 更进一步, 例如你想要替换掉某一个Service的标准实现, 异或, 你想把自己写的service也添加到service registry当中呢? 更进一步来看看Service 首先, BootstrapServiceRegistry中所提供的service是固定的, 无法增减, 除非你提供一个自己的 org.hibernate.boot.registry.internal.BootstrapServiceRegistryImpl 实现类, 但是并不推荐. 从org.hibernate.boot.registry.internal.BootstrapServiceRegistryImpl#locateServiceBinding 方法中我们可以看到BootStrapServiceRegistry所提供的标准服务.     public <R extends Service> ServiceBinding<R> locateServiceBinding(Class<R> serviceRole) {        if ( ClassLoaderService.class.equals( serviceRole ) ) {            return (ServiceBinding<R>) classLoaderServiceBinding;        }        else if ( StrategySelector.class.equals( serviceRole) ) {            return (ServiceBinding<R>) strategySelectorBinding;        }        else if ( IntegratorService.class.equals( serviceRole ) ) {            return (ServiceBinding<R>) integratorServiceBinding;        }        return null;    } 推荐的扩展位置是 ServiceRegistry, 在这里, 你可以增加你自定义的service, 替换标准的service实现等等. ServiceRegistry 中所提供的标准服务是定义在 org.hibernate.service.StandardServiceInitiators 当中:     public class StandardServiceInitiators {        public static List<StandardServiceInitiator> LIST = buildStandardServiceInitiatorList();            private static List<StandardServiceInitiator> buildStandardServiceInitiatorList() {            final List<StandardServiceInitiator> serviceInitiators = new ArrayList<StandardServiceInitiator>();                serviceInitiators.add( ConfigurationServiceInitiator.INSTANCE );            serviceInitiators.add( ImportSqlCommandExtractorInitiator.INSTANCE );                serviceInitiators.add( JndiServiceInitiator.INSTANCE );            serviceInitiators.add( JmxServiceInitiator.INSTANCE );                serviceInitiators.add( PersisterClassResolverInitiator.INSTANCE );            serviceInitiators.add( PersisterFactoryInitiator.INSTANCE );                serviceInitiators.add( ConnectionProviderInitiator.INSTANCE );            serviceInitiators.add( MultiTenantConnectionProviderInitiator.INSTANCE );            serviceInitiators.add( DialectResolverInitiator.INSTANCE );            serviceInitiators.add( DialectFactoryInitiator.INSTANCE );            serviceInitiators.add( BatchBuilderInitiator.INSTANCE );            serviceInitiators.add( JdbcEnvironmentInitiator.INSTANCE );            serviceInitiators.add( JdbcServicesInitiator.INSTANCE );            serviceInitiators.add( RefCursorSupportInitiator.INSTANCE );                serviceInitiators.add( SchemaManagementToolInitiator.INSTANCE );                serviceInitiators.add( MutableIdentifierGeneratorFactoryInitiator.INSTANCE);                serviceInitiators.add( JtaPlatformInitiator.INSTANCE );            serviceInitiators.add( TransactionFactoryInitiator.INSTANCE );                serviceInitiators.add( SessionFactoryServiceRegistryFactoryInitiator.INSTANCE );                    return Collections.unmodifiableList( serviceInitiators );        }    } 可以看到, 每一个标准服务都被封装成了 StandardServiceInitiator, 那么什么是 ServiceInitiator 呢? ServiceInitiator org.hibernate.service.spi.ServiceInitiator 定义了一个 Service 的加载器, 这个接口里面只有一个方法     /**     * Obtains the service role initiated by this initiator.  Should be unique within a registry     *     * @return The service role.     */    public Class<R> getServiceInitiated(); 而org.hibernate.service.StandardServiceInitiator 继承了 org.hibernate.service.spi.ServiceInitiator 并提供了另外一个方法:     /**     * Initiates the managed service.     *     * @param configurationValues The configuration values in effect     * @param registry The service registry.  Can be used to locate services needed to fulfill initiation.     *     * @return The initiated service.     */    public R initiateService(Map configurationValues, ServiceRegistryImplementor registry); 认同下图所示, ServiceInitiator定义了一个Service的接口 以及如何初始化这个service. 所以, 当有了ServiceInitiator之后, 可以通过调用org.hibernate.boot.registry.StandardServiceRegistryBuilder 的方法添加到注册表中: addInitiator(StandardServiceInitiator initiator) addService(final Class serviceRole, final Service service) hibernate在初始化这些service的时候, 会先初始化内置的, 所以, 如果你想要替换以后的标准service的话, 只需要原样调用上面两个方法之一就行了. Hibernate 还提供了一些接口来供Service的创建者来使用(具体如何使用请参考javadoc，在此就不重复了)： org.hibernate.service.spi.Configurable org.hibernate.service.spi.Manageable org.hibernate.service.spi.ServiceRegistryAwareService org.hibernate.service.spi.InjectService org.hibernate.service.spi.Startable org.hibernate.service.spi.Stoppable org.hibernate.service.spi.Wrapped 文章转自：http://planet.jboss.org/post/hibernate_orm_service_registry","title":"Hibernate ORM 新特性之 Service(Registry)"},{"content":"尿片与啤酒不得不说的故事 摘要：尿片与啤酒是数据挖掘的经典传奇，是美国第一大零售商沃尔玛公司发现的消费关联模式，本文通过数据挖掘的一般过程和算法，揭示如何发现了这一经典传奇。 关键词：数据仓库、事务数据库、关联规则、支持度、置信度、相关性 数据挖掘（DataMining）就是从大量数据中提取或“挖掘”知识。 一、数据预处理 首先是构造数据仓库（DataWarehouses），数据仓库是一个面向主题的、集成的、时变的、非易失的数据集合，通过数据清理、数据变换、数据集成、数据装入和定期数据刷新来构造。典型的数据仓库结构如下： 一个商店的售出商品包含有多方面的信息，比如常见的有售出时间、区域、种类、品牌等多个维（Dimension），就本议题而言，我们只关心种类这一个维，而其它的维则可以通过上卷（Roll-up）、维归约（Dimensionality Reducation）、切片（Slice）、切块（Dice）等联机分析处理（OLAP）操作进行排除，从而得到所需的事务数据库。 二、事务数据库 事务数据库可以是一个文件，也可以存放在表中，每个记录代表一个事务，每个事务中的项唯一。对于本议题，以顾客的一次购买行为作为一个事务，下表是示例用事务数据库片断（商品ID的第一列为该事务包含的项数）： 事务ID 商品ID 1 9 I17 I20 I22 I35 I37 I60 I62 I72 I73 2 7 I39 I51 I53 I54 I57 I65 I73 3 9 I17 I20 I21 I22 I34 I37 I62 I73 I76 … … 三、关联规则挖掘中的概念 尿片与啤酒为什么能联系在一起作为一种消费组合，关联规则挖掘就是寻找给定数据集中项之间的有趣联系。关联规则是否“有趣”，取决与规则的支持度和置信度。 设I={i1, i2,…,im}是项的集合，设任务相关的数据D是数据库事务的集合，其中每个事务T是项的集合，T是I的子集；设A是一个项集，事务T包含A当且仅当A是T的子集。关联规则是形如AèB的蕴涵式，其中A、B是I的真子集，且A∩B=空集。规则AèB在事务D中成立，具有支持度s和置信度c；其中s是事务D中包含A∪B的百分比，c是事务D中包含A的事务同时也包含B的百分比。用公式表示如下： support(A è B) = P(A∪B) confidence(A è B) = P(A|B) 对于本论题而言，顾客一次购买行为是一个购买事务，则支持度是同时购买尿片和啤酒的事务数占所有购买事务数的百分比，置信度是在所有购买尿片的事务中也购买啤酒的事务的百分比。 满足给定支持度的项的集合，称为频繁项集（frequent itemset）。 满足给定支持度和置信度的规则称为强关联规则。 关联规则的挖掘一般分为两个步骤： 1)     找出所有的频繁项集； 2)     由频繁项集产生强关联规则。 四、关联规则挖掘 关联规则挖掘的方法有Apriori算法和频繁模式增长（frequent-pattern growth）等算法。Apriori算法需要产生候选项集，且需要重复的扫描数据库因而效率很低。在此主要介绍频繁模式增长算法（简称频繁模式增长或FP-增长）。 FP-增长采用如下分治策略：将提供频繁项集的数据库压缩到一棵频繁模式树（或FP-树），但仍保留项集相关信息；而后将这种压缩后的数据库分成一组条件数据库（一种特殊类型的投影数据库），每个关联一个频繁项，并分别挖掘每个数据库。考察如下事务数据： 事务ID 项ID T100 I1, I2, I5 T200 I2, I4 T300 I2, I3 T400 I1, I2, I4 T500 I1, I3 T600 I2, I3 T700 I1, I3 T800 I1, I2, I3, I5 T900 I1, I2, I3 假定最小事务支持计数为2，则第一次扫描该事务数据库的到频繁1-项集L1=[I2:7, I1:6, I3:6,I4:2, I5:2]。 构建FP-树的步骤如下： 1)     创建树的根节点，项ID由null标记； 2)     再次扫描事务数据库，每个事务中的项按L1中递减支持度秩序排序，并对每个事务创建一个分枝，如果后续加入的事务和之前的有共享的前缀节点，则共同前缀上的每个节点计数增加1。 3)     创建一个项头表，使得每个项通过一个节点链指向树中的节点。 经过上述步骤，数据库频繁模式的挖掘问题转化成挖掘FP-树的问题。如下图： 接下来是FP-树的挖掘，由长度为1的频繁模式（初始后缀模式）开始，构造它的条件模式基（一个“子数据库”，由FP-树中与后缀模式一起出现的前缀路径集组成）；然后，构造它的条件FP-树，并递归地在该树上进行挖掘。模式增长通过后缀模式与由条件FP-树产生得分频繁模式连接实现。结果如下表： 项 条件模式基 条件FP-树 产生的频繁模式 I5 {(I2 I1:1),(I2 I1 I3:1)} <I2:2,I1:2> I2 I5:2,I1 I5:2,I2 I1 I5:2 I4 {(I2 I1:1),(I2:1)} <I2:2> I2 I4:2 I3 {(I2 I1:2),(I2:2),(I1:2)} <I2:4,I1:2>,<I1:2> I2 I3:4,I1 I3:4,I2 I1 I3:2 I1 {(I2:4) } <I2:4> I2 I1:4 对于I3节点，其条件FP-树如下： FP-树的挖掘总结如下表： 算法：FP-增长。使用FP-树，通过模式段增长，挖掘频繁模式。 输入：事务数据库D；最小支持度阈值min_sup。 输出：频繁模式的完全集。 方法： (1)   按一下步骤构造FP-树： (a)   扫描事务数据库D一次，收集频繁项佛然集合F和它们的支持度。对F按支持度降序排序，结果为频繁项表L。 (b)   创建F-树的根节点，以“null”标记它。对D中每个事务Trans，执行：选择Trans中的频繁项，并按L中的次序排序。设排序后的频繁项表为[p|P]，其中p是第一个元素，而P是剩余元素的表。调用insert_tree([p|P],T)，该过程执行情况如下。如果T有子女N使得N.item-name = p.item-name，则N的计数增加1；否则创建一个新节点N，将其计数设置为1，链接到它的父节点T，并且通过节点链结构将其链接到具有相同item-name的节点。如果P非空，递归地调用insert_tree(P,N)。 (2)   FP-树的挖掘通过调用FP_grown(FP_tree, null)实现。实现如下： Procedure FP_growth(Tree, α) 1)      if Tree含单个路径P Then 2)      for 路径P中节点的每个组合（记作β） 3)      产生模式β∪α，其支持度support = β中节点的最小支持度； 4)      else for eachαi 在Tree的头部 { 5)      产生一个模式β=αi∪α，其支持度support=αi.support； 6)      构造β的条件模式基，然后构造β的条件FP-树Treeβ； 7)      if Treeβ≠空 then 8)      调用FP_growth(Treeβ, β) FP-增长方法将发现长频繁模式的问题转换成递归地发现一些短模式，然后连接后缀；使用最不频繁的项作后缀，提供了好的选择性。该方法大大降低了搜索开销。 给定支持度为25%，频繁项集为K=2，执行本文附带的例程，得到如下结果： 事务数：5577 项数：74 支持度项数：1394 真实K项集：2 共 7 项频繁 1-项集 [事务数 支持度] I28  [2826 50.6724%] I73  [2813 50.4393%] I22  [2652 47.5524%] I65  [2012 36.0767%] I54  [1865 33.4409%] I71  [1582 28.3665%] I59  [1455 26.0893%] 共 5 项频繁 2-项集 [事务数 支持度] I73 I65  [1928 34.5706%] I73 I54  [1820 32.634%] I65 I54  [1593 28.5637%] I73 I22  [1521 27.2727%] I73 I28  [1424 25.5334%] 我们假定I73代表啤酒，I54代表尿片，则 support(尿片è 啤酒) = P(I73∪I54)/ 5577 = 1820/5577 =32.634% confidence(尿片è 啤酒) = P(I73∪I54)/P(I73) = 1820/2826 =64.402% 如果我们指定置信度阈值为60%，那么如下的布尔关联规则是强关联规则： buys(X, “尿片”) è buys(X, “啤酒”) 五、相关性分析 强关联规则并不一定都有趣，有时A è B，并不代表A的出项就蕴涵着B的出现。因此，我们还需要进行相关性分析，A和B之间的相关性可通过如下公式计算： corrA,B = P(A∪B)/ P(A)P(B) 来衡量，corrA,B的结果小于1，则A的出现和B的出现负相关，即A的出现导致B的减少；结果大于1，是正相关，即A的出现会导致B可能出现；结果等于1，则A和B是独立的。 对于本论题，尿片和啤酒的相关性为 corr尿片,啤酒 = P(I73∪I54)/ P(I73)P(I54) = 0.32634/(0.504393*0.334409)= 1.93 结果大于1，所以尿片和啤酒是正相关的。 给定支持度为25%，频繁项集为K=2的测试中没有负相关的例子，不过可以重置给定支持度和频繁项集数，比如5%和2，可以找到如下负相关的例子： corrI73,I34 = P(I73∪I34)/ P(I73)P(I34) = 0.0591716/(0.504393*0.131074) = 0.895 即I73、I34是负相关的。实际的购物行为中，常会碰到一种商品销量的增加会导致另一种商品销售量的减少。 六、附带例程说明 VC例程和测试数据可在(程序先不上传啦) 下找到，FP-增长算法在fptree.h中，用标准C++模板编写，在Windows和Linux平台下均已测试， Bin子目录下是执行程序、测试用数据和输出结果，请拷贝到本地机器测试。","title":"尿片与啤酒不得不说的故事"},{"content":"游标是邪恶的！        在关系数据库中，我们对于查询的思考是面向集合的。而游标打破了这一规则，游标使得我们思考方式变为逐行进行.对于类C的开发人员来着，这样的思考方式会更加舒服。        正常面向集合的思维方式是:                而对于游标来说:               这也是为什么游标是邪恶的，它会使开发人员变懒，懒得去想用面向集合的查询方式实现某些功能.       同样的，在性能上，游标会吃更多的内存，减少可用的并发，占用宽带，锁定资源，当然还有更多的代码量……       从游标对数据库的读取方式来说，不难看出游标为什么占用更多的资源，打个比方:                  当你从ATM取钱的时候，是一次取1000效率更高呢，还是取10次100？     既然游标这么“邪恶”，为什么还要学习游标       我个人认为存在既是合理.归结来说，学习游标原因我归纳为以下2点     1.现存系统有一些游标，我们查询必须通过游标来实现     2.作为一个备用方式，当我们穷尽了while循环,子查询，临时表，表变量,自建函数或其他方式扔来无法实现某些查询的时候，使用游标实现.   T-SQL中游标的生命周期以及实现     在T-SQL中，游标的生命周期由5部分组成 1.定义一个游标      在T-SQL中，定义一个游标可以是非常简单，也可以相对复杂，取决于游标的参数.而游标的参数设置取决于你对游标原理的了解程度.      游标其实可以理解成一个定义在特定数据集上的指针，我们可以控制这个指针遍历数据集，或者仅仅是指向特定的行，所以游标是定义在以Select开始的数据集上的:                T-SQL中的游标定义在MSDN中如下:   DECLARE cursor_name CURSOR [ LOCAL | GLOBAL ]      [ FORWARD_ONLY | SCROLL ]      [ STATIC | KEYSET | DYNAMIC | FAST_FORWARD ]      [ READ_ONLY | SCROLL_LOCKS | OPTIMISTIC ]      [ TYPE_WARNING ]      FOR select_statement      [ FOR UPDATE [ OF column_name [ ,...n ] ] ][;]             看起来很让人头痛是吧.下面仔细讲一下如何定义游标:    游标分为游标类型和游标变量，对于游标变量来说，遵循T-SQL变量的定义方法（啥，不知道T-SQL变量定义的规则？参考我前面的博文）.游标变量支持两种方式赋值，定义时赋值和先定义后赋值，定义游标变量像定义其他局部变量一样，在游标前加”@”,注意，如果定义全局的游标，只支持定义时直接赋值，并且不能在游标名称前面加“@”，两种定义方式如下:          下面我们来看游标定义的参数:      LOCAL和GLOBAL二选一      LOCAL意味着游标的生存周期只在批处理或函数或存储过程中可见，而GLOBAL意味着游标对于特定连接作为上下文，全局内有效,例如:            如果不指定游标作用域，默认作用域为GLOBAL        FORWARD_ONLY 和 SCROLL 二选一      FORWARD_ONLY意味着游标只能从数据集开始向数据集结束的方向读取，FETCH NEXT是唯一的选项，而SCROLL支持游标在定义的数据集中向任何方向，或任何位置移动，如下图:                STATIC  KEYSET  DYNAMIC  和 FAST_FORWARD 四选一     这四个关键字是游标所在数据集所反应的表内数据和游标读取出的数据的关系     STATIC意味着，当游标被建立时，将会创建FOR后面的SELECT语句所包含数据集的副本存入tempdb数据库中，任何对于底层表内数据的更改不会影响到游标的内容.     DYNAMIC是和STATIC完全相反的选项,当底层数据库更改时，游标的内容也随之得到反映，在下一次fetch中，数据内容会随之改变     KEYSET可以理解为介于STATIC和DYNAMIC的折中方案。将游标所在结果集的唯一能确定每一行的主键存入tempdb,当结果集中任何行改变或者删除时，@@FETCH_STATUS会为-2,KEYSET无法探测新加入的数据     FAST_FORWARD可以理解成FORWARD_ONLY的优化版本.FORWARD_ONLY执行的是静态计划，而FAST_FORWARD是根据情况进行选择采用动态计划还是静态计划，大多数情况下FAST_FORWARD要比FORWARD_ONLY性能略好.       READ_ONLY  SCROLL_LOCKS  OPTIMISTIC 三选一      READ_ONLY意味着声明的游标只能读取数据,游标不能做任何更新操作     SCROLL_LOCKS是另一种极端，将读入游标的所有数据进行锁定，防止其他程序进行更改，以确保更新的绝对成功     OPTIMISTIC是相对比较好的一个选择，OPTIMISTIC不锁定任何数据，当需要在游标中更新数据时,如果底层表数据更新，则游标内数据更新不成功，如果，底层表数据未更新，则游标内表数据可以更新        2.打开游标     当定义完游标后，游标需要打开后使用，只有简单一行代码: OPEN test_Cursor     注意，当全局游标和局部游标变量重名时，默认会打开局部变量游标 3.使用游标      游标的使用分为两部分,一部分是操作游标在数据集内的指向，另一部分是将游标所指向的行的部分或全部内容进行操作    只有支持6种移动选项,分别为到第一行（FIRST),最后一行(LAST),下一行(NEXT),上一行(PRIOR),直接跳到某行(ABSOLUTE(n)),相对于目前跳几行(RELATIVE(n)),例如:           对于未指定SCROLL选项的游标来说，只支持NEXT取值.     第一步操作完成后，就通过INTO关键字将这行的值传入局部变量:     比如下面代码:                  游标经常会和全局变量@@FETCH_STATUS与WHILE循环来共同使用,以达到遍历游标所在数据集的目的,例如：        4.关闭游标     在游标使用完之后，一定要记得关闭,只需要一行代码:CLOSE+游标名称 CLOSE test_Cursor           5.释放游标     当游标不再需要被使用后，释放游标，只需要一行代码:DEALLOCATE+游标名称 DEALLOCATE test_Cursor   对于游标一些优化建议      如果能不用游标，尽量不要使用游标      用完用完之后一定要关闭和释放      尽量不要在大量数据上定义游标      尽量不要使用游标上更新数据      尽量不要使用insensitive, static和keyset这些参数定义游标      如果可以，尽量使用FAST_FORWARD关键字定义游标      如果只对数据进行读取，当读取时只用到FETCH NEXT选项，则最好使用FORWARD_ONLY参数   总结      本文从游标的基本概念，到生命周期来谈游标。游标是非常邪恶的一种存在，使用游标经常会比使用面向集合的方法慢2-3倍，当游标定义在大数据量时，这个比例还会增加。如果可能，尽量使用while,子查询，临时表，函数，表变量等来替代游标，记住，游标永远只是你最后无奈之下的选择，而不是首选。      游标是邪恶的！","title":"SQL Server游标的使用"},{"content":" non-prime attribute of R is an attribute thatdoes not belong to any candidate key of R. candidate key: X and Y are sets of attributes in R，X functionally determines eachof the members of Y - in this case Y is known as the dependent set. Thus, a candidate key is a minimal set of attributes that functionally determineall of the attributes in a relation Secondnormal form  a 1NF table is in 2NF if and only if, given any candidate key K and any attribute A thatis not a constituent of a candidate key(非主属性),A depends upon the wholeof K rather than just a part of it. Employees' Skills Employee Skill Current Work Location Jones Typing 114 Main Street Jones Shorthand 114 Main Street Jones Whittling 114 Main Street Bravo Light Cleaning 73 Industrial Way Ellis Alchemy 73 Industrial Way Ellis Flying 73 Industrial Way Harrison Light Cleaning 73 Industrial Way a given Employee might need to appear more than once (he mighthave multiple Skills), {Employee, Skill} qualifies as a candidate key for the table.  The remaining attribute, Current WorkLocation, is dependent on only part of the candidate key, namely Employee.Therefore the table is not in 2NF. Note the redundancy in the way Current WorkLocations are represented: we are told three times that Jones works at 114 Main Street,   Thirdnormal form      Tournament Winners Tournament Year Winner Winner Date of Birth Indiana Invitational 1998 Al Fredrickson 21 July 1975 Cleveland Open 1999 Bob Albertson 28 September 1968 Des Moines Masters 1999 Al Fredrickson 21 July 1975 Indiana Invitational 1999 Chip Masterson 14 March 1977 The breach of 3NF occurs becausethe non-prime attribute Winner Date of Birth is transitively dependent on thecandidate key {Tournament, Year} via the non-prime attribute Winner.Thefact that Winner Date of Birth is functionally dependent on Winner makes thetable vulnerable to logical inconsistencies, as there is nothing to stop thesame person from being shown with different dates of birth on differentrecords.   Boyce-Coddnormal form  A table is in Boyce-Codd normal form if and only if for every one of its non-trivial[dependencies] X → Y, X is a superkey—that is, X is either a candidate key or a superset thereof.只要存在x不是超键就不是BCNF   Only inrare cases does a 3NF table not meet the requirements of BCNF.A 3NF table whichdoes not have multiple overlapping candidate keys is guaranteed to be in BCNF.[4] Depending on what its functional dependenciesare, a 3NF tablewith two or more overlapping candidate keys may or may not be in BCNF.   Multivalueddependency   只要两个相互独立的1：N联系在一个关系中，就可能出现多值依赖 course student precourse ENCGLISH {S1,S2} {C1,C2,C3} 不是1NF Course student precourse english S1 C1 english S1 C2 english S1 C3 english S2 C1 english S2 C2 english S2 C3 English有两个学生选，预选课重复出现。     Fourthnormal form Whereas the second, third, and Boyce-Codd normal forms are concerned with functional dependencies, 4NF is concernedwith a more general type of dependency known as a multivalued dependency.  A table is in 4NF if andonly if, for every one of its non-trivial multivalued dependencies X →→ Y, X is a superkey—that is, X is either a candidate key or a superset thereof. A functionaldependency is a special case ofmultivalued dependency. In a functional dependency X → Y, every x determines exactly one y, never more than one.     Pizza Delivery Permutations Restaurant Pizza Variety Delivery Area A1 Pizza Thick Crust Springfield A1 Pizza Thick Crust Shelbyville A1 Pizza Thick Crust Capital City A1 Pizza Stuffed Crust Springfield A1 Pizza Stuffed Crust Shelbyville A1 Pizza Stuffed Crust Capital City Elite Pizza Thin Crust Capital City Elite Pizza Stuffed Crust Capital City Vincenzo's Pizza Thick Crust Springfield Vincenzo's Pizza Thick Crust Shelbyville Vincenzo's Pizza Thin Crust Springfield Vincenzo's Pizza Thin Crust Shelbyville Each row indicates that a given restaurant can deliver a givenvariety of pizza to a given area. The table has no non-key attributes because its only key is{Restaurant, Pizza Variety, Delivery Area}. The problem is that the table features two non-trivial multivalueddependencies on the {Restaurant} attribute (which is not a superkey). Thedependencies are: § {Restaurant} →→ {Pizza Variety} § {Restaurant} →→ {Delivery Area}   if A1 Pizza starts producing Cheese Crust pizzas then we will needto add multiple rows, one for each of A1 Pizza's delivery areas. There is, moreover,nothing to prevent us from doing this incorrectly: we might add Cheese Crustrows for all but one of A1 Pizza's delivery areas, thereby failing to respectthe multivalued dependency {Restaurant} →→ {Pizza Variety}.   Varieties By Restaurant Restaurant Pizza Variety A1 Pizza Thick Crust A1 Pizza Stuffed Crust Elite Pizza Thin Crust Elite Pizza Stuffed Crust Vincenzo's Pizza Thick Crust Vincenzo's Pizza Thin Crust Delivery Areas By Restaurant Restaurant Delivery Area A1 Pizza Springfield A1 Pizza Shelbyville A1 Pizza Capital City Elite Pizza Capital City Vincenzo's Pizza Springfield Vincenzo's Pizza Shelbyville  ","title":"数据库设计之范式"},{"content":"一.数据库的事务应当具有以下四种特性： 　Atomic（原子性）：事务中包含的操作被看做一个逻辑单元，这个逻辑单元中的操作要么全部成功，要么全部失败。 　Consistency（一致性）：数据不会因为事务的执行而遭受破坏.只有合法的数据可以被写入数据库，否则事务应该将其回滚到最初状态。     实现:DBMS的完整性子系统执行测试任务        {        `完整性约束：域约束，基本表约束和断言         } 　Isolation（隔离性）：事务允许多个用户对同一个数据进行并发访问，而不破坏数据的正确性和完整性。 　  事务的隔离性一般由事务的锁来进行控制。     实现:DBMS的并发控制子系统       {         1.丢失更新问题         2.读脏数据         3.不可重复读问题       } 　Durability（持久性）：事务结束后，事务处理的结果必须能够得到固化。 　　实现:恢复管理子系统 二.事务的隔离性 1.选择完隔离级别后，常遇到以下几种情况： 　　1.更新丢失（Lost update）：两个事务同时更新，但是第二个事务却中途失败退出，导致对数据的两个修改都失效了。 　　2.脏读（Dirty Reads）：一个事务开始读取了某行数据，但是另外一个事务已经更新了此数据但没有能够及时提交。这是相当危险的，因为很可能所有的操作都被回滚。 　　3.不可重复读取（Non-repeatable Reads）：一个事务两次读取，但在第二次读取前另一事务已经更新了。 　　4.虚读（Phantom Reads）：一个事务两次读取，第二次读取到了另一事务插入的数据。 　　5.两次更新问题（Second lost updates problem）：两个事务都读取了数据，并同时更新，第一个事务更新失败。 2.隔离级别（低->高） 　　● Read Uncommitted 　　允许脏读取，但不允许更新丢失。如果一个事务已经开始写数据，则另外一个数据则不允许同时进行写操作，但允许其他事务读此行数据。该隔离级别可以通过“排他写锁”实现。 　　● Read Committed 　　允许不可重复读取，但不允许脏读取。这可以通过“瞬间共享读锁”和“排他写锁”实现。读取数据的事务允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行。 　　● 可重复读取（Repeatable Read） 　　禁止不可重复读取和脏读取，但是有时可能出现幻影数据。这可以通过“共享读锁”和“排他写锁”实现。读取数据的事务将会禁止写事务（但允许读事务），写事务则禁止任何其他事务。 　　● 序列化（Serializable） 　　提供严格的事务隔离。它要求事务序列化执行，事务只能一个接着一个地执行，但不能并发执行。如果仅仅通过“行级锁”是无法实现事务序列化的，必须通过其他机制保证新插入的数据不会被刚执行查询操作的事务访问到。 之间关系 3.隔离级别的选择 　　对于多数应用程序，可以优先考虑把数据库系统的隔离级别设为Read Committed，它能够避免脏读取，而且具有较好的并发性能。尽管它会导致不可重复读、虚读和第二类丢失更新这些并发问题，在可能出现这类问题的个别场合，可以由应用程序采用悲观锁或乐观锁来控制。 4.SQL语句可以使用SET TRANSACTION ISOLATION LEVEL来设置事务的隔离级别。  设置事务级别：SET TRANSACTION ISOLATION LEVEL Read Committed。 　　开始事务：begin tran 　　提交事务：COMMIT 　　回滚事务：ROLLBACK 　　创建事务保存点：SAVE TRANSACTION savepoint_name 　　回滚到事务点:ROLLBACK TRANSACTION savepoint_name 5.锁（并发控制的手段） 　　独占锁（排他锁）:只允许一个事务访问数据 　　共享锁:允许其他事务继续使用锁定的资源 　　更新锁 　　锁就是保护指定的资源，不被其他事务操作，锁定的资源包括行、页、簇、表和数据库。为了最小化锁的成本，SQL Server自动地以与任务相应等级的锁来锁定资源对象。锁定比较小的对象，例如锁定行，虽然可以提高并发性，但是却有较高的开支，因为如果锁定许多行，那么需要占有更多的锁。锁定比较大的对象，例如锁定表，会大大降低并发性，因为锁定整个表就限制了其他事务访问该表的其他部分，但是成本开支比较低，因为只需维护比较少的锁。 　","title":"数据库事务"},{"content":"1、打开模拟器；  2、运行cmd，进入命令模式    输入adb shell进入android控制台 3、输入ls -l /data/data/com.android.providers.settings/databases/settings.db，查看当前系统设置数据库是否存在 4、若存在，输入sqlite3 /data/data/com.android.providers.settings/databases/settings.db，进入数据库 5、执行数据加添命令：INSERT INTO system VALUES(99,’http_proxy’, ‘192.168.5.96:3122′); ，这是对应的代表服务器的IP地址和端口，可以根据需要进行个人修改。 6、执行 SELECT * FROM system; 来查看刚才插入的数据  7、重新启动服务器使得代理服务器生效。可以使用 DELETE FROM system WHERE _id=99，语句来删除代理设置 ，或者使用 UPDATE system SET value = ‘192.168.0.245:8070′ WHERE _id=99; 来修改代理服务器设置；也可以直接在模拟器上进行设置的， 启动模拟器，然后进入 settings->Wireless controls->Mobile networks->Access Point Names","title":"Android模拟器代理设置"},{"content":"一个小时内学习SQLite数据库 SQLite 是一个开源的嵌入式关系数据库，实现自包容、零配置、支持事务的SQL数据库引擎。 其特点是高度便携、使用方便、结构紧凑、高效、可靠。 与其他数据库管理系统不同，SQLite 的安装和运行非常简单，在大多数情况下 - 只要确保SQLite的二进制文件存在即可开始创建、连接和使用数据库。如果您正在寻找一个嵌入式数据库项目或解决方案，SQLite是绝对值得考虑。 AD：51CTO云计算架构师峰会 抢票进行中 ！ 1. 介绍 SQLite 是一个开源的嵌入式关系数据库，实现自包容、零配置、支持事务的SQL数据库引擎。 其特点是高度便携、使用方便、结构紧凑、高效、可靠。 与其他数据库管理系统不同，SQLite 的安装和运行非常简单，在大多数情况下 - 只要确保SQLite的二进制文件存在即可开始创建、连接和使用数据库。如果您正在寻找一个嵌入式数据库项目或解决方案，SQLite是绝对值得考虑。 2. 安装 SQLite on Windows 1）进入 SQL 下载页面：http://www.sqlite.org/download.html 2）下载 Windows 下的预编译二进制文件包： sqlite-shell-win32-x86-<build#>.zip sqlite-dll-win32-x86-<build#>.zip 注意: <build#> 是 sqlite 的编译版本号 将 zip 文件解压到你的磁盘，并将解压后的目录添加到系统的 PATH 变量中，以方便在命令行中执行 sqlite 命令。 可选: 如果你计划发布基于 sqlite 数据库的应用程序，你还需要下载源码以便编译和利用其 API sqlite-amalgamation-<build#>.zip SQLite on Linux 在 多个 Linux 发行版提供了方便的命令来获取 SQLite： /* For Debian or Ubuntu /*   $ sudo apt-get install sqlite3 sqlite3-dev     /* For RedHat, CentOS, or Fedora/*   $ yum install SQLite3 sqlite3-dev  SQLite on Mac OS X 如果你正在使用 Mac OS 雪豹或者更新版本的系统，那么系统上已经装有 SQLite 了。 3. 创建首个 SQLite 数据库 现在你已经安装了 SQLite 数据库，接下来我们创建首个数据库。在命令行窗口中输入如下命令来创建一个名为 test.db 的数据库。 sqlite3 test.db  创建表： sqlite> create table mytable(id integer primary key, value text);   2 columns were created.   该表包含一个名为 id 的主键字段和一个名为 value 的文本字段。 注意: 最少必须为新建的数据库创建一个表或者视图，这么才能将数据库保存到磁盘中，否则数据库不会被创建。 接下来往表里中写入一些数据： sqlite> insert into mytable(id, value) values(1, 'Micheal');   sqlite> insert into mytable(id, value) values(2, 'Jenny');   sqlite> insert into mytable(value) values('Francis');   sqlite> insert into mytable(value) values('Kerk');  查询数据： sqlite> select * from test;   1|Micheal   2|Jenny   3|Francis   4|Kerk  设置格式化查询结果： sqlite> .mode column;   sqlite> .header on;   sqlite> select * from test;   id          value   ----------- -------------   1           Micheal   2           Jenny   3           Francis   4           Kerk  .mode column 将设置为列显示模式，.header 将显示列名。 修改表结构，增加列： sqlite> alter table mytable add column email text not null '' collate nocase;;  创建视图： sqlite> create view nameview as select * from mytable;  创建索引： sqlite> create index test_idx on mytable(value);  4. 一些有用的 SQLite 命令 显示表结构： sqlite> .schema [table]  获取所有表和视图： sqlite > .tables  获取指定表的索引列表： sqlite > .indices [table ]  导出数据库到 SQL 文件： sqlite > .output [filename ]   sqlite > .dump   sqlite > .output stdout  从 SQL 文件导入数据库： sqlite > .read [filename ]  格式化输出数据到 CSV 格式： sqlite >.output [filename.csv ]   sqlite >.separator ,   sqlite > select * from test;   sqlite >.output stdout  从 CSV 文件导入数据到表中： sqlite >create table newtable ( id integer primary key, value text );   sqlite >.import [filename.csv ] newtable  备份数据库： /* usage: sqlite3 [database] .dump > [filename] */   sqlite3 mytable.db .dump > backup.sql  恢复数据库： /* usage: sqlite3 [database ] < [filename ] */   sqlite3 mytable.db < backup.sql  原文链接：http://www.oschina.net/question/12_53183","title":"一个小时内学习SQLite数据库"},{"content":"在说单一入口之前，先说说多入口。Discuz!, PHPCMS 2008, DedeCMS 都是采用多入口的结构。 多入口，即通过访问不同的 php 文件运行对应的功能。如： /index.php - 网站首页 /show.php?id=1 - 内容页 /list.php?page=2 - 列表页 /login.php - 用户登录页 …… 多入口都是通过包含头文件统一运行环境，即初始化系统。如： /include/common.inc.php - 头文件，PHP 文件 include 它后便完成了初始化工作，例如可以使用系统的基础函数。 /index.php <?php include './include/common.inc.php' // 包含头文件，基本是每个入口 php 文件的首行代码。 …… ?> 拿 PHPCMS 2008 的头文件来举例， PHPCMS 2008 在头文件中完成了基础函数的加载，常量的定义，系统配置的载入，POST,GET 数据的过滤，数据库类的实例化，保持用户登录等等等等一系列操作。 反正就是个 php 文件嘛，想做什么直接往里加就是了。 所以，所谓的安全检查，统一检查，权限控制等，用头文件同样可以实现，所谓“单一入口”只不过是换了一种形式，并无实质性的变化。 以前我就是这样认为的。 现在，假设用 CMS 为客户建一个站（ CMS 是多入口的）：建栏目，配网站，卡拉卡拉一段忙碌后，网站可以上线了，放在这个地址下： localhost/gz/ 没错，这次建的是 gz 这个地区的地区站，客户认为网站做得不错，希望做多一个 bj 地区的地区站。 bj 站的栏目结构，内容，功能模块等都与 gz 站有所不同。 好，现在问题来了，上面提到的三个多入口的系统，都设计成一套程序一个环境，即一套程序只对应一个数据库。对于上面的需求（ bj 站），除非修改整套程序的结构（这是不切实际的），否则就只能复制多一份源代码，指向另一个数据库。 于是，我便复制多一份源代码，指向 bj 数据库（ gz 站则指向 gz 数据库），建栏目，配网站，卡拉卡拉一优忙碌后，网站又可以上线了，放在这个地址下： localhost/bj/ 所以，现在有两套一样的程序在运行。 然后，客户想改一改 gz 站的功能，于是我修改了 gz 的代码。然后，客户想改一改 bj 站的功能，于是我修改了 bj 的代码。然后，客户想在 bj 站上做与 gz 同样的修改，于是我得把 gz 的修改复制到 bj 中，然后…… 于是，我不得不维护两份实际上是“一样”的代码。 假如网站运营得不错，客户又建了若干个地区站，我维护的便是若干份“一样”的代码——这根本就是恶梦。 现在到单一入口登场了。 单一入口，就是访问同一个文件加不同参数运行不同的功能。如： /index.php - 单一入口，默认显示首页 /index.php?action=show&id=1 - 用 action 参数指明显示内容页 /index.php?action=list&page=2 - 显示列表页 /index.php?action=login - 用户登录页 …… index.php 这个入口做的便是头文件做的初始化操作（外加一些调度），包括加载网站的配置。 现在我们来假设建站用的 CMS 是单一入口的设计，在完成 gz 站后，面对同样的需求（ bj 站），我只需要在 /bj/ 目录入多建一个入口文件，加载指向 bj 数据库的配置，再配配数据卡拉卡拉什么的，就完事了！ 于是，我只需要维护一份源代码。 这便是单一入口特有的作用——构造环境。 使用哪个数据库就是环境的一种，类似的还有：用内存缓存还是文件缓存，用 mysql 还是 mssql 等。 除非在设计阶段特别留意，否则，头文件的结构都会被写成“一套程序一个环境”的结构。而采用单一入口结构，无论是否留意，都可以轻易实现“一套程序多个环境”。这才是使用单一入口的真正理由。 多入口，即通过访问不同的 php 文件运行对应的功能。如： /index.php - 网站首页 /show.php?id=1 - 内容页 /list.php?page=2 - 列表页 /login.php - 用户登录页 …… 多入口都是通过包含头文件统一运行环境，即初始化系统。如： /include/common.inc.php - 头文件，PHP 文件 include 它后便完成了初始化工作，例如可以使用系统的基础函数。 /index.php <?php include './include/common.inc.php' // 包含头文件，基本是每个入口 php 文件的首行代码。 …… ?> 拿 PHPCMS 2008 的头文件来举例， PHPCMS 2008 在头文件中完成了基础函数的加载，常量的定义，系统配置的载入，POST,GET 数据的过滤，数据库类的实例化，保持用户登录等等等等一系列操作。 反正就是个 php 文件嘛，想做什么直接往里加就是了。 所以，所谓的安全检查，统一检查，权限控制等，用头文件同样可以实现，所谓“单一入口”只不过是换了一种形式，并无实质性的变化。 以前我就是这样认为的。 现在，假设用 CMS 为客户建一个站（ CMS 是多入口的）：建栏目，配网站，卡拉卡拉一段忙碌后，网站可以上线了，放在这个地址下： localhost/gz/ 没错，这次建的是 gz 这个地区的地区站，客户认为网站做得不错，希望做多一个 bj 地区的地区站。 bj 站的栏目结构，内容，功能模块等都与 gz 站有所不同。 好，现在问题来了，上面提到的三个多入口的系统，都设计成一套程序一个环境，即一套程序只对应一个数据库。对于上面的需求（ bj 站），除非修改整套程序的结构（这是不切实际的），否则就只能复制多一份源代码，指向另一个数据库。 于是，我便复制多一份源代码，指向 bj 数据库（ gz 站则指向 gz 数据库），建栏目，配网站，卡拉卡拉一优忙碌后，网站又可以上线了，放在这个地址下： localhost/bj/ 所以，现在有两套一样的程序在运行。 然后，客户想改一改 gz 站的功能，于是我修改了 gz 的代码。然后，客户想改一改 bj 站的功能，于是我修改了 bj 的代码。然后，客户想在 bj 站上做与 gz 同样的修改，于是我得把 gz 的修改复制到 bj 中，然后…… 于是，我不得不维护两份实际上是“一样”的代码。 假如网站运营得不错，客户又建了若干个地区站，我维护的便是若干份“一样”的代码——这根本就是恶梦。 现在到单一入口登场了。 单一入口，就是访问同一个文件加不同参数运行不同的功能。如： /index.php - 单一入口，默认显示首页 /index.php?action=show&id=1 - 用 action 参数指明显示内容页 /index.php?action=list&page=2 - 显示列表页 /index.php?action=login - 用户登录页 …… index.php 这个入口做的便是头文件做的初始化操作（外加一些调度），包括加载网站的配置。 现在我们来假设建站用的 CMS 是单一入口的设计，在完成 gz 站后，面对同样的需求（ bj 站），我只需要在 /bj/ 目录入多建一个入口文件，加载指向 bj 数据库的配置，再配配数据卡拉卡拉什么的，就完事了！ 于是，我只需要维护一份源代码。 这便是单一入口特有的作用——构造环境。 使用哪个数据库就是环境的一种，类似的还有：用内存缓存还是文件缓存，用 mysql 还是 mssql 等。 除非在设计阶段特别留意，否则，头文件的结构都会被写成“一套程序一个环境”的结构。而采用单一入口结构，无论是否留意，都可以轻易实现“一套程序多个环境”。这才是使用单一入口的真正理由。","title":"PHP 单一入口的特有作用"},{"content":"以前的一个项目中 写了一个webservices 。其中返回时间函数的时候调用的是date_FORMAT(时间,格式)  返回定义的时间。以前能够正常工作。这段时间由于服务器mysql数据库版本变化了（变化成了5.0.15）。突然一下 webservices中的时间都变成了base64编码。 早了很久的问题。测试的时候。 直接用select date_format(时间 ，格式) from 表，在c#客户端存入 data table 发现里面的类型是system.byte[]; 而用其他数据库版本的时候。直接用select date_format(时间 ，格式) from 表，在c#客户端存入 data table 发现里面的类型是system.string； 诡异的问题。 最后修改方法 ： select  cast(date_format(时间，格式) , char(30)  from 表 结果正确","title":"C#中mysql诡异的Date_format返回base64string的问题"},{"content":"对sequence的一直以来都不是很重视，因为很少在这个上面出过什么问题，当然是在默认参数的时候，此时在sequence上消耗的消耗的资源时间等待与在table上相比，几乎可以忽略不计，创建sequence不指定cache参数的时候oracle默认设置为20，大部分的时候得普通应用不会有性能问题，除了一秒种上万次的SELECT，默认值基本够用，但是最近有个运行了几年的系统在修改程序为并行INSERT的时候响应很慢，几乎于HANG住，基本的环境是AIX 5.3 + ORACLE 10.1 RAC，由于该数据库的特殊性不能直接登录查看等待事件，只能从对方要了一相关资料和SQL，仔细察看发现该系统使用的sequence的设置是nocache，于是手动进行一些测试： RAC两个会话分别处于不同node同时并发循环间断去取4万个值  ：             nocache：           　　  2100s cache ＝1000：　　       55s 差别却是好大。 单Instance数据库单会话循环不间断去1-4万个值  测试（在家里笔记本上测试结果）过程如下： nocache：             37.7s          10000　　　 cache ：20            4.31s          10000 cache ：100         2.92s           10000 cache ：1000       5.56s          40000 nocache：             97.7s         40000 基本上cache 大于20的时候性能基本可以接受，最好设置100以上， nocache的时候性能确实很差，最大相差20倍． 排序参数：oracle默认是NOORDER，如果设置为ORDER；在单实例环境没有影响，在RAC环境此时，多实例实际缓存相同的序列，此时在多个实例并发取该序列的时候，会有短暂的资源竞争来在多实例之间进行同步。因次性能相比noorder要差，所以RAC环境非必须的情况下不要使用ORDER，尤其要避免NOCACHE   ORDER组合； 是以为戒，不要随便更改oracle的默认属性，要改也往乐观的方向改，特别是在RAC上，啥事都得小心谨慎些。 Connected to: Oracle Database 10g Enterprise Edition Release 10.2.0.1.0 - Production With the Partitioning, OLAP and Data Mining options SQL> SQL> create user ikl identified by ikl   2  ; User created. SQL> grant dba to ikl; Grant succeeded. SQL> conn ikl/ikl Connected. SQL> create sequence seq_1 nocache; Sequence created. SQL> set timing on SQL> declare x number ; begin   for i in 1 .. 10000 loop   select seq_1.nextval into x from dual;   end loop; end ;   8  / PL/SQL procedure successfully completed. Elapsed: 00:00:37.88 SQL>  create sequence seq_2 cache 20; Sequence created. Elapsed: 00:00:00.04 SQL> SQL> declare x number ; begin   for i in 1 .. 10000 loop   select seq_2.nextval into x from dual;   end loop; end ;   8  / PL/SQL procedure successfully completed. Elapsed: 00:00:04.31 SQL> create sequence seq_3 cache 100; Sequence created. Elapsed: 00:00:00.08 SQL> declare x number ; begin   for i in 1 .. 10000 loop   select seq_3.nextval into x from dual;   end loop; end ;    8  / PL/SQL procedure successfully completed. Elapsed: 00:00:02.92 SQL>  create sequence seq_4 cache 1000; declare x number ; begin   for i in 1 .. 40000 loop   select seq_4.nextval into x from dual;   end loop; end ; Sequence created. Elapsed: 00:00:00.03 SQL>   9  / PL/SQL procedure successfully completed. Elapsed: 00:00:05.56  SQL> SQL> declare x number ; begin   for i in 1 .. 40000 loop   select seq_1.nextval into x from dual;   end loop; end ;   2    3    4    5    6    7   8  / PL/SQL procedure successfully completed. Elapsed: 00:01:37.66 SQL>                ","title":"ORACLE RAC环境下sequence 的cache参数的重要性"},{"content":"POI的下载与安装 　　请到网站  点击打开链接右击超链接2.5.1.zip下载压缩包poi-bin-3.8-20120326.tar.gz，解压缩后得到如图2.1所示的目录结构。我们主要用到poi-3.8-20120326.jar这个库文件。请把poi-3.8-20120326.jar这个文件的路径添加到系统环境变量classpath中，否则无法编译下面的示例程序。 图2.1 POI的目录结构 　　POI使用初步 　　POI提供给用户使用的对象在org.apache.poi.hssf.usermodel包中,主要部分包括Excel对象、样式和格式，还有辅助操作等。 　　最主要的几个对象如表3.1所示： 　　表3.1 POI主要对象 POI对象名称 对应的Excel对象 HSSFWorkbook 工作簿 HSSFSheet 工作表 HSSFRow 行 HSSFCell 单元格 　　下面我们来看如下的例子，使用表3.1中的对象在程序的当前目录下创建一个Excel文件test.xls，在第一个单元格中写入内容，然后读出第一个单元格的内容。 　　完整的程序如下： import org.apache.poi.hssf.usermodel.HSSFWorkbook; import org.apache.poi.hssf.usermodel.HSSFSheet; import org.apache.poi.hssf.usermodel.HSSFRow; import org.apache.poi.hssf.usermodel.HSSFCell; import java.io.FileOutputStream; import java.io.FileInputStream; public class CreateXL { 　public static String xlsFile=\"test.xls\"; //产生的Excel文件的名称 　public static void main(String args[]) 　{ 　　try 　　{ 　　　HSSFWorkbook workbook = new HSSFWorkbook(); //产生工作簿对象 　　　HSSFSheet sheet = workbook.createSheet(); //产生工作表对象 　　　//设置第一个工作表的名称为firstSheet 　　　//为了工作表能支持中文，设置字符编码为UTF_16 　　　workbook.setSheetName(0,\"firstSheet\",HSSFWorkbook.ENCODING_UTF_16); 　　　//产生一行 　　　HSSFRow row = sheet.createRow((short)0); 　　　//产生第一个单元格 　　　HSSFCell cell = row.createCell((short) 0); 　　　//设置单元格内容为字符串型 　　　cell.setCellType(HSSFCell.CELL_TYPE_STRING); 　　　//为了能在单元格中写入中文，设置字符编码为UTF_16。 　　　cell.setEncoding(HSSFCell.ENCODING_UTF_16); 　　　//往第一个单元格中写入信息 　　　cell.setCellValue(\"测试成功\"); 　　　FileOutputStream fOut = new FileOutputStream(xlsFile); 　　　workbook.write(fOut); 　　　fOut.flush(); 　　　fOut.close(); 　　　System.out.println(\"文件生成...\"); 　　　//以下语句读取生成的Excel文件内容 　　　FileInputStream fIn=new FileInputStream(xlsFile); 　　　HSSFWorkbook readWorkBook= new HSSFWorkbook(fIn); 　　　HSSFSheet readSheet= readWorkBook.getSheet(\"firstSheet\"); 　　　HSSFRow readRow =readSheet.getRow(0); 　　　HSSFCell readCell = readRow.getCell((short)0); 　　　System.out.println(\"第一个单元是：\" + readCell.getStringCellValue()); 　　} 　　catch(Exception e) 　　{ 　　　System.out.println(e); 　　} 　} } 　　与数据库结合使用 　　使用POI，结合JDBC编程技术，我们就可以方便地将数据库中的数据导出生成Excel报表。其关键代码如下： /*把数据集rs中的数据导出至Excel工作表中。 *传入参数：数据集rs，Excel文件名称xlsName，工作表名称sheetName。 */ public static void resultSetToExcel(ResultSet rs,String xlsName,String sheetName) throws Exception { 　HSSFWorkbook workbook = new HSSFWorkbook(); 　HSSFSheet sheet = workbook.createSheet(); 　workbook.setSheetName(0,sheetName,HSSFWorkbook.ENCODING_UTF_16); 　HSSFRow row= sheet.createRow((short)0);; 　HSSFCell cell; 　ResultSetMetaData md=rs.getMetaData(); 　int nColumn=md.getColumnCount(); 　//写入各个字段的名称 　for(int i=1;i<=nColumn;i++) 　{ 　　cell = row.createCell((short)(i-1)); 　　cell.setCellType(HSSFCell.CELL_TYPE_STRING); 　　cell.setEncoding(HSSFCell.ENCODING_UTF_16); 　　cell.setCellValue(md.getColumnLabel(i)); 　} 　int iRow=1; 　//写入各条记录，每条记录对应Excel中的一行 　while(rs.next()) 　{row= sheet.createRow((short)iRow);; 　　for(int j=1;j<=nColumn;j++) 　　{ 　　　cell = row.createCell((short)(j-1)); 　　　cell.setCellType(HSSFCell.CELL_TYPE_STRING); 　　　cell.setEncoding(HSSFCell.ENCODING_UTF_16); 　　　cell.setCellValue(rs.getObject(j).toString()); 　　} 　　iRow++; 　} 　FileOutputStream fOut = new FileOutputStream(xlsName); 　workbook.write(fOut); 　fOut.flush(); 　fOut.close(); 　JOptionPane.showMessageDialog(null,\"导出数据成功！\"); } 　　结束语 　　POI功能强大，还可以设置单元格格式、设置页眉页脚等。限于篇幅的关系就不一一举例了，感兴趣的读者可以参考其帮助文档（在图2.1的doc文件夹中）。总之，使用POI，我们可以较好地解决Java编程中的Excel报表问题，进一步满足用户的需求.","title":"JAVA实现Excel导入/导出【转】"},{"content":"框图在上一篇文章中给出了，删除、更新和插入一样，也都有两种方式，一种是在数据源的编辑器中设定相应的方法来实现，另一种是自己写代码完成。 下面先给出更新的代码：          test_dbDataSet.courseRow cro;             test_dbDataSet.facultyRow fro;             if ( (course.Text == \"\") || (facultyid.Text == \"\") || (this.name.Text == \"\") || (this.num.Text == \"\"))                 MessageBox.Show(\"有一项或者多项没有填写内容，请填写完毕后再提交！\");             else             {                ///第一种方式      这里更新都没有更新表的主键，如果要更新主键最好方法就是找到该记录，删除它，然后在插入一个新的记录。                 if (cbupdate.Text == \"tableAdater.update\")                 {                     int f = facultyTableAdapter.Updatefaculty(this.name.Text, this.num.Text, this.facultyid.Text);                     int c = courseTableAdapter.Updatecourse(this.course.Text, this.facultyid.Text);                     if ((f > 0) && (c > 0))                         MessageBox.Show(\"更新成功！\");                     else                         MessageBox.Show(\"更新失败！\");                 }                 ///第二种方式                 else                 {                     string cid;                     fro = test_dbDataSet.faculty.FindByfaculty_id(facultyid.Text);                     fro = updatefacultydata(ref fro);                     this.Validate();                     facultyBindingSource1.EndEdit();                     int f = facultyTableAdapter.Update(test_dbDataSet.faculty);                    cid = courseTableAdapter.getcourseid_fid(facultyid.Text);                    cro = test_dbDataSet.course.FindBycourse_id(cid);                    cro = updatecoursedata(ref cro);                     ///this.Validate();                     ///facultyBindingSource1.EndEdit();                   ///  courseBindingSource1.EndEdit();                     int c = courseTableAdapter.Update(test_dbDataSet.course);                    if((f>0)&&(c>0))                         MessageBox.Show(\"第二种方式更新成功!\");                     else                         MessageBox.Show(\"第二种方式更新失败！\");                 }     删除的代码：                             test_dbDataSet.courseRow crow;             test_dbDataSet.facultyRow frow;            ///首先会弹出对话框询问是否要删除数据。             if (MessageBox.Show(\"您确定要删除数据吗？\", \"delete\", MessageBoxButtons.YesNo) == System.Windows.Forms.DialogResult.Yes)             {                  ///第一种方式                 if (cbway.Text == \"tableAdater.delete\")                    {                     string str;                     str = facultyTableAdapter.getid(cbdelete.Text);                     int k = facultyTableAdapter.Deletefaculty(str);                     int j = courseTableAdapter.Deletecourse(str);                     if ((k > 0) && (j > 0))                         MessageBox.Show(\"删除成功！\");                     else                         MessageBox.Show(\"删除失败！\");                 }             ///   第二种方式：                 else                 {                     string id = facultyTableAdapter.getid(cbdelete.Text);                     frow = test_dbDataSet.faculty.FindByfaculty_id(id);                     frow.Delete();                     int f = facultyTableAdapter.Update(test_dbDataSet.faculty);     ///这个函数返回的就删除的记录个数                                      string cid = courseTableAdapter.getcourseid_fid(id);                     crow = test_dbDataSet.course.FindBycourse_id(cid);                     crow.Delete();                     int c = courseTableAdapter.Update(test_dbDataSet.course);                     if ((c > 0) && (f > 0))                         MessageBox.Show(\"第二种方式删除成功！\");                     else                         MessageBox.Show(\"第二种方式删除失败！\");                 }  ","title":"C#中数据库的更新和删除记录的两种实现方式"},{"content":"  1、用normal选项关闭 通过shutdown normal命令正常关闭数据库。具体过程是：  （1）  在语句发出后不允许新的连接 （2）  在数据库关闭之前，ORACLE等待所有当前连接的所有用户都从数据库中退出后才开始关闭数据库  （3）  数据库的下一次启动不需要进行实例恢复 注意：但需要注意一点的是，采用这种方式，也许关闭一个数据库需要几天时间，也许更长。   2、用immediate 选项关闭 使用shutdown immediate命令立即关闭数据库。具体过程是： （1）  在语句发出后不允许新的连接 （2）  当前正在被Oracle处理的SQL语句立即中断，系统中任何没有提交的事务全部回滚。（3） ORACLE断开用户当前的数据库连接 （4）  数据库的下一次启动不需要进行实例恢复   3 用transactional 选项关闭 使用shutdown transactional命令关闭数据库的具体过程是： （1）  在语句发出后不允许新的连接 （2）  已经连接的客户不能启动新的事务，如果客户端试图启动一个新的事务，他们将被断开连接 （3）  等待当前激活的所有事务提交完成 （4）  客户事务提交完成后被断开连接 （5）  数据库的下一次启动不需要进行实例恢复   4 用abort选项关闭 使用shutdown abort命令关闭数据库的具体过程是： （1）  ORACLE处理的当前客户端SQL语句立即中断 （2）  未提交的事务将不会被回退 （3）  ORACLE立即断开所有用户的连接 （4）  数据库的下一次启动需要进行实例恢复  ","title":"关闭Oracle数据库shutdown选项"},{"content":"一.建立数据库 sqlite3.exe test.db   二.双击sqlite-3_6_16目录下的程序sqlite3.exe，即可运行 三.退出 .exit 或者 .quit 四.SQLite支持如下5种数据类型 1.NULL：空值。 2.INTEGER：带符号的整型，具体取决有存入数字的范围大小。 3.REAL：浮点数字，存储为8-byte IEEE浮点数。 4.TEXT：字符串文本。 5.BLOB：二进制对象。   五.联系人表格结构如下 create table contact(id integer primary key autoincrement, lastname varchar(20),firstname varchar(20), mobile varchar(30), telephone varchar(20), email  varchar(30), company varchar(50), department varchar(16),address varchar(80), id1 interger,id2 integer, updatetime datetime);   六.查看数据库有哪些数据表 命令是：.tables 七.如何插入一条记录 insert into contact(lastname,firstname,mobile,telephone,updatetime) values('刘','畅','13910128132','010-81749136','2009-07-22'); 八.查看数据表的结构 针对整个数据库 .schema 针对仅仅是contact联系人该表 .schema  contact 注意没有分号   九.如何打开一个已经创建的数据库 sqlite3  test.db 十.如何解决如下问题 SQL error: near \"sqlite3\": syntax error   SQL指令都是以分号（;）结尾的。如果遇到两个减号（--）则代表注解，sqlite3会略过去   十一.如何建立索引 create index index_name on table_name(field_to_be_indexed); 十二.如何删除一张数据表 drop table contact;   十三.查看当前的数据库 .database   十四.如何删除一个数据表的数据 delete from contact; 十五.如何导入一个文件到某个表中 .import  文件路径  表名 注意这是非SQL语句，所以不加分号 十六.如何设置文件字段的分隔符 .separator   “,” .import e:/contact.txt contact 十七.如何查看当前sqllite字段的分隔符是什么？ .show 十八.如何将查询结果导出到一个文件 第一步：.output a.txt 第二步：执行要导出的SQL语句 第三步：.output stdout 十九.SQL查询语句 select * from film order by year limit 10; select * from film order by year desc limit 10; select count(*) from film; select * from film where starring like 'Jodie%';   select * from film where starring='Jodie Foster'; select title, year from film order by year desc limit 10; select columns from table_name where expression;   最常见的用法，当然是倒出所有数据库的内容：   select * from film;   如果资料太多了，我们或许会想限制笔数：   select * from film limit 10;   或是照着电影年份来排列：   select * from film order by year limit 10;   或是年份比较近的电影先列出来：   select * from film order by year desc limit 10;   或是我们只想看电影名称跟年份：   select title, year from film order by year desc limit 10;   查所有茱蒂佛斯特演过的电影：   select * from film where starring='Jodie Foster';   查所有演员名字开头叫茱蒂的电影('%' 符号便是 SQL 的万用字符）：   select * from film where starring like 'Jodie%';   查所有演员名字以茱蒂开头、年份晚于1985年、年份晚的优先列出、最多十笔，只列出电影名称和年份：   select title, year from film where starring like 'Jodie%' and year >= 1985 order by year desc limit 10;   有时候我们只想知道数据库一共有多少笔资料：   select count(*) from film;   有时候我们只想知道1985年以后的电影有几部：   select count(*) from film where year >= 1985;   （进一步的各种组合，要去看SQL专书，不过你大概已经知道SQL为什么这么流行了：这种语言允许你将各种查询条件组合在一起──而我们还没提到「跨数据库的联合查询」呢！）     如何更改或删除资料 了解select的用法非常重要，因为要在sqlite更改或删除一笔资料，也是靠同样的语法。   例如有一笔资料的名字打错了： update film set starring='Jodie Foster' where starring='Jodee Foster'; 就会把主角字段里，被打成'Jodee Foster'的那笔（或多笔）资料，改回成Jodie Foster。 delete from film where year < 1970; 就会删除所有年代早于1970年（不含）的电影了。 其他sqlite的特别用法 sqlite可以在shell底下直接执行命令： sqlite3 film.db \"select * from film;\" 输出 HTML 表格： sqlite3 -html film.db \"select * from film;\" 将数据库「倒出来」： sqlite3 film.db \".dump\" > output.sql 利用输出的资料，建立一个一模一样的数据库（加上以上指令，就是标准的SQL数据库备份了）： sqlite3 film.db < output.sql 在大量插入资料时，你可能会需要先打这个指令：   begin; 插入完资料后要记得打这个指令，资料才会写进数据库中： commit;   创建数据库文件:     >SQLite3 d:\\test.db 回车    就生成了一个test.db在d盘。    这样同时也SQLite3挂上了这个test.db    2)     用.help可以看看有什么命令     >.help 回车即可    3)可以在这里直接输入SQL语句创建表格 用;结束 ，然后回车就可以看到了    4)看看有创建了多少表     >.tables     5)看表结构    >.schema 表名    6)看看目前的数据库     >.database    7)如果要把查询输出到文件     >.output 文件名    > 查询语句；    查询结果就输出到了文件c:\\query.txt    把查询结果用屏幕输出    >.output stdout    8)把表结构输出，同时索引也会输出      .dump 表名    9)退出     >.exit 或者.quit 2。从http://sqlite.phxsoftware.com/ 下载Ado.net驱动。    下载了安装，在安装目录中存在System.Data.SQLite.dll     我们只需要拷贝这个文件到引用目录，并添加引用即可对SQLite数据库操作了    所有的Ado.net对象都是以SQLite开头的，比如SQLiteConnection    连接串只需要如下方式    Data Source=d:\\test.db 或者DataSource=test.db--应用在和应用程序或者.net能够自动找到的目录    剩下的就很简单了~~ 3。SQL语法     由于以前用SQLServer或者ISeries，所以DDL的语法很汗颜    1)创建一个单个Primary Key的table    CREATE TABLE  [Admin] (  [UserName] [nvarchar] (20)   PRIMARY KEY NOT NULL ,  [Password] [nvarchar] (50)   NOT NULL ,  [Rank] [smallint] NOT NULL ,  [MailServer] [nvarchar] (50)   NOT NULL ,  [MailUser] [nvarchar] (50)   NOT NULL ,  [MailPassword] [nvarchar] (50)   NOT NULL ,  [Mail] [nvarchar] (50)   NOT NULL     ) ;    2)创建一个多个Primary Key的table     CREATE TABLE  [CodeDetail] (  [CdType] [nvarchar] (10)  NOT NULL ,  [CdCode] [nvarchar] (20)  NOT NULL ,  [CdString1] [ntext]   NOT NULL ,  [CdString2] [ntext]   NOT NULL ,  [CdString3] [ntext]   NOT NULL,   PRIMARY KEY (CdType,CdCode)              ) ;    3)创建索引     CREATE  INDEX [IX_Account] ON  [Account]([IsCheck], [UserName]);        还可以视图等等。 4.还有很有用的SQL   Select * from Sqlite_master    Select datetime('now')   Select date('now')   Select time('now')   SQLite 内建函数表 oh,还有就是看到有人说，好像成批插入的时候，启动事务，比不启动事务快n倍 还有就是尽量使用参数化的SQL,估计和商用DB一样能够自动Prepare. =========== sqlite可以在shell/dos command底下直接执行命令： sqlite3 film.db \"select * from film;\" 输出 HTML 表格：  sqlite3 -html film.db \"select * from film;\" 将数据库「倒出来」： sqlite3 film.db \".dump\" > output.sql 利用输出的资料，建立一个一模一样的数据库（加上以上指令，就是标准的SQL数据库备份了）： sqlite3 film.db < output.sql 在大量插入资料时，你可能会需要先打这个指令： begin; 插入完资料后要记得打这个指令，资料才会写进数据库中： commit; SQLITE深入------常见问题 如何建立自动增长字段? 简短回答：声明为 INTEGER PRIMARY KEY 的列将会自动增长 。 长一点的答案： 如果你声明表的一列为 INTEGER PRIMARY KEY，那么， 每当你在该列上插入一NULL值时， NULL自动被转换为一个比该列中最大值大1的一个整数，如果表是空的， 将会是1。 (如果是最大可能的主键 9223372036854775807，那个，将键值将是随机未使用的数。） 如，有下列表： CREATE TABLE t1( a INTEGER PRIMARY KEY, b INTEGER ); 在该表上，下列语句 INSERT INTO t1 VALUES(NULL,123); 在逻辑上等价于： INSERT INTO t1 VALUES((SELECT max(a) FROM t1)+1,123); 有一个新的API叫做 sqlite3_last_insert_rowid()， 它将返回最近插入的整数值。 注意该整数会比表中该列上的插入之前的最大值大1。 该键值在当前的表中是唯一的。但有可能与已从表中删除的值重叠。要想建立在整个表的生命周期中唯一的键值，需要在 INTEGER PRIMARY KEY 上增加AUTOINCREMENT声明。那么，新的键值将会比该表中曾能存在过的最大值大1。如果最大可能的整数值在数据表中曾经存在过，INSERT将会失败， 并返回SQLITE_FULL错误代码。 多个应用程序或一个应用程序的多个实例可以同时访问同一个数据库文件吗？ 多个进程可同时打开同一个数据库。多个进程可以同时进行SELECT 操作，但在任一时刻，只能有一个进程对数据库进行更改。 SQLite使用读、写锁控制对数据库的访问。（在Win95/98/ME等不支持读、写锁的系统下，使用一个概率性的模拟来代替。）但使用时要注意： 如果数据库文件存放于一个NFS文件系统上，这种锁机制可能不能正常工作。 这是因为 fcntl() 文件锁在很多NFS上没有正确的实现。 在可能有多个进程同时访问数据库的时候，应该避免将数据库文件放到NFS上。在Windows上，Microsoft的文档中说：如果使用 FAT 文件系统而没有运行 share.exe 守护进程，那么锁可能是不能正常使用的。那些在Windows上有很多经验的人告诉我：对于网络文件，文件锁的实现有好多Bug，是靠不住的。如果他们说的是对的，那么在两台或多台Windows机器间共享数据库可能会引起不期望的问题。 我们意识到，没有其它嵌入式的 SQL 数据库引擎能象 SQLite 这样处理如此多的并发。SQLite允许多个进程同时打开一个数据库，同时读一个数据库。当有任何进程想要写时，它必须在更新过程中锁住数据库文件。但那通常只是几毫秒的时间。其它进程只需等待写进程干完活结束。典型地，其它嵌入式的SQL数据库引擎同时只允许一个进程连接到数据库。 但是，Client/Server数据库引擎（如 PostgreSQL, MySQL, 或 Oracle）通常支持更高级别的并发，并且允许多个进程同时写同一个数据库。这种机制在Client/Server结构的数据库上是可能的，因为总是有一个单一的服务器进程很好地控制、协调对数据库的访问。如果你的应用程序需要很多的并发，那么你应该考虑使用一个Client/Server 结构的数据库。但经验表明，很多应用程序需要的并发，往往比其设计者所想象的少得多。 当SQLite试图访问一个被其它进程锁住的文件时，缺省的行为是返回 SQLITE_BUSY。 可以在C代码中使用 sqlite3_busy_handler() 或 sqlite3_busy_timeout() API 函数调整这一行为。 在SQLite数据库中如何列出所有的表和索引？ 如果你运行 sqlite3 命令行来访问你的数据库，可以键入 “.tables”来获得所有表的列表。或者，你可以输入 “.schema” 来看整个数据库模式，包括所有的表的索引。输入这些命令，后面跟一个LIKE模式匹配可以限制显示的表。 在一个 C/C++ 程序中（或者脚本语言使用 Tcl/Ruby/Perl/Python 等） 你可以在一个特殊的名叫 SQLITE_MASTER 上执行一个SELECT查询以获得所有 表的索引。每一个 SQLite 数据库都有一个叫 SQLITE_MASTER 的表， 它定义数据库的模式。 SQLITE_MASTER 表看起来如下： CREATE TABLE sqlite_master ( type TEXT, name TEXT, tbl_name TEXT, rootpage INTEGER, sql TEXT ); 对于表来说，type 字段永远是 'table'，name 字段永远是表的名字。所以，要获得数据库中所有表的列表，使用下列SELECT语句： SELECT name FROM sqlite_master WHERE type='table' ORDER BY name; 对于索引，type 等于 'index', name 则是索引的名字，tbl_name 是该索引所属的表的名字。不管是表还是索引，sql 字段是原先用 CREATE TABLE 或 CREATE INDEX 语句创建它们时的命令文本。对于自动创建的索引（用来实现 PRIMARY KEY 或 UNIQUE 约束），sql字段为NULL。 SQLITE_MASTER 表是只读的。不能对它使用 UPDATE、INSERT 或 DELETE。 它会被 CREATE TABLE、CREATE INDEX、DROP TABLE 和 DROP INDEX 命令自动更新。 临时表不会出现在 SQLITE_MASTER 表中。临时表及其索引和触发器存放在另外一个叫 SQLITE_TEMP_MASTER 的表中。SQLITE_TEMP_MASTER 跟 SQLITE_MASTER 差不多，但它只是对于创建那些临时表的应用可见。如果要获得所有表的列表， 不管是永久的还是临时的，可以使用类似下面的命令： SELECT name FROM     (SELECT * FROM sqlite_master UNION ALL     SELECT * FROM sqlite_temp_master) WHERE type='table' ORDER BY name 在SQLite中，VARCHAR字段最长是多少？ SQLite 不强制 VARCHAR 的长度。 你可以在 SQLITE 中声明一个 VARCHAR(10)，SQLite还是可以很高兴地允许你放入500个字符。 并且这500个字符是原封不动的，它永远不会被截断。 SQLite支持二进制大对象吗？ SQLite 3.0 及以后版本允许你在任何列中存储 BLOB 数据。 即使该列被声明为其它类型也可以。 在SQLite中，如何在一个表上添加或删除一列？ SQLite 有有限地 ALTER TABLE 支持。你可以使用它来在表的末尾增加一列，可更改表的名称。 如果需要对表结构做更复杂的改变，则必须重新建表。重建时可以先将已存在的数据放到一个临时表中，删除原表， 创建新表，然后将数据从临时表中复制回来。 如，假设有一个 t1 表，其中有 \"a\", \"b\", \"c\" 三列， 如果要删除列 c ，以下过程描述如何做: BEGIN TRANSACTION; CREATE TEMPORARY TABLE t1_backup(a,b); INSERT INTO t1_backup SELECT a,b FROM t1; DROP TABLE t1; CREATE TABLE t1(a,b); INSERT INTO t1 SELECT a,b FROM t1_backup; DROP TABLE t1_backup; COMMIT; 在数据库中删除了很多数据，但数据库文件没有变小，是Bug吗？ 不是。当你从SQLite数据库中删除数据时， 未用的磁盘空间将会加入一个内部的“自由列表”中。 当你下次插入数据时，这部分空间可以重用。磁盘空间不会丢失，但也不会返还给操作系统。 如果删除了大量数据，而又想缩小数据库文件占用的空间，执行 VACUUM 命令。 VACUUM 将会从头重新组织数据库。这将会使用数据库有一个空的“自由链表”， 数据库文件也会最小。但要注意的是，VACUUM 的执行会需要一些时间（在SQLite开发时，在Linux上，大约每M字节需要半秒种），并且， 执行过程中需要原数据库文件至多两倍的临时磁盘空间。 对于 SQLite 3.1版本，一个 auto-vacumm 模式可以替代 VACUUM 命令。 可以使用 auto_vacuum pragma 打开。 SQLITE_SCHEMA error是什么错误？为什么会出现该错误？ 当一个准备好的（prepared）SQL语句不再有效或者无法执行时， 将返回一个 SQLITE_SCHEMA 错误。发生该错误时，SQL语句必须使用 sqlite3_prepare() API来重新编译. 在 SQLite 3 中, 一个 SQLITE_SCHEMA 错误只会发生在用 sqlite3_prepare()/sqlite3_step()/sqlite3_finalize() API 执行 SQL 时。而不会发生在使用 sqlite3_exec()时。 在版本2中不是这样。 准备好的语句失效的最通常原因是：在语句准备好后， 数据库的模式又被修改了。另外的原因会发生在： 数据库离线：DETACHed.  数据库被 VACUUMed  一个用户存储过程定义被删除或改变。  一个 collation 序列定义被删除或改变。  认证函数被改变。  在所有情况下，解决方法是重新编译并执行该SQL语句。 因为一个已准备好的语句可以由于其它进程改变数据库模式而失效，所有使用 sqlite3_prepare()/sqlite3_step()/sqlite3_finalize() API 的代码都应准备处理 SQLITE_SCHEMA 错误。下面给出一个例子：     int rc;     sqlite3_stmt *pStmt;     char zSql[] = \"SELECT .....\";     do {       /* Compile the statement from SQL. Assume success. */       sqlite3_prepare(pDb, zSql, -1, &pStmt, 0);       while( SQLITE_ROW==sqlite3_step(pStmt) ){         /* Do something with the row of available data */       }       /* Finalize the statement. If an SQLITE_SCHEMA error has       ** occured, then the above call to sqlite3_step() will have       ** returned SQLITE_ERROR. sqlite3_finalize() will return       ** SQLITE_SCHEMA. In this case the loop will execute again.       */       rc = sqlite3_finalize(pStmt);     } while( rc==SQLITE_SCHEMA );   如何在字符串中使用单引号(')？ SQL 标准规定，在字符串中，单引号需要使用逃逸字符，即在一行中使用两个单引号。在这方面 SQL 用起来类似 Pascal 语言。 SQLite 尊循标准。如：     INSERT INTO xyz VALUES('5 O''clock'); Sqlite中如何返回本地化当前时间？ 在做ClinicOS的时候遇到一个问题，在保存病历登记时间时，我使用了“CURRENT_TIMESTAMP”，但这有个问题，它返回的是UTC Time，这对我们中国人没啥用，一直希望能想办法将它转为localtime。今天刚好有空，所以去查了查Sqlite的Mail List，果然也有人遇到了这个问题，我从一篇名为《translate time comparison statement》（http://www.mail-archive.com/sqlite-users@sqlite.org /msg12350.html）中看到这样的回复： 二十.如何更新表中数据 update contact set lastname=’江南七怪’where id = 1028   update contact set lastname='江南七怪', mobile='13912345678' where id=1028; 二十一.如何一次插入多个数据 Insert into SAMPLE(PRJNUM, PRJNAME, EMYNUM, EMYNAME, SALCATEGORY, SALPACKAGE) values(100001, 'TPMS', 200001, 'Johnson', 'A', 2000), (100001, 'TPMS', 200002, 'Christine', 'B', 3000), (100001, 'TPMS', 200003, 'Kevin', 'C', 4000), (100002, 'TCT', 200001, 'Johnson', 'A', 2000), (100002, 'TCT', 200004, 'Apple', 'B', 3000);   算术函数 abs(X) 返回给定数字表达式的绝对值。 max(X,Y[,...]) 返回表达式的最大值。 min(X,Y[,...]) 返回表达式的最小值。 random(*) 返回随机数。 round(X[,Y]) 返回数字表达式并四舍五入为指定的长度或精度。 字符处理函数 length(X) 返回给定字符串表达式的字符个数。 lower(X) 将大写字符数据转换为小写字符数据后返回字符表达式。 upper(X) 返回将小写字符数据转换为大写的字符表达式。 substr(X,Y,Z) 返回表达式的一部分。 randstr()   quote(A)   like(A,B) 确定给定的字符串是否与指定的模式匹配。 glob(A,B)   条件判断函数 coalesce(X,Y[,...])   ifnull(X,Y)   nullif(X,Y)   集合函数 avg(X) 返回组中值的平均值。 count(X) 返回组中项目的数量。 max(X) 返回组中值的最大值。 min(X) 返回组中值的最小值。 sum(X) 返回表达式中所有值的和。 其他函数 typeof(X) 返回数据的类型。 last_insert_rowid() 返回最后插入的数据的 ID 。 sqlite_version(*) 返回 SQLite 的版本。 change_count() 返回受上一语句影响的行数。 last_statement_change_count()  ","title":"SQLite学习笔记"},{"content":"发生原因： 关闭数据库是shutdown 后面没有接关闭参数中的任何一个。 nomal          --->所有连接都断开时才能关闭； transactional  --->等待事务结束后，主动断开连接； immediate      --->主动断开事务和连接 abort          --->立刻关闭数据库，这个操作是危险的，不会同步数据，不触发检查点，回滚段直接清  空，相当于掉电，每次启动都要实例恢复。 所以，数据库关闭很慢，这时我一心急，就直接退出了sqlplus，造成oracle文件被lock，当我再次startup时，操作失败，因为文件依然被锁定状态。报错ORA-01012: not logged on。 解决办法： 解决问题思路： 1、等数据库访问连接数下降用户再登录 2、sqlplus “/ as sysdba”登陆后       shutdown abort  3、ps -ef|grep ora_dbw0_$ORACLE_SID      kill -9 pid 4、kill掉一些不重要的session  5、sqlplus /nolog          conn /as sysdba      startup 我用第二种方法：shutdown abort之后，重新启动sqlplus，就没有问题了","title":"ORA-01012:not logged on"},{"content":"方法一 use mysql insert into user (host,user,password) values ('%','user_name','your password'); flush privileges; 方法二 set password for user_name = password(\"your password\") 方法三 创建一个用户时直接设置密码 grant all on *.* to mailto:user_name@ identified by \"your password\"; 方法四 mysqladmin -u root password \"your password\"","title":"mysql数据库为用户设置密码"},{"content":"本来转载于http://kingliu.iteye.com/blog/992325 1.实现SmartLifecycle接口 public class InitRedisCache implements SmartLifecycle{            @Override      public void start() {          // TODO Auto-generated method stub                }        @Override      public void stop() {          // TODO Auto-generated method stub                }        @Override      public boolean isRunning() {          // TODO Auto-generated method stub          return false;      }        @Override      public int getPhase() {          // TODO Auto-generated method stub          return 0;      }        @Override      public boolean isAutoStartup() {          // TODO Auto-generated method stub          return true;      }        @Override      public void stop(Runnable callback) {          // TODO Auto-generated method stub                }} 2.实现ApplicationListener接口，定义个event，判断event是否相等。 @Lazy(false)  @Repository  public class InitRedisCache implements ApplicationListener{            @Autowired      @Qualifier(\"dictionaryService\")      private DictionaryService dictionaryService;            @Autowired      @Qualifier(\"redisService\")      private RedisService redisService;        @Override      public void onApplicationEvent(ApplicationEvent event) {          if(event instanceof InitEvent){              initDictionaryData();          }      }            public  void initDictionaryData(){        }    }","title":"Spring实现数据库的初始化"},{"content":"1、查看数据库归档情况 SQL> archive log list Database log mode              Archive Mode Automatic archival             Enabled Archive destination            USE_DB_RECOVERY_FILE_DEST Oldest online log sequence     5295 Next log sequence to archive   5304 Current log sequence           5304 SQL> show parameter archive NAME                                 TYPE        VALUE ------------------------------------ ----------- ------------------------------ archive_lag_target                   integer     0 log_archive_config                   string log_archive_dest                     string log_archive_dest_1                   string 2、更改归档路径 SQL>  alter system set log_archive_dest_1='/opt/app/oracle/arch'  scope=both;  alter system set log_archive_dest_1='/opt/app/oracle/arch'  scope=both * ERROR at line 1: ORA-32017: failure in updating BOTH ORA-16179: incremental changes to \"log_archive_dest_1\" not allowed with BOTH 添加关键字 location 即可 SQL>  alter system set log_archive_dest_1='location=/opt/app/oracle/arch'  scope=both; System altered. SQL> archive log list Database log mode              Archive Mode Automatic archival             Enabled Archive destination            /opt/app/oracle/arch Oldest online log sequence     5295 Next log sequence to archive   5304 Current log sequence           5304 3、查看当前归档信息 SQL> select name,sequence#,first_change# from v$archived_log; 查看当前归档路径","title":"变更归档路径遇到的ORA-32017and ORA-16179"},{"content":"通过 IP 地址对访问者进行定位是非常 cool 的功能，如 IP 地址（61.141.86.110 ） 可以定位到深圳这个城市，甚至获取地理坐标，其实网上已经有人收集了相关的 IP 映射数据，并提供了 API，今天就介绍三种可以通过 IP 地址进行这样定位的免费 API： Hostip.info 是一个基于社区的 IP 映射数据库，只需一些选项设置输出，就能非常容易把它的 REST API 整合到服务器端代码中，详细使用请访问 Hostip.info 的 API 页面。 Blogama 这个 IP 地址位置 API 是基于 MaxMind API，它对数据进行了精简，删除了一些重复的数据，最后非常神奇只有 120W 条数据，并且能够精确到城市这一级，Blogama 更好开放的是你可以吧这些数据导入到自己的数据库中。 MaxMind 提供的是另外一种 API，它不是调用 Web 服务。它的免费版本是是以二进制方式分发的，并且已经提供多种程序语言访问这个 IP 数据的源代码，详情你请访问 MaxMind GeoIP API 页面。 翻译自：3 Free Ways to Geolocate By IP","title":"3 种通过 IP 地址对访问者定位的方法"},{"content":"SQLite数据库 SQLite是一个老牌的轻量级别的文件数据库，完全免费，使用方便，不需要安装，无须任何配置，也不需要管理员。 它是开源的嵌入式数据库产品，是同类产品中的后起之秀，2005年获得了开源大奖，而且最新的PHP5也内嵌了SQLite。相比另一款著名的嵌入式数据库——Berkely DB。SQLite是关系型数据库，支持大部分SQL语句，这是它比BDB优秀的地方。 作为一款嵌入式数据库，SQLite与Berkely DB一样，以库的形式提供，通过C函数直接操作数据库文件。(也支持其他的访问方式，比如Tcl)。下载包中有SQLite3.dll和 SQlite3.def，def可以用VC的lib工具生成链接库，当然也可以直接链接dll文件。 SQLite不是Server，所以和SQLServer等不同，它和程序运行在同一进程。中间没有进程间通信，速度很快，而且体积小巧，易于分发。适合运行在单机环境和嵌入式环境。(随便说一下，腾讯的QQ中可能就用到了SQLite数据库来保存信息) 支持事务机制和blob数据类型。支持大部分SQL92标准.一个完整的数据库保存在磁盘上面一个文件. 同一个数据库文件可以在不同机器上面使用,最大支持数据库到2TB. 源代码开放, 代码95%有较好的注释,简单易用的API.  现在已经发展到了SQLite3版本,目前最新版本是SQLite3.3.4. 资源下载： Sqlite .net 支持 http://files.cnblogs.com/snow365/SQLite-1.0.31.0-binary.rar 哎，找到好久，终于找到了一个sqlite的图形管理工具SharpPlus Sqlite Developer 。 SQLite Spy 也不错，界面很美观，我感觉功能少了点。 SQLite的源码：http://www.sqlite.org/sqlite-source-3_3_4.zip(包括sqlite3.h) SQLite编译好的dll及def文件:http://www.sqlite.org/sqlitedll-3_3_4.zip SQLite提供一个命令行shell的工具用以访问数据库，下载windows下的SQLite命令行工具sqlite3.exe, 下载地址:http://www.sqlite.org/sqlite-3_3_4.zip。 网上有一款针对SQLite3的 UI工具－SQLite Spy。下载地址：www.yunqa.de/delphi/sqlitespy/ 如果想通过ODBC来访问操作SQLite数据库,需要安装第三方组件库的SQLite ODBC Driver, 可以到\"http://www.patthoyts.tk/sqlite3odbc.html\"或者\"http://www.ch-werner.de/sqliteodbc/\"去下载. 也可以直接下载其ODBC的驱动安装程序:\"http://www.ch-werner.de/sqliteodbc/sqliteodbc.exe\" 现在SQLite ODBC Driver的版本为0.65.  然后在C++程序中就可以使用OTL来统一对数据库的访问。 SQLite的官方主站：http://www.sqlite.org/ SQLite的中文网：http://sqlitecn.feuvan.net/index.html  OTL的官方主站：http://otl.sourceforge.net/home.htm 其它参考： http://www-128.ibm.com/developerworks/cn/opensource/os-sqlite/index.html?ca=dwcn-newsletter-opensource http://blog.donews.com/limodou/archive/2004/03/21/7997.aspx","title":"SQLite数据库"},{"content":"利用共享存储搭建oracle双机负载 准备环境：服务器两台、存储一台 基本原理如上图所示： 环境： 共享存储：172.16.0.5 DB1： eth0：192.168.1.1 eth1：172.168.0.1 vip：192.168.1.5 DB2： eth0：192.168.1.2 eth1：172.168.0.2 vip：192.168.1.5 具体讲解 1、在共享存储上创建数据存储目录 /dev/oradata/ 2、在DB1、DB2上创建挂载目录，挂载共享存储 /oradata 3、DB1安装 按照oracle安装方式将数据库安装到共享存储上，完成之后卸载挂载的共享存储； 4、DB2安装 卸载DB1共享存储，将共享存储上的DB1数据目录修改下目录名字； 将共享存储挂载到DB2上； 在DB2上同步DB1的安装配置使其完全一样； 5、然后卸载到DB2挂载共享，将其挂载到DB1，这样DB1的环境就可以恢复到初次建立数据的状态； 一旦DB1出现问题的时候，将DB1vip挂载到DB2上，并启用DB2的数据库，这样DB2的环境就等同于故障前的DB1； 6、当然两台机器上的配置文件什么修改可以使用rsync软件进行双机之间的同步，以保证高可用性。","title":"利用共享存储搭建oracle双机负载"},{"content":"作者：刘广福,华清远见嵌入式学院讲师。 基于嵌入式linux的数据库主要有SQLite, Firebird, Berkeley DB, eXtremeDB 这几种数据库的特点： 1.Firebird是关系型数据库,功能强大,支持存储过程、SQL兼容等         2.SQLite关系型数据库,体积小,支持ACID事务         3.Berkeley DB中并没有数据库服务器的概念，它的程序库直接链接到应用程序中         4.eXtremeDB是内存数据库,运行效率高 SQLite的源代码是C，其源代码完全开放，是一个轻量级的嵌入式数据库。 SQLite有以下特性：         零配置一无需安装和管理配置；         储存在单一磁盘文件中的一个完整的数据库；         数据库文件可以在不同字节顺序的机器间自由共享；         支持数据库大小至2TB；         足够小，全部源码大致3万行c代码，250KB；         比目前流行的大多数数据库对数据的操作要快；         这个数据库操作比较简单，首先要安装数据库： 这个很简单，在http://www.sqlite.org/download.html这个sqlite主页的下载目录中找到对应的linux版本。下载完成后解压，执行里面的 configure。如图： 执行完之后要执行 sudo make && make install 等待一段时间就可以安装完成。 完成以后看一下我们sqlite3的执行文件的路径在哪里如图： 在/usr/local/bin目录里。 为了以后的方便，可以将该目录加入到环境变量里，先打开 sudo vim /environment 将路径加入到这里，如何将sqlite3 移植到开发板上呢？ 1、去掉/root/sqlite3.3.6目录下的sqlite3的调示信息：（俗称瘦身） #arm-linux-strip sqlite3 2、将sqlite3下载到开发板的/usr/bin目录：         在PC机的目录/usr/lib 中找到libsqlite3.so.0、libsqlite3.so.0.8.6这两个库文件，去掉调示信息后把它们复制到开发板的/usr/lib目录下：         arm-linux-strip libsqlite3.so.0 (/home/linux/sqlite/lib)         arm-linux-strip libsqlite3.so.0.8.6 (/home/linux/sqlite/lib)         cp –arf libsqlite3.so.0 libsqlite3.so.0.8.6 /usr/lib 加上arf的目的是将源库拷贝，千万别只拷贝个链接，那么就悲剧了。。。 经过以上步骤，开发板上就已经有了sqlite数据库。 sqlite的一些基本操作可以在网上找一下，SQL语句都是通用的，所以比较重要的是sqlite3特供的一些操作数据库的接口： int sqlite3_open(char *path, sqlite3 **db)；         功能：打开sqlite数据库         path： 数据库文件路径         db： 指向sqlite句柄的指针         返回值：成功返回0，失败返回错误码(非零值) int sqlite3_close(sqlite3 *db);         功能：关闭sqlite数据库         返回值：成功返回0，失败返回错误码         const char *sqlite3_errmg(sqlite3 *db);         返回值：返回错误信息 gcc -o test test.c -lsqlite3         } 回调函数的定义： typedef int (*sqlite3_callback)(void *para, int f_num, char **f_value, char **f_name); }         功能：每找到一条记录自动执行一次回调函数         para：传递给回调函数的参数         f_num：记录中包含的字段数目         f_value：包含每个字段值的指针数组         f_name：包含每个字段名称的指针数组         返回值：成功返回0，失败返回-1 int sqlite3_exec(sqlite3 *db, const char *sql, sqlite3_callback callback, void *, char **errmsg);         功能：执行SQL操作         db：数据库句柄         sql：SQL语句         callback：回调函数         errmsg：错误信息指针的地址         返回值：成功返回0，失败返回错误码 例如：定义一个回调函数，打印记录中所有字段的名称和值 int callback(void *para, intf_num, char **f_value, char **f_name) {         int i;         printf(“*****************************\\n”);         for (i=0; i< f_num; i++)         {         printf(“%s : %s\\n”, f_name[i], f_value[i]);         }         return 0; } sqlite3 *db; char *errmsg; …… if (sqlite3_exec(db, “select * from table”, callback, NULL, &errmsg) != SQLITE_OK) {         printf(“error : %s\\n”, errmsg);         exit(-1); } …… 不使用回调函数执行SQL语句 int sqlite3_get_table(sqlite3 *db, const char *sql, char ***resultp, int*nrow, int *ncolumn, char **errmsg); 函数功能：执行SQL操作 函数参数：         db：数据库句柄         sql：SQL语句         resultp：用来指向sql执行结果的指针         nrow：满足条件的记录的数目         ncolumn：每条记录包含的字段数目         errmsg：错误信息指针的地址 返回值：成功返回0，失败返回错误码 sqlite3 *db; char *errmsg，**resultp; int nrow, ncolumn, i, j, index; …… if (sqlite3_exec(db, “select * from table”, &resultp, &nrow, &ncolumn, &errmsg) != SQLITE_OK) {         printf(“error : %s\\n”, errmsg);         exit(-1); } index = ncolumn; // 第一条记录的第一个字段的下标 for (i=0; i< nrow; i++)  {         for (j=0; j< ncolumn; j++)         {         printf(“%s : %s\\n”, resultp[j], resultp[index++]);         } } 有了这几个函数，数据库的操作就基本上OK了. 原文地址：http://www.embedu.org/Column/Column588.htm，转载请注明！","title":"linux内核数据库sqlite3的移植和简单操作"},{"content":"1 String和StringBuffer有什么区别？int和Integer有什么不同，float f= 3.14是否正确 2 异常（Exception）分几种类型？有什么区别？写出几个常见异常 3 写出几种常见的java数据结构和特点（List,set,map等） 4 下列两个方法有什么区别 Public synchronized void method1（）{} Public void method2(){ Synchronized (obj){} } 5 public class Test{ public static void so(String[] name){ String temp = name[0] Name[0]=name[1]; Name[1] =temp; } Public static void so（string name(),String name1）{ String temp=name0 Name0=name1; Name1=temp; } Public static void main(String[] arg){ String[] name = new String[]{“mike”,”lily”}; String name0=”mike”; String name1 = “lily”; So(name); System.out.println(name[0]+”,”+name[1]); So(name0,name1); System.out.println(name0+”,”+name1); } 写出结果 6以下数据库操作的程序片段如何改进会更好？ Try{ Class.forNmae(“com.mysql.jdbc.Driver”); Connection conn=DriverManager.getConnection(“jdbc:mySql://localhost/test”,”root”, Statement stmt = conn.createStatement(); String sql=”select* from t_User where username=”””+name +””and password =’’’+password+””; ResultSet rs = stmt.executeQuery(sql); If(rs.next()){ System.out.println(“User Name and password is correct”); }else{ System.out.prinln(“User Name and password pair is invalidate”) } }catch(Exception e){ e.printStactTrace(): } 6 请问下列程序运行输出结果是多少？ Public static void main(String[] afsaf){ List list1; List list2; List1 = new List(); List2 = list1； List1.add(new Object()); System.out.println(list2.size()); } 数据库orcacle 1从product表中取出price大于9.99的前100行数据 SELECT * FROM product WHERE rownum <=100 and price> 9.99 2. 接上题，要求取出满足条件的第100行至200行数据 SELECT *   FROM ( SELECT ROWNUM RN, A.* FROM PRODUCT A)  WHERE RN >= 100    AND RN <= 200    AND PRICE > 9.99 3 获取数据库当前时间，并以yyyy-mm-dd HH:mm:ss的格式输出 select to_char( sysdate , 'yyyy-mm-dd hh24:mi:ss' ) from dual; SQL> select to_char(sysdate, 'yyyy-mm-dd amhh:mi:ss') from dual;   TO_CHAR(SYSDATE,'YYYY-MM-DDAMH ------------------------------ 2012-12-18 下午02:37:23 数据中的索引和外键是什么意思?有什么用途？ 4 下列Sql条件语句中的列都建有恰当的索引，但执行速度非常慢，说出原因并改写 SELECT * FROM XXX WHERE substr(value,1,4)=’5378’ SELECT * FROM xxx WHERE nummber LIKE '5378%' SELECT * FROM xxx WHERE value/30<1000 SELECT * FROM xxx WHERE nummber < 1000* 30 SELECT * FROM xxx WHERE convert(char(10).date,112) = ‘1999201’ SELECT * FROM xxx WHERE datevalue=to_date ('19990201' ,'yyyymmdd' ) Web 表现层 1 javascript 如何效验一个字符串是否为数字？举例说明 2 如何动态改变DIV对象的显示内容？ 3 如下 <script type = “text/javascript”> Runction lop(){ For(int i=0;i<new Date().getMonth();i++) {<%System.out.println(“@_@”)%>} } Lop(); <\/script> 请问此代码是否有问题，@_@输出几次 4如何判断页面中的一个checkbox是否被选中？如何禁用它？如何判断一个input的值是否为空 5 下面一个css 样式文件的片段，写出每种定义方式的含义： Td{width:100%;} Td{width:100%;} #td{width:100%} Td input{font-size:20pt} 6 rward和redirect的区别 7 jsp中动态 INCLUDE与静态INCLUDE的区别 8 jsp页面中 <%%> <%! %>, <%=%> <%--  --%>有什么区别 9 Form变淡的那个属性是表单数据的传送方式（GET/POST）?并简要说明get/post方式有何区别 10 指出/images/123.jpg与images/123.jpg两种写法有什么区别 11 列出你所用的HTml元素 二 进阶（Optional）: -------此部分面试题可选 应用部署与优化 1 写出设置java进程占用内存的出示值和最大值的方法，如 java-Xss512k 2 写出几个Linux/unix系统的常用命令 三其他 必做题 1请写出几种你知道的设计模式 2 列举几个你常去的网站，类型不限，写中文名亦可 3列举最近一年来你读过的技术类图书、文章   1写出HttpServletRequest和HttpSession的几个主要方法，并且说明用法 2用代码或者文字描述模板方法模式，代理模式，门面模式 3解释下面几个原则 开闭原则，里氏替换原则，依赖倒转原则，迪米特法则 4描述Spring的IOC原理，并用代码与xml文件描述 5 Hibernate的几个常用的类及其作用（可以用代码或者文字说明） 6说明公司，部门，职位，员工三者及其自身之间的关系，并用UML类图来表示出他们之间的关系 7取出一个字符串中连续有相同字母的最大个数及该字母 例：字符串：aaaddxxxxxxxdddxxx返回值x,7 如果最大位数有多个，则返回第一个，列：字符串：aaabbb  返回值a,3 字符中取值范围（a-z）和（A—z）之间，且最大字符位数为40 要求：请考虑代码执行效率并注意编码的风格 8请对一下场用的名词进行解释，并简要说明其用途 1） 数据库连接池 2） JTA与事物 3） 容器 4） JNDI  命名和目录接口  5） SessionBean 9谈谈你的对springMVC或Struts的理解：使用方法，数据流程，调用关系等 要列出主要使用java类型 10写出一些你常用的eclipse快捷键并说明用法 11写出一些java web系统中，你唱用的xml配置文件及其用途 12员工星表Tablex有。。。。。。 12.1请写出SQL,找出所有姓张的员工，并按年龄从小到大排列 12.2取出BB岗位考评不合格的员工 12.3通过等值联接，取出Name.position,score请写出sql即输出结果 12.4通过外联，取出每个员工的Name，position,score请写出Sql即输出结果 12.5李四的年龄纪录错了，应该是21，请写SQL,更具主键进行更新 12.6请写SQL,zhaochu Tablex中没有考评的记录 12.7写出，查询税务事业部，的本下级部门以及所有下级的下级不蒙，使用start with 12.88解释下面几个oracle函数的意义和用法或写出一个实例SQL Decode,nvl,case,with,intersect,minus,substr,having   笔试试卷（Java 语言部分） 姓名：                 联系方式：                                 1. which won’t cause a compiler warning or error？(多选) a) float f = 1.3; b) char c = ‘a’; c) byte b = 257; d) boolean b = null; e) int i = 10; 2. 请选择下面这段代码的输出结果? int i = 0; switch (i) { case 0: System.out.println(\"zero\"); case 1: System.out.println(\"one\"); case 2: System.out.println(\"two\"); break; case 3:     System.out.println(\"three\"); } 1) zero 2) zero,one 3) zero,one,two 4) zero,one,two,three 3.  public class Test{     private static int j=0;     public static boolean methodB(int k){       j+=k;      return true;     }     public static void methodA(int i){      boolean b;      b=i>10&methodB(1);      b=i>10&&methodB(2);       }      public static void main(String args){       methodA(0);  17)       }       }     what is the value of j at line 17?  1）0  2）1  3）2 4）3 4. If we execute the code below with “java Test Red Green Blue”, what is the result?  public class Test{  public static void main(String[] args){      String  foo=args[1];      String  bar=args[2];      String  baz=args[3];      }  }  what is the value of baz?  A. baz has value of \"\"  B. baz has value of null  C. baz has value of \"Red\"  D. baz has value of \"Blue\"  E. baz has value of \"Green\"  F. the code does not compile  G. the program throw an exception 5. 请选择下面这段代码的输出结果? 1)public class Test{  2)public static void main(String[] args){  3) class Foo{  4) public int i=3;  5) }  6)Object o=(Object)new Foo();  7) Foo foo=(Foo)o;  8)System.out.println(foo.i);  9) }  10) }  A.compile error at line 6  B.compile error at line 7  C.compile error at line 8  D.print out 3 6.  int index=1;    String[] test=new String[3];    String foo=test[index];    what is the result of foo?     A. \"\"   B.null    C.throw a Exception   D.not compile 7. 下面的五个选择中哪两个描述是正确的？（多选）   A. static inner class requires a static initializer    B. A static inner class requires an instance of the enclosing class    C. A static inner class has no reference to an instance of the enclosing class    D. A static inner class has accesss to the non-static member of the other class    E. static members of a static inner class can be referenced using the class       name of the static inner class 8. 请选择下面这段代码的输出结果?  class A{     public int getNumber(int a){      return a+1;      }      }     class B extends A{       public int getNumber(int a, char c){       return a+2;      }      public static void main(String[] args){       B b=new B();       System.out.println(b.getNumber(0));      }     }              A. compilation succeeds and 1 is printed    B. compilation succeeds and 2 is printed    C. An error at line 8 cause compilation to fail    D. An error at line 14 cause compilation to fail 9. class ExceptionTest{    public static void main(String args[]){     try{  methodA();  }     catch(IOException e){  System.out.println(\"caught IOException\");     }     catch(Exception e){     System.out.println(\"caught Exception\");      }    }  } If methodA() throws a IOException, what is the result? If we change the sequence of catch,what’s the result？ 10. 请写出下面这段代码的输出结果? public class Test{  public static void main(String[] args){     StringBuffer a=new StringBuffer(\"A\");     StringBuffer b=new StringBuffer(\"B\");     operate(a,b);     System.out.pintln(a+\",\"+b);  }  public static void operate(StringBuffer x, StringBuffer y){      x.append(y);      y=x;  }  }  11. 请写出下面这段代码的输出结果? class Shape{   Shape(int i){     System.out.println(\"This is Shape\" + i);   } } public class Circle extends Shape{   static Shape s1 = new Shape(1);   Shape s2 = new Shape(3);   Circle(int i){     super(i);     System.out.println(\"This is Circle\" + i);   }   public static void main(String args[]){     Circle c1 = new Circle(2);   } } 12. 数组有没有length()这个方法? String有没有length()这个方法? JAVA软件开发笔试题目  答题人姓名：            答题时间：2011年  月  日 一、 JAVA部分 1、 QUESTION NO: 1 public class Test { public static void changeStr(String str){ str=\"welcome\"; } public static void main(String[] args) { String str=\"1234\"; changeStr(str); System.out.println(str); } } Please write the output result ：[    ] 2、 QUESTION NO:2 public class Test { static boolean foo(char c) { System.out.print(c); return true; } public static void main( String[] argv ) { int i =0; for ( foo('A'); foo('B')&&(i<2); foo('C')){ i++ ; foo('D');   }     }   }   What is the result?    [       ] A. ABDCBDCB B. ABCDABCD C. Compilation fails. D. An exception is thrown at runtime. 3、 QUESTION NO: 3 public class Outer{ public void someOuterMethod() { // Line 3 } public class Inner{} public static void main( String[]argv ) { Outer o = new Outer(); // Line 8 } } Which instantiates an instance of Inner?   [    ] A. new Inner(); // At line 3 B. new Inner(); // At line 8 C. new o.Inner(); // At line 8 D. new Outer.Inner(); // At line 8//new Outer().new Inner() 4、 QUESTION NO: 4 Which method is used by a servlet to place its session ID in a URL that is written to the servlet’s response output stream?  [      ] A. The encodeURL method of the HttpServletRequest interface. B. The encodeURL method of the HttpServletResponse interface. C. The rewriteURL method of the HttpServletRequest interface. D. The rewriteURL method of the HttpServletResponse interface. 5、 QUESTION NO: 5    Which two are equivalent? (Choose two)  [    ] A. <%= YoshiBean.size%> B. <%= YoshiBean.getSize()%> C. <%= YoshiBean.getProperty(\"size\")%> D. <jsp:getProperty id=\"YoshiBean\" param=\"size\"/> E. <jsp:getProperty name=\"YoshiBean\" param=\"size\"/> F. <jsp:getProperty id=\"YoshiBean\" property=\"size\"/> G. <jsp:getProperty name=\"YoshiBean\" property=\"size\"/> 6、 并发中，设置当前线程后台运行的方法是（  ） A．setBackground(Object) B．setDaemon(true) C．isBackground(Object) D．isDaemon(true)   7、 假定变量x=8的类型是int(它可以存放着负值),则哪些方式能正确地使x的值翻倍,请选出4个正确的答案。（     ） A．x<<1; B．x=x*2; C．x*=2; D．x+=x; E．x<<=1; 8、 下面的包装类中，有两个不是由Number派生的，而直接扩展了Object类，请选出。（     ） A．Boolean B．Byte  C．Character D．Short F．Integer G．Double 9、 以下哪个不是CSS的选择符？ （ ） A.对象选择符 B.类选择符 C.ID选择符 D.包含选择符 10、 下列哪些集合实现是线程安全的？请选出2个正确的答案。（    ） A．ArrayList B．HashTable C．Vector D．HashMap E．LinkedList 11、 Overload和Override的区别，Overloaded的方法是否可以改变返回值的类型?     (答案写在背面，标明题号) 12、 abstract class和interface有什么区别?   (答案写在背面，标明题号) 13、 请列举几个你熟悉的设计模式，并简单描述你的理解。      (答案写在背面，标明题号) 14、 面向对象编程语言有哪几个主要特性？并简单说明你对每个特性的理解       (答案写在背面，标明题号) 15、 请用冒泡排序实现一个对一列数字的排序:   {2,10,3,50,78,22,34,30,65}数字是动态输入的.请以类的形式实现.       (答案写在背面，标明题号) 二、 数据库部分 1. 在数据库中有一名为my_addr的表，其中包含一名为addr_name的列,其列属性为varchar(40), 请问如何统计此表addr_name列中以'CQ'开头的记录数： 答案：select count(*) from my_addr where addr_name like 'CQ%' 2. 在数据库中名为my_salary的表，执行select * from my_salary之后输入内容如下： NAME       　　SAL        ---------- 　　　　　---------- a                6.23 b                6.23 c                6.23 -                6.23 -                6.23 -                6.23 请问执行select count(name) from my_salary之后输出的结果为多少： A. ３ B. ６ C. 输出结果为空 D. 以上答案都不对 答案： 3. 通过数据库客户端查询程序向数据库系统正确提交了一个将执行很长时间的查询语句之后，客户端查询程序异常关闭，则在数据库系统中正在执行的这个语句将 A． 被数据库管理系统强行中止执行。 B． 继续执行、直到结束。 C． 执行一段时间后，自行退出。 D． 以上答案都不对 答案： 4. 以下选项中全部属于事务控制的语句是： A. Select、update、create index、Begin Tran B. Begin、Continue、delete C. Rollback、commit D. 以上答案都不对 答案： 5. 数据库索引是在基本表的列上建立的一种数据库对象，它同基本表分开存储，使用它的主要目的是： A． 增加数据插入速度 B． 增加数据删除速度 C． 提高数据查询速度 D． 保证数据唯一性 E． 增加数据安全性 答案： 6. 若数据库事务T对数据对象A加上X锁，则以下描述哪个正确？  A. 只允许T修改A，其它任何事务都不能再对A加任何类型的锁。 B. 只允许T读取A，其它任何事务都不能再对A加任何类型的锁。  C. 只允许T读取和修改A，其它任何事务都不能再对A加任何类型的锁。 D. 只允许T修改A，其它任何事务都不能再对A加X锁。 答案： 7. 在DB2 UDB数据库中,为了加快完成表对表大批量数据插入操作,可以采用的方法: A. 先删除被插入表上的优化查询索引再批量插入数据. B. 在特定情况下,可以关闭被插入表的日志再进行批量插入操作. C. 在特定情况下,可以将被插入表的锁定粒度指定为表级锁再批量插入数据. D. 以上答案均不正确. 答案: 8. 在DB2 UDB分区数据库中分区表DW_CUST_MM的列serv_id 为主键,其属性为decimal(9,0),另一张分区表DW_SERV_MM的serv_id为唯一索引,两张表的记录数均接近1亿条,针对以下SQL语句,请从SQL优化的角度选择DW_SERV_MM表比较合理的建表语句.    Select count(*),a.MKT_COMM_AREA_ID from DW_SERV_MM a left join DW_CUST_MM b on a.serv_id=b.serv_id group by a.mkt_comm_area_id A.  CREATE TABLE DW_SERV_MM     (      SERV_ID DECIMAL(9,0) ,       MKT_COMM_AREA_ID DECIMAL(9,0) ,       EXCHANGE_ID DECIMAL(9,0)    )    PARTITIONING KEY (MKT_COMM_AREA_ID)  USING HASHING   IN TBS_ODS_01 B. CREATE TABLE DW_SERV_MM     (      SERV_ID DECIMAL(9,0) ,       MKT_COMM_AREA_ID DECIMAL(9,0) ,       EXCHANGE_ID DECIMAL(9,0)    )    PARTITIONING KEY (SERV_ID)  USING HASHING   IN TBS_ODS_01 C. CREATE TABLE DW_SERV_MM     (      MKT_COMM_AREA_ID DECIMAL(9,0) ,       SERV_ID DECIMAL(9,0) ,       EXCHANGE_ID DECIMAL(9,0)    )    IN TBS_ODS_01 D.以上答案都正确 答案: 9. 在关系数据库中出于性能考虑一般都是避免使用IN子名的,请写出使用EXISTS对以下SQL语句进行适当优化后的语句: 　　SELECT *  　　FROM EMP  　　WHERE EMPNO > 0 　　AND DEPTNO IN (SELECT DEPTNO  　　FROM DEPT  　　WHERE LOC = ‘MELB’) 　　答案: 10. 请简单说明ORACLE绑定变量是什么?绑定变量有什么优缺点? 答案:  11. 什么是事务 (transaction) ？ 答案:      1、你认为jsp servlet 开发与框架开发有什么不同 ? 2、写几个 request session 中得常用方法，简单说明功能。 3、写几个常用得jstl的核心标签，并简单说明功能。 4、写几个常用得javascript方法，并简单说明功能。 5、用你的理解描述一下hibernate？   它解决了什么问题？ 它有什么优点缺点？ 6、描述一下mvc，结合一个实际的 mvc框架是如何实现的（struts 1 2 springmvc  webwork） 7、spring 与hibernate整合后带来哪些好处？ 8、简述一下openSessionInView得原理，以及优缺点。 9、写几个 你用过得 annotation （@ ），并简单描述一下他们的作用。 10、平时用什么IDE （比如 eclipse netbeans），使用哪些快捷键？ 11、平时开发中使用哪些辅助工具？ 12、你平时都去哪些技术论坛，方便的话留下 用户名（id ，登录名称）。 13、软件业最近发生了那些事？请根据你心目中的大小排序列出。 机试部分 使用框架编写一个简单功能，要求必须使用spring和hibernate，配置方式使用annotation或xml，应用annotation配置附加10分。 mvc框架可选择: Struts1 Struts2 SpringMVC3(有高附加分) 功能要求： 1. 用户登录   2. 用户注册   3. 用户修改密码   4. 用户查询   5. 用户删除 界面效果可参照图示（以功能作为主要评分标准），要求如下： 1. 用户输入用户名及密码登录，登录后跳转至用户列表页面。  2. 未注册用户需要进行注册，注册后直接跳转至用户列表页面。 3. 用户列表页面中包含修改密码、用户查询及用户删除功能。","title":"各种面试题"},{"content":"功能：Oracle数据导入导出imp/exp就相当与oracle数据还原与备份。 大多情况都可以用Oracle数据导入导出完成数据的备份和还原（不会造成数据的丢失）。 Oracle有个好处，虽然你的电脑不是服务器，但是你装了oracle客户端，并建立了连接 （通过net8 assistant中本地-->服务命名 添加正确的服务命名 其实你可以想成是客户端与服务器端修了条路，然后数据就可以被拉过来了） 这样你可以把数据导出到本地，虽然可能服务器离你很远。 你同样可以把dmp文件从本地导入到远处的数据库服务器中。 利用这个功能你可以构建俩个相同的数据库，一个用来测试，一个用来正式使用。 执行环境：可以在SQLPLUS.EXE或者DOS（命令行）中执行， DOS中可以执行时由于 在oracle 8i 中 安装目录\\ora81\\BIN被设置为全局路径， 该目录下有EXP.EXE与IMP.EXE文件被用来执行导入导出。 oracle用java编写，我想SQLPLUS.EXE、EXP.EXE、IMP.EXE这俩个文件是被包装后的类文件。 SQLPLUS.EXE调用EXP.EXE、IMP.EXE他们所包裹的类，完成导入导出功能。 下面介绍的是导入导出的实例，向导入导出看实例基本上就可以完成，因为导入导出很简单。 数据导出： 1 将数据库TEST完全导出,用户名system 密码manager 导出到D:\\daochu.dmp中 exp system/manager@TEST file=d:\\daochu.dmp full=y 2 将数据库中system用户与sys用户的表导出 exp system/manager@TEST file=d:\\daochu.dmp owner=(system,sys) 3 将数据库中的表table1 、table2导出 exp system/manager@TEST file=d:\\daochu.dmp tables=(table1,table2) 4 将数据库中的表table1中的字段filed1以\"00\"打头的数据导出 exp system/manager@TEST file=d:\\daochu.dmp tables=(table1) query=\\\" where filed1 like '00%'\\\" 上面是常用的导出，对于压缩我不太在意，用winzip把dmp文件可以很好的压缩。 不过在上面命令后面 加上 compress=y 就可以了 数据的导入 1 将D:\\daochu.dmp 中的数据导入 TEST数据库中。 imp system/manager@TEST file=d:\\daochu.dmp 上面可能有点问题，因为有的表已经存在，然后它就报错，对该表就不进行导入。 在后面加上 ignore=y 就可以了。 2 将d:\\daochu.dmp中的表table1 导入 imp system/manager@TEST file=d:\\daochu.dmp tables=(table1) 基本上上面的导入导出够用了。 你用什么管理Oracle数据库，我用的是plsql，这个软件可以连接Oracle数据库，然后找到相应的表，export就可以了 10以上可以选择多个表，很简单，很方便。","title":"Oracle数据库如何导出表?"},{"content":"Oracle练习题              姓名: __________     分数: _______ 1. 构造SQL语句，列出在1981年入职的员工的姓名、入职时间和月收入(薪水和奖金之和)，并将入职时间显示为:”1981年10月10日”这种形式，月收入显示为”$12,345.67”这种形式。 select to_char(hiredate, 'yyyy') ename, to_char(hiredate, 'yyyy') || '年' || to_char(hiredate, 'mm') || '月' ||        to_char(hiredate, 'dd') || '日',        to_char(sal + nvl(comm, 0), '$9,999,999.99')   from emp  where to_char(hiredate, 'yyyy') = '1982' 2. 列出职员表中员工的姓名、薪水、所属部门名称和薪水等级，并按照薪水由高到低排序。 select ename, sal, dname, grade   from emp a, dept b, salgrade c  where a.deptno = b.deptno    and c.losal < a.sal    and c.hisal > a.sal    order by 2; 3. 列出每个员工的名字(别名为EMPLOYEE)及他们的直接领导的名字(别名为MANAGER)，如果某些员工没有领导，则在其领导的位置上显示“boss”。 select ename, nvl((select ename from emp b where a.mgr = b.empno), 'BOSS')   from emp a; 4. 查询哪些职位的薪水总和大于5000元，列出这些职位和其薪水总和，并按薪水总和升值排序。   select job, sum(sal)   from emp a  group by a.job having sum(sal) > 5000  order by sum(sal) 5. 查询哪个部门的平均薪水比20部门的平均薪水低，列出这些部门的编号和平均薪水值。 select deptno, avg(sal)   from emp a  group by a.deptno having avg(sal) < (select avg(sal)                      from emp a                     group by a.deptno                    having deptno = '20'); 6. 查询机构中薪水最低的五名员工，列出员工姓名和薪水值。 select *  from (select ename, sal from emp order by sal)  where rownum < 6 7. 按薪水从高到低排序，列出第5位到第8位员工的姓名、薪水和职位。 select e.*   from (select rownum rn, ename, sal           from (select * from emp order by sal desc)          where rownum < 9) e  where e.rn > 4 8. 列出部门名称和该部门的员工信息，同时列出那些没有员工的部门。 9. 列出最低薪金大于1500的各种工作。 select distinct job from emp where sal > 1500; 10. 查询出薪水比本部门平均薪水高的员工信息。 select *   from emp a  where sal > (select avg(sal)                 from emp b                group by deptno               having a.deptno = b.deptno) 11. 列出所有管理者的最低薪金。 select min(sal)   from (select * from emp where empno in (select mgr from emp))","title":"Oracle练习题"},{"content":"SQL> select table_name from user_tables; TABLE_NAME                                                                       ------------------------------                                                   BONUS                                                                            DEPT                                                                             EMP                                                                              SALGRADE                                                                         TEMP                                                                             SQL> set pagesize 99 SQL> desc emp  名称                                      是否为空? 类型  ----------------------------------------- -------- ----------------------------  EMPNO                                     NOT NULL NUMBER(4)  ENAME                                              VARCHAR2(10)  JOB                                                VARCHAR2(9)  MGR                                                NUMBER(4)  HIREDATE                                           DATE  SAL                                                NUMBER(7,2)  COMM                                               NUMBER(7,2)  DEPTNO                                             NUMBER(2) SQL> select * from emp;      EMPNO ENAME      JOB              MGR HIREDATE          SAL       COMM      ---------- ---------- --------- ---------- ---------- ---------- ----------          DEPTNO                                                                       ----------                                                                             7369 SMITH      CLERK           7902 17-12月-80        800                         20                                                                                                                                                              7499 ALLEN      SALESMAN        7698 20-2月 -81       1600        300              30                                                                                                                                                              7521 WARD       SALESMAN        7698 22-2月 -81       1250        500              30                                                                                                                                                              7566 JONES      MANAGER         7839 02-4月 -81       2975                         20                                                                                                                                                              7654 MARTIN     SALESMAN        7698 28-9月 -81       1250       1400              30                                                                                                                                                              7698 BLAKE      MANAGER         7839 01-5月 -81       2850                         30                                                                                                                                                              7782 CLARK      MANAGER         7839 09-6月 -81       2450                         10                                                                                                                                                              7788 SCOTT      ANALYST         7566 19-4月 -87       3000                         20                                                                                                                                                              7839 KING       PRESIDENT            17-11月-81       5000                         10                                                                                                                                                              7844 TURNER     SALESMAN        7698 08-9月 -81       1500          0              30                                                                                                                                                              7876 ADAMS      CLERK           7788 23-5月 -87       1100                         20                                                                                                                                                              7900 JAMES      CLERK           7698 03-12月-81        950                         30                                                                                                                                                              7902 FORD       ANALYST         7566 03-12月-81       3000                         20                                                                                                                                                              7934 MILLER     CLERK           7782 23-1月 -82       1300                         10                                                                                                                                                        已选择14行。 SQL> desc dept  名称                                      是否为空? 类型  ----------------------------------------- -------- ----------------------------  DEPTNO                                    NOT NULL NUMBER(2)  DNAME                                              VARCHAR2(14)  LOC                                                VARCHAR2(13) SQL> select * from dept;     DEPTNO DNAME          LOC                                                    ---------- -------------- -------------                                                  10 ACCOUNTING     NEW YORK                                                       20 RESEARCH       DALLAS                                                         30 SALES          CHICAGO                                                        40 OPERATIONS     BOSTON                                                 SQL> desc salgrade  名称                                      是否为空? 类型  ----------------------------------------- -------- ----------------------------  GRADE                                              NUMBER  LOSAL                                              NUMBER  HISAL                                              NUMBER SQL> select * from salgrade;      GRADE      LOSAL      HISAL                                                 ---------- ---------- ----------                                                          1        700       1200                                                          2       1201       1400                                                          3       1401       2000                                                          4       2001       3000                                                          5       3001       9999                                                 SQL> spool off","title":"Oracle笔记_Oracle9i_Scott用户下样例表"},{"content":"SQL> create table temp (id number(10) primary key, name varchar2(10), tel varchar2(13), address varchar2(30)); 表已创建。 SQL> create sequence temp_id_seq increment by 1 start with 1 nocache; 序列已创建。 SQL> insert into temp values (temp_id_seq.nextval, '&name', '&tel', '&address'); 输入 name 的值:  ZhangSan 输入 tel 的值:  15999998888 输入 address 的值:  LiaoNingProvinceShenYangCity 原值    1: insert into temp values (temp_id_seq.nextval, '&name', '&tel', '&address') 新值    1: insert into temp values (temp_id_seq.nextval, 'ZhangSan', '15999998888', 'LiaoNingProvinceShenYangCity') 已创建 1 行。 SQL> / 输入 name 的值:  LiSi 输入 tel 的值:  13358861111 输入 address 的值:  TaiWan 原值    1: insert into temp values (temp_id_seq.nextval, '&name', '&tel', '&address') 新值    1: insert into temp values (temp_id_seq.nextval, 'LiSi', '13358861111', 'TaiWan') 已创建 1 行。 SQL> / 输入 name 的值:  Sara 输入 tel 的值:  13399998888 输入 address 的值:  England 原值    1: insert into temp values (temp_id_seq.nextval, '&name', '&tel', '&address') 新值    1: insert into temp values (temp_id_seq.nextval, 'Sara', '13399998888', 'England') 已创建 1 行。 SQL> select * from temp;         ID NAME       TEL           ADDRESS                                      ---------- ---------- ------------- ------------------------------                        1 ZhangSan   15999998888   LiaoNingProvinceShenYangCity                          2 LiSi       13358861111   TaiWan                                                3 Sara       13399998888   England                                      SQL> update temp set name='WangWu', tel='11122223333', address='NewYork' where id = 1; 已更新 1 行。 SQL> select * from temp;         ID NAME       TEL           ADDRESS                                      ---------- ---------- ------------- ------------------------------                        1 WangWu     11122223333   NewYork                                               2 LiSi       13358861111   TaiWan                                                3 Sara       13399998888   England                                      SQL> delete from temp where id = 1; 已删除 1 行。 SQL> select * from temp;         ID NAME       TEL           ADDRESS                                      ---------- ---------- ------------- ------------------------------                        2 LiSi       13358861111   TaiWan                                                3 Sara       13399998888   England                                      SQL> spool off","title":"Oracle笔记_CURD"},{"content":"CREATE SEQUENCE sequencename [INCREMENT BY n] [START WITH s] [MAXVALUE x | NOMAXVALUE] [MINVALUE m | NOMINVALUE] [CYCLE | NOCYCLE] [CACHE c | NOCACHE] [ORDER | NOORDER]; 1、INCREMENT BY n     所产生编号的增量值是n。默认情况下值为1； 2、START WITH s           此序列的起始值是s。默认情况下值为1； 3、MAXVALUE x               产生编号的最大值是x； 4、NOMAXVALUE            序列不停地产生编号，如果采用升序则一直到产生了允许的最大值10的27次幂。如果是降序则序列的NOMAXVALUE是-1； 5、MINVALUE m              产生的最小编号值是m； 6、NOMINVALUE            如果采用升序，则序列的最小值是1；如果是降序，则序列的最小值是-10的26次幂； 7、CYCLE                        到达最大值或最小值之后，序列继续产生编号； 8、NOCYCLE                  到达最大值或最小值之后，序列不再继续产生数字； 9、CACHE c                    Oracle服务器提前产生编号，并把它们存储在高速缓冲存储器区中，以便提高系统性能。c的默认值是20.如果用户提供一个数字，那么服务器将在高   速缓冲存储器中存储这么多的编号； 10、NOCACHE               服务器不提前在内存中存储任何序号； 11、ORDER                     按时间先后顺序产生编号； 12、NOORDER              不按时间先后顺序产生编号；","title":"Oracle笔记_序列"},{"content":"分组函数                                                             用法 SUM(column)                                                    返回一列中所有值的总合，忽略空值 AVG(column)                                                     返回一列中所有值的平均值，忽略空值 MAX(column | expr)                                          返回最大值，忽略空值 MIN(column | expr)                                           返回最小值，忽略空值 COUNT(* | column | expr)                               计算行数，如果用*，则包括空值；如果用列或表达式作为参数，则计算非空值 SELECT column, groupfunction(column) FROM tablename [WHERE condition(s)] [GROUP BY column | expr] [ORDER BY column | expr [ASC | DESC]]; 注： 1、当查询中包含一个分组函数和GROUP BY子句时，SELECT中出现的单个列也必须出现在GROUP BY子句中，因为GROUP BY返回的是一个值，而SELECT查询的单个列可能包含多个值； 2、分组之前仍然可以使用WHERE子句来限制数据； 3、WHERE子句不能用来限制组； 4、列别名不能用在GROUP BY子句中； 5、GROUP BY列不一定必须出现在SELECT查询中； 6、当一列被用在GROUP BY子句中时，默认情况下，其结果是按照这一列的升序来排列。换句话说，GROUP BY具有隐式的ORDER BY，但我们仍然可以使用ORDER BY子句显示地更改隐含的排列顺序； 7、在Oracle9i中，在SELECT查询中WHERE子句和GROUP BY子句的顺序是无关紧要的，但在以前的版本中，WHERE子句必须写在GROUP BY子句的前面。 HAVING子句：用来对分组进行限制 select avg(sal) 平均薪水 from emp group by deptno having deptno > 10;","title":"Oracle笔记_分组函数"},{"content":"http://hi.baidu.com/linuxtrip/item/c81dec25996c7b0176272cd3 Oracle 分析函数（10G）   一、Oracle分析函数简介 1、分析函数，最早是从ORACLE8.1.6开始出现的，它的设计目的是为了解决诸如“累计计算”，“找出分组内百分比”，“前-N条查询”，“移动平均数计算”\"等问题。其实大部分的问题都可以用PL/SQL解决，但是它的性能并不能达到你所期望的效果。分析函数是SQL言语的一种扩充，它并不是仅仅试代码变得更简单而已，它的速度比纯粹的SQL或者PL/SQL更快。现在这些扩展已经被纳入了美国国家标准化组织SQL委员会的SQL规范说明书中。 2、在日常的生产环境中，我们接触得比较多的是OLTP系统(即OnlineTransaction Process），这些系统的特点是具备实时要求，或者至少说对响应的时间多长有一定的要求；其次这些系统的业务逻辑一般比较复杂，可能需要经过多次的运算。比如我们经常接触到的电子商城。 在这些系统之外，还有一种称之为OLAP的系统(即Online Aanalyse Process），这些系统一般用于系统决策使用。通常和数据仓库、数据分析、数据挖掘等概念联系在一起。这些系统的特点是数据量大，对实时响应的要求不高或者根本不关注这方面的要求，以查询、统计操作为主。 Oracle分析函数，主要用于OLAP的系统中 二、Oracle分析函数原理 1、分析函数通过将行分组后，再计算这些分组的值。它们与聚集函数不同之处在于能够对每一个分组返回多行值。分析函数根据analytic claues(分析子句）将行分组，一个分组称为：一个窗口（可通过Windowsing Clause子句进行控制），并通过分析语句定义，对于每一行都对应有一个在行上滑动的窗口。该窗口确定当前行的计算范围。窗口大小可以用多个物理行（例如：rowid实际编号）进行度量，也可以使用逻辑区间进行度量，比如时间。 2、分析函数是查询中除需要在最终处理的order by 子句之外最后执行的操作。所有连接、WHERE、GROUP BY、HAVING子句都是分析函数处理之前完成的。因此，分析函数只出现在SELECT LIST或ORDER BY（按…排序）语句中，而不能出现在where或having子句中 3、分析函数通常用于计算：数据累积值、数据移动值、数据中间值，和输出集合报表。 三、Oracle分析函数的语法 Analytic-Function（<Argument>，<Argument>，…）  over（        <Query-Partition-Clause>        <Order-by-Clause>        <Windowing-Clause> ） 例如：sum（sal） over（partition by deptno order by ename）new_alias 1）sum：就是函数名 2）（sal）： 是分析函数的参数，每个函数有0~3个参数，参数可以是表达式，例如：sum(sal+comm） 3）over：是一个关键字，用于标识分析函数，否则查询分析器不能区别sum(）聚集函数和sum(）分析函数 4）partition by deptno：是可选的分区子句，如果不存在任何分区子句，则全部的结果集可看作一个单一的大区 5）order by ename：是可选的order by 子句，有些函数需要它，有些则不需要。依靠已排序数据的那些函数，例如：用于访问结果集中前一行和后一行的LAG和LEAD，它们就必须使用；其它函数，例如：AVG，则不需要用到order by 子句。在使用了任何排序的开窗函数时，该子句是强制性的，它指定了在计算分析函数时一组内的数据是如何排序的.（即：如果要使用Windowing-Clause子句，那么一定要先使用Order by 子句） 1、Analytic-Function ORACLE提供了28个分析函数（包括如下： AVG *，CORR *，COVAR_POP *，COVAR_SAMP *，COUNT*，CUME_DIST，DENSE_RANK，FIRST，FIRST_VALUE *，LAG，LAST，LAST_VALUE *，LEAD，MAX *， MIN *，NTILE，PERCENT_RANK，PERCENTILE_CONT，PERCENTILE_DISC，RANK，RATIO_TO_REPORT，REGR_(Linear Regression) Functions *，ROW_NUMBER，STDDEV *，STDDEV_POP *，STDDEV_SAMP*，SUM *，VAR_POP *，VAR_SAMP*，VARIANCE），按功能分5类 1）分析函数分类 （1）等级(ranking）函数：用于寻找前N种查询，如：RANK、DENSE_RANK等 （2）开窗(windowing）函数：用于计算不同的累计，如：SUM，COUNT，AVG，MIN，MAX等，作用于数据的一个窗口上 例如：如下函数 sum(t.sal） over (order by t.deptno，t.ename） running_total， sum(t.sal） over (partition by t.deptno order by t.ename） department_total （3）制表(reporting）函数：与开窗函数同名，作用于一个分区或一组上的所有列 例如：如下函数 sum(t.sal） over (） running_total2， sum(t.sal） over (partition by t.deptno ） department_total2 说明：制表函数与开窗函数的关键不同之处：在于OVER语句上缺少一个ORDER BY子句 （4）LAG，LEAD函数：这类函数允许在结果集中向前或向后检索值，为了避免数据的自连接，它们是非常用用的. （5）VAR_POP，VAR_SAMP，STDEV_POPE及线性的衰减函数：计算任何未排序分区的统计值 2） 分析函数函数，及返回值 分析函数可取0-3个参数。参数可以是任何数字类型或是可以隐式转换为数字类型的数据类型。Oracle根据最高数字优先级别确定函数参数，并且隐式地将需要处理的参数转换为数字类型。函数的返回类型也为数字类型，除非此函数另有说明。 2、Analytic_Clause [ query_partition_clause ] [ order_by_clause [ windows_clause ] ] 1）Over Analytic clause用以指明函数操作的是一个查询结果集。也就是说分析函数是在from，where，group by，和having子句之后才开始进行计算的。因此在选择列或order by子句中可以使用分析函数。为了过滤分析函数计算的查询结果，可以将它作为子查询嵌套在外部查询中，然后在外部查询中过滤其查询结果。 2）使用Analytic_Clause子名时，注意如下 （1）Analytic clause中不能包含其他任何分析函数。也就是说，分析函数不能嵌套。然而可以在一个子查询中应用分析函数，并且通过它计算另外的分析函数。 （2）用户自定义分析函数和内置函数分析函数，都可以使用OverAnalytic_Clause。 3、PARTITION子句 partition by { value_expr [，value_expr ]… | （value_expr [，value_expr ] …）}   说明：按照表达式分区(就是分组），如果省略了分区子句，则全部的结果集被看作是一个单一的组 1）Partition by子句根据一个或多个valueexpr将查询结果集分成若干组。若不使用该子句，那么函数将查询结果集的所有行当作一个组。 2）在分析函数中使用query_partition_clause，应该使用语法图中上分支中的语法(不带圆括号）。model查询(位于model column clauses中）或被分隔的外部连接（位于outer_join_clause中）中使用该子句，应该使用语法图中下分支中的语法（带有圆括号）。 3) 在同一个查询中可以使用多个分析函数，它们可以有相同或不同的partition by键值 4) 若被查询的对象具有并行特性，并且分析函数中包含query_partition_clause，那么函数的计算也是并行的。 5) value expr的有效值：包括常量，表列，非分析函数，函数表达式，或者前面这些元素的任意组合表达式。 4、ORDER BY子句 分析函数中ORDER BY的存在将添加一个默认的开窗子句（默认窗口为：RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW），这意味着计算中所使用的行的集合是当前分区中当前行和前面所有行，没有ORDER BY时，默认的窗口是全部的分区 在Order by 子句后可以添加nulls last，如：order by comm desc nullslast   表示排序时忽略comm列为空的行.  1）Order_by_clause用以指定分组中数据的排序形式。除了percentile_cont和percentile_disc之外（它们只能取唯一的键值）外的分析函数，分组中可以使用多个键值对值进行排序，每个键值在value expr中定义，并且被排序序列限定。 2）每个函数内可以指定多个排序表达式。当使用函数给值排名时，尤其显得意义非凡，因为第二个表达式能够解决按照第一个表达式排序后仍然存在相同排名的问题。 3）只要使用order_by_clause后，仍存在值相同的行，则每一行都会返回相同的结果。 4）使用Ordery_by_clause子句的限制：  （1）分析函数中的order_by_clause必须是一个表达式(expr)。Sibling关键字在此处是非法的(它仅仅与层次查询有关)。位置(position)和列别名(c_alias)也是非法的。除此之外，order_by_clause的用法与整个查询或者子查询中的相同。 （2）当分析函数使用range关键字限定窗口时，若使用的窗口是下列两个窗口之一，那么可以在分析函数的order_by_clause中使用多个排序健值。 ① range between UNBOUNDEDPRECEDING and CURRENT ROW  <=>  range UNBOUNDED PRECEDING ② range between CURRENT ROWand UNBOUNDED FOLLOWING  <=> range UNBOUNDED FOLLOWING 注意： 若窗口范围由range关键字指定的分析函数中指定的不是这两个窗口范围（即：range unbounded preceding与range unboundedfollowing），那么order_by子句中仅能使用一个排序键值。 （3）若分析函数的窗口范围由row关键字指定，order_by子句中排序键值的使用没有这个限制。 5）asc | desc：指定排序顺序(升序或降序)，asc是默认值。 6）nulls first | nulls last：指定返回行包含空值，该值应该出现在排序序列的开始还是末尾。 7）升序排序的默认值为：nulls last，降序排序的默认值为：nulls first。 8）分析函数总是按order_by_clause对行排序。然而，分析函数中的order_by_clause只对各个分组进行排序，而不能保证查询结果有序。要保证最后的查询结果有序，可以使用查询的order_by_clause。 5、WINDOWING子句 1）有些分析函数允许使用windowing clause。在上述的分析函数列表中，带有星号(*)的函数都允许使用windowing_clause。 2）用于定义分析函数将在其上操作的行的集合，Windowing子句给出了一个定义变化或固定的数据窗口的方法，分析函数将对这些数据进行操作默认的窗口是一个固定的窗口，仅仅在一组的第一行开始，一直继续到当前行（即：range unbounded preceding），要使用窗口，必须使用ORDER BY子句。 3）row | range：这些关键字为每一行定义一个窗口，该窗口用于计算函数结果（物理或者逻辑的行的集合）。然后对窗口中的每一行应用分析函数。窗口在查询结果集或者分组中从上至下移动。 4）根据2个标准可以建立窗口：数据值的范围（逻辑偏移量--range）或与当前行的行偏移量（物理单位--rows）。 5）只有指定order_by_clause后才能指定windowing_clause。有些range子句定义的窗口范围只能在order_by_clause中指定一个排序表达式。 6）一个带逻辑偏移量的分析函数的返回值总是确定的。然而，除非排序表达式能产生唯一的排序，否则带有物理偏移量的分析函数的返回值可能会产生不确定的结果。为了解决此问题，你可能不得不在order by clause中指定多个列以获得唯一的排序。 （1）between…and：用来指定窗口的起点和终点。第一个表达式(位于and之前)定义起点，第二个表达式(位于and之后)定义终点。若不使用between而仅指定一个终点，那么oracle认为它是起点，终点默一认为当前行。 （2）unbounded preceding：指明窗口开始于分组的第一行。它只用于指定起点而不能用于指定终点 （3）unbounded following：指明窗口结束于分组的最后一行。它只用于指定终点而不能用于指定起点 （4）current row： ① 用作起点：指定窗口开始于当前行或者当前值（依赖于是否分别指定row或者range）。在这种情况下终点不能为value_expre preceding。 ② 用作终点：指定窗口结束于当前行或者当前值（依赖于是否分别指定row或者range）。在这种情况下起点不能为value_expr following。 7）range或者row中的value_expr preceding或者value_expr following： （1）若value_expr  FOLLOWING是起点，那么终点必须为：value_exprFOLLOWING。 （2）若value_expr  PRECEDING是终点，那么起点必须是：value_exprPRECEDING。 （3）若要定义一个数字格式的时间间隔的逻辑窗口，那么可能需要用到转换函数（numtoyminterval与numtodsinterval） 8）若windowing_clause由range指定： （1）value_expr是一个逻辑偏移量。它必须是常量，或者值为正数值的表达式，或者时间间隔文字常量。 （2）只能在order_by_clause中指定一个表达式。 （3）若value_expr求值为一个数字值，那么order_by_expr必须为数字或者date类型。 （4）若value_expr求值为一个间隔值，那么order_by_expr必须是一个date类型。 （5）若完全忽略windowing_clause，那么默认值为: range between unbounded preceding and current row。 注意：range 5 preceding：将产生一个滑动窗口，它在组中拥有当前行以及前5行的集合； RANGE窗口仅对NUMBERS和DATES起作用，因为不可能从VARCHAR2中增加或减去N个单元，另外的限制是ORDER BY中只能有一列，因而范围实际上是一维的，不能在N维空间中 例：avg（t.sal） over（order by t.hiredate asc range 100preceding） 统计前100天平均工资 8）若windowing_clause由rows指定： （1）value_expr是一个物理偏移量，它必须是一个常量或者表达式，并且表达式的值必须是正数值 （2）若value_expr是起点的一部分，那么它必须在终点之前对行求值。 （3）利用ROW分区，就没有RANGE分区那样的限制了，数据可以是任何类型，且ORDER BY 可以包括很多列 9）常用的Specifying窗口 （1）UNBOUNDED PRECEDING：这个窗口从当前分区的每一行开始，并结束于正在处理的当前行 （2）CURRENT ROW：该窗口从当前行开始（并结束） （3）Numeric Expression PRECEDING：对该窗口从当前行之前的数字表达式（Numeric Expression）的行开始，对RANGE来说，从从行序值小于数字表达式的当前行的值开始. （4）Numeric Expression FOLLOWING：该窗口在当前行Numeric Expression行之后的行终止（或开始），且从行序值大于当前行NumericExpression行的范围开始（或终止） 例如：range between 100 preceding and 100 following：当前行100前，当前后100后 注意：分析函数允许你对一个数据集进排序和筛选，这是SQL从来不能实现的.除了最后的Order by子句之外，分析函数是在查询中执行的最后的操作集，这样的话，就不能直接在谓词中使用分析函数，即不能在上面使用where或having子句!!","title":"Oracle 分析函数（10G）语法详解"},{"content":"一 ，TO_CHAR(NUMBER)       1.1 格式图和简单说明              本函数把参数N转为一个VARCHAR2类型的数值。N可以是NUMBER,BINARY_FLOAT,或者BINARY_DOUBLE。如果不带格式，那么函数会把N转换为足以表示N的VARCHAR2字符串。       格式表参考：       序号 格式 简例 说明 1 ,(逗号) '9999,999' 逗号,一般以千分位出现,作为分组符号使用.如果需要您也可以当作是十分位,百分位出现,可以出现N次,视乎数字的大小而定. 变态的例子是 to_char(1234,'9,9,9,9'). 注意事项:只能出现在整数部分. 2 .(点号) '99.99' 点号,不要念为\"句号\",句号是个圆圈,点好只能出现在小数点对应的地方.只能出现一次. to_char(1234.34,'9,9,9,9.99') 注意事项:只能出现在一个地方,就是原来数据小数点位置 3 $(美元符号) '$999.99' 美元.其实你可以放在任意地方(在10G下) to_char(1234.34,'9,9,9,9.$99') 注意事项:只能出现一次. 4 0(零) '0999.99' 零.在对应位置返回对应的字符,如果没有则以'0'填充. to_char(0.34,'9,9,9,0.$99')='$0.34';to_char(1234,'9999.00')='1234.00'; 注意事项:这是一个强制的符号,对应位没有,则以'o'填充,这是9很大不同地方 5 9 '999.99' 9.在小数位,则表示转换为对应字符,如果没有则以0表示;在整数位,没有对应则不填充字符. to_char(123,'999.99')=123.00; TO_CHAR(123,'99999.9')=123.0; 注意事项:对于0和9而言,如果格式的位数不如数字的位数多,会返回'#'. 譬如to_char(12345,'9999')='#####' 6 B(空格符) 'B999' 没有其它特别作用,在整数部分最前面加一个空格,可以出现在任意位置. 'S'||TO_CHAR(1234,'99B99')='S 1234'; 注意事项:只能出现在整数部位. 7 C(国际货币符号) 'C9999' 在特定的位置返回一个ISO货币符号(就是NLS_ISO_CURRENCY参数所代表的值) TO_CHAR(1233,'C9999')='CNY1234' ,这是新的国际标准RMB,关于这个可查询\"国际货币符号\" 注意事项:只能出现在整数部位第一位. 可以通过alter session set NLS_ISO_CURRENCY='JAPAN';来修改当前会话的设置. 8 D(ISO 小数位符号) '999D99' 这是\"点号\"的国际版本(ISO),作用等同于点号,也是只能出现一次.所不同的是,数据库会根据NLS_NUMERIC_CHARACTER的参数值来设置内容.默认的这个值是点号. 注意事项:没有特别需要一般不要用这个格式符号.也不要轻易修改参数值. 也可用alter sesssion set 来修改. alter session set nls_numeric_characters='!,';   to_char(1234.34,'9999d99')=1234!34 9 EEEE(科学计算符) 9.9EEEE 科学计算符号 TO_CHAR(2008032001,'9.9EEEE')='2.01E+09',由于是科学计算方法,所以小数位前面加一个9或者0即可,多个是没有意义的. 10 G(分组符号) 999G999 是逗号(,)的的ISO标准,作为分组符号使用,可以放在多个地方使用. TO_CHAR(123456,'999G9G99')=123,4,56 注意事项:同第八项 -D, 此外如果要转换出小数点,则要和D配合使用,不能和点号配合. 11 L(本地货币符号) 'L999' 是C的本地版本.可以放在整个格式的最前面和最后面. TO_CHAR(123456,'999G9G99D00L')=123,4,56.00￥ 注意事项:同第七项 C 12 MI(负号) '9999MI' 如果是负数,在尾部加上负号(-),如果是正数,则尾巴加上空格 to_char(1234,'9999mi')||'S'||TO_CHAR(-5678,'9999MI') =1234 S5678- 注意事项:只能放在格式尾巴 13 PR(符号) 9999PR 是表达负数的另外一种方式.如果是正数,则头部加上空格;如果是负数,则用小简括号<>把数字包起来. TO_CHAR(-1234.89,'9G999D00PR')=<1,234.89> 注意事项:同12 14 RN(rn) RN(rn) 把整数(1-3999)转换为罗马字符.RN表示转为大写,rn表示小写的. declare i int; begin    for i in 1..20 loop      dbms_output.put_line(to_char(i,'RN'));    end loop; end; 注意事项:只能自己使用,不能和其它符号组合使用. 15 S '9999S' 是12,13的综合改进版本.为整数加一个正号+,为负数加一个符号-.S在前则加在前,在后则在后. TO_CHAR(-1234,'S9999')=-1234;TO_CHAR(1234,'S9999')=+1234 16 TM TM9/TMe 使用这个参数等于没有用参数to_char(number)一样,应为'tm9'是默认的格式参数. to_char(1234,'tme')=1234 注意事项:格式要么是TM9,要么是TME. 当数字长度超过64位时候,TM9的输出等同于TME的输出. 17 U U999 双币符号,例如欧元.作用同11的L TO_CHAR(999,'U999')=￥999 注意事项：通过NLS_DUAL_CURRENCY 控制 18 V 999V9 这是个比较古怪，又不是很常使用的符号。它的作用在于做一个计算。 例如TO_CHAR(N,'999V9'),以p表示V的位置,则该表达式＝to_char(N×(10的P-1次方)).但是9个数又必须保证大于等于乘积之后表示的位数. TO_CHAR(5,'9V')=5*1=5; TO_CHAR(5,'9V9')=5*10=50 TO_CHAR(5,'9V99')=500 TO_CHAR(50,'9V99')='######' 9的个数不够 注意事项：格式中不能和小数表达写在一起，但是可以混合货币等。 19 X xxxx 转换为16进制。 TO_CHAR(100,'XX')= 64 注意事项：数值必须是大于等于0的整数。前面只能和0或者FM组合使用. 20 通过以上的例子，我们了解了各种数字的格式。可以说格式太多样，难于记在脑子，最好是作为一个参考存在着. 归类： 数值类： 0,9, 分组类： (.),(,),D,G ,其中点好和逗号因为表示不明显，所以用小括号凸显。 货币类：　$,C,L,U 计算转换类：EEEE,RN,V,X 正负符号：MI,PR,S 其它类：B 正统类：TM       1.2 格式说明       从上图可以看到格式是可选取的，保留字fmt也不是必须的，关键是NLSPARAM的意思，       从第2-54章节（FORMAT MODELS)查看。       NLSPARAM可以是这样　'NLS_NUMERIC_CHARACTERS = ''dg'' NLS_CURRENCY = ''text'' NLS_ISO_CURRENCY = territory ' 　　举例：(待续) 　　SELECT TO_CHAR(-10000, 'C99G999D99PR',                'NLS_NUMERIC_CHARACTERS=''._'' NLS_ISO_CURRENCY=''UNITED KINGDOM''') \"Amount\"    FROM DUAL;        结果返回：<GBP10_000.00>        如果要了解可以使用的NLS_ISO_CURRENCY值,可以查询数据库的视图V_$NLS_VALID_VALUES       二， TO_CHAR(CHARACTER) 　　把NCLOB,CLOB,NCHAR转换为VARCHAR2.       三， TO_CHAR(DATETIME) 　　把日期转化为字符串.        关于这个格式，没有什么太好说的。它的格式主要分为两类：简写单个字母（或者其复现形式）代表时间位置譬如yyyy ,mm,dd ,hh之类;其次是以英文的时间单词的简写代表时间，例如mon,day,year.        由于可以采取非常多的格式，所以实在是很灵活的.下面简单的举例几个：        SQL> select to_char(sysdate,' PM yyyy-mm-dd hh24:mi:sssss AD   year mon day ddd iw') FROM DUAL;        TO_CHAR(SYSDATE,'PMYYYY-MM-DDH        --------------------------------------------------------------------------------       上午 2008-03-27 09:58:35917 公元   two thousand eight 3月 星期四 087 13      SQL> SELECT TO_CHAR(SYSTIMESTAMP,'HH24:MI:SS.FF5') FROM DUAL;        TO_CHAR(SYSTIMESTAMP,'HH24:MI:        ------------------------------        10:02:28.90000        SQL>SELECT TO_CHAR(SYSDATE,'DS DL') FROM DUAL        TO_CHAR(SYSDATE,'DSDL')         -----------------------------------        2008-03-27 2008年3月27日 星期四        最后一个和国家地区有关.","title":"ORACLE函数TO_CHAR以及数字转换格式"},{"content":"            首先比较一下JDBC的优缺点： JDBC的优点         直接底层操作，提供了很简单、便捷的访问数据库的方法，跨平台性比较强。灵活性比较强，可以写很复杂的SQL语句。 JDBC的缺点 1.因为JAVA是面向对象的，JDBC没有做到使数据能够面向对象的编程，使程序员的思考仍停留在SQL语句上。 2.操作比较繁琐，很多代码需要重复写很多次。 3.如果遇到批量操作，频繁与数据库进行交互，容易造成效率的下降。  Jdbc是一个比较底层的东西  灵活写SQL语句 1、注册驱动 2、获得连接 3、产生一个Statement 4、进行操作 返回数据ResultSet  1、new List对象 2、把ResultSet数据放入List过程中 A a = new A(); a.setXXX(rs.getString(\"xxx\")); 代码比较繁琐 纯的JDBC是没有缓存的 模型不匹配(阻抗不匹配) Java面向对象语言，对象模型，其主要概念有：继承、关联、多态等；数据库是关系模型，其主要概念有：表、主键、外键等。 对象模型中对象与对象之间的关联关系与关系模型中数据库表之间的关系无法一一对应。 对象模型中对象的继承关系在关系模型中无法直接表示。 对象模型中对象的等值性（equals）在关系模型中无法直接实现。 对象模型中有关联的对象之间的导航访问在关系模型中无法直接实现。 解决办法 1使用JDBC手工转换。 2使用ORM(Object Relation Mapping对象关系映射)框架来解决。 Hibernate是一个开源ORM框架。 ORM全称Object Relation Mapping，即对象关系映射。它是一种用来完成对象模型到关系模型的映射技术。 就是把应用程序中的对象数据持久化到关系数据库的表的一种技术。 使用ORM（ Object Relation Mapping ）框架来解决。主流的ORM框架有JBoss公司的Hibernate、Oracle公司的TopLink、Apache组织的OJB、Sun公司的JDO。 简单的说：ORM能利用面向对象的思想开放基于关系型数据库的应用程序，它的主要工作是将对象数据保存到关系数据库的表中，以及将关系数据库表中数据读入到对象中。 下载地址http://www.hibernate.org，使用3.3版本。 解压获取必需类库文件 将下载目录/hibernate3.jar和/lib下的hibernate运行时必须的包加入classpath中： 安装配置 配置文件hibernate.cfg.xml和hibernate.properties，XML和properties两种，这两个文件的作用一样，提供一个即可，推荐XML格式，下载目录/etc下是示例配置文件。 可以在配置文件指定： 数据库的URL、用户名、密码、JDBC驱动类、方言等。 启动时Hibernate会在CLASSPATH里找这个配置文件。 映射文件(hbm.xml，对象模型和关系模型的映射)。在/eg目录下有完整的hibernate示例。  步骤：            1.新建java项目，并加入相应的jar包，及jdbc驱动。            2.创建持久化类            3. 准备数据库表            4.创建配置文件 hibernate.cfg.xml            5.创建映射文件 xxx.hbm.xml        6.创建测试文件 Hibernate.connection.url  表示要链接的数据库地址 Hibernate.connection.driver_class    表示要链接的数据库的驱动类 Hibernate.connection.username     要连接的数据库的用户名 Hibernate.connection.password      要连接的数据库的密码 Hibernate.dialect   表示要使用的数据库的类型           org.hibernate.dialect.MySQL5Dialect       mysql数据库           org.hibernate.dialect.Oracle9Dialect        oracle数据库           org.hibernate.dialect.SQLServerDialect    SQLServer数据库 hibernate.hbm2ddl.auto           validate:加载hibernate时验证创建表结构           update:加载hibernate时自动更新数据库结构，如果表存在不用创建，如果不存在就创建。           create:每一次加载hibernate时都创建表结构           create-drop:加载hibernate时创建，退出时删除 <hibernate-mapping package=\"com.hbsi.domain\"> <class name=\"User\" table=\"user\"> <id name=\"id\">                 <generator class = \"native\" /> <\/id>     <property name=\"name\" /> <property name=\"birthday\" type=\"datetime\" /> <\/class> <\/hibernate-mapping> <hibernate-configuration> <session-factory name=\"foo\"> <property name=\"hibernate.connection.driver_class\">com.mysql.jdbc.Driver<\/property> <property name=\"connection.url\">jdbc:mysql:///test<\/property> <property name=\"connection.username\">root<\/property> <property name=\"connection.password\">root<\/property> <property name=\"dialect\">org.hibernate.dialect.MySQLDialect<\/property>     <property name=\"connection.password\">root<\/property>     <property name=\"show_sql\">true<\/property> <property name=\"hbm2ddl.auto\">update<\/property>  <mapping resource=\"com/hbsi/domain/User.hbm.xml\"/> <\/session-factory> <\/hibernate-configuration> 这些都是配置文件；还需要创建一个domain类；","title":"Hibernate初学之第一讲"},{"content":"Andoird的SQLiteOpenHelper类中有一个onUpgrade方法。帮助文档中只是说当数据库升级时该方法被触发。经过实践，解决了我一连串的疑问： 1. 帮助文档里说的“数据库升级”是指什么？ 你开发了一个程序，当前是1.0版本。该程序用到了数据库。到1.1版本时，你在数据库的某个表中增加了一个字段。那么软件1.0版本用的数据库在软件1.1版本就要被升级了。 2. 数据库升级应该注意什么？ 软件的1.0版本升级到1.1版本时，老的数据不能丢。那么在1.1版本的程序中就要有地方能够检测出来新的软件版本与老的数据库不兼容，并且能够有办法把1.0软件的数据库升级到1.1软件能够使用的数据库。换句话说，要在1.0软件的数据库的那个表中增加那个字段，并赋予这个字段默认值。 3. 程序如何知道数据库需要升级？ SQLiteOpenHelper类的构造函数有一个参数是int version，它的意思就是指数据库版本号。比如在软件1.0版本中，我们使用SQLiteOpenHelper访问数据库时，该参数为1，那么数据库版本号1就会写在我们的数据库中。 到了1.1版本，我们的数据库需要发生变化，那么我们1.1版本的程序中就要使用一个大于1的整数来构造SQLiteOpenHelper类，用于访问新的数据库，比如2。 当我们的1.1新程序读取1.0版本的老数据库时，就发现老数据库里存储的数据库版本是1，而我们新程序访问它时填的版本号为2，系统就知道数据库需要升级。 4. 何时触发数据库升级？如何升级？ 当系统在构造SQLiteOpenHelper类的对象时，如果发现版本号不一样，就会自动调用onUpgrade函数，让你在这里对数据库进行升级。根据上述场景，在这个函数中把老版本数据库的相应表中增加字段，并给每条记录增加默认值即可。 新版本号和老版本号都会作为onUpgrade函数的参数传进来，便于开发者知道数据库应该从哪个版本升级到哪个版本。 升级完成后，数据库会自动存储最新的版本号为当前数据库版本号。","title":"数据库升级onUpgrade方法说明"},{"content":"服务器用的是windows server2003，下载手动安装的6.0等多个版本，当然优先考虑6.0这几个，但是没有安装成功。最后下载了免安装包mysql-noinstall-6.0.9-alpha-win32.zip，网上查看攻略。亲自走了遍。特此记录。         1.下载 MySQL 6.0免安装版         http://dev.mysql.com/get/Downloads/MySQL-6.0/mysql-noinstall-6.0.9-alpha-win32.zip/from/pick#mirrors         2.将 MySQL6.0 解压到待安装目录(自己决定放到哪）。解压后默认文件夹名称为：mysql-6.0.9-alpha-win32（当然可以自己更改），然后在环境变量中设置MYSQL_HOME（这样，以后可以用%MYSQL_HOME%引用安装目录）。如，我放在E盘根目录下，所以，MYSQL_HOME设置为：E:\\mysql-6.0.9-alpha-win32          3.打开文件my-huge.ini另存为my.ini，在my.ini文件最后（当然也可以在其他地方）加入如下配置。(my.ini记得是保存在与my-huge.ini同一个目录下的）(#表示注释） [mysqld]  # 设置mysql的安装目录 basedir=E:\\mysql-6.0.9-alpha-win32 # 设置mysql数据库的数据的存放目录，必须是data，或者是[url=file://\\\\xxx-data]\\\\xxx-data[/url] datadir=E:\\mysql-6.0.9-alpha-win32\\data         4.把%MYSQL_HOME%\\bin 加入到 path环境变量中。         5.在命令行（cmd）执行命令：mysqld -install  。将mysql安装为windows服务。（一定注意，执行此命令时一定要在安装目录下的\\bin目录下执行。否则会出问题。）         6.执行命令： net start mysql 或在windows管理工具->服务里找到MySQL服务，启动。         7.在命令行中运行 mysql -uroot  （可在任意目录下，因为前面设置了path变量）。即可进入数据库。这样操作后，mysql安装完成。 然后进入修改密码的过程。实际操作如下： 　　1.关闭正在运行的MySQL。 　　2.打开DOS窗口，转到mysql\\bin目录。 　　3.输入mysqld --skip-grant-tables回车。如果没有出现提示信息，那就对了。 　　4.再开一个DOS窗口(因为刚才那个DOS窗口已经不能动了)，转到mysql\\bin目录。 　　5.输入mysql -uroot回车，如果成功，将出现MySQL提示符 ,不成功退出，再重新进入> 　　6. 连接权限数据库>use mysql; (>是本来就有的提示符,别忘了最后的分号) 　　7.改密码：> update user set password=password(\"admin\") where user=\"root\"; 　　8.刷新权限(必须的步骤)>flush privileges; 　　9.退出 > \\q 　　10.注销系统，再进入，输入MySQL -uroot -padmin，使用用户名root和刚才设置的新密码admin登陆。","title":"mysql免安装配置和修改密码"},{"content":"14天学会安卓开发   作者:神秘的N (英文名  corder_raine) 联系方式:369428455(反馈) 交流群:284552167(示例,原文档下载) 版权为作者所有,如有转载请注明出处 目录 第八天.SQLite数据库技术... 87 8.1 SQLite介绍 8.1.1数据库存储... 87 8.1.2 SQLite介绍... 87 8.2 创建/打开/删除数据库... 87 8.2.1 创建数据库... 87 8.2.2 其他创建数据库的方法... 88 8.2.3 删除数据库... 88 8.2.4 打开数据库... 89 8.2.5 非查询SQL指令... 89 8.3 创建/删除表... 89 8.3.1 SQLite基础案例... 89 8.3.2 SQLite基础案例：更新视图显示... 90 8.4 CRUD操作 5.5 事务处理... 91 5.5.1 使用事务操作SQLite数据库... 91 第八天.SQLite数据库技术 8.1 SQLite介绍      8.1.1数据库存储 Ø    在某些情况下，文件不是有效的 u  多线程数据访问 u  需要事务处理 u  如果应用程序处理可能变化的复杂数据结构 u  数据库对于创建它们的包套件是私有的 8.1.2 SQLite介绍 Ø  SQLite是一个轻量级的数据库，体积大小只用几千字节 Ø  一些SQL的指令只是部分支持，例如：ALTER、TABLE Ø  广泛应用在嵌入式移动设备之上。 Ø  参阅http://www.sqlite.org 获取更多信息 8.2 创建/打开/删除数据库       8.2.1 创建数据库 1 2 3 4 5 6   Context.createDatabase( String name, // int version, // int mode, // CursorFactory factory // ) Ø  创建一个新的数据库并返回一个SQLiteDatabase对象 Ø  数据库不能被创建，则抛出FileNotFoundException异常 8.2.2 其他创建数据库的方法 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 SQLiteDatabase mydataBase=SQLiteDatabase.create(new CursorFactory(){ //创建一个数据库 //工厂类，一个可选工厂类，当查询时调用来实例化一个光标 public Cursor newCursor(SQLiteDatabase db, SQLiteCursorDriver masterQuery, String editTable, SQLiteQuery query) { return null; } }); SQLiteDatabase myDataBase=this.openOrCreateDatabase(\"myDataBase.db\", MODE_PRIVATE, new CursorFactory(){ //创建新的数据库，名称myDatabase，模式MODE_PRIVATE，游标工厂 //工厂类，一个可选工厂类，当查询时调用来实例化一个光标 public Cursor newCursor(SQLiteDatabase db, SQLiteCursorDriver masterQuery, String editTable, SQLiteQuery query) { return null; } }); 8.2.3 删除数据库 Ø  Context.deleteDatabase(String name) u  删除指定名称的数据库 u  假如数据库成功删除则返回true，失败则为false 8.2.4 打开数据库 Ø  Context.openDatabase(String file,CursorFactory factory) u  打开一个存在的数据库并返回一个SQLiteDatabase 对象 u  如果数据库不存在则抛出FileNotFoundException 异常 u  如创建一个名为：myDataBase的数据库，后缀为.db 1 2 3 4 5 SQLiteDatabase       my_DataBase=              this.openOrCreateDatabase(                     \"myDateBase.db\",                     MODE_PRIVATE, null);  my_DataBase.close();//不要忘记关闭数据库 8.2.5 非查询SQL 指令 Ø  SQLiteDatabase.execSQL(String sql) u  可以用来执行非查询SQL指令，这些指令没有结果， 包括：CREATE TABLE / DROP TABLE / INSERT 等等。 8.3 创建/删除表 8.3.1 SQLite基础案例 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 private SQLiteDatabase mSQLiteDatabase=null; // 打开已经存在的数据库 mSQLiteDatabase = this.openOrCreateDatabase(DATABASE_NAME, MODE_PRIVATE, null); /* 在数据库mSQLiteDatabase中创建一个表 */ mSQLiteDatabase.execSQL(CREATE_TABLE); /* 删除数据库 */ this.deleteDatabase(DATABASE_NAME); /* 退出时，不要忘记关闭 */ mSQLiteDatabase.close(); /* 删除一个表 */ mSQLiteDatabase.execSQL(\"DROP TABLE \" + TABLE_NAME); /* 更新一条数据 */ ContentValues cv = new ContentValues(); cv.put(TABLE_NUM, miCount); cv.put(TABLE_DATA, \"修改后的数据\" + miCount); mSQLiteDatabase.update(TABLE_NAME, cv, TABLE_NUM + \"=\" + Integer.toString(miCount - 1), null); UpdataAdapter(); //更新界面 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 /* 向表中添加一条数据 */        ContentValues cv = new ContentValues();        cv.put(TABLE_NUM, miCount);        cv.put(TABLE_DATA, \"测试数据库数据\" + miCount);        mSQLiteDatabase.insert(TABLE_NAME, null, cv);        miCount++;        UpdataAdapter(); //更新界面                /* 从表中删除指定的一条数据 */        mSQLiteDatabase.execSQL(\"DELETE FROM \" + TABLE_NAME + \" WHERE _id=\" + Integer.toString(miCount));        miCount--;        if (miCount < 0){               miCount = 0;        }        UpdataAdapter(); //更新界面 8.3.2 SQLite基础案例：更新视图显示 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 /* 更新视图显示 */ public void UpdataAdapter(){               // 获取数据库Phones的Cursor               Cursor cur = mSQLiteDatabase.query(TABLE_NAME, new String[] { TABLE_ID, TABLE_NUM, TABLE_DATA }, null, null, null, null, null);               miCount = cur.getCount();               if (cur != null && cur.getCount() >= 0) {                      // ListAdapter是ListView和后台数据的桥梁                      ListAdapter adapter = new SimpleCursorAdapter(this,                      // 定义List中每一行的显示模板                             // 表示每一行包含两个数据项                             android.R.layout.simple_list_item_2,                             // 数据库的Cursor对象                             cur,                             // 从数据库的TABLE_NUM和TABLE_DATA两列中取数据                             new String[] { TABLE_NUM, TABLE_DATA },                             // 与NAME和NUMBER对应的Views                             new int[] { android.R.id.text1, android.R.id.text2 });                      /* 将adapter添加到m_ListView中 */                      m_ListView.setAdapter(adapter);               } } ** 研究案例DatabaseDemo1 8.4 CRUD操作 8.4.1 查询SQL 指令-游标Cursors Ø  Android 使用游标(Cursors)来导航浏览查询结果 Ø  游标(Cursors)被android.database.Cursor 对象来描述 Ø  一个游标(Cursors)是一个简单的指针，它从查询结果的一个元组跳到下一个元组(或前一个或第一个……) Ø  游标(Cursors)在它定位位置的那一刻返回元组数据 01 02 03 04 05 06 07 08 09 10 11 12 13 14 15 16 17 18 19 20 //为创建Cursor(游标)，必须执行查询，要么通过SQL使用rawQuery()方法 //或是更精心设计的方法，像query()方法 Cursor cur=my_DataBase.rawQuery(\"SELECT * FORM test\", null); if(cur!=null){//游标不为空 //返回给定名称的列的基于0开始的index，如果该属性列不存在则返回-1 //通过它们的index来检索属性值 int numColumn=cur.getColumnIndex(\"someNumber\"); if(cur.moveToFirst()){ //cur.moveToFirst()让游标指向第一行，如果游标指向第一行，则返回true do { int num=cur.getInt(numColumn);//获得当前行该属性的值 /*Cursor提供了不同的方法来回索不同的数据类型 例如getInt(int index)/getString(int index)等等*/ /*做一些事情*/ } while (cur.moveToNext()); /*游标移动到下一行，如果游标已经通过了结果集中的最后， 即没有行可以移动时，则返回false*/ //其他可能移动的是previous() 和first()方法 } } 5.5 事务处理 5.5.1 使用事务操作SQLite数据库 使用SQLiteDatabase的beginTransaction()方法可以开启一个事务，程序执行到endTransaction() 方法时会检查事务的标志是否为成功，如果为成功则提交事务，否则回滚事务。当应用需要提交事务，必须在程序执行到endTransaction()方法之前使用setTransactionSuccessful() 方法设置事务的标志为成功，如果不调用setTransactionSuccessful() 方法，默认会回滚事务。使用例子如下： 01 02 03 04 05 06 07 08 09 10 SQLiteDatabase db = ....; db.beginTransaction();//开始事务 try {     db.execSQL(\"insert into person(name, age) values(?,?)\", new Object[]{“lxt008\", 4});     db.execSQL(\"update person set name=? where personid=?\", new Object[]{“lxt008\", 1});     db.setTransactionSuccessful();//调用此方法会在执行到endTransaction() 时提交当前事务，如果不调用此方法会回滚事务 } finally {     db.endTransaction();//由事务的标志决定是提交事务，还是回滚事务 } db.close(); 上面两条SQL语句在同一个事务中执行。 其他 Ø  数据库辅助类 u  研究案例DatabaseDemo2 u  数据库小工具 Sqlitebrowser可以简单管理Sqlite数据库 示例下载","title":"14天学会安卓开发(第八天)SQLite数据库技术"},{"content":"登录oracle的时候突然出现如下问题： ORA-00257:archiver error.Connect internal only, until freed. 疑惑，可以猜想得到，可能是归档日志空间不足导致的。 用sysdba用户登录： 查询归档日志的空间的使用率： 归档日志默认的大小是2G 可以这么计算已经使用的空间： SELECT SUM(A.BLOCK_SIZE * A.BLOCKS) / 1024 / 1024 FROM   V$ARCHIVED_LOG A WHERE  A.DELETED = 'NO'; 可见空间已经几乎耗尽了。 需要对归档日志进行清除，在删除归档日志之后需要使用rman维护控制文件，否则空间仍然无法释放： 首先检查无用的archivelog： 删除无用的archivelog和删除截止到10天前的归档日志：","title":"ORA-00257:archiver error.Connect internal only, until freed"},{"content":"转载自http://blog.csdn.net/smszhuang168/article/details/7761310  首先我们了解一个名词ORM，全称是（Object Relational Mapping），即对象关系映射。ORM的实现思想就是将关系数据库中表的数据映射成对象，以对象的形式展现，这样开发人员就可以把对数据库的操作转化为对这些对象的操作。Hibernate正是实现了这种思想，达到了方便开发人员以面向对象的思想来实现对数据库的操作。                Hibernate在实现ORM功能的时候主要用到的文件有：映射类（*.java）、映射文件（*.hbm.xml）和数据库配置文件（*.properties/*.cfg.xml），它们各自的作用如下。         映射类（*.java）：它是描述数据库表的结构，表中的字段在类中被描述成属性，将来就可以实现把表中的记录映射成为该类的对象了。         映射文件（*.hbm.xml）：它是指定数据库表和映射类之间的关系，包括映射类和数据库表的对应关系、表字段和类属性类型的对应关系以及表字段和类属性名称的对应关系等。         数据库配置文件（*.properties/*.cfg.xml）：它是指定与数据库连接时需要的连接信息，比如连接哪种数据库、登录数据库的用户名、登录密码以及连接字符串等。当然还可以把映射类的地址映射信息放在这里。         接下来让我们就一起走进Hibernate的七种映射关系：         1、        单向一对一关联映射（one-to-one）：         两个对象之间一对的关系，例如：Person（人）-IdCard（身份证）         有两种策略可以实现一对一的关联映射：                *主键关联：即让两个对象具有相同的主键值，以表明它们之间的一一对应的关系；数据库表不会有额外的字段来维护它们之间的关系，仅通过表的主键来关联。如下图：             例子：单向一对一主键关联例子连接                *唯一外键关联：外键关联，本来是用于多对一的配置，但是加上唯一的限制之后（采用<many-to-one>标签来映射，指定多的一端unique为true，这样就限制了多的一端的多重性为一），也可以用来表示一对一关联关系，其实它就是多对一的特殊情况。如下图：         例子：单向一对一唯一外键关联例子连接         注意：因为一对一的主键关联映射扩展性不好，当我们的需要发生改变想要将其变为一对多的时候变无法操作了，所以我们遇到一对一关联的时候经常会采用唯一外键关联来解决问题，而很少使用一对一主键关联。         2、        单向多对一关联映射（many-to-one）：        多对一关联映射原理：在多的一端加入一个外键，指向一的一端，如下图：        关键映射代码——在多的一端加入如下标签映射：       [java] view plaincopy <many-to-one name=\"group\" column=\"groupid\"/>          3、         单向一对多关联映射（one-to-many）：        一对多关联映射和多对一关联映射原理是一致的，都是在多的一端加入一个外键，指向一的一端。如下图（学生和班级）：        注意：它与多对一的区别是维护的关系不同                *多对一维护的关系是：多指向一的关系，有了此关系，加载多的时候可以将一加载上来                *一对多维护的关系是：一指向多的关系，有了此关系，在加载一的时候可以将多加载上来        关键映射代码——在一的一端加入如下标签映射： [java] view plaincopy <set name=\"students\">         <key column=\"classesid\"/>         <one-to-many class=\"com.hibernate.Student\"/>   <\/set>          缺陷：因为多的一端Student不知道Classes的存在（也就是Student没有维护与Classes的关系）所以在保存Student的时候关系字段classesid是为null的，如果将该关系字段设置为非空，则将无法保存数据，常用解决办法是改用双向关联映射，参见6。        4、         单向多对多映射（many-to-many）：       多对多关联映射新增加一张表才完成基本映射，如下图：       关键映射代码——可以在User的一端加入如下标签映射： [java] view plaincopy <set name=\"roles\" table=\"t_user_role\">        <key column=\"user_id\"/>        <many-to-many class=\"com.hibernate.Role\" column=\"role_id\"/>   <\/set>           5、         双向一对一关联映射：         对比单向一对一映射，需要在IdCard加入<one-to-one>标签，它不影响，只影响加载。如下图：            双向一对一主键映射关键映射代码——在IdCard端新加入如下标签映射：        [java] view plaincopy <one-to-one name=\"person\"/>          双向一对一唯一外键映射关键映射代码——在IdCard端新加入如下标签映射： [java] view plaincopy <one-to-one name=\"person\"property-ref=\"idCard\"/>          注意：一对一唯一外键关联双向采用<one-to-one>标签映射，必须指定<one-to-one>标签中的property-ref属性为关系字段的名称        6、         双向一对多关联映射（非常重要）：        采用一对多双向关联映射的目的主要是为了主要是为了解决一对多单向关联的缺陷而不是需求驱动的。        一对多双向关联的映射方式：               * 在一的一端的集合上采用<key>标签，在多的一端加入一个外键               * 在多的一端采用<many-to-one>标签        注意：<key>标签和<many-to-one>标签加入的字段保持一直，否则会产生数据混乱       关键映射代码：       在Classes的一端加入如下标签映射：      [java] view plaincopy <set name=\"students\"inverse=\"true\">          <key column=\"classesid\"/>         <one-to-many class=\"com.hibernate.Student\"/>   <\/set>         在Student的一端加入如下标签映射： [java] view plaincopy <many-to-one name=\"classes\" column=\"classesid\"/>         注释：inverse属性                * inverse属性可以用在一对多和多对多双向关联上，inverse属性默认为false，为false表示本端可以维护关系，如果inverse为true，则本端不能维护关系，会交给另一端维护关系，本端失效。所以一对多关联映射我们通常在多的一端维护关系，让一的一端失效。               * inverse是控制方向上的反转，只影响存储       7、         双向多对多关联映射：       双向的目的就是为了两端都能将对方加载上来，和单向多对多的区别就是双向需要在两端都加入标签映射，需要注意的是：               * 生成的中间表名称必须一样               * 生成的中间表中的字段必须一样         Role（角色）端关键映射代码：  [java] view plaincopy <set name=\"users\" table=\"t_user_role\">          <key column=\"role_id\"/>          <many-to-many class=\"com.hibernate.User\" column=\"user_id\"/>   lt;/set>          User（用户）端关键映射代码：          [java] view plaincopy <set name=\"roles\" table=\"t_user_role\">         <key column=\"user_id\"/>         <many-to-many class=\"com. hibernate.Role\" column=\"role_id\"/>   lt;/set>          总结：对于上面这七种关联映射中，最重要的就是一对多的映射，因为它更贴近我们的现实生活，比如：教室和学生就可以是典型的一对多的关系，而我们开发软件的目的之一就是为了解决一些生活中重复性问题，把那些重复的问题交给计算机帮助我们完成，从而来提高我们的工作效率。一句话：生活离开不开编程，编程更离不开生活。","title":"Hibernate映射解析——七种映射关系"},{"content":"算数运算 1、查询每个人的年薪 select sal * 12 \"annual salary\" from emp; 空值处理 2、查询每个人年薪与奖金的总和（需要考虑空值问题） select sal * 12 + nvl(comm, 0) as 年薪 from emp; 字符串连接 3、字符串连接 || select ename || '---' as \"new name\" from emp; 字符串中的单引号 4、两个单引号代替字符串中的一个单引号 select deptno || 'aa''b' \"new deptno\" from dept; 去除重复项 5、distinct 去掉重复组合 select distinct deptno, job from emp; 条件查询 6、查询部门编号为10的员工的名字 select ename, deptno from emp where deptno = 10; 7、查询指定名称的员工信息 select * from emp where ename = 'KING'; 8、查询员工部门编号大于10的员工信息 select * from emp where deptno > 20; 9、选择员工工资大于等于800，并且小于等于1500的员工信息 select * from emp where sal between 800 and 1500; 或者 select * from emp where sal >= 800 and sal <= 1500; 查询NULL项 10、查询员工薪金为null的员工的姓名和工资及薪金 select ename, sal, comm from emp where comm is null; IN 11、查询员工工资为800， 1500或1300的员工的名字和工资 select ename, sal from emp where sal in (800, 1500, 1300); 格式化查询日期 12、查询81年2月20日之后入职的员工信息 select ename, to_char(hiredate, 'YYYY-MM-DD') from emp where hiredate > to_date('1981-02-20', 'YYYY-MM-DD'); 模糊查询 13、查询员工姓名中包含LA的员工的名字 select ename from emp where ename like '%LA%'; 14、查询员工姓名中第二个字符为A的员工的名字 select ename from emp where ename like '_A%'; 自定义转义字符 15、查询员工姓名中带有%号的员工的名字 select ename from emp where ename like '%\\%%' escape '\\'; 排序默认升序ASC，降序DESC 16、按照倒序查询所有部门编号 select deptno from dept order by deptno desc; 按照多列进行排序 17、按照部门编号升序，工资降序查询员工姓名，部门编号及工资 TO_CHAR() 18、格式化输出工资的结果集S99,999.9999 select ename, to_char(sal, '$99,999.9999') from emp; 19、本地货币L select ename, to_char(sal, 'L99,999.9999') from emp; 20、以0补全格式 select ename, to_char(sal, 'L00,000.0000') from emp; 21、日期转换为字符串 select to_char(sysdate, 'YYYY-MM-DD HH24:MI:SS') 系统当前时间 from dual; TO_DATE() 22、将指定格式YYYY-MM-DD的时间字符串转化为时间 select to_date('2012-12-21', 'YYYY-MM-DD') from dual; TO_NUMBER() 23、查询员工工资小于$1500.00的员工工资 select sal from emp where to_number('$1500.00','$9999.99') < sal 组函数 24、查询员工的最高工资 select max(sal) from emp; 25、查询员工的最高工资、平均工资和最低工资 select max(sal) 最高工资, avg(sal) 平均工资, min(sal) 最低工资 from emp; 26、查询所有员工每个月的工资总和 select sum(sal) from emp; 27、查询一共有多少位员工 select count(*) from emp; 28、查询一共多少员工具有奖金 select count(comm) from emp; 29、查询员工一共属于多少个部门 select count(distinct deptno) from emp; 30、查询每个部门的平均工资 select deptno, avg(sal) from emp group by deptno; 31、查询按照部门和工种分类的平均薪水 select deptno, job, avg(sal) from emp group by deptno, job;","title":"Oracle笔记_基于样例表的一些基础查询"},{"content":"一、你对MVC的理解，MVC有什么优缺点？结合Struts，说明在一个Web应用如何去使用？ 答： MVC设计模式（应用观察者模式的框架模式） M: Model(Business process layer)，模型，操作数据的业务处理层,并独立于表现层(Independent of presentation)。 V: View(Presentation layer)，视图，通过客户端数据类型显示数据,并回显模型层的执行结果。 C: Controller(Control layer)，控制器，也就是视图层和模型层桥梁，控制数据的流向，接受视图层发出的事件，并重绘视图 MVC框架的一种实现模型 模型二(Servlet-centric)： JSP+Servlet+JavaBean，以控制为核心，JSP只负责显示和收集数据，Sevlet，连接视图和模型，将视图层数据，发送给模型层，JavaBean，分为业务类和数据实体，业务类处理业务数据，数据实体，承载数据，基本上大多数的项目都是使用这种MVC的实现模式。 StrutsMVC框架(Web application frameworks) Struts是使用MVC的实现模式二来实现的，也就是以控制器为核心。 Struts提供了一些组件使用MVC开发应用程序： Model：Struts没有提供model类。这个商业逻辑必须由Web应用程序的开发者以JavaBean或EJB的形式提供 View：Struts提供了action form创建form bean, 用于在controller和view间传输数据。此外，Struts提供了自定义JSP标签库，辅助开发者用JSP创建交互式的以表单为基础的应用程序，应用程序资源文件保留了一些文本常量和错误消息，可转变为其它语言，可用于JSP中。 Controller：Struts提供了一个核心的控制器ActionServlet，通过这个核心的控制器来调用其他用户注册了的自定义的控制器Action，自定义Action需要符合Struts的自定义Action规范，还需要在struts-config.xml的特定配置文件中进行配置，接收JSP输入字段形成Action form，然后调用一个Action控制器。Action控制器中提供了model的逻辑接口。 二、什么是WebService？ 答： WebService是一个SOA（面向服务的编程）的架构，它是不依赖于语言，不依赖于平台，可以实现不同的语言间的相互调用，通过Internet进行基于Http协议的网络应用间的交互。 WebService实现不同语言间的调用，是依托于一个标准，webservice是需要遵守WSDL（web服务定义语言）/SOAP（简单请求协议）规范的。 WebService=WSDL+SOAP+UDDI（webservice的注册） Soap是由Soap的part和0个或多个附件组成，一般只有part，在part中有Envelope和Body。 Web Service是通过提供标准的协议和接口，可以让不同的程序集成的一种SOA架构。 Web Service的优点 (1) 可以让异构的程序相互访问（跨平台） (2) 松耦合 (3) 基于标准协议（通用语言，允许其他程序访问） Web Service的基本原理 (1) Service Provider采用WSDL描述服务 (2) Service Provider 采用UDDI将服务的描述文件发布到UDDI服务器（Register server） (3) Service Requestor在UDDI服务器上查询并 获取WSDL文件 (4) Service requestor将请求绑定到SOAP，并访问相应的服务。 三、什么是中间件？   中间件就是程序中可织入的，可重用的，与业务逻辑无关的各种组件。 中间件（middleware）是基础软件的一大类，属于可复用软件的范畴。顾名思义，中间件处于操作系统软件与用户的应用软件的中间。中间件在操作系统、网络和数据库之上，应用软件的下层，总的作用是为处于自己上层的应用软件提供运行与开发的环境，帮助用户灵活、高效地开发和集成复杂的应用软件。   在众多关于中间件的定义中，比较普遍被接受的是IDC表述的：中间件是一种独立的系统软件或服务程序，分布式应用软件借助这种软件在不同的技术之间共享资源，中间件位于客户机服务器的操作系统之上，管理计算资源和网络通信。 分类：数据访问中间件，远程调用中间件，消息中间件，交易中间件，对象中间件。 举例： 1，RMI（Remote Method Invocations, 远程调用） 2，Load Balancing(负载均衡，将访问负荷分散到各个服务器中) 3，Transparent Fail-over(透明的故障切换) 4，Clustering(集群,用多个小的服务器代替大型机） 5，Back-end-Integration(后端集成，用现有的、新开发的系统如何去集成遗留的系统) 6，Transaction事务（全局/局部）全局事务（分布式事务）局部事务（在同一数据库联接内的事务） 7，Dynamic Redeployment(动态重新部署,在不停止原系统的情况下，部署新的系统） 8，System Management(系统管理) 9，Threading(多线程处理) 10，Message-oriented Middleware面向消息的中间件（异步的调用编程） 11，Component Life Cycle(组件的生命周期管理) 12，Resource pooling（资源池） 13，Security（安全） 14，Caching（缓存） 四、什么是典型的软件三层结构？软件设计为什么要分层？软件分层有什么好处？ 答：(1) Presentation layer（表示层） (1) 表示逻辑（生成界面代码） (2) 接收请求 (3) 处理业务层抛出的异常 (4) 负责规则验证（数据格式，数据非空等） (5) 流程控制 (2) Service layer（服务层/业务层） (1) 封装业务逻辑处理，并且对外暴露接口 (2) 负责事务，安全等服务 (3) Persistence layer（持久层） (1) 封装数据访问的逻辑，暴露接口 (2) 提供方便的数据访问的方案（查询语言，API，映射机制等） Domain layer（域层） (1) 业务对象以及业务关系的表示 (2) 处理简单的业务逻辑 (3) 域层的对象可以穿越表示层，业务层，持久层 软件分层结构使得代码维护非常方便，设计明确，各层独立，专注自己擅长的领域。 五、什么是OOP？OOP相对于面向过程编程有哪些优点？ OOP，Object-Oriented Programming，面向对象编程不同于面向过程编程： （1）OOP关注对象和角色，也就是事物的本质 1）OOP把客观世界中的对象抽象成对应的类； 2）通过类构造实例； 3）通过依赖、继承、实现等形式建立对象间的通信关系 （2）OOP易于扩展，增加或改变业务的功能，无需大幅改动改变源代码 （3）OOP易于建模，OOP就是软件架构师在计算机高级语言中对客观世界的抽象和再现，人们可以很好地理解和建立起计算机中的抽象模型 六、谈谈Overload和Override的区别。 答：     方法的重写Overriding和重载Overloading是Java多态性的不同表现。重写Overriding是父类与子类之间多态性的一种表现，重载Overloading是一个类中多态性的一种表现。如果在子类中定义某方法与其父类有相同的名称和参数，我们说该方法被重写(Overriding)。子类的对象使用这个方法时，将调用子类中的定义，对它而言，父类中的定义如同被“屏蔽”了。如果在一个类中定义了多个同名的方法，它们或有不同的参数个数或有不同的参数类型，则称为方法的重载(Overloading)。Overloaded的方法是可以改变返回值的类型。 七、谈谈HashMap和Hashtable的区别。 答： HashMap是轻量级的（线程不安全的，效率高的）集合，Hashtable是重量级的（线程安全的，效率低的）集合。      都属于Map接口的类，实现了将惟一键映射到特定的值上。 HashMap 类没有分类或者排序。它允许一个 null 键和多个 null 值。 Hashtable 类似于 HashMap，但是不允许 null 键和 null 值。它也比 HashMap 慢，因为它是同步的。 八、请问abstract class和interface有什么区别？ 答： 1) 接口没有任何的实现,而抽象类它可以有部分的实现也可以没有; 2) 如果需要复用或者共享部分代码,应该用抽象类而不是接口; 3) 继承无法解决类型的转换问题,接口就是为了解决这一问题而产生的(Java的单继承是接口产生的根本原因) 接口是一种抽象的第三方规范,跟对象没什么直接关系。 九、请问软件开发中的设计模式你会使用哪些？ 答：我熟悉的设计模式有单例模式，DAO模式，模板方法，工厂模式，委托代理模式，MVC模式等。 Singleton模式主要作用是保证在Java应用程序中，一个类Class只有一个实例存在。 Singleton模式一般形式:      定义一个类，它的构造函数为private的，它有一个static的private的该类变量，在类初始化时实例话，通过一个public的getInstance方法获取对它的引用,继而调用其中的方法。 十、类的核心特性有哪些？ 类具有封装性、继承性和多态性。 封装性： 类的封装性为类的成员提供公有、缺省、保护和私有等多级访问权限，目的是隐藏类中的私有变量和类中方法的实现细节。 继承性： 类的继承性提供从已存在的类创建新类的机制，继承（inheritance）使一个新类自动拥有被继承类（父类）的全部成员。 多态性： 类的多态性提供类中方法执行的多样性，多态性有两种表现形式：重载和覆盖。 十一、请问类与对象有什么区别？ 类 类就是某一种事物的一般性的集合体，是相同或相似的各个事物共同特性的一种抽象。 对象 在面向对象概念中，对象（Object）是类的实例（instance）。对象与类的关系就像变量与数据类型的关系一样。 十二、写出生产者消费者模型的实现 十三、用软件工程和Java来叙述购物车（shopping cart）系统实现 十四、文件系统的几个类:FileInputStream、FileOutputStream、FileReader、FileWriter的区别 十五、请写出Java API中最常用的五个包，并且各举两个类加以说明。 十六、请问你在“电信运营支撑系统”中遇到了哪些问题？你是怎么解决的？做这个项目你最大的收获是什么？ 十七、请说出几个常用的异常类 答：NullpointException（空指针异常） ClassNotFoundException（类找不到异常） ClassCastException（类型转换异常） IllegalArgumentException（非法参数异常） ArithmeticException（算术异常） NumberFormatException（数据格式异常） IndexOutOfBoundsException（数组下标越界异常） IllegalStateException（非法语句异常） 十八、什么是进程和线程？两者的区别是什么？ 十九、请简要描述一下你做的ShoppingCart项目。 二十、请问网络7层协议，tcp/ip4 层协议是什么？ 二十一、Java面向对象的四大特点 二十二、public,private,protected，default访问权限（可见性） 答： public：全局可见 protected：继承体系结构之间可见 default（或不写）：同包可见 private：本类可见。 二十二、public,private,protected，default访问权限（可见性） 答： public：全局可见 protected：继承体系结构之间可见 default（或不写）：同包可见 private：本类可见。 二十三、名词解释 CRM [Customer Relationship Management, 客户关系管理] ERP [Enterprise Resource Planning, 企业资源规划] OSS [Operation Support System, 运营支撑系统] BSS [Business Support System, 数据定义语言] BOSS [Business Operation Support System, 数据定义语言] OA [Office Automatization, 办公自动化] HTTP OOP SOA GUI DDL [Data Definition Language, 数据定义语言] DML [Data Manipulation Language, 数据操作语言] WYSIWYG   所见即所得 [What You See is What You Get] CMP CMT B2B C2C B2C IDE DOM Client/Server CMM ORM MIS MVC MVC是Model－View－Controller的简写。\"Model\" 代表的是应用的业务逻辑（通过JavaBean，EJB组件实现）， \"View\" 是应用的表示面（由JSP页面产生），\"Controller\" 是提供应用的处理过程控制（一般是一个Servlet），通过这种设计模型把应用逻辑，处理过程和显示逻辑分成不同的组件实现。这些组件可以进行交互和重用。 OLE CORBA CORBA 标准是公共对象请求代理结构(Common Object Request Broker Architecture)，由对象管理组织 (Object Management Group，缩写为 OMG)标准化。它的组成是接口定义语言(IDL), 语言绑定(binding:也译为联编)和允许应用程序间互操作的协议。 其目的为： 用不同的程序设计语言书写 在不同的进程中运行 为不同的操作系统开发。 UML UML，标准建模语言，包含用例图,静态图(包括类图、对象图和包图),行为图,交互图(顺序图,合作图),实现图等。 XML CMMI JRE J2EE J2EE是Sun公司提出的多层(multi-diered),分布式(distributed),基于组件(component-base)的企业级应用模型(enterpriese application model).在这样的一个应用系统中，可按照功能划分为不同的组件，这些组件又可在不同计算机上，并且处于相应的层次(tier)中。所属层次包括客户层(clietn tier)组件,web层和组件,Business层和组件,企业信息系统(EIS)层。 JDK AOP OO Container W3C JMS Domain POJO JVM JNDI JTA SOAP [Simple Object Access Protocol，简单对象访问协议] WSDL JDO JDO是Java对象持久化的新的规范，为Java Data Object的简称,也是一个用于存取某种数据仓库中的对象的标准化API。JDO提供了透明的对象存储，因此对开发人员来说，存储数据对象完全不需要额外的代码（如JDBC API的使用）。这些繁琐的例行工作已经转移到JDO产品提供商身上，使开发人员解脱出来，从而集中时间和精力在业务逻辑上。另外，JDO很灵活，因为它可以在任何数据底层上运行。JDBC只是面向关系数据库（RDBMS)JDO更通用，提供到任何数据底层的存储功能，比如关系数据库、文件、XML以及对象数据库（ODBMS）等等，使得应用可移植性更强。 TDD DAO IoC [Inversion of Control, 控制反转] RMI DNS [Internet Domain Name System, 因特网域名系统] URL URI 二十四、数据库连接池的工作机制 二十五、互联网提供哪些服务？ 二十六、请写出JSP的几个隐含内置对象 答：JSP中隐含内置对象 名称         类型                                     注释和范围 request javax.servlet.http.HttpServletRequest request response javax.servlet.http.HttpServletResponse response page javax.lang.Object page Exception java.lang.Throwable page pageContext javax.servlet.jsp.PageContext page session javax.servlet.http.HttpSession session application javax.servlet.ServletContext ServletContext out javax.servlet.jsp.JspWriter OutputStream config javax.servlet.ServletConfig ServletConfig JSP共有以下9种基本内置组件（可与ASP的6种内部组件相对应）： request 用户端请求，此请求会包含来自GET/POST请求的参数 response 网页传回用户端的回应 page JSP 网页本身 exception 针对错误网页，未捕捉的例外 pageContext 网页的属性是在这里管理 session 与请求有关的会话期 application servlet 正在执行的内容 out 用来传送回应的输出 config Servlet的构架部件 二十七、请你谈谈SSH整合 答：SSH： Struts（表示层）+Spring（业务层）+Hibernate（持久层） Struts： Struts是一个表示层框架，主要作用是界面展示，接收请求，分发请求。 在MVC框架中，Struts属于VC层次，负责界面表现，负责MVC关系的分发。（View：沿用JSP，HTTP，Form，Tag，Resourse ；Controller：ActionServlet，struts-config.xml，Action） Hibernate： Hibernate是一个持久层框架，它只负责与关系数据库的操作。 Spring： Spring是一个业务层框架，是一个整合的框架，能够很好地黏合表示层与持久层。 二十八、应用服务器与Web Server的区别 二十九、Java Servlet API中forward() 与redirect()的区别 答： 前者仅是容器中控制权的转向，在客户端浏览器地址栏中不会显示出转向后的地址；后者则是完全的跳转，浏览器将会得到跳转的地址，并重新发送请求链接。这样，从浏览器的地址栏中可以看到跳转后的链接地址。所以，前者更加高效，在前者可以满足需要时，尽量使用forward()方法，并且，这样也有助于隐藏实际的链接。在有些情况下，比如，需要跳转到一个其它服务器上的资源，则必须使用sendRedirect()方法。 三十、写一个简单的C/S结构程序，Java 的通信编程，编程题(或问答)，用JAVA SOCKET编程，读服务器几个字符，再写入本地显示？ 答:Server端程序: package test; import java.net.*; import java.io.*; public class Server { private ServerSocket ss; private Socket socket; private BufferedReader in; private PrintWriter out; public Server() { try { ss=new ServerSocket(10000); while(true) { socket = ss.accept(); String RemoteIP = socket.getInetAddress().getHostAddress(); String RemotePort = \":\"+socket.getLocalPort(); System.out.println(\"A client come in!IP:\"+RemoteIP+RemotePort); in = new BufferedReader(new InputStreamReader(socket.getInputStream())); String line = in.readLine(); System.out.println(\"Cleint send is :\" + line); out = new PrintWriter(socket.getOutputStream(),true); out.println(\"Your Message Received!\"); out.close(); in.close(); socket.close(); } }catch (IOException e) { out.println(\"wrong\"); } } public static void main(String[] args) { new Server(); } }; Client端程序: package test; import java.io.*; import java.net.*; public class Client { Socket socket; BufferedReader in; PrintWriter out; public Client() { try { System.out.println(\"Try to Connect to 127.0.0.1:10000\"); socket = new Socket(\"127.0.0.1\",10000); System.out.println(\"The Server Connected!\"); System.out.println(\"Please enter some Character:\"); BufferedReader line = new BufferedReader(new InputStreamReader(System.in)); out = new PrintWriter(socket.getOutputStream(),true); out.println(line.readLine()); in = new BufferedReader(new InputStreamReader(socket.getInputStream())); System.out.println(in.readLine()); out.close(); in.close(); socket.close(); }catch(IOException e) { out.println(\"Wrong\"); } } public static void main(String[] args) { new Client(); } };","title":"面试题"},{"content":"复制代码 <?php //为了避免重复包含文件而造成错误，加了判断函数是否存在的条件： @$page = $_GET['page']; if(!function_exists('pageft')){ //定义函数pageft(),三个参数的含义为： //$totle：信息总数； //$displaypg：每页显示信息数，这里设置为默认是20； //$url：分页导航中的链接，除了加入不同的查询信息“page”外的部分都与这个URL相同。 //　　　默认值本该设为本页URL（即$_SERVER[\"REQUEST_URI\"]），但设置默认值的右边只能为常量，所以该默认值设为空字符串，在函数内部再设置为本页URL。 function pageft($totle,$displaypg=20,$shownum=0,$showtext=0,$showselect=0,$showlvtao=7,$url=''){ //定义几个全局变量： //$page：当前页码； //$firstcount：（数据库）查询的起始项； //$pagenav：页面导航条代码，函数内部并没有将它输出； //$_SERVER：读取本页URL“$_SERVER[\"REQUEST_URI\"]”所必须。 global $page,$firstcount,$pagenav,$_SERVER; //为使函数外部可以访问这里的“$displaypg”，将它也设为全局变量。注意一个变量重新定义为全局变量后，原值被覆盖，所以这里给它重新赋值。 $GLOBALS[\"displaypg\"]=$displaypg; if(!$page) $page=1; //如果$url使用默认，即空值，则赋值为本页URL： if(!$url){ $url=$_SERVER[\"REQUEST_URI\"];} //URL分析： $parse_url=parse_url($url); @$url_query=$parse_url[\"query\"]; //单独取出URL的查询字串 if($url_query){ //因为URL中可能包含了页码信息，我们要把它去掉，以便加入新的页码信息。 //这里用到了正则表达式，请参考“PHP中的正规表达式” $url_query=ereg_replace(\"(^|&)page=$page\",\"\",$url_query); //将处理后的URL的查询字串替换原来的URL的查询字串： $url=str_replace($parse_url[\"query\"],$url_query,$url); //在URL后加page查询信息，但待赋值： if($url_query) $url.=\"&page\"; else $url.=\"page\"; }else { $url.=\"?page\"; } //页码计算： $lastpg=ceil($totle/$displaypg); //最后页，也是总页数 $page=min($lastpg,$page); $prepg=$page-1; //上一页 $nextpg=($page==$lastpg ? 0 : $page+1); //下一页 $firstcount=($page-1)*$displaypg; //开始分页导航条代码： if ($showtext==1){ $pagenav=\"<span class='disabled'>\".($totle?($firstcount+1):0).\"-\".min($firstcount+$displaypg,$totle).\"/$totle 记录<\/span><span class='disabled'>$page/$lastpg 页<\/span>\"; }else{ $pagenav=\"\"; } //如果只有一页则跳出函数： if($lastpg<=1) return false; if($prepg) $pagenav.=\"<a href='$url=1'>首页<\/a>\"; else $pagenav.='<span class=\"disabled\">首页<\/span>'; if($prepg) $pagenav.=\"<a href='$url=$prepg'>上一页<\/a>\"; else $pagenav.='<span class=\"disabled\">上一页<\/span>'; if ($shownum==1){ $o=$showlvtao;//中间页码表总长度，为奇数 $u=ceil($o/2);//根据$o计算单侧页码宽度$u $f=$page-$u;//根据当前页$currentPage和单侧宽度$u计算出第一页的起始数字 //str_replace('{p}',,$fn)//替换格式 if($f<0){$f=0;}//当第一页小于0时，赋值为0 $n=$lastpg;//总页数,20页 if($n<1){$n=1;}//当总数小于1时，赋值为1 if($page==1){ $pagenav.='<span class=\"current\">1<\/span>'; }else{ $pagenav.=\"<a href='$url=1'>1<\/a>\"; } /////////////////////////////////////// for($i=1;$i<=$o;$i++){ if($n<=1){break;}//当总页数为1时 $c=$f+$i;//从第$c开始累加计算 if($i==1 && $c>2){ $pagenav.='...'; } if($c==1){continue;} if($c==$n){break;} if($c==$page){ $pagenav.='<span class=\"current\">'.$page.'<\/span>'; }else{ $pagenav.=\"<a href='$url=$c'>$c<\/a>\"; } if($i==$o && $c<$n-1){ $pagenav.='...'; } if($i>$n){break;}//当总页数小于页码表长度时 } if($page==$n && $n!=1){ $pagenav.='<span class=\"current\">'.$n.'<\/span>'; }else{ $pagenav.=\"<a href='$url=$n'>$n<\/a>\"; } } if($nextpg) $pagenav.=\"<a href='$url=$nextpg'>下一页<\/a>\"; else $pagenav.='<span class=\"disabled\">下一页<\/span>'; if($nextpg) $pagenav.=\"<a href='$url=$lastpg'>尾页<\/a>\"; else $pagenav.='<span class=\"disabled\">尾页<\/span>'; if ($showselect==1){ //下拉跳转列表，循环列出所有页码： $pagenav.=\"跳至<select name='topage' size='1' onchange='window.location.href=this.value'>\\n\"; for($i=1;$i<=$lastpg;$i++){ if($i==$page) $pagenav.=\"<option value='page.php?page=$i' selected>\".$i.\"<\/option>\\n\"; else $pagenav.=\"<option value='page.php?page=$i'>\".$i.\"<\/option>\\n\"; } $pagenav.=\"<\/select>页\"; } } } ?> page页面  复制代码 <?php include_once('pagelist.php');?> <style> /*总容器样式*/ .pager { padding: 3px; text-align: right; color:#66C;font-size:12px; font-family:Tahoma;} /*分页链接样式*/ .pager a { margin: 2px; padding:2px 5px; color: #66C; text-decoration: none; border: 1px solid #aad; } /*分页链接鼠标移过的样式*/ .pager a:hover { color: #000; border: 1px solid #009; background-color:#DCDCF3; } /*当前页码的样式*/ .pager span.current { font-weight: bold; margin: 0 2px; padding: 2px 5px; color: #000; background- color: #66C; border: 1px solid #009; } /*不可用分页链接的样式(比如第1页时的“上一页”链接)*/ .pager span.disabled { margin: 0 2px; padding: 2px 5px; color: #CCC; border: 1px solid #DDD; } /*跳转下拉菜单的样式*/ .pager select {margin: 0px 2px -2px 2px; color:#66C;font-size:12px; font-family:Tahoma;} /*跳转文本框的样式*/ .pager input {margin: 0px 2px -2px 2px; color:#66C; border: 1px solid #DDD; padding:2px; text- align:center;font-size:12px; font-family:Tahoma;} <\/style> <?php error_reporting(E_ALL & ~E_NOTICE); //屏蔽notice错误提示 $pageSize=3; mysql_connect('localhost','root','') or die(\"数据库链接错误\"); mysql_select_db('sctopway'); mysql_query(\"set names 'gb2312'\"); $row = mysql_query(\"select count(*) as cou from top_chuangyi\"); $arr = mysql_fetch_array($row); $total=$arr['cou']; //数据总数 //$startRow1 = 0 ? intval($startRow/$pageRow) + 1 : intval($_GET['startRow']/$pageRow)+1; $page = $_GET['page'];//获取到的页码 $start = ($pageSize * $page)-$pageSize; //每页显示的条数*页码 $row1 = mysql_query(\"SELECT * FROM `top_chuangyi` order by id LIMIT $start , $pageSize\"); $top = array(); $i = 0; while($arr1 = mysql_fetch_array($row1)){ $top[$i]['id'] = $arr1['id']; $top[$i]['b_title']=$arr1['b_title']; $top[$i]['content']=$arr1['content']; $i++; // var_dump($top); } pageft($total,$pageSize,1,1,1,2); ?> <div class=\"pager\"> <ul> <?php for($i=0;$i<=$pageSize-1;$i++){ echo '<li>所属ID：'.$top[$i]['id'].'        所属类别：'.$top[$i]['b_title'].'        主要内容：'.$top[$i]['content'].'<\/li><br />'; } ?> <\/ul> <\/div> <div class=\"pager\"><?php echo $pagenav;?><\/div>","title":"PHP经典分页代码-带数据库文件及实例-复制下来就能用"},{"content":"1.  主要类与接口 Hibernate。Hibernate通过Configuration的实例加载配置文件信息，然后读取指定对象关系映射文件的内容并创建SessionFactory实例。 SessionFactory接口   负责初始化Hibernate。一个SessionFactory实例对应一个数据库。应用程序从SessionFactory中获得Session实例。 Session接口    Session被称为持久化管理器，负责管理与持久化相关的操作：存储、更新、删除和加载对象。 Transaction接口 是Hibernate框架的事务接口。它对底层的事务接口做了封装。包括：JDBC API和JTA。 2. Session的缓存（一级缓存） Session的CRUD方法以及调用查询接口的list()，iterate()方法时，如果session缓存中不存在相应的对象，Hibernate就会把该对象加入到第一级缓存中，如果session缓存中已经存在这个对象，就不需在去数据库加载，而直接使用缓存中的对象。 flush: 进行清理缓存(此时缓存中的数据并不丢失)的操作,让缓存和数据库同步 执行一些列sql语句，但不提交事务,； commit:先调用flush() 方法，然后提交事务. 则意味着提交事务意味着对数据库操作永久保存下来。   session的缓存一般交由hibernate框架自动管理。 3.  Session的几个主要方法    1）、save保存数据,相当于insert方法    2)、delete,删除对象    3)、update,更新对象，如果数据库中没有记录，会出现异常。    4)、get,根据ID查，会立刻访问数据库。    5)、Load，根据ID查，(返回的是代理，不会立即访问数据库)。    6)、saveOrUpdate (根据ID和version的值来确定是save或update 4.主键id的属性值：取值标示符取值器 注：increment是mysql数据库，identity是oracle数据库，Sequence是sql server；最常用的是native，因为该属性可以自行判断是什么数据库而只能的调用相应数据库标示符 5.  一个运用hibernate写的增删改查例子 自己手动编写的一个工具类  Hibernate.javapackage com.hbsi.utils;import org.hibernate.Session;import org.hibernate.SessionFactory;import org.hibernate.cfg.Configuration; public class HibernateUtil {      private static Session session;   static{      Configuration cfg = new Configuration().configure();      SessionFactory factory = cfg.buildSessionFactory();      session = factory.openSession();   }    public static Session getSession(){      return session;    }    public static void close(){      if(session!=null){        session.close();      }    }}增删改查类 UtilTest.java:package com.hbsi.test; import java.util.Date;import java.util.List; import org.hibernate.Query;import org.hibernate.Session;import org.junit.Test; import com.hbsi.domain.User;import com.hbsi.utils.HibernateUtil; public class UtilTest {   @Test   public void addUser(){            User user = new User();      user.setName(\"lisi\");      user.setBirthday(new Date());      try{        Session session = HibernateUtil.getSession();        session.beginTransaction();        session.save(user);        session.getTransaction().commit();      }catch(Exception e){        e.printStackTrace();      }finally{        HibernateUtil.close();      }         }   @Test   public void deleteUser(){      try{        //方法一：先查找，再操作        /*Session session = HibernateUtil.getSession();        session.beginTransaction();        User user = (User)session.get(User.class, 1);        session.delete(user);        session.getTransaction().commit();*/        //方法二：直接new出bean类，然后指明要删除的id        Session session = HibernateUtil.getSession();        session.beginTransaction();        User user = new User();        user.setId(2);        session.delete(user);        session.getTransaction().commit();      }catch(Exception e){        e.printStackTrace();      }finally{        HibernateUtil.close();      }         }   @Test   public void updateUser(){      try{        //方法一：先查找，再操作        /*Session session = HibernateUtil.getSession();        session.beginTransaction();        User user = (User)session.get(User.class, 2);        user.setName(\"lisi\");        session.update(user);        session.getTransaction().commit();*/        //方法二：直接new出bean类，然后指明要更新的id,这种方法适合删除不适合更新，比如你只更新名字字段，其他的字段就会变成空        Session session = HibernateUtil.getSession();        session.beginTransaction();        User user = new User();        user.setId(2);        user.setName(\"利索\");        session.update(user);        session.getTransaction().commit();      }catch(Exception e){        e.printStackTrace();      }finally{        HibernateUtil.close();      }         }   //按id查找;get()方法会立刻访问数据库；load()方法返回的是代理，不会立即访问数据库   @Test   public void findUser(){            try{        Session session = HibernateUtil.getSession();        User user = (User)session.get(User.class, 1);         System.out.println(user.getId()+\"----\"+user.getName()+\"----\"+user.getBirthday());      }catch(Exception e){        e.printStackTrace();      }finally{        HibernateUtil.close();      }   }   //按id查找,懒加载;之所以说懒，是因为这里的load（）方法与上面的get（）方法有所不同，前者只有在使用load（）方法返回的对象时才去执行sql语句，不使用不执行；而后者不一样，它不管什么时候都执行   @Test   public void loadUser(){            try{        Session session = HibernateUtil.getSession();        User user = (User)session.load(User.class, 1);         System.out.println(user.getId()+\"----\"+user.getName()+\"----\"+user.getBirthday());      }catch(Exception e){        e.printStackTrace();      }finally{        HibernateUtil.close();      }   }   //查找所有   @Test   public void findAll(){            try{        Session session = HibernateUtil.getSession();        Query query = session.createQuery(\"from User\");        List<User> list = query.list();        for(User user : list){                    System.out.println(user.getId()+\"----\"+user.getName()+\"----\"+user.getBirthday());        }      }catch(Exception e){        e.printStackTrace();      }finally{        HibernateUtil.close();      }   }}  ","title":"心得2-hibernate入门2"},{"content":"搭几年的数据库，总结一下，以备后用 说在前面：此文档是应需现网将相关数据库导回进行测试数据库搭建出的。 搭建数据库： 查看表空间，数据文件： SELECT * FROM DBA_TABLESPACES; SELECT * FROM DBA_DATA_FILES;   a、  新建表空间：具体见表空间 /*  Before run the script, please modify the file's path, name and size.  To run the script, connect as a user with SYSDBA privilege. */ CREATE TABLESPACE TBS_ICD3_PUB_BJ DATAFILE '/opt/oracle/app/oradata/ora11g/tablespace/tbs_csp30_beijing_01' SIZE 2000M REUSE AUTOEXTEND OFF,          '/opt/oracle/app/oradata/ora11g/tablespace/tbs_csp30_beijing_02' SIZE 500M REUSE AUTOEXTEND ON   LOGGING ONLINE PERMANENT EXTENT MANAGEMENT LOCAL AUTOALLOCATE SEGMENT SPACE MANAGEMENT AUTO; --DROP TABLESPACE TBS_CSP_PUB_TIGO INCLUDING CONTENTS AND DATAFILES; CREATE TEMPORARY TABLESPACE TBS_ICD3_PUB_BJ_TMP TEMPFILE '/opt/oracle/app/oradata/ora11g/tablespace/tbs_csp30_beijing_03' SIZE 500M REUSE AUTOEXTEND on EXTENT MANAGEMENT LOCAL UNIFORM SIZE 10M;   b、  建用户 CREATE USER ICD_BJ IDENTIFIED BY icd   DEFAULT TABLESPACE TBS_ICD3_PUB_BJ   TEMPORARY TABLESPACE TBS_ICD3_PUB_BJ_TMP   PROFILE DEFAULT; GRANT EXP_FULL_DATABASE     TO ICD_BJ; GRANT IMP_FULL_DATABASE     TO ICD_BJ; GRANT CONNECT               TO ICD_BJ; GRANT RESOURCE              TO ICD_BJ; GRANT UNLIMITED TABLESPACE  TO ICD_BJ; -- If the version is 10g or 11g, please delete the double hyphen (--) in the following two lines. GRANT DEBUG CONNECT SESSION TO ICD_BJ; GRANT DEBUG ANY PROCEDURE TO ICD_BJ;   c、  然后用上面的用户登录，将现网导回的对象导入即可。   1、用PL\\SQL导出域对象，具体操作：Tools----Export User Objects      只需要选择Single file一个选项，其他都不要选。   2、导表数据，具体操作：Tools----Export Tables      表数据用SQL格式导出，复选框都不选， commit record 1000条， where 过滤 ROWNUM < 10000 ， 10000 数目自己定。如果需要将全部数据导出where过滤条件不需要。   3、上面两个文件导回来后进行环境搭建，导入域：直接在command窗口， @ 回车选择文件就行了。   4、 导入表数据：表数据导入的时候一定要用 tools --> import table，选择导入文件即可。用command窗口执行很慢。    ","title":"数据库的迁移"},{"content":"1.两个数据库之间数据表的复制: select * into [dbnameA]..[tablenameA] from [dbnameB]..[tablenameB]","title":"MSSQL操作"},{"content":"1.数据库的数据存储 　　1.1文件： 　　我们一旦创建一个数据库，都会生成两个文件： 　　DataBaseName.mdf: 主文件，这是数据库中的数据最终存放的地方。 　　DataBaseName.ldf:日志文件，由数据操作产生的一系列日志记录。 　　1.2分区： 　　在一个给定的文件中，为表和索引分配空间的基本存储单位。 1个区占64KB,由8个连续的页组成。 如果一个分区已满，但需存一条新的记录，那么该记录将占用整个新分区的空间。 　　1.3 页： 　　分区中的一个分配单位。这是实际数据行最终存放的地方。 页用于存储数据行。 　　Sql Server有多种类型的页： 　　Data, Index,BLOB,GAM(Global Allocation Map),SGAM,PFS(Page Free Space),IAM(Index Allocation Map),BCM(Bulk Changed Map)等。 　　2. 索引 　　2.1.1索引 　　索引是与表或视图关联的磁盘上结构，可以加快从表或视图中检索行的速度。索引包含由表或视图中的一列或多列生成的键。这些键存储在一个结构(B 树)中，使 SQL Server 可以快速有效地查找与键值关联的行。 　　通俗点说，索引与表或视图相关，旨在加快检索速度。索引本身占据存储空间，通过索引，数据便会以B树形式存储。因此也加快了查询速度。 　　2.1.2聚集索引 　　聚集索引根据数据行的键值在表或视图中排序和存储这些数据行。索引定义中包含聚集索引列。每个表只能有一个聚集索引，因为数据行本身只能按一个顺序排序。只有当表包含聚集索引时，表中的数据行才按排序顺序存储。如果表具有聚集索引，则该表称为聚集表。如果表没有聚集索引，则其数据行存储在一个称为堆的无序结构中。 　　通俗点说，聚集索引的页存储的是实际数据。每个表只能建立唯一的聚集索引，但也可以没有。 　　如果建立聚集索引，那么表中数据以B树形式存储数据。 　　对于聚集索引的理解，打个比方，即英文字典的单词编排。 英文字典单词以A,B,C,D….X,Y,Z的形式顺序编排，如果我们查找 Good 单词，我们首先定位到G，然后定位o – o-d. 最终查找到Good，便是good实际存在的地方。 　　建聚集索引需要至少相当该表120%的附加空间，以存放该表的副本和索引中间页。 　　2.1.3非聚集索引 　　非聚集索引具有独立于数据行的结构。非聚集索引包含非聚集索引键值，并且每个键值项都有指向包含该键值的数据行的指针。 　　从非聚集索引中的索引行指向数据行的指针称为行定位器。行定位器的结构取决于数据页是存储在堆中还是聚集表中。对于堆，行定位器是指向行的指针。对于聚集表，行定位器是聚集索引键。 　　通俗点说，非聚集索引的页存储的是不是实际数据，而是实际数据的地址。一个表可以存在多个非聚集索引。在Sql Server2005中，每个表最多可以建立249个，而在Sql server2008中，则最多可以建立999个非聚集索引。 　　对于非聚集索引的理解，即新华字典的“偏旁部首”查字法。遇到您不认识的字，不知道它的发音，这时候，您就不能按照刚才的方法找到您要查的字，而需要去根据“偏旁部首”查到您要找的字，然后根据这个字后的页码直接翻到某页来找到您要找的字。但您结合“部首目录”和“检字表”而查到的字的排序并不是真正的正文的排序方法，比如您查“张”字，我们可以看到在查部首之后的检字表中“张”的页码是672页，检字表中“张”的上面是“驰”字，但页码却是63页，“张”的下面是“弩”字，页面是390页。很显然，这些字并不是真正的分别位于“张”字的上下方，现在您看到的连续的“驰、张、弩”三字实际上就是他们在非聚集索引中的排序，是字典正文中的字在非聚集索引中的映射。我们可以通过这种方式来找到您所需要的字，但它需要两个过程，先找到目录中的结果，然后再翻到您所需要的页码。我们把这种目录纯粹是目录，正文纯粹是正文的排序方式称为“非聚集索引”。 　　2.1.4 覆盖索引： 　　覆盖索引是指那些索引项中包含查寻所需要的全部信息的非聚集索引，这种索引之所以比较快也正是因为索引页中包含了查寻所必须的数据,不需去访问数据页。 如果非聚簇索引中包含结果数据,那么它的查询速度将快于聚集索引。 　　但是由于覆盖索引的索引项比较多,要占用比较大的空间。而且update 操作会引起索引值改变。所以如果潜在的覆盖查询并不常用或不太关键，则覆盖索引的增加反而会降低性能。 　　2.1.5 主键和索引 　　主键：表通常具有包含唯一标识表中每一行的值的一列或一组列。这样的一列或多列称为表的主键 (PK)，用于强制表的实体完整性。在创建或修改表时，您可以通过定义 PRIMARY KEY 约束来创建主键。 它是一种唯一索引。 　　下面是一个简单的比较表 　　主键聚集索引 　　用途强制表的实体完整性对数据行的排序，方便查询用 　　一个表多少个一个表最多一个主键一个表最多一个聚集索引 　　是否允许多个字段来定义一个主键可以多个字段来定义一个索引可以多个字段来定义 　　是否允许 null 数据行出现如果要创建的数据列中数据存在null，无法建立主键。 　　创建表时指定的 PRIMARY KEY 约束列隐式转换为 NOT NULL。没有限制建立聚集索引的列一定必须 not null . 　　也就是可以列的数据是 null 　　参看最后一项比较 　　是否要求数据必须唯一要求数据必须唯一数据即可以唯一，也可以不唯一。看你定义这个索引的 UNIQUE 设置。 　　(这一点需要看后面的一个比较，虽然你的数据列可能不唯一，但是系统会替你产生一个你看不到的唯一列) 　　创建的逻辑数据库在创建主键同时，会自动建立一个唯一索引。 　　如果这个表之前没有聚集索引，同时建立主键时候没有强制指定使用非聚集索引，则建立主键时候，同时建立一个唯一的聚集索引如果未使用 UNIQUE 属性创建聚集索引，数据库引擎 将向表自动添加一个四字节 uniqueifier 列。 　　必要时，数据库引擎 将向行自动添加一个 uniqueifier 值，使每个键唯一。此列和列值供内部使用，用户不能查看或访问。 　　2.2 索引的存储结构 　　2.1.1 整表扫描和索引扫描 　　整表扫描和索引扫描是Sql Server数据库检索到数据的唯一的两种方式。除此之外，没有第三种方式供Sql Server检索到数据。 　　整表扫描 　　最直接的检索方式， Sql Server进行表扫描时，会从表头开始扫描，直到整个表结束。 当找到符合条件的记录，便把该记录存在结果集中。对于小数据量的表，这是一种很快捷的方式。如果没有为表创建索引，那么Sql server便按这种方式检索数据。 　　索引扫描 　　如果为表创建了索引，在进行检索前，Sql Server优化器会根据查询条件，从可用的索引中选择最优化的索引。检索时，便会遍历B树，当找到符合条件的记录，便把该记录存在结果集中。因此，检索大数据量的表，使用索引相对于整表扫描会显著地提高性能。 　　2.1.2 B-Tree 　　2.2.3 聚集索引 　　叶子节点存放的是实际的数据。索引的入口点存放在master->sys.indexes中。 　　2.2.4 非聚集索引 　　2.4.1 堆上的非聚集索引(Non-clustered index on heap) 　　与聚集索引很类似。 　　不同处在： 　　叶子节点存放的不是实际数据，而是指向实际数据的指针。检索速度非常接近于聚集索引，比起聚集索引，实际上只是多一步由根据指针检索到实际数据的过程。 　　2.4.2 聚集表上的非聚集索引 3. 管理索引 　　3.1 创建 　　CREATE [UNIQUE] [CLUSTERED|NONCLUSTERED] 　　INDEX ON >( [ASC|DESC] [,...n]) 　　INCLUDE ( [, ...n]) 　　[WITH 　　[PAD_INDEX = { ON | OFF }] 　　[[,] FILLFACTOR = ] 　　[[,] IGNORE_DUP_KEY = { ON | OFF }] 　　[[,] DROP_EXISTING = { ON | OFF }] 　　[[,] STATISTICS_NORECOMPUTE = { ON | OFF }] 　　[[,] SORT_IN_TEMPDB = { ON | OFF }] 　　[[,] ONLINE = { ON | OFF } 　　[[,] ALLOW_ROW_LOCKS = { ON | OFF } 　　[[,] ALLOW_PAGE_LOCKS = { ON | OFF } 　　[[,] MAXDOP = 　　] 　　[ON { | | DEFAULT }] 　　3.2 修改 　　ALTER INDEX { | ALL } 　　ON > 　　{ REBUILD 　　[ [ WITH ( 　　[ PAD_INDEX = { ON | OFF } ] 　　| [[,] FILLFACTOR = 　　| [[,] SORT_IN_TEMPDB = { ON | OFF } ] 　　| [[,] IGNORE_DUP_KEY = { ON | OFF } ] 　　| [[,] STATISTICS_NORECOMPUTE = { ON | OFF } ] 　　| [[,] ONLINE = { ON | OFF } ] 　　| [[,] ALLOW_ROW_LOCKS = { ON | OFF } ] 　　| [[,] ALLOW_PAGE_LOCKS = { ON | OFF } ] 　　| [[,] MAXDOP = 　　) ] 　　| [ PARTITION = 　　[ WITH ( 　　[ ,...n ] ) ] ] ] 　　| DISABLE 　　| REORGANIZE 　　[ PARTITION = ] 　　[ WITH ( LOB_COMPACTION = { ON | OFF } ) ] 　　| SET ([ ALLOW_ROW_LOCKS= { ON | OFF } ] 　　| [[,] ALLOW_PAGE_LOCKS = { ON | OFF } ] 　　| [[,] IGNORE_DUP_KEY = { ON | OFF } ] 　　| [[,] STATISTICS_NORECOMPUTE = { ON | OFF } ] 　　) 　　} [ ; ] 　　3.3 删除 　　DROP INDEX >. 　　4. 使用索引应注意十么 　　1)聚集索引通常速度优于非聚集索引 　　2) 建索引时应考虑是否有足够的空间。索引占据空间,平均约1.2倍数据库本身大小。 　　3) 在经常用于查询或聚合条件的字段上建立聚集索引。这类查询条件包括 between, >, <,group by, max,min, count等。 　　4) 不要在经常作为插入，且插入字段无序的列上建立聚集索引。 插入数据行会涉及分页，rebuild索引会消耗大量时间。参考文末\"一个不恰当使用聚集索引的例子\"。 　　5) 在值高度的唯一性字段上建立索引。不能在诸如性别的字段上建立索引。 　　6) 只有作为索引的第一个列包含在查询条件中，该索引才的作用。 　　打个比方，我们用偏旁+部首来查汉字，那么偏旁首先必须包括在查询条件中，只有先定位偏旁，再结合部首，才能发挥偏旁+部首来检索的快速功效。 　　7) 删除一直不用的索引。特别是对于删除和修改比较频繁的数据表，必须考虑如何精华索引。","title":"数据库索引 你该了解的几件事"},{"content":"1.对Oracle数据库进行描述时我们更愿意将它拆成两部分，一部分是内存加后台进程，这部分称为Oracle的实例部分，另一部分是存放在磁盘中的文件，称作数据库。 2.凡是使用DB Link进行的业务操作，我们都称为分布式事务，这种事务是由Oracle来协调处理的，对用户来说是透明的。 3.分布式数据库之间要保证数据库间字符集一致，Oracle的建议是： ~客户端的字符集要等于数据库字符集或者子集 ~多个数据库中最好设置成相同的，如果有特殊情况，那么数据库之间要保证字符集是被包含的关系。 4.Data Guard容灾数据库 5.ASM 自动存储管理 6.expdp：导出表空间的数据文件时要注意表空间中的对象并非自包含，自包含的意思是不会被表空间以外的对象引用，比如表空间中的分区是表空间外的表的一个分区，或表空间中的对象被表空间外的对象引用等。 7.导出表空间的步骤： 通过表空间的方式进行备份，表空间导出的前提是要将表空间的状态设置为Read-Only状态，如果表空间上存储的是非分区表，通常很难将整个表设置为只读的，所以是不可行的：     <1>将表分区和分区索引（如果有）创建到单独的表空间上     <2>将需要备份的表分区以及分区索引所在的表空间设置为只读     <3>将需要导出的分区和分区索引与一个临时表以及索引进行分区交换     <4>对需要备份的临时表以及索引以导出表空间的方式进行备份     <5>复制表空间的文件，并与导出的文件一起保存 create directory tts as 'E:\\';                                           expdp test/test directory=tts dumpfile = tts_p1.dmp transport_datafiles = (p1, p1_idx) logfile=tts_p1.log; 导入表空间是导出表空间的逆过程 8.对加载数据进行备份：SQL*Loader 9.对于内存相关参数的建议：PGA    SGA     Share Pool 10. I/O相关的参数DB_FILE_MULTIBLOCK_READ_COUNT 11.OLAP可以将DB_FILE_MULTIBLOCK_READ_COUNT设置大些反之OLTP数据库中用户每次读取的值并不多，所以可以考虑设置得小一些，要注意只有在以下两种情况多数据块的读取才会发生：     <1>FTS (FULL TABLE SCAN)     <2>INDEX_FFS (INDEX FAST FULL SCAN) 12.DB_FILES用来约束数据库可以打开的文件数，默认200，如果修改这个参数必须重启数据库才能生效，所以要预先考虑好需要设置的值大小。 13.OPTIMIZER_DYNAMIC_SAMPLING     oracle的动态采样级别有9个 在OLAP中建议采用Level 3或4，而OLTP中建议不适用动态采样技术。 14.出现乱码的两种情况：     <1>输入操作的OS字符编码和查询的OS字符集编码不一致     ​<2>输入的客户端字符集和查询客户端的字符集不同。","title":"【Oracle】杂记"},{"content":"MySQL支持单向、异步复制，复制过程中一个服务器充当主服务器，而一个或多个其它服务器充当从服务器。主服务器将更新写入二进制日志文件，并维护日志文件的一个索引以跟踪日志循环。当一个从服务器连接到主服务器时，它通知主服务器从服务器在日志中读取的最后一次成功更新的位置。从服务器接收从那时起发生的任何更新，然后封锁并等待主服务器通知下一次更新。 配置主主同步的操作步骤： MySQL-A     10.17.1.11 MySQL-B     10.17.1.12 1.     分别在两台机器授权账户：grant replication slave, file, select on *.* to 'repl'@'10.17.%' identified by ‘xxxx’  备注：如果想要在Slave上有权限执行 \"LOAD TABLE FROM MASTER\" 或 \"LOAD DATA FROM MASTER\" 语句的话，必须授予全局的 FILE 和 SELECT 权限。 2.     配置文件/etc/my.cnf，在使用主库配置文件的基础上，加入以下配置项 MySQL-A     MySQL-B log-bin=mysql-bin log-bin=mysql-bin server-id=1 server-id=2 binlog-do-db=TestXXX binlog-do-db=TestXXX binlog-ignore-db=mysql binlog-ignore-db=mysql replicate-do-db=TestXXX replicate-do-db=TestXXX replicate-ignore-db=mysql replicate-ignore-db=mysql log-slave-updates log-slave-updates slave-skip-errors=all slave-skip-errors=all auto_increment_increment=2 auto_increment_increment=2 auto_increment_offset=1 auto_increment_offset=2 备注： log-slave-updates是为从库的写操作记录binlog 多主互备和主从复制有一些区别，因为多主中的各个库，都可以对服务器有写权限，所以设计到自增长重复问题 模拟出现的问题（多主自增长ID重复） 假如我们在AB都建立一张test表，表中有一个auto increment的字段 停掉A的同步，在B上对数据表test(存在自增长ID)执行插入操作，返回插入ID为1 然后停掉B的同步，在A上对数据表test(存在自增长ID)执行插入操作，返回的插入ID也是1 然后同时启动A,B，就会出现主键ID重复 解决方法： 我们只要保证两台服务器上插入的自增长数据不同就可以了 如：A插入奇数ID，B插入偶数ID，当然如果服务器多的话，你可以定义算法，只要不同就可以了 在这里我们在A,B上加入参数，以实现奇偶插入 A：my.cnf上加入参数 auto_increment_increment=2 auto_increment_offset=1 这样A的auto_increment字段产生的数值是：1, 3, 5, 7, …等奇数ID了 B：my.cnf上加入参数 auto_increment_increment=2 auto_increment_offset=2 这样B的auto_increment字段产生的数值是：2, 4, 6, 8, …等偶数ID了 可以看出，你的auto_increment字段在不同的服务器之间绝对不会重复，所以Master-Master结构就没有任何问题了。当然，你还可以使用3台，4台，或者N台服务器，只要保证auto_increment_increment = N 再设置一下auto_increment_offset为适当的初始值就可以了，那样，我们的MySQL可以同时有几十台主服务器，而不会出现自增长ID重复。           3.     重启MySQL读取新的配置文件，进入MySQL后，用change master命令进行同步即可。","title":"MySQL 主主（双主）复制"},{"content":"在我看来分析数据库表是为了获取表的统计信息，以便数据库在对表进行查询等操作的时候选择正确的执行路径，那么什么时候需要对数据库表进行分析呢？在我看来主要是下面的情况： 1.数据以分区交换的方式加载到数据库中，并且在加载入库后不再改变。     这种情况最好是在交换之后再进行分析，因为如果先分析临时表之后再交换，那么交换之后临时表中的分析信息只是作为分区表的分区信息交换进去，而分区表的全局信息并没有更新。分区表的全局信息可以在这两个表（表与索引）中查到： SELECT * FROM USER_TABLES;SELECT * FROM USER_INDEXES; 在未分析之前大多数字段是空的，你可以使用下面的语句对表进行分析： ANALYZE TABLE TABLENAME COMPUTE STATISTICS;ANALYZE INDEX | CLUSTER INDEXNAME ESTIMATE STATISTICS; 或者使用工具包（对于分区表推荐使用工具包，可以满足不同的需求，得到整个分区表或者单个分区的数据，在不同级别上对分区表进行统计，但是不能收集CHAINED ROWS和CLUSTER TABLE的信息）： DBMS_STATS.GATHER_SCHEMA_STATS(USER, ESTIMATE_PERCENT => 100, CASCADE => TRUE);DBMS_STATS.GATHER_TABLE_STATS(USER, TABLENAME, DEGREE => 4, CASCADE => TRUE); 单个分区的分区信息可以在下面的两个表（表与索引）中查到： SELECT * FROM USER_TAB_PARTITIONS;SELECT * FROM USER_IND_PARTITIONS; 全局的分析信息在跨分区查询的时候显得尤为重要，这也是推荐我们在进行分区交换之后再对表进行分析的原因。 2.第二种需要对表进行分析的情况是：数据存在表中并且经常改变。","title":"【Oracle】对表的的分析"},{"content":"    想实现的效果就是动态生成数据，例如每一篇博客的文章名动态生成，然后点击博客名能进入指定的文章。 知识有限，未学GridView的数据绑定控件，只能用现有的知识实现。 后台提取数据放到指定的table中，显示在页面上，然后再点击页面的文章题目进入到文章内容，但是table是动态生成，所以后台不能用id调用，只能用js才能访问到， 动态提取数据放到table请看我的另一篇文章《用table，js实现web动态取数据并实现分页效果》 每个table存储一个文章的简单信息，例如包括文章名作者还有简单的内容展示，即像csdn的文章页面。后台将数据的总条数赋值给Button1，前台用js为每个table添加点击事件，而每个事件都会触法页面上一个button的点击事件，而button可以控制后台程序，button的功能就是讲页面TextBox的text值传给Session，并跳转页面，在新的页面去的session中保存的id值，查询数据库并返回， 总体过程   打通前台后台 后台动态生成table-------前台为table动态添加事件---事件功能是改变页面上TextBox的Text的值并且触法页面上Button的点击事件-----button的功能是将Text的值赋值给Session----- 在新页面取得Session的值并查询数据库 function wenzhang() {     var q2 = document.getElementById(\"Button1\");//button的属性存储着数据库中数据的条数，     var bq2 = document.getElementById(\"TextBox1\");//改变TextBox的text的值     x = q2.defaultValue;         for(var i = 1; i <= x; i++) {         var on = document.getElementById(\"t\" + i + \"\");//后台每个table的id都是tx，x为数字;              on.name = i.toString();              on.onclick = function xxx1() {//为每个table 添加js的点击事件                  bq2.value = this.name;//this.name中存储的是激发此事件的table的name，name中存储着每条数据对应的id，并且赋值给Textbox的text                   document.getElementById(\"Button1\").click();//页面文章名称不允许有button所以不能在后台动态添加事件，这里是创建了一个button，用它控制后台                                      }     }    ","title":"后台动态生成文章名，前台js实现点文章名进入指定文章，打通前台与后台的操作。"},{"content":"1、DUAL表的用途 Dual 是Oracle中的一个实际存在的表，任何用户均可读取，常用在没有目标表的Select语句块中 --查看当前连接用户 Connected to Oracle Database 10g Enterprise Edition Release 10.1.0.2.0 Connected as SYS SQL> select user from dual; USER ------------------------------ SYSTEM --查看当前日期、时间 SQL> select systimestamp from dual; SYSTIMESTAMP -------------------------------------------------------------------------------- 09-3月 -1111.11.05.901000上午+08:00 SQL> select to_char(sysdate,'yyyy-mm-dd hh24:mi:ss') from dual; TO_CHAR(SYSDATE,'YYYY-MM-DDHH2 ------------------------------ 2011-03-09 11:12:03 --当作计算器用 SQL> select 1+2 from dual;        1+2 ----------          3 --查看序列值 SQL> create sequence a increment by 1 start with 1; Sequence created SQL> select a.nextval from dual;    NEXTVAL ----------          1 SQL> select a.currval from dual;    CURRVAL ----------          1 SQL> drop sequence a; Sequence dropped 2、关于DUAL表的测试与分析 DUAL就是个一行一列的表，如果你往里执行insert、delete、truncate操作，就会导致很多程序出问题。结果也因sql*plus、pl/sql dev等工具而异。 --查看DUAL是什么OBJECT --DUAL是属于SYSschema的一个表,然后以PUBLIC SYNONYM的方式供其他数据库USER使用. 先格式化列标题和列数据的现实格式： SQL> clear columns; SQL> COLUMN owner HEADING FORMAT a10 WORD_WRAPPEND SQL> COLUMN object_name HEADING FORMAT a15 WORD_WRAPPEND SQL> COLUMN object_type HEADING FORMAT a15 WORD_WRAPPEND SQL> select owner,object_name,object_type from dba_objects where object_namelike '%DUAL%'; OWNER      OBJECT_NAME    OBJECT_TYPE ---------- --------------- --------------- SYS       DUAL            TABLE PUBLIC    DUAL            SYNONYM SQL> clear columns; --查看表结构，只有一个字段DUMMY，为VARCHAR2(1)型 SQL> desc dual; Name  Type        Nullable DefaultComments ----- ----------- -------- ------- -------- DUMMY VARCHAR2(1) Y --DUAL表的结构： create table SYS.DUAL (   DUMMY VARCHAR2(1) ) tablespace SYSTEM   pctfree 10   pctused 40   initrans 1   maxtrans 255   storage   (     initial 16K     next 16K     minextents 1     maxextents 505     pctincrease 50   ); /* 很是困惑，ORACLE为什么要用VARCHAR2(1)型，用CHAR(1)难道不好么？从这样的表结构来看，DUAL表设计的目的就是要尽可能的简单，以减少检索的开销。 还有，DUAL表是建立在SYSTEM表空间的，第一是因为DUAL表是SYS这个用户建的，本来默认的表空间就是SYSTEM；第二，把这个可能经常被查询的表和用户表分开来存放，对于系统性能的是有 好处的。 有了创建了表、创建了同义词还是不够的。DUAL在SYS这个Schema下面，因此用别的用户登录是无法查询这个表的，因此还需要授权： grant select on SYS.DUAL to PUBLIC with grant option; 将Select权限授予公众。 接下来看看DUAL表中的数据，事实上，DUAL表中的数据和ORACLE数据库环境有着十分重要的关系（ORACLE不会为此瘫痪，但是不少存储过程以及一些查询将无法被正确执行）。 */ --查询行数 --在创建数据库之后，DUAL表中便已经被插入了一条记录。个人认为：DUMMY字段的值并没有什么关系，重要的是DUAL表中的记录数 SQL> select count(*) from dual;   COUNT(*) ----------          1 SQL> select * from dual; DUMMY ----- X --使用PL/SQL Developer插入数据，能现实所有的数据。 SQL> insert into dual values('Y'); 1 row inserted SQL> insert into dual values('X'); 1 row inserted SQL> insert into dual values('Z'); 1 row inserted SQL> commit; Commit complete SQL> select * from dual; DUMMY ----- X Y X Z 但是当我们执行下面语句时只显示一行： SQL> select sysdate from dual; SYSDATE ----------- 2011-3-9 12 SQL> select systimestamp from dual; SYSTIMESTAMP -------------------------------------------------------------------------------- 09-3月 -1112.10.23.073000下午+08:00 当system用户用oracleSQL*Plus登录后，执行相同的操作，显示插入数据成功，但是查询不了添加的数据，统计也只有一条数据，查看表中的所有数据，也只能看到原表中的数据'X'. --把表截掉 SQL> truncate table dual; Table truncated SQL> commit; Commit complete 然而，数据表里还有一条数据没有被删除，这是表里至少要有一条数据的原因。 SQL> select count(*) from dual;   COUNT(*) ----------          1 SQL> select * from dual; no rows selected 但是下面这个语句还能成功： SQL> select sysdate from dual; SYSDATE ----------- 2011-3-9 12 --试着把DUAL表中的数据删除，看看会出现什么结果： SQL> delete from dual; 1 row deleted SQL> select * from dual; no rows selected SQL> select sysdate from dual; SYSDATE ----------- 09-3月 -11 我们能取到系统日期。在以前的版本中是取不到系统日期的，据说原因是：sysdate是个函数，作用于每一个数据行。现在没有数据了，自然就不可能取出系统日期。但是10g版本中对此做了 修改，如果你对表中的数据进行全部删除，oracle也会保留一条空数据在表中的，这样便于你用这个dual表进行其他操作。 --对于DELETE操作来说，ORACLE对DUAL表的操作做了一些内部处理,尽量保证DUAL表中只返回一条记录.当然这写内部操作是不可见的 --不管表内有多少记录（没有记录除外）,ORACLE对于每次DELETE操作都只删除了一条数据。 SQL> select count(*) from dual; COUNT(*) ---------- 4 SQL> delete from dual; 4 rows deleted SQL> commit; Commit complete SQL> select count(*) from dual; COUNT(*) ---------- 1 附:ORACLE关于DUAL表不同寻常特性的解释 There is internalized code that makes this happen. Code checks that ensurethata table scan of SYS.DUAL only returns one row. Svrmgrl behaviour is incorrectbut this is now an obsolete product. The base issue you should always remember and keep is: DUAL table should alwayshave 1 ROW. Dual is a normal table with one dummy column of varchar2(1). This is basically used from several applications as a pseudo table for gettingresults from a select statement that use functions like sysdate or other prebuilt or application functions. If DUAL has no rows at all some applications(that use DUAL) may fail with NO_DATA_FOUND exception. If DUAL has more than 1row then applications (that use DUAL) may fail with TOO_MANY_ROWS exception. So DUAL should ALWAYS have 1 and only 1 row DUAL表可以执行插入、更新、删除操作，还可以执行drop操作。但是不要去执行drop表的操作，否则会使系统不能用，数据库起不了，会报Database startup crashes with ORA-1092错误。 3、如果DUAL表被“不幸”删除后的恢复： 用sys用户登陆。 创建DUAL表。 授予公众SELECT权限（SQL如上述，但不要给UPDATE，INSERT，DELETE权限）。 向DUAL表插入一条记录（仅此一条）： insert into dual values('X'); 提交修改。 --用sys用户登陆。 SQL> create pfile=’d:/pfile.bak’ from spfile SQL> shutdown immediate --在d:/pfile.bak文件中最后加入一条：replication_dependency_tracking= FALSE --重新启动数据库： SQL> startup pfile=’d:/pfile.bak’ SQL> create table “sys”.”DUAL”      ( “DUMMY” varchar2(1) )      pctfree 10 pctused 4; SQL> insert into dual values(‘X’); SQL> commit; SQL> Grant select on dual to Public; 授权成功。   SQL> select * from dual; D - X   SQL> shutdown immediate 数据库已经关闭。 已经卸载数据库。 ORACLE 例程已经关闭。 SQL> startup ORACLE 例程已经启动。   Total System Global Area 135338868 bytes FixedSize                  453492 bytes VariableSize            109051904 bytes Database Buffers          25165824 bytes Redo Buffers                667648 bytes 数据库装载完毕。 数据库已经打开。","title":"oracle dual表"},{"content":"BOOL CKCMODDlg::OnInitDialog() {\tCDialog::OnInitDialog();\t\t// TODO: Add extra initialization here\t\treturn TRUE;  // return TRUE unless you set the focus to a control\t              // EXCEPTION: OCX Property Pages should return FALSE}void CKCMODDlg::OnOK() {\t// TODO: Add extra validation here\tCADO ado;\tado.CADOConnect();\tUpdateData(TRUE);\tif (m_old==\"\"&&m_new==\"\")\t{\t\tMessageBox(\"不能为空\");\t\tGetDlgItem(IDC_EDIT1)->SetFocus();\t}\telse\t{\t\tCString str;\t\tstr.Format(\"update kecheng set cname='%s' where kecheng.cname='%s'\",m_new,m_old);\t\t//str.Format(\"insert into \");\t\tado.ExecuteSQL(_bstr_t(str));\t\tMessageBox(\"修改成功\");\t}\tCDialog::OnOK();} -------------------------------未完待续---------------------------------","title":"vc++选课系统开发 sql语句操作数据库 修改课程名模块"},{"content":"CADO::CADO(){}CADO::~CADO(){\t\tif (m_pRecordset->State==adOpenStatic)\t{\t\tm_pRecordset->Close();\t}\tm_pConnection->Close();\t::CoUninitialize();}_RecordsetPtr& CADO::Select(CString sqlstr){\ttry\t{\t\tif (m_pRecordset->State==adStateOpen)\t\t{\t\t\tm_pRecordset->Close();\t\t}\t\tm_pRecordset->Open((_bstr_t)sqlstr,m_pConnection.GetInterfacePtr(),adOpenDynamic,adLockOptimistic,adCmdText );\t}\tcatch (_com_error e)\t{\t\tAfxMessageBox(e.Description());\t\tm_pRecordset->Close();\t}\treturn m_pRecordset;}BOOL CADO::ExecuteSQL(_bstr_t  bstrSQL){\ttry\t{\t\tif(m_pConnection==NULL)\t\t\t//OnInitADOConn();\t\t\tCADOConnect();\t\tm_pConnection->Execute(bstrSQL,NULL,adCmdText);\t\t//m_pRecordset->Update();\t\treturn true;\t}\tcatch(_com_error &e)\t{\t\tAfxMessageBox(e.Description()+\"错误!\");\t\treturn false;\t}}void CADO::CADOConnect(){\t::CoInitialize(NULL);  \ttry\t{\t\tCString strCon;\t\tstrCon.Format(\"Provider=SQLOLEDB.1;Integrated Security=SSPI;Persist Security Info=False;Initial Catalog=student;Data Source=XIAOLI-PC\");\t\tm_pConnection.CreateInstance(\"ADODB.Connection\"); \t\t\t\tm_pConnection->Open((_bstr_t)strCon,\"\",\"\",adModeUnknown); \t\tm_pRecordset.CreateInstance(\"ADODB.Recordset\");\t}\tcatch(_com_error e) \t{\t\tAfxMessageBox(e.Description());\t}}","title":"vc++选课系统开发 sql操作数据库 ado封装"},{"content":"　PHP是一门高效的网络编程语言，由于它具有编写灵活、运行快速等优点，迅速成为Web程序员的首选语言。那么怎样才能成为一个优秀的PHP开发者呢? 　　要成为一名PHP编程高手并不容易，并不像很多人想象的那样，只要能够飞快地编写几条简单的代码去解决一个复杂的问题就是PHP编程高手了，真正的PHP高手还需要考虑更多的其它问题。以下三条准则是一名成熟的PHP程序员在编程中应该首先遵循的准则。 　　◆懒惰是金 　　◆编写漂亮的代码 　　◆追求程序的速度，而不是编程的速度 　　懒惰是金 　　做一个懒惰的程序员吗?这个想法太奇怪了!因为这个世界上最忙碌的人可能就是计算机程序员了。但正是因为程序员太忙了，所以才应该在编程时学会偷懒。对于一个程序员来说，懒惰的方法有两种： 　　其一，大胆使用现成的别人的程序代码，把这些代码融入到你自己的程序或者项目中去。其二是编写一些有用的代码建立一个函数库，在将来编写程序时可以顺手拈来，省去了许多重复的劳动，自然就可以懒惰一点了。这两种偷懒的方法都非常适合PHP程序员了。 　　首先，PHP是在自由开放的环境中诞生和成长的一门语言。在世界各地，有成千上万的程序员，他们一直在为PHP的完美而不断奋斗，他们也愿意和别人分享自己的聪明才智和自己编写的代码。你每天都可以从一些PHP网站、邮件列表、新闻组发现大量的优秀的程序代码。 　　这样说，我并不是鼓励你整天等着让别人为你编写代码，但是你可以“站在伟人的肩膀上”，充分发扬“拿来主义”，聪明地应用别人的程序代码可以节省你大量时间。其次，在PHP中，你可以方便地建立自己的函数库，这样可以在你以后编写程序时省去很多麻烦。 　　下面笔者为大家介绍几个通用的函数，这些函数有的来自网上的一些开放源代码的项目，有的精选自邮件列表。如果你能把它们加入到你自己的函数库中，迟早你将会发现自己受益无穷。 　　1.通用数据库处理函数 　　和其它的CGI函数相比，PHP的优点之一是具有很强大的数据库处理能力。但是，在PHP中，对于不同的数据库都使用一些特定的函数来专门处理，缺少通用的数据库处理函数。这大大降低了程序代码的可移植性，这也为初学编程的朋友带来了很多不便。 　　在网上，许多程序员都通过封装类解决了这个问题。他们编写了统一的函数用来处理任何流行的数据库——不管是在Linux世界深受欢迎的Mysql还是在Windows平台上广泛流行的SqlServer。 　　就笔者个人来说，非常喜欢使用这些函数，因为可以直接使用一些简单的诸如”query”、”next_record”之类的函数，而不需要考虑数据库的连接、数据库句柄这些复杂的东西，更不需要考虑使用的是何种数据库。如果你需要这些函数，你可以通过访问以下的几个网址而得到： 　　◆http://phplib.netuse.de/ 　　◆http://phpclasses.UpperDesign.com/browse.html/package/20 　　◆http://phpdb.linuxbox.com/","title":"懒惰是金"},{"content":"已经将连接数据库常用方法写到一个类里，只需调用即可 using System; using System.Data; using System.Data.SqlClient; using System.Text; class DBUtil {     // 定义连接字符串     private static string strConnect = System.Configuration.ConfigurationSettings.AppSettings[\"connStr\"];     public static int SqlExecuteNonQuery(SqlCommand objCommand)     {         SqlConnection objConnection = new SqlConnection(strConnect);         objCommand.Connection = objConnection;         try         {             if (objConnection.State == ConnectionState.Closed) objConnection.Open();             return objCommand.ExecuteNonQuery();         }         catch (Exception e)         {             throw e;         }         finally         {             if (objConnection.State == ConnectionState.Open) objConnection.Close();         }     }     public static int SqlExecuteNonQuery(string strCmd)     {         SqlCommand objCommand = new SqlCommand(strCmd);         return SqlExecuteNonQuery(objCommand);     }     public static object SqlExecuteScalar(SqlCommand objCommand)     {         SqlConnection objConnection = new SqlConnection(strConnect);         objCommand.Connection = objConnection;         try         {             if (objConnection.State == ConnectionState.Closed) objConnection.Open();             return objCommand.ExecuteScalar();         }         catch (Exception e)         {             throw e;         }         finally         {             if (objConnection.State == ConnectionState.Open) objConnection.Close();         }     }     public static object SqlExecuteScalar(string strCmd)     {         SqlCommand objCommand = new SqlCommand(strCmd);         return SqlExecuteScalar(objCommand);     }     public static DataSet GetDataSet(SqlCommand objCommand, string strTableName)     {         SqlConnection objConnection = new SqlConnection(strConnect);         objCommand.Connection = objConnection;         try         {             if (objConnection.State == ConnectionState.Closed) objConnection.Open();             SqlDataAdapter objDataAdapter = new SqlDataAdapter(objCommand);             DataSet objDataSet = new DataSet();             objDataAdapter.Fill(objDataSet, strTableName);             return objDataSet;         }         catch (Exception e)         {             throw e;         }         finally         {             if (objConnection.State == ConnectionState.Open) objConnection.Close();         }     }     public static DataSet GetDataSet(string strCmd, string strTableName)     {         SqlCommand objCommand = new SqlCommand(strCmd);         return GetDataSet(objCommand, strTableName);     } }","title":"C#中连接数据库常用的类文件及方法"},{"content":"1、字符函数（character function）：参数是字符串或字符类型的列，返回值是字符值或者数字值 1）UPPER(column | expr)：将每一个字母都转换为大写字母； 2）LOWER(column | expr)：将每一个字母都转换为小写字母； 3）INITCAP(column | expr)：将字符值转换为首字符大写，其余字符小写； 4）CONCAT(column | expr)：将第一个值与第二个值连接起来，与“||”运算符相似； 5）SUBSTR(column | expr, x, y)：返回从x位置开始长度为y的一个子串； 6）SUBSTR(column | expr, z)：返回从z位置开始直到字符串结尾的一个子串； 7）INSTR(column | expr, c)：返回给定字符所处的位置； 8）LTRIM(column | expr, c)：将处于前端位置的给定字符删除； 9）RTRIM(column | expr, c)：将处于尾端位置的给定字符删除； 10）TRIM('c' FROM column | expr)：将处于前端和尾端位置的给定字符都删除； 11）TRIM(column)：只删除前端和尾端的空格； 12）LENGTH(column | expr)：返回字符的个数； 13）LPAD(column | expr, n, 'str')：用'str'填充值的左边，直到总长度为n； 14）RPAD(column | expr, n, 'str')：用'str'填充值的右边，直到总长度为n； 15）REPLACE(column | expr, c, r)：如果列或表达式中存在子串c，则用字符串r替换子串c； 2、数字函数：操作数字值，返回值也是数字值 1）ROUND(column | expr, [n])：对列或表达式进行舍入，小树位数是n； 2）TRUNC(column | expr, [n])：对列或表达式进行截断，小数位数是n； 3）POWER(n, p)：返回n的p次方； 4）ABS(n)：返回n的绝对值； 5）MOD(x, y)：返回x/y的整余数； 6）SIGN(value)：正数返回1，负数返回-1，0则返回0； 7）FLOOR(value)：返回小于等于此值的最大整数； 8）CEIL(value)：返回大于等于次数的最小整数； 3、NVL：将空值转换为由参数指定的实际值 NVL(column, value) NVL(Commission, 0) NVL(HireDate, '01-Jan-12') NVL(Address, 'LiaoNing') 4、NVL2：NVL函数的扩展，如果列是非空值，则显示第二个参数；如果列是空值，则显示第三个参数 NVL2(column, notnullvalue, nullvalue) NVL2(Commission, Commission, 0) 5、DECODE：类似SELECT CASE WHEN THEN DECODE(column | expr, value1, action1                                             [,value2,action2]                                             ...                                             [,default]); SELECT ename, sal, DECODE(DeptNo, 10, sal * 1.2                                                                         , 20, sal * 1.3                                                                         , 30, sal * 1.4                                                                         ,sal) \"New Salary\" FROM EMP; SELECT ename, sal, CASE WHEN DeptNo = 10 THEN sal * 1.2            WHEN DeptNo = 20 THEN sal * 1.3            WHEN DeptNo = 30 THEN sal * 1.4            ELSE sal END \"New Salary\" FROM EMP; 6、转换函数： 6.1、TO_CHAR(number | date[, format])：按照指定的格式将数字或日期转换成VARCHAR2值； 数字格式              含义 9                            用9的个数来确定长度（如：99999） 0                            显示前导0（如：09999） $                            显示浮动美元符号（如：￥9999） .                             在指定的位置显示小数点（如：999999.99） ,                             在指定的位置显示逗号（如：99,999） PR                        将负数置于括号中（如：999PR） SQL> select ename, to_char(sal, '99,999,999.99') from emp where sal > 3000; ENAME      TO_CHAR(SAL,'9                                                        ---------- --------------                                                        KING             5,000.00   日期/时间格式                                                   含义 YYYY                                                                   用4位数字显示年 Y、YY或YYY                                                      用最后一位、两位或三位数字显示年 YEAR                                                                  以拼写格式表示的年 Q                                                                         年的季度 MM                                                                      两位数字的月 MON                                                                   月的前三个字母 MONTH                                                              采用9个字符的月名，左边字符用空格填充 Month                                                                 与MONTH相同，丹采用首字母大写的格式 RR                                                                      基于世纪的用两位数表示的年（50-99年用上一世纪，00-49用当前世纪） RM                                                                      用罗马数字表示的月 WW或W                                                             年或月的星期号 DDD、DD或D                                                  年、月或星期的日 DAY                                                                     采用9个字符的日名，左边字符用空白填充 DY                                                                       日的三个字母缩写名 DDTH                                                                 序数（如：seventh第七） DDSP                                                                 拼写的数 DDSPTH                                                           拼写的序数 HH、HH12或HH24                                         日的小时、用0-14表示的小时或用0-23表示的小时 MI                                                                         分钟（0-59） SS                                                                       秒（0-59） SSSSS                                                               距离午夜的秒数（0-86399） \"of\"                                                                      将引号中的字符串显示在结果中 fm                                                                       与其他格式符号（例如，DAY）一同使用的填充模式，以便消除空白 SQL> select to_char(sysdate, 'YYYY-MM-DD HH24:MI:SS') 系统当前时间 from dual; 系统当前时间                                                                     -------------------                                                              2012-12-18 12:21:45  6.2、TO_NUMBER(char [, format])：按照指定的格式将包含有效数字的字符值转换为数字； 6.3、TO_DATE(char [, format])：按照指定的格式将字符值转换为日期值。默认的格式是DD-MON-YY；","title":"Oracle笔记_单行函数"},{"content":"有时候我常常想，如果当年我随大众去了北上广而不是回了老家，现在的薪水会不会更高，人生就是有这么多选择，但是我一直坚定回家在当时是个不错的选择。理由有下：          1.在家里有父母照顾，有固定的居住空间，可以说后勤稳固。在这样的环境下才有了更好的学习空间，说实在我不是很爱学习的人，下班后不是跟朋友聚餐就是吃完饭玩游戏去了，所以生活可以说是很清闲的，而成都本身也有一种休闲的气氛，没有北上广这么快的节奏，所以我才有更多的闲工夫在吃饱喝足后想想怎么提升下自己吧。          2.IT行业是个高科技行业（据说吧）。对比传统行业来说他有更高的灵活性和发展空间，IT算是对地域要求最低的行业了吧，一人一脑走遍天下的传说在我们周围并不鲜见，就我一个以前的一位前辈说他一个朋友，全国各大城市都旅游过，一个人一台笔记本，每半年换个城市，每到一个城市只要1周就能解决工作问题。当年一直是我的榜样啊，我有时也有这种冲动，还好我是个骨子里的宅男。          3.还有就是性格了。我个人感觉急性子的人真学不了数据库，慢性子的人比较有天赋，如果再龟毛点就更好了，数据库需要的是细心更耐心，也许这就是我当年选择它的原因。          4.选择了一个学习气氛浓厚的公司。新电真是我人生的转折点，怎么说呢，很多以前在那的同事都说它适合养老，工作清闲活不多是最真实的写照，但还是要看个人的选择啊，记得我才进去的时候选坐位，结果好的都被别人选走了，我自能做到一个能被经理直线监控的地方，一直为这件事郁闷，也许就是这样我坚持学习了下来，而那些位置好的同学看小说，聊聊QQ这样来打发时间乐此不疲。          而学习就是如此奇妙的一件事，当你的知识体系建立后你就能学得越快越好，当你学得差不多的时候你就会发现市面上的书讲得也都差不多。怀想当年在CSDN上默默的看帖问一些小白问题，现在论坛上对我来说也都是小白问题了。在这里对那些在论坛上积极回答新人问题的前辈道一声谢，那的确不容易，特别感谢邹健大大，你的脚本和博客对我帮助甚大。","title":"我的6年职场人生从月薪800到2万（ 随笔）"},{"content":"所有复杂的列表控件 GridView/DataList/DataGrid/Repeater 均无法直接绑定多位数组，只能绑定一维数组，多维数组会带歧义性 解决方案是，先读取数据到 DataTable， DataTable 不正是一个二维表吗？ DataGrid1.DataSource = CreateTable(); DataGrid1.DataBind(); public static DataTable CreatTable() { // 建表结构 DataTable dt = new DataTable(); dt.Columns.Add(\"id\", Type.GetType(\"System.Int32\")); dt.Columns.Add(\"name\", Type.GetType(\"System.String\")); dt.Columns.Add(\"sex\", Type.GetType(\"System.String\")); // 写数据 // 方法同你如何读取的二维数据 dt.Rows.Add(1, \"王小二\", \"男\"); dt.Rows.Add(2, \"张小三\", \"男\"); // ... // ... return dt; } }","title":"datagrid 处理二维数组"},{"content":"ORACLE SQL中有两种类型的函数： 1、单行函数：作用域每一行的列，每一行返回一个结果； 2、分组函数或聚集函数：操纵一组行中的数据，并返回单一的一个结果。","title":"Oracle笔记_内置函数"},{"content":"一.SQLite的介绍 1.SQLite简介  SQLite是一款轻型的数据库，是遵守ACID的关联式数据库管理系统，它的设计目标是嵌入 式的，而且目前已经在很多嵌入式产品中使用了它，它占用资源非常的低，在嵌入式设备中，可能只需要几百K的内存就够了。它能够支持 Windows/Linux/Unix等等主流的操作系统，同时能够跟很多程序语言相结合，比如Tcl、PHP、Java、C++、.Net等，还有ODBC接口，同样比起 Mysql、PostgreSQL这两款开源世界著名的数据库管理系统来讲，它的处理速度比他们都快。 2.SQLite的特点： 轻量级 SQLite和C/S模式的数据库软件不同，它是进程内的数据库引擎，因此不存在数据库的客户端和服务器。使用SQLite一般只需要带上它的一个动态 库，就可以享受它的全部功能。而且那个动态库的尺寸也挺小，以版本3.6.11为例，Windows下487KB、Linux下347KB。 不需要\"安装\" SQLite的核心引擎本身不依赖第三方的软件，使用它也不需要\"安装\"。有点类似那种绿色软件。 单一文件   数据库中所有的信息（比如表、视图等）都包含在一个文件内。这个文件可以自由复制到其它目录或其它机器上。 跨平台/可移植性 除了主流操作系统 windows，linux之后，SQLite还支持其它一些不常用的操作系统。 弱类型的字段 同一列中的数据可以是不同类型 开源 这个相信大家都懂的！  3.SQLite数据类型 一般数据采用的固定的静态数据类型，而SQLite采用的是动态数据类型，会根据存入值自动判断。SQLite具有以下五种常用的数据类型： NULL: 这个值为空值 VARCHAR(n)：长度不固定且其最大长度为 n 的字串，n不能超过 4000。 CHAR(n)：长度固定为n的字串，n不能超过 254。 INTEGER: 值被标识为整数,依据值的大小可以依次被存储为1,2,3,4,5,6,7,8. REAL: 所有值都是浮动的数值,被存储为8字节的IEEE浮动标记序号. TEXT: 值为文本字符串,使用数据库编码存储(TUTF-8, UTF-16BE or UTF-16-LE). BLOB: 值是BLOB数据块，以输入的数据格式进行存储。如何输入就如何存储,不改  变格式。 DATA ：包含了 年份、月份、日期。 TIME： 包含了 小时、分钟、秒。 相信学过数据库的童鞋对这些数据类型都不陌生的!!!!!!!!!! 二.SQLiteDatabase的介绍 Android提供了创建和是用SQLite数据库的API。SQLiteDatabase代表一个数据库对象，提供了操作数据库的一些方法。在Android的SDK目录下有sqlite3工具，我们可以利用它创建数据库、创建表和执行一些SQL语句。下面是SQLiteDatabase的常用方法。  SQLiteDatabase的常用方法  方法名称 方法描述 openOrCreateDatabase(String path,SQLiteDatabase.CursorFactory factory) 打开或创建数据库 insert(String table,String nullColumnHack,ContentValues values) 添加一条记录 delete(String table,String whereClause,String[] whereArgs) 删除一条记录 query(String table,String[] columns,String selection,String[] selectionArgs,String groupBy,String having,String orderBy) 查询一条记录 update(String table,ContentValues values,String whereClause,String[] whereArgs) 修改记录 execSQL(String sql) 执行一条SQL语句 close() 关闭数据库 1、打开或者创建数据库 在Android 中以使用SQLiteDatabase的静态方法openOrCreateDatabase(String path,SQLiteDatabae.CursorFactory factory)打开或者创建一个数据库。它会自动去检测是否存在这个数据库，如果存在则打开，不存在则创建一个数据库；创建成功则返回一个SQLiteDatabase对象，否则抛出异常FileNotFoundException。 下面是创建名为“stu.db”数据库的代码： 1. db=SQLiteDatabase.openOrCreateDatabase(\"/data/data/com.lingdududu.db/databases/stu.db\",null);  2、创建表 创建一张表很简单。首先，编写创建表的SQL语句，然后，调用SQLiteDatabase的execSQL()方法来执行SQL语句便可以创建一张表了。 下面的代码创建了一张用户表，属性列为：_id（主键并且自动增加）、sname（学生姓名）、snumber（学号） 1. private void createTable(SQLiteDatabase db){   2.     3.       //创建表SQL语句   4.       String stu_table=\"create table usertable(_id integer primary key autoincrement,sname text,snumber text)\";   5.     6.       //执行SQL语句    7.       db.execSQL(stu_table);   8. }   3、插入数据 插入数据有两种方法： ①SQLiteDatabase的insert(String table,String nullColumnHack,ContentValues values)方法，参数一是表名称，参数二是空列的默认值，参数三是ContentValues类型的一个封装了列名称和列值的Map； ②编写插入数据的SQL语句，直接调用SQLiteDatabase的execSQL()方法来执行 第一种方法的代码： 1. private void insert(SQLiteDatabase db) {   2.     3.     //实例化常量值   4.     ContentValues cValue = new ContentValues();   5.     6.     //添加用户名   7.     cValue.put(\"sname\",\"xiaoming\");   8.     9.     //添加密码   10.     cValue.put(\"snumber\",\"01005\");   11.     12.     //调用insert()方法插入数据   13.     db.insert(\"stu_table\",null,cValue);   14. }   第二种方法的代码： 1. private void insert(SQLiteDatabase db){    2.   3.      //插入数据SQL语句   4.      String stu_sql=\"insert into stu_table(sname,snumber) values('xiaoming','01005')\";   5.     6.     //执行SQL语句   7.      db.execSQL(sql);   8. }   4、删除数据 删除数据也有两种方法： ①调用SQLiteDatabase的delete(String table,String whereClause,String[] whereArgs)方法，参数一是表名称，参数二是删除条件，参数三是删除条件值数组； ②编写删除SQL语句，调用SQLiteDatabase的execSQL()方法来执行删除。 第一种方法的代码： 1. private void delete(SQLiteDatabase db) {   2.     3.    //删除条件   4.    String whereClause = \"_id=?\";   5.     6.    //删除条件参数   7.    String[] whereArgs = {String.valueOf(2)};   8.     9.    //执行删除   10.    db.delete(\"stu_table\",whereClause,whereArgs);    11. }   第二种方法的代码： 1. private void delete(SQLiteDatabase db) {   2.     3.    //删除SQL语句   4.    String sql = \"delete from stu_table where _id  = 6\";   5.     6.    //执行SQL语句   7.    db.execSQL(sql);   8. }   5、修改数据 修改数据有两种方法： ①调用SQLiteDatabase的update(String table,ContentValues values,String whereClause, String[] whereArgs)方法。参数是表名称，参数是更行列ContentValues类型的键值对（Map），参数是更新条件（where字句），参数是更新条件数组。 ②编写更新的SQL语句，调用SQLiteDatabase的execSQL执行更新。 第一种方法的代码： 1. private void update(SQLiteDatabase db) {   2.     3.     //实例化内容值   4.     ContentValues values = new ContentValues();   5.     6.     //在values中添加内容    7.     values.put(\"snumber\",\"101003\");   8.     9.     //修改条件    10.     String whereClause = \"id=?\";   11.     12.     //修改添加参数   13.     String[] whereArgs={String.valuesOf(1)};   14.     15.     //修改   16.     db.update(\"usertable\",values,whereClause,whereArgs);    17. }   第二种方法的代码： 1. private void update(SQLiteDatabase db){   2.     3.     //修改SQL语句   4.     String sql = \"update stu_table set snumber = 654321 where id = 1\";   5.     6.     //执行SQL   7.     db.execSQL(sql);    8. }     6、查询数据 在Android中查询数据是通过Cursor类来实现的，当我们使用SQLiteDatabase.query()方法时，会得到一个Cursor对象，Cursor指向的就是每一条数据。它提供了很多有关查询的方法，具体方法如下： public Cursor query(String table,String[] columns,String selection,String[] selectionArgs,String groupBy,String having,String orderBy,String limit); 各个参数的意义说明： ①table:表名称 ②columns:列名称数组 ③selection:条件字句，相当于where ④selectionArgs:条件字句，参数数组 ⑤groupBy:分组列 ⑥having:分组条件 ⑦orderBy:排序列 ⑧limit:分页查询限制 ⑨Cursor:返回值，相当于结果集ResultSet Cursor是一个游标接口，提供了遍历查询结果的方法，如移动指针方法move()，获得列值方法getString()等. Cursor游标常用方法 方法名称 方法描述 getCount() 获得总的数据项数 isFirst() 判断是否第一条记录 isLast() 判断是否最后一条记录 moveToFirst() 移动到第一条记录 moveToLast() 移动到最后一条记录 move(int offset) 移动到指定记录 moveToNext() 移动到下一条记录 moveToPrevious() 移动到上一条记录 getColumnIndexOrThrow(String columnName) 根据列名称获得列索引 getInt(int columnIndex) 获得指定列索引的int类型值 getString(int columnIndex) 获得指定列缩影的String类型值   下面就是用Cursor来查询数据库中的数据，具体代码如下： 1. private void query(SQLiteDatabase db)   2. {   3.     4.    //查询获得游标   5.    Cursor cursor = db.query   (\"usertable\",null,null,null,null,null,null);   6.     7.    //判断游标是否为空   8.    if(cursor.moveToFirst() {   9.     10.        //遍历游标   11.        for(int i=0;i<cursor.getCount();i++){   12.     13.             cursor.move(i);   14.   15.             //获得ID   16.             int id = cursor.getInt(0);   17.     18.             //获得用户名   19.             String username=cursor.getString(1);   20.     21.             //获得密码   22.             String password=cursor.getString(2);   23.     24.             //输出用户信息   25.             System.out.println(id+\":\"+sname+\":\"+snumber);   26.        }   27.    }    28. }    7、删除指定表  编写插入数据的SQL语句，直接调用SQLiteDatabase的execSQL()方法来执行 1. private void drop(SQLiteDatabase db){           2.      //删除表的SQL语句         3.      String sql =\"DROP TABLE stu_table\";            4.     //执行SQL        5.     db.execSQL(sql);      6. }     三. SQLiteOpenHelper 该类是SQLiteDatabase一个辅助类。这个类主要生成一 个数据库，并对数据库的版本进行管理。当在程序当中调用这个类的方法getWritableDatabase()或者 getReadableDatabase()方法的时候，如果当时没有数据，那么Android系统就会自动生成一个数据库。 SQLiteOpenHelper 是一个抽象类，我们通常需要继承它，并且实现里面的3个函数：  1.onCreate（SQLiteDatabase） 在数据库第一次生成的时候会调用这个方法，也就是说，只有在创建数据库的时候才会调用，当然也有一些其它的情况，一般我们在这个方法里边生成数据库表。   2.  onUpgrade（SQLiteDatabase，int，int）    当数据库需要升级的时候，Android系统会主动的调用这个方法。一般我们在这个方法里边删除数据表，并建立新的数据表，当然是否还需要做其他的操作，完全取决于应用的需求。 3.  onOpen（SQLiteDatabase）： 这是当打开数据库时的回调函数，一般在程序中不是很常使用。 写了这么多，改改用实际例子来说明上面的内容了。下面这个操作数据库的实例实现了创建数据库，创建表以及数据库的增删改查的操作。 SQLiteActivity.java 1. package com.lingdududu.testSQLite;   2.   3. import com.lingdududu.testSQLiteDb.StuDBHelper;   4.   5. import android.app.Activity;   6. import android.content.ContentValues;   7. import android.database.Cursor;   8. import android.database.sqlite.SQLiteDatabase;   9. import android.os.Bundle;   10. import android.view.View;   11. import android.view.View.OnClickListener;   12. import android.widget.Button;   13. /*   14.  * @author lingdududu   15.  */  16. public class SQLiteActivity extends Activity {   17.     /** Called when the activity is first created. */  18.     //声明各个按钮   19.     private Button createBtn;   20.     private Button insertBtn;   21.     private Button updateBtn;   22.     private Button queryBtn;   23.     private Button deleteBtn;   24.     private Button ModifyBtn;   25.     @Override  26.     public void onCreate(Bundle savedInstanceState) {   27.         super.onCreate(savedInstanceState);   28.         setContentView(R.layout.main);   29.            30.         //调用creatView方法   31.         creatView();   32.         //setListener方法   33.         setListener();           34.     }   35.        36.     //通过findViewById获得Button对象的方法   37.     private void creatView(){   38.         createBtn = (Button)findViewById(R.id.createDatabase);   39.         updateBtn = (Button)findViewById(R.id.updateDatabase);   40.         insertBtn = (Button)findViewById(R.id.insert);   41.         ModifyBtn = (Button)findViewById(R.id.update);   42.         queryBtn = (Button)findViewById(R.id.query);   43.         deleteBtn = (Button)findViewById(R.id.delete);   44.     }   45.        46.     //为按钮注册监听的方法   47.     private void setListener(){   48.         createBtn.setOnClickListener(new CreateListener());   49.         updateBtn.setOnClickListener(new UpdateListener());   50.         insertBtn.setOnClickListener(new InsertListener());   51.         ModifyBtn.setOnClickListener(new  ModifyListener());   52.         queryBtn.setOnClickListener(new QueryListener());   53.         deleteBtn.setOnClickListener(new DeleteListener());   54.     }   55.        56.     //创建数据库的方法   57.     class CreateListener implements OnClickListener{   58.   59.         @Override  60.         public void onClick(View v) {   61.             //创建StuDBHelper对象   62.             StuDBHelper dbHelper = new StuDBHelper(SQLiteActivity.this,\"stu_db\",null,1);   63.             //得到一个可读的SQLiteDatabase对象   64.             SQLiteDatabase db =dbHelper.getReadableDatabase();   65.         }          66.     }   67.        68.     //更新数据库的方法   69.     class UpdateListener implements OnClickListener{   70.   71.         @Override  72.         public void onClick(View v) {   73.             // 数据库版本的更新,由原来的1变为2   74.             StuDBHelper dbHelper = new StuDBHelper(SQLiteActivity.this,\"stu_db\",null,2);   75.             SQLiteDatabase db =dbHelper.getReadableDatabase();   76.         }          77.     }   78.        79.     //插入数据的方法   80.     class InsertListener implements OnClickListener{   81.   82.         @Override  83.         public void onClick(View v) {   84.   85.             StuDBHelper dbHelper = new StuDBHelper(SQLiteActivity.this,\"stu_db\",null,1);   86.             //得到一个可写的数据库   87.             SQLiteDatabase db =dbHelper.getWritableDatabase();   88.                89.             //生成ContentValues对象 //key:列名，value:想插入的值     90.             ContentValues cv = new ContentValues();   91.             //往ContentValues对象存放数据，键-值对模式   92.             cv.put(\"id\", 1);   93.             cv.put(\"sname\", \"xiaoming\");   94.             cv.put(\"sage\", 21);   95.             cv.put(\"ssex\", \"male\");   96.             //调用insert方法，将数据插入数据库   97.             db.insert(\"stu_table\", null, cv);   98.             //关闭数据库   99.             db.close();   100.         }          101.     }   102.        103.     //查询数据的方法   104.     class QueryListener implements OnClickListener{   105.   106.         @Override  107.         public void onClick(View v) {   108.   109.             StuDBHelper dbHelper = new StuDBHelper(SQLiteActivity.this,\"stu_db\",null,1);   110.             //得到一个可写的数据库   111.             SQLiteDatabase db =dbHelper.getReadableDatabase();   112.             //参数1：表名     113.             //参数2：要想显示的列     114.             //参数3：where子句     115.             //参数4：where子句对应的条件值     116.             //参数5：分组方式     117.             //参数6：having条件     118.             //参数7：排序方式     119.             Cursor cursor = db.query(\"stu_table\", new String[]{\"id\",\"sname\",\"sage\",\"ssex\"}, \"id=?\", new String[]{\"1\"}, null, null, null);   120.             while(cursor.moveToNext()){   121.                 String name = cursor.getString(cursor.getColumnIndex(\"sname\"));   122.                 String age = cursor.getString(cursor.getColumnIndex(\"sage\"));   123.                 String sex = cursor.getString(cursor.getColumnIndex(\"ssex\"));   124.                 System.out.println(\"query------->\" + \"姓名：\"+name+\" \"+\"年龄：\"+age+\" \"+\"性别：\"+sex);   125.             }   126.             //关闭数据库   127.             db.close();   128.         }          129.     }   130.        131.     //修改数据的方法   132.     class ModifyListener implements OnClickListener{   133.   134.         @Override  135.         public void onClick(View v) {   136.   137.             StuDBHelper dbHelper = new StuDBHelper(SQLiteActivity.this,\"stu_db\",null,1);   138.             //得到一个可写的数据库   139.             SQLiteDatabase db =dbHelper.getWritableDatabase();   140.             ContentValues cv = new ContentValues();   141.             cv.put(\"sage\", \"23\");   142.             //where 子句 \"?\"是占位符号，对应后面的\"1\",   143.             String whereClause=\"id=?\";   144.             String [] whereArgs = {String.valueOf(1)};   145.             //参数1 是要更新的表名   146.             //参数2 是一个ContentValeus对象   147.             //参数3 是where子句   148.             db.update(\"stu_table\", cv, whereClause, whereArgs);   149.         }   150.     }   151.        152.     //删除数据的方法   153.     class DeleteListener implements OnClickListener{   154.   155.         @Override  156.         public void onClick(View v) {   157.   158.             StuDBHelper dbHelper = new StuDBHelper(SQLiteActivity.this,\"stu_db\",null,1);   159.             //得到一个可写的数据库   160.             SQLiteDatabase db =dbHelper.getReadableDatabase();   161.             String whereClauses = \"id=?\";   162.             String [] whereArgs = {String.valueOf(2)};   163.             //调用delete方法，删除数据    164.             db.delete(\"stu_table\", whereClauses, whereArgs);   165.         }      166.     }   167. }    StuDBHelper.java 1. package com.lingdududu.testSQLiteDb;   2.   3. import android.content.Context;   4. import android.database.sqlite.SQLiteDatabase;   5. import android.database.sqlite.SQLiteDatabase.CursorFactory;   6. import android.database.sqlite.SQLiteOpenHelper;   7. import android.util.Log;   8.   9. public class StuDBHelper extends SQLiteOpenHelper {   10.   11.     private static final String TAG = \"TestSQLite\";   12.     public static final int VERSION = 1;   13.            14.     //必须要有构造函数   15.     public StuDBHelper(Context context, String name, CursorFactory factory,   16.             int version) {   17.         super(context, name, factory, version);   18.     }   19.   20.     // 当第一次创建数据库的时候，调用该方法    21.     public void onCreate(SQLiteDatabase db) {   22.         String sql = \"create table stu_table(id int,sname varchar(20),sage int,ssex varchar(10))\";   23.         //输出创建数据库的日志信息   24.         Log.i(TAG, \"create Database------------->\");   25.         //execSQL函数用于执行SQL语句   26.         db.execSQL(sql);   27.     }   28.   29.     //当更新数据库的时候执行该方法   30.     public void onUpgrade(SQLiteDatabase db, int oldVersion, int newVersion) {   31.         //输出更新数据库的日志信息   32.         Log.i(TAG, \"update Database------------->\");   33.     }   34. }   main.xml 1. <?xml version=\"1.0\" encoding=\"utf-8\"?>  2. <LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\"  3.     android:orientation=\"vertical\"  4.     android:layout_width=\"fill_parent\"  5.     android:layout_height=\"fill_parent\"  6.     >  7.    <TextView     8.         android:layout_width=\"fill_parent\"    9.         android:layout_height=\"wrap_content\"    10.         android:text=\"@string/hello\"  11.         />  12.     <Button  13.         android:id=\"@+id/createDatabase\"  14.         android:layout_width=\"fill_parent\"    15.         android:layout_height=\"wrap_content\"    16.         android:text=\"创建数据库\"  17.         />         18.     <Button  19.         android:id=\"@+id/updateDatabase\"  20.         android:layout_width=\"fill_parent\"    21.         android:layout_height=\"wrap_content\"    22.         android:text=\"更新数据库\"  23.         />     24.     <Button  25.         android:id=\"@+id/insert\"  26.         android:layout_width=\"fill_parent\"    27.         android:layout_height=\"wrap_content\"    28.         android:text=\"插入数据\"  29.         />  30.     <Button  31.         android:id=\"@+id/update\"  32.         android:layout_width=\"fill_parent\"    33.         android:layout_height=\"wrap_content\"    34.         android:text=\"更新数据\"  35.         />  36.     <Button  37.         android:id=\"@+id/query\"  38.         android:layout_width=\"fill_parent\"    39.         android:layout_height=\"wrap_content\"    40.         android:text=\"查询数据\"  41.         />  42.      <Button  43.         android:id=\"@+id/delete\"  44.         android:layout_width=\"fill_parent\"    45.         android:layout_height=\"wrap_content\"    46.         android:text=\"删除数据\"  47.         />  48. <\/LinearLayout>    使用adb命令查看数据库： 1.在命令行窗口输入adb shell回车，就进入了Linux命令行，现在就可以使用Linux的命令了。 2.ls回车，显示所有的东西，其中有个data。（ls:显示所有，cd:进入） 3.cd data回车，再ls回车，cd data回车，ls回车后就会看到很多的com.。。。，那就是系统上的应用程序包名，找到你数据库程序的包名，然后进入。 4.进去后在查看所有，会看到有databases,进入databases，显示所有就会发现你的数据库名字，这里使用的是\"stu_db\"。 5.sqlite3 stu_db回车就进入了你的数据库了，然后“.schema”就会看到该应用程序的所有表及建表语句。 6.之后就可以使用标准的SQL语句查看刚才生成的数据库及对数据执行增删改查了。 # sqlite3 stu_db sqlite3 stu_db SQLite version 3.6.22 Enter \".help\" for instructions Enter SQL statements terminated with a \";\" sqlite> .schema .schema CREATE TABLE android_metadata (locale TEXT); CREATE TABLE stu_table(id int,sname varchar(20),sage int,ssex varchar(10));  --->创建的表 sqlite> select * from stu_table; select * from stu_table; 1|xiaoming|21|male sqlite>  插入数据 sqlite> insert into stu_table values(2,'xiaohong',20,'female'); 插入的数据记得要和表中的属性一一对应 insert into stu_table values(2,'xiaohong',20,'female'); sqlite> select * from stu_table; select * from stu_table; 1|xiaoming|21|male 2|xiaohong|20|female   --------------> 插入的数据 sqlite> 当点击修改数据的按钮时候 sqlite> select * from stu_table; select * from stu_table; 1|xiaoming|23|male  -------------->年龄被修改为23 2|xiaohong|20|female sqlite>   当点击删除数据的按钮 sqlite> select * from stu_table; select * from stu_table; 1|xiaoming|23|male        id=2的数据已经被删除 总之，我们可以在代码中执行数据库的增删改查，也可以在adb命令行下实现。不过因为SQLite没有客户端，不能直接的查看数据库变化后的信息，所以常用adb命令行查看数据库改变后的信息。","title":"android 之 SQLite"},{"content":"1、VARCHAR2：字符型数据类型，存储可变长度的字母数字混合的数据。最大长度4000个字符。使用Varchar2(20)，但是实际存储的为\"Clerk\"则只存储5个字符，并不在其尾部再添加15个空格； 2、CHAR：字符型数据类型，允许的最大长度是2000个字符，如果输入的值比指定的长度短，则在其尾部添加空格，以使其长度等于指定的长度； 3、NUMBER：存储负数、正数、整数、定点数和浮点数。可以用于任何要进行数学计算的列，例如薪水、佣金或价格。当某一列使用number类型时，可以指定其精度（precision）和标度（scale）。精度是一个数字的有意义数字的总数，包括小数点左右两边的数字，但指定精度时小数点不计算在内。标度是小数点右边的数字位数的总数。精度范围是1-38，标度范围是-84到127； 4、DATE：存储日期和时间值。允许的日期范围公元前4712年1月1日到公元后9999年12月31日。date类型的 列中存储着日、月、世纪、小时、分钟和苗。对date类型不需要制定大小。末日的数据格式是DD-MON-YY； 5、LONG：用于可变长度的字符数据，最大为2G Byte。一张数据表中只能有一列定义为LONG类型，这种类型用于以文本格式存储备忘录、发货单或者学生成绩单。定义为LONG类型时，不需要指定其大小； 6、NCHAR：NCHAR类型与CHAR类型相似，但它对没一个字符都是用两个字节的二进制编码，而CHAR类型则对没一个字符是用一个字节的ASCII编码，它只能表示256个不同的字符； 7、CLOB：这一字符大对象（Character Large Object）数据类型用于存储单字节字符数据，最大为4G个字符； 8、BLOB：二进制大对象（Binary Large Object）数据类型用于存储二进制数据，最大为4G Byte； 9、ROWID：用于以十六进制格式表示惟一的行地址。","title":"Oracle笔记_数据类型"},{"content":"void CKCADDDlg::OnOK() {\t// TODO: Add extra validation here\tUpdateData(TRUE);\tCADO  ado;\t\t//CLoginDlg mydlg;\t\t//设置查询字符串\t//CString str;\t//str= \"select * from student_xuanke\";\t//创建记录集指针对象实例\t//m_pRecordset.CreateInstance(__uuidof(Recordset));\t//_RecordsetPtr pRS = ado.Select(str);\t\tado.CADOConnect();\t_bstr_t str1;\tCString str2;\tstr2.Format(\"insert into student  values('%s','%s','%s')\",m_sno,m_sname,m_class);\t\t//\tstr1=\"insert into student_xuanke values('11','True','True','True','False','False')\";\tMessageBox(str2);\t\tado.ExecuteSQL(_bstr_t(str2));\tCDialog::OnOK();} -------------------------------未完待续---------------------------------","title":"vc++选课系统开发 sql 操作数据库添加数据 管理员对学生信息的添加"},{"content":"这里是使用tab控件实现的，为了显示在主对话框中，那两个子对话框必须属性设置为子对话框。 BOOL CStudent::OnInitDialog() {\tCDialog::OnInitDialog();\t\t// TODO: Add extra initialization here\tCFont font;\tfont.CreatePointFont(300,\"宋体\");\tGetDlgItem(IDC_STATIC_SHOW)->SetWindowText(\"欢迎来到学生选课系统\");\tGetDlgItem(IDC_STATIC_SHOW)->SetFont(&font);\t\tm_Tab.InsertItem(0,\"学生成绩查看\",0);\tm_Tab.InsertItem(1,\"学生选课\",1);\t\tm_ChaKan.Create(IDD_DIALOG_STUCHAKAN,&m_Tab);\tm_XuKe.Create(IDD_DIALOG_XUANKE,&m_Tab);\t//获得IDC_TABTEST客户区大小    CRect rs;    m_Tab.GetClientRect(rs);    //调整子对话框在父窗口中的位置\trs.DeflateRect(2,21,2,2);           //设置子对话框尺寸并移动到指定位置\tm_ChaKan.MoveWindow(&rs);    m_XuKe.MoveWindow(&rs);\t    //分别设置隐藏和显示    m_ChaKan.ShowWindow(true);    m_XuKe.ShowWindow(false);        //设置默认的选项卡    m_Tab.SetCurSel(0);\t\treturn TRUE;  // return TRUE unless you set the focus to a control\t              // EXCEPTION: OCX Property Pages should return FALSE}void CStudent::OnSelchangeTab1(NMHDR* pNMHDR, LRESULT* pResult) {\t// TODO: Add your control notification handler code here\tint nCurSel=m_Tab.GetCurSel();\tif (nCurSel==0)\t{\t//\tMessageBox(str);\t\tm_ChaKan.strxk=str;\t//\tMessageBox(m_ChaKan.strxk);\t\tm_ChaKan.ShowWindow(SW_SHOW);\t\tm_XuKe.ShowWindow(SW_HIDE);\t}\telse if (nCurSel==1)\t{        //MessageBox(str);\t\tm_XuKe.strxk = str;\t\t//MessageBox(m_XuKe.strxk);\t\t\t\tm_XuKe.ShowWindow(SW_SHOW);\t\tm_ChaKan.ShowWindow(SW_HIDE);\t}\t*pResult = 0;} -------------------------------未完待续---------------------------------","title":"vc++选课系统开发 sql语句操作数据库 学生界面模块"},{"content":"import java.sql.Connection; import java.sql.DriverManager; import java.sql.ResultSet; import java.sql.SQLException; import java.sql.Statement; public class MySQLConnection {  public static void main(String[] args) {   Connection conn = null;   Statement stmt = null;   ResultSet rs = null;   String url = null;   String user = null;   String password = null;   String sql = null;   try {    Class.forName(\"com.mysql.jdbc.Driver\"); //加载mysq驱动   } catch (ClassNotFoundException e) {    System.out.println(\"驱动加载错误\");    e.printStackTrace();//打印出错详细信息   }   try {    url =      \"jdbc:mysql://localhost/test?user=root&password=yqs2602555&useUnicode=true&&characterEncoding=gb2312&autoReconnect = true\";//简单写法：url=\\'#\\'\" //localhost/test(数据库名)? user=root(用户)&password=yqs2602555(密码)\";    user = \"root\";    password = \"yqs2602555\";    conn = DriverManager.getConnection(url,user,password);   } catch (SQLException e) {    System.out.println(\"数据库链接错误\");    e.printStackTrace();   }   try {    stmt = conn.createStatement();    sql = \"select * from dept\";//dept这张表有deptno，deptname和age这三个字段    rs = stmt.executeQuery(sql);//执行sql语句    while(rs.next()) {     System.out.print(rs.getInt(\"deptno\") + \"   \");     System.out.print(rs.getString(\"deptname\") + \"   \");     System.out.println(rs.getInt(\"age\") + \"   \");    }   } catch (SQLException e) {    System.out.println(\"数据操作错误\");    e.printStackTrace();   } //关闭数据库   try {    if(rs != null) {     rs.close();     rs = null;    }    if(stmt != null) {     stmt.close();     stmt = null;    }    if(conn != null) {     conn.close();     conn = null;    }   } catch(Exception e) {    System.out.println(\"数据库关闭错误\");    e.printStackTrace();   }  } }","title":"一个经典的JDBC连接MySQL的程序"},{"content":"在创建Oracle索引时，有一些问题使我们需要注意的，下面就为您介绍创建Oracle索引的一些注意事项，希望对您学习创建Oracle索引方面能有所帮助。   1、一般来说，不需要为比较小的表创建索引； 2、即使是大表，如果经常需要查询的数据不超过10%到15%的话，那就没有必要为其建立索引的必要。因为此时建立索引的开销可能要比性能的改善大的多。这个比例只是一个经验的数据。如果数据库管理员需要得出一个比较精确的结论，那么就需要进行测试分析。 3、如对于一些重复内容比较少的列，特别是对于那些定义了唯一约束的列。在这些列上建立索引，往往可以起到非常不错的效果。如对于一些null值的列与非Null值的列混合情况下，如果用户需要经常查询所有的非Null值记录的列，则最好为其设置索引。如果经常需要多表连接查询，在用与连接的列上设置索引可以达到事半功倍的效果。 4、数据库管理员，需要隔一段时间，如一年，对数据库的索引进行优化。该去掉的去掉，该调整的调整，以提高数据库的性能。 5、通常来说，表的索引越多，其查询的速度也就越快。但是，表的更新速度则会降低。这主要是因为表的更新(如往表中插入一条记录)速度，反而随着索引的增加而增加。这主要是因为，在更新记录的同时需要更新相关的索引信息。为此，到底在表中创建多少索引合适，就需要在这个更新速度与查询速度之间取得一个均衡点。 6、对于一些数据仓库或者决策型数据库系统，其主要用来进行查询。相关的记录往往是在数据库初始化的时候倒入。此时，设置的索引多一点，可以提高数据库的查询性能。同时因为记录不怎么更新，所以索引比较多的情况下，也不会影响到更新的速度。即使在起初的时候需要导入大量的数据，此时也可以先将索引禁用掉。等到数据导入完毕后，再启用索引。可以通过这种方式来减少索引对数据更新的影响。相反，如果那些表中经常需要更新记录，如一些事务型的应用系统，数据更新操作是家常便饭的事情。此时如果在一张表中建立过多的索引，则会影响到更新的速度。 7、关于位图索引。 基数是位图索引中的一个基本的定义，它是指数据库表中某个字段内容中不重复的数值。如在员工信息表中的性别字段，一般就只有男跟女两个值，所以，其基数为2;婚姻状况字段的话，则其只有已婚、未婚、离婚三种状态，其基数就为3;民族一览内也是只有有限的几个值。 　　对于要查询基数小的字段，如现在用户想查找所有婚姻状况为“已婚”的“女性”时，利用位图索引可以提高查询的效率。这主要是因为标准索引是通过在索引中保存排序过的索引列以及对应的ROWID来实现的。若我们在基数小的列上建立标准索引的话，则其会返回大量的记录。 　　而当我们在创建位图索引的时候，在Oracle会对整个表进行扫描，并且会为索引列的每个取值建立一个位图。若内容相同，则在位图上会以一个相同的数字表示。此时，若这个字段的基数比较小的话，则若需要实现对整个字段的查询的话，效率就会非常的高。因为此时，数据库只要位图中数字相同的内容找出来即可。 　　除了在数据表某列基数比较小的情况下，采用位图索引外，我们往往在一些特殊的情况下，也会建议采用位图索引。最常见的情况是，在Where限制条件中，若我们多次采用AND或者OR条件时，也建议采用位图索引。因为当一个查询饮用了一些部署了位图索引的列的时候，这些位图可以很方便的与AND或者Or 运算符操作结合以快速的找出用户所需要的记录。 　　但是，这里要注意，不是在条件语句中包含运算符的时候，采用位图索引都能够提供比较高的效率。一般来说，只有AND 或者OR运算符的时候，位图索引才会比较具有优势。若此时用户采用大于号或者不等于号作为条件语句中的限制条件的时候，则往往采用标准索引具有更大的优势。 　　所以，笔者在数据库设置中，一般只有在三种情况下才采用位图索引。一是列的基数比较小，而有可能需要根据这些字段的内容查找相关的记录;二是在条件语句中，用到了AND或者OR运算符的时候。除了这两种情况外，最好能够采用其他适合的索引。第三种情况是，需要用到NULL作为查询的限制条件。因为标准查询一般情况下，会忽略所有的NULL值列。也就是说，若需要查询“所有没有身份证号码”的员工的信息的时候，标准索引并不能够起到加速查询速度的作用。此时，就需要采用位图索引。因为位图索引会记录相关的NULL值列信息。","title":"创建oracle索引时需要注意的7个事项"},{"content":"在RDBMS管理的任何数据库中，基本数据表中的数据保持一致是非常重要的。如果数据的一致性遭到破坏，则数据就不能再使用。为了满足这一需求，数据库领域的的先驱们制定了两条完整性规则： 1、实体完整性（entity intergrity）：主键中的列不能是空（null）。主键提供了可以惟一地识别一行或者一个实体的方法。空值意味着不知道、不能键入、没有定义或不能应用的一个值。零或空格不能认为是空值。如果一行的主键值是空值，我们就无法获得这一行的足够信息来惟一地对这一行加以识别。RDBMS软件严格地遵循实体完整性规则，不允许用户输入主键列的值不惟一的行； 2、引用完整性（referential integrity）：外键值或者是空值，或者必须作为引用表的主键值而存在。","title":"Oracle笔记_完整性规则"},{"content":"   LINUX下MYSQL代码开发本人推荐使用MySQL Connector/C  (本人使用的开发包mysql-connector-c-6.0.2-linux-glibc2.3-x86-32bit.tar）如果你之前使用的是SQL SERVER + ADO的方式，代码需移植的话，简单封装一下MySql C的代码。    LINUX环境搭建请参考：LINUX 开发环境选择。 1、LINUX下MYSQL代码开发实例    参考：http://curran.blog.51cto.com/2788306/533169 2、关于乱码问题     问题一、LINUX默认使用UTF-8的字符集，在数据库连接之后，需要设置为UTF-8字符格式。     代码示例：mysql_query(m_pConnection,\"SET NAMES utf8\");     windows下代码如下：（ mysql c乱码解决）     char charset[32] = \"SET CHARACTER SET GBK\";     mysql_real_query(&mysql, charset, strlen(charset));     问题二、当你在程序中使用COUT输出中文时，一部分文件代码编译后输出正常，一部分文件代码编译后输出为乱码；     导致原因：因为通过Code::Builder创建的文件默认为UTF-8编码的，即显示乱码的文件编码不是UTF-8的。     解决办法：将该文件编码改为UTF-8，编辑->文件编码->UTF-8。 3、性能对比MYSQL  VS  SQL SERVER 2005     通过MySQL Connector/C在linux环境下数据加载方面明显优于SQL SERVER 2005 通过ADO的方式（Windows平台下）。","title":"LINUX下MYSQL代码开发 LINUX 开发环境选择"},{"content":"一、创建语句： 创建数据库：CREATE DATABASE menagerie; 选择数据库：USE menagerie 创建表：CREATE TABLE pet (name VARCHAR(20), owner VARCHAR(20),species VARCHAR(20), sexCHAR(1), birth DATE, death DATE); 二、 将数据装入表中 LOAD DATA和INSERT语句： 1、 要想将文本文件“pet.txt”装载到pet表中，使用这个命令：LOAD DATA LOCAL INFILE'/path/pet.txt' INTO TABLE pet; 2、insert语句： insert[into] 表名[（列名1,列名2，…）] values (值1,值2,…) ; insert[into] 表名[（列名1,列名2，…）]values(值1,值2,…), (值1,值2,…), (值1,值2,…)…; 三、删除数据 deletefrom 表名[where 条件]; 清空表中数据：Truncatetable 表名; 四、更新数据 update表名set 列名1=值[,列名2=值,…]where 条件; 五、查询数据 1、所有数据：SELECT * FROM pet; 2、特殊行：SELECT * FROM pet WHEREname = 'Bowser';条件可以组合or 与and，两者也可以混用，但是and要比or优先级高。 3、特殊列：SELECT name, birth FROMpet;DISTINCT关键字保证不重复。 4、 分类行：为了排序结果，使用ORDER BY子句（ASC 升序 DESC 降序） 分组，使用GROUP BY子句。 5、limit的用法： limit 一般用于经常要返回前几条或者中间某几行数据的查询语句语句中，具体格式如下： SELECT * FROM table LIMIT[offset,] rows| rows OFFSET offset LIMIT 子句可以被用于强制 SELECT 语句返回指定的记录数。LIMIT 接受一个或两个数字参数。参数必须是一个整数常量。如果给定两个参数，第一个参数指定第一个返回记录行的偏移量，第二个参数指定返回记录行的最大数目。初始记录行的偏移量是 0(而不是 1) 举例说明： mysql>SELECT*FROMtable LIMIT5,10;// 检索记录行6-15 为了检索从某一个偏移量到记录集的结束所有的记录行，可以指定第二个参数为-1： mysql>SELECT*FROMtable LIMIT95,-1;// 检索记录行96-last. //如果只给定一个参数，它表示返回最大的记录行数目： mysql>SELECT*FROMtable LIMIT5;//检索前5 个记录行 //换句话说，LIMIT n 等价于 LIMIT0,n。 而如果想要实现从数据库的最后一条倒序读出固定的信息条数，则可用： select * from tablename where(后加条件) order by (条件) desc limit (固定条数) ； 例如：如果想从表hello中读出10条以id形式排列的classID数为0的信息。可写为： select * from hello where classID=0 order by id desc limit 10; 在sql语句中，limit的功能很强大，使用的地方很多，所以要多注意，使用它能够很大的节省代码数，让代码看起来简洁明了 6、多表查询： （1）、子查询：一条SQL语句中嵌套select语句 select * from titles where title_id=(select title_id from titleauthor where au_id=(select au_id from authors where au_fname='johnson' and au_lname='white')); （2）、连接查询：内查询、外查询。 a、内连接 inner join：显示连接的两个表中符合连接条件的信息。 标准语句：select 列名表 from 表1 [inner] join 表2 on 表1.公共列=表2.公共列 常用语法：select 列名表 from 表1,表2 where 表1.公共列=表2.公共列 注：当连接查询时，显示的列名在多个表中都存在的话，需要在列名前加上表名或表的别名来明确指出列名出自那个表格。 b、外查询 outer join：显示一个表中所有的信息，显示另一个表中符合连接条件的信息。 标准语句：select 列名表 from 表1 [left|right] outer join 表2 on 表1.公共列=表2.公共列","title":"MySql数据库语句整理（一）"},{"content":"以下面试题都是在网上找的总结出来的，谢谢大家的分享！希望，我们共同进步，找到自己梦想的公司： 1.android dvm 的进程和Linux的进程，应用程序的进程是否为同一个概念： 答：dvm是dalivk虚拟机。每一个android应用程序都在自己的进程中运行，都拥有一个dalivk虚拟机实例。而每一个dvm都是在linux的一个进程。所以说可以认为是同一个概念。 2.android的动画有哪几种？他们的特点和区别是什么？ 答：两种，一种是tween动画，一种是frame动画。tween动画，这种实现方式可以使视图组件移动，放大或缩小以及产生透明度的变化。frame动画，传统的动画方法，通过顺序的播放排列好的图片来实现，类似电影。 3.handler进制的原理： 答：android提供了handler和looper来满足线程间的通信。Handler先进先出原则。looper用来管理特定线程内对象之间的消息交换（message Exchange）.     1)looper:一个线程可以产生一个looper对象，由它来管理此线程里的message queue(消息队列)    2)handler:你可以构造一个handler对象来与looper沟通，以便push新消息到messagequeue里；或者接收looper（从messagequeue里取出）所送来的消息。     3)messagequeue:用来存放线程放入的消息。     4)线程：UI thread 通常就是main thread,而android启动程序时会为它建立一个message queue. 4.android view的刷新： 答：Android中对View的更新有很多种方式，使用时要区分不同的应用场合。我感觉最要紧的是分清：多线程和双缓冲的使用情况。     1).不使用多线程和双缓冲    这种情况最简单了，一般只是希望在View发生改变时对UI进行重绘。你只需在Activity中显式地调用View对象中的invalidate()方法即可。系统会自动调用 View的onDraw()方法。     2).使用多线程和不使用双缓冲     这种情况需要开启新的线程，新开的线程就不好访问View对象了。强行访问的话会报：android.view.ViewRoot$CalledFromWrongThreadException：Only the originalthread that created a view hierarchy can touch its views.     这时候你需要创建一个继承了android.os.Handler的子类，并重写handleMessage(Messagemsg)方法。android.os.Handler是能发送和处理消息的，你需要在Activity中发出更新UI的消息，然后再你的Handler（可以使用匿名内部类）中处理消息（因为匿名内部类可以访问父类变量，你可以直接调用View对象中的invalidate()方法 ）。也就是说：在新线程创建并发送一个Message，然后再主线程中捕获、处理该消息。     3).使用多线程和双缓冲     Android中SurfaceView是View的子类，她同时也实现了双缓冲。你可以定义一个她的子类并实现SurfaceHolder.Callback接口。由于实现SurfaceHolder.Callback接口，新线程就不需要android.os.Handler帮忙了。SurfaceHolder中lockCanvas()方法可以锁定画布，绘制玩新的图像后调用unlockCanvasAndPost(canvas)解锁（显示），还是比较方便得。   5.说说mvc模式的原理，它在android中的运用: 答：android的官方建议应用程序的开发采用mvc模式。何谓mvc？   　mvc是model,view,controller的缩写，mvc包含三个部分：   　　l模型（model）对象：是应用程序的主体部分，所有的业务逻辑都应该写在该层。 　　2视图（view）对象：是应用程序中负责生成用户界面的部分。也是在整个mvc架构中用户唯一可以看到的一层，接收用户的输入，显示处理结果。 　　3控制器（control）对象：是根据用户的输入，控制用户界面数据显示及更新model对象状态的部分，控制器更重要的一种导航功能，想用用户出发的相关事件，交给m哦得了处理。   　android鼓励弱耦合和组件的重用，在android中mvc的具体体现如下：     1)视图层（view）：一般采用xml文件进行界面的描述，使用的时候可以非常方便的引入，当然，如何你对android了解的比较的多了话，就一定 可以想到在android中也可以使用javascript+html等的方式作为view层，当然这里需要进行java和javascript之间的通 信，幸运的是，android提供了它们之间非常方便的通信实现。 　2)控制层（controller）：android的控制层的重 任通常落在了众多的acitvity的肩上，这句话也就暗含了不要在acitivity中写代码，要通过activity交割model业务逻辑层处理， 这样做的另外一个原因是android中的acitivity的响应时间是5s，如果耗时的操作放在这里，程序就很容易被回收掉。 　3)模型层（model）：对数据库的操作、对网络等的操作都应该在model里面处理，当然对业务计算等操作也是必须放在的该层的。   6.Activity的生命周期: 答：onCreate: 在这里创建界面，做一些数据 的初始化工作   　　onStart: 到这一步变成用户可见不可交互的     onResume:变成和用户可交互 的，(在activity 栈系统通过栈的方式管理这些个Activity的最上面，运行完弹出栈，则回到上一个Activity) 　　onPause: 到这一步是可见但不可交互的，系统会停止动画 等消耗CPU 的事情从上文的描述已经知道，应该在这里保存你的一些数据,因为这个时候你的程序的优先级降低，有可能被系统收回。在这里保存的数据，应该在 　　onstop: 变得不可见，被下一个activity覆盖了 onDestroy: 这是activity被干掉前最后一个被调用方法了，可能是外面类调用finish方法或者是系统为了节省空间将它暂时性的干掉   7.让Activity变成一个窗口： 答：Activity属性设定：有时候会做个应用程序是漂浮在手机主界面的。这个只需要在设置下Activity的主题theme,即在Manifest.xml定义Activity的地方加一句： android :theme=\"@android:style/Theme.Dialog\" 如果是作半透明的效果： android:theme=\"@android:style/Theme.Translucent\" 8.Android中常用的五种布局: 答：LinearLayout线性布局；AbsoluteLayout绝对布局；TableLayout表格布局；RelativeLayout相对布局；FrameLayout帧布局； 9.Android的五种数据存储方式： 答：sharedPreferences；文件；SQLite；contentProvider；网络 10.请解释下在单线程模型中Message、Handler、Message Queue、Looper之间的关系： 答：Handler获取当前线程中的looper对象，looper用来从存有Message的Message Queue里取出message，再由Handler进行message的分发和处理。 11.AIDL的全称是什么?如何工作?能处理哪些类型的数据? 答：AIDL(AndroidInterface Definition Language)android接口描述语言 12.系统上安装了多种浏览器，能否指定某浏览器访问指定页面？请说明原由： 答：通过直接发送Uri把参数带过去，或者通过manifest里的intentfilter里的data属性。代码如下：     Intent intent = new Intent(); Intent.setAction(“android.intent.action.View”); Uri uriBrowsers = Uri.parse(“http://www.sina.com.cn”); Intent.setData(uriBrowsers); //包名、要打开的activity     intent.setClassName(“com.android.browser”,”com.android.browser.BrowserActivity”); startActivity(intent); 13.什么是ANR,如何避免？ 答：ANR的定义： 在android上，如果你的应用程序有一段时间响应不移灵敏，系统会向用户提示“应用程序无响应”（ANR：application Not Responding）对话框。因此，在程序里对响应性能的设计很重要，这样，系统不会显示ANR给用户。 如何避免： 首先来研究下为什么它会在android的应用程序里发生和如何最佳构建应用程序来避免ANR.     android应用程序通常是运行在一个单独的线程（例如：main）里，这就意味你的应用程序所做的事情如果在主线程里占用了大长时间的话，就会引发ANR对话框，因为你的应用程序并没有给自己机会来处理输入事件或者Intent广播。     因此，运行在主线程里的任何访求都尽可能少做事情。特别是，activity应该在它的关键生命周期方法（onCreate()和onResume()）里尽可能少的去作创建操作。潜在的耗时操作，例如网络或数据库操作，或者高耗时的计算如改变位图尺寸，应该在子线程里（或者以数据库操作为例，通过异步请求的方式）来完成。然而，不是说你的主线程阻塞在那里等待子线程的完成---也不是调用Thread.wait()或者Thread.sleep()。替代的方法是：主线程应该为子线程提供一个Handler,以便完成时能够提交给主线程。以这种方式设计你的应用程序，将能保证你的主线程保持对输入的响应性并能避免由5秒输入事件的超时引发的ANR对话框。这种做法应该在其它显示UI的线程里效仿，因为它们都受相同的超时影响。     IntentReceiver执行时间的特殊限制意味着它应该做：在后台里做小的、琐碎的工作，如保存设定或注册一个Notification。和在主线程里调用的其它方法一样，应用程序应该避免在BroadcastReceiver里做耗时的操作或计算，但也不是在子线程里做这些任务（因为BroadcastReceiver的生命周期短），替代的是，如果响应Intent广播需要执行一个耗时的动作的话，应用程序应该启动一个Service。顺便提及一句，你也应该避免在Intent Receiver里启动一个Activity，因为它会创建一个新的画面，并从当前用户正在运行的程序上抢夺焦点。如果你的应用程序在响应Intent广播时需要向用户展示什么，你应该使用Notification Manager来实现。     一般来说，在应用程序里，100到200ms是用户能感知阻滞的时间阈值，下面总结了一些技巧来避免ANR,并有助于让你的应用程序看起来有响应性。     如果你的应用程序为响应用户输入正在后台工作的话，可以显示工作的进度（ProgressBar和ProgressDialog对这种情况来说很有用）。特别是游戏，在子线程里做移动的计算。如果你的程序有一个耗时的初始化过程的话，考虑可以显示一个Splash Screen或者快速显示主画面并异步来填充这些信息。在这两种情况下，你都应该显示正在进行的进度，以免用户认为程序被冻结了。   14.什么情况会导致Force Close？如何避免？能否捕获导致其的异常？ 答：如空指针等可以导致ForceClose;可以看Logcat，然后找到对应的程序代码来解决错误。 15.横竖屏切换时候的activity的生命周期： 答： 1） 新建一个activity,并把各个生命周期打印出来 2） 运行activity，得到如下信息： onCreate()à onStart()à onResume()à     3)  按ctrl+F12切换成横屏时         onSaveInstanceState()à         onPause()à         onStop()à         onDestroy()à         onCreate()à         onStart()à         onRestoreInstanceState()à         onResume()à     4)  再按ctrl+f12切换成竖屏时，发现打印了两次相同的Log         onSaveInstanceState()à         onPause()à         onStop()à         onDestroyà         onCreate()à         onStart()à         onRestoreInstanceState()à         onResume()à           onSaveInstanceState()à         onPause()à         onStop()à         onDestroyà         onCreate()à         onStart()à         onRestoreInstanceState()à         onResume()à     5)  修改AndroidManifest.xml，把该Activity添加android:configChanges=“orientation”,执行步骤3         onSaveInstanceState()à         onPause()à         onStop()à         onDestroy()à         onCreate()à         onStart()à         onRestoreInstanceState()à         onResume()à     6)  修改AndroidManifest.xml，把该Activity添加android:configChanges=“orientation”,执行步骤4,发现不会再打印相同信息，但多打印了一行onConfigChanged         onSaveInstanceState()à         onPause()à         onStop()à         onDestroy()à         onCreate()à         onStart()à         onRestoreInstanceState()à         onResume()à         onConfigurationChanged()à     7)  把步骤5的android:configChanges=“orientation”改成 android:configChanges=“orientation|keyboradHidden”,执行步骤3，就只打印onConfigChanged         onConfigurationChanged()à     8)  把步骤5的android:configChanges=“orientation”改成 android:configChanges=“orientation|keyboradHidden”,执行步骤4         onConfigurationChanged()à         onConfigurationChanged()à     总结： 1） 不设置activity的android:configChanges时,切屏会重新调用各个生命周期，切横屏时会执行一次，切竖屏时会执行两次。 2） 设置activity的android:configChanges=“orientation”时, 切屏会重新调用各个生命周期，切横屏、竖屏时都只会执行一次，但是竖屏最后多打印一条onConfigurationChanged() 3） 设置activity的android:configChanges=“orientation|keyboardHidden”时,切屏不会重新调用各个生命周期，只会执行onConfigurationChanged(),横屏一次，竖屏两次 再总结下整个activity的生命周期： 1）  当前activity产生事件弹出Toast和AlertDialog的时候Activity的生命周期不会有改变 2）  Activity运行时按下HOME键（跟被完全覆盖一样的） onSavaInstanceStateà onPauseà onStopà   onRestartà onStartà onResumeà     3)  未被完全覆盖，只是失去焦点：         onPauseà         onResumeà 16.如何将SQLite数据库(.db文件)与apk文件一起发布? 答：可以将.db文件复制到Eclipse Android工程中的res aw目录中。所有在res aw目录中的文件不会被压缩，这样可以直接提取该目录中的文件。可以将.db文件复制到res aw目录中 17.如何将打开res aw目录中的数据库文件? 答：在Android中不能直接打开res aw目录中的数据库文件，而需要在程序第一次启动时将该文件复制到手机内存或SD卡的某个目录中，然后再打开该数据库文件。复制的基本方法是使用getResources().openRawResource方法获得res aw目录中资源的 InputStream对象，然后将该InputStream对象中的数据写入其他的目录中相应文件中。在Android SDK中可以使用SQLiteDatabase.openOrCreateDatabase方法来打开任意目录中的SQLite数据库文件。 18.android 中有哪几种解析xml的类？官方推荐哪种？以及它们的原理和区别： 答：XML解析主要有三种方式，SAX、DOM、PULL。常规在PC上开发我们使用Dom相对轻松些，但一些性能敏感的数据库或手机上还是主要采用SAX方 式，SAX读取是单向的，优点:不占内存空间、解析属性方便，但缺点就是对于套嵌多个分支来说处理不是很方便。而DOM方式会把整个XML文件加载到内存 中去，这里Android开发网提醒大家该方法在查找方面可以和XPath很好的结合如果数据量不是很大推荐使用，而PULL常常用在J2ME对于节点处 理比较好，类似SAX方式，同样很节省内存，在J2ME中我们经常使用的KXML库来解析。 19.DDMS和TraceView的区别? 答：DDMS是一个程序执行查看器，在里面可以看见线程和堆栈等信息，TraceView是程序性能分析器 20.谈谈Android的IPC机制： 答：IPC是内部进程通信的简称，是共享\"命名管道\"的资源。Android中的IPC机制是为了让Activity和Service之间可以随时的进行交互，故在Android中该机制，只适用于Activity和Service之间的通信，类似于远程方法调用，类似于C/S模式的访问。通过定义AIDL接口文件来定义IPC接口。Servier端实现IPC接口，Client端调用IPC接口本地代理。 21.NDK是什么： 答：NDK是一系列工具的集合     NDK提供了一系列的工具，帮助开发者迅速的开发C/C++的动态库，并能自动将so和java应用打成apk包     NDK集成了交叉编译器，并提供了相应的mk文件和隔离cpu，平台等的差异，开发人员只需简单的修改mk文件就可以创建出so 22.描述一下android的系统架构： 答：android系统架构分从下往上为Linux内核层、运行库、应用程序框架层和应用程序层。     Linux内核层：负责硬件的驱动程序、网络、电源、系统安全以及内存管理等功能。 运行库和androidruntion：运行库：即c/c++函数库部分，大多数都是开放源代码的函数库，例如webkit，该函数库负责android网页浏览器的运行；例如标准的c函数库libc、openssl、sqlite等，当然也包括支持游戏开发的2dsgl和3dopengles，在多媒体方面有mediaframework框架来支持各种影音和图形文件的播放与显示，如mpeg4、h.264、mp3、aac、amr、jpg和png等众多的多媒体文件格式。Androidruntion负责解释和执行生成的dalvik格式的字节码 应用软件架构：java应用程序开发人员主要是使用该层封装好的api进行快速开发的。 应用程序层：该层是java的应用程序层，android内置的googlemaps、email、IM、浏览器等，都处于该层，java开发人员工发的程序也处于该层，而且和内置的应用程序具有平等的地位，可以调用内置的应用程序，也可以替换内置的应用程序 23.Activity 与 Task的启动模式有哪些，它们含义具体是什么? 答：在一个activity中，有多次调用startActivity来启动另一个activity，要想只生成一个activity实例，可以设置启动模式。     一个activity有四种启动模式：standed,signleTop,singleTask,singleInstance     Standed:标准模式，一调用startActivity()方法就会产生一个新的实例。     SingleTop:如果已经有一个实例位于activity栈顶，就不产生新的实例，而只是调用activity中的newInstance()方法。如果不位于栈顶，会产生一个新的实例。     singleTask:会在一个新的task中产生这个实例，以后每次调用都会使用这个，不会去产生新的实例了。     SingleInstance:这个和singleTask基本一样，只有一个区别：在这个模式下的activity实例所处的task中，只能有这个activity实例，不能有其他实例 24.Application类的作用： 答：API里的第一句是： Base class for those who need to maintain global application state  如果想在整个应用中使用全局变量，在java中一般是使用静态变量，public类型；而在android中如果使用这样的全局变量就不符合Android的框架架构，但是可以使用一种更优雅的方式就是使用Application context。    首先需要重写Application，主要重写里面的onCreate方法，就是创建的时候，初始化变量的值。然后在整个应用中的各个文件中就可以对该变量进行操作了。    启动Application时，系统会创建一个PID，即进程ID，所有的Activity就会在此进程上运行。那么我们在Application创建的时候初始化全局变量，同一个应用的所有Activity都可以取到这些全局变量的值，换句话说，我们在某一个Activity中改变了这些全局变量的值，那么在同一个应用的其他Activity中值就会改变 25.说明onSaveInstanceState() 和 onRestoreInstanceState()在什么时候被调用： 答：Activity的 onSaveInstanceState() 和 onRestoreInstanceState()并不是生命周期方法，它们不同于 onCreate()、onPause()等生命周期方法，它们并不一定会被触发。当应用遇到意外情况（如：内存不足、用户直接按Home键）由系统销毁一个Activity时，onSaveInstanceState()才会被调用。但是当用户主动去销毁一个Activity时，例如在应用中按返回键，onSaveInstanceState()就不会被调用。因为在这种情况下，用户的行为决定了不需要保存Activity的状态。通常onSaveInstanceState()只适合用于保存一些临时性的状态，而onPause()适合用于数据的持久化保存。 另外，当屏幕的方向发生了改变， Activity会被摧毁并且被重新创建，如果你想在Activity被摧毁前缓存一些数据，并且在Activity被重新创建后恢复缓存的数据。可以重写Activity的 onSaveInstanceState() 和 onRestoreInstanceState()方法。 26.android的service的生命周期？哪个方法可以多次被调用： 答：1)与采用Context.startService()方法启动服务有关的生命周期方法 onCreate() -> onStart() -> onDestroy() onCreate()该方法在服务被创建时调用，该方法只会被调用一次，无论调用多少次startService()或bindService()方法，服务也只被创建一次。 onStart() 只有采用Context.startService()方法启动服务时才会回调该方法。该方法在服务开始运行时被调用。多次调用startService()方法尽管不会多次创建服务，但onStart() 方法会被多次调用。 onDestroy()该方法在服务被终止时调用。 2)与采用Context.bindService()方法启动服务有关的生命周期方法 onCreate() -> onBind() -> onUnbind() -> onDestroy() onBind()只有采用Context.bindService()方法启动服务时才会回调该方法。该方法在调用者与服务绑定时被调用，当调用者与服务已经绑定，多次调用Context.bindService()方法并不会导致该方法被多次调用。 onUnbind()只有采用Context.bindService()方法启动服务时才会回调该方法。该方法在调用者与服务解除绑定时被调用。 如果先采用startService()方法启动服务,然后调用bindService()方法绑定到服务，再调用unbindService()方法解除绑定，最后调用bindService()方法再次绑定到服务，触发的生命周期方法如下： onCreate() ->onStart() ->onBind() ->onUnbind()[重载后的方法需返回true] ->onRebind() 27.android的broadcast的生命周期： 答：1)Broadcast receiver生命周期中仅有一个回调方法：  void onReceive(Context curContext, Intent broadcastMsg)  当接收器接收到一条broadcast消息，Android就会调用onReceiver(),并传递给它一个Intent对象，这个对象携带着那条broadcast消息。我们认为仅当执行这个方式时，Broadcast receiver是活动的；这个方法返回时，它就终止了。这就是Broadcast receiver的生命周期。  2)由于Broadcast receiver的生命周期很短，一个带有活动的Broadcast receiver的进程是受保护的，以避免被干掉；但是别忘了有一点，Android会在任意时刻干掉那些携带不再活动的组件的进程，所以很可能会造成这个问题。  3)解决上述问题的方案采用一个Service来完成这项工作，Android会认为那个进程中（Service所在的进程）仍然有在活动的组件。  28.android view，surfaceview，glsurfaceview的区别： 答：SurfaceView是从View基类中派生出来的显示类，直接子类有GLSurfaceView和VideoView，可以看出GL和视频播放以及Camera摄像头一般均使用SurfaceView SurfaceView和View最本质的区别在于，surfaceView是在一个新起的单独线程中可以重新绘制画面而View必须在UI的主线程中更新画面。  那么在UI的主线程中更新画面 可能会引发问题，比如你更新画面的时间过长，那么你的主UI线程会被你正在画的函数阻塞。那么将无法响应按键，触屏等消息。  当使用surfaceView 由于是在新的线程中更新画面所以不会阻塞你的UI主线程。但这也带来了另外一个问题，就是事件同步。比如你触屏了一下，你需要surfaceView中thread处理，一般就需要有一个event queue的设计来保存touch event，这会稍稍复杂一点，因为涉及到线程同步。  所以基于以上，根据游戏特点，一般分成两类。  1)被动更新画面的。比如棋类，这种用view就好了。因为画面的更新是依赖于 onTouch 来更新，可以直接使用 invalidate。 因为这种情况下，这一次Touch和下一次的Touch需要的时间比较长些，不会产生影响。  2)主动更新。比如一个人在一直跑动。这就需要一个单独的thread不停的重绘人的状态，避免阻塞main UI thread。所以显然view不合适，需要surfaceView来控制。 ","title":"android面试题 不单单为了面试也是一次很好的学习"},{"content":"/// <summary>         /// 获取UserInfo泛型集合         /// <\/summary>         /// <param name=\"connStr\">数据库连接字符串<\/param>         /// <param name=\"sqlStr\">要查询的T-SQL<\/param>         /// <returns><\/returns>         public IList<UserInfo> GetUserInfoAll(string connStr, string sqlStr)         {             using (SqlConnection conn = new SqlConnection(connStr))             {                 using (SqlCommand cmd = new SqlCommand(sqlStr, conn))                 {                     SqlDataReader sdr = cmd.ExecuteReader();                     IList<UserInfo> list = new List<UserInfo>();                     while (sdr.Read())                     {                         UserInfo userInfo = new UserInfo();                         userInfo.ID = (Guid)sdr[\"ID\"];                         userInfo.LoginName = sdr[\"LoginName\"].ToString();                         userInfo.LoginPwd = sdr[\"LoginPwd\"].ToString();                         list.Add(userInfo);                     }                     return list;                 }             }         }         /// <summary>         /// 获取泛型集合         /// <\/summary>         /// <typeparam name=\"T\">类型<\/typeparam>         /// <param name=\"connStr\">数据库连接字符串<\/param>         /// <param name=\"sqlStr\">要查询的T-SQL<\/param>         /// <returns><\/returns>         public IList<T> GetList<T>(string connStr, string sqlStr)         {             using (SqlConnection conn = new SqlConnection(connStr))             {                 using (SqlDataAdapter sda = new SqlDataAdapter(sqlStr, conn))                 {                     DataSet ds = new DataSet();                     sda.Fill(ds);                     return DataSetToList<T>(ds, 0);                 }             }         }         /// <summary>         /// DataSetToList         /// <\/summary>         /// <typeparam name=\"T\">转换类型<\/typeparam>         /// <param name=\"dataSet\">数据源<\/param>         /// <param name=\"tableIndex\">需要转换表的索引<\/param>         /// <returns><\/returns>         public IList<T> DataSetToList<T>(DataSet dataSet, int tableIndex)         {             //确认参数有效             if (dataSet == null || dataSet.Tables.Count <= 0 || tableIndex < 0)                 return null;             DataTable dt = dataSet.Tables[tableIndex];             IList<T> list = new List<T>();             for (int i = 0; i < dt.Rows.Count; i++)             {                 //创建泛型对象                 T _t = Activator.CreateInstance<T>();                 //获取对象所有属性                 PropertyInfo[] propertyInfo = _t.GetType().GetProperties();                 for (int j = 0; j < dt.Columns.Count; j++)                 {                     foreach (PropertyInfo info in propertyInfo)                     {                         //属性名称和列名相同时赋值                         if (dt.Columns[j].ColumnName.ToUpper().Equals(info.Name.ToUpper()))                         {                             if (dt.Rows[i][j] != DBNull.Value)                             {                                 info.SetValue(_t, dt.Rows[i][j], null);                             }                             else                             {                                 info.SetValue(_t, null, null);                             }                             break;                         }                     }                 }                 list.Add(_t);             }             return list;         }","title":"C#读取数据库返回泛型集合 把DataSet类型转换为List<T>泛型集合"},{"content":"方法1:  mysqladmin -u root password ‘new_password’   方法2:  mysql -uroot -p UPDATE user SET password=PASSWORD(‘new_password’) WHERE user=’root’; FLUSH PRIVILEGES;   方法3:  mysql -uroot -p SET PASSWORD FOR root=PASSWORD(‘new_password’); 方法4 不知道root密码情况下修改root密码  使用下面方法启动  mysql mysqld_safe –skip-grant-tables &","title":"修改mysql密码的几种方法"},{"content":"前一阵子要研究下好的mysql备份方案，很多朋友介绍percona的xtrabackup，于是尝试安装使用了一下。 1. 下载XtraBackup并安装 我测试的时候最新的版本是1.6 ，从这里可以选择不同OS的相应版本： http://www.percona.com/downloads/XtraBackup/XtraBackup-1.6/ 在LINUX下你可以直接运行： wget http://www.percona.com/redir/downloads/XtraBackup/XtraBackup-1.6/RPM/rhel5/x86_64/xtrabackup-1.6-245.rhel5.x86_64.rpmrpm -ivh xtrabackup-1.6-245.rhel5.x86_64.rpm 2. 数据库中建立备份账号 GRANT SELECT, RELOAD, LOCK TABLES, REPLICATION CLIENT ON *.* TO ‘username’@'localhost’ IDENTIFIED BY ‘password’; 这个帐户主要是用来完成备份时一些锁表等工作； 3. 全量备份与恢复 一般库不大（< 200G）,我们就选择用全量备份 ； innobackupex-1.5.1 工具是用PERL包装过的”xtrabackup“，他不旦可以备份INNODB，还可以备份MYISAM等非事务数据库； 也就是说innobakcup封装了xtrabackup，因为xtrabackup理论上只能备份innodb引擎的。如果要备份同一个库的myisam引擎，则需要特殊处理之。 3.1 全量备份 # 指定mysql配置文件路径mycnf=/etc/my.cnf#指定备份根目录backup_path=/data/mysqlbackup# 开始备份innobackupex-1.5.1 –user=username –password=password –host=127.0.0.1 –port=3306 –slave-info –tmpdir=$backup_path –defaults-file=$mycnf $backup_path 2> $backup_path/xtrabk.log ### 注意点： 在备份过程中，把INNODB数据文件备份完成后，会锁住整个库，并开始复制MYISAM等非事务引擎的数据和.frm； 所以如果你拥有比较多的MYISAM表，锁库的时候会持续很长。如果是在主库上运行，千万注意。 3.2 全量恢复 3.2.1 应用日志 ## 这个过程主要是产生REDOLOG并将备份期间产生的REDO应用到数据文件中； ## xtrabackup 会启动一个INNODB进程去做，与你当前在跑的不冲突 innobackupex-1.5.1 -apply-log /data/mysqlbackup/ 3.2.2 复制数据文件到数据目录 ## 这个过程将恢复好的数据复制到my.cnf中指定的数据目录中。 这时你需要把原有的实例停掉 innobackupex-1.5.1 -copy-back /data/mysqlbackup/ 4. 增量备份 增量备份我们只能使用xtrabackup工具； 1）只能用于INNODB 2）my.cnf文件[mysqld]中需要设置 default_table_type=InnoDB 4.1 全量备份（参考 3.1） 4.2 增量备份 （只复制变化过的块） #指定备份根目录backup_path=/data/mysqlbackup/2012-03-23_10-03-41/#指定备份根目录incre_path=/data/mysqlbackup/incre001#开始备份xtrabackup –defaults-file=/etc/my.cnf –backup –target-dir=$incre_path –incremental-basedir=$backup_path 在/data/mysqlbackup/incre001将产生一些.delta数据文件； 另外可以注意xtrabackup_checkpoints这个文件lsn的变化 4.3 恢复 （先恢复全量备份的日志） ## 用增量备份加入全量数据xtrabackup –defaults-file=/etc/my.cnf –prepare –target-dir=/data/mysqlbackup/2012-03-23_10-03-41/xtrabackup –target-dir=/data/mysqlbackup/2012-03-23_10-03-41/ –prepare –incremental-dir=/data/mysqlbackup/incre001## 应用日志xtrabackup –defaults-file=/etc/my.cnf –prepare –target-dir=/data/mysqlbackup/2012-03-23_10-03-41/ 可以看出，使用xtrabackup是粒度非常大的备份工具，一次必须备份整个库。 如果需要粒度比较小的方案，那么推荐mydumper，可以每个表导出一个文件，方便恢复。 然而xtrabackup的热备功能是无可比拟的，这个方面有需要的朋友，强烈推荐使用之。","title":"MySQL的热备份开源工具XtraBackup"},{"content":" 机房收费系统中有这样两个窗体，日结账单，周结账单，其中要做个机房收入汇总表，会用到Grid++Report报表设计器来设计报表，有很多同学已经把报表做完了，听说不好做，说实话自从我听说它不好做以后自己好像就有往后拖拖的想法，想把其它的都做好了以后再回头做这两个窗体，但是今天在去打水的路上听到电梯门口那传来这样的一句话“哇，报表终于做出来啦，轻松啦，太美啦，哈哈哈哈哈哈的一段笑声”，因为我已经把这件事看做是很难的意见事了，于是在别人说做完报表的时候我也觉得这是一件多么高兴的事了，回到自己的座位上运行了一下胡阳师哥的那个例子，看了看那两个窗体，决定马上去了解一下，为做报表做好充分的准备 ，嘿嘿。 下面是制作报表的过程 一.创建空白模板 启动Grid++Report 报表设计器，此时一个空白的报表模板创建在报表设计器应用程序中。如下图所示   二．定义报表头 1．执行菜单命令“插入”→“报表头”，一个新的报表头被创建。如下图所示：   2．执行菜单命令“插入”→“静态框”，将鼠标光标移动到报表头之上，拖放鼠标。   通过以上，就创建了一个静态框，其“名称”属性应为“StaticBox1”。 3．设置 StaticBox1 的“文本”属性设为“机房收入汇总”。如下图所示：   4．设置 StaticBox1 的“居中”属性，设置 StaticBox1 的“字体”等等 5．在 StaticBox1 上单击鼠标右键弹出关联菜单，执行命令“自动调整大小”，将 StaticBox1 的大小自动调整到合适      6．执行菜单命令“文件”→“保存”保存文件，在文件对话框选择合适的目录位置并输入文件名“机房收入汇总列表”。   至此已经完成报表头的定义，并保存为一个模板文件了。    三．插入明细网格 执行菜单命令“插入”→“明细网格”，明细网格将被创建。如下图所示：   一个明细网格已经添加到报表定义中。如下图所示：    四．绑定明细网格数据   1．执行菜单命令“报表”→“数据库查询...”，“设置数据库连接串与查询SQL”对话框打开。       2．在“设置数据库连接串与查询SQL”对话框中，执行“创建数据库连接串...”按钮。       3．然后执行“下一步(N)>>”按钮,将连接中的三项设置好，进行测试       4.测试成功以后点击“确定”按钮 ，将看到下面的界面      5.在“查询 SQL”编辑框中输入“select * from CheckDay_Info”，注意不要包括引号，表示将从 CheckDay_Info 表中取其所有数据。        6．执行“测试”按钮验证数据库连接串与查询 SQL是否正确设置。 7．执行“确定”按钮关闭设置数据库连接串与查询SQL对话框，至此已经完成报表明细数据的绑定。    五．生成报表数据集的字段 1．执行菜单命令“编辑”→“根据查询生成字段”，此时 Grid++Report 将根据上一步中创建的数据库连接串与查询 SQL 参数自动生成报表明细记录集的字段,生成的字段与数据库表中的字段保持一致。   2.执行菜单命令“报表”→“字段集合...”，打开“字段集合”对话框中可以看到刚才自动创建的各个字段。 下面是我将标题行和内容行的字段名分别改成汉子的形式 3.操作以后是这样的效果   至此已经完成了报表数据绑定与数据存储方面的定义工作，下一步就是怎样将报表数据展现出来。 4.通过点击设计器下端的“预览视图”与“查询视图”切换按钮，大家可以及时看到报表的运行效果，其实在整个设计过程中，大家都可以随时进入预览视图与查询视图，及时查看报表的运行效果。 这就是我做出的报表的大概模版，制作报表的过程没有我想象的那么困难，接下来就是把报表完善好进行与vb的连接了。","title":"做报表前的准备"},{"content":"BOOL CAdminDlg::OnInitDialog() {\tCDialog::OnInitDialog();\t\t// TODO: Add extra initialization here\tCFont font;\tfont.CreatePointFont(300,\"宋体\");\tGetDlgItem(IDC_STATIC_SHOW)->SetWindowText(\"欢迎来到学生选课系统\");\tGetDlgItem(IDC_STATIC_SHOW)->SetFont(&font);\t\tHTREEITEM hRoot=m_Tree.InsertItem(\"管理员\",0,0);\tHTREEITEM hleaf=m_Tree.InsertItem(\"学生信息\",1,1,hRoot);\tHTREEITEM hleaf01=m_Tree.InsertItem(\"学生信息管理\",2,2,hleaf);// \tHTREEITEM hleaf02=m_Tree.InsertItem(\"学生信息添加\",2,2,hleaf);// \tHTREEITEM hleaf03=m_Tree.InsertItem(\"学生信息删除\",2,2,hleaf);\tHTREEITEM hleaf1=m_Tree.InsertItem(\"课程信息\",1,1,hRoot);  \tHTREEITEM hleaf11=m_Tree.InsertItem(\"课程信息管理\",2,2,hleaf1);// \tHTREEITEM hleaf12=m_Tree.InsertItem(\"课程信息添加\",2,2,hleaf1);// \tHTREEITEM hleaf13=m_Tree.InsertItem(\"课程信息删除\",2,2,hleaf1);// \tHTREEITEM hleaf2=m_Tree.InsertItem(\"学生成绩\",1,1,hRoot);//  \tHTREEITEM hleaf21=m_Tree.InsertItem(\"学生成绩管理\",2,2,hleaf2);// // \tHTREEITEM hleaf22=m_Tree.InsertItem(\"学生成绩添加\",2,2,hleaf2);// // \tHTREEITEM hleaf23=m_Tree.InsertItem(\"学生成绩删除\",2,2,hleaf2);\tHTREEITEM hleaf3=m_Tree.InsertItem(\"用户管理\",1,1,hRoot);\tHTREEITEM hleaf31=m_Tree.InsertItem(\"用户管理信息\",2,2,hleaf3);// \tHTREEITEM hleaf31=m_Tree.InsertItem(\"用户修改\",2,2,hleaf3);// \tHTREEITEM hleaf32=m_Tree.InsertItem(\"用户添加\",2,2,hleaf3);// \tHTREEITEM hleaf33=m_Tree.InsertItem(\"用户删除\",2,2,hleaf3);\tm_Tree.Expand(hRoot,TVE_EXPAND);// \tHTREEITEM hleaf=m_Tree.InsertItem(\"学生信息\",1,1,hRoot);\tm_List.SetExtendedStyle(LVS_EX_FLATSB|LVS_EX_FULLROWSELECT|LVS_EX_HEADERDRAGDROP|LVS_EX_ONECLICKACTIVATE|LVS_EX_GRIDLINES);\t\tm_List.InsertColumn(0,\"学号\",LVCFMT_LEFT,60);// \tm_List.InsertColumn(1,\"姓名\",LVCFMT_LEFT,60);// \tm_List.InsertColumn(2,\"班级\",LVCFMT_LEFT,60);\tm_List.InsertColumn(1,\"英语\",LVCFMT_LEFT,60);\tm_List.InsertColumn(2,\"语文\",LVCFMT_LEFT,60);\tm_List.InsertColumn(3,\"C\",LVCFMT_LEFT,60);\tm_List.InsertColumn(4,\"C++\",LVCFMT_LEFT,60);\tm_List.InsertColumn(5,\"计算机\",LVCFMT_LEFT,60);\tAddToList();//\tOnClickList1();//\tGetDlgItem(IDC_EDIT8)->EnableWindow(FALSE);\t\t\t//连接数据库\tCADO ado;\tado.CADOConnect();\t\t//设置查询字符串\tCString str;\tstr= \"select * from student_xuank\";\t//创建记录集指针对象实例\t//m_pRecordset.CreateInstance(__uuidof(Recordset));\t_RecordsetPtr pRS = ado.Select(str);\t//打开记录集\t// \tm_pRecordset->Open(bstrSQL,m_pConnection.GetInterfacePtr(),adOpenDynamic,\t// \t\tadLockOptimistic,adCmdText);\twhile(!pRS->adoEOF)\t{\t\tint m=0;\t\t//m_List.SetExtendedStyle(LVS_EX_CHECKBOXES);\t\t\t\t//m_ctlList.InsertItem(0,\"\");\t\t// m_List.InsertItem(m, _T(\"\"));\t\t//\tm_List.SetCheck(m, FALSE);>GetItem(_variant_t(\"姓名\"))->Value=_bstr_t(\"赵薇\");\t\t\t\tCString str;\t\tstr=(char*)(_bstr_t)(pRS->Fields->GetItem(_variant_t(\"english\"))->Value);\t\t//MessageBox(str);\t\t\t\t//m_List.SetItemText(0,0,(char*)(_bstr_t)(pRS->Fields->GetItem(_variant_t(\"sno\"))->Value));// \t\t// \t\tm_List.SetItemText(0,1,(char*)(_bstr_t)(pRS->Fields->GetItem(_variant_t(\"english\"))->Value));// \t\tm_List.SetItemText(0,2,(_bstr_t)pRS->GetCollect(\"chinese\"));// \t\tm_List.SetItemText(0,3,(_bstr_t)pRS->GetCollect(\"c\"));// \t\tm_List.SetItemText(0,4,(_bstr_t)pRS->GetCollect(\"cplusplus\"));// \t\tm_List.SetItemText(0,5,(_bstr_t)pRS->GetCollect(\"computer\"));// \t\t\t\t\t\tm++;\t\t\t\t//将记录集指针移动到下一条记录\t\tpRS->MoveNext();\t}\treturn TRUE;  // return TRUE unless you set the focus to a control\t              // EXCEPTION: OCX Property Pages should return FALSE}void CAdminDlg::OnClickTree1(NMHDR* pNMHDR, LRESULT* pResult) {\t// TODO: Add your control notification handler code here\t\t*pResult = 0;}void CAdminDlg::OnDblclkTree1(NMHDR* pNMHDR, LRESULT* pResult) {\t// TODO: Add your control notification handler code here\tm_hTreeItem = m_Tree.GetSelectedItem();// \tHTREEITEM hroot=m_hTreeItem.GetParent();\t// CString S1 = m_Tree.GetItemText(hroot);// \tif(m_Tree.GetItemText(m_hTreeItem)==\"课程信息管理\")// \t{// \t\tCKCADDDlg mydlg;// \t\tmydlg.DoModal();// \t\treturn;// \t}\tif(m_Tree.GetItemText(m_hTreeItem)==\"学生信息管理\")\t{\t\tCKCADDDlg mydlg;\t\tmydlg.DoModal();\t\treturn;\t}\tif(m_Tree.GetItemText(m_hTreeItem)==\"课程信息管理\")\t{\t\tCKCMODDlg   mydlg;\t\tmydlg.DoModal();\t\treturn;\t}\tif(m_Tree.GetItemText(m_hTreeItem)==\"用户管理信息\")\t{\t\tCUSERDlg  mydlg;\t\tmydlg.DoModal();\t\treturn;\t}\t*pResult = 0;}//static CKCDELDlg dlg;void CAdminDlg::OnClickList1(NMHDR* pNMHDR, LRESULT* pResult) {// \t//Name=atoi(m_strName);\t// TODO: Add your control notification handler code here \tint pos=m_List.GetSelectionMark();//当前选中的行索引// \tCEdit* pBoxOne;// \tpBoxOne = (CEdit*) GetDlgItem(IDC_EDIT8);// \tGotoDlgCtrl(pBoxOne);//\tGetDlgItem(IDC_EDIT8)->EnableWindow(FALSE); \tint n;\tn=m_List.GetItemCount();// \tdlg.DoModal();\t//MessageBox((_variant_t)n);// \tif (dlg.m_sno==0)// \t{// \t\tdlg.GetDlgItem(dlg.IDC_EDIT1)->EnableWindow(FALSE);// \t}\tif (m_List.GetSelectionMark()==-1)\t{\t\tMessageBox(\"请选择用户\");\t\treturn;\t}\tCKCDELDlg dlg;\tdlg.str5=dlg.m_sno=m_List.GetItemText(pos,0);\tdlg.str=dlg.m_enlish=m_List.GetItemText(pos,1);\t//MessageBox(dlg.str);\tdlg.str1=dlg.m_chinese=m_List.GetItemText(pos,2);\tdlg.str2=dlg.m_computer=m_List.GetItemText(pos,3); \tdlg.str3=dlg.m_c=m_List.GetItemText(pos,4); \tdlg.str4=dlg.m_cplus=m_List.GetItemText(pos,5);\tUpdateData(FALSE);\t//dlg.m_snum.EnableWindow(FALSE);//\tdlg.m_ctleng.EnableWindow(FALSE);\tdlg.DoModal();// //  \tif (dlg.m_english==\"\")// \t{// \t\tdlg.m_snum.EnableWindow(FALSE);//  \t}//\tOnInitDialog();\t*pResult = 0;}void CAdminDlg::AddToList(){\tm_List.DeleteAllItems();\t//连接数据库\tCADO ado;\tado.CADOConnect();\t\t//设置查询字符串\tCString str;\tstr= \"select * from student_xuank\";\t//创建记录集指针对象实例\t//m_pRecordset.CreateInstance(__uuidof(Recordset));\t_RecordsetPtr pRS = ado.Select(str);\t//打开记录集\t// \tm_pRecordset->Open(bstrSQL,m_pConnection.GetInterfacePtr(),adOpenDynamic,\t// \t\tadLockOptimistic,adCmdText);\twhile(!pRS->adoEOF)\t{\t\tint m=0;\t\t//m_List.SetExtendedStyle(LVS_EX_CHECKBOXES);\t\t\t\t//m_ctlList.InsertItem(0,\"\");\t\tm_List.InsertItem(m, _T(\"\"));\t\t//\tm_List.SetCheck(m, FALSE);>GetItem(_variant_t(\"姓名\"))->Value=_bstr_t(\"赵薇\");\t\t\t\t\t\tm_List.SetItemText(0,0,(char*)(_bstr_t)(pRS->Fields->GetItem(_variant_t(\"sno\"))->Value));\t\t//m_user=(char*)_bstr_t(m_FieldsPtr->Item[\"username\"]->Value);//这两个是字符型的,读取和写都没问题// \t\t_variant_t vt;// \t\tvt = (pRS->Fields->GetItem(_variant_t(\"english\"))->Value);// \t\tbool m_admin = -vt.boolVal;\t\tm_List.SetItemText(0,1,(char*)(_bstr_t)(pRS->Fields->GetItem(_variant_t(\"english\"))->Value));\t\t//m_List.SetItemText(0,1,(_bstr_t)m_admin);\t\tm_List.SetItemText(0,2,(_bstr_t)pRS->GetCollect(\"chinese\"));\t\tm_List.SetItemText(0,3,(_bstr_t)pRS->GetCollect(\"c\"));\t\tm_List.SetItemText(0,4,(_bstr_t)pRS->GetCollect(\"cplusplus\"));\t\tm_List.SetItemText(0,5,(_bstr_t)pRS->GetCollect(\"computer\"));\t\tm++;\t\t\t\t//将记录集指针移动到下一条记录\t\tpRS->MoveNext();\t}}void CAdminDlg::OnButton1() {\t// TODO: Add your control notification handler code here\tUpdateData(true);\t\tCADO ado;\tado.CADOConnect();\t\t\tCString temp,str,str1;\t_variant_t ra;// // \tint k=m_combo.GetCurSel();// \tif (k==0)// \t{// \t\tstr1=\"student\";// \t\t// \t}// \telse// \t{// \t\tstr1=\"admin\";// \t}// \tif (m_name==\"\")// \t{// \t\tMessageBox(\"用户名不能为空\");// \t\tGetDlgItem(IDC_EDIT4)->SetFocus();// \t}// \telse if (m_pass1!=m_pass2)// \t{// \t\tMessageBox(\"密码不符\");// \t\tGetDlgItem(IDC_EDIT5)->SetFocus();// \t\tm_pass1=m_pass2=\"\";// \t\tUpdateData(FALSE);// \t\t// \t}// \telse// \t{// \t\tstr.Format(\"insert into login values('%s','%s','%s')\",m_name,m_pass1,str1);// \t\t//str.Format(\"insert into \");// \t\tado.ExecuteSQL(_bstr_t(str));// \t\tshowData();// \t\tm_name=m_pass1=m_pass2=\"\";// \t\tMessageBox(\"添加用户成功\");// \t}}void CAdminDlg::OnRclickList1(NMHDR* pNMHDR, LRESULT* pResult) {\t// TODO: Add your control notification handler code here\tUpdateData(true);\tCADO ado;\tado.CADOConnect();\tif (m_List.GetSelectionMark()==-1)\t{\t\tMessageBox(\"请选择用户\");\t\treturn;\t}\tint pos=m_List.GetSelectionMark();//当前选中的行索引\tCString str1=m_List.GetItemText(pos,0);\tCString str;\tstr.Format(\"delete from student_xuank where sno='%s'\",str1);\tMessageBox(str1);\tado.ExecuteSQL(_bstr_t(str));\tMessageBox(\"删除成功\"); \tAddToList();\t*pResult = 0;}-------------------------------未完待续---------------------------------","title":"vc++选课系统 sql语句操作数据库 管理员登陆界面"},{"content":"1．将数据库驱动程序的JAR文件放在Tomcat的 common/lib 中； 2．在server.xml中设置数据源，以MySQL数据库为例，如下： 在<GlobalNamingResources> <\/GlobalNamingResources>节点中加入，       <Resource       name=\"jdbc/DBPool\"       type=\"javax.sql.DataSource\"       password=\"root\"       driverClassName=\"com.mysql.jdbc.Driver\"       maxIdle=\"2\"       maxWait=\"5000\"       username=\"root\"       url=\"jdbc:mysql://127.0.0.1:3306/test\"       maxActive=\"4\"/>    属性说明：name，数据源名称，通常取”jdbc/XXX”的格式；             type，”javax.sql.DataSource”;             password，数据库用户密码；             driveClassName，数据库驱动；             maxIdle，最大空闲数，数据库连接的最大空闲时间。超过空闲时间，数据库连                      接将被标记为不可用，然后被释放。设为0表示无限制。             MaxActive，连接池的最大数据库连接数。设为0表示无限制。             maxWait ，最大建立连接等待时间。如果超过此时间将接到异常。设为-1表示                      无限制。 3．在你的web应用程序的web.xml中设置数据源参考，如下：   在<web-app><\/web-app>节点中加入，   <resource-ref>     <description>MySQL DB Connection Pool<\/description>     <res-ref-name>jdbc/DBPool<\/res-ref-name>     <res-type>javax.sql.DataSource<\/res-type>     <res-auth>Container<\/res-auth>     <res-sharing-scope>Shareable<\/res-sharing-scope>  <\/resource-ref>   子节点说明： description，描述信息；                res-ref-name，参考数据源名字，同上一步的属性name；                res-type，资源类型，”javax.sql.DataSource”；                res-auth，”Container”；                res-sharing-scope，”Shareable”； 4．在web应用程序的context.xml中设置数据源链接，如下：   在<Context><\/Context>节点中加入，   <ResourceLink    name=\"jdbc/DBPool\"     type=\"javax.sql.DataSource\"     global=\"jdbc/DBPool\"/>    属性说明：name，同第2步和第3步的属性name值，和子节点res-ref-name值；              type，同样取”javax.sql.DataSource”；              global，同name值。   至此，设置完成，下面是如何使用数据库连接池。 1．建立一个连接池类，DBPool.java，用来创建连接池，代码如下： import javax.naming.Context; import javax.naming.InitialContext; import javax.naming.NamingException; import javax.sql.DataSource; public class DBPool {     private static DataSource pool;     static {          Context env = null;           try {               env = (Context) new InitialContext().lookup(\"java:comp/env\");               pool = (DataSource)env.lookup(\"jdbc/DBPool\");               if(pool==null)                    System.err.println(\"'DBPool' is an unknown DataSource\");                } catch(NamingException ne) {                   ne.printStackTrace();           }       }     public static DataSource getPool() {         return pool;     } } 2．在要用到数据库操作的类或jsp页面中，用DBPool.getPool().getConnection()，获得一个Connection对象，就可以进行数据库操作，最后别忘了对Connection对象调用close()方法，注意：这里不会关闭这个Connection，而是将这个Connection放回数据库连接池。   学习网页：http://www.blogjava.net/csusky/archive/2008/02/19/180599.html","title":"Tomcat 的数据库连接池设置与应用"},{"content":"1.jdbc连接的优缺点 JDBC的优点    直接底层操作，提供了很简单、便捷的访问数据库的方法，跨平台性比较强。灵活性比较强，可以写很复杂的SQL语句。 JDBC的缺点 1）.因为JAVA是面向对象的，JDBC没有做到使数据能够面向对象的编程，使程序员的思考仍停留在SQL语句上。 2）.操作比较繁琐，很多代码需要重复写很多次。 3）.如果遇到批量操作，频繁与数据库进行交互，容易造成效率的下降。 Jdbc是一个比较底层的东西，灵活写SQL语句 1）、注册驱动 2）、获得连接 3）、产生一个Statement 4）、进行操作 返回数据ResultSet 1）、new List对象 2）、把ResultSet数据放入List过程中 A a = new A(); a.setXXX(rs.getString(\"xxx\")); 代码比较繁琐，纯的JDBC是没有缓存的。 2. hibernate引言 l     模型不匹配(阻抗不匹配)    Java面向对象语言，对象模型，其主要概念有：继承、关联、多态等；数据库是关系模型，其主要概念有：表、主键、外键等。 l     解决办法    1使用JDBC手工转换。    2使用ORM(Object Relation Mapping对象关系映射)框架来解决。 对象模型中对象与对象之间的关联关系与关系模型中数据库表之间的关系无法一一对应。 对象模型中对象的继承关系在关系模型中无法直接表示。 对象模型中对象的等值性（equals）在关系模型中无法直接实现。 对象模型中有关联的对象之间的导航访问在关系模型中无法直接实现。 3.  hibernate l     Hibernate是一个开源ORM框架。 l     ORM全称Object Relation Mapping，即对象关系映射。它是一种用来完成对象模型到关系模型的映射技术。就是把应用程序中的对象数据持久化到关系数据库的表的一种技术。 l     使用ORM（ Object Relation Mapping ）框架来解决。主流的ORM框架有JBoss公司的Hibernate、Oracle公司的TopLink、Apache组织的OJB、Sun公司的JDO。 l     简单的说：ORM能利用面向对象的思想开放基于关系型数据库的应用程序，它的主要工作是将对象数据保存到关系数据库的表中，以及将关系数据库表中数据读入到对象中。 4.安装配置 下载地址http://www.hibernate.org，这里举例使用的是3.3版本。解压获取必需类库文件。将下载目录/hibernate3.jar和/lib下的hibernate运行时必须的包加入classpath中： 需要使用的jar包以及jar包对应含义如下： l     配置文件hibernate.cfg.xml和hibernate.properties，XML和properties两种，这两个文件的作用一样，提供一个即可，推荐XML格式，下载目录/etc下是示例配置文件，后者中列举的更详细，主要是与各种数据库连接模版。 l     可以在配置文件指定：    数据库的URL、用户名、密码、JDBC驱动类、方言等。    启动时Hibernate会在CLASSPATH里找这个配置文件。 l     映射文件(hbm.xml，对象模型和关系模型的映射)。在/eg目录下有完整的hibernate示例。 l     一个小例子步骤： 1）.新建java或web项目，并加入相应的jar包及jdbc驱动。 2）.创建持久化类（java bean）   3）.准备数据库表   4）.创建配置文件 hibernate.cfg.xml 5）.创建映射文件 xxx.hbm.xml（与bean类在同一个包中）   6）.创建测试文件（测试本项目） 5. 细节分析 Hibernate.connection.url  表示要链接的数据库地址 Hibernate.connection.driver_class表示要链接的数据库的驱动类 Hibernate.connection.username     要连接的数据库的用户名 Hibernate.connection.password      要连接的数据库的密码 Hibernate.dialect   表示要使用的数据库的类型 org.hibernate.dialect.MySQL5Dialect       mysql数据库 org.hibernate.dialect.Oracle9Dialect        oracle数据库 org.hibernate.dialect.SQLServerDialect    SQLServer数据库 hibernate.hbm2ddl.auto validate:加载hibernate时验证创建表结构 update:加载hibernate时自动更新数据库结构，如果表存在不用创建，如果不存在就创建。 create:每一次加载hibernate时都创建表结构 create-drop:加载hibernate时创建，退出时删除 6.基本概念和CURD 开发流程: 1、由Domain object -> mapping->db。(官方推荐) 2、由DB开始，用工具生成mapping和Domain object。(使用较多) 3、由映射文件开始。 Domain Object限制    1、默认的构造方法(必须的)。    2、有无意义的标示符id（主键）(可选)    3、非final的，对懒加载有影响（可选） 7.  案例说明    Domain Java Object(User)    public class User {       private int id;       private String name;       private Date birthDay;       //getter setter… } l     对象关系映射文件：把面向对象中的实体类对象映射到数据库中的实体（表的记录），把实体类之间的关联关系也映射到数据库中多个表之间的相互关系中。这样，在Hibernate中对这些实体对象的操作就直接转换为对数据库表的记录的操作。 user.hbm.xml <?xml version=\"1.0\"?> <hibernate-mapping package=“cn.itcast.domain\"> <class name=\"User\" table=\"user\">    <id name=\"id\">       <generator class=\"native\"/>    <\/id>    <property name=\"name\"/>    <property name=\"birthday”/> <\/class> <\/hibernate-mapping> hibernate.cfg.xml <!DOCTYPE hibernate-configuration PUBLIC    \"-//Hibernate/Hibernate Configuration DTD 3.0//EN\"    \"http://hibernate.sourceforge.net/hibernate-configuration-3.0.dtd\">   <hibernate-configuration>    <session-factory name=\"foo\">    <property name=\"connection.driver_class\">com.mysql.jdbc.Driver<\/property>         <property name=\"connection.url\">jdbc:mysql:///hibernate<\/property>         <property name=\"connection.username\">root<\/property>         <property name=\"connection.password\">root<\/property>         <property name=\"dialect\">org.hibernate.dialect.HSQLDialect<\/property>       <property name=\"show_sql\">true<\/property>       <property name=\"hbm2ddl.auto\">update<\/property>       <mapping resource=\"com/hbsi/domain/User.hbm.xml\"/>          <\/session-factory> <\/hibernate-configuration> 测试类 DemoTest.java package com.hbsi.test;   import java.text.DateFormat; import java.text.ParseException; import java.util.Date;   import org.hibernate.Session; import org.hibernate.SessionFactory; import org.hibernate.cfg.Configuration;   import com.hbsi.domain.User;   public class UserTest {      /**     * @param args     * @throws ParseException     */    public static void main(String[] args) throws ParseException {             //给user类字段赋值       User user = new User();       user.setName(\"aa\");       //user.setBirthday(new Date());       user.setBirthday(DateFormat.getDateInstance().parse(\"1992-01-01\"));       //获取hibernate.cfg.xml的配置文件       Configuration cfg = new Configuration().configure();       //从session工厂中获取session，相当于jdbc中的connection       SessionFactory factory = cfg.buildSessionFactory();       Session session = factory.openSession();       session.beginTransaction();       session.save(user);       session.getTransaction().commit();       session.close();      } }      ","title":"心得1-hibernate入门"},{"content":"表名和列名的长度最多可为30个字符，如果表名的长度只有一个字符，也是可以的。在明明表和列时，允许使用字母（A-Z，a-z）、数字和一些特殊字符（$、_、#）。但是，表名或列命必须以字母开头。虽然Oracle把所有对象名都以大写字母保存在其数据字典里，但是这些名字对大小写是不敏感的。表名或列 名种不允许有空格和连字号。Oracle服务器的保留字也不能用作表名或列名。需要牢记的是，在命名一张表或以列时最常见的错误是使用空格。为表或列取一个简短而有意义的名称不失为一个好习惯。另外还需要牢记的是，表名在模式或账号中必须是惟一的，在一个模式中不应该有具有相同名称的另一个Oracle对象。","title":"Oracle笔记_命名规则"},{"content":"1、CLEAR SCREEN：清空屏幕； 2、APPEND text：将文本添加到当前行的最后； 3、CHANGE /old/new：将当前行的旧文本修改为新文本； 4、CHANGE /text/：删除当前行的文本； 5、CLEAR BUFFER：删除SQL缓冲区中的所有行； 6、DEL：删除当前行； 7、DEL n：删除第n行； 8、DEL m n：删除第m-n行； 9、INPUT：插入不确定的行数； 10、INPUT text：插入一行文本； 11、LIST：显示SQL缓冲区中的所有行； 12、LIST n：显示第n行； 13、LIST m n：显示第m-n行； 14、RUN：显示并运行缓冲区中的SQL语句； 15、” / \"：运行（缓冲区中的）SQL语句； 16、N：将第N行作为当前行； 17、n text：将第n行替换为新文本； 18、0 text：在第1行之前插入一行新文本；","title":"Oracle笔记_SQL*PLUS的编辑命令"},{"content":"1、SAVE filename[.ext] REPLACE|APPEND：将当前缓冲区中的内容保存到文件中，可以选择是替换还是追加； 2、GET filename[.ext]：将上一次保存的文件写到缓存区中。默认的扩展名是SQL。写的是SQL语句，而不是SQL*PLUS命令； 3、START filename[.ext]：运行文件中保存的上一条命令； 4、EDIT：调用默认编辑器（例如Notepad记事本），并将缓冲区中的内容保存到文件名为afiedt.buf的文件中； 5、EDIT [filename[.ext]]：用保存在文件中的命令来调用编辑器； 6、SPOOL[filename[.ext]|OFF|OUT]：将查询结果存储在文件中。OFF是关闭文件，OUT是将文件发送到系统打印机； SQL> spool c:\\dept.txt SQL> select * from dept;     DEPTNO DNAME          LOC                                              ---------- -------------- -------------                                                10 ACCOUNTING     NEW YORK                                               20 RESEARCH       DALLAS                                                        30 SALES          CHICAGO                                       40 OPERATIONS     BOSTON                                 SQL> spool off 7、EXIT：离开SQL*PLUS环境，提交当前事务。","title":"Oracle笔记_与文件相关的SQL*PLUS命令"},{"content":"关系代数是一种过程化语言，因为用户通过顺序使用一组运算来达到期望的结果。通过对数据表执行集合运算，产生新的结果表，然后将这些结果表用于随后的顺序运算。在Oracle中，所有的运算名市级上都不用做编程术语，这些运算中的大多数都不产生新的结果表。 1、并运算（Union）：两张数据表的并运算结果是检索一张或两张表中的所有行。重复的行要从结果表中除去，也就是说，结果表中不能包含具有相同数据值的两行。对于两张数据表执行并运算需要满足两个基本要求：1）两张表必须具有相同的度；2）两张数据表的响应列必须具有相同的域； 2、交运算（Intersection）：两张数据表的交运算所产生的结果表包括两张表中共有的行。两张数据表必须是兼容的，才能执行交运算； 3、差运算（Difference）：两张数据表的差运算所产生的结果表包括第一章表中出现但地二张表中不出现的那些行。差运算只能再并兼容的表上才能完成； 4、投影运算（Projection）：通过投影运算，我们可以从一张表的所有存在列中选择一些期望的列来生成一张新表，不期望的列则可以忽略不管。投影运算返回数据表的“垂直切片（vertical slice）“； 5、选择运算（Selection）：选择运算根据一个或多个条件从一张数据表中选择符合条件的行。条件运算符（=、<>、>、>=、<、<=）和逻辑运算符（AND、OR、NOT）与列和值一同使用，可以生成要满足的条件。选择运算返回数据表的”水平切片（horizontal slice）“； 6、乘积运算（Product）：两张数据表的乘积是将这两张表的所有信息联合起来。乘积也称为笛卡尔积（Cartesian product）。如果数据表较大，则其乘积会很大。如果第一张数据表包括x行，第二张数据表包括y行，那么其成绩会包括x*y行。如果第一张表包括m列，第二张数据表包括n列，那么其乘积结果包括m+n列； 7、赋值运算（Assignment）：这种运算是通过存在的表来创建一张新表。我们在所有其他运算里都已经执行过这种运算。通过赋值（=）运算，我们可以根据其他一些数据表来命名一些新表； 8、连接运算（Join）：连接运算是最重要的运算之一，通过这种运算我们可以得到许多表的相关数据。连接运算基于共同的值集，两张数据表中的值集不一定具有相同的名称，但必须具有相同的域。连接运算会增加系统开销，因为连接运算是通过以系列运算完成的。首先执行一个乘积运算，其结果包括m*n行。接着再执行一个选择运算，选出值相等的那些行。最后，执行投影运算，将重复的值列删除； 9、除法运算（Division）：除法运算是理解起来难度最大的一种运算。它并不像数学中的除法那么简单。在关系代数中，它识别一张表中与另一张表中的所有行具有一定的关系的那些行。","title":"Oracle笔记_关系代数"},{"content":"依赖： 1、全部依赖或完全依赖：一个非键列依赖于所有主键列则为全部依赖； 2、部分依赖：一个非键列依赖于部分主键列。也只有在复合主键中才可能出现这种情况； 3、传递以来：一个非键列依赖于另一个非键列。 三范式： 1、第一范式（First Normal Form）或称1NF：主键得到定义，单独主键或者复合主键。所有的非键列都表现为功能上依赖于主键（可能包含部分或传递的依赖）。数据表不包含多值列，即：在单值列中，一行和一列的交叉点只返回一个值。满足第一范式的数据表可能存在大量冗余数据。只满足第一范式的数据表终究会显露出数据的不一致性和不完整性； 2、第二范式（Second Normal Form）或称2NF：1NF的要求已全部满足，并且不存在部分依赖。假设一张数据表满足1NF，并且 没有复合主键，那么它肯定满足2NF； 3、第三范式（Third Normal Form）或称3NF：2NF的要求已全部满足，并且不存在传递依赖。 注：范式的等级并不是越高越好，3NF之上甚至还有4NF、5NF，满足的范式等级越低，效率就越高，也是我们常说的以空间换时间。反之冗余数据就会越多，之间的粒度需要自己掌握。","title":"Oracle笔记_数据库设计之三范式"},{"content":"用RPM包安装MySQL服务器端 包安装顺序：①perl-DBI-1.52-2.el5.i386.rpm                      ②perl-DBD-Pg-1.49-2.el5.i386.rpm                      ③MySql-5.0.77                      ④perl-DBD-MySQL                      ⑤mysql-server-5.0.77 包安装完毕后执行netstat命令查看MySQL端口状态： 3306端口在侦听状态，说明端口已经打开。 执行service mysqld restart 命令重新启动mysql服务器。   MySql服务器装成功后生成很多文件，数据库文件、配置文件和命令文件都不在同一个目录下。 /var/lib/mysql/ 数据库目录文件 /usr/share/mysql 配置文件 /usr/bin 相关命令  包括mysqladmin mysqldump /etc/rc.d/init.d/  启动脚本文件   修改MySQL管理员root口令 #mysqladmin -u root password ***** 设置口令后再从本地登陆   登陆mysql：    输入密码后成功登陆MySQL。   测试MySQL： 利用mysqladmin命令测试 show databases;       测试成功完成！  1.连接MySQL数据库  mysql -u [username] -p [passwd] 远程连接： mysql -h ipaddress -u username -p passwd; 2.显示数据库 SHOW DATABASES； 3.创建数据库 CREATE DATABASE <DATABASE NAME>; 4.更换数据库 USE <DATABASES>; 5.删除数据库 DROP DATABASE <DATABASE NAME>; 表 1.建表 CREATE TABLE <TABLE NAME>(<FIELD 1><TYPE>,....<FIELD N><TYPE>); 例建一名为st1_degree的表用来存储学生的成绩； mysql>CREATE TABLE st1_degree( >id INT(4) DEFAULT ' 0' NOT NULL, >name CHAR(30) NOT NULL, >degree DOUBLE (16,2), >PRIMARY KEY(id)); 2.copy tables CREATE TABLE st2_degree LIKE st1_degree; 3.删除表 DROP TABLE <TABLE NAME>; 4修改表 修改动作包括’ADD,DROP,CHANGE,ALTER.,MODIFY‘等关键字； ①修改字段名或者字段类型 ALTER TABLE <TABLE NAME > CHANGE <FIELD NAME > <NEW FIE.NAME><NEW FIE.TYPE>; ②添加字段 ALTER TABLE <TABLE NAME> ADD <FIELD NAME ><FIELD NAME TYPE>; ③删除字段 ALTER TABLE <TABLE NAME> DROP <FIELD NAME>; ④修改表名 ALTER TABLE <OLD TAB.NAME> RENAME TO  <NEW TAB.NAME>; 5.表记录的操作 ①插入记录 INSERT INTO <FIELD NAME>  (<FIELD 1>,<FIELD2>,...<FIELDn>) VALUES <值1>,....< 值n>； ②查询记录 SELECT * FROM <TABLE NAME>; ③修改记录 update <FIELD NAME> SET FIELD1=值1,... where 条件表达式； ④删除记录 DROP FROM <FIELD NAME> WHERE <表达式>；","title":"MySQL Install and Config on Linux."},{"content":"1、说明：创建数据库 CREATE DATABASE database-name 2、说明：删除数据库 drop database dbname 3、说明：备份sql server --- 创建 备份数据的 device USE master EXEC sp_addumpdevice 'disk', 'testBack', 'c:\\mssql7backup\\MyNwind_1.dat' --- 开始 备份 BACKUP DATABASE pubs TO testBack 4、说明：创建新表 create table tabname(col1 type1 [not null] [primary key],col2 type2 [not null],..) 根据已有的表创建新表： A：create table tab_new like tab_old (使用旧表创建新表) B：create table tab_new as select col1,col2… from tab_old definition only 5、说明：删除新表 drop table tabname 6、说明：增加一个列 Alter table tabname add column col type 注：列增加后将不能删除。DB2中列加上后数据类型也不能改变，唯一能改变的是增加varchar类型的长度。 7、说明：添加主键： Alter table tabname add primary key(col) 说明：删除主键： Alter table tabname drop primary key(col) 8、说明：创建索引：create [unique] index idxname on tabname(col….) 删除索引：drop index idxname 注：索引是不可更改的，想更改必须删除重新建。 9、说明：创建视图：create view viewname as select statement 删除视图：drop view viewname 10、说明：几个简单的基本的sql语句 选择：select * from table1 where 范围 插入：insert into table1(field1,field2) values(value1,value2) 删除：delete from table1 where 范围 更新：update table1 set field1=value1 where 范围 查找：select * from table1 where field1 like ’%value1%’ ---like的语法很精妙，查资料! 排序：select * from table1 order by field1,field2 [desc] 总数：select count as totalcount from table1 求和：select sum(field1) as sumvalue from table1 平均：select avg(field1) as avgvalue from table1 最大：select max(field1) as maxvalue from table1 最小：select min(field1) as minvalue from table1 11、说明：几个高级查询运算词 A： UNION 运算符 UNION 运算符通过组合其他两个结果表（例如 TABLE1 和 TABLE2）并消去表中任何重复行而派生出一个结果表。当 ALL 随 UNION 一起使用时（即 UNION ALL），不消除重复行。两种情况下，派生表的每一行不是来自 TABLE1 就是来自 TABLE2。 B： EXCEPT 运算符 EXCEPT 运算符通过包括所有在 TABLE1 中但不在 TABLE2 中的行并消除所有重复行而派生出一个结果表。当 ALL 随 EXCEPT 一起使用时 (EXCEPT ALL)，不消除重复行。 C： INTERSECT 运算符 INTERSECT 运算符通过只包括 TABLE1 和 TABLE2 中都有的行并消除所有重复行而派生出一个结果表。当 ALL 随 INTERSECT 一起使用时 (INTERSECT ALL)，不消除重复行。 注：使用运算词的几个查询结果行必须是一致的。 12、说明：使用外连接 A、left outer join： 左外连接（左连接）：结果集几包括连接表的匹配行，也包括左连接表的所有行。 SQL: select a.a, a.b, a.c, b.c, b.d, b.f from a LEFT OUT JOIN b ON a.a = b.c B：right outer join: 右外连接(右连接)：结果集既包括连接表的匹配连接行，也包括右连接表的所有行。 C：full outer join： 全外连接：不仅包括符号连接表的匹配行，还包括两个连接表中的所有记录。 二、提升 1、说明：复制表(只复制结构,源表名：a 新表名：b) (Access可用) 法一：select * into b from a where 1<>1 法二：select top 0 * into b from a 2、说明：拷贝表(拷贝数据,源表名：a 目标表名：b) (Access可用) insert into b(a, b, c) select d,e,f from b; 3、说明：跨数据库之间表的拷贝(具体数据使用绝对路径) (Access可用) insert into b(a, b, c) select d,e,f from b in ‘具体数据库’ where 条件 例子：..from b in '\"&Server.MapPath(\".\")&\"\\data.mdb\" &\"' where.. 4、说明：子查询(表名1：a 表名2：b) select a,b,c from a where a IN (select d from b ) 或者: select a,b,c from a where a IN (1,2,3) 5、说明：显示文章、提交人和最后回复时间 select a.title,a.username,b.adddate from table a,(select max(adddate) adddate from table where table.title=a.title) b 6、说明：外连接查询(表名1：a 表名2：b) select a.a, a.b, a.c, b.c, b.d, b.f from a LEFT OUT JOIN b ON a.a = b.c 7、说明：在线视图查询(表名1：a ) select * from (SELECT a,b,c FROM a) T where t.a > 1; 8、说明：between的用法,between限制查询数据范围时包括了边界值,not between不包括 select * from table1 where time between time1 and time2 select a,b,c, from table1 where a not between 数值1 and 数值2 9、说明：in 的使用方法 select * from table1 where a [not] in (‘值1’,’值2’,’值4’,’值6’) 10、说明：两张关联表，删除主表中已经在副表中没有的信息 delete from table1 where not exists ( select * from table2 where table1.field1=table2.field1 ) 11、说明：四表联查问题： select * from a left inner join b on a.a=b.b right inner join c on a.a=c.c inner join d on a.a=d.d where ..... 12、说明：日程安排提前五分钟提醒 SQL: select * from 日程安排 where datediff('minute',f开始时间,getdate())>5 13、说明：一条sql 语句搞定数据库分页 select top 10 b.* from (select top 20 主键字段,排序字段 from 表名 order by 排序字段 desc) a,表名 b where b.主键字段 = a.主键字段 order by a.排序字段 14、说明：前10条记录 select top 10 * form table1 where 范围 15、说明：选择在每一组b值相同的数据中对应的a最大的记录的所有信息(类似这样的用法可以用于论坛每月排行榜,每月热销产品分析,按科目成绩排名,等等.) select a,b,c from tablename ta where a=(select max(a) from tablename tb where tb.b=ta.b) 16、说明：包括所有在 TableA 中但不在 TableB和TableC 中的行并消除所有重复行而派生出一个结果表 (select a from tableA ) except (select a from tableB) except (select a from tableC) 17、说明：随机取出10条数据 select top 10 * from tablename order by newid() 18、说明：随机选择记录 select newid() 19、说明：删除重复记录 Delete from tablename where id not in (select max(id) from tablename group by col1,col2,...) 20、说明：列出数据库里所有的表名 select name from sysobjects where type='U' 21、说明：列出表里的所有的 select name from syscolumns where id=object_id('TableName') 22、说明：列示type、vender、pcs字段，以type字段排列，case可以方便地实现多重选择，类似select 中的case。 select type,sum(case vender when 'A' then pcs else 0 end),sum(case vender when 'C' then pcs else 0 end),sum(case vender when 'B' then pcs else 0 end) FROM tablename group by type 显示结果： type vender pcs 电脑 A 1 电脑 A 1 光盘 B 2 光盘 A 2 手机 B 3 手机 C 3 23、说明：初始化表table1 TRUNCATE TABLE table1 24、说明：选择从10到15的记录 select top 5 * from (select top 15 * from table order by id asc) table_别名 order by id desc 三、技巧 1、1=1，1=2的使用，在SQL语句组合时用的较多 “where 1=1” 是表示选择全部 “where 1=2”全部不选， 如： if @strWhere !='' begin set @strSQL = 'select count(*) as Total from [' + @tblName + '] where ' + @strWhere end else begin set @strSQL = 'select count(*) as Total from [' + @tblName + ']' end 我们可以直接写成 set @strSQL = 'select count(*) as Total from [' + @tblName + '] where 1=1 安定 '+ @strWhere 2、收缩数据库 --重建索引 DBCC REINDEX DBCC INDEXDEFRAG --收缩数据和日志 DBCC SHRINKDB DBCC SHRINKFILE 3、压缩数据库 dbcc shrinkdatabase(dbname) 4、转移数据库给新用户以已存在用户权限 exec sp_change_users_login 'update_one','newname','oldname' go 5、检查备份集 RESTORE VERIFYONLY from disk='E:\\dvbbs.bak' 6、修复数据库 ALTER DATABASE [dvbbs] SET SINGLE_USER GO DBCC CHECKDB('dvbbs',repair_allow_data_loss) WITH TABLOCK GO ALTER DATABASE [dvbbs] SET MULTI_USER GO 7、日志清除 SET NOCOUNT ON DECLARE @LogicalFileName sysname, @MaxMinutes INT, @NewSize INT USE tablename -- 要操作的数据库名 SELECT @LogicalFileName = 'tablename_log', -- 日志文件名 @MaxMinutes = 10, -- Limit on time allowed to wrap log. @NewSize = 1 -- 你想设定的日志文件的大小(M) -- Setup / initialize DECLARE @OriginalSize int SELECT @OriginalSize = size FROM sysfiles WHERE name = @LogicalFileName SELECT 'Original Size of ' + db_name() + ' LOG is ' + CONVERT(VARCHAR(30),@OriginalSize) + ' 8K pages or ' + CONVERT(VARCHAR(30),(@OriginalSize*8/1024)) + 'MB' FROM sysfiles WHERE name = @LogicalFileName CREATE TABLE DummyTrans (DummyColumn char (8000) not null) DECLARE @Counter INT, @StartTime DATETIME, @TruncLog VARCHAR(255) SELECT @StartTime = GETDATE(), @TruncLog = 'BACKUP LOG ' + db_name() + ' WITH TRUNCATE_ONLY' DBCC SHRINKFILE (@LogicalFileName, @NewSize) EXEC (@TruncLog) -- Wrap the log if necessary. WHILE @MaxMinutes > DATEDIFF (mi, @StartTime, GETDATE()) -- time has not expired AND @OriginalSize = (SELECT size FROM sysfiles WHERE name = @LogicalFileName) AND (@OriginalSize * 8 /1024) > @NewSize BEGIN -- Outer loop. SELECT @Counter = 0 WHILE ((@Counter < @OriginalSize / 16) AND (@Counter < 50000)) BEGIN -- update INSERT DummyTrans VALUES ('Fill Log') DELETE DummyTrans SELECT @Counter = @Counter + 1 END EXEC (@TruncLog) END SELECT 'Final Size of ' + db_name() + ' LOG is ' + CONVERT(VARCHAR(30),size) + ' 8K pages or ' + CONVERT(VARCHAR(30),(size*8/1024)) + 'MB' FROM sysfiles WHERE name = @LogicalFileName DROP TABLE DummyTrans SET NOCOUNT OFF 8、说明：更改某个表 exec sp_changeobjectowner 'tablename','dbo' 留下备用！！！","title":"精妙SQL语句收集"},{"content":"         在机房收费中的 上下机记录中，需要获取上机时的时间和日期，因为是用VB做的这个程序，就用了 VB的 date 和 time 函数 直接获取了程序所在ＰＣ的时间，然后这个时间就被存入了数据库中。不只是这一条记录，还有其他好多窗体的关于时间的数据，都是通过ＶＢ获取ＰＣ上的时间。 　　当时没察觉有问题，直到验收的时候，才发觉了原来这是个错误。        因为客户端的时间是不稳定的，不知道会因为什么缘故计算机时钟时间就会发生变化，这就给数据查询的正确性埋下了隐患。举个例子，假如客户端的机器BOIS电池有问题，每次开机时间都是1900-01-01 00:00:00 ,那么他的上机记录在按时间查询的时候，就只会显示这一天的记录，那么他的记录也就没有多大意义了！ 而服务器上的时间是比较稳定，更重的是所有的时间记录都是统一一个时钟，在时间顺序记录上不会混乱！所以在程序中用一个 select getdate() 获取服务的时间再存入数据库就OK了。 博客地址：http://blog.csdn.net/chenjinge7/article/ 　　","title":"机房收费系统-- 客户端与服务器 时间获取存在的问题"},{"content":"一、创建索引         MYSQL常用的索引类型主要有以下几种： 1、普通索引         CREATE INDEX idx_name ON table_name(table_col(length));         如果索引字段是CHAR，varchar类型，length可以指定小于字段实际长度；如果是BLOB和TEXT类型，必须指定length。         mysql> create index idx_name on user(name(10));         mysql> show index from user;         +-------+------------+----------+--------------+-------------+-----------+         | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation |         +-------+------------+----------+--------------+-------------+-----------+         | user  |          1 | idx_name |            1 | name        | A         |         +-------+------------+----------+--------------+-------------+-----------+ 2、唯一索引         CREATE UNIQUE INDEX idx_name ON table_name(table_col(length));         它与普通索引类似，但不同的是，其索引列的值必须唯一，但允许有空值。         mysql> create unique index idx_cn_name_u on user(cn_name(20));         mysql> show index from user;         +-------+------------+---------------+--------------+-------------+-----------+         | Table | Non_unique | Key_name      | Seq_in_index | Column_name | Collation |         +-------+------------+---------------+--------------+-------------+-----------+         | user  |          0 | idx_cn_name_u |            1 | cn_name     | A         |         | user  |          1 | idx_name      |            1 | name        | A         |         +-------+------------+---------------+--------------+-------------+-----------+ 3、主键索引         ALTER TABLE table_name ADD PRIMARY KEY (table_col);         它是一种特殊的唯一索引，且不允许有空值。一个表只能有一个主键索引。         mysql> alter table user add primary key (id);         mysql> show index from user;         +-------+------------+---------------+--------------+-------------+         | Table | Non_unique | Key_name      | Seq_in_index | Column_name |         +-------+------------+---------------+--------------+-------------+         | user  |          0 | PRIMARY       |            1 | id          |         | user  |          0 | idx_cn_name_u |            1 | cn_name     |         | user  |          1 | idx_name      |            1 | name        |         +-------+------------+---------------+--------------+-------------+ 4、组合索引         CREATE INDEX idx_name ON table_name(table_col_1,table_col_2,...,table_col_n);         它允许使用多个列作为索引列。         mysql> create index idx_name_sex on user(name,sex);         mysql> show index from user;         +-------+------------+---------------+--------------+-------------+-----------+-         | Table | Non_unique | Key_name      | Seq_in_index | Column_name | Collation |         +-------+------------+---------------+--------------+-------------+-----------+-         | user  |          0 | PRIMARY       |            1 | id          | A         |         | user  |          0 | idx_cn_name_u |            1 | cn_name     | A         |         | user  |          1 | idx_name      |            1 | name        | A         |         | user  |          1 | idx_name_sex  |            1 | name        | A         |         | user  |          1 | idx_name_sex  |            2 | sex         | A         |         +-------+------------+---------------+--------------+-------------+-----------+- 二、删除索引         DROP INDEX idx_name on table_name;         ALTER TABLE table_name DROP INDEX idx_name;         ALTER TABLE table_name DROP PRIMARY KEY;         mysql> alter table user drop primary key;         mysql> show keys from user;         +-------+------------+---------------+--------------+-------------+-         | Table | Non_unique | Key_name      | Seq_in_index | Column_name |         +-------+------------+---------------+--------------+-------------+-         | user  |          0 | idx_cn_name_u |            1 | cn_name     |         | user  |          1 | idx_name      |            1 | name        |         | user  |          1 | idx_name_sex  |            1 | name        |         | user  |          1 | idx_name_sex  |            2 | sex         |         +-------+------------+---------------+--------------+-------------+- 三、查看索引         SHOW INDEX FROM table_name;         SHOW KEYS FROM table_name;         查看索引语句的一个完全输出类似如下：         mysql> show keys from user;         +-------+------------+---------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+         | Table | Non_unique | Key_name      | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment |         +-------+------------+---------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+         | user  |          0 | idx_cn_name_u |            1 | cn_name     | A         |        NULL |       20 | NULL   | YES  | BTREE      |         |         | user  |          1 | idx_name      |            1 | name        | A         |        NULL |       10 | NULL   | YES  | BTREE      |         |         | user  |          1 | idx_name_sex  |            1 | name        | A         |        NULL |     NULL | NULL   | YES  | BTREE      |         |         | user  |          1 | idx_name_sex  |            2 | sex         | A         |        NULL |     NULL | NULL   | YES  | BTREE      |         |         +-------+------------+---------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+         其中：         Table：表的名称         Non_unique：如果索引不能包括重复词，则为0。如果可以，则为1。         Key_name：索引的名称。         Seq_in_index：索引中的列序列号，从1开始。         Column_name：列名称。         Collation：列以什么方式存储在索引中。在MySQL中，有值‘A’（升序）或NULL（无分类）。         Cardinality：索引中唯一值的数目的估计值。通过运行ANALYZE TABLE或myisamchk -a可以更新。基数根据被存储为整数的统计数据来计数，所以即使对于小型表，该值也没有必要是精确的。基数越大，当进行联合时，MySQL使用该索引的机会就越大。         Sub_part：如果列只是被部分地编入索引，则为被编入索引的字符的数目。如果整列被编入索引，则为NULL。         Packed：指示关键字如何被压缩。如果没有被压缩，则为NULL。         Null：如果列含有NULL，则含有YES。如果没有，则该列含有NO。         Index_type：使用的索引类型（BTREE, FULLTEXT, HASH, RTREE）。         Comment：索引说明。 四、使用索引的注意事项 1、索引不会包含有NULL值的列         只要列中包含有NULL值都将不会被包含在索引中，复合索引中只要有一列含有NULL值，那么这一列对于此复合索引就是无效的。所以在数据库设计时尽量不要让字段的默认值为NULL。 2、使用短索引         对列进行索引，如果可能应该指定一个前缀长度。例如，如果有一个CHAR(255)的列，如果在前10个或20个字符内，多数值是惟一的，那么就不要对整个列进行索引。短索引不仅可以提高查询速度而且可以节省磁盘空间和I/O操作。 3、不要在列上进行运算         在列上进行运算，将导致索引失效而进行全表扫描。 4、不使用NOT和<>操作 5、索引列排序         MySQL查询只使用一个索引，因此如果where子句中已经使用了索引的话，那么order by中的列是不会使用索引的。因此数据库默认排序可以符合要求的情况下不要使用排序操作；尽量不要包含多个列的排序，如果需要最好给这些列创建复合索引。 参考：http://www.chinaz.com/program/2010/0119/104365_2.shtml","title":"MYSQL入门学习之九：索引的基本操作"},{"content":"--四舍五入 SELECT CAST(ROUND(50.2,0) AS INT) --切舍 SELECT FLOOR(50.9) --切上 SELECT CEILING(50.2)","title":"MSSQL 四舍五入 切舍 切上"},{"content":"1、Oracle官方文档（11gR2）：Oracle Database Java Developer's Guide   2、另外推荐一本书：《Oracle Database Programming using Java and Web Services》，以下地址可以找到： （1）csdn，需要2积分： http://download.csdn.net/download/DoomLord/2746823 （2）豆丁网，可以在线阅读，下载需要9豆元： http://www.docin.com/p-489229721.html http://www.docin.com/p-259915970.html  ","title":"资料--使用java、web services进行数据库编程"},{"content":"Mysql Oracle Java BIGINT NUMBER(19,0) java.lang.Long BIT RAW byte[] BLOB BLOB   RAW byte[] CHAR CHAR java.lang.String DATE DATE java.sql.Date DATETIME DATE java.sql.Timestamp DECIMAL FLOAT (24) java.math.BigDecimal DOUBLE FLOAT (24) java.lang.Double DOUBLE PRECISION FLOAT (24) java.lang.Double ENUM VARCHAR2 java.lang.String FLOAT FLOAT java.lang.Float INT NUMBER(10,0) java.lang.Integer INTEGER NUMBER(10,0) java.lang.Integer LONGBLOB BLOB RAW byte[] LONGTEXT CLOB RAW java.lang.String MEDIUMBLOB BLOB RAW byte[] MEDIUMINT NUMBER(7,0) java.lang.Integer MEDIUMTEXT CLOB RAW java.lang.String NUMERIC NUMBER   REAL FLOAT (24)   SET VARCHAR2 java.lang.String SMALLINT NUMBER(5,0) java.lang.Integer TEXT VARCHAR2 CLOB java.lang.String TIME DATE java.sql.Time TIMESTAMP DATE java.sql.Timestamp TINYBLOB RAW byte[] TINYINT NUMBER(3,0) java.lang.Boolean TINYTEXT VARCHAR2 java.lang.String VARCHAR VARCHAR2 CLOB java.lang.String YEAR NUMBER java.sql.Date（日期设为2月1日晚上2点） 来自http://okhelper.blog.51cto.com/blog/313500/758498","title":"Mysql,Oracle,Java数据类型对应（备忘）"},{"content":"本来是不想再写了，但是有很多朋友给我了恢复和邮件，虽然我都一一作答，但是这次难得大家这么关注我给了我很大的动力，所以我才再次打键盘来写下一些乱七八糟的东西。          为什么是乱七八糟的？因为我也不知道他们有没有帮助或者有什么帮助，大家选这行大部分人无非是为了混口饭吃，能挣更多钱谁也不会介意，但不能不说当你在某一技术领域获得一个些成功时难免都会得意骄傲，这也是他的魅力所在吧，要学会一门技术真的不容易，出了天才以为大家都花费了不菲的经理才能对某一门语言或工具有所熟悉和经验，在获得突破或成功时更是情难自禁。         对成功的喜悦，对技术的热衷就会变成依赖，让你越来越难以放下它去追寻新的天地，想要技术升级或者转行的难度由此可见，真需要大决心和大毅力人才能放下到手的利益，哪怕它是那么微不足道。         有时候我真的很羡慕律师和医生，背完几本书之后就可以吃一辈子饭，可以拿20，30年的时间去经验其中的某一领域，哪怕不那么努力最终也能靠着经验成为一名合格的专家。但是IT这个行业留给我们的时间是在太少了，一门技术从新生到崛起到热门到普及再到最后的被淘汰，时间一晃而过，在最近10年里面不知道有多少的新兴技术不知道走过了以上几个阶段就已经被后来的所淹没，而留给我的时间是在太少了，特别在中国这个时间往往是3年，3年就得成为一个专家或者资深人员，哪怕你真不是，但是你的职位上肯定是这么写的。在IT领域里面是如此廉价，或者也说明了它的朝气蓬勃。         有时候我们得停下来思考，我们不能像传统行业的专家那样只用做个老学究，我们更重要的是选择和判断，再这个行业里面紧跟市场需求，把握发展方向的那一拨人才是混得最好的，所以…          我不敢告诉你：你也来学BI就对了，因为我也不敢说3年后这个行业还能像现在这样。移动应用，云服务，大数据，当前这3个热门3年后谁还能笑傲下去呢？10年的时候团购火了一把，11年的时候电商火了一把，12年淘宝告诉我们电商有些能活有些活不了，13年又会怎样呢？我们这个行业总是在变，总有一个方面会火的把，特别在中国，我有个同事加朋友说过一句话：在这混不是靠本事是靠眼光。","title":"我的6年职场人生从月薪800到2万（ 学什么才重要？）"},{"content":"            今天在自己电脑里面安装了oracle 10G 服务端后。之前正常的使用的plsql 既然无法登录了。仔细观察后发现plsql 根本没有把之前配置的数据库信息读出来。而是读出了另外的 orcl 和 一个 EXTPROC_CONNECTION_DATA  。想想 可能加载tnsnames.ora 文件出了问题，加载到了 另外的地方的tnsnames.ora文件。由于刚刚安装的服务端才出的问题。那肯定是加载的服务端的tnsnames.ora 配置文件默认的信息了。   根据 plsql 加载原理 肯定是在环境变量里面被改变了加载顺序。           打开环境变量一看 ，果然是这个问题。把path 里面指定的之前oracle客户端的环境变量复制到刚刚安装的服务端环境变量信息前面，问题就解决了。","title":"win7下面安装oracle服务端后plsql 不能使用解决方案"},{"content":"茫茫项目上线期，看似简单的一件事情，却经历了一个星期才搞好.. 总结出来很多问题,听我细细罗列. 部署沟通： 与人员的沟通，像这种跨部门依托其他部门的服务器部署项目最是麻烦，往往存在人员调配的各种问题，我们需要问清楚以下东西。 1、服务器内网地址，公网地址，端口号，数据库用户名密码。 2、相关联系人员联系方式。 3、周期时间。 4、需要部署的资源。 开始部署： 首先项目与数据库应当分开,项目部署在公共服务器,数据库产品部署在应用服务器(虽然最后由于种种原因我最后还是把服务器和数据源都部署在公共服务器上). 需要准备工具： VPN：架设虚拟局域网。 FlashFXP：FTP工具上传相关项目。 SecureCRT：SSH工具登陆Linux命令行。 飞秋：不同网段之间通过VPN资源互传。 Navicat ：数据库管理工具。 乱码问题： 在部署的过程中通过SSH工具连接LINUX,出现了好多次中文乱码的问题.试过更改etc/sysconfig/i18n文件的字符编码,也试过 export LANG=zh_CN.gb2312 export LANG=zh_CN.GBK export LANG=zh_CN.utf8 这三种似乎都不怎么理想，最终使用 export LANG=US_EN 解决，虽然所有操作界面都是英文，但是起码已经不乱码了，但是好景不长，登陆mysql后，查看数据库还是中文乱码，怎么办呢？其实没有关系，只是SSH显示乱码罢了，正常应用交互还是没有问题。 数据库外网连接： 我们数据库架设好之后通过Windows环境远程连接Linux中的数据库产品进行管理，但是发现连接不了，在网上查了许久之后发现是linux服务器中的Mysql需要开通外网访问的权限 select User,host from mysql.user; 我们查看发现 root 只有本地的访问权限，我们登陆mysql后执行 然后再查询访问权限。 多出来一行 root的host 是%，现在所有权限都能访问了，大功告成。 应用发布： 接着到发布的时候了，打开tomcat/bin 目录./shutdown.sh 关闭，./startup.sh 开启，等等怎么没有log信息， 别着急，我们先查看tomcat的状态，运行命令 我们发现tomcat 已经启动，然后再用ftp工具把tomcat/logs/catalina.out传回windows服务器使用文本工具打开，因为在linux环境下的vi编辑操作这种大型的文件是很痛苦的，这里推荐UlraEditor或者EditPlus。 打开发现有报错！ 但是我们回到控制台select * from map.two_level_code发现小写的表名能查询到这个表的信息，大写就不行了~ 我们需要编辑mysql的配置文件我们进行以下步骤  　  1.用ROOT登录，修改/etc/my.cnf 　　 2.在[mysqld]下加入一行：lower_case_table_names=1 　　 3.重新启动数据库即可 接着我们重启Tomcat！ OK，发布成功！       开始访问吧~","title":"Linux发布项目"},{"content":"1 :普通SQL语句可以用exec执行 Select * from tableName exec('select * from tableName') exec sp_executesql N'select * from tableName' -- 请注意字符串前一定要加N 2:字段名，表名，数据库名之类作为变量时，必须用动态SQL declare @fname varchar(20) set @fname = 'FiledName' Select @fname from tableName -- 错误,不会提示错误，但结果为固定值FiledName,并非所要。 exec('select ' + @fname + ' from tableName') -- 请注意 加号前后的 单引号的边上加空格 当然将字符串改成变量的形式也可 declare @fname varchar(20) set @fname = 'FiledName' --设置字段名 declare @s varchar(1000) set @s = 'select ' + @fname + ' from tableName' exec(@s) -- 成功 exec sp_executesql @s -- 此句会报错 declare @s Nvarchar(1000) -- 注意此处改为nvarchar(1000) set @s = 'select ' + @fname + ' from tableName' exec(@s) -- 成功 exec sp_executesql @s -- 此句正确 3. 输出参数 declare @num int, @sqls nvarchar(4000) set @sqls='select count(*) from tableName' exec(@sqls) --如何将exec执行结果放入变量中？ declare @num int, @sqls nvarchar(4000) set @sqls='select @a=count(*) from tableName ' exec sp_executesql @sqls,N'@a int output',@num output select @num 1 :普通SQL语句可以用Exec执行 例: Select * from tableName Exec('select * from tableName') Exec sp_executesql N'select * from tableName' -- 请注意字符串前一定要加N 2:字段名，表名，数据库名之类作为变量时，必须用动态SQL 错误: declare @fname varchar(20) set @fname = 'FiledName' Select @fname from tableName -- 错误,不会提示错误，但结果为固定值FiledName,并非所要。 正确: Exec('select ' + @fname + ' from tableName') -- 请注意加号前后的单引号的边上加空格 当然将字符串改成变量的形式也可 declare @fname varchar(20) set @fname = 'FiledName' --设置字段名 declare @s varchar(1000) set @s = 'select ' + @fname + ' from tableName' Exec(@s) -- 成功 exec sp_executesql @s -- 此句会报错 --注：@s参数必须为ntext或nchar或nvarchar类型,必须将declare @s varchar(1000) 改为declare @s Nvarchar(1000) 如下： declare @s Nvarchar(1000) -- 注意此处改为nvarchar(1000) set @fname = 'FiledName' --设置字段名 set @s = 'select ' + @fname + ' from tableName' Exec(@s) -- 成功 exec sp_executesql @s -- 此句正确 3. 输入或输出参数 (1)输入参数: declare @QueryString nvarchar(1000) --动态查询语句变量(注：必须为ntext或nchar哐nvarchar类型，不能是varchar类型) declare @paramstring nvarchar(200) --设置动态语句中的参数的字符串(注：必须为ntext或nchar哐nvarchar类型，不能是varchar类型) declare @input_id int--定义需传入动态语句的参数的值 set @QueryString='select * from tablename where id=@id' --id为字段名，@id为要传入的参数 set @paramstring='@id int' --设置动态语句中参数的定义的字符串 set @input_id =1 --设置需传入动态语句的参数的值为1 exec sp_executesql @querystring,@paramstring,@id=@input_id　　 若有多个参数: declare @QueryString nvarchar(1000) --动态查询语句变量(注：必须为ntext或nchar哐nvarchar类型，不能是varchar类型) declare @paramstring nvarchar(200) --设置动态语句中的参数的字符串(注：必须为ntext或nchar哐nvarchar类型，不能是varchar类型) declare @input_id int--定义需传入动态语句的参数的值,参数1 declare @input_name varchar(20)--定义需传入动态语句的参数的值,参数2 set @QueryString='select * from tablename where id=@id and name=@name' --id与name为字段名，@id与@name为要传入的参数 set @paramstring='@id int,@name varchar(20)' --设置动态语句中参数的定义的字符串,多个参数用\",\"隔开 set @input_id =1 --设置需传入动态语句的参数的值为1 set @input_name='张三' --设置需传入动态语句的参数的值为\"张三\" exec sp_executesql @querystring,@paramstring,@id=@input_id,@name=@input_name　--请注意参数的顺序 (2)输出参数 declare @num int, @sqls nvarchar(4000) set @sqls='select count(*) from tableName' exec(@sqls) --如何将exec执行结果放入变量中？ declare @QueryString nvarchar(1000) --动态查询语名变量(注：必须为ntext或nchar哐nvarchar类型，不能是varchar类型) declare @paramstring nvarchar(200) --设置动态语句中的参数的字符串(注：必须为ntext或nchar哐nvarchar类型，不能是varchar类型) declare @output_result int--查询结果赋给@output_result set @QueryString='select @totalcount=count(*) from tablename' --@totalcount　为输出结果参数 set @paramstring='@totalcount int output' --设置动态语句中参数的定义的字符串,多个参数用\",\"隔开 exec sp_executesql @querystring,@paramstring,@totalcount=@output_result output select @output_result 当然，输入与输出参数可以一起使用，大家可以自己去试一试。 另外，动态语句查询的结果集要输出的话，我只想到以下用临时表的方法，不知各位有没有更好的方法. IF object_id('[tempdb].[dbo].#tmp') IS NOT NULL --判断临时表#tmp是否存在,存在则删除 drop table #tmp select * into #tmp from tablename where 1=2 --创建临时表#tmp,其结构与tablename相同 declare @QueryString nvarchar(1000) --动态查询语名变量(注：必须为ntext或nchar哐nvarchar类型，不能是varchar类型) set @QueryString='select * from tablename ' insert into #tmp(field1,field2,...) exec(@querystirng)","title":"sql 动态表名"},{"content":"1.MySQL Class.forName(\"com.mysql.jdbc.Driver\"); con = DriverManager.getConnection(\"jdbc:mysql://IPAddr:3306/myDatabaseName?useUnicode=true&characterEncoding=utf8\", \"user\", \"password\"); 2.Oracle Class.forName(\"oracle.jdbc.driver.OracleDriver\"); con = DriverManager.getConnection(\"jdbc:oracle:thin:@IPAddr:1521:myDatabaseName\"); 3.DB2  Class.forName(\"com.ibm.db2.jdbc.net.DB2Driver\");  String url=\"jdbc:db2://IPAddr:6789/myDatabaseName\"  con = DriverManager.getConnection( url, user, password ); 4. PostgreSQL(http://www.de.postgresql.org)pgjdbc2.jar  Class.forName( \"org.postgresql.Driver\" );  cn = DriverManager.getConnection( \"jdbc:postgresql://MyDbComputerNameOrIP/myDatabaseName\", sUsr, sPwd );  5. Sybase(http://jtds.sourceforge.net)jconn2.jar  Class*forJame( \"com.sybase.jdbc2.jdbc.SybDriver\" );  cn = DriverManager.getConnection( \"jdbc:sybase:Tds:MyDbComputerNameOrIP:2638\", sUsr, sPwd );  //(Default-Username/Password: \"dba\"/\"sql\")  6. Microsoft SQLServer(http://jtds.sourceforge.net)  Class.forName( \"net.sourceforge.jtds.jdbc.Driver\" );  cn = DriverManager.getConnection( \"jdbc:jtds:sqlserver://MyDbComputerNameOrIP:1433/master\", sUsr, sPwd );  7. Microsoft SQLServer(http://www.microsoft.com)  Class.forName( \"com.microsoft.jdbc.sqlserver.SQLServerDriver\" );  cn = DriverManager.getConnection( \"jdbc:microsoft:sqlserver://MyDbComputerNameOrIP:1433;databaseName=master\", sUsr, sPwd );  8. ODBC  Class.forName( \"sun.jdbc.odbc.JdbcOdbcDriver\" );  Connection cn = DriverManager.getConnection( \"jdbc:odbc:\" + sDsn, sUsr, sPwd ); ","title":"常用数据库JDBC连接写法"},{"content":"    http://www.mongodb.org/downloads 官网下载地址可以下到最新的mongodb.     上面有全英文的安装说明.     这边简单介绍一下,供给看到e文就头疼的同学.     解压后启动方式有两种.     1,通过cmd直接启动 例子      C:\\mongodb\\bin\\mongod.exe --dbpath d:\\test\\mongodb\\data    dbpath之前的路径为解压安装包后安装包内的mongod.exe当前路径,后面的路径是你希望数据库数据存放的路径.      之后启动  C:\\mongodb\\bin\\mongo.exe便进入数据库,可以通过如下语句体验下,nosql的魅力. > db.test.save( { a: 1 } ) > db.test.find()     2通过cmd作为windows service方式安装 通过md C:\\mongodb\\log新建一个log文件 路径可以自己定        之后运行echo logpath=C:\\mongodb\\log\\mongo.log > C:\\mongodb\\mongod.cfg         echo dbpath=d:\\test\\mongodb\\data\\db > C:\\mongodb\\mongod.cfg         C:\\mongodb\\bin\\mongod.exe --config C:\\mongodb\\mongod.cfg --install 完成安装         命令         net start MongoDB 启用mongodb 服务         net stop MongoDB   停用         C:\\mongodb\\bin\\mongod.exe --remove 卸载安装","title":"Mongodb--安装"},{"content":"1、查询“”课程比“”课程成绩高的所有学生的学号；   SELECT a.S# FROM (SELECT s#,score FROM SC WHERE C#='001') a,  (SELECT s#,score  FROM SC WHERE C#='002') b      WHEREa.score>b.score AND a.s#=b.s#;   2、查询平均成绩大于分的同学的学号和平均成绩；      SELECT S#,avg(score)       FROM sc       GROUP BY S# having avg(score) >60;    3、查询所有同学的学号、姓名、选课数、总成绩；    SELECT Student.S#,Student.Sname,count(SC.C#),sum(score)      FROMStudent left Outer JOIN SC on Student.S#=SC.S#      GROUPBY Student.S#,Sname    4、查询姓“李”的老师的个数；    SELECT count(distinct(Tname))      FROMTeacher      WHERETname like '李%';    5、查询没学过“叶平”老师课的同学的学号、姓名；      SELECT Student.S#,Student.Sname       FROM Student        WHERE S# not in (SELECT distinct( SC.S#) FROM SC,Course,Teacher WHERE SC.C#=Course.C# AND Teacher.T#=Course.T# AND Teacher.Tname='叶平');    6、查询学过“”并且也学过编号“”课程的同学的学号、姓名；    SELECT Student.S#,Student.Sname FROM Student,SC WHERE Student.S#=SC.S# ANDSC.C#='001'and exists( SELECT * FROM SC as SC_2 WHERE SC_2.S#=SC.S# ANDSC_2.C#='002');    7、查询学过“叶平”老师所教的所有课的同学的学号、姓名；    SELECT S#,Sname      FROMStudent      WHERES# in (SELECT S# FROM SC ,Course ,Teacher WHERE SC.C#=Course.C# ANDTeacher.T#=Course.T# AND Teacher.Tname='叶平' GROUP BY S# having count(SC.C#)=(SELECTcount(C#) FROM Course,Teacher  WHERE Teacher.T#=Course.T# AND Tname='叶平'));    8、查询课程编号“”的成绩比课程编号“”课程低的所有同学的学号、姓名；    SELECT S#,Sname FROM (SELECT Student.S#,Student.Sname,score ,(SELECT score FROMSC SC_2 WHERE SC_2.S#=Student.S# AND SC_2.C#='002') score2      FROMStudent,SC WHERE Student.S#=SC.S# AND C#='001') S_2 WHERE score2<score;    9、查询所有课程成绩小于分的同学的学号、姓名；    SELECT S#,Sname      FROMStudent      WHERES# not in (SELECT Student.S# FROM Student,SC WHERE S.S#=SC.S# ANDscore>60);    10、查询没有学全所有课的同学的学号、姓名；      SELECT Student.S#,Student.Sname       FROM Student,SC       WHERE Student.S#=SC.S# GROUP BY  Student.S#,Student.Sname having count(C#)<(SELECT count(C#) FROM Course);    11、查询至少有一门课与学号为“”的同学所学相同的同学的学号和姓名；      SELECT S#,Sname FROM Student,SC WHERE Student.S#=SC.S# AND C# in SELECT C# FROMSC WHERE S#='1001';    12、查询至少学过学号为“”同学所有一门课的其他同学学号和姓名；      SELECT distinct SC.S#,Sname       FROM Student,SC       WHERE Student.S#=SC.S# AND C# in (SELECT C# FROM SC WHERE S#='001');    13、把“SC”表中“叶平”老师教的课的成绩都更改为此课程的平均成绩；      update SC set score=(SELECT avg(SC_2.score)       FROM SC SC_2       WHERE SC_2.C#=SC.C# ) FROM Course,Teacher WHERE Course.C#=SC.C# ANDCourse.T#=Teacher.T# AND Teacher.Tname='叶平');    14、查询和“”号的同学学习的课程完全相同的其他同学学号和姓名；      SELECT S# FROM SC WHERE C# in (SELECT C# FROM SC WHERE S#='1002')     GROUP BY S# having count(*)=(SELECT count(*) FROM SC WHERE S#='1002');  15、删除学习“叶平”老师课的SC表记录；    Delect SC     FROM course ,Teacher      WHERE Course.C#=SC.C# AND Course.T#= Teacher.T# AND Tname='叶平';  16、向SC表中插入一些记录，这些记录要求符合以下条件：没有上过编号“”课程的同学学号、、    号课的平均成绩；    Insert SC SELECT S#,'002',(SELECT avg(score)     FROM SC WHERE C#='002') FROM Student WHERE S# not in (SELECT S# FROM SC WHEREC#='002');  17、按平均成绩从高到低显示所有学生的“数据库”、“企业管理”、“英语”三门的课程成绩，按如下形式显示：学生ID,,数据库,企业管理,英语,有效课程数,有效平均分    SELECT S# as 学生ID         ,(SELECT score FROM SC WHERE SC.S#=t.S# AND C#='004') AS 数据库        ,(SELECT score FROM SC WHERE SC.S#=t.S# AND C#='001') AS 企业管理        ,(SELECT score FROM SC WHERE SC.S#=t.S# AND C#='006') AS 英语        ,COUNT(*) AS 有效课程数,AVG(t.score) AS 平均成绩    FROM SC AS t     GROUP BY S#     ORDER BY avg(t.score)    18、查询各科成绩最高和最低的分：以如下形式显示：课程ID，最高分，最低分    SELECT L.C# As 课程ID,L.scoreAS 最高分,R.score AS 最低分     FROM SC L ,SC AS R     WHERE L.C# = R.C# AND          L.score = (SELECT MAX(IL.score)                       FROM SC AS IL,Student AS IM                       WHERE L.C# = IL.C# AND IM.S#=IL.S#                       GROUP BY IL.C#)         AND         R.Score = (SELECT MIN(IR.score)                       FROM SC AS IR                       WHERE R.C# = IR.C#                   GROUP BY IR.C#                     );   19、按各科平均成绩从低到高和及格率的百分数从高到低顺序     SELECT t.C# AS 课程号,max(course.Cname)AS课程名,isnull(AVG(score),0)AS 平均成绩        ,100 * SUM(CASE WHEN  isnull(score,0)>=60 THEN 1 ELSE 0 END)/COUNT(*)AS 及格百分数    FROM SC T,Course     WHERE t.C#=course.C#     GROUP BY t.C#     ORDER BY 100 * SUM(CASE WHEN  isnull(score,0)>=60 THEN 1 ELSE 0END)/COUNT(*) DESC  20、查询如下课程平均成绩和及格率的百分数(用\"1行\"显示): 企业管理（），马克思（），OO&UML （），数据库（）     SELECT SUM(CASE WHEN C# ='001' THEN score ELSE 0 END)/SUM(CASE C# WHEN '001'THEN 1 ELSE 0 END) AS 企业管理平均分        ,100 * SUM(CASE WHEN C# = '001' AND score >= 60 THEN 1 ELSE 0 END)/SUM(CASEWHEN C# = '001' THEN 1 ELSE 0 END) AS 企业管理及格百分数          ,SUM(CASE WHEN C# = '002' THEN score ELSE 0 END)/SUM(CASE C# WHEN '002' THEN 1ELSE 0 END) AS 马克思平均分        ,100 * SUM(CASE WHEN C# = '002' AND score >= 60 THEN 1 ELSE 0 END)/SUM(CASEWHEN C# = '002' THEN 1 ELSE 0 END) AS 马克思及格百分数        ,SUM(CASE WHEN C# = '003' THEN score ELSE 0 END)/SUM(CASE C# WHEN '003' THEN 1ELSE 0 END) AS UML平均分        ,100 * SUM(CASE WHEN C# = '003' AND score >= 60 THEN 1 ELSE 0 END)/SUM(CASEWHEN C# = '003' THEN 1 ELSE 0 END) AS UML及格百分数        ,SUM(CASE WHEN C# = '004' THEN score ELSE 0 END)/SUM(CASE C# WHEN '004' THEN 1ELSE 0 END) AS 数据库平均分        ,100 * SUM(CASE WHEN C# = '004' AND score >= 60 THEN 1 ELSE 0 END)/SUM(CASEWHEN C# = '004' THEN 1 ELSE 0 END) AS 数据库及格百分数   FROMSC   21、查询不同老师所教不同课程平均分从高到低显示   SELECT max(Z.T#) AS 教师ID,MAX(Z.Tname)AS 教师姓名,C.C# AS 课程ＩＤ,MAX(C.Cname) AS 课程名称,AVG(Score) AS 平均成绩     FROM SC AS T,Course AS C ,Teacher AS Z      WHERE T.C#=C.C# AND C.T#=Z.T#    GROUP BY C.C#    ORDERBY AVG(Score) DESC  22、查询如下课程成绩第3 名到第6 名的学生成绩单：企业管理（），马克思（），UML （），数据库（）     [学生ID],[学生姓名],企业管理,马克思,UML,数据库,平均成绩     SELECT  DISTINCT top 3        SC.S# As 学生学号,          Student.Sname AS 学生姓名,        T1.score AS 企业管理,        T2.score AS 马克思,       T3.score AS UML,       T4.score AS 数据库,        ISNULL(T1.score,0) + ISNULL(T2.score,0) + ISNULL(T3.score,0) +ISNULL(T4.score,0) as 总分       FROM Student,SC  LEFT JOIN SC AS T1                        ON SC.S# = T1.S# AND T1.C# = '001'              LEFT JOIN SC AS T2                        ON SC.S# = T2.S# AND T2.C# = '002'             LEFT JOIN SC AS T3                       ON SC.S# = T3.S# AND T3.C# = '003'             LEFT JOIN SC AS T4                       ON SC.S# = T4.S# AND T4.C# = '004'       WHERE student.S#=SC.S# AND       ISNULL(T1.score,0) + ISNULL(T2.score,0) + ISNULL(T3.score,0) +ISNULL(T4.score,0)        NOT IN       (SELECT              DISTINCT              TOP 15 WITH TIES              ISNULL(T1.score,0) + ISNULL(T2.score,0) + ISNULL(T3.score,0) +ISNULL(T4.score,0)        FROM sc              LEFT JOIN sc AS T1                        ON sc.S# = T1.S# AND T1.C# = 'k1'              LEFT JOIN sc AS T2                        ON sc.S# = T2.S# AND T2.C# = 'k2'             LEFT JOIN sc AS T3                      ON sc.S# = T3.S# AND T3.C# = 'k3'             LEFT JOIN sc AS T4                      ON sc.S# = T4.S# AND T4.C# = 'k4'        ORDER BY ISNULL(T1.score,0) + ISNULL(T2.score,0) + ISNULL(T3.score,0) +ISNULL(T4.score,0) DESC);   3、统计列印各科成绩,各分数段人数:课程ID,课程名称,[100-85],[85-70],[70-60],[<60]      SELECT SC.C# as 课程ID, Cname as课程名称          ,SUM(CASE WHEN score BETWEEN 85 AND 100 THEN 1 ELSE 0 END) AS [100 - 85]          ,SUM(CASE WHEN score BETWEEN 70 AND 85 THEN 1 ELSE 0 END) AS [85 - 70]          ,SUM(CASE WHEN score BETWEEN 60 AND 70 THEN 1 ELSE 0 END) AS [70 - 60]          ,SUM(CASE WHEN score < 60 THEN 1 ELSE 0 END) AS [60 -]      FROM SC,Course      WHERE SC.C#=Course.C#      GROUP BY SC.C#,Cname;  ","title":"sql2005常用sql语句（一）"},{"content":"先说一下我的环境 win8-32bit， MongoDB V2.2.2 1、先到http://www.mongodb.org/downloads下载对应的MongoDB 2、解压缩 mongodb-win32-i386-2.2.2.zip 到任意目录下，我解压到D：\\下面 3、在所有程序中找到命令提示符程序，右击选择以管理员的身份运行 4、安装mongodb到目录d:\\mongodb(读者可以自己任意修改) 在命令提示符程序中输入D：转到D盘，然后输入move d:\\mongodb-win32-i386-2.2.2 d:\\mongodb 回车 5、创建数据存放目录d:\\data\\db(读者可以自己任意修改) 接着上一步在命令提示符程序中输入 md data 回车  继续输入 md data\\db 回车 6、启动mongodb 接着上面输入 D:\\mongodb\\bin\\mongod.exe 回车，到此步为止，所有显示如下： 7、连接到MongoDB 启动另外一个命令提示符程序，d:\\mongodb\\bin\\mongo.exe 回车 8、测试 接着上一步，输入一条插入语句与一条查询语句 db.test.save( { a: 1 } ) db.test.find() 9、恭喜您！MongoDB安装完成。结果如下图所示 注：有不足之处请指出！参考资料：http://docs.mongodb.org/manual/tutorial/install-mongodb-on-windows/","title":"开始接触MongoDB之MongoDB的安装"},{"content":"今天看了csdn中lifetragedy的一篇精华博文《通向架构师的道路（第六天）之漫谈基于数据库的权限系统的设计》，里面提到的菜单表的设计方式。其中使用lft，rgt两个字段的标示和预计算，从而jquery等tree控件能够从检索结果，通过一次遍历达到构建菜单目录树的效果。详情参见：http://blog.csdn.net/lifetragedy/article/details/7734864。 笔者想到创建表的时候可以直接从树形结构的菜单，通过计算获得lft，rgt，level字段，并与其他所需信息一同入库，这个方式在初始建库的时候特别有用。不需要每一个菜单项都是用lifetragedy给出的四步，当然，如果后续添加一些菜单，还是使用lifetragedy的方法直接一些。 下面给出笔者的模拟代码（其中的tree使用的是lifetragedy在原文中给出的示例，这里的Tree可以是从xml文件中读取，那么这段代码的实用性就大了。）： package com.ss.util;public class CreateMenuTable {\tprivate static Node tree;\tstatic{\t\t//create a menu tree\t\ttree = new Node(\"caidan\");\t\t\t\t//first level\t\tNode baobiao = new Node(\"baobiao\");\t\tNode xitong = new Node(\"xitongguanli\");\t\ttree.addChild(baobiao);\t\tbaobiao.setParent(tree);\t\ttree.addChild(xitong);\t\txitong.setParent(tree);\t\t//second level\t\tNode nianbao = new Node(\"nianbao\");\t\tNode jibao = new Node(\"jibao\");\t\tNode yuebao = new Node(\"yuebao\");\t\tNode zhoubao = new Node(\"zhoubao\");\t\tbaobiao.addChild(zhoubao);\t\tzhoubao.setParent(baobiao);\t\tbaobiao.addChild(yuebao);\t\tyuebao.setParent(baobiao);\t\tbaobiao.addChild(jibao);\t\tjibao.setParent(baobiao);\t\tbaobiao.addChild(nianbao);\t\tnianbao.setParent(baobiao);\t\t\t\t\t\tNode yonghuguanli = new Node(\"yonghuguanli\");\t\tNode jueseguanli = new Node(\"jeuseguanli\");\t\txitong.addChild(yonghuguanli);\t\tyonghuguanli.setParent(xitong);\t\txitong.addChild(jueseguanli);\t\tjueseguanli.setParent(xitong);\t\t\t//third level\t\tNode zengjia = new Node(\"zengjia\");\t\tNode shanchu = new Node(\"shanchu\");\t\tyonghuguanli.addChild(zengjia);\t\tzengjia.setParent(yonghuguanli);\t\tyonghuguanli.addChild(shanchu);\t\tshanchu.setParent(yonghuguanli);\t\t\t\tNode zengjia1 = new Node(\"zengjia\");\t\tNode shanchu1 = new Node(\"shanchu\");\t\tjueseguanli.addChild(zengjia1);\t\tzengjia1.setParent(jueseguanli);\t\tjueseguanli.addChild(shanchu1);\t\tshanchu1.setParent(jueseguanli);\t}\t\t//use depth first traversal method to calc width of each node.\t//every node's span is 2, so set it's width = 2\tprivate void calculate_width(Node tree){\t\t//leaf node set width = 2\t\tif(tree.getChilds().size() == 0){\t\t\ttree.setWidth(2);\t\t\t\t\t\treturn;\t\t}\t\t\t\t//calc each child's width\t\tfor(Node child : tree.getChilds()){\t\t\tcalculate_width(child);\t\t}\t\t\t\t//calc this root node's width\t\tfor(Node child : tree.getChilds()){\t\t\ttree.setWidth(tree.getWidth() + child.getWidth());\t\t}\t\ttree.setWidth(tree.getWidth() + 2);//his own width\t}\t//calc by breadth first traversal method and use the following equals:\t//for the first child node--\t//lft = parent.lft + 1\t//rgt = lft + width -1\t//\t//for orther child node--\t//lft = rgt_before + 1\t//rgt = lft + width -1\tprivate void calculate_landr(Node tree){\t\t//for leaf node\t\tif(tree.getChilds().size() == 0){\t\t\t\t\t\treturn;\t\t}\t\t\t\t//for trees has child node\t\t//calc first node's landr\t\tNode firstNode = tree.getChilds().get(0);\t\tfirstNode.setLft(firstNode.getParent().getLft() + 1);\t\tfirstNode.setRft(firstNode.getLft() + firstNode.getWidth() -1);\t\t\t\tprintNodeInfo(firstNode);\t\t\t\tNode preNode = firstNode;\t\tfor(int index=1, size=tree.getChilds().size(); index<size; index++){\t\t\tNode otherNode = tree.getChilds().get(index);\t\t\totherNode.setLft(preNode.getRft() + 1);\t\t\totherNode.setRft(otherNode.getLft() + otherNode.getWidth() -1);\t\t\t\t\t\tprintNodeInfo(otherNode);\t\t\t\t\t\tpreNode = otherNode;\t\t}\t\t\t\t//calc tree's child's child's landr\t\tfor(Node child : tree.getChilds()){\t\t\tcalculate_landr(child);\t\t}\t}\tprivate void printNodeInfo(Node node){\t\tStringBuilder sbuilder = new StringBuilder();\t\tsbuilder.append(node.getName());\t\tsbuilder.append(\" \");\t\tsbuilder.append(node.getLft());\t\tsbuilder.append(\" \");\t\tsbuilder.append(node.getRft());\t\tsbuilder.append(\" \");\t\tsbuilder.append(node.getWidth());\t\tsbuilder.append(\" \");\t\t\t\tSystem.out.println(sbuilder.toString());\t}\tpublic static void main(String[] arg){\t\tCreateMenuTable cmt = new CreateMenuTable();\t\tcmt.calculate_width(tree);\t\ttree.setLft(1);\t\ttree.setRft(1 + tree.getWidth() - 1);\t\tcmt.printNodeInfo(tree);\t\tcmt.calculate_landr(tree);\t\t\t}}下面给出Node类的代码： package com.ss.util;import java.util.ArrayList;import java.util.List;public class Node {\tprivate Node parent;\tprivate List<Node> childs = new ArrayList<Node>();\tprivate String name;\tprivate int lft;\tprivate int rft;\tprivate int depth;\tprivate int width;\tpublic int getWidth() {\t\treturn width;\t}\tpublic void setWidth(int width) {\t\tthis.width = width;\t}\tpublic Node(String name){\t\tthis.name = name;\t}\tpublic Node getParent() {\t\treturn parent;\t}\tpublic void setParent(Node parent) {\t\tthis.parent = parent;\t}\tpublic String getName() {\t\treturn name;\t}\tpublic void addChild(Node child){\t\tthis.childs.add(child);\t}\tpublic List<Node> getChilds(){\t\treturn this.childs;\t}\tpublic int getLft() {\t\treturn lft;\t}\tpublic void setLft(int lft) {\t\tthis.lft = lft;\t}\tpublic int getRft() {\t\treturn rft;\t}\tpublic void setRft(int rft) {\t\tthis.rft = rft;\t}\tpublic int getDepth() {\t\treturn depth;\t}\tpublic void setDepth(int depth) {\t\tthis.depth = depth;\t}} 运行输出的控制台结果如下： caidan 1 26 26 baobiao 2 11 10 xitongguanli 12 25 14 zhoubao 3 4 2 yuebao 5 6 2 jibao 7 8 2 nianbao 9 10 2 yonghuguanli 13 18 6 jeuseguanli 19 24 6 zengjia 14 15 2 shanchu 16 17 2 zengjia 20 21 2 shanchu 22 23 2","title":"符合lft, rgt的无限分类算法的Java生成代码"},{"content":"SQL2005对2000进行了很大的改进，而用户关系这部分也变得相当复杂了，很多朋友都对此一知半解！下面，我将把我应用中总结的和大家分享下，先从概念入手，希望对不理解的朋友有点提示。 今天我们要说的包括服务器登录名Server Login，服务器角色Server Role，数据库用户DB User，数据库架构DB Schema，数据库角色DB Role。以上几个名词应该从服务器与数据库来区分，服务器包含一到多个数据库，其中： 服务器登录名：指有权限登录到某服务器的用户； 服务器角色：指一组固定的服务器用户，默认有9组； ·                     登录名一定属于某些角色，默认为public ·                     服务器角色不容许更改 ·                     登录后也不一定有权限操作数据库 数据库用户：指有权限能操作数据库的用户； 数据库角色：指一组固定的有某些权限的数据库角色； 数据库架构：指数据库对象的容器； ·                     数据库用户对应于服务器登录名以便登录者可以操作数据库 ·                     数据库角色可以添加，可以定制不同权限　　 ·                     数据库架构，类似于数据库对象的命名空间，用户通过架构访问数据库对象 而通过下图可以让这些概念清晰一些： 即： 1.           服务器登录名属于某组服务器角色； 2.           服务器登录名需要于数据库的用户映射后才拥有操作数据库的权限 3.           数据库用户属于某组数据库角色以获取操作数据库的权限 4.           数据库角色拥有对应的数据库架构，数据库用户可以通过角色直接拥有架构 5.           数据库用户有默认架构，写SQL语句可以直接以“对象名”访问 6.           非默认架构则要以“架构名.对象名”访问 因此，新建一个非SA账户并建立数据库的过程可以如下： 1、新建登录名Login1 2、新建数据库DB1   3、新建DB1的架构Schema1   4、新建BD1的用户User1，登录名对应Login1，默认架构选择Schema1，角色选择db_owner     5、在登录名Login1的属性窗口里选择“用户映射”，勾选DB1，在用户里填写User1，默认架构选择\"Schema1\"   6、至此，新建表名会是Schema1.Table1，其他对象也如此 7、当然还可以新建其他架构的对象Schema2，只有User1拥有该架构，一样可以访问，如Schema2.Table2 值得注意的是，当为登录映射数据库用户的时候，多个数据库可以有相同名称的用户，而单独为某个数据库新建的用户，如User1，则在其他数据库里不允许同名","title":"SQL Server2005中登录名、用户名、角色和架构之间的关系"},{"content":"   Mysql数据库中的数据越来越多,当然排除不了重复的数据,在维护数据的时候突然想到要把多余的数据给删减掉,剩下有价值的数据。     以下sql语句可以实现查找出一个表中的所有重复的记录. select user_name,count(*) as count from user_table group by user_name having count>1; 参数说明: user_name为要查找的重复字段. count用来判断大于一的才是重复的. user_table为要查找的表名. group by用来分组 having用来过滤.     把参数换成自己数据表的相应字段参数，可以先在Phpmyadmin里面或者Navicat里面去运行，看看有哪些数据重复了，然后在数据库里面删除掉，也可以直接将SQL语句放到后台读取新闻的页面里面读取出来，完善成查询重复数据的列表，有重复的可以直接删除。 效果如下：    缺点：这种方法的缺点就是当你的数据库里面的数据量很大的时候，效率很低，我用的是Navicat测试的，数据量不大，效率很高，当然，网站还有其它查询数据重复的SQL语句，举一反三，大家好好研究研究，找到一个适合自己网站的查询语句。 转载于我的博客：http://www.60ie.net/article/5/190.html","title":"查找mysql数据表中重复记录"},{"content":"一、视图的基本介绍         视图是虚拟的表。与包含数据的表不一样，视图只包含使用时动态检索数据的查询。         使用视图需要MySQL5及以后的版本支持。         下面是视图的一些常见应用：         重用SQL语句；         简化复杂的SQL操作；         使用表的组成部分而不是整个表；         保护数据；         更改数据格式和表示；         在视图创建之后，可以用与表基本相同的方式利用它们。         但对于大量的复杂或嵌套视图，性能可能下降得很厉害。因此在部署相应的应用前，应进行充分的测试。 二、使用视图的规则和限制         与表一样，视图必须唯一命名（不能给视图取与别的视图或表相同的名字）；         对于可以创建的视图数目没有限制；         为了创建视图，必须具有足够的访问权限；         视图可嵌套；         ORDER BY可以用在视图中；         视图不能索引，也不能有关联的触发器或默认值；         视图可以和表一起使用； 三、使用视图 1、创建视图         create  view view_name         AS         select 语句         示例：         mysql> create or replace view v_pic_url             -> as             -> select             ->     id,url             -> from v9_picture             -> where catid=17; 2、查看创建视图的语句         SHOW CREATE VIEW viewname;         示例：         mysql> show create view v_pic_url;         +-----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------+----------------------+         | View      | Create View                                                                                                                                                                                                     | character_set_client | collation_connection |         +-----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------+----------------------+         | v_pic_url | CREATE ALGORITHM=UNDEFINED DEFINER=`root`@`localhost` SQL SECURITY DEFINER VIEW `v_pic_url` AS select `v9_picture`.`id` AS `id`,`v9_picture`.`url` AS `url` from `v9_picture` where (`v9_picture`.`catid` = 17) | latin1               | latin1_swedish_ci    |         +-----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------+----------------------+ 3、删除视图         DROP VIEW viewname;         示例：         mysql> drop view v_pic_url; 4、更新视图结构         可以先将视图DROP，再使用CREATE语句创建；         也可以直接使用CREATE OR REPLACE VIEW语句； 四、更新视图数据         通常，视图是可更新的（即，可以对它们使用INSERT、UPDATE和DELETE）。更新一个视图将更新其基表。如果对视图增加或删除行，实际上是对其基表增加或删除行。         但是，并非所有视图都是可更新的。如果视图定义中有以下操作，则不能进行视图的更新：         分组（使用GROUP BY和HAVING）；         联结；         子查询；         并；         聚焦函数；         DISTINCT；         导出（计算）列；         一般，应该将视图用于检索而不用于更新。 参考：《MySQL必知必会》","title":"MYSQL入门学习之十：视图的基本操作"},{"content":"// char_.cpp : 定义控制台应用程序的入口点。 // #include \"stdafx.h\" #include <afx.h> #include <windows.h> #include <stdlib.h> #include <stdio.h> #include <string.h> #include <malloc.h> #define WIN32_LEAN_AND_MEAN  // Exclude rarely-used stuff from Windows headers #include <tchar.h>   //使用# import把动态连接库msado15.dll导入Visual C++应用程序，并生成定义ADO库的两个C++头文件：msado15.tlh和ado15.tli。即： #import \"c:\\Program Files\\Common Files\\System\\ADO\\msado15.dll\"     no_namespace rename(\"EOF\", \"adoEOF\") void main() {  char * sqlCommand = \"select * from dbo.db_test\";                                                                                                     _bstr_t strConnect=\"driver={SQL Server};Server=127.0.0.1;Database=view;uid=sa;pwd=Rootroot1;\";  ::CoInitialize(NULL);//初始化COM库  //添加一个指向Connection对象的指针m_pConnection   _ConnectionPtr m_pConnection(__uuidof(Connection));  if( FAILED( m_pConnection.CreateInstance(__uuidof(Connection)) ) ) //创键Connection对象  {   printf(\"创键Connection对象时出错\\n\");  }  try  {   m_pConnection->Open (strConnect,\"\",\"\", adModeUnknown); //连接数据库  }  catch(_com_error e)   {   MessageBox(NULL,e.Description(),L\"test\",1);   //printf(\"连接数据库时出错\\n\");  }  m_pConnection->Execute(sqlCommand, NULL, 1);//执行SQL语句  _RecordsetPtr m_pRecordset(__uuidof(Recordset));  m_pRecordset.CreateInstance(__uuidof(Recordset));  m_pRecordset->Open(sqlCommand, m_pConnection.GetInterfacePtr(), adOpenDynamic, adLockOptimistic, adCmdText);  while(m_pRecordset->adoEOF==0)  {   printf(\"%s\\n\", (char*)(_bstr_t)m_pRecordset->GetCollect(\"id\"));   printf(\"%s\\n\", (char*)(_bstr_t)m_pRecordset->GetCollect(\"name\"));   printf(\"%s\\n\", (char*)(_bstr_t)m_pRecordset->GetCollect(\"salary\"));   m_pRecordset->MoveNext();     }  m_pRecordset->Close();  m_pConnection->Close();   ::CoUninitialize(); //释放程序占用的COM 资源  }","title":"vs2005 sqlserver2005 连接、查询"},{"content":"方法一 为mdf 附加 ldf日志文件，执行如下sql CREATE DATABASE DBname ON (FILENAME = 'D:\\SalesData\\archdat1.mdf')  FOR ATTACH_REBUILD_LOG ; 执行前先分离数据库 方法二 1、新建一个同名数据库。 2、停止数据库服务，覆盖新建的数据库主文件（小技巧：最好放在同一个磁盘里面，把新建的数据库主文件删掉或移开，再把要恢复的数据库主文件剪切过去，这样就可以节省时间。） 3、启动数据库服务，数据库变为置疑或可疑状态。然后在查询分析器中运行： alter database 无日志文件的数据库名称 set emergency 设置为紧急状态。 4、再运行： alter database 无日志文件的数据库名称 set single_user 或者： Sp_dboption '无日志文件的数据库名称', 'single user', 'true' 设置为单用户模式。 5、检查并重建日志文件，运行： dbcc checkdb('无日志文件的数据库名称',REPAIR_ALLOW_DATA_LOSS) 这个时间比较长。耐心等待！如果有错误提示，再运行： dbcc checkdb('无日志文件的数据库名称',REPAIR_REBUILD) 进行修复。如果没有错误，可以跳过。 6、恢复成多用户模式 alter database 无日志文件的数据库名称 set multi_user 或者： Sp_dboption '无日志文件的数据库名称', 'single user', 'false' 刷新数据库，你就可以看到已经修复好的数据库了。 我是如此修复，至于网上还有很多修复方法，我试过，没有成功。通过多方组合得到这个方法。可能也不是数据库的每一个版本都适用，如果你用过后，不行，希望能留言，让我们能共同讨论，共同进步！ #1楼 2010-05-21 19:19 | 感谢poofly  提供方法： CREATE DATABASE DBname ON (FILENAME = 'D:\\SalesData\\archdat1.mdf')  FOR ATTACH_REBUILD_LOG ; GO #12楼 121.29.113.* 2010-08-11 09:11 | peking2[未注册用户] 评注： 这个方法不错，操作简单。我个人Sql2005的mdf文件大小为16G。在sql2008下进行操作成功。 #30楼 116.228.132.* 2011-11-26 13:58 | $涅槃重生$ 哦，不好意思！试了之后，报这样的错。 错误提示：无法打开数据库 'db_name'版本 611。请将该数据库升级为最新版本。 (SQL SERVER 2005 附加到SQL SERVER 2008) $涅磐重生$ 14:34:20 提供解决方法： 把报2005下生成的mdf文件放在安装目录下的Sqlserver2008/MSSQL/Data目录下就行了。","title":"SQL Server 无日志文件附加数据库"},{"content":"今天在写一个小项目的时候连接数据库读取数据生成栏目，开始写了个这样的方法：但是每次只能读取一行数据，明明有好几条数据，其代码如下： public static List<Programa> getPrograma(int qx) throws SQLException{\t\tConnection conn = null;\t\tPreparedStatement pstmt = null;\t\tResultSet rs = null;\t\tList<Programa> list = new ArrayList<Programa>();\t\tPrograma programa = null;\t\t\t\ttry {\t\t\tconn=connectionFactory.getConnection();\t\t\t\t\t\tString sql = \"\";\t\t\tif (qx == 1) {\t//for admin\t\t\t\tsql=\"select pId,pName,pURL from programaTable where -1<?\";\t\t\t\t}\t\t\telse {\t//for user :QX == 0\t\t\t\tsql=\"select pId,pName,pURL from programaTable where QX=?\";\t\t\t}\t\t\t\t\t\tpstmt=conn.prepareStatement(sql);\t\t\tpstmt.setInt(1, qx);\t\t\t\t\t\trs=pstmt.executeQuery();\t\t\t\t\t\t\t\t\tif(rs.next()){\t\t\t\tSystem.out.println(\"000000000\");\t\t\t\tprograma = new Programa();\t\t\t\t\t\t\t\tprograma.setId(rs.getInt(1));\t\t\t\tprograma.setName(rs.getString(2));\t\t\t\tprograma.setUrl(rs.getString(3));\t\t\t\t\t\t\t\tlist.add(programa);\t\t\t}\t\t\t\t\t\trs.close();\t\t\tpstmt.close();\t\t\tconn.close();\t\t} catch (SQLException e) {\t\t\te.printStackTrace();\t\t} \t\treturn list;\t}   我就纳闷了，以前也写过JDBC连数据库的，我开始还以为是MYSQL的问题，后来我写过了一个方法，能把数据全部正确的读出来：代码如下： public static List<Programa> getPrograma2(int qx) throws SQLException{\t\tConnection con = null;\t\tStatement stmt = null;\t\tResultSet rs = null;\t\tList<Programa> list = new ArrayList<Programa>();\t\tPrograma programa = null;\t\ttry {\t\t\tcon = connectionFactory.getConnection();\t\t\tString sql = \"select pId,pName,pURL from programaTable\";\t\t\tstmt = con.createStatement();\t\t\trs = stmt.executeQuery(sql);\t\t\twhile (rs.next()) {\t\t\t\tint col1 = rs.getInt(1);\t\t\t\tString col2 = rs.getString(2);\t\t\t\tString col3 = rs.getString(3);\t\t\t\tprograma = new Programa();\t\t\t\tprograma.setId(col1);\t\t\t\tprograma.setName(col2);\t\t\t\tprograma.setUrl(col3);\t\t\t\tlist.add(programa);\t\t\t}\t\t\t// 关闭数据库连接\t\t\trs.close();\t\t\tstmt.close();\t\t\tcon.close();\t\t} catch (Exception e) {\t\t\te.printStackTrace();\t\t}\t\treturn list;\t} 后来看查一下，连接数据库的配置文件，原来配置文件将自动提交设置为true， 总结：如果设置自动提交为false，用预处理连接数据库，只能查询一条数据（不管rs = stmt.executeQuery(sql);后面是否写上上con.commit(); ）                                                       但是不用预处理能查到该查到的所有数据（不用写自动提交）               如果设置自动提交为true ，用预处理连接数据库，只能查询一条数据（rs = stmt.executeQuery(sql);后面不能写上上con.commit();否则报错 ）                                                       但是不用预处理能查到该查到的所有数据（不用写自动提交）   于是就出现一个问题，难道用预处理只能查到一条数据吗？？？？？          ","title":"Java/jdbc连接数据库预处理只能查询一条数据？"},{"content":"一：C# 连接SQL数据库    Data Source=myServerAddress;Initial Catalog=myDataBase;User Id=myUsername;Password=myPassword;  Data Source=190.190.200.100,1433;Network Library=DBMSSOCN;Initial Catalog=myDataBase;User ID=myUsername;Password=myPassword;  Server=myServerAddress;Database=myDataBase;User ID=myUsername;Password=myPassword;Trusted_Connection=False;  Server=myServerAddress;Database=myDataBase;Trusted_Connection=True;  Server=myServerName\\theInstanceName;Database=myDataBase;Trusted_Connection=True;  Data Source=myServerAddress;Initial Catalog=myDataBase;Integrated Security=SSPI;    1：Integrated Security参数      当设置Integrated Security为 True 的时候，连接语句前面的 UserID, PW 是不起作用的，即采用windows身份验证模式。      只有设置为 False 或省略该项的时候，才按照 UserID, PW 来连接。      Integrated Security 还可以设置为：sspi ，相当于 True，建议用这个代替 True。      Data Source=myServerAddress;Initial Catalog=myDataBase;Integrated Security=SSPI;      Data Source=myServerAddress;Initial Catalog=myDataBase;Integrated Security=true;      Data Source=myServerAddress;Initial Catalog=myDataBase;;User ID=myUsername;Password=myPasswordIntegrated Security=false;    2：参数Trusted_Connection      Trusted_Connection=true，将使用当前的   Windows   帐户凭据进行身份验证      Trusted_Connection=false;将不采用信任连接方式(也即不采用Windows验证方式)，而改由SQL Server 2000验证方式      Server=myServerAddress;Database=myDataBase;User ID=myUsername;Password=myPassword;Trusted_Connection=false;      Server=myServerAddress;Database=myDataBase;Trusted_Connection=True;    3：Initial Catalog是你要连接的数据库的名字    4：WINCE连接      Data Source=myServerAddress;Initial Catalog=myDataBase;Integrated Security=SSPI;User ID=myDomain\\myUsername;Password=myPassword;    二：可以利用SqlConnectionStringBuilder，这样不必去记住名称。      SqlConnectionStringBuilder scsb = new SqlConnectionStringBuilder();      scsb.DataSource = @\"(local)\\SQLExpress\";      scsb.IntegratedSecurity = true;      scsb.InitialCatalog = \"Northwind\";      SqlConnection myConnection = new SqlConnection(scsb.ConnectionString);    三：可以利用属性中的Setting来自动设置连接字符串      1：在type中选择 (connection string),      2：在DataSouce中选择数据源，然后再Server中输入服务器名，本地用(local)\\SQLExpress      3：选择登陆验证方式，本次选Windows验证（即信任连接Integrated Security=True）      4：选择数据库名，确认即可      Data Source=(local)\\SQLExpress;Initial Catalog=Northwind;Integrated Security=True      server = .\\sqlexpress;integrated security = true;database = northwind    四：SQL2005远程服务器连接方法    如何打开sql server 2005 的1433端口：  配置工具->Sql Server Configuration Manager->MSSQLSERVER的协议看看TCP/IP协议是否启动,如果启动,右键菜单点\"属性\" ,在分页菜单中选\"IP地址\",把\"IP1\"和\"IP2\"中\"TCP端口\"为1433,\"已启用\"改为\"是\"  配置工具->Sql Server Configuration Manager->SQL Native Client 配置->客户端协议->TCP/IP选择TCP/IP右键菜单中\"属性\",确认\"默认端口\"是1433,\"已启用\"为\"是\"。    SQL Server 2005 远程连接配置TCP/IP属性：  Surface Area Configuration --> Database Engine --> Remote Connections --->Using TCP/IT SQL Server 外围应用配置器?服务和连接外围配置?database englie?远程连接?启用(远程连接的TCP/IP和named pipes)   SQL Server Configuration Manager?SQL2005网络配置?启用TCP/IP和named pipes    其他说明见下: sqlserver2005(Express版），为了便于管理，你还需要去下一个manage管理器：  安装好manage管理器后，在程序中连接sqlserver2005,下面几点是要注意的。   1. 开启sql2005远程连接功能,开启办法如下, 配置工具->sql server外围应用配置器->服务和连接的外围应用配置器->打开MSSQLSERVER节点下的Database Engine 节点,先择\"远程连接\",接下建议选择\"同时使用TCP/IP和named pipes\",确定后,重启数据库服务就可以了.   2.登陆设置改为,Sql server and windows Authentication方式同时选中,具体设置如下: manage管理器->windows Authentication(第一次用windows方式进去),->对象资源管理器中选择你的数据服务器--右键>属性>security>Sql server and windows Authentication方式同时选中.   3:设置一个Sql server方式的用户名和密码,具体设置如下: manage管理器->windows Authentication>new query>sp_password null,'sa123456','sa' 这样就设置了一个用户名为sa ,密码为:sa123456的用户,下次在登陆时,可以用Sql server方式, 用户名为sa ,密码为:sa123456的用户进数据库了.   4: 做完上面三步后,这样写连接字符串就可以顺利进入数据库了,   (server=.\\sqlexpress;uid=sa;pwd=sa123456;database=master\";     五：SQL2000远程服务器连接方法    1：看ping 服务器IP能否ping通。   2：在Dos或命令行下输入telnet 服务器IP 端口，看能否连通。 　　如telnet 202.114.100.100 1433 　　通常端口值是1433，因为1433是sql server 2000的对于Tcp/IP的默认侦听端口。如果有问题，通常这一步会出问题。通常的提示是“……无法打开连接,连接失败\"。 　　      如果这一步有问题，应该检查以下选项。 　　      1） 检查远程服务器是否启动了sql server 2000服务。如果没有，则启动。 　　      2） 检查服务器端有没启用Tcp/IP协议，因为远程连接(通过因特网)需要靠这个协议。检查方法是，在服务器上打开 开始菜单-> 程序-> Microsoft SQL Server-> 服务器网络实用工具，看启用的协议里是否有tcp/ip协议，如果没有，则启用它。 　　      3）检查服务器的tcp/ip端口是否配置为1433端口。仍然在服务器网络实用工具里查看启用协议里面的tcp/ip的属性，确保默认端口为1433，并且隐藏服务器复选框没有勾上。 　　事实上，如果默认端口被修改，也是可以的，但是在客户端做 telnet测试时，写服务器端口号时必须与服务器配置的端口号保持一致。如果隐藏服务器复选框被勾选，则意味着客户端无法通过枚举服务器来看到这台服务器，起到了保护的作用，但不影响连接，但是Tcp/ip协议的默认端口将被隐式修改为2433，在客户端连接时必须作相应的改变。 　　      4）如果服务器端操作系统打过sp2补丁，则要对windows防火墙作一定的配置，要对它开放1433端口，通常在测试时可以直接关掉windows防火墙(其他的防火墙也关掉最好)。 　　      5）检查服务器是否在1433端口侦听。如果服务器没有在tcp连接的1433端口侦听，则是连接不上的。检查方法是在服务器的dos或命令行下面输入　　netstat -a -n 或者是netstat -an，在结果列表里看是否有类似 tcp 127.0.0.1 1433 listening 的项。如果没有，则通常需要给sql server 2000打上至少sp3的补丁。其实在服务器端启动查询分析器，输入 select @@version 执行后可以看到版本号，版本号在8.0.2039以下的都需要打补丁。　　如果以上都没问题，这时你再做telnet 服务器ip 1433 测试，将会看到屏幕一闪之后光标在左上角不停闪动。恭喜你，你马上可以开始在企业管理器或查询分析器连接了。 　　    3： 检查客户端设置　　程序-> Microsoft SQL Server -> 客户端网络使用工具。像在服务器网络实用工具里一样，确保客户端tcp/ip协议启用，并且默认端口为1433(或其他端口，与服务器端保持一致就行)。　　  4：在企业管理器里或查询那分析器连接测试 　　企业管理器-> 右键SQlserver组-> 新建sqlserver注册-> 下一步-> 写入远程IP-> 下一步-> 选Sqlserver登陆-> 下一步-> 写入登陆名与密码(sa,password)-> 下一步-> 下一步-> 完成 　　查询分析器-> 文件-> 连接-> 写入远程IP-> 写入登录名和密码(sa,password)-> 确定　　通常建议在查询分析器里做，因为默认情况下，通过企业管理器注册另外一台SQL Server的超时设置是4秒，而查询分析器是15秒。　　修改默认连接超时的方法: 　　企业管理器-> 工具-> 选项-> 在弹出的\"SQL Server企业管理器属性\"窗口中，点击\"高级\"选项卡-> 连接设置-> 在 登录超时(秒) 后面的框里输入一个较大的数字　　查询分析器-> 工具-> 选项-> 连接-> 在 登录超时(秒) 后面的框里输入一个较大的数字　　通常就可以连通了，如果提示错误，则进入下一步。 　　  5：错误产生的原因通常是由于SQL Server使用了\"仅 Windows\"的身份验证方式，因此用户无法使用SQL Server的登录帐户(如 sa )进行连接。解决方法如下所示: 　　      1） 在服务器端使用企业管理器，并且选择\"使用 Windows 身份验证\"连接上 SQL Server。 　　      2） 展开\"SQL Server组\"，鼠标右键点击SQL Server服务器的名称，选择\"属性\"，再选择\"安全性\" 选项卡。 　　      3）在\"身份验证\"下，选择\"SQL Server和 Windows \"。 　　      4） 重新启动SQL Server服务。(在dos或命令行下面net stop mssqlserver停止服务，net start mssqlserver启动服务，也是一种快捷的方法)。      本文来自CSDN博客，转载请标明出处：http://blog.csdn.net/fredrickhu/archive/2009/12/08/4961799.aspx","title":"C# 连接SQL数据库 常用连接字符串"},{"content":"新加表字段：           alter table 表名add  字段名 字段类型(字段类型大小);    例句： alter table CUSTOM_MA_STORECONTRACT add seal varchar (20); alter table CUSTOM_MA_STORECONTRACT add sealDetail varchar(100 ); 删除表字段：           alter table 表名 drop column 字段名;    例句: alter table CUSTOM_MA_STORECONTRACT drop column Treaty4; alter table CUSTOM_MA_STORECONTRACT drop column Apply4; 修改表字段的名称：           EXEC sp_rename '表名.[原字段名]' , '新字段名' , 'COLUMN';     例句： EXEC sp_rename 'CUSTOM_MA_STORECONTRACT.[YSG_BB]' , 'YSG_ABS', 'COLUMN'; EXEC sp_rename 'CUSTOM_MA_STORECONTRACT.[YSG_RDC]' , 'YSG_PLUS', 'COLUMN'; 修改表字段的类型或者大小：           alter table 表名 alter column 字段名 新字段类型(新字段类型大小);     例句：           alter table CUSTOM_MA_STORECONTRACT           alter column Apply1Detail varchar(60);           alter table CUSTOM_MA_STORECONTRACT      alter column Apply1Detail int;","title":"[置顶] 菜鸟笔记：SQL修改表结构_sqlserver"},{"content":"原文连接地址：http://www.amhl.net/wenzhang/DianNao-BianChengKaiFa/20101201/115247.html 在使用SQL语句查询数据库记录时，如果要查询相同的内容，有着不同的多种方法。 　　仍然，尽管使用多种方法可以得到相同的结果，但是，如果您使用不同的方法，在执行效益上是截然不同的。因此，我们得仔细考虑，如果要查询相同结果，该使用哪种语句，执行效益比较好。 　　这就是SQL语句的优化。 　　以下优化语句，针对MS Sql数据库。 　　1、对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。 　　2、应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描，如： 　　select id from t where num is null 　　可以在num上设置默认值0，确保表中num列没有null值，然后这样查询： 　　select id from t where num=0 　　3、应尽量避免在 where 子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描。 　　4、应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如： 　　select id from t where num=10 or num=20 　　可以改为如下的查询： 　　select id from t where num=10 　　union all 　　select id from t where num=20 　　5、in 和 not in 也要慎用，否则会导致全表扫描，如： 　　select id from t where num in(1,2,3) 　　对于连续的数值，能用 between 就不要用 in 了： 　　select id from t where num between 1 and 3 　　6、下面的查询也将导致全表扫描： 　　select id from t where name like '玞%' 　　若要提高效率，可以考虑全文检索。 　　7、如果在 where 子句中使用参数，也会导致全表扫描。因为SQL只有在运行时才会解析局部变量，但优化程序不能将访问计划的选择推迟到运行时；它必须在编译时进行选择。然而，如果在编译时建立访问计划，变量的值还是未知的，因而无法作为索引选择的输入项。如下面语句将进行全表扫描： 　　select id from t where num=@num 　　可以改为强制查询使用索引： 　　select id from t with(index(索引名)) where num=@num 　　8、应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如： 　　select id from t where num/2=100 　　应改为: 　　select id from t where num=100*2 　　9、应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如： 　　select id from t where substring(name,1,3)='abc'--name以abc开头的id 　　select id from t where datediff(day,createdate,'2010-11-30')=0--‘2010-11-30’生成的id 　　应改为: 　　select id from t where name like 'abc%' 　　select id from t where createdate>='2010-11-30' and createdate<'2010-12-1' 　　10、不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。 　　11、在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。 　　12、不要写一些没有意义的查询，如需要生成一个空表结构： 　　select col1,col2 into #t from t where 1=0 　　这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样： 　　create table #t(...) 　　13、很多时候用 exists 代替 in 是一个好的选择： 　　select num from a where num in(select num from b) 　　用下面的语句替换： 　　select num from a where exists(select 1 from b where num=a.num) 　　14、并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引，如一表中有字段sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。 　　15、索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数最好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有必要。 　　16、应尽可能的避免更新 clustered 索引数据列，因为 clustered 索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新 clustered 索引数据列，那么需要考虑是否应将该索引建为 clustered 索引。 　　17、尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。 　　18、尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 　　19、任何地方都不要使用 select * from t ，用具体的字段名称代替“*”，不要返回用不到的任何字段。 　　20、尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。 　　21、避免频繁创建和删除临时表，以减少系统表资源的消耗。 　　22、临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件，最好使用导出表。 　　23、在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert。 　　24、如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。 　　25、尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。 　　26、使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。 　　27、与临时表一样，游标并不是不可使用。对小型数据集使用 FAST_FORWARD 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。 　　28、在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON ，在结束时设置 SET NOCOUNT OFF 。无需在执行存储过程和触发器的每个语句后向客户端发送 DONE_IN_PROC 消息。 　　29、尽量避免大事务操作，提高系统并发能力。","title":"SQL提高查询效益之in、not in、between、like等条件讲述 数据库Sql,VFP,Access"},{"content":"Orange Orange 是一个基于组件的数据挖掘和机器学习软件套装，它的功能即友好，又很强大，快速而又多功能的可视化编程前端，以便浏览数据分析和可视化，基绑定了Python以进行脚本开发。它包含了完整的一系列的组件以进行数据预处理，并提供了数据帐目，过渡，建模，模式评估和勘探的功能。其由C++ 和 Python开发，它的图形库是由跨平台的Qt框架开发。 RapidMiner RapidMiner, 以前叫 YALE (Yet Another Learning Environment), 其是一个给机器学习和数据挖掘和分析的试验环境，同时用于研究了真实世界数据挖掘。它提供的实验由大量的算子组成，而这些算子由详细的XML 文件记录，并被RapidMiner图形化的用户接口表现出来。RapidMiner为主要的机器学习过程提供了超过500算子，并且，其结合了学习方案和Weka学习环境的属性评估器。它是一个独立的工具可以用来做数据分析，同样也是一个数据挖掘引擎可以用来集成到你的产品中。 Weka 由Java开发的 Weka (Waikato Environment for Knowledge Analysis) 是一个知名机器学机软件，其支持几种经典的数据挖掘任务，显著的数据预处理，集群，分类，回归，虚拟化，以及功能选择。其技术基于假设数据是以一种单个文件或关联的，在那里，每个数据点都被许多属性标注。 Weka 使用Java的数据库链接能力可以访问SQL数据库，并可以处理一个数据库的查询结果。它主要的用户接品是Explorer，也同样支持相同功能的命令行，或是一种基于组件的知识流接口。 JHepWork 为科学家，工程师和学生所设计的 jHepWork 是一个免费的开源数据分析框架，其主要是用开源库来创建 一个数据分析环境，并提供了丰富的用户接口，以此来和那些收费的的软件竞争。它主要是为了科学计算用的二维和三维的制图，并包含了用Java实现的数学科学库，随机数，和其它的数据挖掘算法。 jHepWork 是基于一个高级的编程语言 Jython，当然，Java代码同样可以用来调用 jHepWork 的数学和图形库。 KNIME KNIME (Konstanz Information Miner) 是一个用户友好，智能的，并有丰演的开源的数据集成，数据处理，数据分析和数据勘探平台。它给了用户有能力以可视化的方式创建数据流或数据通道，可选择性地运行一些或全部的分析步骤，并以后面研究结果，模型 以及 可交互的视图。 KNIME 由Java写成，其基于 Eclipse 并通过插件的方式来提供更多的功能。通过以插件的文件，用户可以为文件，图片，和时间序列加入处理模块，并可以集成到其它各种各样的开源项目中，比如：R语言，Weka， Chemistry Development Kit, 和 LibSVM. 源文：http://www.junauza.com/2010/11/free-data-mining-software.html","title":"五款开源的数据挖掘软件"},{"content":"摘要: ibatis的resultClass与resultMap还是有很大的区别。以下是我碰到的一个问题。 配置文件写法如下： 1 sqlMap2 typeAlias alias=\"notice\" type=\"path.country.basic.entity.Notice\"/3 resultMap id={% ...   ibatis的resultClass与resultMap还是有很大的区别。以下是我碰到的一个问题。      配置文件写法如下：     1 <sqlMap>  2     <typeAlias alias=\"notice\" type=\"path.country.basic.entity.Notice\"/>  3     <resultMap id=\"noticeResult\" class=\"notice\" >  4         <result property=\"id\" column=\"MainID\"/>  5         <result property=\"content\" column=\"Notice_Content\"/>  6         <result property=\"isUsed\" column=\"Notice_IsUsed\"/>  7         <result property=\"createMan\" column=\"CreateId\"/>  8         <result property=\"createDate\" column=\"CreateDate\"/>  9         <result property=\"createIp\" column=\"CreateIP\" /> 10         <result property=\"lastModifyMan\" column=\"ModifyId\"/> 11         <result property=\"lastModifyDate\" column=\"ModifyDate\" /> 12         <result property=\"lastModifyIp\" column=\"ModifyIP\" /> 13         <result property=\"manName\" column=\"CreateId\" select=\"getUserNameById\"/> 14     <\/resultMap> 15      <select id=\"getNewNotice\" resultClass=\"notice\"> 16         SELECT *  FROM Bse_Notice WHERE Notice_IsUsed='1' 17     <\/select> 18  <\/sqlMap>       在前台调用时，对象是取到了，但是里面的属性值为空。       查了相关资料才知道：resultclass属于隐身映射，虽然你指定resultclass=“”，具体某一个类，但是select语句得到的结果是一条实力记录，但如果数据库字段与类的属性名字不一致，这个时候就会出现映射错误，有一种方式可以解决就是在写select语句时，给每个字段用as运算符取名字与属性一样：例如：select realname as name...其中realname是字段列名，name是属性字段名。       当然解决问题还是很容易的，只需要把resultClass改为resultMap就行了。       在性能方面，resultMap要比resultClass高，所以建议尽量使用resultMap。","title":"ibatis的resultClass"},{"content":"需要带入dom4j.jar 1  数据库  使用mysql @Entity @Table(name=\"t_stu\") public class Student { private int id; private String name; @Id @GeneratedValue public int getId() {     return id; } public void setId(int id) {     this.id = id; } public String getName() {     return name; } public void setName(String name) {     this.name = name; } } 2      连接数据库生成xml public class JavaSql {     /**      * java读取xml                */     public static void main(String[] args) {           try {                try {                      Class.forName(\"com.mysql.jdbc.Driver\");                } catch(ClassNotFoundException e) {                 System.out.println(\"加载驱动器类时出现异常\");                 }               try {                File file=new File(\"d:/user.xml\");                FileOutputStream fos = new FileOutputStream(file);                  OutputFormat format = OutputFormat.createPrettyPrint();                format.setEncoding(\"GB2312\");                XMLWriter writer =  new XMLWriter(fos,format);                Document doc = DocumentHelper.createDocument();                Element rootElement = DocumentHelper.createElement(\"user\");                doc.setRootElement(rootElement);                java.sql.Connection conn = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/student\",\"root\",\"\");                java.sql.Statement sql=conn.createStatement();                java.sql.ResultSet rs=sql.executeQuery(\"select * from stu\");                while(rs.next())                {                    Element stu=rootElement.addElement(\"stu\");                    Element id=stu.addElement(\"id\");                    Element name=stu.addElement(\"name\");                    id.addText(rs.getString(1));                    name.addText(rs.getString(2));                }                               writer.write(doc);               } catch (IOException e) {                e.printStackTrace();               }               } catch(SQLException e) {                System.out.println(\"数据库连接时出现异常\");                }              } } 3   读取xml并输出 public class Xml {     @SuppressWarnings(\"unchecked\")     public static void main(String[] args) throws Exception {         SAXReader read = new SAXReader();         try {             Document doc = read.read(new File(\"d:/user.xml\"));             // 根元素             Element root = doc.getRootElement();             // 取根元素下的子元素名称             Iterator it = root.elementIterator();             while (it.hasNext()) {                 // 遍历子元素                 Element ele = (Element) it.next();                 /*                  * System.out.println(ele.getName()); // 取子元素下的元素 Iterator                  * chilIterator = ele.elementIterator(); while                  * (chilIterator.hasNext()) { // 遍历子元素的元素 Element eleChiElement =                  * (Element) chilIterator.next();                  * System.out.println(eleChiElement.getText()); }                  */                 getChildNode(ele);             }         } catch (DocumentException e) {             e.printStackTrace();         }     } 4  递归方法    无限输出     @SuppressWarnings(\"unchecked\")     public static void getChildNode(Element root) {         // 遍历跟元素下的所有子元素         Iterator iter = root.elementIterator();         //下条记录         while (iter.hasNext()) {             //取子元素             Element element = (Element) iter.next();             // 遍历子元素的下面的所有元素             Iterator iter1 = element.elementIterator();             //如果子元素存在  递归  不存在输入             if(!iter1.hasNext())               System.out.println(\"child:\" + element.getText());             else {                 getChildNode(element);// 自己调用自己             }         }     } }","title":"java从数据库生成xml和读取xml(无限生成或读取)"},{"content":"数据库启动之后想要提供网络服务还需要启动数据库的监听器（配置文件通常为listener.ora），其缺省端口是1521，接收来自客户端的访问请求（客户端请求通过tnsnames.ora文件定义发送）。 一、客户端的TNSNAMES.ORA文件配置 这个配置文件位于$ORACLE_HOME/network/admin目录下，典型的配置如下： CLAUDE =  (DESCRIPTION =    (ADDRESS = (PROTOCOL = TCP)(HOST = localhost)(PORT = 1521))    (CONNECT_DATA =      (SERVER = DEDICATED)      (SERVICE_NAME = claude.com.cn)    )  )这里的ADDRESS部分包含了服务器的地址及监听端口信息，CONNECT_DATA部分包含了链接信息，用于定义目标服务的名称。SERVER_NAME在这里用于识别访问的数据库服务。 配置完成之后，可以通过tnsping工具进行连通性测试： [oracle@claude ~]$ tnsping claudeUsed parameter files:/home/oracle/app/oracle/product/11.2.0/dbhome_1/network/admin/sqlnet.oraUsed TNSNAMES adapter to resolve the aliasAttempting to contact (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = localhost)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = claude.com.cn)))OK (0 msec)在服务器端数据库中存在一个初始化参数SERVICE_NAME，这个参数用于客户端请求的数据库服务名。SERVICE_NAMES为实例所连接的数据库定义一个或多个服务名，可以通过定义多个服务名将不同的用户连接区分开来。 二、服务器端的监听器文件LISTENER.ORA配置 这个配置文件同样位于$ORACLE_HOME/network/admin目录下，典型的配置如下： LISTENER =  (DESCRIPTION_LIST =    (DESCRIPTION =      (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521))      (ADDRESS = (PROTOCOL = TCP)(HOST = localhost)(PORT = 1521))    )  )SID_LIST_LISTENER=  (SID_LIST=    (SID_DESC=      (GLOBAL_DBNAME=orcl)      (ORACLE_HOME=/home/oracle/app/oracle/product/11.2.0/dbhome_1)      (SID_NAME=orcl)    )  )监听器文件主要包括两个部分： 第一部分LISTENER信息，这部分包含了监听的协议、地址以及端口等信息。 第二部分SID_LIST_LISTENER信息，这部分信息用于提供对外的数据库服务列表。 设置服务名的参数为GLOBAL_DBNAME，当处理客户端连接请求时，监听器首先尝试将GLOBAL_DBNAME和客户端请求中的SERVICE_NAME相匹配；如果客户端连接请求的是SID信息，则Oracle不检查GLOBAL_DBNAME设置，而是对监听器中设置的SID_NAME进行匹配。 三、通过不同服务器名对数据库的访问 客户端的配置示范： SALES =  (DESCRIPTION =    (ADDRESS = (PROTOCOL = TCP)(HOST = localhost)(PORT = 1521))    (CONNECT_DATA =      (SERVER = DEDICATED)      (SERVICE_NAME = sales.claude.com)    )  )NEWS =  (DESCRIPTION =    (ADDRESS = (PROTOCOL = TCP)(HOST = localhost)(PORT = 1521))    (CONNECT_DATA =      (SERVER = DEDICATED)       (SERVICE_NAME = news.claude.com)    )  )通过这两个服务名都可以顺利地访问到数据库： SQL> connect claude/claude@news;Connected.SQL> show parameter service_names;NAME\t\t\t\t     TYPE\t VALUE------------------------------------ ----------- ------------------------------service_names\t\t\t     string\t sales.claude.com, news.claude.\t\t\t\t\t\t comSQL> connect claude/claude@sales;Connected.SQL> show parameter service_names;NAME\t\t\t\t     TYPE\t VALUE------------------------------------ ----------- ------------------------------service_names\t\t\t     string\t sales.claude.com, news.claude.\t\t\t\t\t\t com 四、动态监听器注册服务 所谓动态注册时指当前实例启动之后，由后台进程PMON在监听器中注册数据库服务信息。在动态注册机制下，原来监听器中的SID_LIST部分将不再需要。 如果监听器具有非缺省配置，则需要设置LOCAL_LISTENER参数。例如监听器端口为1522，可以设置初始化参数为： LOCAL_LISTENER=listener1; 对于共享服务器模式，可以设置为： DISPATCHERS=\"(PROTOCOL=tcp)(LISTENER=listener1)\" 在tnsnames.ora文件中listener1可以按如下方式解析： listener1=     (DESCRIPTION=          (ADDRESS=(PROTOCOL=tcp)(HOST=prod-server)(PORT=1522)))","title":"ORACLE学习笔记（四）——数据库的访问"},{"content":"Lag和Lead分析函数可以在同一次查询中取出同一字段的前N行的数据(Lag)和后N行的数据(Lead)作为独立的列。 这种操作可以代替表的自联接，并且LAG和LEAD有更高的效率。 语法： /*语法*/lag(exp_str,offset,defval) over()Lead(exp_str,offset,defval) over()--exp_str要取的列--offset取偏移后的第几行数据--defval:没有符合条件的默认值 1. /*基础数据*/select t.* from test1 t; 2. /*用lag,lead分析以后的数据*/select t.id, lag(t.name,1,0) over(order by id desc) max_v, t.name,  lead(t.name,1,0) over(order by id desc) min_vfrom TEST1 t; 3. /*满足查询结果的数据*/select i.* from(select t.id, lag(t.name,1,0) over(order by id desc) max_v, t.name,  lead(t.name,1,0) over(order by id desc) min_v  from TEST1 t) i where i.name='3aa';","title":"oracle下lag和lead分析函数"},{"content":"需求及问题 在一些表关联查询中，当存在源表和关联表都有过虑条件（and）时，如果其中一个条件不符合，结果就有可能为空； 而实际上我们要求结果集中，条件不符合的显示空，但其它条件正常的，依然要显示。 1.要达到目的，不符合的数据显示为空，符合的照常显示 2.直接在where里放入条件，当有一个不符合时，结果集可能为空 /*需求和问题*//*1.where中放两个查询条件,有可能数据集为空*/selec distinct t t.sec_code, t.sec_sname, decode(t1.chng_pct,null,'--',TO_CHAR(t1.chng_pct,'FM9999999999999990.90')) chng_pct, t.trans_type, t.tradedate from mv_stk_trans_info t left outer join mv_sec_mkt t1 on t.sec_unicode = t1.sec_unicode where t.tradedate=(select max(tradedate) from mv_stk_trans_info ) and t1.tradedate=(select max(tradedate) from mv_stk_trans_info )order by t.sec_code asc; 3.把限制为空列的条件放到outer join的on中,要报ORA-01799:列不能外部联接到子查询的错 /*2.把限制为空列的条件放到outer join的on中,要报ORA-01799:列不能外部联接到子查询的错*/select distinct t.sec_code, t.sec_sname, decode(t1.chng_pct,null,'--',TO_CHAR(t1.chng_pct,'FM9999999999999990.90')) chng_pct, t.trans_type, t.tradedate from mv_stk_trans_info t left outer join mv_sec_mkt t1 on t.sec_unicode = t1.sec_unicode and t1.tradedate=(select max(tradedate) from mv_stk_trans_info )where t.tradedate=(select max(tradedate) from mv_stk_trans_info ) order by t.sec_code asc; 解决方案 1.先查询出关联表的关联列,条件列,以及其它需要的列,查询结果集作为一个表,再让其它表来关联这个结果集 /*(推荐)1.先查询出关联表的关联列,条件列,以及其它需要的列,查询结果集作为一个表,再让其它表来关联这个结果集*//*方案1,速度运行为0.938*/select distinct t.sec_code, t.sec_sname, decode(t1.chng_pct,null,'--',TO_CHAR(t1.chng_pct,'FM9999999999999990.90')) chng_pct, t.trans_type, t.tradedate from mv_stk_trans_info t left outer join (select sec_unicode, chng_pct from mv_sec_mkt  where tradedate=(select max(tradedate) from mv_sec_mkt)) t1 on t.sec_unicode=t1.sec_unicode where t.tradedate=(select max(tradedate) from mv_stk_trans_info )order by t.sec_code asc; 2.先用一个函数来完成关联表的限制条件,并返回限制条件,再在outer join的on中加入限制条件 /*2.先用一个函数来完成关联表的限制条件,并返回限制条件,再在outer join的on中加入限制条件*//*方案2,速度运行为3.922*/--函数返回关联条件create or replace function fun_getMaxDay return date as  v_max_date date;begin  select max(tradedate) into v_max_date from mv_stk_trans_info;  return v_max_date;end;--关联查询select t.sec_code, t.sec_sname, decode(t1.chng_pct,null,'--',TO_CHAR(t1.chng_pct,'FM9999999999999990.90')) chng_pct, t.trans_type, t.tradedate from mv_stk_trans_info t left outer join mv_sec_mkt t1 on t.sec_unicode = t1.sec_unicode and t1.tradedate=fun_getMaxDay where t.tradedate=(select max(tradedate) from mv_stk_trans_info ) order by t.sec_code asc;方案1.2均能达到目的，但方案1用时少，且方便，推荐1。","title":"ORA-01799 列不能外部联接到子查询"},{"content":"SQLite3　API编程手册 前序：... 1 一、 版本... 1 二、 基本编译... 2 三、 SQLITE操作入门... 2 （1） 基本流程... 2 （2） SQL语句操作... 4 （3） 操作二进制... 8 （4） 事务处理... 10 四、 给数据库加密... 10 五、 后记... 25 前序： Sqlite3 的确很好用。小巧、速度快。但是因为非微软的产品，帮助文档总觉得不够。这些天再次研究它，又有一些收获，这里把我对 sqlite3 的研究列出来，以备忘记。 这里要注明，我是一个跨平台专注者，并不喜欢只用 windows 平台。我以前的工作就是为 unix 平台写代码。下面我所写的东西，虽然没有验证，但是我已尽量不使用任何 windows 的东西，只使用标准 C 或标准C++。但是，我没有尝试过在别的系统、别的编译器下编译，因此下面的叙述如果不正确，则留待以后修改。 下面我的代码仍然用 VC 编写，因为我觉得VC是一个很不错的IDE，可以加快代码编写速度（例如配合 Vassist ）。下面我所说的编译环境，是VC2003。如果读者觉得自己习惯于 unix 下用 vi 编写代码速度较快，可以不用管我的说明，只需要符合自己习惯即可，因为我用的是标准 C 或 C++ 。不会给任何人带来不便。 一、 版本 从 www.sqlite.org 网站可下载到最新的 sqlite 代码和编译版本。我写此文章时，最新代码是 3.3.17 版本。 很久没有去下载 sqlite 新代码，因此也不知道 sqlite 变化这么大。以前很多文件，现在全部合并成一个 sqlite3.c 文件。如果单独用此文件，是挺好的，省去拷贝一堆文件还担心有没有遗漏。但是也带来一个问题：此文件太大，快接近7万行代码，VC开它整个机器都慢下来了。如果不需要改它代码，也就不需要打开 sqlite3.c 文件，机器不会慢。但是，下面我要写通过修改 sqlite 代码完成加密功能，那时候就比较痛苦了。如果个人水平较高，建议用些简单的编辑器来编辑，例如 UltraEdit 或 Notepad 。速度会快很多。 二、 基本编译 这个不想多说了，在 VC 里新建 dos 控制台空白工程，把 sqlite3.c 和 sqlite3.h 添加到工程，再新建一个 main.cpp 文件。在里面写: extern \"C\" { #include \"./sqlite3.h\" }; int main( int , char** ) { return 0; } 为什么要 extern “C” ？如果问这个问题，我不想说太多，这是C++的基础。要在 C++ 里使用一段 C 的代码，必须要用 extern “C” 括起来。C++跟 C虽然语法上有重叠，但是它们是两个不同的东西，内存里的布局是完全不同的，在C++编译器里不用extern “C”括起C代码，会导致编译器不知道该如何为 C 代码描述内存布局。 可能在 sqlite3.c 里人家已经把整段代码都 extern “C” 括起来了，但是你遇到一个 .c 文件就自觉的再括一次，也没什么不好。 基本工程就这样建立起来了。编译，可以通过。但是有一堆的 warning。可以不管它。 三、 SQLITE操作入门 sqlite提供的是一些C函数接口，你可以用这些函数操作数据库。通过使用这些接口，传递一些标准 sql 语句（以 char * 类型）给 sqlite 函数，sqlite 就会为你操作数据库。 sqlite 跟MS的access一样是文件型数据库，就是说，一个数据库就是一个文件，此数据库里可以建立很多的表，可以建立索引、触发器等等，但是，它实际上得到的就是一个文件。备份这个文件就备份了整个数据库。 sqlite 不需要任何数据库引擎，这意味着如果你需要 sqlite 来保存一些用户数据，甚至都不需要安装数据库(如果你做个小软件还要求人家必须装了sqlserver 才能运行，那也太黑心了)。 下面开始介绍数据库基本操作。 （1） 基本流程 i.1 关键数据结构 sqlite 里最常用到的是 sqlite3 * 类型。从数据库打开开始，sqlite就要为这个类型准备好内存，直到数据库关闭，整个过程都需要用到这个类型。当数据库打开时开始，这个类型的变量就代表了你要操作的数据库。下面再详细介绍。 i.2 打开数据库 int sqlite3_open( 文件名, sqlite3 ** ); 用这个函数开始数据库操作。 需要传入两个参数，一是数据库文件名，比如：c://DongChunGuang_Database.db。 文件名不需要一定存在，如果此文件不存在，sqlite 会自动建立它。如果它存在，就尝试把它当数据库文件来打开。 sqlite3 ** 参数即前面提到的关键数据结构。这个结构底层细节如何，你不要关它。 函数返回值表示操作是否正确，如果是 SQLITE_OK 则表示操作正常。相关的返回值sqlite定义了一些宏。具体这些宏的含义可以参考 sqlite3.h 文件。里面有详细定义（顺便说一下，sqlite3 的代码注释率自称是非常高的，实际上也的确很高。只要你会看英文，sqlite 可以让你学到不少东西）。 下面介绍关闭数据库后，再给一段参考代码。 i.3 关闭数据库 int sqlite3_close(sqlite3 *); 前面如果用 sqlite3_open 开启了一个数据库，结尾时不要忘了用这个函数关闭数据库。 下面给段简单的代码： extern \"C\" { #include \"./sqlite3.h\" }; int main( int , char** ) { sqlite3 * db = NULL; //声明sqlite关键结构指针 int result; //打开数据库 //需要传入 db 这个指针的指针，因为 sqlite3_open 函数要为这个指针分配内存，还要让db指针指向这个内存区 result = sqlite3_open( “c://Dcg_database.db”, &db ); if( result != SQLITE_OK ) { //数据库打开失败 return -1; } //数据库操作代码 //… //数据库打开成功 //关闭数据库 sqlite3_close( db ); return 0; } 这就是一次数据库操作过程。 （2） SQL语句操作 本节介绍如何用sqlite 执行标准 sql 语法。 i.1 执行sql语句 int sqlite3_exec(sqlite3*, const char *sql, sqlite3_callback, void *, char **errmsg ); 这就是执行一条 sql 语句的函数。 第1个参数不再说了，是前面open函数得到的指针。说了是关键数据结构。 第2个参数const char *sql 是一条 sql 语句，以/0结尾。 第3个参数sqlite3_callback 是回调，当这条语句执行之后，sqlite3会去调用你提供的这个函数。（什么是回调函数，自己找别的资料学习） 第4个参数void * 是你所提供的指针，你可以传递任何一个指针参数到这里，这个参数最终会传到回调函数里面，如果不需要传递指针给回调函数，可以填NULL。等下我们再看回调函数的写法，以及这个参数的使用。 第5个参数char ** errmsg 是错误信息。注意是指针的指针。sqlite3里面有很多固定的错误信息。执行 sqlite3_exec 之后，执行失败时可以查阅这个指针（直接 printf(“%s/n”,errmsg)）得到一串字符串信息，这串信息告诉你错在什么地方。sqlite3_exec函数通过修改你传入的指针的指针，把你提供的指针指向错误提示信息，这样sqlite3_exec函数外面就可以通过这个 char*得到具体错误提示。 说明：通常，sqlite3_callback 和它后面的 void * 这两个位置都可以填 NULL。填NULL表示你不需要回调。比如你做 insert 操作，做 delete 操作，就没有必要使用回调。而当你做 select 时，就要使用回调，因为 sqlite3 把数据查出来，得通过回调告诉你查出了什么数据。 i.2 exec 的回调 typedef int (*sqlite3_callback)(void*,int,char**, char**); 你的回调函数必须定义成上面这个函数的类型。下面给个简单的例子： //sqlite3的回调函数 // sqlite 每查到一条记录，就调用一次这个回调 int LoadMyInfo( void * para, int n_column, char ** column_value, char ** column_name ) { //para是你在 sqlite3_exec 里传入的 void * 参数 //通过para参数，你可以传入一些特殊的指针（比如类指针、结构指针），然后在这里面强制转换成对应的类型（这里面是void*类型，必须强制转换成你的类型才可用）。然后操作这些数据 //n_column是这一条记录有多少个字段 (即这条记录有多少列) // char ** column_value 是个关键值，查出来的数据都保存在这里，它实际上是个1维数组（不要以为是2维数组），每一个元素都是一个 char * 值，是一个字段内容（用字符串来表示，以/0结尾） //char ** column_name 跟 column_value是对应的，表示这个字段的字段名称 //这里，我不使用 para 参数。忽略它的存在. int i; printf( “记录包含 %d 个字段/n”, n_column ); for( i = 0 ; i < n_column; i ++ ) { printf( “字段名:%s ß> 字段值:%s/n”, column_name[i], column_value[i] ); } printf( “------------------/n“ ); return 0; } int main( int , char ** ) { sqlite3 * db; int result; char * errmsg = NULL; result = sqlite3_open( “c://Dcg_database.db”, &db ); if( result != SQLITE_OK ) { //数据库打开失败 return -1; } //数据库操作代码 //创建一个测试表，表名叫 MyTable_1，有2个字段： ID 和 name。其中ID是一个自动增加的类型，以后insert时可以不去指定这个字段，它会自己从0开始增加 result = sqlite3_exec( db, “create table MyTable_1( ID integer primary key autoincrement, name nvarchar(32) )”, NULL, NULL, errmsg ); if(result != SQLITE_OK ) { printf( “创建表失败，错误码:%d，错误原因:%s/n”, result, errmsg ); } //插入一些记录 result = sqlite3_exec( db, “insert into MyTable_1( name ) values ( ‘走路’ )”, 0, 0, errmsg ); if(result != SQLITE_OK ) { printf( “插入记录失败，错误码:%d，错误原因:%s/n”, result, errmsg ); } result = sqlite3_exec( db, “insert into MyTable_1( name ) values ( ‘骑单车’ )”, 0, 0, errmsg ); if(result != SQLITE_OK ) { printf( “插入记录失败，错误码:%d，错误原因:%s/n”, result, errmsg ); } result = sqlite3_exec( db, “insert into MyTable_1( name ) values ( ‘坐汽车’ )”, 0, 0, errmsg ); if(result != SQLITE_OK ) { printf( “插入记录失败，错误码:%d，错误原因:%s/n”, result, errmsg ); } //开始查询数据库 result = sqlite3_exec( db, “select * from MyTable_1”, LoadMyInfo, NULL, errmsg ); //关闭数据库 sqlite3_close( db ); return 0; } 通过上面的例子，应该可以知道如何打开一个数据库，如何做数据库基本操作。 有这些知识，基本上可以应付很多数据库操作了。 i.3 不使用回调查询数据库 上面介绍的 sqlite3_exec 是使用回调来执行 select 操作。还有一个方法可以直接查询而不需要回调。但是，我个人感觉还是回调好，因为代码可以更加整齐，只不过用回调很麻烦，你得声明一个函数，如果这个函数是类成员函数，你还不得不把它声明成 static 的（要问为什么？这又是C++基础了。C++成员函数实际上隐藏了一个参数：this，C++调用类的成员函数的时候，隐含把类指针当成函数的第一个参数传递进去。结果，这造成跟前面说的 sqlite 回调函数的参数不相符。只有当把成员函数声明成 static 时，它才没有多余的隐含的this参数）。 虽然回调显得代码整齐，但有时候你还是想要非回调的 select 查询。这可以通过 sqlite3_get_table 函数做到。 int sqlite3_get_table(sqlite3*, const char *sql, char ***resultp, int *nrow, int *ncolumn, char **errmsg ); 第1个参数不再多说，看前面的例子。 第2个参数是 sql 语句，跟 sqlite3_exec 里的 sql 是一样的。是一个很普通的以/0结尾的char *字符串。 第3个参数是查询结果，它依然一维数组（不要以为是二维数组，更不要以为是三维数组）。它内存布局是：第一行是字段名称，后面是紧接着是每个字段的值。下面用例子来说事。 第4个参数是查询出多少条记录（即查出多少行）。 第5个参数是多少个字段（多少列）。 第6个参数是错误信息，跟前面一样，这里不多说了。 下面给个简单例子: int main( int , char ** ) { sqlite3 * db; int result; char * errmsg = NULL; char **dbResult; //是 char ** 类型，两个*号 int nRow, nColumn; int i , j; int index; result = sqlite3_open( “c://Dcg_database.db”, &db ); if( result != SQLITE_OK ) { //数据库打开失败 return -1; } //数据库操作代码 //假设前面已经创建了 MyTable_1 表 //开始查询，传入的 dbResult 已经是 char **，这里又加了一个 & 取地址符，传递进去的就成了 char *** result = sqlite3_get_table( db, “select * from MyTable_1”, &dbResult, &nRow, &nColumn, &errmsg ); if( SQLITE_OK == result ) { //查询成功 index = nColumn; //前面说过 dbResult 前面第一行数据是字段名称，从 nColumn 索引开始才是真正的数据 printf( “查到%d条记录/n”, nRow ); for( i = 0; i < nRow ; i++ ) { printf( “第 %d 条记录/n”, i+1 ); for( j = 0 ; j < nColumn; j++ ) { printf( “字段名:%s ß> 字段值:%s/n”, dbResult[j], dbResult [index] ); ++index; // dbResult 的字段值是连续的，从第0索引到第 nColumn - 1索引都是字段名称，从第 nColumn 索引开始，后面都是字段值，它把一个二维的表（传统的行列表示法）用一个扁平的形式来表示 } printf( “-------/n” ); } } //到这里，不论数据库查询是否成功，都释放 char** 查询结果，使用 sqlite 提供的功能来释放 sqlite3_free_table( dbResult ); //关闭数据库 sqlite3_close( db ); return 0; } 到这个例子为止，sqlite3 的常用用法都介绍完了。 用以上的方法，再配上 sql 语句，完全可以应付绝大多数数据库需求。 但有一种情况，用上面方法是无法实现的：需要insert、select 二进制。当需要处理二进制数据时，上面的方法就没办法做到。下面这一节说明如何插入二进制数据 （2） 操作二进制 sqlite 操作二进制数据需要用一个辅助的数据类型：sqlite3_stmt * 。 这个数据类型记录了一个“sql语句”。为什么我把 “sql语句” 用双引号引起来？因为你可以把 sqlite3_stmt * 所表示的内容看成是 sql语句，但是实际上它不是我们所熟知的sql语句。它是一个已经把sql语句解析了的、用sqlite自己标记记录的内部数据结构。 正因为这个结构已经被解析了，所以你可以往这个语句里插入二进制数据。当然，把二进制数据插到 sqlite3_stmt 结构里可不能直接 memcpy ，也不能像 std::string 那样用 + 号。必须用 sqlite 提供的函数来插入。   i.1 写入二进制 下面说写二进制的步骤。 要插入二进制，前提是这个表的字段的类型是 blob 类型。我假设有这么一张表： create table Tbl_2( ID integer, file_content blob ) 首先声明 sqlite3_stmt * stat; 然后，把一个 sql 语句解析到 stat 结构里去： sqlite3_prepare( db, “insert into Tbl_2( ID, file_content) values( 10, ? )”, -1, &stat, 0 ); 上面的函数完成 sql 语句的解析。第一个参数跟前面一样，是个 sqlite3 * 类型变量，第二个参数是一个 sql 语句。 这个 sql 语句特别之处在于 values 里面有个 ? 号。在sqlite3_prepare函数里，?号表示一个未定的值，它的值等下才插入。 第三个参数我写的是-1，这个参数含义是前面 sql 语句的长度。如果小于0，sqlite会自动计算它的长度（把sql语句当成以/0结尾的字符串）。 第四个参数是 sqlite3_stmt 的指针的指针。解析以后的sql语句就放在这个结构里。 第五个参数我也不知道是干什么的。为0就可以了。 如果这个函数执行成功（返回值是 SQLITE_OK 且 stat 不为NULL ），那么下面就可以开始插入二进制数据。 sqlite3_bind_blob( stat, 1, pdata, (int)(length_of_data_in_bytes), NULL ); // pdata为数据缓冲区，length_of_data_in_bytes为数据大小，以字节为单位 这个函数一共有5个参数。 第1个参数：是前面prepare得到的 sqlite3_stmt * 类型变量。 第2个参数：?号的索引。前面prepare的sql语句里有一个?号，假如有多个?号怎么插入？方法就是改变 bind_blob 函数第2个参数。这个参数我写1，表示这里插入的值要替换 stat 的第一个?号（这里的索引从1开始计数，而非从0开始）。如果你有多个?号，就写多个 bind_blob 语句，并改变它们的第2个参数就替换到不同的?号。如果有?号没有替换，sqlite为它取值null。 第3个参数：二进制数据起始指针。 第4个参数：二进制数据的长度，以字节为单位。 第5个参数：是个析够回调函数，告诉sqlite当把数据处理完后调用此函数来析够你的数据。这个参数我还没有使用过，因此理解也不深刻。但是一般都填NULL，需要释放的内存自己用代码来释放。 bind完了之后，二进制数据就进入了你的“sql语句”里了。你现在可以把它保存到数据库里： int result = sqlite3_step( stat ); 通过这个语句，stat 表示的sql语句就被写到了数据库里。 最后，要把 sqlite3_stmt 结构给释放： sqlite3_finalize( stat ); //把刚才分配的内容析构掉   i.2 读出二进制 下面说读二进制的步骤。 跟前面一样，先声明 sqlite3_stmt * 类型变量： sqlite3_stmt * stat; 然后，把一个 sql 语句解析到 stat 结构里去： sqlite3_prepare( db, “select * from Tbl_2”, -1, &stat, 0 ); 当 prepare 成功之后（返回值是 SQLITE_OK ），开始查询数据。 int result = sqlite3_step( stat ); 这一句的返回值是 SQLITE_ROW 时表示成功（不是 SQLITE_OK ）。 你可以循环执行 sqlite3_step 函数，一次 step 查询出一条记录。直到返回值不为 SQLITE_ROW 时表示查询结束。 然后开始获取第一个字段：ID 的值。ID是个整数，用下面这个语句获取它的值： int id = sqlite3_column_int( stat, 0 ); //第2个参数表示获取第几个字段内容，从0开始计算，因为我的表的ID字段是第一个字段，因此这里我填0 下面开始获取 file_content 的值，因为 file_content 是二进制，因此我需要得到它的指针，还有它的长度： const void * pFileContent = sqlite3_column_blob( stat, 1 ); int len = sqlite3_column_bytes( stat, 1 ); 这样就得到了二进制的值。 把 pFileContent 的内容保存出来之后，不要忘了释放 sqlite3_stmt 结构： sqlite3_finalize( stat ); //把刚才分配的内容析构掉 i.3 重复使用 sqlite3_stmt 结构 如果你需要重复使用 sqlite3_prepare 解析好的 sqlite3_stmt 结构，需要用函数： sqlite3_reset。 result = sqlite3_reset(stat); 这样， stat 结构又成为 sqlite3_prepare 完成时的状态，你可以重新为它 bind 内容。 （4） 事务处理 sqlite 是支持事务处理的。如果你知道你要同步删除很多数据，不仿把它们做成一个统一的事务。 通常一次 sqlite3_exec 就是一次事务，如果你要删除1万条数据，sqlite就做了1万次：开始新事务->删除一条数据->提交事务->开始新事务->… 的过程。这个操作是很慢的。因为时间都花在了开始事务、提交事务上。 你可以把这些同类操作做成一个事务，这样如果操作错误，还能够回滚事务。 事务的操作没有特别的接口函数，它就是一个普通的 sql 语句而已： 分别如下： int result; result = sqlite3_exec( db, \"begin transaction\", 0, 0, &zErrorMsg ); //开始一个事务 result = sqlite3_exec( db, \"commit transaction\", 0, 0, &zErrorMsg ); //提交事务 result = sqlite3_exec( db, \"rollback transaction\", 0, 0, &zErrorMsg ); //回滚事务 一、 给数据库加密 前面所说的内容网上已经有很多资料，虽然比较零散，但是花点时间也还是可以找到的。现在要说的这个——数据库加密，资料就很难找。也可能是我操作水平不够，找不到对应资料。但不管这样，我还是通过网上能找到的很有限的资料，探索出了给sqlite数据库加密的完整步骤。 这里要提一下，虽然 sqlite 很好用，速度快、体积小巧。但是它保存的文件却是明文的。若不信可以用 NotePad 打开数据库文件瞧瞧，里面 insert 的内容几乎一览无余。这样赤裸裸的展现自己，可不是我们的初衷。当然，如果你在嵌入式系统、智能手机上使用 sqlite，最好是不加密，因为这些系统运算能力有限，你做为一个新功能提供者，不能把用户有限的运算能力全部花掉。 Sqlite为了速度而诞生。因此Sqlite本身不对数据库加密，要知道，如果你选择标准AES算法加密，那么一定有接近50%的时间消耗在加解密算法上，甚至更多（性能主要取决于你算法编写水平以及你是否能使用cpu提供的底层运算能力，比如MMX或sse系列指令可以大幅度提升运算速度）。 Sqlite免费版本是不提供加密功能的，当然你也可以选择他们的收费版本，那你得支付2000块钱，而且是USD。我这里也不是说支付钱不好，如果只为了数据库加密就去支付2000块，我觉得划不来。因为下面我将要告诉你如何为免费的Sqlite扩展出加密模块——自己动手扩展，这是Sqlite允许，也是它提倡的。 那么，就让我们一起开始为 sqlite3.c 文件扩展出加密模块。 i.1 必要的宏 通过阅读 Sqlite 代码（当然没有全部阅读完，6万多行代码，没有一行是我习惯的风格，我可没那么多眼神去看），我搞清楚了两件事： Sqlite是支持加密扩展的； 需要 #define 一个宏才能使用加密扩展。 这个宏就是 SQLITE_HAS_CODEC。 你在代码最前面（也可以在 sqlite3.h 文件第一行）定义： #ifndef SQLITE_HAS_CODEC #define SQLITE_HAS_CODEC #endif 如果你在代码里定义了此宏，但是还能够正常编译，那么应该是操作没有成功。因为你应该会被编译器提示有一些函数无法链接才对。如果你用的是 VC 2003，你可以在“解决方案”里右键点击你的工程，然后选“属性”，找到“C/C ”，再找到“命令行”，在里面手工添加“/D \"SQLITE_HAS_CODEC\"”。 定义了这个宏，一些被 Sqlite 故意屏蔽掉的代码就被使用了。这些代码就是加解密的接口。 尝试编译，vc会提示你有一些函数无法链接，因为找不到他们的实现。 如果你也用的是VC2003，那么会得到下面的提示： error LNK2019: 无法解析的外部符号 _sqlite3CodecGetKey ，该符号在函数 _attachFunc 中被引用 error LNK2019: 无法解析的外部符号 _sqlite3CodecAttach ，该符号在函数 _attachFunc 中被引用 error LNK2019: 无法解析的外部符号 _sqlite3_activate_see，该符号在函数 _sqlite3Pragma 中被引用 error LNK2019: 无法解析的外部符号 _sqlite3_key ，该符号在函数 _sqlite3Pragma 中被引用 fatal error LNK1120: 4 个无法解析的外部命令 这是正常的，因为Sqlite只留了接口而已，并没有给出实现。 下面就让我来实现这些接口。 i.2 自己实现加解密接口函数 如果真要我从一份 www.sqlite.org 网上down下来的 sqlite3.c 文件，直接摸索出这些接口的实现，我认为我还没有这个能力。 好在网上还有一些代码已经实现了这个功能。通过参照他们的代码以及不断编译中vc给出的错误提示，最终我把整个接口整理出来。 实现这些预留接口不是那么容易，要重头说一次怎么回事很困难。我把代码都写好了，直接把他们按我下面的说明拷贝到 sqlite3.c 文件对应地方即可。我在下面也提供了sqlite3.c 文件，可以直接参考或取下来使用。 这里要说一点的是，我另外新建了两个文件：crypt.c和crypt.h。 其中crypt.h如此定义： #ifndef DCG_SQLITE_CRYPT_FUNC_ #define DCG_SQLITE_CRYPT_FUNC_ ***********/ int My_DeEncrypt_Func( unsigned char * pData, unsigned int data_len, const char * key, unsigned int len_of_key ); #endif   其中的 crypt.c 如此定义： #include \"./crypt.h\" #include \"memory.h\" int My_Encrypt_Func( unsigned char * pData, unsigned int data_len, const char * key, unsigned int len_of_key ) { return 0; } int My_DeEncrypt_Func( unsigned char * pData, unsigned int data_len, const char * key, unsigned int len_of_key ) { return 0; } 这个文件很容易看，就两函数，一个加密一个解密。传进来的参数分别是待处理的数据、数据长度、密钥、密钥长度。 处理时直接把结果作用于 pData 指针指向的内容。 你需要定义自己的加解密过程，就改动这两个函数，其它部分不用动。扩展起来很简单。 这里有个特点，data_len 一般总是 1024 字节。正因为如此，你可以在你的算法里使用一些特定长度的加密算法，比如AES要求被加密数据一定是128位（16字节）长。这个1024不是碰巧，而是 Sqlite 的页定义是1024字节，在sqlite3.c文件里有定义: # define SQLITE_DEFAULT_PAGE_SIZE 1024 你可以改动这个值，不过还是建议没有必要不要去改它。 上面写了两个扩展函数，如何把扩展函数跟 Sqlite 挂接起来，这个过程说起来比较麻烦。我直接贴代码。 分3个步骤。 首先，在 sqlite3.c 文件顶部，添加下面内容： #ifdef SQLITE_HAS_CODEC #include \"./crypt.h\" void sqlite3pager_free_codecarg(void *pArg); #endif 这个函数之所以要在 sqlite3.c 开头声明，是因为下面在 sqlite3.c 里面某些函数里要插入这个函数调用。所以要提前声明。 其次，在sqlite3.c文件里搜索“sqlite3PagerClose”函数，要找到它的实现代码（而不是声明代码）。 实现代码里一开始是： #ifdef SQLITE_ENABLE_MEMORY_MANAGEMENT ThreadData *pTsd = sqlite3ThreadData(); assert( pPager ); assert( pTsd && pTsd->nAlloc ); #endif 需要在这部分后面紧接着插入： #ifdef SQLITE_HAS_CODEC sqlite3pager_free_codecarg(pPager->pCodecArg); #endif 这里要注意，sqlite3PagerClose 函数大概也是 3.3.17版本左右才改名的，以前版本里是叫 “sqlite3pager_close”。因此你在老版本sqlite代码里搜索“sqlite3PagerClose”是搜不到的。 类似的还有“sqlite3pager_get”、“sqlite3pager_unref”、“sqlite3pager_write”、“sqlite3pager_pagecount”等都是老版本函数，它们在 pager.h 文件里定义。新版本对应函数是在 sqlite3.h 里定义（因为都合并到 sqlite3.c和sqlite3.h两文件了）。所以，如果你在使用老版本的sqlite，先看看 pager.h 文件，这些函数不是消失了，也不是新蹦出来的，而是老版本函数改名得到的。   最后，往sqlite3.c 文件下找。找到最后一行： 在这一行后面，接上本文最下面的代码段。 这些代码很长，我不再解释，直接接上去就得了。 唯一要提的是 DeriveKey 函数。这个函数是对密钥的扩展。比如，你要求密钥是128位，即是16字节，但是如果用户只输入 1个字节呢？2个字节呢？或输入50个字节呢？你得对密钥进行扩展，使之符合16字节的要求。 DeriveKey 函数就是做这个扩展的。有人把接收到的密钥求md5，这也是一个办法，因为md5运算结果固定16字节，不论你有多少字符，最后就是16字节。这是md5算法的特点。但是我不想用md5，因为还得为它添加包含一些 md5 的.c或.cpp文件。我不想这么做。我自己写了一个算法来扩展密钥，很简单的算法。当然，你也可以使用你的扩展方法，也而可以使用 md5 算法。只要修改 DeriveKey 函数就可以了。 在 DeriveKey 函数里，只管申请空间构造所需要的密钥，不需要释放，因为在另一个函数里有释放过程，而那个函数会在数据库关闭时被调用。参考我的 DeriveKey 函数来申请内存。 这里我给出我已经修改好的 sqlite3.c 和 sqlite3.h 文件。 如果太懒，就直接使用这两个文件，编译肯定能通过，运行也正常。当然，你必须按我前面提的，新建 crypt.h 和 crypt.c 文件，而且函数要按我前面定义的要求来做。 i.3 加密使用方法： 现在，你代码已经有了加密功能。 你要把加密功能给用上，除了改 sqlite3.c 文件、给你工程添加 SQLITE_HAS_CODEC 宏，还得修改你的数据库调用函数。 前面提到过，要开始一个数据库操作，必须先 sqlite3_open 。 加解密过程就在 sqlite3_open 后面操作。 假设你已经 sqlite3_open 成功了，紧接着写下面的代码： int i; //添加、使用密码 i = sqlite3_key( db, \"dcg\", 3 ); //修改密码 i = sqlite3_rekey( db, \"dcg\", 0 ); 用 sqlite3_key 函数来提交密码。 第1个参数是 sqlite3 * 类型变量，代表着用 sqlite3_open 打开的数据库（或新建数据库）。 第2个参数是密钥。 第3个参数是密钥长度。 用 sqlite3_rekey 来修改密码。参数含义同 sqlite3_key。 实际上，你可以在sqlite3_open函数之后，到 sqlite3_close 函数之前任意位置调用 sqlite3_key 来设置密码。 但是如果你没有设置密码，而数据库之前是有密码的，那么你做任何操作都会得到一个返回值：SQLITE_NOTADB，并且得到错误提示：“file is encrypted or is not a database”。 只有当你用 sqlite3_key 设置了正确的密码，数据库才会正常工作。 如果你要修改密码，前提是你必须先 sqlite3_open 打开数据库成功，然后 sqlite3_key 设置密钥成功，之后才能用 sqlite3_rekey 来修改密码。 如果数据库有密码，但你没有用 sqlite3_key 设置密码，那么当你尝试用 sqlite3_rekey 来修改密码时会得到 SQLITE_NOTADB 返回值。 如果你需要清空密码，可以使用： //修改密码 i = sqlite3_rekey( db, NULL, 0 ); 来完成密码清空功能。   i.4 sqlite3.c 最后添加代码段   #ifdef SQLITE_HAS_CODEC #define CRYPT_OFFSET 8 typedef struct _CryptBlock { BYTE* ReadKey; // 读数据库和写入事务的密钥 BYTE* WriteKey; // 写入数据库的密钥 int PageSize; // 页的大小 BYTE* Data; } CryptBlock, *LPCryptBlock; #ifndef DB_KEY_LENGTH_BYTE #define DB_KEY_LENGTH_BYTE 16 #endif #ifndef DB_KEY_PADDING #define DB_KEY_PADDING 0x33 #endif void sqlite3CodecGetKey(sqlite3* db, int nDB, void** Key, int* nKey) { return ; } int sqlite3CodecAttach(sqlite3 *db, int nDb, const void *pKey, int nKeyLen); void sqlite3_activate_see(const char* right ) { return; } int sqlite3_key(sqlite3 *db, const void *pKey, int nKey); int sqlite3_rekey(sqlite3 *db, const void *pKey, int nKey);   // 从用户提供的缓冲区中得到一个加密密钥 // 用户提供的密钥可能位数上满足不了要求，使用这个函数来完成密钥扩展 static unsigned char * DeriveKey(const void *pKey, int nKeyLen); //创建或更新一个页的加密算法索引.此函数会申请缓冲区. static LPCryptBlock CreateCryptBlock(unsigned char* hKey, Pager *pager, LPCryptBlock pExisting); //加密/解密函数, 被pager调用 void * sqlite3Codec(void *pArg, unsigned char *data, Pgno nPageNum, int nMode); //设置密码函数 int __stdcall sqlite3_key_interop(sqlite3 *db, const void *pKey, int nKeySize); // 修改密码函数 int __stdcall sqlite3_rekey_interop(sqlite3 *db, const void *pKey, int nKeySize); //销毁一个加密块及相关的缓冲区,密钥. static void DestroyCryptBlock(LPCryptBlock pBlock); static void * sqlite3pager_get_codecarg(Pager *pPager); void sqlite3pager_set_codec(Pager *pPager,void *(*xCodec)(void*,void*,Pgno,int),void *pCodecArg );   //加密/解密函数, 被pager调用 void * sqlite3Codec(void *pArg, unsigned char *data, Pgno nPageNum, int nMode) { LPCryptBlock pBlock = (LPCryptBlock)pArg; unsigned int dwPageSize = 0; if (!pBlock) return data; // 确保pager的页长度和加密块的页长度相等.如果改变,就需要调整. if (nMode != 2) { PgHdr *pageHeader; pageHeader = DATA_TO_PGHDR(data); if (pageHeader->pPager->pageSize != pBlock->PageSize) { CreateCryptBlock(0, pageHeader->pPager, pBlock); } }   switch(nMode) { case 0: // Undo a \"case 7\" journal file encryption case 2: //重载一个页 case 3: //载入一个页 if (!pBlock->ReadKey) break;   dwPageSize = pBlock->PageSize; My_DeEncrypt_Func(data, dwPageSize, pBlock->ReadKey, DB_KEY_LENGTH_BYTE );   break; case 6: //加密一个主数据库文件的页 if (!pBlock->WriteKey) break; memcpy(pBlock->Data CRYPT_OFFSET, data, pBlock->PageSize); data = pBlock->Data CRYPT_OFFSET;   dwPageSize = pBlock->PageSize; My_Encrypt_Func(data , dwPageSize, pBlock->WriteKey, DB_KEY_LENGTH_BYTE ); break; case 7: //加密事务文件的页 if (!pBlock->ReadKey) break; memcpy(pBlock->Data CRYPT_OFFSET, data, pBlock->PageSize); data = pBlock->Data CRYPT_OFFSET; dwPageSize = pBlock->PageSize; My_Encrypt_Func( data, dwPageSize, pBlock->ReadKey, DB_KEY_LENGTH_BYTE ); break; } return data; }   // 销毁一个加密块及相关的缓冲区,密钥. static void DestroyCryptBlock(LPCryptBlock pBlock) { //销毁读密钥. if (pBlock->ReadKey){ sqliteFree(pBlock->ReadKey); } //如果写密钥存在并且不等于读密钥,也销毁. if (pBlock->WriteKey && pBlock->WriteKey != pBlock->ReadKey){ sqliteFree(pBlock->WriteKey); } if(pBlock->Data){ sqliteFree(pBlock->Data); } //释放加密块. sqliteFree(pBlock); } static void * sqlite3pager_get_codecarg(Pager *pPager) { return (pPager->xCodec) ? pPager->pCodecArg: NULL; } // 从用户提供的缓冲区中得到一个加密密钥 static unsigned char * DeriveKey(const void *pKey, int nKeyLen) { unsigned char * hKey = NULL; int j; if( pKey == NULL || nKeyLen == 0 ) { return NULL; } hKey = sqliteMalloc( DB_KEY_LENGTH_BYTE 1 ); if( hKey == NULL ) { return NULL; } hKey[ DB_KEY_LENGTH_BYTE ] = 0; if( nKeyLen < DB_KEY_LENGTH_BYTE ) { memcpy( hKey, pKey, nKeyLen ); //先拷贝得到密钥前面的部分 j = DB_KEY_LENGTH_BYTE - nKeyLen; //补充密钥后面的部分 memset( hKey nKeyLen, DB_KEY_PADDING, j ); } else { //密钥位数已经足够,直接把密钥取过来 memcpy( hKey, pKey, DB_KEY_LENGTH_BYTE ); } return hKey; }   //创建或更新一个页的加密算法索引.此函数会申请缓冲区. static LPCryptBlock CreateCryptBlock(unsigned char* hKey, Pager *pager, LPCryptBlock pExisting) { LPCryptBlock pBlock;   if (!pExisting) //创建新加密块 { pBlock = sqliteMalloc(sizeof(CryptBlock)); memset(pBlock, 0, sizeof(CryptBlock)); pBlock->ReadKey = hKey; pBlock->WriteKey = hKey; pBlock->PageSize = pager->pageSize; pBlock->Data = (unsigned char*)sqliteMalloc(pBlock->PageSize CRYPT_OFFSET); } else //更新存在的加密块 { pBlock = pExisting; if ( pBlock->PageSize != pager->pageSize && !pBlock->Data){ sqliteFree(pBlock->Data); pBlock->PageSize = pager->pageSize; pBlock->Data = (unsigned char*)sqliteMalloc(pBlock->PageSize CRYPT_OFFSET); } }   memset(pBlock->Data, 0, pBlock->PageSize CRYPT_OFFSET); return pBlock; }   void sqlite3pager_set_codec( Pager *pPager, void *(*xCodec)(void*,void*,Pgno,int), void *pCodecArg ) { pPager->xCodec = xCodec; pPager->pCodecArg = pCodecArg; } int sqlite3_key(sqlite3 *db, const void *pKey, int nKey) { return sqlite3_key_interop(db, pKey, nKey); } int sqlite3_rekey(sqlite3 *db, const void *pKey, int nKey) { return sqlite3_rekey_interop(db, pKey, nKey); } int sqlite3CodecAttach(sqlite3 *db, int nDb, const void *pKey, int nKeyLen) { int rc = SQLITE_ERROR; unsigned char* hKey = 0; //如果没有指定密匙,可能标识用了主数据库的加密或没加密. if (!pKey || !nKeyLen) { if (!nDb) { return SQLITE_OK; //主数据库, 没有指定密钥所以没有加密. } else //附加数据库,使用主数据库的密钥. { //获取主数据库的加密块并复制密钥给附加数据库使用 LPCryptBlock pBlock = (LPCryptBlock)sqlite3pager_get_codecarg(sqlite3BtreePager(db->aDb[0].pBt)); if (!pBlock) return SQLITE_OK; //主数据库没有加密 if (!pBlock->ReadKey) return SQLITE_OK; //没有加密 memcpy(pBlock->ReadKey, &hKey, 16); } } else //用户提供了密码,从中创建密钥. { hKey = DeriveKey(pKey, nKeyLen); } //创建一个新的加密块,并将解码器指向新的附加数据库. if (hKey) { LPCryptBlock pBlock = CreateCryptBlock(hKey, sqlite3BtreePager(db->aDb[nDb].pBt), NULL); sqlite3pager_set_codec(sqlite3BtreePager(db->aDb[nDb].pBt), sqlite3Codec, pBlock); rc = SQLITE_OK; } return rc; } // Changes the encryption key for an existing database. int __stdcall sqlite3_rekey_interop(sqlite3 *db, const void *pKey, int nKeySize) { Btree *pbt = db->aDb[0].pBt; Pager *p = sqlite3BtreePager(pbt); LPCryptBlock pBlock = (LPCryptBlock)sqlite3pager_get_codecarg(p); unsigned char * hKey = DeriveKey(pKey, nKeySize); int rc = SQLITE_ERROR; if (!pBlock && !hKey) return SQLITE_OK; //重新加密一个数据库,改变pager的写密钥, 读密钥依旧保留. if (!pBlock) //加密一个未加密的数据库 { pBlock = CreateCryptBlock(hKey, p, NULL); pBlock->ReadKey = 0; // 原始数据库未加密 sqlite3pager_set_codec(sqlite3BtreePager(pbt), sqlite3Codec, pBlock); } else // 改变已加密数据库的写密钥 { pBlock->WriteKey = hKey; } // 开始一个事务 rc = sqlite3BtreeBeginTrans(pbt, 1); if (!rc) { // 用新密钥重写所有的页到数据库。 Pgno nPage = sqlite3PagerPagecount(p); Pgno nSkip = PAGER_MJ_PGNO(p); void *pPage; Pgno n; for(n = 1; rc == SQLITE_OK && n <= nPage; n ) { if (n == nSkip) continue; rc = sqlite3PagerGet(p, n, &pPage); if(!rc) { rc = sqlite3PagerWrite(pPage); sqlite3PagerUnref(pPage); } } } // 如果成功，提交事务。 if (!rc) { rc = sqlite3BtreeCommit(pbt); } // 如果失败，回滚。 if (rc) { sqlite3BtreeRollback(pbt); }     // 如果成功，销毁先前的读密钥。并使读密钥等于当前的写密钥。 if (!rc) { if (pBlock->ReadKey) { sqliteFree(pBlock->ReadKey); } pBlock->ReadKey = pBlock->WriteKey; } else// 如果失败，销毁当前的写密钥，并恢复为当前的读密钥。 { if (pBlock->WriteKey) { sqliteFree(pBlock->WriteKey); } pBlock->WriteKey = pBlock->ReadKey; }   // 如果读密钥和写密钥皆为空，就不需要再对页进行编解码。 // 销毁加密块并移除页的编解码器 if (!pBlock->ReadKey && !pBlock->WriteKey) { sqlite3pager_set_codec(p, NULL, NULL); DestroyCryptBlock(pBlock); } return rc; } int __stdcall sqlite3_key_interop(sqlite3 *db, const void *pKey, int nKeySize) { return sqlite3CodecAttach(db, 0, pKey, nKeySize); }   // 释放与一个页相关的加密块 void sqlite3pager_free_codecarg(void *pArg) { if (pArg) DestroyCryptBlock((LPCryptBlock)pArg); } #endif //#ifdef SQLITE_HAS_CODEC 作者：Leo Chin 出处：http://www.cnblogs.com/hnrainll/ 本博客文章,大多系网络中收集,转载请注明出处","title":"sqlite api"},{"content":"1、只导出数据库中某个表的数据，而且每次只导出一个表的数据。 select * into outfile 'd:\\\\test.txt' from t_message; 注：导出了表的数据，表结构没有被导出。   2、导出这个数据库的数据，及表结构 mysqldump.exe -u root -p webdb > d:\\\\test.sql root mysql的管理员 webdb是数据库名称 d:\\\\test.sql是导出数据的目标位置   导出数据库中某个表的结构及数据 mysqldump.exe -u root -p webdb tableName> d:\\\\test.sql tableName是表的名称。   3、先创建数据库，再使用该命令将运行test.sql脚本。可以同时 创建表和插入表信息。 source d:\\\\test.sql 此命令要在MySQL Command Line Client下执行。 备注：要添加mysql的环境变量，不然mysql的命令系统不会识别。","title":"mysql 数据备份、还原"},{"content":"原文链接：http://blog.csdn.net/sunlin5000/article/details/6578250   1、找到my.cnf配置文件 如果/etc/目录下没有my.cnf配置文件，请到/usr/share/mysql/下找到*.cnf文件，拷贝其中一个到/etc/并改名为my.cnf)中。命令如下： [root@test1 mysql]# cp /usr/share/mysql/my-medium.cnf　/etc/my.cnf       mysql5.5.10默认字符集修改，字符编码设置，中文乱码，gb2312，gbk，utf8格式存储数据 通过修改mysql默认字符集，可以存储中文数据，以免出现中文乱码，以下以设置为utf8为例。 ================================================================================= 以下内容是在本机安装的mysql-5.5.10上,没有修改my.ini前显示结果 ===================================================================================  mysql> show variables like 'character%'; +--------------------------+---------------------------------+ | Variable_name            | Value                           | +--------------------------+---------------------------------+ | character_set_client     | gbk                             | | character_set_connection | gbk                             | | character_set_database   | latin1                          | | character_set_filesystem | binary                          | | character_set_results    | gbk                             | | character_set_server     | latin1                          | | character_set_system     | utf8                            | | character_sets_dir       |/usr/share/mysql/charsets/ | +--------------------------+---------------------------------+ 8 rows in set (0.02 sec) mysql> show variables like 'collation%'; +----------------------+-------------------+ | Variable_name        | Value             | +----------------------+-------------------+ | collation_connection | gbk_chinese_ci    | | collation_database   | latin1_swedish_ci | | collation_server     | latin1_swedish_ci | +----------------------+-------------------+ 3 rows in set (0.00 sec)   ============================================================================== 关闭mysql服务，在mysql安装目录下，my.ini文件进行如下修改，没有则直接进行添加 ============================================================================== [client] #修改客户端默认字符编码格式为utf8 default-character-set=utf8 [mysqld] #修改服务器端默认字符编码格式为utf8 character-set-server = utf8   ============================================================================= 修改后，再次输入命令查看，显示结果如下 ============================================================================== mysql> show variables like 'character%'; +--------------------------+---------------------------------+ | Variable_name            | Value                           | +--------------------------+---------------------------------+ | character_set_client     | utf8                            | | character_set_connection | utf8                            | | character_set_database   | utf8                            | | character_set_filesystem | binary                          | | character_set_results    | utf8                            | | character_set_server     | utf8                            | | character_set_system     | utf8                            | | character_sets_dir       | /usr/share/mysql/charsets/  | +--------------------------+---------------------------------+ 8 rows in set (0.00 sec) mysql> show variables like 'collation%'; +----------------------+-----------------+ | Variable_name        | Value           | +----------------------+-----------------+ | collation_connection | utf8_general_ci | | collation_database   | utf8_general_ci | | collation_server     | utf8_general_ci | +----------------------+-----------------+ 3 rows in set (0.00 sec) ================================================================================ 查看mysql已经安装的所有字符集，也就是在mysql中可以使用的字符集，结果如下 ================================================================================ mysql> show character set; +----------+-----------------------------+---------------------+--------+ | Charset  | Description                 | Default collation   | Maxlen | +----------+-----------------------------+---------------------+--------+ | big5     | Big5 Traditional Chinese    | big5_chinese_ci     |      2 | | dec8     | DEC West European           | dec8_swedish_ci     |      1 | | cp850    | DOS West European           | cp850_general_ci    |      1 | | hp8      | HP West European            | hp8_english_ci      |      1 | | koi8r    | KOI8-R Relcom Russian       | koi8r_general_ci    |      1 | | latin1   | cp1252 West European        | latin1_swedish_ci   |      1 | | latin2   | ISO 8859-2 Central European | latin2_general_ci   |      1 | | swe7     | 7bit Swedish                | swe7_swedish_ci     |      1 | | ascii    | US ASCII                    | ascii_general_ci    |      1 | | ujis     | EUC-JP Japanese             | ujis_japanese_ci    |      3 | | sjis     | Shift-JIS Japanese          | sjis_japanese_ci    |      2 | | hebrew   | ISO 8859-8 Hebrew           | hebrew_general_ci   |      1 | | tis620   | TIS620 Thai                 | tis620_thai_ci      |      1 | | euckr    | EUC-KR Korean               | euckr_korean_ci     |      2 | | koi8u    | KOI8-U Ukrainian            | koi8u_general_ci    |      1 | | gb2312   | GB2312 Simplified Chinese   | gb2312_chinese_ci   |      2 | | greek    | ISO 8859-7 Greek            | greek_general_ci    |      1 | | cp1250   | Windows Central European    | cp1250_general_ci   |      1 | | gbk      | GBK Simplified Chinese      | gbk_chinese_ci      |      2 | | latin5   | ISO 8859-9 Turkish          | latin5_turkish_ci   |      1 | | armscii8 | ARMSCII-8 Armenian          | armscii8_general_ci |      1 | | utf8     | UTF-8 Unicode               | utf8_general_ci     |      3 | | ucs2     | UCS-2 Unicode               | ucs2_general_ci     |      2 | | cp866    | DOS Russian                 | cp866_general_ci    |      1 | | keybcs2  | DOS Kamenicky Czech-Slovak  | keybcs2_general_ci  |      1 | | macce    | Mac Central European        | macce_general_ci    |      1 | | macroman | Mac West European           | macroman_general_ci |      1 | | cp852    | DOS Central European        | cp852_general_ci    |      1 | | latin7   | ISO 8859-13 Baltic          | latin7_general_ci   |      1 | | utf8mb4  | UTF-8 Unicode               | utf8mb4_general_ci  |      4 | | cp1251   | Windows Cyrillic            | cp1251_general_ci   |      1 | | utf16    | UTF-16 Unicode              | utf16_general_ci    |      4 | | cp1256   | Windows Arabic              | cp1256_general_ci   |      1 | | cp1257   | Windows Baltic              | cp1257_general_ci   |      1 | | utf32    | UTF-32 Unicode              | utf32_general_ci    |      4 | | binary   | Binary pseudo charset       | binary              |      1 | | geostd8  | GEOSTD8 Georgian            | geostd8_general_ci  |      1 | | cp932    | SJIS for Windows Japanese   | cp932_japanese_ci   |      2 | | eucjpms  | UJIS for Windows Japanese   | eucjpms_japanese_ci |      3 | +----------+-----------------------------+---------------------+--------+ 39 rows in set (0.00 sec) =============================================================================== 经过所有以上设置以后，mysql中所有字符集都是utf8的了，但是在控制台操作的时候，还是会出现乱码中文乱码。 这是因为windows XP的控制台窗口默认显示字符编码格式为gbk，所以这里要设置显示结果使用的字符编码格式为utf8。 每次在控制台进行操作的时候，都要进行如下这个设置，结果才能正常显示中文 =============================================================================== mysql> set character_set_results='gbk'; Query OK, 0 rows affected (0.00 sec) =============================================================================== 一般就算设置了表的默认字符集为utf8并且通过UTF-8编码发送查询，你会发现存入数据库的仍然是乱码。 问题就出在这个connection连接层上。解决方法是在发送查询前执行一下下面这句： =============================================================================== mysql> set names gbk; Query OK, 0 rows affected (0.00 sec) 它相当于下面的三句指令： SET character_set_client = utf8; SET character_set_results = utf8; SET character_set_connection = utf8; 因此，这个方法也可以解决所有字符编码设置为utf8，而控制台显示中文乱码的问题。  ","title":"mysql 中文乱码问题"},{"content":"今天，Linux的发行版非常地容易安装也非常容易入门。就算是一个缺乏经验的系统管理员，建立必须的服务并完成可运行的程序通常也可以在几小时内完成。   很不幸，容易入门反而掩盖了需要做的维护工作，这些工作是保持系统稳定和使系统长期处于一个良好的工作次序中所必需的。一个单一的服务器通常可以在没有人工干预的情况下运行很长时间。但是前提是所有其他的位和块必需被提前配置。   关于这个列表，最糟糕的事情是你可能已经几个月或几年没有做这些事情了。你忽略这些事情中的任何一件，它们都会在最糟糕的时候回来作祟：比如流量高峰期，硬盘驱动器崩溃，或黑客攻击的时候。Linux系统管理员每天都应该做一些什么工作？我们这就为您来总结一下。   配置管理   我用配置管理来开始，是因为它和这个列表中的其余项有很大的不同。这一项对单一的服务器并不重要，但是如果你有许多系统，这一项就至关重要了。Puppet或Chef这样的配置管理工具允许你编写‘recipes’来定义服务器应该如何的被放置在一起。那些‘recipes’可以在每个服务器上运行产生一个一致的、容易复制的安装程序。这可以让你立即启动一个系统的新拷贝，可以给你的安装提供极大的自由度。   配置管理是做了，但是，却给服务器安装程序添加了一定的初始化复杂性，所以如果你胆子小，不用也罢。不过，即使只有两个或三个服务器，好处也是相当巨大的。   备份   这一项是显而易见的，大多数的系统管理员都会在这方面做点工作的。如果你没有一个可靠的备份策略，你现在需要马上调整它。哪怕只等一天，后果很可能就是是灾难性的。同时请确保你正确的做了备份，因为备份很容易做错。Mozy，Carbonite，Backblaze等工具的At-home备份已经取得了很大的进展，但是类似的Linux解决方案还远没有成熟。Rsync ，tar，和类似的脚本工具一直很受欢迎，并且也是可行的替代方案，但是必须要小心，以适应像MySQL数据库那样的特殊情况。每个人的备份需求是不同的，所以无论你选择什么解决方案也要仔细研究它潜在的不足。你选择的解决方案应该：   ◆定期运行 ◆保持多轮的备份 ◆自动的删除旧的备份 ◆在你的现在的操作系统以外存储备份 ◆保持和你的原始数据一样的安全性 ◆合并所有的关键数据，关键的配置文件（更换服务器以后启动和运行系统可能会需要的任何东西），和最近的日志   测试你的备份   紧跟着备份计划的是测试它。这意味着定期检查备份是否一直在做，产生的文件是否是有效的并且是否没有被损坏，以及他们是否包括你需要的所有数据。一个好的经验法则是如果你的备份每30天一轮换，那么你应该经常的重新检查他们。这里自动化工具可以帮一些忙（自动地检查备份文件是否是最新的，是否是合理的大小并且是否有效）。尽管如此，没有任何东西可以替代人的眼睛……否则，当你发现你并没有备份那些你认为你已经备份的数据时，就只有哭的份了。   日志轮换   在最近几年，Ubuntu，RedHat和其他主要的发行版针对他们提供的软件包的logrotate的运行和配置有了很大的改善。所以你的apache和mysql日志也可以被合适的轮换（默认设置是相当合理的，虽然可能并不是你希望的方式）。但是你添加的“额外”的东西，例如Rails应用程序，需要建立它自己的logrotate条目。缺少这个步骤会在最不合适的时刻引发无数的“硬盘驱动器已满”的服务器错误。当然，通常你甚至不知道你的日志引发了这个问题。针对这种情况，资源监视才是关键。   资源监视   跟踪CPU，内存的使用情况，硬盘空间，带宽，等可以让你更好的洞察你的系统状态。当流量增加的时候，你可以比较你的增加的内存或IO使用情况，来提前规划你的“scaling”。RRDTool/Munin，ServerDensity和Cloudkick是观察这些随着时间的推移而变化的数据的很好的选择。如果你选择的工具包括对意外的变化（失控的进程，驱动器已满等）的警报功能，你将会领先任何潜在的问题一步。   进程监视   对你的网站来说，让你的Apache，MySQL和类似的进程一直处于运行状态至关重要。有几个很好的工具，例如Monit和God，可以帮助你确保你的进程一直处于运行状态。通过检查进程的响应性，打开的端口，或进程id那些工具可以重新启动一个已死的服务或在一个失控的进程使你的整个系统崩溃前终止它。配置这件事的规则是个老大难问题，但是当一切都做好的时候，可以节省大量的凌晨3点钟的宕机时间。   安全加固（Hardening）   Hardening包含了许多不同的操作，这些操作可以使你的stock系统更安全。许多简单的操作经常会被遗漏。你真的知道那些正在运行的进程中的每一个都做了什么吗？在你的系统上，哪些额外的端口和服务被打开了？有合适的PAM模块载入来进行安全认证吗？又一次，RedHat和Ubuntu走在了时代的前列，他们提供了安全stock系统，并确保最常见的软件包遵守正确的安全协议。但是，这并不意味着你可以跳过这个步骤。   安全更新   在一个基于apt或RPM的系统上，安全更新是很容易执行的。这个过程的陷阱是很难知道升级包是否会在你的栈里引发某些类型的错误。为了确切知道升级包将对你的系统产生怎样的影响，拥有一台同样配置的模拟服务器是唯一的好办法。幸运的是，由安全更新引发的麻烦是十分罕见的。修复一个更新的兼容性问题，需要花费一些停机时间，这个风险要比你的系统上的一个已知安全漏洞被利用的风险小很多。所以，不要让“not knowing”阻止你进行正确的升级。最后，不是每一个安全漏洞都能马上获得一个安装补丁。查看CVE字典上的可用警报，可以让你在补丁可用前，在保持你的系统安全性方面争取主动。为了确保一切都平滑的运行并保持最新，在这方面真的没有什么可以代替人的肉眼。   日志监视/安全扫描/入侵检测   这个列表中的所有项都是最低限度需要完成的。它们很容易被忘记，直到你的系统已经被入侵为止，你可能都不会想起它们。对异常活动，黑客攻击和其他恶意行为的持续扫描，对于帮助阻止或减轻攻击来说，是十分重要的。   这当然不是一个完整的列表，但是它也是十分广泛的，许多开发者和系统管理员只是没有时间、兴趣或知识来处理它们。更糟糕的是，许多开发项目被移交给了客户，而一旦技术团队迁移到另一个项目上，这些客户就没有能处理这些事情的职员了。","title":"系统管理员应该定期完成的九件事"},{"content":"　　说到数据库，我认为不能不先谈数据结构。1996年，在我初入大学学习计算机编程时，当时的老师就告诉我们说：计算机程序＝数据结构＋算法。尽管现在的程序开发已由面向过程为主逐步过渡到面向对象为主，但我还是深深赞同8年前老师的告诉我们的公式：计算机程序＝数据结构＋算法。面向对象的程序开发，要做的第一件事就是，先分析整个程序中需处理的数据，从中提取出抽象模板，以这个抽象模板设计类，再在其中逐步添加处理其数据的函数(即算法)，最后，再给类中的数据成员和函数划分访问权限，从而实现封装。 　　数据库的最初雏形据说源自美国一个奶牛场的记账薄(纸质的，由此可见，数据库并不一定是存储在电脑里的数据^_^)，里面记录的是该奶牛场的收支账目，程序员在将其整理、录入到电脑中时从中受到启发。当按照规定好的数据结构所采集到的数据量大到一定程度后，出于程序执行效率的考虑，程序员将其中的检索、更新维护等功能分离出来，做成单独调用的模块，这个模块后来就慢慢发展、演变成现在我们所接触到的数据库管理系统(DBMS)——程序开发中的一个重要分支。 　　下面进入正题，首先按我个人所接触过的程序给数据库设计人员的功底分一下类： 　　１、没有系统学习过数据结构的程序员。这类程序员的作品往往只是他们的即兴玩具，他们往往习惯只设计有限的几个表，实现某类功能的数据全部塞在一个表中，各表之间几乎毫无关联。网上不少的免费管理软件都是这样的东西，当程序功能有限，数据量不多的时候，其程序运行起来没有什么问题，但是如果用其管理比较重要的数据，风险性非常大。 　　２、系统学习过数据结构，但是还没有开发过对程序效率要求比较高的管理软件的程序员。这类人多半刚从学校毕业不久，他们在设计数据库表结构时，严格按照教科书上的规定，死扣E-R图和3NF(别灰心，所有的数据库设计高手都是从这一步开始的)。他们的作品，对于一般的access型轻量级的管理软件，已经够用。但是一旦该系统需要添加新功能，原有的数据库表差不多得进行大换血。 　　３、第二类程序员，在经历过数次程序效率的提升，以及功能升级的折腾后，终于升级成为数据库设计的老鸟，第一类程序员眼中的高人。这类程序员可以胜任二十个表以上的中型商业数据管理系统的开发工作。他们知道该在什么样的情况下保留一定的冗余数据来提高程序效率，而且其设计的数据库可拓展性较好，当用户需要添加新功能时，原有数据库表只需做少量修改即可。 　　４、在经历过上十个类似数据库管理软件的重复设计后，第三类程序员中坚持下来没有转行，而是希望从中找出“偷懒”窍门的有心人会慢慢觉悟，从而完成量变到质变的转换。他们所设计的数据库表结构有一定的远见，能够预测到未来功能升级所需要的数据，从而预先留下伏笔。这类程序员目前大多晋级成数据挖掘方面的高级软件开发人员。 　　５、第三类程序员或第四类程序员，在对现有的各家数据库管理系统的原理和开发都有一定的钻研后，要么在其基础上进行二次开发，要么自行开发一套有自主版权的通用数据库管理系统。 　　我个人正处于第三类的末期，所以下面所列出的一些设计技巧只适合第二类和部分第三类数据库设计人员。同时，由于我很少碰到有兴趣在这方面深钻下去的同行，所以文中难免出现错误和遗漏，在此先行声明，欢迎大家指正，不要藏私哦8) 　　一、树型关系的数据表 　　不少程序员在进行数据库设计的时候都遇到过树型关系的数据，例如常见的类别表，即一个大类，下面有若干个子类，某些子类又有子类这样的情况。当类别不确定，用户希望可以在任意类别下添加新的子类，或者删除某个类别和其下的所有子类，而且预计以后其数量会逐步增长，此时我们就会考虑用一个数据表来保存这些数据。按照教科书上的教导，第二类程序员大概会设计出类似这样的数据表结构： 类别表_1(Type_table_1) 名称　　　　　类型　　　　约束条件　　　说明 type_id   　        int    　            无重复　　     类别标识，主键 type_name　   char(50)         不允许为空     类型名称，不允许重复 type_father        int                   不允许为空     该类别的父类别标识，如果是顶节点的话设定为某个唯一值 　　这样的设计短小精悍，完全满足3NF，而且可以满足用户的所有要求。是不是这样就行呢？答案是NO！Why？ 　　我们来估计一下用户希望如何罗列出这个表的数据的。对用户而言，他当然期望按他所设定的层次关系一次罗列出所有的类别，例如这样： 总类别 　　类别1 　　　　类别1.1 　　　　　　类别1.1.1 　　　　类别1.2 　　类别2 　　　　类别2.1 　　类别3 　　　　类别3.1 　　　　类别3.2 　　…… 　　看看为了实现这样的列表显示(树的先序遍历)，要对上面的表进行多少次检索？注意，尽管类别1.1.1可能是在类别3.2之后添加的记录，答案仍然是N次。这样的效率对于少量的数据没什么影响，但是日后类型扩充到数十条甚至上百条记录后，单单列一次类型就要检索数十次该表，整个程序的运行效率就不敢恭维了。或许第二类程序员会说，那我再建一个临时数组或临时表，专门保存类型表的先序遍历结果，这样只在第一次运行时检索数十次，再次罗列所有的类型关系时就直接读那个临时数组或临时表就行了。其实，用不着再去分配一块新的内存来保存这些数据，只要对数据表进行一定的扩充，再对添加类型的数量进行一下约束就行了，要完成上面的列表只需一次检索就行了。下面是扩充后的数据表结构： 类别表_2(Type_table_2) 名称　　　　　类型　　　　约束条件　　　                    说明 type_id   　        int     　          无重复　　                   类别标识，主键 type_name　   char(50)        不允许为空                   类型名称，不允许重复 type_father       int                   不允许为空                   该类别的父类别标识，如果是顶节点的话设定为某个唯一值 type_layer        char(6)           限定3层,初始值为000000       类别的先序遍历，主要为减少检索数据库的次数 　　按照这样的表结构，我们来看看上面例子记录在表中的数据是怎样的： type_id      type_name          type_father          type_layer 1             总类别               0                 000000 2             类别1                1                 010000 3             类别1.1              2                 010100 4             类别1.2              2                 010200 5             类别2                1                 020000 6             类别2.1              5                 020100 7             类别3                1                 030000 8             类别3.1              7                 030100 9             类别3.2              7                 030200 10            类别1.1.1            3                 010101 …… 　　现在按type_layer的大小来检索一下：SELECT * FROM Type_table_2 ORDER BY type_layer 列出记录集如下： type_id      type_name          type_father          type_layer 1             总类别               0                 000000 2             类别1                1                 010000 3             类别1.1              2                 010100 10            类别1.1.1            3                 010101 4             类别1.2              2                 010200 5             类别2                1                 020000 6             类别2.1              5                 020100 7             类别3                1                 030000 8             类别3.1              7                 030100 9             类别3.2              7                 030200 …… 　　现在列出的记录顺序正好是先序遍历的结果。在控制显示类别的层次时，只要对type_layer字段中的数值进行判断，每2位一组，如大于0则向右移2个空格。当然，我这个例子中设定的限制条件是最多3层，每层最多可设99个子类别，只要按用户的需求情况修改一下type_layer的长度和位数，即可更改限制层数和子类别数。其实，上面的设计不单单只在类别表中用到，网上某些可按树型列表显示的论坛程序大多采用类似的设计。 　　或许有人认为，Type_table_2中的type_father字段是冗余数据，可以除去。如果这样，在插入、删除某个类别的时候，就得对type_layer 的内容进行比较繁琐的判定，所以我并没有消去type_father字段，这也正符合数据库设计中适当保留冗余数据的来降低程序复杂度的原则，后面我会举一个故意增加数据冗余的案例。 　　 　　二、商品信息表的设计 　　假设你是一家百货公司电脑部的开发人员，某天老板要求你为公司开发一套网上电子商务平台，该百货公司有数千种商品出售，不过目前仅打算先在网上销售数十种方便运输的商品，当然，以后可能会陆续在该电子商务平台上增加新的商品出售。现在开始进行该平台数据库的商品信息表的设计。每种出售的商品都会有相同的属性，如商品编号，商品名称，商品所属类别，相关信息，供货厂商，内含件数，库存，进货价，销售价，优惠价。你很快就设计出4个表：商品类型表(Wares_type)，供货厂商表(Wares_PRovider)，商品信息表(Wares_info)： 商品类型表(Wares_type) 名称　　　　　类型　　　　约束条件　　　                    说明 type_id   　  int    　   无重复　　                   类别标识，主键 type_name　　 char(50)    不允许为空                   类型名称，不允许重复 type_father   int         不允许为空                   该类别的父类别标识，如果是顶节点的话设定为某个唯一值 type_layer    char(6)     限定3层,初始值为000000       类别的先序遍历，主要为减少检索数据库的次数 供货厂商表(Wares_provider) 名称　　　　　类型　　　　约束条件　　　                    说明 provider_id   int    　   无重复　　                   供货商标识，主键 provider_name char(100)   不允许为空                   供货商名称 商品信息表(Wares_info) 名称　　　　  类型　　　　约束条件　　　                    说明 wares_id       int    　  无重复　　                     商品标识，主键 wares_name     char(100)  不允许为空                     商品名称 wares_type　　 int        不允许为空　　　　　　　　　　 商品类型标识，和Wares_type.type_id关联 wares_info     char(200)  允许为空                       相关信息 provider       int        不允许为空                     供货厂商标识，和Wares_provider.provider_id关联 setnum         int        初始值为1                      内含件数，默认为1 stock          int        初始值为0                      库存，默认为0 buy_price      money      不允许为空                     进货价 sell_price     money      不允许为空                     销售价 discount       money      不允许为空                     优惠价 　　你拿着这3个表给老板检查，老板希望能够再添加一个商品图片的字段，不过只有一部分商品有图片。OK，你在商品信息表(Wares_info)中增加了一个haspic的BOOL型字段，然后再建了一个新表——商品图片表(Wares_pic)： 商品图片表(Wares_pic) 名称　　　　  类型　　　　约束条件　　　                    说明 pic_id        int    　   无重复　　                     商品图片标识，主键 wares_id      int         不允许为空                     所属商品标识，和Wares_info.wares_id关联 pic_address　 char(200)   不允许为空　　　　　　　　　　 图片存放路径 　　程序开发完成后，完全满足老板目前的要求，于是正式启用。一段时间后，老板打算在这套平台上推出新的商品销售，其中，某类商品全部都需添加“长度”的属性。第一轮折腾来了……当然，你按照添加商品图片表的老方法，在商品信息表(Wares_info)中增加了一个haslength的BOOL型字段，又建了一个新表——商品长度表(Wares_length)： 商品长度表(Wares_length) 名称　　　　  类型　　　　约束条件　　　                    说明 length_id     int    　   无重复　　                     商品图片标识，主键 wares_id      int         不允许为空                     所属商品标识，和Wares_info.wares_id关联 length　      char(20)    不允许为空　　　　　　　　　　 商品长度说明 　　刚刚改完没多久，老板又打算上一批新的商品，这次某类商品全部需要添加“宽度”的属性。你咬了咬牙，又照方抓药，添加了商品宽度表(Wares_width)。又过了一段时间，老板新上的商品中有一些需要添加“高度”的属性，你是不是开始觉得你所设计的数据库按照这种方式增长下去，很快就能变成一个迷宫呢？那么，有没有什么办法遏制这种不可预见性，但却类似重复的数据库膨胀呢？我在阅读《敏捷软件开发：原则、模式与实践》中发现作者举过类似的例子：7.3　“Copy”程序。其中，我非常赞同敏捷软件开发这个观点：在最初几乎不进行预先设计，但是一旦需求发生变化，此时作为一名追求卓越的程序员，应该从头审查整个架构设计，在此次修改中设计出能够满足日后类似修改的系统架构。下面是我在需要添加“长度”的属性时所提供的修改方案： 　　去掉商品信息表(Wares_info)中的haspic字段，添加商品额外属性表(Wares_ex_property)和商品额外信息表(Wares_ex_info)2个表来完成添加新属性的功能。 商品额外属性表(Wares_ex_property) 名称　　　　  类型　　　　约束条件　　　                    说明 ex_pid        int    　   无重复　　                     商品额外属性标识，主键 p_name        char(20)    不允许为空                     额外属性名称 商品额外信息表(Wares_ex_info) 名称　　　　    类型　　　　约束条件　　　                    说明 ex_iid          int    　   无重复　　                     商品额外信息标识，主键 wares_id        int         不允许为空                     所属商品标识，和Wares_info.wares_id关联 property_id　   int         不允许为空　　　　　　　　　　 商品额外属性标识，和Wares_ex_property.ex_pid关联 property_value  char(200)   不允许为空                     商品额外属性值 　　在商品额外属性表(Wares_ex_property)中添加2条记录： ex_pid            p_name 1                商品图片 2                商品长度 　　再在整个电子商务平台的后台管理功能中追加一项商品额外属性管理的功能，以后添加新的商品时出现新的属性，只需利用该功能往商品额外属性表(Wares_ex_property)中添加一条记录即可。不要害怕变化，被第一颗子弹击中并不是坏事，坏的是被相同轨道飞来的第二颗、第三颗子弹击中。第一颗子弹来得越早，所受的伤越重，之后的抵抗力也越强8)(待续)","title":"【转】浅谈数据库设计技巧(上)——ps：对于现在的我来说，很经典，很精妙！"},{"content":"在软卓班的第一个小系统.其实在软卓跟其他软件班一样嘛,哎照样上课,我又没参与到老师的项目.... 当真是从0开始啊,在项目开始的时候才发现,原来自己的.net的知识真的是0,,,囧..自己花在这一方面的时间太少了..哎..一开始就准备各种资料,首先就是三层架构...orz,,最基础的东西我花了一天时间去看网上的各种资料,,最后竟然在自己的Asp.net的书最后一个项目看到有这一方面较系统的知识..真是想吐血了.网上的资料也许比较直接,但是就是不够系统..然后是代码了,三层架构理解了小部分,代码基本上可以动了.但是我勒个去,,叫自己小组的人画数据库,,但是光顾着LOL就是不会和我们这边的人交流,,搞的写出来的数据库真是那个不敢恭维,,真是够\"简朴的\"!!!所以小组的WM同学又得重建数据库..虽然也 简朴但是能用就行了,我的要求并不高-_-...代码开始写了,,从底层开始写了 一开始就是数据访问层部分(DAL,IDAL),一开始还不会用微软带的helper类,,囧..所以写的连接数据库的部分真是又长又臭,就是建立一个连接字符串,然后建立sqlserver语句来当做命令对象..用helper类好简单啊,一开始我的代码就是这样:  #region 得到已发布所有新闻        public static DataSet GetUserNewsListByUserID(string userID)        {            string connectionString = ConfigurationManager.ConnectionStrings[\"PubsConnectionString\"].ToString();            //ConfigurationManage            using (SqlConnection dbConnection = new SqlConnection(connectionString))            {                dbConnection.Open();                string queryString = \"Select _title,_content,_userName from dbo.News where _userID=@userID  order by _date DESC\";                SqlCommand dbCommand = new SqlCommand();                dbCommand.Connection = dbConnection;                dbCommand.CommandType = CommandType.Text;                dbCommand.CommandText = queryString;                //userID参数                SqlParameter dbParameter_userID = new SqlParameter();                dbParameter_userID.ParameterName = \"@userID\";                dbParameter_userID.Value = userID;                dbParameter_userID.DbType = DbType.StringFixedLength;                dbCommand.Parameters.Add(dbParameter_userID);                //运行sqlserver命令                SqlDataAdapter dataAdapter = new SqlDataAdapter(dbCommand);                DataSet ds = new DataSet();                dataAdapter.Fill(ds);                return ds;            }        }        #endregion   但是何必呢?这样太麻烦了.. 后来回头翻老师的课件,,囧..于是看到了sqlhelper类的用法.. /// <summary>        /// 根据用户ID，得到用户已发布的新闻列表        /// <\/summary>        /// <param name=\"userID\">用户ID<\/param>        /// <returns>用户已发布的新闻列表<\/returns>        public List<NewsModel> GetUserNewsListByUserName(string userName)//返回类型很重要,这样子就可以用对象的思想了        {            //创建新闻对象列表            List<NewsModel> userNewsList = new List<NewsModel>();            //选择dbo.Table_News中该用户已发布新闻的标题、作者、发布日期            string sql = \"select top 10 NewsID, Title,UserName,Date from dbo.Table_News where UserName=@userName  order by Date desc\";            SqlParameter[] param = new SqlParameter[1]{               // new SqlParameter(\"@userName\",\"@password\", userName,password)               //必须的注意了:这个@UserName是数据库的字段,而上面的@userName是中间变量                new SqlParameter(\"@UserName\", userName)                        };            SqlDataReader res = sqlhelper.ExecuteReader(sql, CommandType.Text, param);            //获取新闻对象            while (res.Read())            {                //创建新闻对象                NewsModel news = new NewsModel();                //给新闻对象属性赋值                //使用SqlDataReader的GetOrdinal（）方法，获得列的序号，输入参数为列名                //从reader中拿出相对应的列并且赋值于model身上.那就OK了,呵呵                news.NewsID = res.GetInt32(res.GetOrdinal(\"NewsID\"));                news.Title = res.GetString(res.GetOrdinal(\"Title\"));                news.UserName = res.GetString(res.GetOrdinal(\"UserName\"));                news.Date = res.GetDateTime(res.GetOrdinal(\"Date\"));                //将新闻添加到列表中                userNewsList.Add(news);            }            return userNewsList;        }   一开始我还没有把参数加载到sqlparameter当中的,囧.现在还只是知道怎么用,具体运行机制还不是很清楚.囧. 这是一个关键的代码之处.也是我碰到的一个小坎. 接下来嘛就是书写业务逻辑层BLL的代码了,呵呵,如果DLL的代码写好了,我一开始用的是DataSet这样的返回类型(这样高深的做法),但是回头在一个博客里面见到,用泛型list是现在最流行的啊.DataSet的是以前的写法..呃,,我这小菜鸟,还没怎么认识.不过因为c++,所以对list 还算熟,那么就用泛型吧.后来知道gridview竟然一般是可以接收list的类型文章的,好不管了.想到这里整个项目基本上就成功了,能连上gridview可能对大牛;来说就是切菜,但是对于我这个0开始的小菜,竟然摸索了那么久,真心惭愧. 写到这,还是回头讲一下自己的三层架构吧,毕竟自己辛辛苦苦的搜了一天,榨出来的小结就只有短短几句话:数据访问层嘛就是主要是从数据库中取数据,存数据.关键的数据库访问代码就是在这里写了.然后业务逻辑层嘛:就是负责把客户要求的业务逻辑在表达出来的情况下去访问数据库:说的太抽象了,囧..自我认为就是:从数据库取出来的数据,如果还需要具有一定的逻辑性的话,应该算是传进去的参数就有这个神奇的功能,因为对于数据库来说,谁来取数据他不知道.只有业务逻辑层知道,至于显示层嘛,用户在这里视图上点击能够显示出来的业务效果在显示层的设计代码出现了,对于这我也有点疑惑是占了业务逻辑层的工作.但是在网上有反驳的话没看懂. 除了IDLL,DLL,IBLL,IBLL.还有建立了工厂.建立工厂的效果是 namespace NewsPublish.Factory{    public static class DALFactory    {        public static IUserDAL CreateUserDAL()        {            return new UserDAL();        }        public static INewsDAL CreateNewsDAL()        {            return new NewsDAL();        }    }} 比如在BLL层就要通过DAL比如在BLL层就要通过DAL工厂来建立DAL的实例,如此便可在BLL层调用DAL层的数据了: 下面这句话就是这个作用: namespace NewsPublish.BLL {     public class NewsBLL : INewsBLL     {         INewsDAL _newsDAL = Factory.DALFactory.CreateNewsDAL();//开始BLL之前建立了DAL对象便于引用DAL的方法 建立工厂的好处是直接有一个对象会自动被生成就可以了,我们不必管它是怎么生成的. 下面的BLL层的工厂,在显示层的设计代码中会被引用生成对象.   namespace NewsPublish.Factory{    public class BLLFactory    {        public static IUserBLL CreatUserBLL()        {            return new UserBLL();        }        public static INewsBLL CreateNewsBLL()        {            return new NewsBLL();        }    }} 说了这些,感觉关键代码都说得差不多了..但是显示层gridview我却还没搞定.哎,老师上课演示走神,这是对我的惩罚延迟到了作为那一天(父类)的这一天(子类).. 显示层算是请了班上熟练的好手来帮忙了: 首先看看这个gridview吧: 普通的一个gridview: 然后看看前台gridview的属性以及后台gridview的代码: <asp:GridView ID=\"GridView1\" runat=\"server\" AutoGenerateColumns=\"False\" Height=\"599px\" Width=\"800px\" OnSelectedIndexChanged=\"GridView1_SelectedIndexChanged\">                <Columns>                    <asp:HyperLinkField DataNavigateUrlFields=\"NewsID\" DataNavigateUrlFormatString=\"~/newscontent.aspx ? NewsID={0}\" DataTextField=\"Title\" HeaderText=\"标题\" NavigateUrl=\"~/newscontent.aspx\"/>                                                   <asp:BoundField HeaderText=\"作者\" DataField=\"UserName\" />                    <asp:BoundField HeaderText=\"发布时间\" DataField=\"Date\" />                    <asp:BoundField DataField=\"NewsID\" HeaderText=\"NewsID\" Visible=\"False\" />                <\/Columns>            <\/asp:GridView>   首先是第一列,列名是标题,然后数据绑定是数据库中 \"Title\"!!这是个超链接,然后需要传参数进去,所以就需要?NewsID,并且注明跳转到某一特定页面. 然后第二列是直接写在DIV上面的(不是很清楚,猜的),列名是作者,绑定的数据在数据库中是 \"Date\",以此类推.   再看看后台代码是怎么连接gridview和BLL层的. public partial class WebForm2 : System.Web.UI.Page    {        INewsBLL _iBLL;        protected void Page_Load(object sender, EventArgs e)        {            {                _iBLL = BLLFactory.CreateNewsBLL();//通过BLL接口创建一个BLL对象实例                GridView1.DataSource = _iBLL.GetAllNewsList();//绑定数据源,BLL层函数返回类型是List的.                GridView1.DataBind();//调用绑定,也就是已进入这个页面的数据就会绑定好,并且出现            }        }        protected void GridView1_SelectedIndexChanged(object sender, EventArgs e)        {        }    } 说到这也差不多了,最后剩下一项就是页面跳转吧,在调试的时候出现了问题,一开始使用: 那么最后一项就讲一下页面跳转吧:   也就是有上面这一个发布新闻页面跳转到下面已发布新闻列表这个页面:   下面看看跳转的后台代码:           protected void Button1_Click(object sender, EventArgs e)        {            string title = Txt_Title.Text.ToString();            string publisher = Txt_Publish.Text.ToString();            if (true)//判断如果发布人不是用户名,则不能发布,此功能暂没实现            {            }            string content = Txt_Content.Text.ToString();            DateTime date = DateTime.Now;            bool tmp = _newsBLL.PublishNews(title, date, publisher, content);            //暂时假定发布一定成功,所以利马跳转到已发布新闻页面            Session[\"userName\"] = publisher;            Response.Redirect(\"personnel.aspx\");        }   一开始直接在Response加了?和参数的这种类型,调试过不去,同学LX后来改用Session这种方法就可以了,囧. 好,下面看接受方的后台代码: public partial class personnel : System.Web.UI.Page    {        INewsBLL _newsBLL = NewsPublish.Factory.BLLFactory.CreateNewsBLL();        protected void Page_Load(object sender, EventArgs e)        {           // string userName = Request.QueryString[\"userName\"].ToString();            string userName = Session[\"userName\"].ToString();            GridView1.DataSource = _newsBLL.GetUserNewsListByUserName(userName);            GridView1.DataBind();                               }        protected void GridView1_SelectedIndexChanged(object sender, EventArgs e)        {            string userName = Request.QueryString[\"userName\"].ToString();            //DataTable dt=new DataTable();            //dt=_newsBLL.GetUserNewsListByUserID(userName);            GridView1.DataSource = _newsBLL.GetUserNewsListByUserName(userName);            GridView1.DataBind();        }    } 搞不清楚一开始的Response+Request竟然调试不过去群殴就晕了..这里的绑定跟上面的雷同.. 整个项目的代码差不多就是这样了.但可恶的老师说这只是第一阶段的需求; 还有第二阶段,第三阶段在后面等着呢?哎,我的Acm时间,我的考研时间,orz...但还是必须后续,, 因为虽然能花的时间不多,但是就是不能让别人小看了.... 加油,加油,muxi加油!!!","title":"小菜Asp.net第一个班级小组小项目 第一阶段需求的 新闻发布系统 小结"},{"content":"今天刚好有空,于是就思考了一些事情,熟话说'吾日三省吾身',初中老师就教导我们要每天睡觉前来个反思!这个idea不错!   现在大三了,以前看了很多的帖子,也经历了一些事情,看到了很多人迷茫ing,无助ing!不知道来了大学该怎么度过,该怎么学习,起初我来到大学也是如此一切都是如此的新鲜,强烈的好奇感充满心头,我也像同志们一样迷茫过,无助过,也曾经为自己选择计算机这个要学的知识浩如烟海的专业而烦恼过,无措过,慌乱过.但是由于选择这个专业既是处于偶然也是处于兴趣选择的吧!所以即使经常听到各种学习的消极声音但是我依然像高中的孩子们一样的保持着学习习惯,每天上课,下课,自习!学习的步调简直和高中没有多大的差别,大学强调的是自主学习而高中是有人天天管着你的,所有大学更多的是自由支配的时间,而我自己也是出于家里的压力在拼命学习,那时我抱着的态度是自己认认真真学了就好!在一味的学习积累知识!逛各大编程论坛技术社区等等。   那时的学习自主性还是可以的,但是我那时依然是迷茫的,因为我根本不知道将来得到的会是什么结果,我也不清楚自己想要的到底是什么,所以到了大二有时在学习上会有种消极的情绪,因为经过接近一年的学习,认知和了解,我几乎快被这个庞大的知识群给压垮因为要学的太多,到图书馆逛一圈发现,这个要学,那个想学,结果抱着一大摞书回去,不但没看完,还身心俱疲,甚至影响学习了,反而得不偿失!本文我想分享的是自主学习能力所以还是回归正文上来,以上只是分享下自己的学习感受,想表达的意思是我们学计算机的同学,在计算机这个行业要学的挺多,我们经常会迷茫,我总结的就是:我们任何时候还是不要把重心偏移了,既然要上大学，我们学习的重心仍然是上课学习的知识,因为那是我们以后发展的本钱,是基础!现在在计算机行业出现了很多的培训机构!而大学与培训机构的不同之处在于我们学习的重点方向不同,培训机构一般都在短短的半年甚至几个月就可以出来找工作干活了,他们学习到的知识是具有很强的针对性的,学习的知识没有系统性,完整性,如果他们仅仅学的是培训机构的那些知识我想他们的发展空间也不会很大吧!而我们的优势在于我们有系统的完整性的知识,在以后就职方面如果我们肯下功夫我们上升的机会很快,但是所有的这些前提就是我们要认认真真踏踏实实把大学的知识都学好,这是我们的本钱!   所有要学好大学的知识而重要的一方面就是要有一定的自主学习能力,就如大多数同学已经知道的大学不像高中有人管着你，大学给你的就是(在大的规则上面的)自由,所有你有充分的支配权.而或许正是由于这个原因有些同学茫然了,不知道干什么了,变的手忙脚乱了!从而迷失了自我!所以这就需要我们要自主要给自己安排事情去做,自己得认真思考并规划着,想想我要的是什么？如此等等!鉴于我身边的一些低年级同学以我个人经历总结一下仅供借鉴:   (1)要有清晰的头脑,冷静对待,不要急于追求一时的兴趣!而把自己的精力都投放其中.这样反而得不偿失!   我和其他同学一样经常对高科技的东西很好奇觉得很神奇,于是我们花大把的时间去研究学习,然而就在我们知道了其所有然之后,我又叹息了,因为我发现了其实这并不神奇,这些个东西要弄出来其实并不难,所需要的知识也比较简单!而反过头来想想我失去了什么？我失去的是大把的时间学习基础知识,以至根基不牢,大厦何以稳？   (2)我们要学会用自己的学习方式去解决问题-培养自己的自主学习方式   和许多的同学交流时,有时很多问题其实挺头疼的,当然是大多刚进来的低年级同学,碰到了问题无论难易劈头问过来就是,其实大家会发现问题其实很简单,关键在于你去发现了没有！你思考过了没有!殊不知其实就在于你这一次次你想都没想过的问题当中,你的自主意识变的淡薄,在慢慢丧失.当然你解决问题的能力也在下降!   (3)选择了就要认真对待,不要做都没做,就回复对方-I can't;   相信很多同学参加过社团等类似的组织.细心的同学会发现其实真正笑道最后的是那些'主动请战'的同学,他们有很强的自主能力,他们会主动的去领任务,甚至在没事干的时候会考虑同样的事情如何干的更好!这就是区别.同样的我们学习也是如此,很多事情,尤其是计算机知识学习方面!即使领导给你的任务你根本没学过,没见过(其实这种事常有)就叫你去做,一般的同学可能就会望而却步了，或者说没自信,没头绪,但是归结的说,还是没自主学习能力。即使这个问题经过你的努力之后仍然不会那又是另外一回事了,关键就在于做与没做的区别!   (4)扩充知识,多方学习! 保持兴趣,激发斗志。但得-宁专勿杂,杂而学无力   在学习的过程中我们难免会有点烦躁,无味!我们可以选择一个兴趣点,参与其中,这样在我们学习乏味没有斗志时,我们可以凭着这股兴趣做点东西出来,这样我们的斗志又有了,就更有利于我们学习了,而且了解了一块知识!总之保持学习激情的方式很多我们可以找到适合自己的方式即可!   (5)懂得交流,相互学习   有时我们会发现,在我们解决问题的过程中,我们会常常碰到一个问题很棘手,始终不得正解。这时我们就要学会去讨教了,学会和别人去沟通了,这时你会发现别人的一个点子就会给以你莫大的启示和帮助,从而顺利的解决了问题!然而学会正确的沟通作用不光于此,沟通其作用体现在很多的方面,例如团队协作,一个好的团队应该是沟通自然的，这样才会利于工作的顺利进行.   另外大学计算机专业几门课比较重要的例如数据结构,操作系统,数据库,计算机网络等最近也看到过国内IT大头HR的招聘其实那些公司更看重的是基础知识,例如最近听百度HR培训其中就明确了要有扎实的算法,操作系统知识,当然每个企业研发的产品不同要求也不同,只是说有些基础东西咋得认真学学!   以上只是有感而发,希望彼此相互交流,如有不当,忘大家多探讨交流学习经验!","title":"自主学习,理性学习"},{"content":"一、操作数据库  1、查看数据库          show databases [ like ''];          示例：          mysql> show databases;          +--------------------+          | Database           |          +--------------------+          | information_schema |          | luomian            |          | mydb               |          | mysql              |          | net80576314        |          | phpcms_uat         |          | phpcmsv9           |          | phpcmsv9_new       |          | rutiao             |          | szwalkers          |          | test               |          | v9test1            |          +--------------------+          mysql>  show databases like 'php%';          +-----------------+          | Database (php%) |          +-----------------+          | phpcms_uat      |          | phpcmsv9        |          | phpcmsv9_new    |          +-----------------+  2、创建数据库          create database [if not exists] dbname;          示例：          mysql> create database if not exists mydb;  3、选择需要的数据库          use dbname          示例：          mysql> use mydb;          Database changed  4、删除数据库          drop database [if exists] dbname;          示例：          mysql> drop database if exists mydb;  二、操作表  1、显示表          show tables;          示例：          mysql> show tables;          +-----------------------+          | Tables_in_test        |          +-----------------------+          | newname               |          | productnotes          |          | test_char             |          | test_inn              |          | test_inn2             |          | test_priority         |          | test_trans            |          | test_view             |          +-----------------------+  2、创建表          示例：          mysql> create table user(              -> id   int(10) not null auto_increment primary key,              -> name varchar(50) default 'N/A' not null,              -> sex  char(1) null              -> )engine=InnDB;  3、复制表          示例：          mysql> create table student select * from user;          mysql> create table teacher like user;  4、重命名表          mysql> rename table teacher to senior_teacher;          mysql> alter table student rename to senior_student;  5、删除表          mysql> drop table if exists senior_teacher;  6、查看创建表语句          mysql> show create table student;          +---------+-------------------------------------          | Table   | Create Table          +---------+-------------------------------------          | student | CREATE TABLE `student` (            `id` int(10) NOT NULL DEFAULT '0',            `name` varchar(50) NOT NULL DEFAULT 'N/A',            `sex` char(1) DEFAULT NULL          ) ENGINE=MyISAM DEFAULT CHARSET=latin1 |          +---------+-------------------------------------  7、查看表结构          mysql> desc student;          +-------+-------------+------+-----+---------+-------+          | Field | Type        | Null | Key | Default | Extra |          +-------+-------------+------+-----+---------+-------+          | id    | int(10)     | NO   |     | 0       |       |          | name  | varchar(50) | NO   |     | N/A     |       |          | sex   | char(1)     | YES  |     | NULL    |       |          +-------+-------------+------+-----+---------+-------+  8、修改表结构          mysql> alter table student add bithday date null;          mysql> alter table student modify bithday datetime;          mysql> alter table student change bithday birt datetime;          mysql> alter table student drop column bithday;  9、操作表中的数据          mysql> select * from student;          +----+------+------+---------------------+          | id | name | sex  | birt                |          +----+------+------+---------------------+          |  0 | jack | 1    | 2012-12-13 00:00:00 |          +----+------+------+---------------------+          mysql> insert into senior_student select * from student;          mysql> insert into student(name,sex,birt) values('jack','1',current_date());          mysql> update student set sex = 0 where name = 'jack';          mysql> delete from student where name = 'jack';  10、创建及查看索引          mysql> create index idx_student_name on student(name);           mysql> show index from student;          +---------+------------+------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+          | Table   | Non_unique | Key_name         | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment |          +---------+------------+------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+          | student |          1 | idx_student_name |            1 | name        | A         |        NULL |     NULL | NULL   |      | BTREE      |         |          +---------+------------+------------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+          ","title":"MYSQL入门学习之八：数据库及表的基本操作"},{"content":"说实在前面几章讲自己的经历对大家大家是没撒帮助的，顺便还取了一个骚包点的标题，为什么这么做呢？因为我不是什么名人嘛不会放一个屁都有一堆人来顶，所以只有靠这些不入流的方式吸引大家来看我写的东西，我想凡是一个写博客的人都希望让更多的人来看它写的玩意，不管是不是狗屁不通。          为什么要描述自己的经历，也不是真想让大家羡慕什么，当然还是有点那个意思，更多的还是因为俺不出名，大家都不知道我是那只阿玛阿狗，所以我得证明下我的经历还是值得大家看看的。能不能帮到大家那就不清楚了。         其实我不是个学习很努力的人，但是我是个很有目标感的人，每学一个新的知识我都先明确了我学它是不是有用，能用到什么地方，但就是这样我仍然觉得我学的东西里面正真用上的只有20%，而社会跟学校的不同就在于你学的多不多好不好不重要，关键在于你干的好不好，有些看起来很爱学习的同事最终并没有从学习中获得什么实际的利益，就源于他们没有学到点子上或者知识运用的不是很合理，但这只能靠你自己了，谁都帮不了。那我能帮你什么呢？         我们经常听到要求学习能力强，是因为我们并不需要你很爱学习，我们只要你学的快，学的准，并且能速度上手，这才是学习能力强的标准，希望各位没弄清楚的能够明白这点。         技术是有升级的，相信大家都玩过游戏，游戏里面你等级越高就能学到更高级的技能，你如果只把你的技能点用来升级你的那些基础的技能，那你后期是玩不下去的。技术同样如此以微软技术为例，.NET只是基础的开发入门，很多人都是靠他进入这个行业的，之后就有SharePoint，Silverlight，CRM等等，数据库方面才入门的时候就是SQL SERVER XXXX，然后有TSQL，SSIS，SSAS，SSRS，MDX…，所以你的技术点就是你的学习时间一定要合理安排好啊，前50级（5年）你点出来的东西就决定了你的职业是什么XXX师了，当然还有所谓的一器破万法的说法，不过那太高深是条很难的路。         等级高了你还得有一身好装备，你的装备是什么呢？可以是你这些年来的开发经历，在这里你要把他们很好的包装成你的简历，也可以是你在行业内积累的人脉，所以不妨时常联系下以前熟识的同事。         有时觉得人生真是如游戏，但是社会里的游戏的确比学校里的好玩但是更加危险，学校里打怪只给经验，但是你挂了可以马上原地复活，而在社会里面练级是会有丰硕的收获的，但是不小心挂了你就得掉级从来了。点技能的时候一定要想好这里是没法重置的，贪多是最危险的做法，可能最后谁都不想跟你组队除非你是团长。         总的来说再艰难苦涩的技术你学习和工作三年也能成功技术专家了，所以工作的前3年你转换自己的目标和专业是完全可行的，只要你在第5年毕业的时候能够有拿得出手的成绩。         为什么我老是把1--3，3--5，5--8这几个数字挂在嘴边是因为大部分的企业也是根据这个规则来甄别所要招收的目标人物的经验等级的。         每次对博客的更新其实也是对自己一段时间以来的回顾和总结，最后希望大家越混越好。","title":"我的6年职场人生从月薪800到2万（ 学习的目标感怎么建立）"},{"content":"        在使用数据库的时候，莫名其妙的发现数据库无法插入中文，但可以插入英文，去查了一下，是mysql的字符集被人更改了（由于多人均是用的root账户登录，无法查出是谁更改了数据库的字符集），gbk被更改为了latin。        Mysql的数据库其实一向用的很少。所以也不大知道怎么修改字符集，现将Mysql的数据库字符集的更改写一下。        先贴一个Mysql的官方文档。之后在详细的写下        http://dev.mysql.com/doc/refman/5.1/zh/charset.html#charset-general","title":"Mysql数据库字符集的设置"},{"content":"前言 SQLite (http://www.sqlite.org/docs.html) 是一个轻量级的关系数据库。iOS SDK很早就支持了SQLite，在使用时，只需要加入 libsqlite3.dylib 依赖以及引入 sqlite3.h 头文件即可。但是，原生的SQLite API在使用上相当不友好，在使用时，非常不便。于是，开源社区中就出现了一系列将SQLite API进行封装的库，而FMDB (https://github.com/ccgus/fmdb) 则是开源社区中的优秀者。 FMDB在使用上相当方便。以下是一个简单的例子： 1234567891011 NSString* docsdir = [NSSearchPathForDirectoriesInDomains( NSDocumentDirectory, NSUserDomainMask, YES) lastObject];NSString* dbpath = [docsdir stringByAppendingPathComponent:@\"user.sqlite\"];FMDatabase* db = [FMDatabase databaseWithPath:dbpath];[db open];FMResultSet *rs = [db executeQuery:@\"select * from people\"];while ([rs next]) {    NSLog(@\"%@ %@\",        [rs stringForColumn:@\"firstname\"],        [rs stringForColumn:@\"lastname\"]);}[db close]; 可以看到，使用FMDB后的数据库代码清晰明了，比原生的API优雅多了。另外，FMDB同时兼容ARC和非ARC工程，会自动根据工程配置来调整相关的内存管理代码。 使用说明 该使用说明主要翻译自fmdb的github项目说明文档: https://github.com/ccgus/fmdb 引入相关文件 首先将FMDB从github上clone下来，然后将以下文件copy到你的工程中： 12345678910 FMDatabase.hFMDatabase.mFMDatabaseAdditions.hFMDatabaseAdditions.mFMDatabasePool.hFMDatabasePool.mFMDatabaseQueue.hFMDatabaseQueue.mFMResultSet.hFMResultSet.m 建立数据库 建立数据库只需要如下一行即可,当该文件不存在时，fmdb会自己创建一个。如果你传入的参数是空串：@”” ，则fmdb会在临时文件目录下创建这个数据库，如果你传入的参数是 NULL，则它会建立一个在内存中的数据库。 1 FMDatabase *db = [FMDatabase databaseWithPath:@\"/tmp/tmp.db\"]; 打开数据库 使用如下语句，如果打开失败，可能是权限不足或者资源不足。通常打开完操作操作后，需要调用close方法来关闭数据库。 12345678 if (![db open]) {    // error     return;}// some operation// ...[db close]; 执行更新操作 除了Select操作之外，其它的都是更新操作。更新操作使用如下方法，如果有错误，可以用error参数中获得。 1 -[FMDatabase executeUpdate:error:withArgumentsInArray:orVAList:] 执行查询操作 查询操作示例如下。注意：即使操作结果只有一行，也需要先调用FMResultSet的next方法。 123456789 FMResultSet *s = [db executeQuery:@\"SELECT * FROM myTable\"];while ([s next]) {    //retrieve values for each record}FMResultSet *s = [db executeQuery:@\"SELECT COUNT(*) FROM myTable\"];if ([s next]) {    int totalCount = [s intForColumnIndex:0];} FMDB提供如下多个方法来获取不同类型的数据： 1234567891011 intForColumn:longForColumn:longLongIntForColumn:boolForColumn:doubleForColumn:stringForColumn:dateForColumn:dataForColumn:dataNoCopyForColumn:UTF8StringForColumnIndex:objectForColumn: 通常情况下，你并不需要关闭FMResultSet，因为相关的数据库关闭时，FMResultSet也会被自动关闭。 数据参数 通常情况下，你可以按照标准的SQL语句，用?表示执行语句的参数，如： 1 INSERT INTO myTable VALUES (?, ?, ?) 然后，可以我们可以调用executeUpdate方法来将?所指代的具体参数传入，通常是用变长参数来传递进去的，如下： 12 NSString *sql = @\"insert into User (name, password) values (?, ?)\";[db executeUpdate:sql, user.name, user.password]; 这里需要注意的是，参数必须是NSObject的子类，所以象int,double,bool这种基本类型，需要封装成对应的包装类才行，如下所示： 1234 // 错误，42不能作为参数[db executeUpdate:@\"INSERT INTO myTable VALUES (?)\", 42];// 正确，将42封装成 NSNumber 类[db executeUpdate:@\"INSERT INTO myTable VALUES (?)\", [NSNumber numberWithInt:42]]; 线程安全 如果我们的app需要多线程操作数据库，那么就需要使用FMDatabaseQueue来保证线程安全了。 切记不能在多个线程中共同一个FMDatabase对象并且在多个线程中同时使用，这个类本身不是线程安全的，这样使用会造成数据混乱等问题。 使用FMDatabaseQueue很简单，首先用一个数据库文件地址来初使化FMDatabaseQueue，然后就可以将一个闭包(block)传入inDatabase方法中。 在闭包中操作数据库，而不直接参与FMDatabase的管理。 12345678910111213141516171819202122232425262728 // 创建，最好放在一个单例的类中FMDatabaseQueue *queue = [FMDatabaseQueue databaseQueueWithPath:aPath];// 使用[queue inDatabase:^(FMDatabase *db) {    [db executeUpdate:@\"INSERT INTO myTable VALUES (?)\", [NSNumber numberWithInt:1]];    [db executeUpdate:@\"INSERT INTO myTable VALUES (?)\", [NSNumber numberWithInt:2]];    [db executeUpdate:@\"INSERT INTO myTable VALUES (?)\", [NSNumber numberWithInt:3]];    FMResultSet *rs = [db executeQuery:@\"select * from foo\"];    while ([rs next]) {        // …    }}];// 如果要支持事务[queue inTransaction:^(FMDatabase *db, BOOL *rollback) {    [db executeUpdate:@\"INSERT INTO myTable VALUES (?)\", [NSNumber numberWithInt:1]];    [db executeUpdate:@\"INSERT INTO myTable VALUES (?)\", [NSNumber numberWithInt:2]];    [db executeUpdate:@\"INSERT INTO myTable VALUES (?)\", [NSNumber numberWithInt:3]];    if (whoopsSomethingWrongHappened) {        *rollback = YES;        return;    }    // etc…    [db executeUpdate:@\"INSERT INTO myTable VALUES (?)\", [NSNumber numberWithInt:4]];}]; 工具 为了查看Sqlite中的数据，一个好的图形化界面的数据库管理程序是必不可少的。mysql有phpMyAdmin，那么sqlite呢？ 我主要使用的是Firefox的一个名为SQLite Manager的插件，安装此插件后，可以直接打开后缀名为sqlite的数据库文件。SQLite Manager提供一个图形化的界面来执行数据查询或更改操作。如下图所示： 总结 FMDB将SQLite API进行了很友好的封装，使用上非常方便，对于那些使用纯Sqlite API来进行数据库操作的app，可以考虑将其迁移到基于FMDB上，这对于以后数据库相关功能的开发维护，可以提高不少效率。 我在学习fmdb的时候做了一个小工程用于练习，我把它放到github上了。感兴趣的可以自行下载：https://github.com/tangqiaoboy/FmdbSample 祝大家玩得开心。 转自：http://blog.devtang.com/blog/2012/04/22/use-fmdb/","title":"在iOS开发中使用FMDB"},{"content":"（转载地址：http://www.oracle-base.com/articles/misc/ftp-from-plsql.php）   FTP From PL/SQL Sometimes it's preferable to trigger FTP jobs directly from PL/SQL rather than rely on CRON or AT. This article contains a brief description of the two methods I use. Shell Script PL/SQL FTP API ACL for 11g   Shell Script The first method relies on a java stored procedure, described in Shell Commands From PL/SQL, which can be used to trigger a shell script to perform the transfer. The shell script may look like the following. #! /bin/ksh# Move to appropriate directory on local servercd /extracts# FTP all files in directoryftp -inv ftp.company.com <<EOFuser ftpuser ftppassword# Move to appropriate directory on remote server.cd /loadsasciimput *.*byeEOF   PL/SQL FTP API The second approach uses a combination of the UTL_TCP and UTL_FILE packages to create a simple FTP API (ftp.pks, ftp.pkb). Once the API is loaded into the appropriate schema simple FTP commands can be initiated as follows. CREATE OR REPLACE DIRECTORY my_docs AS '/u01/app/oracle/';SET SERVEROUTPUT ON SIZE 1000000@c:\\ftp.pks@c:\\ftp.pkb-- Retrieve an ASCII file from a remote FTP server.DECLARE  l_conn  UTL_TCP.connection;BEGIN  l_conn := ftp.login('ftp.company.com', '21', 'ftpuser', 'ftppassword');  ftp.ascii(p_conn => l_conn);  ftp.get(p_conn      => l_conn,          p_from_file => '/u01/app/oracle/test.txt',          p_to_dir    => 'MY_DOCS',          p_to_file   => 'test_get.txt');  ftp.logout(l_conn);END;/-- Send an ASCII file to a remote FTP server.DECLARE  l_conn  UTL_TCP.connection;BEGIN  l_conn := ftp.login('ftp.company.com', '21', 'ftpuser', 'ftppassword');  ftp.ascii(p_conn => l_conn);  ftp.put(p_conn      => l_conn,          p_from_dir  => 'MY_DOCS',          p_from_file => 'test_get.txt',          p_to_file   => '/u01/app/oracle/test_put.txt');  ftp.logout(l_conn);END;/-- Retrieve a binary file from a remote FTP server.DECLARE  l_conn  UTL_TCP.connection;BEGIN  l_conn := ftp.login('ftp.company.com', '21', 'ftpuser', 'ftppassword');  ftp.binary(p_conn => l_conn);  ftp.get(p_conn      => l_conn,          p_from_file => '/u01/app/oracle/product/9.2.0.1.0/sysman/reporting/gif/jobs.gif',          p_to_dir    => 'MY_DOCS',          p_to_file   => 'jobs_get.gif');  ftp.logout(l_conn);END;/-- Send a binary file to a remote FTP server.DECLARE  l_conn  UTL_TCP.connection;BEGIN  l_conn := ftp.login('ftp.company.com', '21', 'ftpuser', 'ftppassword');  ftp.binary(p_conn => l_conn);  ftp.put(p_conn      => l_conn,          p_from_dir  => 'MY_DOCS',          p_from_file => 'jobs_get.gif',          p_to_file   => '/u01/app/oracle/jobs_put.gif');  ftp.logout(l_conn);END;/-- Get a directory listing from a remote FTP server.DECLARE  l_conn  UTL_TCP.connection;  l_list  ftp.t_string_table;BEGIN  l_conn := ftp.login('ftp.company.com', '21', 'ftpuser', 'ftppassword');  ftp.list(p_conn   => l_conn,           p_dir   => '/u01/app/oracle',           p_list  => l_list);  ftp.logout(l_conn);    IF l_list.COUNT > 0 THEN    FOR i IN l_list.first .. l_list.last LOOP      DBMS_OUTPUT.put_line(i || ': ' || l_list(i));    END LOOP;  END IF;END;/-- Get a directory listing (file names only) from a remote FTP server.DECLARE  l_conn  UTL_TCP.connection;  l_list  ftp.t_string_table;BEGIN  l_conn := ftp.login('ftp.company.com', '21', 'ftpuser', 'ftppassword');  ftp.nlst(p_conn   => l_conn,           p_dir   => '/u01/app/oracle',           p_list  => l_list);  ftp.logout(l_conn);    IF l_list.COUNT > 0 THEN    FOR i IN l_list.first .. l_list.last LOOP      DBMS_OUTPUT.put_line(i || ': ' || l_list(i));    END LOOP;  END IF;END;/-- Rename a file on a remote FTP server.DECLARE  l_conn  UTL_TCP.connection;BEGIN  l_conn := ftp.login('ftp.company.com', '21', 'ftpuser', 'ftppassword');  ftp.rename(p_conn => l_conn,             p_from => '/u01/app/oracle/dba/shutdown',             p_to   => '/u01/app/oracle/dba/shutdown.old');  ftp.logout(l_conn);END;/-- Delete a file on a remote FTP server.DECLARE  l_conn  UTL_TCP.connection;BEGIN  l_conn := ftp.login('ftp.company.com', '21', 'ftpuser', 'ftppassword');  ftp.delete(p_conn => l_conn,             p_file => '/u01/app/oracle/dba/temp.txt');  ftp.logout(l_conn);END;/-- Create a directory on a remote FTP server.DECLARE  l_conn  UTL_TCP.connection;BEGIN  l_conn := ftp.login('ftp.company.com', '21', 'ftpuser', 'ftppassword');  ftp.mkdir(p_conn => l_conn,            p_dir => '/u01/app/oracle/test');  ftp.logout(l_conn);END;/-- Remove a directory from a remote FTP server.DECLARE  l_conn  UTL_TCP.connection;BEGIN  l_conn := ftp.login('ftp.company.com', '21', 'ftpuser', 'ftppassword');  ftp.rmdir(p_conn => l_conn,            p_dir  => '/u01/app/oracle/test');  ftp.logout(l_conn);END;/ The basic functions are implemented using LOBs to allow FTP without having to access files on the local filesystem. The getand put procedures string these together to form a complete job using all the functions. If a straight forward FTP to, or from, the local filesystem is required it is more efficient to use the GET_DIRECT and PUT_DIRECT procedures as they avoid the temporary LOBs. The current implementation has the following issues: The mput and mget operations are not supported directly, but can be implemented using a combination of the list/nlst and get/put operations. The implementation of binary transfers relies on UTL_FILE features only available in Oracle9i Release 2 upwards. There is no support for ASCII mode in the PUT_DIRECT procedure. Thanks to Hans van Doormalen for noticing I wasn't closing my passive connections. I do now :)   ACL for 11g The introduction of Fine-Grained Access to Network Services in Oracle Database 11g Release 1 means you will need to configure an access control list (ACL) to allow UTL_TCP to access the network. The examples above work correctly with the following basic ACL. You will need to amend the FTP server details and username details to match your FTP server address and the Oracle username running the FTP API. DECLARE  l_acl_name         VARCHAR2(30) := 'utl_tcp.xml';  l_ftp_server_ip    VARCHAR2(20) := '192.168.0.131';  l_ftp_server_name  VARCHAR2(20) := 'ftp.company.com';  l_username         VARCHAR2(30) := 'TEST';BEGIN  DBMS_NETWORK_ACL_ADMIN.create_acl (    acl          => l_acl_name,     description  => 'Allow connections using UTL_TCP',    principal    => l_username,    is_grant     => TRUE,     privilege    => 'connect',    start_date   => SYSTIMESTAMP,    end_date     => NULL);  COMMIT;  DBMS_NETWORK_ACL_ADMIN.add_privilege (     acl         => l_acl_name,     principal   => l_username,    is_grant    => FALSE,     privilege   => 'connect',     position    => NULL,     start_date  => NULL,    end_date    => NULL);  COMMIT;  DBMS_NETWORK_ACL_ADMIN.assign_acl (    acl         => l_acl_name,    host        => l_ftp_server_ip,     lower_port  => NULL,    upper_port  => NULL);  DBMS_NETWORK_ACL_ADMIN.assign_acl (    acl         => l_acl_name,    host        => l_ftp_server_name,     lower_port  => NULL,    upper_port  => NULL);  COMMIT;END;/ For more information see: Shell Commands From PL/SQL UTL_FILE Enhancements UTL_TCP UTL_FILE Fine-Grained Access to Network Services in Oracle Database 11g Release 1 Hope this helps. Regards Tim... Back to the Top.  ","title":"（转）FTP From PL/SQL"},{"content":"本文链接：http://blog.pfan.cn/tiay/28128.html 复制链接 [引用：地址不明确了！] --不足：23山东和16山东重复 --创建DBPromary数据库  create database DBPromary use DBPromary go --创建promary表 create table promary (  proID int primary key,  proName varchar(50) not null ) ---------------------------------------------------------------------------------------------------------------------------------------- --中国34个省级行政单位 23个省 5个自治区 4个直辖市 2特别行政区 insert into promary values(1,'北京市') insert into promary values(2,'天津市') insert into promary values(3,'上海市') insert into promary values(4,'重庆市') insert into promary values(5,'河北省') insert into promary values(6,'山西省') insert into promary values(7,'台湾省') insert into promary values(8,'辽宁省') insert into promary values(9,'吉林省') insert into promary values(10,'黑龙江省') insert into promary values(11,'江苏省') insert into promary values(12,'浙江省') insert into promary values(13,'安徽省') insert into promary values(14,'福建省') insert into promary values(15,'江西省') insert into promary values(16,'山东省') insert into promary values(17,'河南省') insert into promary values(18,'湖北省') insert into promary values(19,'湖南省') insert into promary values(20,'广东省') insert into promary values(21,'甘肃省') insert into promary values(22,'四川省') --insert into promary values(23,'山东省') insert into promary values(24,'贵州省') insert into promary values(25,'海南省') insert into promary values(26,'云南省') insert into promary values(27,'青海省') insert into promary values(28,'陕西省') insert into promary values(29,'广西壮族自治区') insert into promary values(30,'西藏自治区') insert into promary values(31,'宁夏回族自治区') insert into promary values(32,'新疆维吾尔自治区') insert into promary values(33,'内蒙古自治区') insert into promary values(34,'澳门特别行政区') insert into promary values(35,'香港特别行政区') ---------------------------------------------------------------------------------------------------------------------------------------- --创建city表 create table city (  cityID int not null,  cityName varchar(50) primary key,  proID int foreign key references promary(proID) ) ---------------------------------------------------------------------------------------------------------------------------------------- --插入各个省的城市数据 --4个直辖市 insert into city values(1,'北京市',1) insert into city values(1,'天津市',2) insert into city values(1,'上海市',3) insert into city values(1,'重庆市',4) --5河北省(2005年辖：11个地级市，36个市辖区、22个县级市、108个县、6个自治县) insert into city values(1,'石家庄市',5) insert into city values(2,'唐山市',5) insert into city values(3,'秦皇岛市',5) insert into city values(4,'邯郸市',5) insert into city values(5,'邢台市',5) insert into city values(6,'保定市',5) insert into city values(7,'张家口市',5) insert into city values(8,'承德市',5) insert into city values(9,'沧州市',5) insert into city values(10,'廊坊市',5) insert into city values(11,'衡水市',5) --6山西省11个城市 insert into city values(1,'太原市',6) insert into city values(2,'大同市',6) insert into city values(3,'阳泉市',6) insert into city values(4,'长治市',6) insert into city values(5,'晋城市',6) insert into city values(6,'朔州市',6) insert into city values(7,'晋中市',6) insert into city values(8,'运城市',6) insert into city values(9,'忻州市',6) insert into city values(10,'临汾市',6) insert into city values(11,'吕梁市',6) --7台湾省(台湾本岛和澎湖共设7市、16县，其中台北市和高雄市为“院辖市”，直属“行政院”，其余属台湾省；市下设区，县下设市（县辖市）、镇、乡，合称区市镇乡。) insert into city values(1,'台北市',7) insert into city values(2,'高雄市',7) insert into city values(3,'基隆市',7) insert into city values(4,'台中市',7) insert into city values(5,'台南市',7) insert into city values(6,'新竹市',7) insert into city values(7,'嘉义市',7) insert into city values(8,'台北县',7) insert into city values(9,'宜兰县',7) insert into city values(10,'桃园县',7) insert into city values(11,'新竹县',7) insert into city values(12,'苗栗县',7) insert into city values(13,'台中县',7) insert into city values(14,'彰化县',7) insert into city values(15,'南投县',7) insert into city values(16,'云林县',7) insert into city values(17,'嘉义县',7) insert into city values(18,'台南县',7) insert into city values(19,'高雄县',7) insert into city values(20,'屏东县',7) insert into city values(21,'澎湖县',7) insert into city values(22,'台东县',7) insert into city values(23,'花莲县',7) --8辽宁省(2006年，辖：14个地级市；56个市辖区、17个县级市、19个县、8个自治县。) insert into city values(1,'沈阳市',8) insert into city values(2,'大连市',8) insert into city values(3,'鞍山市',8) insert into city values(4,'抚顺市',8) insert into city values(5,'本溪市',8) insert into city values(6,'丹东市',8) insert into city values(7,'锦州市',8) insert into city values(8,'营口市',8) insert into city values(9,'阜新市',8) insert into city values(10,'辽阳市',8) insert into city values(11,'盘锦市',8) insert into city values(12,'铁岭市',8) insert into city values(13,'朝阳市',8) insert into city values(14,'葫芦岛市',8) --9吉林省(2006年，辖：8个地级市、1个自治州；20个市辖区、20个县级市、17个县、3个自治县。) insert into city values(1,'长春市',9) insert into city values(2,'吉林市',9) insert into city values(3,'四平市',9) insert into city values(4,'辽源市',9) insert into city values(5,'通化市',9) insert into city values(6,'白山市',9) insert into city values(7,'松原市',9) insert into city values(8,'白城市',9) insert into city values(9,'延边朝鲜族自治州',9) --10黑龙江省(2006年，辖：12地级市、1地区；64市辖区、18县级市、45县、1自治县) insert into city values(1,'哈尔滨市',10) insert into city values(2,'齐齐哈尔市',10) insert into city values(3,'鹤 岗 市',10) insert into city values(4,'双鸭山市',10) insert into city values(5,'鸡 西 市',10) insert into city values(6,'大 庆 市',10) insert into city values(7,'伊 春 市',10) insert into city values(8,'牡丹江市',10) insert into city values(9,'佳木斯市',10) insert into city values(10,'七台河市',10) insert into city values(11,'黑 河 市',10) insert into city values(12,'绥 化 市',10) insert into city values(13,'大兴安岭地区',10) --11江苏省(2005年辖：13个地级市；54个市辖区、27个县级市、25个县) insert into city values(1,'南京市',11) insert into city values(2,'无锡市',11) insert into city values(3,'徐州市',11) insert into city values(4,'常州市',11) insert into city values(5,'苏州市',11) insert into city values(6,'南通市',11) insert into city values(7,'连云港市',11) insert into city values(8,'淮安市',11) insert into city values(9,'盐城市',11) insert into city values(10,'扬州市',11) insert into city values(11,'镇江市',11) insert into city values(12,'泰州市',11) insert into city values(13,'宿迁市',11) --12浙江省(2006年，辖：11个地级市；32个市辖区、22个县级市、35个县、1个自治县。) insert into city values(1,'杭州市',12) insert into city values(2,'宁波市',12) insert into city values(3,'温州市',12) insert into city values(4,'嘉兴市',12) insert into city values(5,'湖州市',12) insert into city values(6,'绍兴市',12) insert into city values(7,'金华市',12) insert into city values(8,'衢州市',12) insert into city values(9,'舟山市',12) insert into city values(10,'台州市',12) insert into city values(11,'丽水市',12) --13安徽省(2005年辖：17个地级市；44个市辖区、5县个级市、56个县。) insert into city values(1,'合肥市',13) insert into city values(2,'芜湖市',13) insert into city values(3,'蚌埠市',13) insert into city values(4,'淮南市',13) insert into city values(5,'马鞍山市',13) insert into city values(6,'淮北市',13) insert into city values(7,'铜陵市',13) insert into city values(8,'安庆市',13) insert into city values(9,'黄山市',13) insert into city values(10,'滁州市',13) insert into city values(11,'阜阳市',13) insert into city values(12,'宿州市',13) insert into city values(13,'巢湖市',13) insert into city values(14,'六安市',13) insert into city values(15,'亳州市',13) insert into city values(16,'池州市',13) insert into city values(17,'宣城市',13) --14福建省(2006年辖：9个地级市；26个市辖区、14个县级市、45个县。) insert into city values(1,'福州市',14) insert into city values(2,'厦门市',14) insert into city values(3,'莆田市',14) insert into city values(4,'三明市',14) insert into city values(5,'泉州市',14) insert into city values(6,'漳州市',14) insert into city values(7,'南平市',14) insert into city values(8,'龙岩市',14) insert into city values(9,'宁德市',14) --15江西省(2006年全省辖：11个地级市；19个市辖区、10个县级市、70个县。) insert into city values(1,'南昌市',15) insert into city values(2,'景德镇市',15) insert into city values(3,'萍乡市',15) insert into city values(4,'九江市',15) insert into city values(5,'新余市',15) insert into city values(6,'鹰潭市',15) insert into city values(7,'赣州市',15) insert into city values(8,'吉安市',15) insert into city values(9,'宜春市',15) insert into city values(10,'抚州市',15) insert into city values(11,'上饶市',15) --16山东省(2005年，辖：17个地级市；49个市辖区、31个县级市、60个县。) insert into city values(1,'济南市',16) insert into city values(2,'青岛市',16) insert into city values(3,'淄博市',16) insert into city values(4,'枣庄市',16) insert into city values(5,'东营市',16) insert into city values(6,'烟台市',16) insert into city values(7,'潍坊市',16) insert into city values(8,'济宁市',16) insert into city values(9,'泰安市',16) insert into city values(10,'威海市',16) insert into city values(11,'日照市',16) insert into city values(12,'莱芜市',16) insert into city values(13,'临沂市',16) insert into city values(14,'德州市',16) insert into city values(15,'聊城市',16) insert into city values(16,'滨州市',16) insert into city values(17,'菏泽市',16) --17河南省（2005年辖：17个地级市；50个市辖区、21个县级市、88个县。） insert into city values(1,'郑州市',17) insert into city values(2,'开封市',17) insert into city values(3,'洛阳市',17) insert into city values(4,'平顶山市',17) insert into city values(5,'安阳市',17) insert into city values(6,'鹤壁市',17) insert into city values(7,'新乡市',17) insert into city values(8,'焦作市',17) insert into city values(9,'濮阳市',17) insert into city values(10,'许昌市',17) insert into city values(11,'漯河市',17) insert into city values(12,'三门峡市',17) insert into city values(13,'南阳市',17) insert into city values(14,'商丘市',17) insert into city values(15,'信阳市',17) insert into city values(16,'周口市',17) insert into city values(17,'驻马店市',17) insert into city values(18,'济源市',17) --18湖北省（截至2005年12月31日，全省辖13个地级单位（12个地级市、1个自治州）；102县级单位（38个市辖区、24个县级市、37个县、2个自治县、1个林区），共有1220个乡级单位（277个街道、733个镇、210个乡）。） insert into city values(1,'武汉市',18) insert into city values(2,'黄石市',18) insert into city values(3,'十堰市',18) insert into city values(4,'荆州市',18) insert into city values(5,'宜昌市',18) insert into city values(6,'襄樊市',18) insert into city values(7,'鄂州市',18) insert into city values(8,'荆门市',18) insert into city values(9,'孝感市',18) insert into city values(10,'黄冈市',18) insert into city values(11,'咸宁市',18) insert into city values(12,'随州市',18) insert into city values(13,'仙桃市',18) insert into city values(14,'天门市',18) insert into city values(15,'潜江市',18) insert into city values(16,'神农架林区',18) insert into city values(17,'恩施土家族苗族自治州',18) --19湖南省（2005年辖：13个地级市、1个自治州；34个市辖区、16个县级市、65个县、7个自治县。） insert into city values(1,'长沙市',19) insert into city values(2,'株洲市',19) insert into city values(3,'湘潭市',19) insert into city values(4,'衡阳市',19) insert into city values(5,'邵阳市',19) insert into city values(6,'岳阳市',19) insert into city values(7,'常德市',19) insert into city values(8,'张家界市',19) insert into city values(9,'益阳市',19) insert into city values(10,'郴州市',19) insert into city values(11,'永州市',19) insert into city values(12,'怀化市',19) insert into city values(13,'娄底市',19) insert into city values(14,'湘西土家族苗族自治州',19) --20广东省（截至2005年12月31日，广东省辖：21个地级市，54个市辖区、23个县级市、41个县、3个自治县，429个街道办事处、1145个镇、4个乡、7个民族乡。） insert into city values(1,'广州市',20) insert into city values(2,'深圳市',20) insert into city values(3,'珠海市',20) insert into city values(4,'汕头市',20) insert into city values(5,'韶关市',20) insert into city values(6,'佛山市',20) insert into city values(7,'江门市',20) insert into city values(8,'湛江市',20) insert into city values(9,'茂名市',20) insert into city values(10,'肇庆市',20) insert into city values(11,'惠州市',20) insert into city values(12,'梅州市',20) insert into city values(13,'汕尾市',20) insert into city values(14,'河源市',20) insert into city values(15,'阳江市',20) insert into city values(16,'清远市',20) insert into city values(17,'东莞市',20) insert into city values(18,'中山市',20) insert into city values(19,'潮州市',20) insert into city values(20,'揭阳市',20) insert into city values(21,'云浮市',20) --21甘肃省（2006年辖：12个地级市、2个自治州；17个市辖区、4个县级市、58个县、7个自治县。） insert into city values(1,'兰州市',21) insert into city values(2,'金昌市',21) insert into city values(3,'白银市',21) insert into city values(4,'天水市',21) insert into city values(5,'嘉峪关市',21) insert into city values(6,'武威市',21) insert into city values(7,'张掖市',21) insert into city values(8,'平凉市',21) insert into city values(9,'酒泉市',21) insert into city values(10,'庆阳市',21) insert into city values(11,'定西市',21) insert into city values(12,'陇南市',21) insert into city values(13,'临夏回族自治州',21) insert into city values(14,'甘南藏族自治州',21) --22四川省（2006年辖：18个地级市、3个自治州；43个市辖区、14个县级市、120个县、4个自治县。） insert into city values(1,'成都市',22) insert into city values(2,'自贡市',22) insert into city values(3,'攀枝花市',22) insert into city values(4,'泸州市',22) insert into city values(5,'德阳市',22) insert into city values(6,'绵阳市',22) insert into city values(7,'广元市',22) insert into city values(8,'遂宁市',22) insert into city values(9,'内江市',22) insert into city values(10,'乐山市',22) insert into city values(11,'南充市',22) insert into city values(12,'眉山市',22) insert into city values(13,'宜宾市',22) insert into city values(14,'广安市',22) insert into city values(15,'达州市',22) insert into city values(16,'雅安市',22) insert into city values(17,'巴中市',22) insert into city values(18,'资阳市',22) insert into city values(19,'阿坝藏族羌族自治州',22) insert into city values(20,'甘孜藏族自治州',22) insert into city values(21,'凉山彝族自治州',22) /**//**************************************** --23山东省(2005年，辖：17个地级市；49个市辖区、31个县级市、60个县。) insert into city values(1,'济南市',16) insert into city values(2,'青岛市',16) insert into city values(3,'淄博市',16) insert into city values(4,'枣庄市',16) insert into city values(5,'东营市',16) insert into city values(6,'烟台市',16) insert into city values(7,'潍坊市',16) insert into city values(8,'济宁市',16) insert into city values(9,'泰安市',16) insert into city values(10,'威海市',16) insert into city values(11,'日照市',16) insert into city values(12,'莱芜市',16) insert into city values(13,'临沂市',16) insert into city values(14,'德州市',16) insert into city values(15,'聊城市',16) insert into city values(16,'滨州市',16) insert into city values(17,'菏泽市',16) *************************************/ --24贵州省(2006年辖：4个地级市、2个地区、3个自治州；10个市辖区、9个县级市、56个县、11个自治县、2个特区。) insert into city values(1,'贵阳市',24) insert into city values(2,'六盘水市',24) insert into city values(3,'遵义市',24) insert into city values(4,'安顺市',24) insert into city values(5,'铜仁地区',24) insert into city values(6,'毕节地区',24) insert into city values(7,'黔西南布依族苗族自治州',24) insert into city values(8,'黔东南苗族侗族自治州',24) insert into city values(9,'黔南布依族苗族自治州',24) --25海南省(2003－2005年　全省有2个地级市，6个县级市，4个县，6个民族自治县，4个市辖区，1个办事处（西南中沙群岛办事处，县级）。) insert into city values(1,'海口市',25) insert into city values(2,'三亚市',25) insert into city values(3,'五指山市',25) insert into city values(4,'琼海市',25) insert into city values(5,'儋州市',25) insert into city values(6,'文昌市',25) insert into city values(7,'万宁市',25) insert into city values(8,'东方市',25) insert into city values(9,'澄迈县',25) insert into city values(10,'定安县',25) insert into city values(11,'屯昌县',25) insert into city values(12,'临高县',25) insert into city values(13,'白沙黎族自治县',25) insert into city values(14,'昌江黎族自治县',25) insert into city values(15,'乐东黎族自治县',25) insert into city values(16,'陵水黎族自治县',25) insert into city values(17,'保亭黎族苗族自治县',25) insert into city values(18,'琼中黎族苗族自治县',25) --26云南省(2006年辖：8个地级市、8个自治州；12个市辖区、9个县级市、79个县、29个自治县。) insert into city values(1,'昆明市',26) insert into city values(2,'曲靖市',26) insert into city values(3,'玉溪市',26) insert into city values(4,'保山市',26) insert into city values(5,'昭通市',26) insert into city values(6,'丽江市',26) insert into city values(7,'思茅市',26) insert into city values(8,'临沧市',26) insert into city values(9,'文山壮族苗族自治州',26) insert into city values(10,'红河哈尼族彝族自治州',26) insert into city values(11,'西双版纳傣族自治州',26) insert into city values(12,'楚雄彝族自治州',26) insert into city values(13,'大理白族自治州',26) insert into city values(14,'德宏傣族景颇族自治州',26) insert into city values(15,'怒江傈傈族自治州',26) insert into city values(16,'迪庆藏族自治州',26) --27青海省(2006年辖：1个地级市、1个地区、6个自治州；4个市辖区、2个县级市、30个县、7个自治县。) insert into city values(1,'西宁市',27) insert into city values(2,'海东地区',27) insert into city values(3,'海北藏族自治州',27) insert into city values(4,'黄南藏族自治州',27) insert into city values(5,'海南藏族自治州',27) insert into city values(6,'果洛藏族自治州',27) insert into city values(7,'玉树藏族自治州',27) insert into city values(8,'海西蒙古族藏族自治州',27) --28陕西省(2006年辖：10个地级市；24个市辖区、3个县级市、80个县。) insert into city values(1,'西安市',28) insert into city values(2,'铜川市',28) insert into city values(3,'宝鸡市',28) insert into city values(4,'咸阳市',28) insert into city values(5,'渭南市',28) insert into city values(6,'延安市',28) insert into city values(7,'汉中市',28) insert into city values(8,'榆林市',28) insert into city values(9,'安康市',28) insert into city values(10,'商洛市',28) --29广西壮族自治区(2005年辖：14个地级市；34个市辖区、7个县级市、56个县、12个自治县。) insert into city values(1,'南宁市',29) insert into city values(2,'柳州市',29) insert into city values(3,'桂林市',29) insert into city values(4,'梧州市',29) insert into city values(5,'北海市',29) insert into city values(6,'防城港市',29) insert into city values(7,'钦州市',29) insert into city values(8,'贵港市',29) insert into city values(9,'玉林市',29) insert into city values(10,'百色市',29) insert into city values(11,'贺州市',29) insert into city values(12,'河池市',29) insert into city values(13,'来宾市',29) insert into city values(14,'崇左市',29) --30西藏自治区(2005年辖：1个地级市、6个地区；1个市辖区、1个县级市、71个县。) insert into city values(1,'拉萨市',30) insert into city values(2,'那曲地区',30) insert into city values(3,'昌都地区',30) insert into city values(4,'山南地区',30) insert into city values(5,'日喀则地区',30) insert into city values(6,'阿里地区',30) insert into city values(7,'林芝地区',30) --31宁夏回族自治区 insert into city values(1,'银川市',31) insert into city values(2,'石嘴山市',31) insert into city values(3,'吴忠市',31) insert into city values(4,'固原市',31) insert into city values(5,'中卫市',31) --32新疆维吾尔自治区(2005年辖：2个地级市、7个地区、5个自治州；11个市辖区、20个县级市、62个县、6个自治县) insert into city values(1,'乌鲁木齐市',32) insert into city values(2,'克拉玛依市',32) insert into city values(3,'石河子市　',32) insert into city values(4,'阿拉尔市',32) insert into city values(5,'图木舒克市',32) insert into city values(6,'五家渠市',32) insert into city values(7,'吐鲁番市',32) insert into city values(8,'阿克苏市',32) insert into city values(9,'喀什市',32) insert into city values(10,'哈密市',32) insert into city values(11,'和田市',32) insert into city values(12,'阿图什市',32) insert into city values(13,'库尔勒市',32) insert into city values(14,'昌吉市　',32) insert into city values(15,'阜康市',32) insert into city values(16,'米泉市',32) insert into city values(17,'博乐市',32) insert into city values(18,'伊宁市',32) insert into city values(19,'奎屯市',32) insert into city values(20,'塔城市',32) insert into city values(21,'乌苏市',32) insert into city values(22,'阿勒泰市',32) --33内蒙古自治区(2006年，辖：9个地级市、3个盟；21个市辖区、11个县级市、17个县、49个旗、3个自治旗。) insert into city values(1,'呼和浩特市',33) insert into city values(2,'包头市',33) insert into city values(3,'乌海市',33) insert into city values(4,'赤峰市',33) insert into city values(5,'通辽市',33) insert into city values(6,'鄂尔多斯市',33) insert into city values(7,'呼伦贝尔市',33) insert into city values(8,'巴彦淖尔市',33) insert into city values(9,'乌兰察布市',33) insert into city values(10,'锡林郭勒盟',33) insert into city values(11,'兴安盟',33) insert into city values(12,'阿拉善盟',33) --34澳门特别行政区 insert into city values(1,'澳门特别行政区',34) --35香港特别行政区 insert into city values(1,'香港特别行政区',35) ---------------------------------------------------------------------------------------------------------------------------------------- --查询语句 select * from promary select * from city创建DB.cs实现代码重用 using System; using System.Data.SqlClient; namespace DBPromary ...{     public class DB     ...{         public DB()         ...{             //             // TODO: 在此处添加构造函数逻辑             //         }         public static SqlConnection createConnection()         ...{             SqlConnection con=new SqlConnection(\"server='local';database='DBPromary';user id='**';password='***'\");             return con;         }     } }","title":"全国省市数据库"},{"content":"一、算术运算符 1、加         mysql> select 1+2;         +-----+         | 1+2 |         +-----+         |   3 |         +-----+ 2、减         mysql> select 1-2;         +-----+         | 1-2 |         +-----+         |  -1 |         +-----+ 3、乘         mysql> select 2*3;         +-----+         | 2*3 |         +-----+         |   6 |         +-----+ 4、除         mysql> select 2/3;         +--------+         | 2/3    |         +--------+         | 0.6667 |         +--------+ 5、商         mysql> select 10 DIV 4;         +----------+         | 10 DIV 4 |         +----------+         |        2 |         +----------+ 6、取余         mysql> select 10 MOD 4;         +----------+         | 10 MOD 4 |         +----------+         |        2 |         +----------+ 二、比较运算符 1、等于         mysql> select 2=3;         +-----+         | 2=3 |         +-----+         |   0 |         +-----+         mysql> select NULL = NULL;         +-------------+         | NULL = NULL |         +-------------+         |        NULL |         +-------------+ 2、不等于         mysql> select 2<>3;         +------+         | 2<>3 |         +------+         |    1 |         +------+ 3、安全等于         与“=”的区别在于当两个操作码均为NULL时，其所得值为1而不为NULL，而当一个操作码为NULL时，其所得值为0而不为NULL。         mysql> select 2<=>3;         +-------+         | 2<=>3 |         +-------+         |     0 |         +-------+         mysql> select null=null;         +-----------+         | null=null |         +-----------+         |      NULL |         +-----------+         mysql> select null<=>null;         +-------------+         | null<=>null |         +-------------+         |           1 |         +-------------+ 4、小于         mysql> select 2<3;         +-----+         | 2<3 |         +-----+         |   1 |         +-----+ 5、小于等于         mysql> select 2<=3;         +------+         | 2<=3 |         +------+         |    1 |         +------+ 6、大于         mysql> select 2>3;         +-----+         | 2>3 |         +-----+         |   0 |         +-----+ 7、大于等于         mysql> select 2>=3;         +------+         | 2>=3 |         +------+         |    0 |         +------+ 8、BETWEEN         mysql> select 5 between 1 and 10;         +--------------------+         | 5 between 1 and 10 |         +--------------------+         |                  1 |         +--------------------+ 9、IN         mysql> select 5 in (1,2,3,4,5);         +------------------+         | 5 in (1,2,3,4,5) |         +------------------+         |                1 |         +------------------+ 10、NOT IN         mysql> select 5 not in (1,2,3,4,5);         +----------------------+         | 5 not in (1,2,3,4,5) |         +----------------------+         |                    0 |         +----------------------+ 11、IS NULL         mysql> select null is NULL;         +--------------+         | null is NULL |         +--------------+         |            1 |         +--------------+         mysql> select 'a' is NULL;         +-------------+         | 'a' is NULL |         +-------------+         |           0 |         +-------------+ 12、IS NOT NULL         mysql> select null IS NOT NULL;         +------------------+         | null IS NOT NULL |         +------------------+         |                0 |         +------------------+         mysql> select 'a' IS NOT NULL;         +-----------------+         | 'a' IS NOT NULL |         +-----------------+         |               1 |         +-----------------+ 13、LIKE         mysql> select '12345' like '12%';         +--------------------+         | '12345' like '12%' |         +--------------------+         |                  1 |         +--------------------+         mysql> select '12345' like '12_';         +--------------------+         | '12345' like '12_' |         +--------------------+         |                  0 |         +--------------------+ 14、REGEXP         mysql> select 'beijing' REGEXP 'jing';         +-------------------------+         | 'beijing' REGEXP 'jing' |         +-------------------------+         |                       1 |         +-------------------------+         mysql> select 'beijing' REGEXP 'xi';         +-----------------------+         | 'beijing' REGEXP 'xi' |         +-----------------------+         |                     0 |         +-----------------------+ 三、逻辑运算符 1、与         mysql> select 2 and 0;         +---------+         | 2 and 0 |         +---------+         |       0 |         +---------+         mysql> select 2 and 1;         +---------+         | 2 and 1 |         +---------+         |       1 |         +---------+ 2、或         mysql> select 2 or 0;         +--------+         | 2 or 0 |         +--------+         |      1 |         +--------+         mysql> select 2 or 1;         +--------+         | 2 or 1 |         +--------+         |      1 |         +--------+         mysql> select 0 or 0;         +--------+         | 0 or 0 |         +--------+         |      0 |         +--------+         mysql> select 1 || 0;         +--------+         | 1 || 0 |         +--------+         |      1 |         +--------+ 3、非         mysql> select not 1;         +-------+         | not 1 |         +-------+         |     0 |         +-------+         mysql> select !0;         +----+         | !0 |         +----+         |  1 |         +----+ 4、异或         mysql> select 1 xor 1;         +---------+         | 1 xor 1 |         +---------+         |       0 |         +---------+         mysql> select 0 xor 0;         +---------+         | 0 xor 0 |         +---------+         |       0 |         +---------+         mysql> select 1 xor 0;         +---------+         | 1 xor 0 |         +---------+         |       1 |         +---------+         mysql> select null or 1;         +-----------+         | null or 1 |         +-----------+         |         1 |         +-----------+         mysql> select 1 ^ 0;         +-------+         | 1 ^ 0 |         +-------+         |     1 |         +-------+ 四、位运算符 1、按位与         mysql> select 3&5;         +-----+         | 3&5 |         +-----+         |   1 |         +-----+ 2、按位或         mysql> select 3|5;         +-----+         | 3|5 |         +-----+         |   7 |         +-----+ 3、按位异或         mysql> select 3^5;         +-----+         | 3^5 |         +-----+         |   6 |         +-----+ 4、按位取反         +----------------------+         | ~3                   |         +----------------------+         | 18446744073709551612 |         +----------------------+         mysql> select ~18446744073709551612;         +-----------------------+         | ~18446744073709551612 |         +-----------------------+         |                     3 |         +-----------------------+ 5、按位右移         mysql> select 3>>1;         +------+         | 3>>1 |         +------+         |    1 |         +------+ 6、按位左移         mysql> select 3<<1;         +------+         | 3<<1 |         +------+         |    6 |         +------+ 五、运算符优先级顺序         最高优先级 :=         1 ||, OR, XOR         2 &&, AND         3 BETWEEN, CASE, WHEN, THEN, ELSE         4 =, <=>, >=, >, <=, <, <>, !=, IS, LIKE, REGEXP, IN         5 |         6 &         7 <<, >>         8 -, +         9 *, /, DIV, %, MOD         10 ^         11 - (unary minus), ~ (unary bit inversion)         12 !, NOT         最低优先级 BINARY, COLLATE","title":"MYSQL入门学习之六：MYSQL的运算符"},{"content":"删除表格:drop table [表名]; 插入语句:当我们插入信息时,出现缺少select语句时,我们要写完整的插入语句:insert into [表名](列)values(值);","title":"Oracle常用语法,练习中发现的薄弱语法。"},{"content":"             这几天在做JSP最后大作业时遇到一个小编程问题，值得反思很多。               问题：MySql数据库操作              测试执行时问题报这样的错 ：com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '?,?)' at line 1            一开始以为是版本问题，上网查了一些也多热指版本问题（问题原因不一样，提示一样），然后换了几个包，还是不行。最后步步排除实在找不到了，随便点了几个函数声明，原来错是这样的：PreparedStatement类中有execute（）方法，是无参数的，其父类Statement也有execute（str）但是为有参数的。去了上图中sql参数就可以运行了。         是这种很错误，基础很不扎实。看了看一些网页，也有类似的错误。除了错误本身外，发现了很多要去反醒的。        一开始在机房做的时候老师给的例子就是上述用法，大家都遇到了这个问题。但是也有些同学没有这个问题。老师下来调了两次，也没有找到解决方法。自己就想：额，这个问题不是我自己编程的问题，等老师去解决吧。犯错一：完全依靠他人。         自己做的时候，也不去管那个问题，觉得这是只是学期终的考查案例，老师不会去细查的，就拖。错误二：对自己不负责。 编程学技术这本身就要求很强的自学能力，有问题为不应该完全依赖别人。解决问题的本身就是一个学习过程，没有问题的编程有吗？完全指望别人去解决问题的，能走多远？         大学了，什么事要对自己负责，这就大三了，更是要对自己的一切学会负责：有问题就要去解决，不能逃避。否则的话，就要享受“被动负责”。         牢记：要会自学，对自己负责。","title":"[置顶] 问题总结error in your SQL syntax"},{"content":"  sqlcode sqlstate 说明 000 00000 SQL语句成功完成   01xxx SQL语句成功完成，但是有警告 +012 01545 未限定的列名被解释为一个有相互关系的引用 +098 01568 动态SQL语句用分号结束 +100 02000 没有找到满足SQL语句的行 +110 01561 用DATA CAPTURE定义的表的更新操作不能发送到原来的子系统 +111 01590 为2型索引设置了SUBPAGES语句 +117 01525 要插入的值的个数不等于被插入表的列数 +162 01514 指定的表空间被置为检查挂起状态 +203 01552 使用非唯一的名字来解决命名的限定列 +204 01532 命名的对象未在DB2中定义 +206 01533 命名的列不在SQL语句中指定的任何表中存在 +218 01537 因为SQL语句引用一个远程对象，不能为该SQL语句执行EXPLAIN +219 01532 命名的PLAN TABLE不存在 +220 01546 不正确定义PLAN TABLE，检查命名列的定义 +236 01005 SQLDA中的SQLN的值至少应于所描述的列的个数一样大 +237 01594 至少有一个被描述的列应该是单值类型，因此扩展的SQLVAR条目需要另外的空间 +238 01005 至少应有一个被描述的列是一个LOB，因此扩展的SQLVAR条目需要另外的空间 +239 01005 至少应有一个被描述的列应是单值类型，因此扩展的SQLVAR条目需要另外的空间 +304 01515 该值不能被分配给宿主变量，因为该值不再数据类型的范围之内 +331 01520 不能被翻译的字符串，因此被设置为NULL +339 01569 由于与DB2 2.2版本的子系统连接，所以可能存在字符转换问题 +394 01629 使用优化提示来选择访问路径 +395 01628 设置了无效的优化提示，原因代码指定了为什么，忽略优化提示 +402 01521 未知的位置 +403 01522 本地不存在CREAT ALIAS对象 +434 01608 在DB2未来发布的版本中将不支持指定的特性，IBM建议你停止使用这些特性 +445 01004 值被CAST函数截取 +462 01Hxx 由用户定义的函数或存储过程发出的警告 +464 01609 命名的存储过程超出了它可能返回的查询结果集的个数限制 +466 01610 指定由命名的存储过程返回的查询结果集的个数。成功完成 +494 01614 由存储过程返回的结果集的个数超过了由ASSOCIATE LOCATORS语句指定的结果集定位器的个数 +495 01616 因为倒台SQL的成本估算超出了在ELST中指定的警告阀值，所以发出警告 +535 01591 请求一个主健的定位更新，或请求一个使用自我引出 约束的表的删除操作 +541 01543 命名外健是一个重复的引用约束 +551 01548 命名的授权ID缺少在命名的DB2对象上执行命名操作的权限 +552 01542 命名的授权ID缺少执行命名操作的权限 +558 01516 已经被授权该PUBLIC，因此WITH GRANT OPTION不可用 +561 01523 对ALTER REFERENCES INDEX 和TRIGGER特权，PUBLIC AT ALL LOCATION无效 +562 01560 因为GRANTEE已经拥有这些特权，所以一个或更多的特权被忽略 +585 01625 模式名指定了不止一次 +599 01596 没有为长字符数据类型（BLOB，CLOB和DBCLOB）建立比较函数 +610 01566 由于建立了一个指定为DEFER YES的索引，指定的对象处于PENDING状态，或者因为使用了ALTER INDEX改变关键值的范围，所以指定的对象处于PENDING状态 +625 01518 因为删除了主健索引，所以表定义被标注为不完整 +626 01529 删除了加强UNIQUE约束的索引，唯一性不在被加强 +645 01528 因为建立的索引中没有包含NULL，所以WHERE NOT NULL被忽略 +650 01538 不能更改或者建立已命名的表为从属表 +653 01551 在已指定的分区表空间中尚没有建立指定的分区索引，所以分区索引不可得 +655 01597 为CREATE或ALTER STOGROUP语句指定特定或者非特定的卷ID，在DB2较新发布的版本中（版本6以后）将不再支持他们 +658 01600 当建立目录索引时，不能指定SUBPAGES语句，SUBPAGES将被忽略，并缺省为1 +664 01540 分区索引的限制关键字超出了最大值 +738 01530 已命名的对象的更改可能像只读系统中对象的改变要求一样 +799 0157 SET语句中引用的特定寄存器不存在，将忽略 SET请求 +802 01519 数据溢出或者因除法异常而引起的数据异常错误 +806 01553 ISOLATION（RR）与LOCKSIZE PAGE 冲突 +807 01554 由于十进制乘法导致溢出 +863 01539 连接成功，但是只支持SBCS +2000 56094 SUBPAGES不等于1的1型索引不能成为数据共享环境中的缓冲池组依赖者 +2002 01624 因为指定的缓冲池不允许超高速缓存，GNPCACHE指定被忽略 +2007 01602 因为DB2子系统的参数禁用“提示(hiats）”所以不能指定优化提示 +30100 01558 分布式协议错误被检测到，提供原来的SQLCODE和SQLSTATE -007 42601 SQL语句中由非法字符 -010 42603 字符串常量非正常终止；检查到有遗漏的引号标志 -029 42601 需要INTO语句 -060 42815 某特定数据类型的长度或者标量规范无效 -084 42612 不能执行SQL语句，因为该语句对动态SQL无效或者对OS/390的DB2无效 -097 42601 在单位类型、用户自定义的函数以及过程中不能使用带有CAST的LONG VARCHAR或LONGVARGRAPHIC -101 54001 SQL语句超出了已确定的DB2限制：例如，表的数目太多，语句中的字节太多 -102 54002 字符串常量太长 -103 42604 无效数学文字 -104 42601 SQL语句中遇到非法符号 -105 42604 无效的字符串格式；通常引用一个格式不正确的图形字符串 -107 42622 对象名太长 -108 42601 RENAME语句中指定的名字有错误，不能使用限定词 -109 42601 指定了无效语句；例如CREATE VIEW不能包含ORDER BY 语句 -110 42606 遇到了无效的十六进制的文字 -111 42901 指定的列函数没有给出列名 -112 42607 无效的列函数语法；列函数不能运行与其他的列函数之上 -113 42602 遇到无效字符 -114 42961 该语句的位置名称必须与当前服务器匹配，但是却没有匹配 -115 42601 因为比较运算符没有伴着一个表达式或者列表，遇到了无效谓词 -117 42802 待插入的数值的个数于被插入的行中的列数不相等 -118 42902 数据修改语句(UPDATE或DELETE）和FROM语句中的表和视图命名不合法 -119 42803 HAVING语句中的列的列表与GROUP BY语句中的列列表不匹配 -120 42903 不允许WHERE语句、SET语句、VALUES语句或者SET ASSIGNMENT语句引用列函数 -121 42701 在INSERT或UPDATE语句中，某一列被非法引用了两次 -122 42803 非法使用了列函数。因为没有用于一个列函数的所有列不再GROUP BY语句中 -123 42601 特定位置的参数必须是一个常数或者一个关键词 -125 42805 ORDER BY语句中指定了无效数字，该数字要么小于1要么大于选定的列数 -126 42829 不能为一个UPDATE语句指定ORDER BY语句 -127 42905 在子选择中DISTINCT只能指定一次 -128 42601 SQL谓词中NULL使用不当 -129 54004 SQL语句中包含的表多于15个 -130 22019 ESCAPE语句必须为一个字符   22025 无效的ESCAPE模式 -131 42818 LIKE谓词只能用于字符数据 -132 42824 LIKE语句、ESCAPE语句、LOCATE函数或POSSTR函数中有无效运算对象 -133 42906 无效相关子查询引用 -134 42907 大于255字节的列被不正确使用 -136 54005 排序关键字的长度大于4000字节 -137 54006 被连接的字符串太大；字符的最大值为32767；图形的最大值为16382 -138 22011 SUBSTR列函数的第二个或第三个操作符无效 -142 42612 不支持的SQL语句。该语句可能在另外的RDBMS上有效，也有可能在其他的上下文中有效（例如，VALUES只能在触发器中出现） -144 58003 指定的段号无效 -147 42809 某一源函数不能更改。要改变源函数，必须删除该源函数并重新建立他 -148 42809 RENAME和ALTER无法执行。RENAME不能对视图或者活动RI.ST表重新命名。ALTER不能用于改变列的长度，因为该列参与了RI、一个用户退出程序、全局的临时表或打开DATACAPTURE CHANGES表的列 -150 42807 触发活动的INSERT，UPDATE或DELETE语句中指定了无效的视图更新或一个无效的转换表 -151 42808 试图更新一个不可更新的视图的列、一个DB2 CATALOG表的列或者一个ROWID列 -152 42809 DROP CHECK试图删除一个参照约束，或者DROP FOREIGN试图删除一个检查约束 -153 42908 无效的视图建立请求，必须为旋转列表中列出的列出的未命名的列或者重复的列提供一个名字 -154 42909 不能用UNION、UNION ALL或者一个远程表建立视图 -156 42809 在视图上建立索引是非法的，或者在ALTER TABLE，CREATE TRIGGER，DROP TABLE或LOCK TABLE语句上指定一个不是表的其他对象这是无效的 -157 42810 必须在FOREIGN KEY语句中指定一个表名 -158 42811 视图的列和选择列表中的列不相匹配 -159 42089 无效DROP或COMMENT ON语句 -160 42813 对该视图的WITH CHECK OPTION无效 -161 44000 正被更新的视图WITH CHECK OPTION语句使得这行不能被插入或更新 -164 42502 用户没有建立这个视图的权限 -170 42605 标量函数指定了无效的参数个数 -171 42815 标量函数指定了无效的数据类型长度或者无效数值 -173 42801 在非只读型的游标上不能指定隔离级别UR -180 22007 DATE、TIME、TIMESTAMP值的字符串表示法的语法不对 -181 22001 不是有效的DATE、TIME、TIMESTAMP值 -182 42816 在算术表达式中的日期/时间值无效 -183 22008 在算术表达式中返回的日期/时间值的结果不在有效值的范围内 -184 42610 没有正确使用日期/时间值的参数标记 -185 57008 没有定义本定的日期/时间出口 -186 22505 改变本定的日期/时间出口引发这个程序的长度无效 -187 22506 MVS返回无效的当前日期/时间 -188 22503 字符串表示无效 -189 22522 指定的编码字符集的ID无效或没有定义 -190 42837 不能象所设定的那样改变（ALTER）列。只能改变（ALTER）VARCHAR列的长度 -191 22504 字符串中包含了无效的混合数据 -197 42877 当两个或多个表被联合在一起排序时，限定的列名不能在ORDER BY语句中使用 -198 42617 试图对空的字符串发布一个PREPARE或EXECUTE IMMEDIATE语句 -199 42601 SQL语句中使用了非法关键词 -203 42702 模糊列引用 -204 42704 没有定义的对象名 -205 42703 指定的表的列名无效 -206 42703 列名没有在FROM语句所引用的任何表中，或者没有在定义触发器所在的表中 -208 42707 不能ORDER BY指定列，应为该列不在选择列表中 -212 42712 指定的表名在触发器中不允许多次使用，只能使用一次 -214 42822 DISTINCT、ORDER BY 引起的无效表达式 -219 42704 因为PLAN_TABLE不存在，EXPLAIN无法执行 -220 55002 遇到无效的PLAN_TABLE列 -221 55002 如果为PLAN_TABLE定义了可供选择的列，那么，必须定义所有的列 -229 42708 指定的现场找不到 -240 428B4 LOCK TABLE语句的PART子句无效 -250 42718 没有定义本地位置名 -251 42602 记号无效 -300 22024 宿主变量或参数中的字符串不是以NULL为终止 -301 42895 无效的宿主变量数据类型 -302 22001 输入的变量值对指定的列无效   22003 输入的变量值对指定的列而言太大 -303 42806 因为数据类型不兼容，不能分配数值 -304 22003 因为数据超出了范围，不能分配数值 -305 22002 没有NULL指示符变量 -309 22512 因为引用的宿主变量被设置成NULL，所以谓词无效 -310 22501 十进制的宿主变量或参数包含非十进制数据 -311 22501 输入的宿主变量长度无效，或者时负值或者太大 -312 42618 没有定义宿主变量或者宿主变量不可用 -313 07001 宿主变量的个数不等于参数标识的个数 -314 42714 模糊的宿主变量引用 -327 22525 在最后分区的关键字范围内，不能插入行 -330 22021 不能成功的翻译字符串 -331 22021 字符串不能分配到宿主变量，因为其不能成功的被翻译 -332 57017 不能为两个命名的编码字符集的ID定义翻译规则 -333 56010 子类型无效导致翻译失败 -338 42972 ON语句无效，必须引用连接的列 -339 56082 访问DB2 2.2版本的子系统被拒绝，原因时ASCII到EBCDIC翻译不能进行 -350 42962 无效的大对象规范 -351 56084 SELECT列表中有不支持的数据类型 -352 56084 输入列表中有不支持的数据类型 -355 42993 LOB列太大，以至不能被记录在日志中 -372 428C1 每个表只允许有一个ROWID列 -390 42887 在上下文中指定的函数无效 -392 42855 自从前一次FETCH以来，指定游标的SQLDA已被不恰当的改变 -396 38505 在最后的访问过程中，视图执行SQL语句 -397 428D3 在某一列上不恰当的指定了GENERATED因为该列不是ROWID数据类型 -398 428D2 为某一个宿主变量请求LOCATOR，但是该宿主变量不是一个LOB -399 22511 在INSERT语句中为ROWID列指定的值无效 -400 54027 在DB2编目中定义的用户自定义索引不能超过100个 -401 42818 算术操作符或比较操作符的操作对象不是兼容的 -402 42819 算术函数不能用于字符或日期时间数据 -404 22001 SQL语句指定的字符串太长 -405 42820 数值文字超出了范围 -406 22003 计算出的或者倒出的数值超出了范围 -407 23502 不能把NULL值插到定义为NOT NULL的列中 -408 42821 数值不能被更新或插入，因为他与列的数据类型不兼容 -409 42607 COUNT函数指定的运算对象无效 -410 42820 浮点文字笔30个字符的最大允许长度长 -411 56040 CURRENT SQLID使用无效 -412 42823 在子查询的选择列表中遇到了多个列 -413 22003 当转换为一个数字型数据类型时，数据溢出 -414 42824 LIKE谓词不能运行于用数字或日期时间类型定义的列 -415 42825 为UNION操作指定的选择列表不是联合兼容的 -416 42907 包含UNION操作符的SQL语句不允许有长的字符串列 -417 42609 两参数标识符作为运算对象被指定在同一谓词的两边 -418 42610 参数标识符使用无效 -419 42911 十进制除法无效 -420 22018 字符串自变量值不符合函数的要求 -421 42826 UNION操作的选择列表中没有提供相同数目的列 -423 0F001 为LOB或结果集定位器指定的值无效 -426 2D528 在不允许更新的应用服务器不允许执行COMMIT语句 -427 2D529 在不允许更新的应用服务器不允许执行ROLLBACK语句 -430 38503 在用户自定义的函数或存储过程中遇到了错误 -433 22001 指定的值太长 -435 428B3 无效的应用定义的SQLSTATE -438 xxxxx 使用了RAISE_ERROR函数的应用发出了一个错误 -440 42884 存储过程或用户自定义函数的参数列表参数个数于预期的个数不匹配 -441 42601 与标量函数一起使用DISTINCT或ALL是不正确的用法 -443 42601 指定的外部函数返回错误的SQLSTATE -444 42724 与被称为存储过程或用户自定义函数有关的程序不能找到 -449 42878 对存储过程或用户自定义的 函数，CREATE或ALTER语句不正确（缺失EXTERNAL NAME 子句) -450 39501 存储过程或用户自定义函数写入存储器的值超过了参数声明的长度 -451 42815 CREATE FUNCTION中指定了不正确的数据类型 -453 42880 用户自定义函数中的RETURNS语句无效 -454 42723 指定的函数识别标记与已存在的另一函数的识别标记冲突 -455 42882 模式名不比配 -456 42710 为用户自定义函数指定的函数名已经存在 -457 42939 用户自定义函数或用户自定义类型正试图使用系统中定义的函数或者类型所用的名称 -458 42883 没有找到函数 -463 39001 特定的外部例程返回无效的SQLSTATE -469 42886 参数定义为OUT或INOUT的CALL语句必须提供宿主变量 -470 39002 指定了NULL参数，但是该例程却不支持NULL -471 55023 存储过程或用户自定义函数失败：提供原因代码 -472 24517 外部的函数程序使游标处于打开状态 -473 42918 用户自定义数据类型命名不能和系统定义的数据类型一样 -475 42866 结果类型不能被转换成RETURNS类型 -476 42725 在其模式中该函数不是独一无二的 -478 42893 不能DROP或REVOKE特定的对象，因为其他对象依赖于该对象 -480 51030 直到存储过程已经被CALL后，DESCRIBE PROCEDURE和ASSOCIATE LOCATORS才能被发布 -482 51030 存储过程不返回到任何一个定位器 -483 42885 CREATE FUNCTION语句中的参数个数与源函数中的参数个数不匹配 -487 38001 选择了NO SQL选项建立指定的存储过程或用户自定义函数，但却视图发布SQL语句 -491 42601 CREATE FUNCTION语句无效，因为该语句没有RETURNS语句或者因为该语句没有指定有效的SOURCE或者EXTERNAL语句 -492 42879 指定函数的指定参数的个数有错误 -495 57051 语句的估计处理器成本超出了资源限制 -496 51033 语句无法执行，因为当前服务器与调用存储过程的服务器不同 -497 54041 指定的数据库超过了32767 OBID的上限，或者CREATE DATABASE语句使之达到了32511DBID的上限 -499 24516 指定的游标已被分配到结果集，该结果集来自已经指定的存储过程 -500 24501 因为连接被破坏，WITH HOLD游标被关闭 -501 24501 在试图获取数据或关闭一个游标前必须打开一个游标 -502 24502 在没有关闭游标前不能再次打开游标 -503 42912 因为列在游标的FOR UPDATE OF语句中没有被指定，该游标用于获取该列，所以不能更新该列 -504 34000 不能引用一个游标，因为他不是定义到程序里的 -507 24501 在试图更新或者删除WHERE CURRENT OF前，必须打开游标 -508 24504 因为被引用的游标当前不是处于数据行上，所以不能被更新或删除 -509 42827 除了在游标上指定的那个表（该表由WHERE CURRENT OF语句引用的）以外，再也不能从别的表上更新数据 -510 42828 表或视图不能被修改 -511 42829 对不可修改的表或视图，FOR UPDATE OF语句无效 -512 56023 对远程对象的无效引用 -513 42924 一个别名不能再被定义成另外的别名 -514 26501 游标尚没有被准备 -516 26501 试图描述未准备好的SQL语句 -517 07005 因为SQL语句尚没有准备好，游标无效 -518 07003 试图执行尚没有准备好的SQL语句 -519 24506 当为游标的SQL语句发布一个准备语句是，游标不能是打开的 -525 51015 不能在已指定的程序包中执行SQL语句，因为在绑定时间内该程序包无效 -526 42995 在给定的上下文中，不能使用全局的临时表 -530 23503 对特定的约束名指定了无效的外健值 -531 23504 从版本5开始，父关键字的多行更新将试图删除一个外关键字依赖的父关键字值，在版本5以前，当引用主关键值外健值当前存在时，试图更新该主健值 -532 23504 删除操作违反了已指定的参照约束 -533 21501 多行插入无效，试图将多行插到自我引用的表中 -534 21502 可改变主健列值的更新语句不能在同一时刻用于更新多行 -535 21502 当从自我引用表中删除数据或者更新主健列时，不能指定WHERE CURRENT OF。不是版本5的子系统才调用该代码 -536 42914 因为某一特定表的参照约束存在，所以删除语句无效 -537 42709 在外健语句或主健语句的规范中，每个列的出现不能多于一次 -538 42830 无效的外健；不符合引用的表没有主健 -539 42888 不能定义外健，因为被引用的表没有主健 -540 57001 表定义不完整，直到为主健建立了唯一索引或UNIQUE语句、或者包含GENERATED BYDEFAULT属性的ROWID列 -542 42831 可以为空的列不允许作为主健的一部分包含在内 -543 23511 因为该表是指定了SET NULL删除规则的参照约束的父表而且检查约束不允许NULL，所以DELETE不能发生 -544 23512 不能用ALTER添加检查约束，因为已存在的某行与该检查约束冲突 -545 23513 INSERT或者UPDATE导致检查约束冲突 -546 42621 在CREATE或ALTER TABLE中指定的检查约束无效 -548 42621 因为指定的列而引起的检查约束无效 -549 42509 DYNAMICRULES（BIND）计划或程序包的无效SQL语句 -551 42501 用户试图对不拥有权限的特定的对象进行操作，或者表不存在 -552 42502 用户试图执行未被授权的操作 -553 42503 不能指定CURRENT SQLID，因为用户尚没有被允许改变那个ID -554 42502 不能对你本身赋予一个权限 -555 42502 不能对你本身撤销一个权限 -556 42504 不能撤销用户没有拥有的权限 -557 42852 指定了不一致的授予或撤销关键词 -558 56025 为授予或撤销语句指定了无效的语句（一个或一组） -559 57002 DB2权限机制已经禁用，授予或者撤销不能被发布 -567 42501 指定的权限ID缺少对指定的程序包的绑定权限 -571 25000 不允许多点更新 -573 42890 不能定义参照约束，因为已指定的父表中在指定的列上没有唯一健 -574 42864 指定的缺省与列定义冲突 -577 38002 试图修改用户自定义函数中的数据或者存储过程中的数据，但这些对象的建立没有选择MODIFIES SQL DATA选项 -579 38004 试图修改用户自定义函数中的数据或者存储过程中的数据，但这些对象的建立没有选择READ SQL DATA选项，也没有选择MODIFIES SQL DATA选项 -580 42625 CASE表达式中的结果表达式不能都是空的 -581 42804 CASE表达式中的结果表达式为不兼容的数据类型 -582 42625 SEARCHED－WHEN－CLAUSE中的查找条件指定了一个限定的、IN或EXISTS谓词 -583 42845 指定的函数失败，因为他不是决定性的，或者可能有外部动作 -585 42732 在当前路径中模式名不止一次出现 -586 42907 CURRENT PATH专用寄存器在长度上不能超过254字符 -587 428C6 项目引用的列表必须是同一个家族 -590 42734 在命名的存储过程或用户自定义的函数中的参数必须是独一无二的 -592 42510 没有授权权限，让你在WLM环境中建立的存储过程或者用户自定义函数 -601 42710 试图创建（或重命名）已经存在的对象 -602 54008 CREATE INDEX语句中指定的列太多 -603 23515 因为发现有重复值，所以不能建立唯一的索引 -604 42611 在CREATE或ALTER TABLE语句中的为数据类型指定的长度、精度以及标度无效 -607 42832 指定的INSERT、UPDATE或DELETE语句不能被发布，应为这些语句对DB2 CATLOG表执行写操作 -611 53088 当LOCKSIZE是TABLE或者TABLESPACE时，LOCKMAX必须为0 -612 42711 在同一个表、索引或试图中不允许有重复列名 -613 54008 主健或UNIQUE约束太长或者包含了太多的列 -614 54008 已经超过了索引的内部健长度的最大长度（255）限制 -615 55006 不能删除这个程序包，因为该程序包目前正在执行 -616 42893 指定的对象不能被删除，因为其他对象依赖于该对象 -617 56089 对于DB2版本6，1型索引无效。对于以前的版本，1型索引不能用LOCKSIZE ROW或LARGE表空间定义 -618 42832 对DB2 CATALOG表的请求操作时不允许的 -619 55011 DSNDB07不能修改，除非他先被停止了 -620 53001 对在DSNDB07中的表空间不允许指定该关键词 -621 58001 遇到了重复的DBID，遇到了系统问题 -622 56031 不能指定FOR MIXED DATA因为没有安装混合数据选项 -623 55012 不能为单一的表定义多个族索引 -624 42889 不能为单一的表定义多个主健 -625 55014 用主健定义的表要求唯一索引 -626 55015 不能发布ALTER语句来改变PRIQTY SECQTY或ERASE，除非先停止了表空间 -627 55016 不能发布ALTER语句来改变PRIQTY SECQTY或ERASE，除非先把表空间定义为使用存储器组的表空间 -628 42613 指定语句时相互排斥的（例如，不能分区一个分段的表空间） -629 42834 因为该外健不能包含空值，所以SET NULL无效 -630 56089 不能为1型索引指定WHERE NOT NULL -631 54008 无效的外健；要么是比254个字节长，要么包含的列数多于40 -632 42915 指定的删除规则禁止把这个表定义为已制定表的从属表 -633 42915 无效删除规则；必须使用特定的强制删除规则 -634 42915 在这种情况下，DELETE CASCADE不允许 -635 42915 删除规则不能有差异或者不能为SET NULL -636 56016 在分区索引健的升序或降序规范中，分区所以必须与该规范一致 -637 42614 遇到重复的关键词 -638 42601 在CREATE TABLE语句中缺少列定义 -639 56027 带有SET NULL的删除规则的外健的可空列不能是分区索引的列 -640 56089 不能为这个表空间指定LOCKSIZE ROW，因为在该表空间中的表上定义了1型索引 -642 54021 唯一约束包含太多的列 -643 54024 检查约束超出了3800个字符的最大长度 -644 42615 在SQL语句中为关键词指定的值无效 -646 55017 在指定的分区表空间或者缺省表空间中不能创建表，因为指定的表空间已经包含了一个表 -647 57003 指定的缓冲池无效，因为他没有被激活 -650 56090 ALTER INDEX不能被执行；提供了原因代码 -651 54025 如果CREARE或ALTER TABLE被允许，表对象的描述词（object descriptor,OBD）将超过最大值（32KB） -652 23506 遇到了EDITRPROC或VALIDPROC冲突 -653 57004 在分区表空间中的表不可用，因为分区索引尚未被创建 -655 56036 在卷的列表中，STOGROUP不能指定为特定的或不特定（“*”）的卷 -658 42917 当试图删除指定的对象时，无法删除该对象，该对象的删除必须通过删除与之相关联的对象完成 -660 53035 不正确的分区索引规范，必须为族索引定义有限制的关键字 -661 53036 分区索引没有指定恰当的分区数目 -662 53037 试图在未分区的表空间（分段的或简单的）上建立分区索引 -663 53038 为分区索引指定的关键字限制值是一个无效数字 -665 53039 为ALTER TABLESOACE语句指定了无效的PART语句 -666 57005 SQL语句不能被处理，因为指定的函数当前正处于进行过程中 -667 42917 不能明确的删除分区表空间的族索引，必须除去分区表空间来去掉分区索引 -668 56018 不能向用EDITPROC定义的表中添加列 -669 42917 不能显式的删除分区表空间中的表，必须删除分区表空间来删除表 -670 54010 表的记录长度超过了页面的大小 -671 53040 不能更改指定的表空间的缓冲池，因为这将改变表空间的页面大小 -672 55035 在命名的表上不允许DROP -676 53041 只有4KB的缓冲池可被用于一个索引 -677 57011 缓冲池扩展失败，由于可用的虚拟内存的大小不足 -678 53045 为才分区索引中指定的限制健提供的值与数据类型不符 -679 57006 不能创建某一个特定对象，因为该对象的一个drop目前正在挂起 -680 54011 对DB2表不能超过750列 -681 23507 列违反了指定的FIELDPROC -682 57010 不能载入FIELDPROC -683 42842 列、单值类型、函数或者过程无效，因为不兼容语句。例如，指定的INTEGER具有FORBITDATA选项 -684 54012 指定的文字列表不能超过254个字节 -685 58002 FIELDPROC返回一个无效的域描述 -686 53043 用FIELDPROC定义的一个列不能与一个使用不同的FIELDPROC定义的列作比较 -687 53044 列不能与一个非兼容字段类型的列比较 -688 58002 返回不正确的数据 -689 54011 从属表定义了太多的列 -690 23508 数据定义的控制支持拒绝这个语句 -691 57018 命名的注册表不存在 -692 57018 命名的索引不存在，但命名的注册表需要该索引 -693 55003 命名的注册表/索引的命名列无效 -694 57023 DROP正在命名的注册表上挂起 -696 42898 由于相关的名字或者转换表的名字使用不正确，指定的触发器无效 -697 42899 FOR EACH语句被指定，因此与OLD合NEW相关的名字是不允许的，或者不能为一个BEFORE触发器指定OLD_TABLE和NEW_TABLE -713 42815 指定的专用寄存器是无效的 -715 56064 命名的程序不能被运行，因为他依赖与你所安装的DB2版本的部件，但是你的数据中心没有安装这个部件 -716 56065 命名的程序使用这个版本的不正确的发行版本做了预编译 -717 56066 BIND失败，因为他依赖与你所安装的DB2版本的部件，但是你的数据中心没有安装这个部件 -718 56067 REBIND失败，因为IBMREQD列无效 -719 42710 不能BIND ADD一个已经存在的程序包 -720 42710 不能BIND REPLACE一个已经存在的程序包版本 -721 42710 程序包的一致性记号必须是独一无二的 -722 42704 绑定错误，因为指定的程序包不存在 -723 09000 一个触发的SQL语句接受到一个错误 -724 54038 达到了（16）级联间接的SQL语句的最大项目 -725 42721 对专门指定的寄存器提供了一个无效值 -726 55030 因为SYSPKSYSTEM条目，不能绑定这个程序包 -728 56080 指定的数据类型不能与私有协议发布一起使用 -729 429B1 用COMMIT ON RETURN定义的存储过程不能用作嵌套的CALL过程的目标 -730 56053 在只读的共享数据库中为表定义的参照完整性无效 -731 56054 VSAM数据集必须用SHAREOPTION（1.3）定义 -732 56055 被定义为只读型数据库却拥有没有定义空间或者索引空间的DB2子系统 -733 56056 只读共享数据库的定义不一致 -734 56057 一旦一个数据库被定义为ROSHARE READ，他将不能被更改为其他不同的ROSHARE状态 -735 55004 用DBID名称标识的数据库不再是一个只读共享数据库 -736 53014 命名的DBID无效 -737 53056 在这种状况下，不能建立一个隐含的表空间 -739 56088 因为同时指定了ALLOW PARALLEL和MODIELES SQL DATA这两个语句，因此已设定的函数将不能再被更改 -740 51034 在这种方式下不能用MODIELES SQL DATA定义指定的函数 -741 55030 已经为命名的共享组成员的数据定义了工作文件数据库 -742 53004 DSNDB07是隐含的工作文件数据库 -746 57053 在特定的触发器、存储过程或函数中的SQL语句违反嵌套SQL限制 -747 57054 指定的表是不可用的除非为LOB数据列建立起必须的辅助表 -748 54042 在指定的辅助表上已经有一个索引 -750 42986 不能对已指定的表重新命名,因为他至少在一个现存的视图或触发器中被引用 -751 42987 存储过程或用户自定义的函数试图执行一个不允许执行的SQL语句。DB2的线程被置于MUST_ROLLBACK状态 -752 0A001 无效CONNECT语句 -763 560A1 无效的表空间名 -764 560A2 LOB表空间必须与其相关的基表空间同在一个数据库中 -765 560A3 表和数据库不兼容 -766 560A4 不能对辅助表进行请求的操作 -767 42626 CREATE INDEX失败，因为在辅助表中为索引指定了列，或者因为没有为非辅助表的索引指定列 -768 560A50 不能为指定的列或者指定的分区建立辅助表，因为其辅助表已经存在 -769 53096 CREATE AUX TABLE的规格与基表不匹配 -770 530A6 指定的表必须有一个ROWID列，那么该表才可以包含一个LOB列 -771 428C7 无效的ROWID列规范 -797 42987 CREATE TRIGGER包含不被支持的语法 -798 428C9 不能把一个值插入到用GENERATED ALWAYS定义的ROWID列 -802 22012 某一特定操作发生了异常错误。被零除   22003 某一特定操作发生了异常错误。但不是被零除 -803 23505 不能插入行，因为这将违反唯一索引的约束 -804 07002 SQLDA的调用参数列表有误 -805 51002 在计划中没有发现DBRM或程序包名 -807 23509 对已指定的环境和连接，该程序包不可用 -808 08001 CONECT语句与程序中的第一个CONNECT语句不一致 -811 21000 当多行作为一内嵌的选择语句的返回结果是，必须使用游标 -812 22508 在CURRENT PACKAGESET中的ID集合是空白的，语句不能被执行 -815 42920 在一个内置选择语句或者一个基本谓词的子查询中，显式的或隐含的指定了GROUP BY或HAVING语句 -817 25000 执行SQL语句将可能导致禁止更新用户数据或DB2编目 -818 5103 计划<－>载入组件的时间戳不匹配，在执行计划中没有从同一个预编译中建立DBRM，该预编译是作为组件载入的 -819 58004 视图不能重建，因为在DB2编目中存储的分析树长度为0 -820 58004 在这个DB2版本的DB2编目中遇到了无效值 -822 51004 在SQLDA中遇到了无效地址 -840 54004 在选择列表或插入列表中返回的项目太多 -842 08002 到指定位置的连接已经存在 -843 08003 SET CONNECTION或RELEASE语句无法执行，因为连接不存在 -870 58026 宿主变量描述符的个数不等于语句中宿主变量的个数 -872 51302 这个子系统已指定了有效的CCSID -873 53090 同一SQL语句中，不能同时引用EBCDIC表中的定义的列和ASCII表中定义的列 -874 53901 指定对象的编码方案与其表空间的编码方案不匹配 -875 42988 指定的操作符不能用于ASCII数据 -876 53092 不能为指定的原因创建对象：提供了原因代码 -877 53093 数据库或表空间不允许用ASCII，必须使用EBCDIC -878 53094 该PLAN——TABLE不能是ASCII，必须使用EBCDIC -879 53095 指定对象的CREATE或ALTER语句不能将列、单值类型，某个存储过程或用户自定义函数的参数定义为以下类型：MAXED DATA，GRAPHIC，VARGRAPHIC，LONGVARGRAPHIC，因为系统没有为指定的编码方案定义相应的CCSID -900 08003 应用处理没有连接到应用服务器，语句不能被执行 -901 58004 遇到时断时续的系统错误，该错误不能抑制后继的SQL语句的执行 -902 58005 内部控制块的指针错误，要求重新绑定 -904 57011 指定的资源不可用 -905 57014 超出了资源上限 -906 51005 因为重大错误，SQL语句无法执行 -908 23510 当前资源限制设施的规范或者自动重绑定的系统参数不允许BIND，REBIND，AUTOREBIND -909 57007 对象已被删除 -910 57007 因为在该对象上挂起DROP，所以不能访问该对象 -911 40001 当前工作单元已被回滚 -913 57033 因为死锁或超时导致不成功执行 -917 42969 绑定程序包已经失败 -918 51021 SQL语句不能被执行，因为连接丢失 -919 56045 需要一个ROLLBACK -922 42505 连接权限失败。试图从TSO、CICS或IMS访问DB2，同时相应的连接设施处于非活动的状态 -923 57015 因为DB2不可用，所以不能建立连接 -924 58006 遇到了DB2内部的连接错误：提供了原因代码 -925 2D521 SQL的COMMIT语句不能从CICS或IMS/TM发布 -926 2D521 SQL的ROLLBACK语句不能从CICS或IMS/TM发布 -927 51006 当正在连接的环境没有建立时，语言接口被调用。利用DSN命令激发该程序 -929 58002 数据获取退出已经失败（DPROP） -939 51021 由于远程服务器的未请求的回滚，要求一个回滚 -947 56038 SQL语句失败，因为更新不能被传播（DPROP） -948 56062 DDF没有启动，分布式操作无效 -950 42705 在SQL语句中指定的位置在SYSIBM.LOCATIONS中没有定义 -965 51021 存储过程非正常终止（在DB2 6之前的版本） -981 57015 当前不是处于允许SQL的状态时，试图在RRSAF中执行SQL -991 57015 调用连接不能建立一个到DB2的隐含或开放连接 -2001 53089 为储存过程指定的宿主变量参数的个数不等于预期的参数个数 -20003 560A7 不能为GRECP中的表空间或索引指定GBPCACHE NONE -20004 560A8 对于WORKFILE对象。8KB或16Kb的缓冲池页面大小无效 -20005 54035 指定的对象类型超出了内部的ID极限 -20006 53097 当没有指定WLM环境时，LOB不能被指定为参数 -20070 53098 不能非LOB列建立一个辅助表 -20071 53099 必须指定WLM环境名 -20072 56052 指定的权限ID不拥有在触发器程序包上执行BIND所需的权限 -20073 42927 不能按照指定的要求更改命名的函数，因为在现存的视图定义中引用了该函数 -20074 42939 不能建立指定的对象，因为“SYS”是一个保留的前缀 -20100 56059 在被触发的SQL语句中有BIND错误，指定了错误的SQLCODE和SQLSTATE -20101 56059 由于指定的原因代码，该函数失败 -20102 42849 在CREATE或ALTER FUNCTION语句中不能使用指定的选项 -20104 42856 更改一个CCSID失败 -20106 42945 不能改变表空间或数据库的CCSID，因为现存的试图引用 -30000 58008 DRDA分布协议错误；处理可以继续 -30002 57057 使用DRDA的分布式客户把OPEN语句连接到PREPARE，但PREPARE接受到一个SQLCODE为＋495的警告 -30020 58009 DRDA分布协议错误；对话被解除 -30021 58010 DRDA分布协议错误；处理不能继续 -30030 58013 违反分布协议：COMMIT不成功，对话被解除（AS） -30040 57012 因为不能得到资源，执行失败，处理可以继续（AS） -30041 57013 因为不能得到资源，执行失败，处理不能成功的继续（AS） -30050 58011 执行不成功，在BIND过程中不能执行语句 -30051 58012 特定的BIND过程不是处于活动状态（远程BIND），从而导致失败 -30052 42932 程序准备的假设错误 -30053 42506 程序包的拥有者遭遇授权失败 -30060 08004 RBD遭遇授权失败 -30061 08004 指定了无效或者没有存在的RDB -30070 58014 目标子系统不支持这个命令 -30071 58015 目标子系统不支持这个对象 -30072 58016 目标子系统不支持这个参数 -30073 58017 目标子系统不支持这个参数值 -30074 58018 应答信息不被支持 -30080 08001 SNA通信错误 -30081 58019 TCP/IP通信错误 -30082 08001 由于安全冲突、通信失败：提供了原因代码 -30090 25000 指定的操作对远程执行失败 -30104 56095 在绑定选项与绑定值中有错误 -30105 56096 指定的绑定选项不兼容","title":"DB2错误信息"},{"content":"   来讲讲工资怎么提高，相信大家很关心这个，我就来分享点经验吧。          就拿北京来说吧，纯粹个人观点大家别喷哈，才毕业或有一年经验的能拿到4000--6000就算不错了，三年经验的能拿到8000--10000也是一种成功，五年经验能到12000--15000那也没白混，当然这都是我这工作6年来根据周围人士及自身普及出来的，也有个别混得很好和混得很不靠谱的那都别提了。          这里面有什么讲究呢？我也做过不少人的面试当然都是技术方面的，对于招不同经验需求的人也有自己的一定要求，对于才才毕业和一年工作应验的人一般都他的技术没有多大的要求，真的只要基础好就行了比如会写点SQL，至少知道2008怎么装吧，只要你能表现出足够的兴趣和不是太二的言语在我这都能过，剩下的留给HR和经理去吧，很多时候不是你不行而是候选人和需求数量里面没有你的名额而已，所以别气馁多试几次不断学习，这个行业对于新人来说还是很热情的。           如果你有3年的工作经验了呢，这个时候我至少要求你在某一个技术方面有一定倾向和能力了，不要求你很牛，至少你的有过我们这个职位差不多的经历和技术经验，在这个时候你自少得确认一下你技术的大致方向了吧，你是走微软，安卓，苹果，java，你得有条自己的路了，对于3年的人才你的技术越是有倾向性有目标性那你投出简历被看上的几率越大，举例来讲：如果你说这个时候你要从做Java,转到做.NET我看还是算了，这对你和公司来说都不是一笔好买卖，但是你要说从做前台转到最后太那这个阶段是你最佳的机会。          工作五年是道坎啊，这个时候你的选择要从做技术还是做管理还是做销售上来选择了，IT售前的门槛还是很高的根据不同公司从要求从业经验1年到5年的都有。如果想继续在产品研发本身上干下去，你得想想你是要技术到底还是得偏技术管理（如：PM）方向了，2条路都很难因为不管是管理者还是技术牛人公司的需求都很低，当然后者难度更高些，很多人都在这一步停下，几年难以寸进，从而选择了转销售或者换行，是啊工资不动人心就不稳在我们这个时代更是如此。当然这里提出一个比较容易的方式，那就是你选择一门新兴的技术钻研，能够快速的通过这个阶段，比如当前的移动开发，如果你有经验你就能够快速的在一个新兴项目里面成为领导者，说实在很多人都是这么过来的。          如果你能过了上面难道坎那真是恭喜你了，这几年来你没白混，你在这个行业里面有了所谓的核心竞争力，这为你将来打下了良好的基础。后面怎么办说实在我也不清楚了，大众化道路到此结束以后靠的就不光是努力这么简单了，需要运气，需要天赋还有毅力，不过要告诉你一个好消息的是中国很难有10年以上的技术开发人员，为什么呢？因为这些牛人要不转行或者创业了，要不就去国外跟老外抢饭碗了，所以五年以上经验的你已经是国内某一领域的稀有人才了，也许最后你也会走上前辈的道路，破碎虚空（走出国门）去更广阔的天地转战全世界。你也可以趁这几年存些钱积累些人脉以备以后创业，谁知道呢？","title":"我的6年职场人生从月薪800到2万（工资怎么提高）"},{"content":"写这篇文章也做了下思考，首先是本人技术欠佳。但就是喜欢研究一些东西。因为在此之前有很多的朋友已经写过类似的，很多我也看过，但是讲解的不够深入。对有些朋友提出的问题不能给出答案。在这里，我根据我目前的能力对其进行整理。并最终运行成功。 在测试过程中出现过一下问题： 1、org/springframework/data/mapping/context/MappingContextAware 2、src-resolve: Cannot resolve the name 'repository:repository' to a(n) 'type definition' 以上都是版本不匹配引起的。特别是第二个错误我看有些解决时候提到了jpa，但是我这里没有使用jpa后来我是把spring-data-commons的包替换了个版本就不出现了。 我先说下我的开发环境： myeclipse 6.5 mongodb 2.0.8 spring 3.0.4  最后就是下面2个(这两个版本不对就容易出现各种各样的，杂七杂八的问题) 这里我就给出我所采用的版本 spring-data-document spring-data-commons 有所改变所有版本必须要对应好下面是jar下载地址 http://www.springsource.org/spring-data/mongodb http://www.springsource.org/spring-data/commons 下载版本分别为： spring-data-commons-dist-1.4.0.M1 spring-data-document-1.0.0.M2.zip 下面给出我工程的图片   然后就开始我们开发之旅吧! 首先新建application.xml配置文件 <?xml version=\"1.0\" encoding=\"UTF-8\"?><beans xmlns=\"http://www.springframework.org/schema/beans\"            xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"            xmlns:context=\"http://www.springframework.org/schema/context\"            xmlns:mongo=\"http://www.springframework.org/schema/data/mongo\"            xsi:schemaLocation=\"http://www.springframework.org/schema/context             http://www.springframework.org/schema/context/spring-context-3.0.xsd             http://www.springframework.org/schema/data/mongo             http://www.springframework.org/schema/data/mongo/spring-mongo-1.0.xsd             http://www.springframework.org/schema/beans             http://www.springframework.org/schema/beans/spring-beans-3.0.xsd\">       \t\t<mongo:mongo host=\"192.168.0.138\" port=\"27017\"/>\t\t\t\t\t\t   <bean id=\"mongoTemplate\" class=\"org.springframework.data.document.mongodb.MongoTemplate\">   \t    <constructor-arg ref=\"mongo\"/>   \t    <constructor-arg name=\"databaseName\" value=\"db\"/>   \t    <constructor-arg name=\"defaultCollectionName\" value=\"person\" />   \t  <\/bean>      \t   \t <bean id=\"personRepository\" class=\"com.mongo.dao.impl.PersonRepository\">           <property name=\"mongoTemplate\" ref=\"mongoTemplate\"><\/property>       <\/bean>      \t  \t <context:annotation-config /> \t\t<\/beans> \t 然后编写操作mongodb的接口 /** * AbstractRepository.java * 版权所有(C) 2012  * 创建:cuiran 2012-12-12 11:40:40 */package com.mongo.dao;import java.util.List;import com.mongo.bean.Person;/** * TODO * @author cuiran * @version TODO */public interface AbstractRepository {\t\t/**\t * \t *<b>function:<\/b>添加对象\t * @author cuiran\t * @createDate 2012-12-12 11:41:30\t */\tpublic void insert(Person person); \t\t/**\t * \t *<b>function:<\/b>根据ID查找对象\t * @author cuiran\t * @createDate 2012-12-12 11:41:41\t */    public Person findOne(String id);       /**     *      *<b>function:<\/b>查询所有     * @author cuiran     * @createDate 2012-12-12 16:26:06     */    public List<Person> findAll();           public List<Person> findByRegex(String regex);    /**     *      *<b>function:<\/b>删除指定的ID对象     * @author cuiran     * @createDate 2012-12-12 16:26:16     */    public void removeOne(String id);       /**     *      *<b>function:<\/b>删除所有     * @author cuiran     * @createDate 2012-12-12 16:25:40     */    public void removeAll();       /**     * 通过ID找到并修改     *<b>function:<\/b>     * @author cuiran     * @createDate 2012-12-12 16:25:51     */    public void findAndModify(String id);   \t} 再写对应接口的实现类： /** * PersonRepository.java * 版权所有(C) 2012  * 创建:cuiran 2012-12-12 11:42:51 */package com.mongo.dao.impl;import java.util.List;import java.util.regex.Pattern;import org.springframework.data.document.mongodb.MongoTemplate;import org.springframework.data.document.mongodb.query.Criteria;import org.springframework.data.document.mongodb.query.Query;import org.springframework.data.document.mongodb.query.Update;import com.mongo.bean.Person;import com.mongo.dao.AbstractRepository;/** * TODO * @author cuiran * @version TODO */public class PersonRepository implements AbstractRepository {\t  private MongoTemplate mongoTemplate;   \t/* (non-Javadoc)\t * @see com.mongo.dao.AbstractRepository#findAll()\t */\t@Override\tpublic List<Person> findAll() {\t\t// TODO Auto-generated method stub\t\treturn getMongoTemplate().find(new Query(), Person.class);   \t}\t/* (non-Javadoc)\t * @see com.mongo.dao.AbstractRepository#findAndModify(java.lang.String)\t */\t@Override\tpublic void findAndModify(String id) {\t\t// TODO Auto-generated method stub\t\t//new Query(Criteria.where(\"id\").is(id)), new Update().inc(\"age\", 3)\t\t\t\tgetMongoTemplate().updateFirst(new Query(Criteria.where(\"id\").is(id)), new Update().inc(\"age\", 3));\t}\t/* (non-Javadoc)\t * @see com.mongo.dao.AbstractRepository#findByRegex(java.lang.String)\t */\t@Override\tpublic List<Person> findByRegex(String regex) {\t\t// TODO Auto-generated method stub\t\t Pattern pattern = Pattern.compile(regex,Pattern.CASE_INSENSITIVE);   \t      Criteria criteria = new Criteria(\"name\").regex(pattern.toString());   \t        return getMongoTemplate().find(new Query(criteria), Person.class);   \t}\t/* (non-Javadoc)\t * @see com.mongo.dao.AbstractRepository#findOne(java.lang.String)\t */\t@Override\tpublic Person findOne(String id) {\t\t// TODO Auto-generated method stub\t\t return getMongoTemplate().findOne(new Query(Criteria.where(\"id\").is(id)), Person.class);   \t}\t/* (non-Javadoc)\t * @see com.mongo.dao.AbstractRepository#insert(com.mongo.bean.Person)\t */\t@Override\tpublic void insert(Person person) {\t\t// TODO Auto-generated method stub\t\tgetMongoTemplate().insert(person);   \t}\t/* (non-Javadoc)\t * @see com.mongo.dao.AbstractRepository#removeAll()\t */\t@Override\tpublic void removeAll() {\t\t// TODO Auto-generated method stub\t\tList<Person> list = this.findAll();           if(list != null){               for(Person person : list){                   getMongoTemplate().remove(person);               }           }   \t}\t/* (non-Javadoc)\t * @see com.mongo.dao.AbstractRepository#removeOne(java.lang.String)\t */\t@Override\tpublic void removeOne(String id) {\t\t// TODO Auto-generated method stub\t\tCriteria criteria = Criteria.where(\"id\").in(id);           if(criteria == null){                Query query = new Query(criteria);                if(query != null && getMongoTemplate().findOne(query, Person.class) != null)                    getMongoTemplate().remove(getMongoTemplate().findOne(query, Person.class));           }   \t}\t/**\t * @return the mongoTemplate\t */\tpublic MongoTemplate getMongoTemplate() {\t\treturn mongoTemplate;\t}\t/**\t * @param mongoTemplate the mongoTemplate to set\t */\tpublic void setMongoTemplate(MongoTemplate mongoTemplate) {\t\tthis.mongoTemplate = mongoTemplate;\t}} 这里也给出对应Person对象代码 /** * Person.java * 版权所有(C) 2012  * 创建:cuiran 2012-12-12 11:37:16 */package com.mongo.bean;import java.io.Serializable;/** * TODO * @author cuiran * @version TODO */public class Person implements Serializable {\t/**\t * \t */\tprivate static final long serialVersionUID = 3617931430808763429L;\t\tprivate String id;       private String name;       private int age;\tpublic Person() {\t\tsuper();\t}\tpublic Person(String id, String name, int age) {\t\tsuper();\t\tthis.id = id;\t\tthis.name = name;\t\tthis.age = age;\t}\t/**\t * @return the id\t */\tpublic String getId() {\t\treturn id;\t}\t/**\t * @param id the id to set\t */\tpublic void setId(String id) {\t\tthis.id = id;\t}\t/**\t * @return the name\t */\tpublic String getName() {\t\treturn name;\t}\t/**\t * @param name the name to set\t */\tpublic void setName(String name) {\t\tthis.name = name;\t}\t/**\t * @return the age\t */\tpublic int getAge() {\t\treturn age;\t}\t/**\t * @param age the age to set\t */\tpublic void setAge(int age) {\t\tthis.age = age;\t}\t/**\t * \t * @param name\t * @param age\t */\tpublic Person(String name, int age) {\t\tsuper();\t\tthis.name = name;\t\tthis.age = age;\t}   \t public String toString() {   \t        return \"Person[id=\"+id+\",name=\"+name+\",age=\"+age+\"]\";   \t    }   } 最后写出我们的测试类开始进行测试 /** * MongoTest.java * 版权所有(C) 2012  * 创建:cuiran 2012-12-12 11:54:30 */package com.mongo.test;import java.util.List;import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import com.mongo.bean.Person;import com.mongo.dao.AbstractRepository;import com.mongo.dao.impl.PersonRepository;/** * TODO * @author cuiran * @version TODO */public class MongoTest {\tprivate static Log log = LogFactory.getLog(MongoTest.class.getName());\t\tprivate  AbstractRepository pr=null;\t\t/**\t * \t *<b>function:<\/b>\t * @author cuiran\t * @createDate 2012-12-12 16:08:02\t */\tpublic void init(){\t\t log.debug(\"开始启动\");\t\t ApplicationContext ctx = new ClassPathXmlApplicationContext(\"applicationContext.xml\");\t\t  pr= (PersonRepository)ctx.getBean(\"personRepository\");\t\t \t\t\t\t\t}\t/**\t * \t *<b>function:<\/b>添加\t * @author cuiran\t * @createDate 2012-12-12 16:11:01\t */\tpublic void insert(){\t\t\t\tPerson p=new Person(\"cuiran\",27);\t\t pr.insert(p);\t\t log.debug(\"添加成功\");\t}\t/**\t * \t *<b>function:<\/b>根据输入的ID查找对象\t * @author cuiran\t * @createDate 2012-12-12 16:24:10\t */\tpublic void findOne(){\t\tString id=\"50c83cb552c2ceb0463177d6\";\t\tPerson p= pr.findOne(id);\t\tlog.debug(p);\t}\t\t\t/**\t * \t *<b>function:<\/b>查询所有\t * @author cuiran\t * @createDate 2012-12-12 16:08:54\t */\tpublic void listAll(){\t\t\t\tList<Person> list=pr.findAll();\t\tlog.debug(\"查询结果如下:\");\t\tfor (Person p:list){\t\t\tlog.debug(p.toString());\t\t}\t\t\t\t\t}\t\t/**\t * \t *<b>function:<\/b>测试方法\t * @author cuiran\t * @createDate 2012-12-12 16:11:37\t */\tpublic void start(){\t\tinit();\t\t\t\t//insert();\t\t//listAll();\t\t\t\tfindOne();\t}\t\t/**\t *<b>function:<\/b>main函数\t * @author cuiran\t * @createDate 2012-12-12 11:54:30\t */\tpublic static void main(String[] args) {\t\t// TODO Auto-generated method stub\t\tMongoTest t=new MongoTest();\t\tt.start();\t}} 运行出现一下日志，就没什么问题。 2012-12-12 16:23:59:DEBUG com.mongo.test.MongoTest - 开始启动2012-12-12 16:23:59:INFO org.springframework.context.support.ClassPathXmlApplicationContext - Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@253498: startup date [Wed Dec 12 16:23:59 CST 2012]; root of context hierarchy2012-12-12 16:23:59:INFO org.springframework.beans.factory.xml.XmlBeanDefinitionReader - Loading XML bean definitions from class path resource [applicationContext.xml]2012-12-12 16:24:00:INFO org.springframework.beans.factory.support.DefaultListableBeanFactory - Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@12a0f6c: defining beans [mongo,mongoTemplate,personRepository,org.springframework.context.annotation.internalConfigurationAnnotationProcessor,org.springframework.context.annotation.internalAutowiredAnnotationProcessor,org.springframework.context.annotation.internalRequiredAnnotationProcessor,org.springframework.context.annotation.internalCommonAnnotationProcessor]; root of factory hierarchy2012-12-12 16:24:00:DEBUG com.mongo.test.MongoTest - Person[id=50c83cb552c2ceb0463177d6,name=cuiran,age=27]   由于这些程序只是作为测试使用，对出现的问题， 欢迎留言咨询。谢谢大家。  在此附上demo源码欢迎朋友下载学习  http://vdisk.weibo.com/s/krDlf    ","title":"[置顶] MongoDB整合Spring 详细讲解(含代码)"},{"content":"先需要明白数据库的物理结构是由数据库的操作系统文件所决定，每一个Oracle数据库是由三种类型的文件组成：数据文件、日志文件和控制文件。数据库的文件为数据库信息提供真正的物理存储。     每一个Oracle数据库有一个或多个物理的数据文件（data file）。一个数据库的数据文件包含全部数据库数据。逻辑数据库结构（如表、索引等）的数据物理地存储在数据库的数据文件中。数据文件通常为*.dbf格式，例如：userCIMS.dbf。数据文件有下列特征：①、一个数据文件仅与一个数据库联系；②、一旦建立，数据文件只增不减；③、一个表空间（数据库存储的逻辑单位）由一个或多个数据文件组成。     其次，我们再来叙述一下Oracle的逻辑结构：Oracle的逻辑结构包括表空间（tablespace），段（segment），数据块（data block）以及模式对象（schema object）。     Oracle数据库在逻辑上是由多个表空间组成的，表空间在物理上包含一个或多个数据文件。而数据文件大小是块大小的整数倍；表空间中存储的对象叫段，比如数据段，索引段和回退段。段由区组成，区是磁盘分配的最小单位。段的增大是通过增加区的个数来实现的。每个区的大小是数据块大小的整数倍，区的大小可以不相同；数据块是数据库中的最小的I/O单位，同时也是内存数据缓冲区的单位，及数据文件存储空间单位。块的大小由参数DB_BLOCK_SIZE设置，其值应设置为操作系统块大小的整数倍。    ⑴、表空间（tablespace）    表空间是数据库中最大的逻辑单位，每一个表空间由一个或多个数据文件组成，一个数据文件只能与一个表空间相联系。每一个数据库都有一个SYSTEM表空间，该表空间是在数据库创建或数据库安装时自动创建的，用于存储系统的数据字典表，程序系统单元，过程函数，包和触发器等，也可用于存储用户数据表，索引对象。表空间具有在线（online）和离线（offline）属性，可以将除SYSTME以外的其他任何表空间置为离线。    ⑵、段（segment）    数据库的段可以分为四类：数据段、索引段、回退段和临时段。    ⑶、区    区是磁盘空间分配的最小单位。磁盘按区划分，每次至少分配一个区。区存储与段中，它由连续的数据块组成。    ⑷、数据块    数据块是数据库中最小的数据组织单位与管理单位，是数据文件磁盘存储空间单位，也是数据库I/O的最小单位，数据块大小由DB_BLOCK_SIZE参数决定，不同的Oracle版本DB_BLOCK_SIZE的默认值是不同的。    ⑸、模式对象    模式对象是一种应用，包括：表、聚簇、视图、索引序列生成器、同义词、哈希、程序单元、数据库链等。    最后，在来说一下Oracle的用户、表空间和数据文件的关系：    一个用户可以使用一个或多个表空间，一个表空间也可以供多个用户使用。用户和表空间没有隶属关系，表空间是一个用来管理数据存储的逻辑概念，表空间只是和数据文件发生关系，数据文件是物理的，一个表空间可以包含多个数据文件，而一个数据文件只能隶属一个表空间。    总结：解释数据库、表空间、数据文件、表、数据的最好办法就是想象一个装满东西的柜子。数据库其实就是柜子，柜中的抽屉是表空间，抽屉中的文件夹是数据文件，文件夹中的纸是表，写在纸上的信息就是数据。","title":"oracle 表 表空间 数据库 用户之间的关系"},{"content":"           一、引言 　　 想使用Linux已经很长时间了，由于没有硬性任务一直也没有系统学习，近日由于工作需要必须使用Linux下的MySQL。本以为有Windows下使用SQL Server的经验，觉得在Linux下安装MySql应该是易如反掌的事，可在真正安装和使用MySQL时走了很多弯路，遇见很多问题，毕竟Linux和Windows本身就有很大区别。为了让和我一样的初学者在学习的过程中少走弯路，尽快入门，写了此文，希望对您有所帮助。本文的Linux环境是Red Hat 9.0，MySQL是4.0.16。 　　 二、安装Mysql 　　 1、下载MySQL的安装文件 　　 安装MySQL需要下面两个文件： 　　 MySQL-server-4.0.16-0.i386.rpm　　　 　　 MySQL-client-4.0.16-0.i386.rpm 　　 下载地址为：http://www.mysql.com/downloads/mysql-4.0.html， 打开此网页，下拉网页找到“Linux x86 RPM downloads”项，找到“Server”和“Client programs”项，下载需要的上述两个rpm文件。 　　 2、安装MySQL 　　 rpm文件是Red Hat公司开发的软件安装包，rpm可让Linux在安装软件包时免除许多复杂的手续。该命令在安装时常用的参数是 –ivh ,其中i表示将安装指定的rmp软件包，V表示安装时的详细信息，h表示在安装期间出现“#”符号来显示目前的安装过程。这个符号将持续到安装完成后才停止。 　　 1）安装服务器端 　　 在有两个rmp文件的目录下运行如下命令： 　　 [root@test1 local]# rpm -ivh MySQL-server-4.0.16-0.i386.rpm 　　 显示如下信息。 　　　 warning: MySQL-server-4.0.16-0.i386.rpm: V3 DSA signature: NOKEY, key ID 5072e1f5 　　 Preparing...　　　　　　　########################################### [100%] 　　 1:MySQL-server　　　　　########################################### [100%] 　　　 。。。。。。（省略显示） 　　 /usr/bin/mysqladmin -u root password 'new-password' 　　 /usr/bin/mysqladmin -u root -h test1 password 'new-password' 　　　 。。。。。。（省略显示） 　　 Starting mysqld daemon with databases from /var/lib/mysql 　　 如出现如上信息，服务端安装完毕。测试是否成功可运行netstat看Mysql端口是否打开，如打开表示服务已经启动，安装成功。Mysql默认的端口是3306。 　　 [root@test1 local]# netstat -nat 　　 Active Internet connections (servers and established) 　　 Proto Recv-Q Send-Q Local Address　　　　　 Foreign Address　　　　 State　　　 　　 tcp　　0　　0 0.0.0.0:3306　　　　 0.0.0.0:*　　　　　 LISTEN　　　 　　 上面显示可以看出MySQL服务已经启动。 　　 2）安装客户端 　　 运行如下命令： 　　 [root@test1 local]# rpm -ivh MySQL-client-4.0.16-0.i386.rpm 　　 warning: MySQL-client-4.0.16-0.i386.rpm: V3 DSA signature: NOKEY, key ID 5072e1f5 　　 Preparing...　　　　########################################### [100%] 　　 1:MySQL-client　 ########################################### [100%] 　　 显示安装完毕。 　　 用下面的命令连接mysql,测试是否成功。 　 三、登录MySQL 　　 登录MySQL的命令是mysql， mysql 的使用语法如下： 　　 mysql [-u username] [-h host] [-p[password]] [dbname] 　　 username 与 password 分别是 MySQL 的用户名与密码，mysql的初始管理帐号是root，没有密码，注意：这个root用户不是Linux的系统用户。MySQL默认用户是root，由于初始没有密码，第一次进时只需键入mysql即可。 　　 [root@test1 local]# mysql 　　 Welcome to the MySQL monitor.　Commands end with ; or \\g. 　　 Your MySQL connection id is 1 to server version: 4.0.16-standard 　　 Type 'help;' or '\\h' for help. Type '\\c' to clear the buffer. 　　 mysql> 　　 出现了“mysql>”提示符，恭喜你，安装成功！ 　　 增加了密码后的登录格式如下： 　　 mysql -u root -p 　　 Enter password: (输入密码) 　　 其中-u后跟的是用户名，-p要求输入密码，回车后在输入密码处输入密码。 　　 注意：这个mysql文件在/usr/bin目录下，与后面讲的启动文件/etc/init.d/mysql不是一个文件。 　　 四、MySQL的几个重要目录 　　 MySQL安装完成后不象SQL Server默认安装在一个目录，它的数据库文件、配置文件和命令文件分别在不同的目录，了解这些目录非常重要，尤其对于Linux的初学者，因为Linux本身的目录结构就比较复杂，如果搞不清楚MySQL的安装目录那就无从谈起深入学习。 　　 下面就介绍一下这几个目录。 　　 1、数据库目录 　　 /var/lib/mysql/ 　　 2、配置文件 　　 /usr/share/mysql（mysql.server命令及配置文件） 　　 3、相关命令 　　 /usr/bin(mysqladmin mysqldump等命令) 　　 4、启动脚本 　　 /etc/rc.d/init.d/（启动脚本文件mysql的目录） 　 五、修改登录密码 　　 MySQL默认没有密码，安装完毕增加密码的重要性是不言而喻的。 　　 1、命令 　　 usr/bin/mysqladmin -u root password 'new-password' 　　 格式：mysqladmin -u用户名 -p旧密码 password 新密码 　　 2、例子 　　 例1：给root加个密码123456。 　　 键入以下命令 ： 　　 [root@test1 local]# /usr/bin/mysqladmin -u root password 123456 　　 注：因为开始时root没有密码，所以-p旧密码一项就可以省略了。 　　 3、测试是否修改成功 　　 1）不用密码登录 　　 [root@test1 local]# mysql 　　 ERROR 1045: Access denied for user: 'root@localhost' (Using password: NO) 　　 显示错误，说明密码已经修改。 　　 2）用修改后的密码登录 　　 [root@test1 local]# mysql -u root -p 　　 Enter password: (输入修改后的密码123456) 　　 Welcome to the MySQL monitor.　Commands end with ; or \\g. 　　 Your MySQL connection id is 4 to server version: 4.0.16-standard 　　 Type 'help;' or '\\h' for help. Type '\\c' to clear the buffer. 　　 mysql> 　　 成功！ 　　 这是通过mysqladmin命令修改口令，也可通过修改库来更改口令。 　　 六、启动与停止 　　 1、启动 　　 MySQL安装完成后启动文件mysql在/etc/init.d目录下，在需要启动时运行下面命令即可。 　　 [root@test1 init.d]# /etc/init.d/mysql start 　　 2、停止 　　 /usr/bin/mysqladmin -u root -p shutdown 　　 3、自动启动 　　 1）察看mysql是否在自动启动列表中 　　 [root@test1 local]#　/sbin/chkconfig –list 　　 2）把MySQL添加到你系统的启动服务组里面去 　　 [root@test1 local]#　/sbin/chkconfig　– add　mysql 　　 3）把MySQL从启动服务组里面删除。 　　 [root@test1 local]#　/sbin/chkconfig　– del　mysql 七、更改MySQL目录 　　 MySQL默认的数据文件存储目录为/var/lib/mysql。假如要把目录移到/home/data下需要进行下面几步： 　　 1、home目录下建立data目录 　　 cd /home 　　 mkdir data 　　 2、把MySQL服务进程停掉： 　　 mysqladmin -u root -p shutdown 　　 3、把/var/lib/mysql整个目录移到/home/data 　　 mv /var/lib/mysql　/home/data/ 　　 这样就把MySQL的数据文件移动到了/home/data/mysql下 　　 4、找到my.cnf配置文件 　　 如果/etc/目录下没有my.cnf配置文件，请到/usr/share/mysql/下找到*.cnf文件，拷贝其中一个到/etc/并改名为my.cnf)中。命令如下： 　　 [root@test1 mysql]# cp /usr/share/mysql/my-medium.cnf　/etc/my.cnf 　　 5、编辑MySQL的配置文件/etc/my.cnf 　　 为保证MySQL能够正常工作，需要指明mysql.sock文件的产生位置。 修改socket=/var/lib/mysql/mysql.sock一行中等号右边的值为：/home/mysql/mysql.sock 。操作如下： 　　 vi　 my.cnf　　　 (用vi工具编辑my.cnf文件，找到下列数据修改之) 　　 # The MySQL server 　　　 [mysqld] 　　　 port　　　= 3306 　　　 #socket　 = /var/lib/mysql/mysql.sock（原内容，为了更稳妥用“#”注释此行） 　　　 socket　 = /home/data/mysql/mysql.sock　　　（加上此行） 　　 6、修改MySQL启动脚本/etc/rc.d/init.d/mysql 　　 最后，需要修改MySQL启动脚本/etc/rc.d/init.d/mysql，把其中datadir=/var/lib/mysql一行中，等号右边的路径改成你现在的实际存放路径：home/data/mysql。 　　 [root@test1 etc]# vi　/etc/rc.d/init.d/mysql 　　 #datadir=/var/lib/mysql　　　　（注释此行） 　　 datadir=/home/data/mysql　　 （加上此行） 　　 7、重新启动MySQL服务 　　 /etc/rc.d/init.d/mysql　start 　　 或用reboot命令重启Linux 　　 如果工作正常移动就成功了，否则对照前面的7步再检查一下。 　　 八、MySQL的常用操作 　　 注意：MySQL中每个命令后都要以分号；结尾。 　　 1、显示数据库 　　 mysql> show databases; 　　 +----------+ 　　 | Database | 　　 +----------+ 　　 | mysql　　| 　　 | test　　 | 　　 +----------+ 　　 2 rows in set (0.04 sec) 　　 Mysql刚安装完有两个数据库：mysql和test。mysql库非常重要，它里面有MySQL的系统信息，我们改密码和新增用户，实际上就是用这个库中的相关表进行操作。 　　 2、显示数据库中的表 　　 mysql> use mysql; （打开库，对每个库进行操作就要打开此库，类似于foxpro ） 　　 Database changed 　　 mysql> show tables; 　　 +-----------------+ 　　 | Tables_in_mysql | 　　 +-----------------+ 　　 | columns_priv　　| 　　 | db　　　　　　　| 　　 | func　　　　　　| 　　 | host　　　　　　| 　　 | tables_priv　　 | 　　 | user　　　　　　| 　　 +-----------------+ 　　 6 rows in set (0.01 sec) 　　 3、显示数据表的结构： 　　 describe 表名; 　　 4、显示表中的记录： 　　 select * from 表名; 　　 例如：显示mysql库中user表中的纪录。所有能对MySQL用户操作的用户都在此表中。 　　 Select * from user; 　　 5、建库： 　　 create database 库名; 　　 例如：创建一个名字位aaa的库 　　 mysql> create databases aaa; 6、建表： 　　 use 库名； 　　 create table 表名 (字段设定列表)； 　　 例如：在刚创建的aaa库中建立表name,表中有id(序号，自动增长)，xm（姓名）,xb（性别）,csny（出身年月）四个字段 　　 use aaa; 　　 mysql> create table name (id int(3) auto_increment not null primary key, xm char(8),xb char(2),csny date); 　　 可以用describe命令察看刚建立的表结构。 　　 mysql> describe name; 　　 +-------+---------+------+-----+---------+----------------+ 　　 | Field | Type　　| Null | Key | Default | Extra　　　　　| 　　 +-------+---------+------+-----+---------+----------------+ 　　 | id　　| int(3)　|　　　| PRI | NULL　　| auto_increment | 　　 | xm　　| char(8) | YES　|　　 | NULL　　|　　　　　　　　| 　　 | xb　　| char(2) | YES　|　　 | NULL　　|　　　　　　　　| 　　 | csny　| date　　| YES　|　　 | NULL　　|　　　　　　　　| 　　 +-------+---------+------+-----+---------+----------------+ 　　 7、增加记录 　　 例如：增加几条相关纪录。 　　 mysql> insert into name values('','张三','男','1971-10-01'); 　　 mysql> insert into name values('','白云','女','1972-05-20'); 　　 可用select命令来验证结果。 　　 mysql> select * from name; 　　 +----+------+------+------------+ 　　 | id | xm　 | xb　 | csny　　　 | 　　 +----+------+------+------------+ 　　 |　1 | 张三 | 男　 | 1971-10-01 | 　　 |　2 | 白云 | 女　 | 1972-05-20 | 　　 +----+------+------+------------+ 　　 8、修改纪录 　　 例如：将张三的出生年月改为1971-01-10 　　 mysql> update name set csny='1971-01-10' where xm='张三'; 　　 9、删除纪录 　　 例如：删除张三的纪录。 　　 mysql> delete from name where xm='张三'; 　　 10、删库和删表 　　 drop database 库名; 　　 drop table 表名； 　　 九、增加MySQL用户 　　 格式：grant select on 数据库.* to 用户名@登录主机 identified by \"密码\" 例1、增加一个用户user_1密码为123，让他可以在任何主机上登录，并对所有数据库有查询、插入、修改、删除的权限。首先用以root用户连入MySQL，然后键入以下命令： 　　 mysql> grant select,insert,update,delete on *.* to user_1@\"%\" Identified by \"123\"; 例1增加的用户是十分危险的，如果知道了user_1的密码，那么他就可以在网上的任何一台电脑上登录你的MySQL数据库并对你的数据为所欲为了，解决办法见例2。 　　 例2、增加一个用户user_2密码为123,让此用户只可以在localhost上登录，并可以对数据库aaa进行查询、插入、修改、删除的操作（localhost指本地主机，即MySQL数据库所在的那台主机），这样用户即使用知道user_2的密码，他也无法从网上直接访问数据库，只能通过MYSQL主机来操作aaa库。 　　 mysql>grant select,insert,update,delete on aaa.* to user_2@localhost identified by \"123\"; 　　 用新增的用户如果登录不了MySQL，在登录时用如下命令： 　　 mysql -u user_1 -p　-h 192.168.113.50　（-h后跟的是要登录主机的ip地址） 　　 十、备份与恢复 　　 1、备份 　　 例如：将上例创建的aaa库备份到文件back_aaa中 　　 [root@test1 root]# cd　/home/data/mysql　(进入到库目录，本例库已由val/lib/mysql转到/home/data/mysql，见上述第七部分内容) 　　 [root@test1 mysql]# mysqldump -u root -p --opt aaa > back_aaa 　　 2、恢复 　　 [root@test mysql]# mysql -u root -p ccc < back_aaa","title":"Linux下MySql的安装和使用"},{"content":"跳巢，这真是当下社会的一个好东西，特别在我们这个行业，跳巢是一个常挂在口边的事。          网络上常说的一句话，钱才能让我有安全感，对应到我们这些做技术的人来讲，每月工资多少才是最实际的，而要让工资快速提高起来不跳巢几乎是不可能的，再这6年里我也算是个很有经验的人士了，在这里讲讲心得大家不妨借鉴下。          才进社会第一份工作对于工资的要求一般都是最低的，这时候不管你拿2000还是4000还是6000其实是没有多大区别的，能进一个能学到东西的地方和明确一个好的发展方向才是最重要的，基本上我们前3年都在干这个事，尽量努力学习，尽量确认发展目标。才毕业就能进微软，IBM，SAP这类公司的人实在太少了，大部分的程序员都是从本土中小企业奋斗起来的，当你发现你没什么东西可学或者公司的业务方向跟你的目标方向不一致的时候你就不妨跳吧，建议几点：骑驴找马，尽量找更好的或者看起来更好的公司，经常更新自己的简历，没找好下家别忙着辞职。          如果你毕业3年都在一个地方那只能说明，你是我们这个社会里不可多见的忠诚型人才，还有一种可能就是你在混。才开始工作的1--3年里面，能找个符合自己技术发展方向的，或者符合你要转变的技术方向的，工资再能提高点，别考虑太多就可以去了。这个时候方向最重要，特别是在技术的海洋里，没有好的学习发展方向你是永远游不到下一个节点的。          在1--3年的时候1年1跳是可以的也很普遍，你可以在这个期间里好好的选择者一把，或选择公司或选择工资，但一定得保证自己的学习发展目标不动摇，或者你要转技术或者要转平台那你也尽快吧，这时你职业生涯的黄金时代。          3--5年的时候你得有拿得出手的一门技术了，要不然HR就会觉得你这个人这不行那不行了，总的来说社会对你的看法就会有所转变了，这个时候你要跳巢就会出现一定的风险了，所以尽量建议去大的公司，或者谋求职位上的转变，比如努力成为一个Team Leader是要尽量去做的，混进一个规范的公司对你在这期间升职也有所帮助。这个时候你要跳巢不得不关注下你要去的公司要你做什么和你能做什么了，在面试的时候就要尽量说清楚，进不进的去，工资涨不涨是小事，要是跳错了会让自己摔得有点痛。          5年以后你的选择需要更慎重了，在面试一家新公司大的时候你一定让对方清楚的知道你的技术方向和工作经验，并且你也的很清楚你进去后是要做什么，你能不能Hold住，如果前5年里你跳了3次以上，那我建议你得稳稳了，你现在得再一个公司里面多呆一会，所以尽量给自己选个好点的窝吧，尽量是纯外资企业，这种企业里你上司的权利不是太大，同事相处起来不是太难，还能接触很多先进的培训和技术，算是不错的选择，这个时候凭借你5年来的积累和经验你已经在这个行业里面有一定的主动选择权了，如果你英语再好些那真是一路通杀，给自己找个好的归属好好规划下下一个方向吧。          8年以上的的前辈们要不是成经理，要不是主管，要不已经创业或者出国了，很少还有继续在国内做纯技术的，这也是中国特色吧。话说国外对于专业技术人才从不吝啬，10年以上英语过关的前辈很容易混到国外去旅游几年；那些人脉好的也都跟着自己以前的上司或者伙同几位老朋友创业去了；技术好英语不好的在国内也能找到一个不错的坑呆着；技术不乍样，人脉也不强的那我只能说你白混了，回家找个安稳的地头生儿子养老吧，希望你房子买得早。          道理大家都明白，在业内混或积累技术或积累人脉，争取做某个业务里的急先锋你会过的越来越滋润的，努力了不会白给也是我们这个行业的一大优点吧。","title":"我的6年职场人生从月薪800到2万（跳巢经验谈）"},{"content":"关于Oracle云数据库（Oracle Cloud Database）的一些体验和分享，也可以参考以下链接： http://www.eygle.com/archives/2012/12/oracle_cloud_database_req.html http://www.eygle.com/archives/2012/12/oracle_cloud_database_application_express.html http://www.eygle.com/archives/2012/12/oracle_cloud_sql_developer.html Oracle公司在2012年OOW大会上，强势的确立了公司的云战略方向，也随之开放了Oracle Database Cloud平台。该平台的首页地址为： http://cloud.oracle.com 在这个首页上，你可以找到Oracle云数据库的试用链接： Oracle云数据库目前按照存储空间方式收费，分为5GB、20GB、50GB三种，分别收取175$,900$,2000$的月服务费，数据库版本选用了11gR2，由于技术限制，目前只支持 1 个 Schema的授权方式。将来如果升级到Oracle Database 12c，将可以支持用户模式，Pluggable Database将为云计算提供极大的便利。 目前Oracle云数据库开放30天的试用版本，支持1GB存储，6GB的数据传输流量。 申请注册Oracle数据库云，需要首先申请一个OTN账户，然后提供基本信息，提供信用卡号，注意Oracle并不会收取费用，信用卡仅用于验证身份。 申请到获得批准，一般需要3～5个工作日，一旦你收到如下Greeting邮件，恭喜你，你的申请获得了审批： 然后邮件会接踵而至，我相信Larry Ellision 是学习了乔帮主的一套，以下是我的订单： 登陆激活之后，可以看到自己的服务信息，数据库信息等，随之可以创建应用与发布公开访问： Oracle Cloud Database - 云数据库需要依托应用才能够发挥出作用，所以在申请云数据库之后，Oracle提供了Application Express开发环境，通过这个开发环境，用户可以构建应用并发布出去，对外提供服务。 所以，Oracle的云数据库和其他Oracle云应用的区别就在于： 1.数据库是可视化和自我可管理的 2.应用是自行部署和开发的 不过目前Oracle提供的在线开发环境就只有Application Express。 登陆后Oracle Database Cloud环境后，可以打开开发环境，其中提供了非常友好的\"SQL Workshop\"接口，用于访问数据库： SQL WorkShop的接口非常友好，可以直接通过SQL语句访问数据库内容，或者查看表结构等信息： Express 内部集成了Team开发功能，具备里程碑、Bugs协作等团队协作功能： Express 内置了示范样例，通过一个订单销售系统，示范应用开发和发布模式，整体风格非常清爽： 从目前开放的Oracle Cloud Database看来，实际上只是一个集成的Oracle Application Express开发环境。进一步的功能有待于Oracle的继续演进。 Oracle云数据库申请成功之后，同时会开通两个sftp账户，可以用于上传和下载程序文件或数据。在用户管理页面需要初始化用户密码，应用的远程SQL Developer连接，需要在OAE（Oracle  Application Express）进行用户创建。 完成这些工作之后，你将可以像使用一个本地数据库一样使用这个云端的Oracle数据库。 以下是一些核心步骤的操作示范。 登陆之后，在Identity Console处进入用户管理，可以通过Reset方式修改用户口令，这里两个sftp用户的口令必须要更改才能使用： 此外，应用的访问用户需要通过Express的管理页面进行用户创建： 用户组可以选择SQL Developer组，这个用户就可以用于远程的连接访问： 接下来就可以使用已经具备的信息，进行连接配置，在SQL Developer最新的3.2版本中，通过\"Cloud Connection\"功能可以创建云数据库连接。 名称使用你获得的数据库标识名称，用户名为Express中创建的，URL使用你的apex连接串： 然后就可以启动连接，SQL Developer就像连接一个本地数据库一样，连通了云端的Oracle数据库：","title":"Oracle云数据库初体验 之一 - 申请与介绍"},{"content":"完整的Oracle数据库通常由两部分组成：Oracle数据库实例和数据库。   　　1)数据库是一系列物理文件的集合(数据文件，控制文件，联机日志，参数文件等);   　　2)Oracle数据库实例则是一组Oracle后台进程/线程以及在服务器分配的共享内存区。   　　在启动Oracle数据库服务器时，实际上是在服务器的内存中创建一个Oracle实例(即在服务器内存中分配共享内存并创建相关的后台内存)，然后由这个Oracle数据库实例来访问和控制磁盘中的数据文件。Oracle有一个很大的内存快，成为全局区(SGA)。   　　一、数据库、表空间、数据文件   　　1.数据库   　　数据库是数据集合。Oracle是一种数据库管理系统，是一种关系型的数据库管理系统。   　　通常情况了我们称的“数据库”，并不仅指物理的数据集合，他包含物理数据、数据库管理系统。也即物理数据、内存、操作系统进程的组合体。   　　数据库的数据存储在表中。数据的关系由列来定义，即通常我们讲的字段，每个列都有一个列名。数据以行(我们通常称为记录)的方式存储在表中。表之间可以相互关联。以上就是关系模型数据库的一个最简单的描述。   　　当然，Oracle也是提供对面象对象型的结构数据库的最强大支持，对象既可以与其它对象建立关系，也可以包含其它对象。关于OO型数据库，以后利用专门的篇幅来讨论。一般情况下我们的讨论都基于关系模型。   　　2.表空间、文件   　　无论关系结构还是OO结构，Oracle数据库都将其数据存储在文件中。数据库结构提供对数据文件的逻辑映射，允许不同类型的数据分开存储。这些逻辑划分称作表空间。   　　表空间(tablespace)是数据库的逻辑划分，每个数据库至少有一个表空间(称作SYSTEM表空间)。为了便于管理和提高运行效率，可以使用一些附加表空间来划分用户和应用程序。例如：USER表空间供一般用户使用，RBS表空间供回滚段使用。一个表空间只能属于一个数据库。   　　每个表空间由同一磁盘上的一个或多个文件组成，这些文件叫数据文件(datafile)。一个数据文件只能属于一个表空间。在Oracle7.2以后，数据文件创建可以改变大小。创建新的表空间需要创建新的数据文件。数据文件一旦加入到表空间中，就不能从这个表空间中移走，也不能与其它表空间发生联系。   　　如果数据库存储在多个表空间中，可以将它们各自的数据文件存放在不同磁盘上来对其进行物理分割。在规划和协调数据库I/O请求的方法中，上述的数据分割是一种很重要的方法。   　　3.Oracle数据库的存储结构分为逻辑存储结构和物理存储结构：   　　1)逻辑存储结构：用于描述Oracle内部组织和管理数据的方式;   　　2)物理存储结构：用于描述Oracle外部即操作系统中组织和管理数据的方式。   　　二、Oracle数据库实例   　　为了访问数据库中的数据，Oracle使用一组所有用户共享的后台进程。此外，还有一些存储结构(统称为System Gloabl Area,即SGA)，用来存储最近从数据库查询的数据。数据块缓存区和SQL共享池(Shared SQL Pool)是SGA的最大部分，一般占SGA内存的95%以上。通过减少对数据文件的I/O次数，这些存储区域可以改善数据库的性能。   　　Oracle数据库实例(instance)也称作服务器(server)，是用来访问数据库文件集的存储结构及后台进程的集合。一个数据库可以被多个实例访问(这是Oracle并行服务器选项)。   　　决定实例大小及组成的参数存储在init.ora文件中(在9i中是spfile)。Oracle数据库实例启动时需要读这个文件，并且在运行时可以由数据库管理员修改。对该文件的任何修改都只有在下一次启动时才启作用。实例的init.ora文件件通常包含实例的名字:如果一个实例名为orcl, 那么init.ora文件通常被命名为initorcl.ora。另一个配置文件config.ora用来存放在数据库创建后就不再改变的变量值(如数据库的块大小)。实例的config.ora文件通常也包含该实例的名字：如果实例的名字为orcl，则config.ora一般将被命名为 configorcl.ora。为了便于使用config.ora文件的设置值，在实例的init.ora文件中，该文件必须通过IFILE参数作为包含文件列出。 原文出自【比特网】，转载请保留原文链接：http://soft.chinabyte.com/database/220/11669720.shtml","title":"oracle 数据库 实例 及相关概念"},{"content":"sqllink.cs c#数据库操作类 using System; using System.Configuration; using System.Data; using System.Data.SqlClient; namespace Chenzhang {  /// <summary>  /// SQL Server数据库操作组件  /// <\/summary>  public class SqlLink :IDisposable  {   private SqlDataAdapter dsCommand;   private AppSettingsReader appsettingsreader;   private String cn;   /// <summary>   /// Constructor   /// <\/summary>   public SqlLink()   {    dsCommand =new SqlDataAdapter() ;    appsettingsreader = new AppSettingsReader();    cn=(string)appsettingsreader.GetValue(\"SQLConnectionString\", typeof(string));   }   /// <summary>   /// Dispose   /// <\/summary>   public void Dispose()   {    Dispose(true);    GC.SuppressFinalize(this);   }   protected virtual void Dispose(bool disposing)   {    if (!disposing)     return;    if (dsCommand != null)    {     //dispose dsCommand.SelectCommand     if (dsCommand.SelectCommand!=null)     {      if (dsCommand.SelectCommand.Connection!=null)       dsCommand.SelectCommand.Connection.Dispose();      dsCommand.SelectCommand.Dispose();     }     //dispose dsCommand.InsertCommand     if (dsCommand.InsertCommand!=null)     {      if (dsCommand.InsertCommand.Connection!=null)       dsCommand.InsertCommand.Connection.Dispose();      dsCommand.InsertCommand.Dispose();     }     //dispose dsCommand.UpdateCommand     if (dsCommand.UpdateCommand!=null)     {      if (dsCommand.UpdateCommand.Connection!=null)       dsCommand.UpdateCommand.Connection.Dispose();      dsCommand.UpdateCommand.Dispose();     }     dsCommand.Dispose();     dsCommand=null;    }        }   /// <summary>   /// 获取select语句查询结果记录集   /// <\/summary>   /// <param name=\"sql\">select语句<\/param>   /// <returns>结果记录集<\/returns>   public DataTable SelectSql(String sql)   {    dsCommand.SelectCommand=new SqlCommand();    dsCommand.SelectCommand.Connection=new SqlConnection(cn);    DataSet ds=new DataSet() ;    dsCommand.SelectCommand.CommandText=sql;    dsCommand.SelectCommand.CommandType=CommandType.Text;    dsCommand.SelectCommand.Connection.Open();    try    {     dsCommand.Fill(ds,\"result\");     return ds.Tables[\"result\"];    }    catch    {     return null;    }    finally    {     if (dsCommand.SelectCommand!=null)     {      if (dsCommand.SelectCommand.Connection!=null)       dsCommand.SelectCommand.Connection.Dispose();      dsCommand.SelectCommand.Dispose();     }     dsCommand.Dispose();     ds.Dispose();    }   }   /// <summary>   /// 获取存储过程运行结果记录集，存储过程不带参数   /// <\/summary>   /// <param name=\"sp_name\">存储过程名称<\/param>   /// <returns>结果记录集<\/returns>   public DataTable SelectSql_sp(String sp_name)   {    dsCommand.SelectCommand=new SqlCommand();    dsCommand.SelectCommand.Connection=new SqlConnection(cn);    DataSet ds=new DataSet() ;    dsCommand.SelectCommand.CommandText=sp_name;    dsCommand.SelectCommand.CommandType=CommandType.StoredProcedure;    dsCommand.SelectCommand.Connection.Open();    try    {     dsCommand.Fill(ds,\"result\");     return ds.Tables[\"result\"];    }    catch    {     return null;    }    finally    {     if (dsCommand.SelectCommand!=null)     {      if (dsCommand.SelectCommand.Connection!=null)       dsCommand.SelectCommand.Connection.Dispose();      dsCommand.SelectCommand.Dispose();     }     dsCommand.Dispose();     ds.Dispose();    }   }   /// <summary>   /// 获取存储过程运行结果记录集，存储过程带1个参数   /// <\/summary>   /// <param name=\"sp_name\">存储过程名称<\/param>   /// <param name=\"par1_name\">存储过程参数名称，如\"@Age\",\"@StudentName\"<\/param>   /// <param name=\"par1_type\">存储过程参数类型，如\"int\",\"varchar\"<\/param>   /// <param name=\"par1_value\">存储过程参数值，如\"18\",\"张三\"<\/param>   /// <returns>结果记录集<\/returns>   public DataTable SelectSql_sp_par1(String sp_name,String par1_name,String par1_type,String par1_value)   {    int par1_dbtype=0;    if (par1_type.ToLower()==\"varchar\") par1_dbtype=Convert.ToInt16(SqlDbType.VarChar);    else if (par1_type.ToLower()==\"string\") par1_dbtype=Convert.ToInt16(SqlDbType.VarChar);    else if (par1_type.ToLower()==\"integer\") par1_dbtype=Convert.ToInt16(SqlDbType.Int);    else if (par1_type.ToLower()==\"int\") par1_dbtype=Convert.ToInt16(SqlDbType.Int);    dsCommand.SelectCommand=new SqlCommand();    dsCommand.SelectCommand.Connection=new SqlConnection(cn);    DataSet ds=new DataSet() ;    dsCommand.SelectCommand.CommandText=sp_name;    dsCommand.SelectCommand.CommandType=CommandType.StoredProcedure;    SqlParameter objPar;    objPar=dsCommand.SelectCommand.Parameters.Add(par1_name,par1_dbtype);    objPar.Direction=ParameterDirection.Input;    objPar.Value=par1_value;    dsCommand.SelectCommand.Connection.Open();    try    {     dsCommand.Fill(ds,\"result\");     return ds.Tables[\"result\"];    }    catch    {     return null;    }    finally    {     if (dsCommand.SelectCommand!=null)     {      if (dsCommand.SelectCommand.Connection!=null)       dsCommand.SelectCommand.Connection.Dispose();      dsCommand.SelectCommand.Dispose();     }     dsCommand.Dispose();     ds.Dispose();    }   }   /// <summary>   /// 获取存储过程运行结果记录集，存储过程带2个参数   /// <\/summary>   /// <param name=\"sp_name\">存储过程名称<\/param>   /// <param name=\"par1_name\">存储过程参数名称，如\"@Age\",\"@StudentName\"<\/param>   /// <param name=\"par1_type\">存储过程参数类型，如\"int\",\"varchar\"<\/param>   /// <param name=\"par1_value\">存储过程参数值，如\"18\",\"张三\"<\/param>   /// <param name=\"par2_name\">存储过程参数名称，如\"@Age\",\"@StudentName\"<\/param>   /// <param name=\"par2_type\">存储过程参数类型，如\"int\",\"varchar\"<\/param>   /// <param name=\"par2_value\">存储过程参数值，如\"18\",\"张三\"<\/param>   /// <returns>结果记录集<\/returns>   public DataTable SelectSql_sp_par2(String sp_name,String par1_name,String par1_type,String par1_value,String par2_name,String par2_type,String par2_value)   {    int par1_dbtype=0;    int par2_dbtype=0;    if (par1_type.ToLower()==\"varchar\") par1_dbtype=Convert.ToInt16(SqlDbType.VarChar);    else if (par1_type.ToLower()==\"string\") par1_dbtype=Convert.ToInt16(SqlDbType.VarChar);    else if (par1_type.ToLower()==\"integer\") par1_dbtype=Convert.ToInt16(SqlDbType.Int);    else if (par1_type.ToLower()==\"int\") par1_dbtype=Convert.ToInt16(SqlDbType.Int);    if (par2_type.ToLower()==\"varchar\") par2_dbtype=Convert.ToInt16(SqlDbType.VarChar);    else if (par2_type.ToLower()==\"string\") par2_dbtype=Convert.ToInt16(SqlDbType.VarChar);    else if (par2_type.ToLower()==\"integer\") par2_dbtype=Convert.ToInt16(SqlDbType.Int);    else if (par2_type.ToLower()==\"int\") par2_dbtype=Convert.ToInt16(SqlDbType.Int);    dsCommand.SelectCommand=new SqlCommand();    dsCommand.SelectCommand.Connection=new SqlConnection(cn);    DataSet ds=new DataSet() ;    dsCommand.SelectCommand.CommandText=sp_name;    dsCommand.SelectCommand.CommandType=CommandType.StoredProcedure;    SqlParameter objPar;    objPar=dsCommand.SelectCommand.Parameters.Add(par1_name,par1_dbtype);    objPar.Direction=ParameterDirection.Input;    objPar.Value=par1_value;    objPar=dsCommand.SelectCommand.Parameters.Add(par2_name,par2_dbtype);    objPar.Direction=ParameterDirection.Input;    objPar.Value=par2_value;    dsCommand.SelectCommand.Connection.Open();    try    {     dsCommand.Fill(ds,\"result\");     return ds.Tables[\"result\"];    }    catch    {     return null;    }    finally    {     if (dsCommand.SelectCommand!=null)     {      if (dsCommand.SelectCommand.Connection!=null)       dsCommand.SelectCommand.Connection.Dispose();      dsCommand.SelectCommand.Dispose();     }     dsCommand.Dispose();     ds.Dispose();    }   }   /// <summary>   /// 获取存储过程运行结果记录集，存储过程带3个参数   /// <\/summary>   /// <param name=\"sp_name\">存储过程名称<\/param>   /// <param name=\"par1_name\">存储过程参数名称，如\"@Age\",\"@StudentName\"<\/param>   /// <param name=\"par1_type\">存储过程参数类型，如\"int\",\"varchar\"<\/param>   /// <param name=\"par1_value\">存储过程参数值，如\"18\",\"张三\"<\/param>   /// <param name=\"par2_name\">存储过程参数名称，如\"@Age\",\"@StudentName\"<\/param>   /// <param name=\"par2_type\">存储过程参数类型，如\"int\",\"varchar\"<\/param>   /// <param name=\"par2_value\">存储过程参数值，如\"18\",\"张三\"<\/param>   /// <param name=\"par3_name\">存储过程参数名称，如\"@Age\",\"@StudentName\"<\/param>   /// <param name=\"par3_type\">存储过程参数类型，如\"int\",\"varchar\"<\/param>   /// <param name=\"par3_value\">存储过程参数值，如\"18\",\"张三\"<\/param>   /// <returns>结果记录集<\/returns>   public DataTable SelectSql_sp_par3(String sp_name,String par1_name,String par1_type,String par1_value,String par2_name,String par2_type,String par2_value,String par3_name,String par3_type,String par3_value)   {    int par1_dbtype=0;    int par2_dbtype=0;    int par3_dbtype=0;    if (par1_type.ToLower()==\"varchar\") par1_dbtype=Convert.ToInt16(SqlDbType.VarChar);    else if (par1_type.ToLower()==\"string\") par1_dbtype=Convert.ToInt16(SqlDbType.VarChar);    else if (par1_type.ToLower()==\"integer\") par1_dbtype=Convert.ToInt16(SqlDbType.Int);    else if (par1_type.ToLower()==\"int\") par1_dbtype=Convert.ToInt16(SqlDbType.Int);    if (par2_type.ToLower()==\"varchar\") par2_dbtype=Convert.ToInt16(SqlDbType.VarChar);    else if (par2_type.ToLower()==\"string\") par2_dbtype=Convert.ToInt16(SqlDbType.VarChar);    else if (par2_type.ToLower()==\"integer\") par2_dbtype=Convert.ToInt16(SqlDbType.Int);    else if (par2_type.ToLower()==\"int\") par2_dbtype=Convert.ToInt16(SqlDbType.Int);    if (par3_type.ToLower()==\"varchar\") par3_dbtype=Convert.ToInt16(SqlDbType.VarChar);    else if (par3_type.ToLower()==\"string\") par3_dbtype=Convert.ToInt16(SqlDbType.VarChar);    else if (par3_type.ToLower()==\"integer\") par3_dbtype=Convert.ToInt16(SqlDbType.Int);    else if (par3_type.ToLower()==\"int\") par3_dbtype=Convert.ToInt16(SqlDbType.Int);    dsCommand.SelectCommand=new SqlCommand();    dsCommand.SelectCommand.Connection=new SqlConnection(cn);    DataSet ds=new DataSet() ;    dsCommand.SelectCommand.CommandText=sp_name;    dsCommand.SelectCommand.CommandType=CommandType.StoredProcedure;    SqlParameter objPar;    objPar=dsCommand.SelectCommand.Parameters.Add(par1_name,par1_dbtype);    objPar.Direction=ParameterDirection.Input;    objPar.Value=par1_value;    objPar=dsCommand.SelectCommand.Parameters.Add(par2_name,par2_dbtype);    objPar.Direction=ParameterDirection.Input;    objPar.Value=par2_value;    objPar=dsCommand.SelectCommand.Parameters.Add(par3_name,par3_dbtype);    objPar.Direction=ParameterDirection.Input;    objPar.Value=par3_value;    dsCommand.SelectCommand.Connection.Open();    try    {     dsCommand.Fill(ds,\"result\");     return ds.Tables[\"result\"];    }    catch    {     return null;    }    finally    {     if (dsCommand.SelectCommand!=null)     {      if (dsCommand.SelectCommand.Connection!=null)       dsCommand.SelectCommand.Connection.Dispose();      dsCommand.SelectCommand.Dispose();     }     dsCommand.Dispose();     ds.Dispose();    }   }   /// <summary>   /// 获取存储过程运行结果记录集，存储过程带4个参数   /// <\/summary>   /// <param name=\"sp_name\">存储过程名称<\/param>   /// <param name=\"par1_name\">存储过程参数名称，如\"@Age\",\"@StudentName\"<\/param>   /// <param name=\"par1_type\">存储过程参数类型，如\"int\",\"varchar\"<\/param>   /// <param name=\"par1_value\">存储过程参数值，如\"18\",\"张三\"<\/param>   /// <param name=\"par2_name\">存储过程参数名称，如\"@Age\",\"@StudentName\"<\/param>   /// <param name=\"par2_type\">存储过程参数类型，如\"int\",\"varchar\"<\/param>   /// <param name=\"par2_value\">存储过程参数值，如\"18\",\"张三\"<\/param>   /// <param name=\"par3_name\">存储过程参数名称，如\"@Age\",\"@StudentName\"<\/param>   /// <param name=\"par3_type\">存储过程参数类型，如\"int\",\"varchar\"<\/param>   /// <param name=\"par3_value\">存储过程参数值，如\"18\",\"张三\"<\/param>   /// <param name=\"par4_name\">存储过程参数名称，如\"@Age\",\"@StudentName\"<\/param>   /// <param name=\"par4_type\">存储过程参数类型，如\"int\",\"varchar\"<\/param>   /// <param name=\"par4_value\">存储过程参数值，如\"18\",\"张三\"<\/param>   /// <returns>结果记录集<\/returns>   public DataTable SelectSql_sp_par4(String sp_name,String par1_name,String par1_type,String par1_value,String par2_name,String par2_type,String par2_value,String par3_name,String par3_type,String par3_value,String par4_name,String par4_type,String par4_value)   {    int par1_dbtype=0;    int par2_dbtype=0;    int par3_dbtype=0;    int par4_dbtype=0;    if (par1_type.ToLower()==\"varchar\") par1_dbtype=Convert.ToInt16(SqlDbType.VarChar);    else if (par1_type.ToLower()==\"string\") par1_dbtype=Convert.ToInt16(SqlDbType.VarChar);    else if (par1_type.ToLower()==\"integer\") par1_dbtype=Convert.ToInt16(SqlDbType.Int);    else if (par1_type.ToLower()==\"int\") par1_dbtype=Convert.ToInt16(SqlDbType.Int);    if (par2_type.ToLower()==\"varchar\") par2_dbtype=Convert.ToInt16(SqlDbType.VarChar);    else if (par2_type.ToLower()==\"string\") par2_dbtype=Convert.ToInt16(SqlDbType.VarChar);    else if (par2_type.ToLower()==\"integer\") par2_dbtype=Convert.ToInt16(SqlDbType.Int);    else if (par2_type.ToLower()==\"int\") par2_dbtype=Convert.ToInt16(SqlDbType.Int);    if (par3_type.ToLower()==\"varchar\") par3_dbtype=Convert.ToInt16(SqlDbType.VarChar);    else if (par3_type.ToLower()==\"string\") par3_dbtype=Convert.ToInt16(SqlDbType.VarChar);    else if (par3_type.ToLower()==\"integer\") par3_dbtype=Convert.ToInt16(SqlDbType.Int);    else if (par3_type.ToLower()==\"int\") par3_dbtype=Convert.ToInt16(SqlDbType.Int);    if (par4_type.ToLower()==\"varchar\") par4_dbtype=Convert.ToInt16(SqlDbType.VarChar);    else if (par4_type.ToLower()==\"string\") par4_dbtype=Convert.ToInt16(SqlDbType.VarChar);    else if (par4_type.ToLower()==\"integer\") par4_dbtype=Convert.ToInt16(SqlDbType.Int);    else if (par4_type.ToLower()==\"int\") par4_dbtype=Convert.ToInt16(SqlDbType.Int);    dsCommand.SelectCommand=new SqlCommand();    dsCommand.SelectCommand.Connection=new SqlConnection(cn);    DataSet ds=new DataSet() ;    dsCommand.SelectCommand.CommandText=sp_name;    dsCommand.SelectCommand.CommandType=CommandType.StoredProcedure;    SqlParameter objPar;    objPar=dsCommand.SelectCommand.Parameters.Add(par1_name,par1_dbtype);    objPar.Direction=ParameterDirection.Input;    objPar.Value=par1_value;    objPar=dsCommand.SelectCommand.Parameters.Add(par2_name,par2_dbtype);    objPar.Direction=ParameterDirection.Input;    objPar.Value=par2_value;    objPar=dsCommand.SelectCommand.Parameters.Add(par3_name,par3_dbtype);    objPar.Direction=ParameterDirection.Input;    objPar.Value=par3_value;    objPar=dsCommand.SelectCommand.Parameters.Add(par4_name,par4_dbtype);    objPar.Direction=ParameterDirection.Input;    objPar.Value=par4_value;    dsCommand.SelectCommand.Connection.Open();    try    {     dsCommand.Fill(ds,\"result\");     return ds.Tables[\"result\"];    }    catch    {     return null;    }    finally    {     if (dsCommand.SelectCommand!=null)     {      if (dsCommand.SelectCommand.Connection!=null)       dsCommand.SelectCommand.Connection.Dispose();      dsCommand.SelectCommand.Dispose();     }     dsCommand.Dispose();     ds.Dispose();    }   }  /// <summary>   /// 运行insert语句，并返回成功与否   /// <\/summary>   /// <param name=\"sql\">insert语句<\/param>   /// <returns>成功与否<\/returns>   public bool InsertSql(String sql)   {    dsCommand.InsertCommand=new SqlCommand();    dsCommand.InsertCommand.Connection=new SqlConnection(cn);    dsCommand.InsertCommand.CommandText=sql;    dsCommand.InsertCommand.CommandType=CommandType.Text;    dsCommand.InsertCommand.Connection.Open();    try    {     dsCommand.InsertCommand.ExecuteNonQuery();     return true;    }    catch    {     return false;    }    finally    {     if(dsCommand.InsertCommand!=null)     {      if (dsCommand.InsertCommand.Connection!=null)       dsCommand.InsertCommand.Connection.Dispose();      dsCommand.InsertCommand.Dispose();     }     dsCommand.Dispose();    }   }   /// <summary>   /// 运行update语句，并返回成功与否   /// <\/summary>   /// <param name=\"sql\">update语句<\/param>   /// <returns>成功与否<\/returns>   public bool UpdateSql(String sql)   {    dsCommand.UpdateCommand=new SqlCommand();    dsCommand.UpdateCommand.Connection=new SqlConnection(cn);    dsCommand.UpdateCommand.CommandText=sql;    dsCommand.UpdateCommand.CommandType=CommandType.Text;    dsCommand.UpdateCommand.Connection.Open();    try    {     dsCommand.UpdateCommand.ExecuteNonQuery();     return true;    }    catch    {     return false;    }    finally    {     if (dsCommand.UpdateCommand!=null)     {      if (dsCommand.UpdateCommand.Connection!=null)       dsCommand.UpdateCommand.Connection.Dispose();      dsCommand.UpdateCommand.Dispose();     }     dsCommand.Dispose();    }   }   /// <summary>   /// 运行delete语句，并返回成功与否   /// <\/summary>   /// <param name=\"sql\">delete语句<\/param>   /// <returns>成功与否<\/returns>   public bool DeleteSql(String sql)   {    dsCommand.DeleteCommand=new SqlCommand();    dsCommand.DeleteCommand.Connection=new SqlConnection(cn);    dsCommand.DeleteCommand.CommandText=sql;    dsCommand.DeleteCommand.CommandType=CommandType.Text;    dsCommand.DeleteCommand.Connection.Open();    try    {     dsCommand.DeleteCommand.ExecuteNonQuery();     return true;    }    catch    {     return false;    }    finally    {     if (dsCommand.DeleteCommand!=null)     {      if (dsCommand.DeleteCommand.Connection!=null)       dsCommand.DeleteCommand.Connection.Dispose();      dsCommand.DeleteCommand.Dispose();     }     dsCommand.Dispose();    }   }  } }  ","title":"sqllink.cs c#数据库操作类"},{"content":"Python MySQLdb模块 2012-07-03 10:14:01     我来说两句       收藏  我要投稿  [Python]代码 view source  print ? 01 #-*- encoding: gb2312 -*- 02 import os, sys, string 03 import MySQLdb 04   05 # 连接数据库　 06 try: 07     conn = MySQLdb.connect(host='localhost',user='root',passwd='xxxx',db='test1') 08 except Exception, e: 09     print e 10     sys.exit() 11   12 # 获取cursor对象来进行操作 13   14 cursor = conn.cursor() 15 # 创建表 16 sql = \"create table if not exists test1(name varchar(128) primary key, age int(4))\" 17 cursor.execute(sql) 18 # 插入数据 19 sql = \"insert into test1(name, age) values ('%s', %d)\" % (\"zhaowei\", 23) 20 try: 21     cursor.execute(sql) 22 except Exception, e: 23     print e 24   25 sql = \"insert into test1(name, age) values ('%s', %d)\" % (\"张三\", 21) 26 try: 27     cursor.execute(sql) 28 except Exception, e: 29     print e 30 # 插入多条 31   32 sql = \"insert into test1(name, age) values (%s, %s)\" 33 val = ((\"李四\", 24), (\"王五\", 25), (\"洪六\", 26)) 34 try: 35     cursor.executemany(sql, val) 36 except Exception, e: 37     print e 38   39 #查询出数据 40 sql = \"select * from test1\" 41 cursor.execute(sql) 42 alldata = cursor.fetchall() 43 # 如果有数据返回，就循环输出, alldata是有个二维的列表 44 if alldata: 45     for rec in alldata: 46         print rec[0], rec[1] 47   48   49 cursor.close() 50   51 conn.close() Python代码                       # -*- coding: utf-8 -*-                 #mysqldb                import time, MySQLdb                               #连接                conn=MySQLdb.connect(host=\"localhost\",user=\"root\",passwd=\"\",db=\"test\",charset=\"utf8\")              cursor = conn.cursor()                               #写入                sql = \"insert into user(name,created) values(%s,%s)\"               param = (\"aaa\",int(time.time()))                n = cursor.execute(sql,param)                print n                               #更新                sql = \"update user set name=%s where id=3\"               param = (\"bbb\")                n = cursor.execute(sql,param)                print n                               #查询                n = cursor.execute(\"select * from user\")                for row in cursor.fetchall():                    for r in row:                        print r                               #删除                sql = \"delete from user where name=%s\"               param =(\"aaa\")                n = cursor.execute(sql,param)                print n                cursor.close()                               #关闭                conn.close()               基本的使用如上，还是很简单的，进一步使用还没操作，先从网上找点资料放上来，以备后续查看 1.引入MySQLdb库 import MySQLdb 2.和数据库建立连接 conn=MySQLdb.connect(host=\"localhost\",user=\"root\",passwd=\"sa\",db=\"mytable\",charset=\"utf8\") 提供的connect方法用来和数据库建立连接,接收数个参数,返回连接对象. 比较常用的参数包括 host:数据库主机名.默认是用本地主机. user:数据库登陆名.默认是当前用户. passwd:数据库登陆的秘密.默认为空. db:要使用的数据库名.没有默认值. port:MySQL服务使用的TCP端口.默认是3306. charset:数据库编码. 更多关于参数的信息可以查这里 http://mysql-python.sourceforge.net/MySQLdb.html 然后,这个连接对象也提供了对事务操作的支持,标准的方法 commit() 提交 rollback() 回滚 3.执行sql语句和接收返回值 cursor=conn.cursor() n=cursor.execute(sql,param) 首先,我们用使用连接对象获得一个cursor对象,接下来,我们会使用cursor提供的方法来进行工作.这些方法包括两大类:1.执行命令,2.接收返回值 cursor用来执行命令的方法: callproc(self, procname, args):用来执行存储过程,接收的参数为存储过程名和参数列表,返回值为受影响的行数 execute(self, query, args):执行单条sql语句,接收的参数为sql语句本身和使用的参数列表,返回值为受影响的行数 executemany(self, query, args):执行单条sql语句,但是重复执行参数列表里的参数,返回值为受影响的行数 nextset(self):移动到下一个结果集 cursor用来接收返回值的方法: fetchall(self):接收全部的返回结果行. fetchmany(self, size=None):接收size条返回结果行.如果size的值大于返回的结果行的数量,则会返回cursor.arraysize条数据. fetchone(self):返回一条结果行. scroll(self, value, mode='relative'):移动指针到某一行.如果mode='relative',则表示从当前所在行移动value条,如果mode='absolute',则表示从结果集的第一行移动value条. 下面的代码是一个完整的例子. #使用sql语句,这里要接收的参数都用%s占位符.要注意的是,无论你要插入的数据是什么类型,占位符永远都要用%s sql=\"insert into cdinfo values(%s,%s,%s,%s,%s)\" #param应该为tuple或者list param=(title,singer,imgurl,url,alpha) #执行,如果成功,n的值为1 n=cursor.execute(sql,param) #再来执行一个查询的操作 cursor.execute(\"select * from cdinfo\") #我们使用了fetchall这个方法.这样,cds里保存的将会是查询返回的全部结果.每条结果都是一个tuple类型的数据,这些tuple组成了一个tuple cds=cursor.fetchall() #因为是tuple,所以可以这样使用结果集 print cds[0][3] #或者直接显示出来,看看结果集的真实样子 print cds #如果需要批量的插入数据,就这样做 sql=\"insert into cdinfo values(0,%s,%s,%s,%s,%s)\" #每个值的集合为一个tuple,整个参数集组成一个tuple,或者list param=((title,singer,imgurl,url,alpha),(title2,singer2,imgurl2,url2,alpha2)) #使用executemany方法来批量的插入数据.这真是一个很酷的方法! n=cursor.executemany(sql,param) 4.关闭数据库连接 需要分别的关闭指针对象和连接对象.他们有名字相同的方法 cursor.close() conn.close() 5 编码（防止乱码） 需要注意的点：     1 Python文件设置编码 utf-8 （文件前面加上 #encoding=utf-8)     2 MySQL数据库charset=utf-8     3 Python连接MySQL是加上参数 charset=utf8     4 设置Python的默认编码为 utf-8 (sys.setdefaultencoding(utf-8)                   #encoding=utf-8            import sys            import MySQLdb                        reload(sys)            sys.setdefaultencoding('utf-8')                        db=MySQLdb.connect(user='root',charset='utf8')         注：MySQL的配置文件设置也必须配置成utf8 设置 MySQL 的 my.cnf 文件，在 [client]/[mysqld]部分都设置默认的字符集（通常在/etc/mysql/my.cnf)： [client] default-character-set = utf8 [mysqld] default-character-set = utf8  ","title":"Python MySQLdb模块"},{"content":"win7 64位 PowerDesigner ODBC 连接 mysql 报Connection failed 数据库安装的是MariaDB 5.5 64位，一直配置不好。下载了mysql-connector-odbc-5.2.2-winx64，发现pw链接时报错，经查询，安装32位mysql连接器，使用32位odbc配置【好像也没找到64位odbct_t】。控制面板的odbc没有的就用这个：C:\\Windows\\SysWOW64\\odbcad32.exe。然后一切顺利。 总结：64位相关的用着要慎重。","title":"数据库问题"},{"content":"性能调节的目的是通过将网络流通、磁盘 I/O 和 CPU 时间减到最小，使每个查询的响应时间最短并最大限度地提高整个数据库服务器的吞吐量。为达到此目的，需要了解应用程序的需求和数据的逻辑和物理结构，并在相互冲突的数据库使用之间（如联机事务处理 (OLTP) 与决策支持）权衡。 对性能问题的考虑应贯穿于开发阶段的全过程，不应只在最后实现系统时才考虑性能问题。许多使性能得到显著提高的性能事宜可通过开始时仔细设计得以实现。为最有效地优化 Microsoft® SQL Server™ 2000 的性能，必须在极为多样化的情形中识别出会使性能提升最多的区域，并对这些区域集中分析。 虽然其它系统级性能问题（如内存、硬件等）也是研究对象，但经验表明从这些方面获得的性能收益通常会增长。通常情况下，SQL Server 自动管理可用的硬件资源，从而减少对大量的系统级手动调节任务的需求（以及从中所得的收益）。 目录： 设计联合数据库服务器：描述如何通过将处理负荷分摊在多个服务器间而达到高性能级别（如大型 Web 站点等所需的性能级别）。 1 数据库设计：描述数据库设计如何成为提高总体性能的最有效途径。数据库设计包括逻辑数据库架构（如表和约束）和物理特性（如磁盘系统、对象位置和索引）。... 2 查询优化：描述正确设计的查询（用于应用程序）如何显著提高性能。... 3 应用程序设计：描述正确设计的用户应用程序如何显著提高性能。应用程序设计包括事务边界、锁定和批处理的使用。    4 优化实用工具和工具性能：述及 Microsoft SQL Server 2000 提供的实用工具和工具的一些可用选项，描述这些选项如何突出说明提高这些工具的性能的方法，以及同时运行这些工具和应用程序的效果。... 5 优化服务器性能：描述如何更改操作系统（Microsoft Windows NT®、Microsoft Windows® 95、Microsoft Windows 98 或 Microsoft Windows 2000）和 SQL Server 的设置以提高总体性能。... 6 操作系统相关优化:描述操作系统和数据库之间可改善的方面…………………………………………………7 设计联合数据库服务器 为达到大型 Web 站点所需的高性能级别，多层系统一般在多个服务器之间平衡每一层的处理负荷。Microsoft® SQL Server™ 2000 通过对 SQL Server 数据进行水平分区，在一组服务器之间分摊数据库处理负荷。这些服务器相互独立，但也可以相互协作以处理来自应用程序的数据库请求；这样的一组协作服务器称为联合体。 只有当应用程序将每个 SQL 语句发送到拥有该语句所需的大部分数据的成员服务器时，联合数据库层才可以达到非常高的性能级别。这称为使用语句所需的数据配置 SQL 语句。使用所需的数据配置 SQL 语句不是联合服务器所独有的要求；在群集系统中同样有此要求。 虽然服务器联合体与单个数据库服务器呈现给应用程序的图像相同，但在实现数据库服务层的方式上存在内部差异。 单个服务器层 联合服务器层 生产服务器上有一个 SQL Server 实例。 每个成员服务器上都有一个 SQL Server 实例。 生产数据存储在一个数据库中。 每个成员服务器都有一个成员数据库。数据分布在成员数据库之间。 一般每个表都是单个实体。 原始数据库中的表被水平分区为成员表。一个成员数据库有一个成员表，而且使用分布式分区视图使每个成员服务器上看起来似乎都有原始表的完整复本。 与单个服务器的所有连接和所有 SQL 语句都由 SQL Server 的同一个实例处理。 应用程序层必须能够在包含语句所引用的大部分数据的成员服务器上配置 SQL 语句。 虽然目的是设计数据库服务器联合体来处理全部的工作负荷，但是可通过设计一组在不同的服务器之间分布数据的分布式分区视图来达到此目的。 数据库设计 数据库的设计包括两个组成部分：逻辑设计和物理设计。逻辑数据库设计包括使用数据库组件（如表和约束）为业务需求和数据建模，而无须考虑如何或在哪里物理存储这些数据。物理数据库设计包括将逻辑设计映射到物理媒体上、利用可用的硬件和软件功能使得尽可能快地对数据进行物理访问和维护，还包括生成索引。要在设计后更改这些组件很困难，因此在数据库应用程序开发的早期阶段正确设计数据库、使其为业务需求建模并利用硬件和软件功能很重要。 实现SQL Server数据库的优化，首先要有一个好的数据库设计方案。在实际工作中，许多SQL Server方案往往是由于数据库设计得不好导致性能很差。实现良好的数据库设计必须考虑这些问题: 1.1　逻辑库规范化问题 一般来说，逻辑数据库设计会满足规范化的前3级标准: 1.第1规范:没有重复的组或多值的列。 2.第2规范:每个非关键字段必须依赖于主关键字，不能依赖于1个组合式主关键字的某些组成部分。 3.第3规范:1个非关键字段不能依赖于另1个非关键字段。 　　遵守这些规则的设计会产生较少的列和更多的表，因而也就减少了数据冗余，也减少了用于存储数据的页。但表关系也许需要通过复杂的合并来处理，这样会降低系统的性能。某种程度上的非规范化可以改善系统的性能，非规范化过程可以根据性能方面不同的考虑用多种不同的方法进行，但以下方法经实践验证往往能提高性能。 1.如果规范化设计产生了许多4路或更多路合并关系，就可以考虑在数据库实体(表)中加入重复属性(列) 2.常用的计算字段(如总计、最大值等)可以考虑存储到数据库实体中。 　　比如某一个项目的计划管理系统中有计划表，其字段为:项目编号、年初计划、二次计划、调整计划、补列计划…，而计划总数(年初计划+二次计划+调整计划+补列计划)是用户经常需要在查询和报表中用到的，在表的记录量很大时，有必要把计划总数作为1个独立的字段加入到表中。这里可以采用触发器以在客户端保持数据的一致性。 3.重新定义实体以减少外部属性数据或行数据的开支。相应的非规范化类型是: 　　(1)把1个实体(表)分割成2个表(把所有的属性分成2组)。这样就把频繁被访问的数据同较少被访问的数据分开了。这种方法要求在每个表中复制首要关键字。这样产生的设计有利于并行处理，并将产生列数较少的表。 　　(2)把1个实体(表)分割成2个表(把所有的行分成2组)。这种方法适用于那些将包含大量数据的实体(表)。在应用中常要保留历史记录，但是历史记录很少用到。因此可以把频繁被访问的数据同较少被访问的历史数据分开。而且如果数据行是作为子集被逻辑工作组(部门、销售分区、地理区域等)访问的，那么这种方法也是很有好处的。 　1.2　生成物理数据库 　　要想正确选择基本物理实现策略，必须懂得数据库访问格式和硬件资源的操作特点，主要是内存和磁盘子系统I/O。这是一个范围广泛的话题，但以下的准则可能会有所帮助。 　　1.与每个表列相关的数据类型应该反映数据所需的最小存储空间，特别是对于被索引的列更是如此。比如能使用smallint类型就不要用integer类型，这样索引字段可以被更快地读取，而且可以在1个数据页上放置更多的数据行，因而也就减少了I/O操作。 　　2.把1个表放在某个物理设备上，再通过SQL Server段把它的不分簇索引放在1个不同的物理设备上，这样能提高性能。尤其是系统采用了多个智能型磁盘控制器和数据分离技术的情况下，这样做的好处更加明显。 　　3.用SQL Server段把一个频繁使用的大表分割开，并放在2个单独的智能型磁盘控制器的数据库设备上，这样也可以提高性能。因为有多个磁头在查找，所以数据分离也能提高性能。 　　4.用SQL Server段把文本或图像列的数据存放在1个单独的物理设备上可以提高性能。1个专用的智能型的控制器能进一步提高性能。 查询优化 查询速度慢的原因很多，常见如下几种：　　 　　1、没有索引或者没有用到索引(这是查询慢最常见的问题，是程序设计的缺陷)　　 　　2、I/O吞吐量小，形成了瓶颈效应。　　 　　3、没有创建计算列导致查询不优化。　　 　　4、内存不足　　 　　5、网络速度慢　　 　　6、查询出的数据量过大（可以采用多次查询，其他的方法降低数据量）　　 　　7、锁或者死锁(这也是查询慢最常见的问题，是程序设计的缺陷)　　 　　8、sp_lock,sp_who,活动的用户查看,原因是读写竞争资源。　　 　　9、返回了不必要的行和列　　 10、查询语句不好，没有优化 可以通过如下方法来优化查询 :　　 　　1、把数据、日志、索引放到不同的I/O设备上，增加读取速度，以前可以将Tempdb应放在RAID0上，SQL2000不在支持。数据量（尺寸）越大，提高I/O越重要.　　 　　2、纵向、横向分割表，减少表的尺寸(sp_spaceuse)　　 　　3、升级硬件　　 　　4、根据查询条件,建立索引,优化索引、优化访问方式，限制结果集的数据量。注意填充因子要适当（最好是使用默认值0）。索引应该尽量小，使用字节数小的列建索引好（参照索引的创建）,不要对有限的几个值的字段建单一索引如性别字段　　 　　5、提高网速;　　 　　6、扩大服务器的内存,Windows 2000和SQL server 2000能支持4-8G的内存。配置虚拟内存：虚拟内存大小应基于计算机上并发运行的服务进行配置。运行 Microsoft SQL Server? 2000 时，可考虑将虚拟内存大小设置为计算机中安装的物理内存的 1.5 倍。如果另外安装了全文检索功能，并打算运行 Microsoft 搜索服务以便执行全文索引和查询，可考虑：将虚拟内存大小配置为至少是计算机中安装的物理内存的 3 倍。将 SQL Server max server memory 服务器配置选项配置为物理内存的 1.5 倍（虚拟内存大小设置的一半）。　　 　　7、增加服务器 CPU个数;但是必须明白并行处理串行处理更需要资源例如内存。使用并行还是串行程是MsSQL自动评估选择的。单个任务分解成多个任务，就可以在处理器上运行。例如耽搁查询的排序、连接、扫描和GROUP BY字句同时执行，SQL SERVER根据系统的负载情况决定最优的并行等级，复杂的需要消耗大量的CPU的查询最适合并行处理。但是更新操作Update,Insert， Delete还不能并行处理。　　 　　8、如果是使用like进行查询的话，简单的使用index是不行的，但是全文索引，耗空间。 like 'a%' 使用索引 like '%a' 不使用索引用 like '%a%' 查询时，查询耗时和字段值总长度成正比,所以不能用CHAR类型，而是VARCHAR。对于字段的值很长的建全文索引。　　 　　9、DB Server 和APPLication Server 分离；OLTP和OLAP分离　　 　　10、分布式分区视图可用于实现数据库服务器联合体。联合体是一组分开管理的服务器，但它们相互协作分担系统的处理负荷。这种通过分区数据形成数据库服务器联合体的机制能够扩大一组服务器，以支持大型的多层 Web 站点的处理需要。有关更多信息，参见设计联合数据库服务器。（参照SQL帮助文件'分区视图'）　　 　　a、在实现分区视图之前，必须先水平分区表　　 　　b、在创建成员表后，在每个成员服务器上定义一个分布式分区视图，并且每个视图具有相同的名称。这样，引用分布式分区视图名的查询可以在任何一个成员服务器上运行。系统操作如同每个成员服务器上都有一个原始表的复本一样，但其实每个服务器上只有一个成员表和一个分布式分区视图。数据的位置对应用程序是透明的。　　 　　11、重建索引 DBCC REINDEX ,DBCC INDEXDEFRAG,收缩数据和日志 DBCC SHRINKDB,DBCC SHRINKFILE. 设置自动收缩日志.对于大的数据库不要设置数据库自动增长，它会降低服务器的性能。在T-sql的写法上有很大的讲究，下面列出常见的要点：首先，DBMS处理查询计划的过程是这样的：　　 　　 1、查询语句的词法、语法检查　　 　　 2、将语句提交给DBMS的查询优化器　　 　　 3、优化器做代数优化和存取路径的优化　　 　　 4、由预编译模块生成查询规划　　 　　 5、然后在合适的时间提交给系统处理执行　　 　　 6、最后将执行结果返回给用户其次，看一下SQL SERVER的数据存放的结构：一个页面的大小为8K(8060)字节，8个页面为一个盘区，按照B树存放。　　 　　12、Commit和rollback的区别 Rollback:回滚所有的事物。 Commit:提交当前的事物. 没有必要在动态SQL里写事物，如果要写请写在外面如： begin tran exec(@s) commit trans 或者将动态SQL 写成函数或者存储过程。　　 　　13、在查询Select语句中用Where字句限制返回的行数,避免表扫描,如果返回不必要的数据，浪费了服务器的I/O资源，加重了网络的负担降低性能。如果表很大，在表扫描的期间将表锁住，禁止其他的联接访问表,后果严重。　　 　　14、SQL的注释申明对执行没有任何影响 　　15、尽可能不使用光标，它占用大量的资源。如果需要row-by-row地执行，尽量采用非光标技术,如：在客户端循环，用临时表，Table变量，用子查询，用Case语句等等。游标可以按照它所支持的提取选项进行分类：只进必须按照从第一行到最后一行的顺序提取行。FETCH NEXT 是唯一允许的提取操作,也是默认方式。可滚动性可以在游标中任何地方随机提取任意行。游标的技术在SQL2000下变得功能很强大，他的目的是支持循环。有四个并发选项 READ_ONLY：不允许通过游标定位更新(Update)，且在组成结果集的行中没有锁。 OPTIMISTIC WITH valueS:乐观并发控制是事务控制理论的一个标准部分。乐观并发控制用于这样的情形，即在打开游标及更新行的间隔中，只有很小的机会让第二个用户更新某一行。当某个游标以此选项打开时，没有锁控制其中的行，这将有助于最大化其处理能力。如果用户试图修改某一行，则此行的当前值会与最后一次提取此行时获取的值进行比较。如果任何值发生改变，则服务器就会知道其他人已更新了此行，并会返回一个错误。如果值是一样的，服务器就执行修改。选择这个并发选项OPTIMISTIC WITH ROW VERSIONING:此乐观并发控制选项基于行版本控制。使用行版本控制，其中的表必须具有某种版本标识符，服务器可用它来确定该行在读入游标后是否有所更改。在 SQL Server 中，这个性能由 timestamp 数据类型提供，它是一个二进制数字，表示数据库中更改的相对顺序。每个数据库都有一个全局当前时间戳值：@@DBTS。每次以任何方式更改带有 timestamp 列的行时，SQL Server 先在时间戳列中存储当前的 @@DBTS 值，然后增加 @@DBTS 的值。如果某个表具有 timestamp 列，则时间戳会被记到行级。服务器就可以比较某行的当前时间戳值和上次提取时所存储的时间戳值，从而确定该行是否已更新。服务器不必比较所有列的值，只需比较 timestamp 列即可。如果应用程序对没有 timestamp 列的表要求基于行版本控制的乐观并发，则游标默认为基于数值的乐观并发控制。 SCROLL LOCKS 这个选项实现悲观并发控制。在悲观并发控制中，在把数据库的行读入游标结果集时，应用程序将试图锁定数据库行。在使用服务器游标时，将行读入游标时会在其上放置一个更新锁。如果在事务内打开游标，则该事务更新锁将一直保持到事务被提交或回滚；当提取下一行时，将除去游标锁。如果在事务外打开游标，则提取下一行时，锁就被丢弃。因此，每当用户需要完全的悲观并发控制时，游标都应在事务内打开。更新锁将阻止任何其它任务获取更新锁或排它锁，从而阻止其它任务更新该行。然而，更新锁并不阻止共享锁，所以它不会阻止其它任务读取行，除非第二个任务也在要求带更新锁的读取。滚动锁根据在游标定义的 Select 语句中指定的锁提示，这些游标并发选项可以生成滚动锁。滚动锁在提取时在每行上获取，并保持到下次提取或者游标关闭，以先发生者为准。下次提取时，服务器为新提取中的行获取滚动锁，并释放上次提取中行的滚动锁。滚动锁独立于事务锁，并可以保持到一个提交或回滚操作之后。如果提交时关闭游标的选项为关，则 COMMIT 语句并不关闭任何打开的游标，而且滚动锁被保留到提交之后，以维护对所提取数据的隔离。所获取滚动锁的类型取决于游标并发选项和游标 Select 语句中的锁提示。锁提示只读乐观数值乐观行版本控制锁定无提示未锁定未锁定未锁定更新 NOLOCK 未锁定未锁定未锁定未锁定 HOLDLOCK 共享共享共享更新 UPDLOCK 错误更新更新更新 TABLOCKX 错误未锁定未锁定更新其它未锁定未锁定未锁定更新 *指定 NOLOCK 提示将使指定了该提示的表在游标内是只读的。　　 　　16、用Profiler来跟踪查询，得到查询所需的时间，找出SQL的问题所在;用索引优化器优化索引　　 　　17、注意UNion和UNion all 的区别。UNION all好　　 　　18、注意使用DISTINCT，在没有必要时不要用，它同UNION一样会使查询变慢。重复的记录在查询里是没有问题的　　 　　19、查询时不要返回不需要的行、列　　 　　20、用sp_configure 'query governor cost limit'或者SET QUERY_GOVERNOR_COST_LIMIT来限制查询消耗的资源。当评估查询消耗的资源超出限制时，服务器自动取消查询,在查询之前就扼杀掉。 SET LOCKTIME设置锁的时间　　 　　21、用select top 100 / 10 Percent 来限制用户返回的行数或者SET ROWCOUNT来限制操作的行　　 　　22、在SQL2000以前，一般不要用如下的字句: \"IS NULL\", \"<>\", \"!=\", \"!>\", \"!<\", \"NOT\", \"NOT EXISTS\", \"NOT IN\", \"NOT LIKE\", and \"LIKE '%500'\"，因为他们不走索引全是表扫描。也不要在Where字句中的列名加函数，如Convert，substring等,如果必须用函数的时候，创建计算列再创建索引来替代.还可以变通写法：Where SUBSTRING(firstname,1,1) = 'm'改为Where firstname like 'm%'（索引扫描），一定要将函数和列名分开。并且索引不能建得太多和太大。NOT IN会多次扫描表，使用EXISTS、NOT EXISTS ，IN , LEFT OUTER JOIN 来替代，特别是左连接,而Exists比IN更快，最慢的是NOT操作.如果列的值含有空，以前它的索引不起作用，现在2000的优化器能够处理了。相同的是IS NULL，\"NOT\", \"NOT EXISTS\", \"NOT IN\"能优化她，而\"<>\"等还是不能优化，用不到索引。　　 　　23、使用Query Analyzer，查看SQL语句的查询计划和评估分析是否是优化的SQL。一般的20%的代码占据了80%的资源，我们优化的重点是这些慢的地方。　　 　　24、如果使用了IN或者OR等时发现查询没有走索引，使用显示申明指定索引： Select * FROM PersonMember (INDEX = IX_Title) Where processid IN ('男'，'女')　　 　　25、将需要查询的结果预先计算好放在表中，查询的时候再Select。这在SQL7.0以前是最重要的手段。例如医院的住院费计算。　　 　　26、MIN() 和 MAX()能使用到合适的索引。　　 　　27、数据库有一个原则是代码离数据越近越好，所以优先选择Default,依次为Rules,Triggers, Constraint（约束如外健主健CheckUNIQUE……,数据类型的最大长度等等都是约束）,Procedure.这样不仅维护工作小，编写程序质量高，并且执行的速度快。　　 　　28、如果要插入大的二进制值到Image列，使用存储过程，千万不要用内嵌Insert来插入(不知JAVA是否)。因为这样应用程序首先将二进制值转换成字符串（尺寸是它的两倍），服务器受到字符后又将他转换成二进制值.存储过程就没有这些动作: 方法：Create procedure p_insert as insert into table(Fimage) values (@image), 在前台调用这个存储过程传入二进制参数，这样处理速度明显改善。　　 　　29、Between在某些时候比IN 速度更快,Between能够更快地根据索引找到范围。用查询优化器可见到差别。 select * from chineseresume where title in ('男','女') Select * from chineseresume where between '男' and '女' 是一样的。由于in会在比较多次，所以有时会慢些。　　 　　30、在必要是对全局或者局部临时表创建索引，有时能够提高速度，但不是一定会这样，因为索引也耗费大量的资源。他的创建同是实际表一样。　　 　　31、不要建没有作用的事物例如产生报表时，浪费资源。只有在必要使用事物时使用它。　　 　　32、用OR的字句可以分解成多个查询，并且通过UNION 连接多个查询。他们的速度只同是否使用索引有关,如果查询需要用到联合索引，用UNION all执行的效率更高.多个OR的字句没有用到索引，改写成UNION的形式再试图与索引匹配。一个关键的问题是否用到索引。　　 　　 33、尽量少用视图，它的效率低。对视图操作比直接对表操作慢,可以用stored procedure来代替她。特别的是不要用视图嵌套,嵌套视图增加了寻找原始资料的难度。我们看视图的本质：它是存放在服务器上的被优化好了的已经产生了查询规划的SQL。对单个表检索数据时，不要使用指向多个表的视图，直接从表检索或者仅仅包含这个表的视图上读，否则增加了不必要的开销,查询受到干扰.为了加快视图的查询，MsSQL增加了视图索引的功能。　　 　　34、没有必要时不要用DISTINCT和ORDER BY，这些动作可以改在客户端执行。它们增加了额外的开销。这同UNION 和UNION ALL一样的道理。　　　 　　35、在IN后面值的列表中，将出现最频繁的值放在最前面，出现得最少的放在最后面，减少判断的次数。　　 　　36、当用Select INTO时，它会锁住系统表(sysobjects，sysindexes等等)，阻塞其他的连接的存取。创建临时表时用显示申明语句，而不是 select INTO. drop table t_lxh begin tran select * into t_lxh from chineseresume where name = 'XYZ' --commit 在另一个连接中Select * from sysobjects可以看到 Select INTO 会锁住系统表，Create table 也会锁系统表(不管是临时表还是系统表)。所以千万不要在事物内使用它！！！这样的话如果是经常要用的临时表请使用实表，或者临时表变量。　　 　　37、一般在GROUP BY 个HAVING字句之前就能剔除多余的行，所以尽量不要用它们来做剔除行的工作。他们的执行顺序应该如下最优：select 的Where字句选择所有合适的行，Group By用来分组个统计行，Having字句用来剔除多余的分组。这样Group By 个Having的开销小，查询快.对于大的数据行进行分组和Having十分消耗资源。如果Group BY的目的不包括计算，只是分组，那么用Distinct更快　　 　　38、一次更新多条记录比分多次更新每次一条快,就是说批处理好　　 　　39、少用临时表，尽量用结果集和Table类性的变量来代替它,Table 类型的变量比临时表好　　 　　40、在SQL2000下，计算字段是可以索引的，需要满足的条件如下：　　 　　a、计算字段的表达是确定的　　 　　b、不能用在TEXT,Ntext，Image数据类型　　 　　c、必须配制如下选项 ANSI_NULLS = ON, ANSI_PADDINGS = ON, …….　　 　　41、尽量将数据的处理工作放在服务器上，减少网络的开销，如使用存储过程。存储过程是编译好、优化过、并且被组织到一个执行规划里、且存储在数据库中的SQL语句，是控制流语言的集合，速度当然快。反复执行的动态SQL,可以使用临时存储过程，该过程（临时表）被放在Tempdb中。以前由于SQL SERVER对复杂的数学计算不支持，所以不得不将这个工作放在其他的层上而增加网络的开销。SQL2000支持UDFs,现在支持复杂的数学计算，函数的返回值不要太大，这样的开销很大。用户自定义函数象光标一样执行的消耗大量的资源，如果返回大的结果采用存储过程　　 　　42、不要在一句话里再三的使用相同的函数，浪费资源,将结果放在变量里再调用更快　　 　　43、Select COUNT(*)的效率教低，尽量变通他的写法，而EXISTS快.同时请注意区别： select count(Field of null) from Table 和 select count(Field of NOT null) from Table 的返回值是不同的！！！　　 　　44、当服务器的内存够多时，配制线程数量 = 最大连接数+5，这样能发挥最大的效率；否则使用配制线程数量<最大连接数启用SQL SERVER的线程池来解决,如果还是数量 = 最大连接数+5，严重的损害服务器的性能。　　 　　45、按照一定的次序来访问你的表。如果你先锁住表A，再锁住表B，那么在所有的存储过程中都要按照这个顺序来锁定它们。如果你（不经意的）某个存储过程中先锁定表B，再锁定表A，这可能就会导致一个死锁。如果锁定顺序没有被预先详细的设计好，死锁很难被发现　　 　　46、通过SQL Server Performance Monitor监视相应硬件的负载 Memory: Page Faults / sec计数器如果该值偶尔走高，表明当时有线程竞争内存。如果持续很高，则内存可能是瓶颈。 　　Process:　　 　　1、% DPC Time 指在范例间隔期间处理器用在缓延程序调用(DPC)接收和提供服务的百分比。(DPC 正在运行的为比标准间隔优先权低的间隔)。由于 DPC 是以特权模式执行的，DPC 时间的百分比为特权时间百分比的一部分。这些时间单独计算并且不属于间隔计算总数的一部分。这个总数显示了作为实例时间百分比的平均忙时。　　 　　2、%Processor Time计数器　如果该参数值持续超过95%，表明瓶颈是CPU。可以考虑增加一个处理器或换一个更快的处理器。　　 　　3、% Privileged Time 指非闲置处理器时间用于特权模式的百分比。(特权模式是为操作系统组件和操纵硬件驱动程序而设计的一种处理模式。它允许直接访问硬件和所有内存。另一种模式为用户模式，它是一种为应用程序、环境分系统和整数分系统设计的一种有限处理模式。操作系统将应用程序线程转换成特权模式以访问操作系统服务)。特权时间的 % 包括为间断和 DPC 提供服务的时间。特权时间比率高可能是由于失败设备产生的大数量的间隔而引起的。这个计数器将平均忙时作为样本时间的一部分显示。　　 　　4、% User Time表示耗费CPU的数据库操作，如排序，执行aggregate functions等。如果该值很高，可考虑增加索引，尽量使用简单的表联接，水平分割大表格等方法来降低该值。 Physical Disk: Curretn Disk Queue Length计数器该值应不超过磁盘数的1.5~2倍。要提高性能，可增加磁盘。 SQLServer:Cache Hit Ratio计数器该值越高越好。如果持续低于80%，应考虑增加内存。注意该参数值是从SQL Server启动后，就一直累加记数，所以运行经过一段时间后，该值将不能反映系统当前值。　　 　　47、分析select emp_name form employee where salary > 3000 在此语句中若salary是Float类型的，则优化器对其进行优化为Convert(float,3000)，因为3000是个整数，我们应在编程时使用3000.0而不要等运行时让DBMS进行转化。同样字符和整型数据的转换。　　 　　48、查询的关联同写的顺序　　 　　select a.personMemberID, * from chineseresume a,personmember b where personMemberID = b.referenceid and a.personMemberID = 'JCNPRH39681' （A = B ,B = '号码'）　　 　　select a.personMemberID, * from chineseresume a,personmember b where a.personMemberID = b.referenceid and a.personMemberID = 'JCNPRH39681' and b.referenceid = 'JCNPRH39681' （A = B ,B = '号码'， A = '号码'）　　 　　select a.personMemberID, * from chineseresume a,personmember b where b.referenceid = 'JCNPRH39681' and a.personMemberID = 'JCNPRH39681' （B = '号码'， A = '号码'）　　 　　49、　　 　　(1)IF 没有输入负责人代码 THEN code1=0 code2=9999 ELSE code1=code2=负责人代码 END IF 执行SQL语句为: Select 负责人名 FROM P2000 Where 负责人代码>=:code1 AND负责人代码 <=:code2　　 　　(2)IF 没有输入负责人代码 THEN 　Select 负责人名 FROM P2000 ELSE code= 负责人代码 Select 负责人代码 FROM P2000 Where 负责人代码=:code END IF 第一种方法只用了一条SQL语句,第二种方法用了两条SQL语句。在没有输入负责人代码时,第二种方法显然比第一种方法执行效率高,因为它没有限制条件; 在输入了负责人代码时,第二种方法仍然比第一种方法效率高,不仅是少了一个限制条件,还因相等运算是最快的查询运算。我们写程序不要怕麻烦　　 　　50、关于JOBCN现在查询分页的新方法（如下），用性能优化器分析性能的瓶颈，如果在I/O或者网络的速度上，如下的方法优化切实有效，如果在CPU或者内存上，用现在的方法更好。请区分如下的方法，说明索引越小越好。　　 　　begin　　 　　DECLARE @local_variable table (FID int identity(1,1),ReferenceID varchar(20))　　 　　insert into @local_variable (ReferenceID)　　 　　select top 100000 ReferenceID from chineseresume order by ReferenceID　　 　　select * from @local_variable where Fid > 40 and fid <= 60　　 　　end 和 　　 　　begin　　 　　DECLARE @local_variable table (FID int identity(1,1),ReferenceID varchar(20))　　 　　insert into @local_variable (ReferenceID)　　 　　select top 100000 ReferenceID from chineseresume order by updatedate　　 　　select * from @local_variable where Fid > 40 and fid <= 60　　 　　end 的不同 　　 　　begin　　 　　create table #temp (FID int identity(1,1),ReferenceID varchar(20))　　 　　insert into #temp (ReferenceID)　　 　　select top 100000 ReferenceID from chineseresume order by updatedate　　 　　select * from #temp where Fid > 40 and fid <= 60 drop table #temp　　 　　end 完全通过系统级服务器性能优化（如内存大小、文件系统类型、处理器的数目及类型等）解决性能问题可能很诱人。但经验表明大多数性能问题不能用这种方法解决。必须通过这些方法解决性能问题：分析应用程序以及应用程序提交给数据库的查询和更新，并分析这些查询和更新如何与数据库架构交互。 持续时间意外地长的查询和更新可能由下列原因引起： ·                     网络通讯速度慢。 ·                     服务器计算机的内存不足或 Microsoft® SQL Server™ 2000 可用的内存不足。 ·                     缺少有用的统计数据。 ·                     统计数据过期。 ·                     缺少有用的索引 ·                     缺少有用的数据条带化。 当查询或更新花费的时间比预期的长时，使用下面的检查清单提高性能： 说明  建议在与技术支持提供商联系之前先参考该检查清单。 1.              性能问题与查询以外的组件是否有关？例如，问题是否为网络性能慢？是否有任何其它可能引起或间接导致性能下降的组件？可以使用 Windows NT 性能监视器监视与 SQL Server 相关和与 SQL Server 不相关的组件性能。有关更多信息，请参见使用系统监视器进行监视。 2.              如果性能问题与查询相关，涉及哪个查询或哪组查询？使用 SQL 事件探查器帮助识别慢速查询。有关更多信息，请参见使用 SQL 事件探查器进行监视。 通过使用 SET 语句启用 SHOWPLAN、STATISTICS IO、STATISTICS TIME 和 STATISTICS PROFILE 选项，可以确定数据库查询性能。 ·                             SHOWPLAN 描述 SQL Server 查询优化器选择的数据检索方法。有关更多信息，请参见 SET SHOWPLAN_ALL。 ·                             STATISTICS IO 报告与语句内引用的每个表的扫描数、逻辑读取数（在高速缓存中访问的页数）和物理读取数（访问磁盘的次数）有关的信息。有关更多信息，请参见 SET STATISTICS IO。 ·                             STATISTICS TIME 显示分析、编译和执行查询所需的时间（以毫秒为单位）。有关更多信息，请参见 SET STATISTICS TIME。 ·                             STATISTICS PROFILE 显示每个查询执行后的结果集，代表查询执行的配置文件。有关更多信息，请参见 SET STATISTICS PROFILE。 在 SQL 查询分析器中，还可以打开 graphical execution plan 选项查看关于 SQL Server 如何检索数据的图形表示。 由这些工具收集的信息使您得以确定 SQL Server 查询优化器正在如何执行查询以及正在使用哪些索引。利用这些信息，可以确定通过重写查询、更改表上的索引或修改数据库设计等方法能否提高性能。有关更多信息，请参见分析查询。 3.              是否已经用有用的统计数据优化查询？ SQL Server 自动在索引列上创建对列内的值分布情况的统计。也可以使用 SQL 查询分析器或 CREATE STATISTICS 语句在非索引列上手动创建统计；或者如果将 auto create statistics 数据库选项设置为 true，则自动在非索引列上创建统计。查询处理器可以利用这些统计确定最佳的查询评估策略。在联接操作所涉及的非索引列上维护附加的统计信息可以提高查询性能。有关更多信息，请参见统计信息。 使用 SQL 事件探查器或 SQL 查询分析器内的图形执行计划来监视查询，以确定查询是否有足够的统计信息。有关更多信息，请参见错误和警告事件分类。 4.              查询统计信息是否为最新？统计信息是否自动更新？ SQL Server 自动在索引列上创建并更新查询统计（只要没有禁用自动查询统计更新特性）。另外，可以使用 SQL 查询分析器或 UPDATE STATISTICS 语句在非索引列上手工更新统计；或者如果 auto update statistics 数据库选项设置为 true，则自动在非索引列上更新统计。最新的统计不取决于日期或时间数据。如果尚未进行 UPDATE 操作，则查询统计信息仍是最新的。 如果没有将统计设置为自动更新，则应设置为自动更新。有关更多信息，请参见统计信息。 5.              是否有合适的索引？添加一个或多个索引是否会提高查询性能？有关更多信息，请参见索引优化建议。 6.              是否有任何数据热点或索引热点？如果有，考虑使用磁盘条带化。有关更多信息，请参见使用文件组放置数据和 RAID。 7.              是否为查询优化器提供了优化复杂查询的最有利条件？有关更多信息，请参见查询优化建议。 存储过程的优化： 一、前言：在经过一段时间的存储过程开发之后，写下了一些开发时候的小结和经验与大家共享，希望对大家有益，主要是针对Sybase和SQL Server数据库，但其它数据库应该有一些共性。 二、适合读者对象：数据库开发程序员，数据库的数据量很多，涉及到对SP（存储过程）的优化的项目开发人员，对数据库有浓厚兴趣的人。 三、介绍：在数据库的开发过程中，经常会遇到复杂的业务逻辑和对数据库的操作，这个时候就会用SP来封装数据库操作。如果项目的SP较多，书写又没有一定的规范，将会影响以后的系统维护困难和大SP逻辑的难以理解，另外如果数据库的数据量大或者项目对SP的性能要求很，就会遇到优化的问题，否则速度有可能很慢，经过亲身经验，一个经过优化过的SP要比一个性能差的SP的效率甚至高几百倍。 四、内容： 1、开发人员如果用到其他库的Table或View，务必在当前库中建立View来实现跨库操作，最好不要直接使用“databse.dbo.table_name”，因为sp_depends不能显示出该SP所使用的跨库table或view，不方便校验。 2、开发人员在提交SP前，必须已经使用set showplan on分析过查询计划，做过自身的查询优化检查。 3、高程序运行效率，优化应用程序，在SP编写过程中应该注意以下几点： a) SQL的使用规范： i. 尽量避免大事务操作，慎用holdlock子句，提高系统并发能力。 ii. 尽量避免反复访问同一张或几张表，尤其是数据量较大的表，可以考虑先根据条件提取数据到临时表中，然后再做连接。 iii.尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该改写；如果使用了游标，就要尽量避免在游标循环中再进行表连接的操作。 iv. 注意where字句写法，必须考虑语句顺序，应该根据索引顺序、范围大小来确定条件子句的前后顺序，尽可能的让字段顺序与索引顺序相一致，范围从大到小。 v. 不要在where子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。 vi. 尽量使用exists代替select count(1)来判断是否存在记录，count函数只有在统计表中所有行数时使用，而且count(1)比count(*)更有效率。 vii.尽量使用“>=”，不要使用“>”。 viii.注意一些or子句和union子句之间的替换 ix.注意表之间连接的数据类型，避免不同类型数据之间的连接。 x. 注意存储过程中参数和数据类型的关系。 xi.注意insert、update操作的数据量，防止与其他应用冲突。如果数据量超过200个数据页面（400k），那么系统将会进行锁升级，页级锁会升级成表级锁。 b) 索引的使用规范： i. 索引的创建要与应用结合考虑，建议大的OLTP表不要超过6个索引。 ii. 尽可能的使用索引字段作为查询条件，尤其是聚簇索引，必要时可以通过index index_name来强制指定索引 iii.避免对大表查询时进行table scan，必要时考虑新建索引。 iv. 在使用索引字段作为条件时，如果该索引是联合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用。 v. 要注意索引的维护，周期性重建索引，重新编译存储过程。 c)tempdb的使用规范： i. 尽量避免使用distinct、order by、group by、having、join、cumpute，因为这些语句会加重tempdb的负担。 ii. 避免频繁创建和删除临时表，减少系统表资源的消耗。 iii.在新建临时表时，如果一次性插入数据量很大，那么可以使用select into代替create table，避免log，提高速度；如果数据量不大，为了缓和系统表的资源，建议先create table，然后insert。 iv. 如果临时表的数据量较大，需要建立索引，那么应该将创建临时表和建立索引的过程放在单独一个子存储过程中，这样才能保证系统能够很好的使用到该临时表的索引。 v. 如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先truncate table，然后drop table，这样可以避免系统表的较长时间锁定。 vi. 慎用大的临时表与其他大表的连接查询和修改，减低系统表负担，因为这种操作会在一条语句中多次使用tempdb的系统表。 d)合理的算法使用： 根据上面已提到的SQL优化技术和ASE Tuning手册中的SQL优化内容,结合实际应用,采用多种算法进行比较,以获得消耗资源最少、效率最高的方法。具体可用ASE调优命令：set statistics io on, set statistics time on , set showplan on 等。 以下是一些常用的优化需要注意的方面： 操作符优化 IN 操作符 用IN写出来的SQL的优点是比较容易写及清晰易懂，这比较适合现代软件开发的风格。 但是用IN的SQL性能总是比较低的，从ORACLE执行的步骤来分析用IN的SQL与不用IN的SQL有以下区别： ORACLE试图将其转换成多个表的连接，如果转换不成功则先执行IN里面的子查询，再查询外层的表记录，如果转换成功则直接采用多个表的连接方式查询。由此可见用IN的SQL至少多了一个转换的过程。一般的SQL都可以转换成功，但对于含有分组统计等方面的SQL就不能转换了。 推荐方案：在业务密集的SQL当中尽量不采用IN操作符。 NOT IN操作符 此操作是强列推荐不使用的，因为它不能应用表的索引。 推荐方案：用NOT EXISTS 或（外连接+判断为空）方案代替 <> 操作符（不等于） 不等于操作符是永远不会用到索引的，因此对它的处理只会产生全表扫描。 推荐方案：用其它相同功能的操作运算代替，如 a<>0 改为 a>0 or a<0 a<>’’ 改为 a>’’ IS NULL 或IS NOT NULL操作（判断字段是否为空） 判断字段是否为空一般是不会应用索引的，因为B树索引是不索引空值的。 推荐方案： 用其它相同功能的操作运算代替，如 a is not null 改为 a>0 或a>’’等。 不允许字段为空，而用一个缺省值代替空值，如业扩申请中状态字段不允许为空，缺省为申请。 建立位图索引（有分区的表不能建，位图索引比较难控制，如字段值太多索引会使性能下降，多人更新操作会增加数据块锁的现象） > 及 < 操作符（大于或小于操作符） 大于或小于操作符一般情况下是不用调整的，因为它有索引就会采用索引查找，但有的情况下可以对它进行优化，如一个表有100万记录，一个数值型字段A，30万记录的A=0，30万记录的A=1，39万记录的A=2，1万记录的A=3。那么执行A>2与A>=3的效果就有很大的区别了，因为A>2时ORACLE会先找出为2的记录索引再进行比较，而A>=3时ORACLE则直接找到=3的记录索引。 LIKE操作符 LIKE操作符可以应用通配符查询，里面的通配符组合可能达到几乎是任意的查询，但是如果用得不好则会产生性能上的问题，如LIKE ‘%5400%’ 这种查询不会引用索引，而LIKE ‘X5400%’则会引用范围索引。一个实际例子：用YW_YHJBQK表中营业编号后面的户标识号可来查询营业编号 YY_BH LIKE ‘%5400%’ 这个条件会产生全表扫描，如果改成YY_BH LIKE ’X5400%’ OR YY_BH LIKE ’B5400%’ 则会利用YY_BH的索引进行两个范围的查询，性能肯定大大提高。 UNION操作符 UNION在进行表链接后会筛选掉重复的记录，所以在表链接后会对所产生的结果集进行排序运算，删除重复的记录再返回结果。实际大部分应用中是不会产生重复的记录，最常见的是过程表与历史表UNION。如： select * from gc_dfys union select * from ls_jg_dfys 这个SQL在运行时先取出两个表的结果，再用排序空间进行排序删除重复的记录，最后返回结果集，如果表数据量大的话可能会导致用磁盘进行排序。 推荐方案：采用UNION ALL操作符替代UNION，因为UNION ALL操作只是简单的将两个结果合并后就返回。 select * from gc_dfys union all select * from ls_jg_dfys SQL书写的影响 同一功能同一性能不同写法SQL的影响 如一个SQL在A程序员写的为 Select * from zl_yhjbqk B程序员写的为 Select * from dlyx.zl_yhjbqk（带表所有者的前缀） C程序员写的为 Select * from DLYX.ZLYHJBQK（大写表名） D程序员写的为 Select * from DLYX.ZLYHJBQK（中间多了空格） 以上四个SQL在ORACLE分析整理之后产生的结果及执行的时间是一样的，但是从ORACLE共享内存SGA的原理，可以得出ORACLE对每个SQL 都会对其进行一次分析，并且占用共享内存，如果将SQL的字符串及格式写得完全相同则ORACLE只会分析一次，共享内存也只会留下一次的分析结果，这不仅可以减少分析SQL的时间，而且可以减少共享内存重复的信息，ORACLE也可以准确统计SQL的执行频率。 WHERE后面的条件顺序影响 WHERE子句后面的条件顺序对大数据量表的查询会产生直接的影响，如 Select * from zl_yhjbqk where dy_dj = '1KV以下' and xh_bz=1 Select * from zl_yhjbqk where xh_bz=1 and dy_dj = '1KV以下' 以上两个SQL中dy_dj（电压等级）及xh_bz（销户标志）两个字段都没进行索引，所以执行的时候都是全表扫描，第一条SQL的dy_dj = '1KV以下'条件在记录集内比率为99%，而xh_bz=1的比率只为0.5%，在进行第一条SQL的时候99%条记录都进行dy_dj及xh_bz的比较，而在进行第二条SQL的时候0.5%条记录都进行dy_dj及xh_bz的比较，以此可以得出第二条SQL的CPU占用率明显比第一条低。 查询表顺序的影响 在FROM后面的表中的列表顺序会对SQL执行性能影响，在没有索引及ORACLE没有对表进行统计分析的情况下ORACLE会按表出现的顺序进行链接，由此因为表的顺序不对会产生十分耗服务器资源的数据交叉。（注：如果对表进行了统计分析，ORACLE会自动先进小表的链接，再进行大表的链接） SQL语句索引的利用 对操作符的优化（见上节） 对条件字段的一些优化 采用函数处理的字段不能利用索引，如： substr(hbs_bh,1,4)=’5400’，优化处理：hbs_bh like ‘5400%’ trunc(sk_rq)=trunc(sysdate)，优化处理： sk_rq>=trunc(sysdate) and sk_rq<trunc(sysdate+1) 进行了显式或隐式的运算的字段不能进行索引，如： ss_df+20>50，优化处理：ss_df>30 ‘X’||hbs_bh>’X5400021452’，优化处理：hbs_bh>’5400021542’ sk_rq+5=sysdate，优化处理：sk_rq=sysdate-5 hbs_bh=5401002554，优化处理：hbs_bh=’ 5401002554’，注：此条件对hbs_bh 进行隐式的to_number转换，因为hbs_bh字段是字符型。 条件内包括了多个本表的字段运算时不能进行索引，如： ys_df>cx_df，无法进行优化 qc_bh||kh_bh=’5400250000’，优化处理：qc_bh=’5400’ and kh_bh=’250000’ 应用ORACLE的HINT（提示）处理 提示处理是在ORACLE产生的SQL分析执行路径不满意的情况下要用到的。它可以对SQL进行以下方面的提示 目标方面的提示： COST（按成本优化） RULE（按规则优化） CHOOSE（缺省）（ORACLE自动选择成本或规则进行优化） ALL_ROWS（所有的行尽快返回） FIRST_ROWS（第一行数据尽快返回） 执行方法的提示： USE_NL（使用NESTED LOOPS方式联合） USE_MERGE（使用MERGE JOIN方式联合） USE_HASH（使用HASH JOIN方式联合） 索引提示： INDEX（TABLE INDEX）（使用提示的表索引进行查询） 其它高级提示（如并行处理等等） ORACLE的提示功能是比较强的功能，也是比较复杂的应用，并且提示只是给ORACLE执行的一个建议，有时如果出于成本方面的考虑ORACLE也可能不会按提示进行。根据实践应用，一般不建议开发人员应用ORACLE提示，因为各个数据库及服务器性能情况不一样，很可能一个地方性能提升了，但另一个地方却下降了，ORACLE在SQL执行分析方面已经比较成熟，如果分析执行的路径不对首先应在数据库结构（主要是索引）、服务器当前性能（共享内存、磁盘文件碎片）、数据库对象（表、索引）统计信息是否正确这几方面分析。 与没有优化数据库的网站相比，数据库的存取会降低你的系统性能。但是大多数情况下，网站和数据库有密不可分的关系，正是数据库给站点提供了大容量、多样性、个性化等特色，并实现了很多特殊的功能。 1 不要忘记给数据库做索引。 合理的索引能立即显著地提高数据库整个系统的性能。可以参考有关SQL性能调试书籍，学会根据所需查询方式合理制作索引和根据索引方式改进查询语句。 2 在适当的情况下，尽可能的用存储过程而不是SQL查询。 因为前者已经过了预编译，运行速度更快。同时让数据库仅仅返回你所需要的那些数据，而不是返回大量数据再让ASP程序过滤。总之要充分和有效地发挥数据库的强大功能，让它按照我们的要求反馈给我们最合适和最精练的信息。 3 在可能情况下我们应该使用SQL Server而不是Access。因为Access仅仅是基于文件的数据库，多用户性能很差。数据库连接尽量使用OLEDB和非DSN方式，因为这种连接方式有更好的并发性能。 4 避免使用DAO（Data Access Objects）和RDO（Remote Data Objects）数据源。因为他们主要应用在单用户的处理系统里，ADO（ActiveX Data Objects）才是为Web应用设计的。 5 建立记录集Rescordset的时候要清晰合理地设置数据游标(cursort)和锁定方式(locktype)。 因为在不同的方式下ASP会以不同的方式操纵数据库，其执行速度也有很大区别，尤其在大数据量的时候。如果你只想遍历数据，那么默认游标（前进、只读）会带来最好的性能。 6 当你引用ADO变量的时候，会消耗较多的CPU周期。因此，如果在一个ASP页面中多次引用数据库的字段变量，一个较好的方式是将字段值先放入本地变量，然后可以直接调用本地变量来计算和显示数据。 7 缓存ADO Connection对象也许不是一个好主意。 如果一个连接（Connection）对象被存储在Application对象中而被所有ASP页面使用，那么所有页面就会争着使用这个连接。但是如果连接对象被存储在Session对象中，就要为每个用户创建一个数据库连接，这就减小了连接池的作用，并且增大了Web服务器和数据库服务器的压力。可以用在每个使用ADO的ASP页创建和释放ADO对象来替代缓存数据库连接。因为IIS内建了数据库连接池，所以这种方法非常有效，缺点是每个ASP页面都需要进行一些创建和释放操作。 8 ASP最强大和主要的用途之一就是对数据库进行操作，在数据库操作中我们要注意：不要任意使用“SELECT ＊ ......” 形式的SQL查询语句。应该尽量检索你所需要的那些字段。比如一个表中有10个字段，但是你只会用到其中的一个字段（name），就该使用“select name from mytable”，而不是用“select ＊ from mytable”。在字段数比较少的时候，两者的区别可能并不明显，但是当一个表中拥有几十个字段的时候，数据库会多检索很多你并不需要的数据。在这种情况下你最好不要为了节省打字时间或者害怕查找对应字段名称的麻烦，而要老老实实地使用“select id,name,age... from mytable”。 9 及时关闭打开的记录集对象以及连接(Connection)对象。 记录集对象和连接对象耗费系统资源相当大，因此它们的可用数量是有限的。如果你打开了太多的记录集对象以及连接对象而最后却没有关闭它们，可能会出现ASP程序刚开始的时候运行速度很快，而多运行几遍就越来越慢的现象，甚至导致服务器死机。请使用如下方法进行关闭： MyRecordSet.closeSet MyRecordSet=Nothing Set MyConnection=Nothing 10 连接数据库 仍然使用ODBC系统或者文件DSN来连接数据库，或者使用很快的OLEDB技术来连接。使用后者，当移动Web文件时，不再需要修改配置。 OLEDB位于应用程序与ODBC层之间。在ASP页面中，ADO就是位于OLEDB之上的程序。调用ADO时，首先发送给OLEDB，然后再发送给ODBC层。可以直接连接到OLEDB层，这么做后，将提高服务器端的性能。怎么直接连接到OLEDB呢？ 如果使用SQLServer 7，使用下面的代码做为连接字符串： strConnString = \"DSN='';DRIVER={SQL SERVER};\" & _ \"UID=myuid;PWD=mypwd;\" & _ \"DATABASE=MyDb;SERVER=MyServer;\" 最重要的参数就是“DRIVER=”部分。如果你想绕过ODBC而使用OLEDB来访问SQL Server，使用下面的语法： strConnString =\"Provider=SQLOLEDB.1;Password=mypassword;\" & _ \"Persist Security Info=True;User ID=myuid;\" & _ \"Initial Catalog=mydbname;\" & _ \"Data Source=myserver;Connect Timeout=15\" 为什么这很重要 现在你可能奇怪为什么学习这种新的连接方法很关键？为什么不使用标准的DSN或者系统DSN方法？好，根据Wrox在他们的ADO 2.0程序员参考书籍中所做的测试，如果使用OLEDB连接，要比使用DSN或者DSN－less连接，有以下的性能提高表现： 性能比较： ---------------------------------------------------------------------- SQL Access 连接时间: 18 82 重复1，000个记录的时间：2900 5400 OLEDB DSN OLEDB DSN 连接时间：62 99 重复1，000个记录的时间：100 950 ---------------------------------------------------------------------- 这个结论在Wrox的ADO 2.0程序员参考发表。时间是以毫秒为单位，重复1，000个记录的时间是以服务器油标的方式计算的。 有一个例子： select a. *, m.amount from tableA a, ( select b.fieldD, sum(c.total_amount) amount from tableA b, tableB c where b.fieldC = 100 and b.fieldA in ('AA', 'BB', 'CC', 'DD', 'EE', 'FF') and b.fieldId = c.fieldId group by b.fieldD ) m where a.fieldC = 100 and a.fieldD = m.fieldD and a.fieldA = 'GG' 这句sql当中对同一个表扫描了两次,所以效率太低,有什么办法可以避免这种写法? tableA,tableB 是主从表关系。 请不要用sql server 中太特殊的语法，因为要用到oracle中。 在oracle中无人回答。 ------------------------------------------ SQL语句的写法是根据你的业务要求，改写起来效果不能很明显。 先分析一下你的SQL的执行路径： 1、 首先会分别对tableA和tableB应用filter动作（使用m子查询中的where条件）。然后进行连接，可能会是nestloop或hash join...这取决于你 的两个表数据过滤情况。然后进行汇总（group by）输出m结果集。 2、接下来会将m结果集与tableA（外层）过滤后（a.fieldC = 100 and a.fieldA = 'GG'）的结果集进行连接，还是有多种连接方式。最后输 出a. *, m.amount 大致分析了一下执行的路径，就会对你的描述产生疑惑：“对同一个表扫描了两次”肯定指的是tableA了。但是你没有建立相关的索引吗？如 果说外层的查询就算建立索引也会通过rowid定位到表中，我们权当这是“表扫描”，但是内层的查询应该不会发生产生表扫描（all table access）的情况！应该是索引扫描（index scan）才对。根据这一点，我们可以首先考虑建立索引来提高效率。 可以考虑建立的索引： create index idx_1 on tableA(fieldC,fieldA,fieldId,fieldD) create index idx_2 on tableB(fieldId,total_amount) 建立完这两个索引后别忘了重新执行分析，以保证统计值准确。 建立完这两个索引后，内层的执行计划应该是对idx_1和idx_2进行索引扫描（index scan）然后连接输出m结果集，再与外层的经过索引扫描（ index scan + rowid to table）的结果集进行连接。 如果查询计划不对，请检查你的优化器参数设置，不要使用rbo要使用cbo。如果还是没有采用请用/* index*/提示强制指定.... 上面的是单纯从索引方面考虑。如果还是不能提高速度，考虑建立实体化视图（物化视图）。可以只将m部分进行实体化。如果tableA和tableB 基本属于静态表，可以考虑将整条语句实体化。 这里有个非常好的例子并总结了： SERVER数据库中实现快速的数据提取和数据分页。以下代码说明了我们实例中数据库的“红头文件”一表的部分数据结构： CREATE table [dbo].[TGongwen] (　　--TGongwen是红头文件表名 [Gid] [int] ideNTITY (1, 1) NOT NULL , --本表的id号，也是主键 [title] [varchar] (80) COLLATE Chinese_PRC_CI_AS NULL , --红头文件的标题 [fariqi] [datetime] NULL , --发布日期 [neibuYonghu] [varchar] (70) COLLATE Chinese_PRC_CI_AS NULL , --发布用户 [reader] [varchar] (900) COLLATE Chinese_PRC_CI_AS NULL , --需要浏览的用户。每个用户中间用分隔符“,”分开 ) ON [PRIMARY] TEXTimage_ON [PRIMARY] GO 下面，我们来往数据库中添加1000万条数据： declare @i int set @i=1 while @i<=250000 begin insert into Tgongwen(fariqi,neibuyonghu,reader,title) values('2004-2-5','通信科','通信科,办公室,王局长,刘局长,张局长,admin,刑侦支队,特勤支队,交巡警支队,经侦支队,户政科,治安支队,外事科','这是最先的25万条记录') set @i=@i+1 end GO declare @i int set @i=1 while @i<=250000 begin insert into Tgongwen(fariqi,neibuyonghu,reader,title) values('2004-9-16','办公室','办公室,通信科,王局长,刘局长,张局长,admin,刑侦支队,特勤支队,交巡警支队,经侦支队,户政科,外事科','这是中间的25万条记录') set @i=@i+1 end GO declare @h int set @h=1 while @h<=100 begin declare @i int set @i=2002 while @i<=2003 begin declare @j int set @j=0 while @j<50 begin declare @k int set @k=0 while @k<50 begin insert into Tgongwen(fariqi,neibuyonghu,reader,title) values(cast(@i as varchar(4))+'-8-15 3:'+cast(@j as varchar(2))+':'+cast(@j as varchar(2)),'通信科','办公室,通信科,王局长,刘局长,张局长,admin,刑侦支队,特勤支队,交巡警支队,经侦支队,户政科,外事科','这是最后的50万条记录') set @k=@k+1 end set @j=@j+1 end set @i=@i+1 end set @h=@h+1 end GO declare @i int set @i=1 while @i<=9000000 begin insert into Tgongwen(fariqi,neibuyonghu,reader,title) values('2004-5-5','通信科','通信科,办公室,王局长,刘局长,张局长,admin,刑侦支队,特勤支队,交巡警支队,经侦支队,户政科,治安支队,外事科','这是最后添加的900万条记录') set @i=@i+1000000 end GO 通过以上语句，我们创建了25万条由于2004年2月5日发布的记录，25万条由办公室于2004年9月6日发布的记录，2002年和2003年各100个2500条相同日期、不同分秒的记录（共50万条），还有由通信科于2004年5月5日发布的900万条记录，合计1000万条。 一、因情制宜，建立“适当”的索引 建立“适当”的索引是实现查询优化的首要前提。 索引（index）是除表之外另一重要的、用户定义的存储在物理介质上的数据结构。当根据索引码的值搜索数据时，索引提供了对数据的快速访问。事实上，没有索引,数据库也能根据select语句成功地检索到结果，但随着表变得越来越大，使用“适当”的索引的效果就越来越明显。注意，在这句话中，我们用了“适当”这个词，这是因为，如果使用索引时不认真考虑其实现过程，索引既可以提高也会破坏数据库的工作性能。 （一）深入浅出理解索引结构 实际上，您可以把索引理解为一种特殊的目录。微软的SQL SERVER提供了两种索引：聚集索引（clustered index，也称聚类索引、簇集索引）和非聚集索引（nonclustered index，也称非聚类索引、非簇集索引）。下面，我们举例来说明一下聚集索引和非聚集索引的区别： 其实，我们的汉语字典的正文本身就是一个聚集索引。比如，我们要查“安”字，就会很自然地翻开字典的前几页，因为“安”的拼音是“an”，而按照拼音排序汉字的字典是以英文字母“a”开头并以“z”结尾的，那么“安”字就自然地排在字典的前部。如果您翻完了所有以“a”开头的部分仍然找不到这个字，那么就说明您的字典中没有这个字；同样的，如果查“张”字，那您也会将您的字典翻到最后部分，因为“张”的拼音是“zhang”。也就是说，字典的正文部分本身就是一个目录，您不需要再去查其他目录来找到您需要找的内容。 我们把这种正文内容本身就是一种按照一定规则排列的目录称为“聚集索引”。 如果您认识某个字，您可以快速地从自动中查到这个字。但您也可能会遇到您不认识的字，不知道它的发音，这时候，您就不能按照刚才的方法找到您要查的字，而需要去根据“偏旁部首”查到您要找的字，然后根据这个字后的页码直接翻到某页来找到您要找的字。但您结合“部首目录”和“检字表”而查到的字的排序并不是真正的正文的排序方法，比如您查“张”字，我们可以看到在查部首之后的检字表中“张”的页码是672页，检字表中“张”的上面是“驰”字，但页码却是63页，“张”的下面是“弩”字，页面是390页。很显然，这些字并不是真正的分别位于“张”字的上下方，现在您看到的连续的“驰、张、弩”三字实际上就是他们在非聚集索引中的排序，是字典正文中的字在非聚集索引中的映射。我们可以通过这种方式来找到您所需要的字，但它需要两个过程，先找到目录中的结果，然后再翻到您所需要的页码。 我们把这种目录纯粹是目录，正文纯粹是正文的排序方式称为“非聚集索引”。 通过以上例子，我们可以理解到什么是“聚集索引”和“非聚集索引”。 进一步引申一下，我们可以很容易的理解：每个表只能有一个聚集索引，因为目录只能按照一种方法进行排序。 （二）何时使用聚集索引或非聚集索引 下面的表总结了何时使用聚集索引或非聚集索引（很重要）。 动作描述 使用聚集索引 使用非聚集索引 列经常被分组排序 应 应 返回某范围内的数据 应 不应 一个或极少不同值 不应 不应 小数目的不同值 应 不应 大数目的不同值 不应 应 频繁更新的列 不应 应 外键列 应 应 主键列 应 应 频繁修改索引列 不应 应 事实上，我们可以通过前面聚集索引和非聚集索引的定义的例子来理解上表。如：返回某范围内的数据一项。比如您的某个表有一个时间列，恰好您把聚合索引建立在了该列，这时您查询2004年1月1日至2004年10月1日之间的全部数据时，这个速度就将是很快的，因为您的这本字典正文是按日期进行排序的，聚类索引只需要找到要检索的所有数据中的开头和结尾数据即可；而不像非聚集索引，必须先查到目录中查到每一项数据对应的页码，然后再根据页码查到具体内容。 （三）结合实际，谈索引使用的误区 理论的目的是应用。虽然我们刚才列出了何时应使用聚集索引或非聚集索引，但在实践中以上规则却很容易被忽视或不能根据实际情况进行综合分析。下面我们将根据在实践中遇到的实际问题来谈一下索引使用的误区，以便于大家掌握索引建立的方法。 1、主键就是聚集索引 这种想法笔者认为是极端错误的，是对聚集索引的一种浪费。虽然SQL SERVER默认是在主键上建立聚集索引的。 通常，我们会在每个表中都建立一个ID列，以区分每条数据，并且这个ID列是自动增大的，步长一般为1。我们的这个办公自动化的实例中的列Gid就是如此。此时，如果我们将这个列设为主键，SQL SERVER会将此列默认为聚集索引。这样做有好处，就是可以让您的数据在数据库中按照ID进行物理排序，但笔者认为这样做意义不大。 显而易见，聚集索引的优势是很明显的，而每个表中只能有一个聚集索引的规则，这使得聚集索引变得更加珍贵。 从我们前面谈到的聚集索引的定义我们可以看出，使用聚集索引的最大好处就是能够根据查询要求，迅速缩小查询范围，避免全表扫描。在实际应用中，因为ID号是自动生成的，我们并不知道每条记录的ID号，所以我们很难在实践中用ID号来进行查询。这就使让ID号这个主键作为聚集索引成为一种资源浪费。其次，让每个ID号都不同的字段作为聚集索引也不符合“大数目的不同值情况下不应建立聚合索引”规则；当然，这种情况只是针对用户经常修改记录内容，特别是索引项的时候会负作用，但对于查询速度并没有影响。 在办公自动化系统中，无论是系统首页显示的需要用户签收的文件、会议还是用户进行文件查询等任何情况下进行数据查询都离不开字段的是“日期”还有用户本身的“用户名”。 通常，办公自动化的首页会显示每个用户尚未签收的文件或会议。虽然我们的where语句可以仅仅限制当前用户尚未签收的情况，但如果您的系统已建立了很长时间，并且数据量很大，那么，每次每个用户打开首页的时候都进行一次全表扫描，这样做意义是不大的，绝大多数的用户1个月前的文件都已经浏览过了，这样做只能徒增数据库的开销而已。事实上，我们完全可以让用户打开系统首页时，数据库仅仅查询这个用户近3个月来未阅览的文件，通过“日期”这个字段来限制表扫描，提高查询速度。如果您的办公自动化系统已经建立的2年，那么您的首页显示速度理论上将是原来速度8倍，甚至更快。 在这里之所以提到“理论上”三字，是因为如果您的聚集索引还是盲目地建在ID这个主键上时，您的查询速度是没有这么高的，即使您在“日期”这个字段上建立的索引（非聚合索引）。下面我们就来看一下在1000万条数据量的情况下各种查询的速度表现（3个月内的数据为25万条）： （1）仅在主键上建立聚集索引，并且不划分时间段： Select gid,fariqi,neibuyonghu,title from tgongwen 用时：128470毫秒（即：128秒） （2）在主键上建立聚集索引，在fariq上建立非聚集索引： select gid,fariqi,neibuyonghu,title from Tgongwen where fariqi> dateadd(day,-90,getdate()) 用时：53763毫秒（54秒） （3）将聚合索引建立在日期列（fariqi）上： select gid,fariqi,neibuyonghu,title from Tgongwen where fariqi> dateadd(day,-90,getdate()) 用时：2423毫秒（2秒） 虽然每条语句提取出来的都是25万条数据，各种情况的差异却是巨大的，特别是将聚集索引建立在日期列时的差异。事实上，如果您的数据库真的有1000万容量的话，把主键建立在ID列上，就像以上的第1、2种情况，在网页上的表现就是超时，根本就无法显示。这也是我摒弃ID列作为聚集索引的一个最重要的因素。 得出以上速度的方法是：在各个select语句前加：declare @d datetime set @d=getdate() 并在select语句后加： select [语句执行花费时间(毫秒)]=datediff(ms,@d,getdate()) 2、只要建立索引就能显著提高查询速度 事实上，我们可以发现上面的例子中，第2、3条语句完全相同，且建立索引的字段也相同；不同的仅是前者在fariqi字段上建立的是非聚合索引，后者在此字段上建立的是聚合索引，但查询速度却有着天壤之别。所以，并非是在任何字段上简单地建立索引就能提高查询速度。 从建表的语句中，我们可以看到这个有着1000万数据的表中fariqi字段有5003个不同记录。在此字段上建立聚合索引是再合适不过了。在现实中，我们每天都会发几个文件，这几个文件的发文日期就相同，这完全符合建立聚集索引要求的：“既不能绝大多数都相同，又不能只有极少数相同”的规则。由此看来，我们建立“适当”的聚合索引对于我们提高查询速度是非常重要的。 3、把所有需要提高查询速度的字段都加进聚集索引，以提高查询速度 上面已经谈到：在进行数据查询时都离不开字段的是“日期”还有用户本身的“用户名”。既然这两个字段都是如此的重要，我们可以把他们合并起来，建立一个复合索引（compound index）。 很多人认为只要把任何字段加进聚集索引，就能提高查询速度，也有人感到迷惑：如果把复合的聚集索引字段分开查询，那么查询速度会减慢吗？带着这个问题，我们来看一下以下的查询速度（结果集都是25万条数据）：（日期列fariqi首先排在复合聚集索引的起始列，用户名neibuyonghu排在后列） （1）select gid,fariqi,neibuyonghu,title from Tgongwen where fariqi>'2004-5-5' 查询速度：2513毫秒 （2）select gid,fariqi,neibuyonghu,title from Tgongwen where fariqi>'2004-5-5' and neibuyonghu='办公室' 查询速度：2516毫秒 （3）select gid,fariqi,neibuyonghu,title from Tgongwen where neibuyonghu='办公室' 查询速度：60280毫秒 从以上试验中，我们可以看到如果仅用聚集索引的起始列作为查询条件和同时用到复合聚集索引的全部列的查询速度是几乎一样的，甚至比用上全部的复合索引列还要略快（在查询结果集数目一样的情况下）；而如果仅用复合聚集索引的非起始列作为查询条件的话，这个索引是不起任何作用的。当然，语句1、2的查询速度一样是因为查询的条目数一样，如果复合索引的所有列都用上，而且查询结果少的话，这样就会形成“索引覆盖”，因而性能可以达到最优。同时，请记住：无论您是否经常使用聚合索引的其他列，但其前导列一定要是使用最频繁的列。 （四）其他书上没有的索引使用经验总结 1、用聚合索引比用不是聚合索引的主键速度快 下面是实例语句：（都是提取25万条数据） select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi='2004-9-16' 使用时间：3326毫秒 select gid,fariqi,neibuyonghu,reader,title from Tgongwen where gid<=250000 使用时间：4470毫秒 这里，用聚合索引比用不是聚合索引的主键速度快了近1/4。 2、用聚合索引比用一般的主键作order by时速度快，特别是在小数据量情况下 select gid,fariqi,neibuyonghu,reader,title from Tgongwen order by fariqi 用时：12936 select gid,fariqi,neibuyonghu,reader,title from Tgongwen order by gid 用时：18843 这里，用聚合索引比用一般的主键作order by时，速度快了3/10。事实上，如果数据量很小的话，用聚集索引作为排序列要比使用非聚集索引速度快得明显的多；而数据量如果很大的话，如10万以上，则二者的速度差别不明显。 3、使用聚合索引内的时间段，搜索时间会按数据占整个数据表的百分比成比例减少，而无论聚合索引使用了多少个 select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi>'2004-1-1' 用时：6343毫秒（提取100万条） select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi>'2004-6-6' 用时：3170毫秒（提取50万条） select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi='2004-9-16' 用时：3326毫秒（和上句的结果一模一样。如果采集的数量一样，那么用大于号和等于号是一样的） select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi>'2004-1-1' and fariqi<'2004-6-6' 用时：3280毫秒 　　4 、日期列不会因为有分秒的输入而减慢查询速度 下面的例子中，共有100万条数据，2004年1月1日以后的数据有50万条，但只有两个不同的日期，日期精确到日；之前有数据50万条，有5000个不同的日期，日期精确到秒。 select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi>'2004-1-1' order by fariqi 用时：6390毫秒 select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi<'2004-1-1' order by fariqi 用时：6453毫秒 （五）其他注意事项 “水可载舟，亦可覆舟”，索引也一样。索引有助于提高检索性能，但过多或不当的索引也会导致系统低效。因为用户在表中每加进一个索引，数据库就要做更多的工作。过多的索引甚至会导致索引碎片。 所以说，我们要建立一个“适当”的索引体系，特别是对聚合索引的创建，更应精益求精，以使您的数据库能得到高性能的发挥。 当然，在实践中，作为一个尽职的数据库管理员，您还要多测试一些方案，找出哪种方案效率最高、最为有效。 二、改善SQL语句 很多人不知道SQL语句在SQL SERVER中是如何执行的，他们担心自己所写的SQL语句会被SQL SERVER误解。比如： select * from table1 where name='zhangsan' and tID > 10000 和执行: select * from table1 where tID > 10000 and name='zhangsan' 一些人不知道以上两条语句的执行效率是否一样，因为如果简单的从语句先后上看，这两个语句的确是不一样，如果tID是一个聚合索引，那么后一句仅仅从表的10000条以后的记录中查找就行了；而前一句则要先从全表中查找看有几个name='zhangsan'的，而后再根据限制条件条件tID>10000来提出查询结果。 事实上，这样的担心是不必要的。SQL SERVER中有一个“查询分析优化器”，它可以计算出where子句中的搜索条件并确定哪个索引能缩小表扫描的搜索空间，也就是说，它能实现自动优化。 虽然查询优化器可以根据where子句自动的进行查询优化，但大家仍然有必要了解一下“查询优化器”的工作原理，如非这样，有时查询优化器就会不按照您的本意进行快速查询。 在查询分析阶段，查询优化器查看查询的每个阶段并决定限制需要扫描的数据量是否有用。如果一个阶段可以被用作一个扫描参数（SARG），那么就称之为可优化的，并且可以利用索引快速获得所需数据。 SARG的定义：用于限制搜索的一个操作，因为它通常是指一个特定的匹配，一个值得范围内的匹配或者两个以上条件的AND连接。形式如下： 列名操作符 <常数或变量> 或 <常数或变量> 操作符列名 列名可以出现在操作符的一边，而常数或变量出现在操作符的另一边。如： Name=’张三’ 价格>5000 5000<价格 Name=’张三’ and 价格>5000 如果一个表达式不能满足SARG的形式，那它就无法限制搜索的范围了，也就是SQL SERVER必须对每一行都判断它是否满足WHERE子句中的所有条件。所以一个索引对于不满足SARG形式的表达式来说是无用的。 介绍完SARG后，我们来总结一下使用SARG以及在实践中遇到的和某些资料上结论不同的经验： 1、Like语句是否属于SARG取决于所使用的通配符的类型 如：name like ‘张%’ ，这就属于SARG 而：name like ‘%张’ ,就不属于SARG。 原因是通配符%在字符串的开通使得索引无法使用。 2、or 会引起全表扫描 Name=’张三’ and 价格>5000 符号SARG，而：Name=’张三’ or 价格>5000 则不符合SARG。使用or会引起全表扫描。 3、非操作符、函数引起的不满足SARG形式的语句 不满足SARG形式的语句最典型的情况就是包括非操作符的语句，如：NOT、!=、<>、!<、!>、NOT EXISTS、NOT IN、NOT LIKE等，另外还有函数。下面就是几个不满足SARG形式的例子： ABS(价格)<5000 Name like ‘%三’ 有些表达式，如： WHERE 价格*2>5000 SQL SERVER也会认为是SARG，SQL SERVER会将此式转化为： WHERE 价格>2500/2 但我们不推荐这样使用，因为有时SQL SERVER不能保证这种转化与原始表达式是完全等价的。 4、IN 的作用相当与OR 语句： Select * from table1 where tid in (2,3) 和 Select * from table1 where tid=2 or tid=3 是一样的，都会引起全表扫描，如果tid上有索引，其索引也会失效。 5、尽量少用NOT 6、exists 和 in 的执行效率是一样的 很多资料上都显示说，exists要比in的执行效率要高，同时应尽可能的用not exists来代替not in。但事实上，我试验了一下，发现二者无论是前面带不带not，二者之间的执行效率都是一样的。因为涉及子查询，我们试验这次用SQL SERVER自带的pubs数据库。运行前我们可以把SQL SERVER的statistics I/O状态打开。 （1）select title,price from titles where title_id in (select title_id from sales where qty>30) 该句的执行结果为： 表 'sales'。扫描计数 18，逻辑读 56 次，物理读 0 次，预读 0 次。 表 'titles'。扫描计数 1，逻辑读 2 次，物理读 0 次，预读 0 次。 （2）select title,price from titles where exists (select * from sales where sales.title_id=titles.title_id and qty>30) 第二句的执行结果为： 表 'sales'。扫描计数 18，逻辑读 56 次，物理读 0 次，预读 0 次。 表 'titles'。扫描计数 1，逻辑读 2 次，物理读 0 次，预读 0 次。 我们从此可以看到用exists和用in的执行效率是一样的。 7、用函数charindex()和前面加通配符%的LIKE执行效率一样 前面，我们谈到，如果在LIKE前面加上通配符%，那么将会引起全表扫描，所以其执行效率是低下的。但有的资料介绍说，用函数charindex()来代替LIKE速度会有大的提升，经我试验，发现这种说明也是错误的： select gid,title,fariqi,reader from tgongwen where charindex('刑侦支队',reader)>0 and fariqi>'2004-5-5' 用时：7秒，另外：扫描计数 4，逻辑读 7155 次，物理读 0 次，预读 0 次。 select gid,title,fariqi,reader from tgongwen where reader like '%' + '刑侦支队' + '%' and fariqi>'2004-5-5' 用时：7秒，另外：扫描计数 4，逻辑读 7155 次，物理读 0 次，预读 0 次。 8、union并不绝对比or的执行效率高 我们前面已经谈到了在where子句中使用or会引起全表扫描，一般的，我所见过的资料都是推荐这里用union来代替or。事实证明，这种说法对于大部分都是适用的。 select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi='2004-9-16' or gid>9990000 用时：68秒。扫描计数 1，逻辑读 404008 次，物理读 283 次，预读 392163 次。 select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi='2004-9-16' union select gid,fariqi,neibuyonghu,reader,title from Tgongwen where gid>9990000 用时：9秒。扫描计数 8，逻辑读 67489 次，物理读 216 次，预读 7499 次。 看来，用union在通常情况下比用or的效率要高的多。 但经过试验，笔者发现如果or两边的查询列是一样的话，那么用union则反倒和用or的执行速度差很多，虽然这里union扫描的是索引，而or扫描的是全表。 select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi='2004-9-16' or fariqi='2004-2-5' 用时：6423毫秒。扫描计数 2，逻辑读 14726 次，物理读 1 次，预读 7176 次。 select gid,fariqi,neibuyonghu,reader,title from Tgongwen where fariqi='2004-9-16' union select gid,fariqi,neibuyonghu,reader,title from Tgongwen where　fariqi='2004-2-5' 用时：11640毫秒。扫描计数 8，逻辑读 14806 次，物理读 108 次，预读 1144 次。 9、字段提取要按照“需多少、提多少”的原则，避免“select *” 我们来做一个试验： select top 10000 gid,fariqi,reader,title from tgongwen order by gid desc 用时：4673毫秒 select top 10000 gid,fariqi,title from tgongwen order by gid desc 用时：1376毫秒 select top 10000 gid,fariqi from tgongwen order by gid desc 用时：80毫秒 由此看来，我们每少提取一个字段，数据的提取速度就会有相应的提升。提升的速度还要看您舍弃的字段的大小来判断。 10、count(*)不比count(字段)慢 某些资料上说：用*会统计所有列，显然要比一个世界的列名效率低。这种说法其实是没有根据的。我们来看： select count(*) from Tgongwen 用时：1500毫秒 select count(gid) from Tgongwen 用时：1483毫秒 select count(fariqi) from Tgongwen 用时：3140毫秒 select count(title) from Tgongwen 用时：52050毫秒 从以上可以看出，如果用count(*)和用count(主键)的速度是相当的，而count(*)却比其他任何除主键以外的字段汇总速度要快，而且字段越长，汇总的速度就越慢。我想，如果用count(*)， SQL SERVER可能会自动查找最小字段来汇总的。当然，如果您直接写count(主键)将会来的更直接些。 11、order by按聚集索引列排序效率最高 我们来看：（gid是主键，fariqi是聚合索引列） select top 10000 gid,fariqi,reader,title from tgongwen 用时：196 毫秒。扫描计数 1，逻辑读 289 次，物理读 1 次，预读 1527 次。 select top 10000 gid,fariqi,reader,title from tgongwen order by gid asc 用时：4720毫秒。扫描计数 1，逻辑读 41956 次，物理读 0 次，预读 1287 次。 select top 10000 gid,fariqi,reader,title from tgongwen order by gid desc 用时：4736毫秒。扫描计数 1，逻辑读 55350 次，物理读 10 次，预读 775 次。 select top 10000 gid,fariqi,reader,title from tgongwen order by fariqi asc 用时：173毫秒。扫描计数 1，逻辑读 290 次，物理读 0 次，预读 0 次。 select top 10000 gid,fariqi,reader,title from tgongwen order by fariqi desc 用时：156毫秒。扫描计数 1，逻辑读 289 次，物理读 0 次，预读 0 次。 从以上我们可以看出，不排序的速度以及逻辑读次数都是和“order by 聚集索引列” 的速度是相当的，但这些都比“order by 非聚集索引列”的查询速度是快得多的。 同时，按照某个字段进行排序的时候，无论是正序还是倒序，速度是基本相当的。 12、高效的TOP 事实上，在查询和提取超大容量的数据集时，影响数据库响应时间的最大因素不是数据查找，而是物理的I/0操作。如： select top 10 * from ( select top 10000 gid,fariqi,title from tgongwen where neibuyonghu='办公室' order by gid desc) as a order by gid asc 这条语句，从理论上讲，整条语句的执行时间应该比子句的执行时间长，但事实相反。因为，子句执行后返回的是10000条记录，而整条语句仅返回10条语句，所以影响数据库响应时间最大的因素是物理I/O操作。而限制物理I/O操作此处的最有效方法之一就是使用TOP关键词了。TOP关键词是SQL SERVER中经过系统优化过的一个用来提取前几条或前几个百分比数据的词。经笔者在实践中的应用，发现TOP确实很好用，效率也很高。但这个词在另外一个大型数据库ORACLE中却没有，这不能说不是一个遗憾，虽然在ORACLE中可以用其他方法（如：rownumber）来解决。在以后的关于“实现千万级数据的分页显示存储过程”的讨论中，我们就将用到TOP这个关键词。 到此为止，我们上面讨论了如何实现从大容量的数据库中快速地查询出您所需要的数据方法。当然，我们介绍的这些方法都是“软”方法，在实践中，我们还要考虑各种“硬”因素，如：网络性能、服务器的性能、操作系统的性能，甚至网卡、交换机等。 　　三、实现小数据量和海量数据的通用分页显示存储过程 建立一个web 应用，分页浏览功能必不可少。这个问题是数据库处理中十分常见的问题。经典的数据分页方法是:ADO 纪录集分页法，也就是利用ADO自带的分页功能（利用游标）来实现分页。但这种分页方法仅适用于较小数据量的情形，因为游标本身有缺点：游标是存放在内存中，很费内存。游标一建立，就将相关的记录锁住，直到取消游标。游标提供了对特定集合中逐行扫描的手段，一般使用游标来逐行遍历数据，根据取出数据条件的不同进行不同的操作。而对于多表和大表中定义的游标（大的数据集合）循环很容易使程序进入一个漫长的等待甚至死机。 更重要的是，对于非常大的数据模型而言，分页检索时，如果按照传统的每次都加载整个数据源的方法是非常浪费资源的。现在流行的分页方法一般是检索页面大小的块区的数据，而非检索所有的数据，然后单步执行当前行。 最早较好地实现这种根据页面大小和页码来提取数据的方法大概就是“俄罗斯存储过程”。这个存储过程用了游标，由于游标的局限性，所以这个方法并没有得到大家的普遍认可。 后来，网上有人改造了此存储过程，下面的存储过程就是结合我们的办公自动化实例写的分页存储过程： CREATE procedure pagination1 (@pagesize int,　--页面大小，如每页存储20条记录 @pageindex int　 --当前页码 ) as set nocount on begin declare @indextable table(id int identity(1,1),nid int)　--定义表变量 declare @PageLowerBound int　--定义此页的底码 declare @PageUpperBound int　--定义此页的顶码 set @PageLowerBound=(@pageindex-1)*@pagesize set @PageUpperBound=@PageLowerBound+@pagesize set rowcount @PageUpperBound insert into @indextable(nid) select gid from TGongwen where fariqi >dateadd(day,-365,getdate()) order by fariqi desc select O.gid,O.mid,O.title,O.fadanwei,O.fariqi from TGongwen O,@indextable t where O.gid=t.nid and t.id>@PageLowerBound and t.id<=@PageUpperBound order by t.id end set nocount off 以上存储过程运用了SQL SERVER的最新技术――表变量。应该说这个存储过程也是一个非常优秀的分页存储过程。当然，在这个过程中，您也可以把其中的表变量写成临时表：CREATE TABLE #Temp。但很明显，在SQL SERVER中，用临时表是没有用表变量快的。所以笔者刚开始使用这个存储过程时，感觉非常的不错，速度也比原来的ADO的好。但后来，我又发现了比此方法更好的方法。 笔者曾在网上看到了一篇小短文《从数据表中取出第n条到第m条的记录的方法》，全文如下： 从publish 表中取出第 n 条到第 m 条的记录： SELECT TOP m-n+1 * FROM publish WHERE (id NOT IN (SELECT TOP n-1 id FROM publish)) id 为publish 表的关键字 我当时看到这篇文章的时候，真的是精神为之一振，觉得思路非常得好。等到后来，我在作办公自动化系统（ASP.net+ C#＋SQL SERVER）的时候，忽然想起了这篇文章，我想如果把这个语句改造一下，这就可能是一个非常好的分页存储过程。于是我就满网上找这篇文章，没想到，文章还没找到，却找到了一篇根据此语句写的一个分页存储过程，这个存储过程也是目前较为流行的一种分页存储过程，我很后悔没有争先把这段文字改造成存储过程： CREATE PROCEDURE pagination2 ( @SQL nVARCHAR(4000),　　--不带排序语句的SQL语句 @Page int,　　　　　　　--页码 @RecsPerPage int,　　　 --每页容纳的记录数 @ID VARCHAR(255),　　　 --需要排序的不重复的ID号 @Sort VARCHAR(255)　　　--排序字段及规则 ) AS DECLARE @Str nVARCHAR(4000) SET @Str='SELECT　 TOP '+CAST(@RecsPerPage AS VARCHAR(20))+' * FROM ('+@SQL+') T WHERE T.'+@ID+'NOT IN (SELECT　 TOP '+CAST((@RecsPerPage*(@Page-1)) AS VARCHAR(20))+' '+@ID+' FROM ('+@SQL+') T9 ORDER BY '+@Sort+') ORDER BY '+@Sort PRINT @Str EXEC sp_ExecuteSql @Str GO 其实，以上语句可以简化为： SELECT TOP 页大小 * FROM Table1 WHERE (ID NOT IN (SELECT TOP 页大小*页数 id FROM 表 ORDER BY id)) ORDER BY ID 但这个存储过程有一个致命的缺点，就是它含有NOT IN字样。虽然我可以把它改造为： SELECT TOP 页大小 * FROM Table1 WHERE not exists (select * from (select top (页大小*页数) * from table1 order by id) b where b.id=a.id ) order by id 即，用not exists来代替not in，但我们前面已经谈过了，二者的执行效率实际上是没有区别的。 既便如此，用TOP 结合NOT IN的这个方法还是比用游标要来得快一些。 虽然用not exists并不能挽救上个存储过程的效率，但使用SQL SERVER中的TOP关键字却是一个非常明智的选择。因为分页优化的最终目的就是避免产生过大的记录集，而我们在前面也已经提到了TOP的优势，通过TOP 即可实现对数据量的控制。 在分页算法中，影响我们查询速度的关键因素有两点：TOP和NOT IN。TOP可以提高我们的查询速度，而NOT IN会减慢我们的查询速度，所以要提高我们整个分页算法的速度，就要彻底改造NOT IN，同其他方法来替代它。 我们知道，几乎任何字段，我们都可以通过max(字段)或min(字段)来提取某个字段中的最大或最小值，所以如果这个字段不重复，那么就可以利用这些不重复的字段的max或min作为分水岭，使其成为分页算法中分开每页的参照物。在这里，我们可以用操作符“>”或“<”号来完成这个使命，使查询语句符合SARG形式。如： Select top 10 * from table1 where id>200 于是就有了如下分页方案： select top 页大小 * from table1 where id> (select max (id) from (select top ((页码-1)*页大小) id from table1 order by id) as T ) order by id 在选择即不重复值，又容易分辨大小的列时，我们通常会选择主键。下表列出了笔者用有着1000万数据的办公自动化系统中的表，在以GID（GID是主键，但并不是聚集索引。）为排序列、提取gid,fariqi,title字段，分别以第1、10、100、500、1000、1万、10万、25万、50万页为例，测试以上三种分页方案的执行速度：（单位：毫秒） 页　码 方案1 方案2 方案3 1 60 30 76 10 46 16 63 100 1076 720 130 500 540 12943 83 1000 17110 470 250 1万 24796 4500 140 10万 38326 42283 1553 25万 28140 128720 2330 50万 121686 127846 7168 从上表中，我们可以看出，三种存储过程在执行100页以下的分页命令时，都是可以信任的，速度都很好。但第一种方案在执行分页1000页以上后，速度就降了下来。第二种方案大约是在执行分页1万页以上后速度开始降了下来。而第三种方案却始终没有大的降势，后劲仍然很足。 在确定了第三种分页方案后，我们可以据此写一个存储过程。大家知道SQL SERVER的存储过程是事先编译好的SQL语句，它的执行效率要比通过WEB页面传来的SQL语句的执行效率要高。下面的存储过程不仅含有分页方案，还会根据页面传来的参数来确定是否进行数据总数统计。 -- 获取指定页的数据 CREATE PROCEDURE pagination3 @tblName　 varchar(255),　　　 -- 表名 @strGetFields varchar(1000) = '*',　-- 需要返回的列 @fldName varchar(255)='',　　　-- 排序的字段名 @PageSize　 int = 10,　　　　　-- 页尺寸 @PageIndex　int = 1,　　　　　 -- 页码 @doCount　bit = 0,　 -- 返回记录总数, 非 0 值则返回 @OrderType bit = 0,　-- 设置排序类型, 非 0 值则降序 @strWhere　varchar(1500) = ''　-- 查询条件 (注意: 不要加 where) AS declare @strSQL　 varchar(5000)　　　 -- 主语句 declare @strTmp　 varchar(110)　　　　-- 临时变量 declare @strOrder varchar(400)　　　　-- 排序类型 if @doCount != 0 begin if @strWhere !='' set @strSQL = \"select count(*) as Total from [\" + @tblName + \"] where \"+@strWhere else set @strSQL = \"select count(*) as Total from [\" + @tblName + \"]\" end --以上代码的意思是如果@doCount传递过来的不是0，就执行总数统计。以下的所有代码都是@doCount为0的情况 else begin if @OrderType != 0 begin set @strTmp = \"<(select min\" set @strOrder = \" order by [\" + @fldName +\"] desc\" --如果@OrderType不是0，就执行降序，这句很重要！ end else begin set @strTmp = \">(select max\" set @strOrder = \" order by [\" + @fldName +\"] asc\" end if @PageIndex = 1 begin if @strWhere != '' set @strSQL = \"select top \" + str(@PageSize) +\" \"+@strGetFields+ \"　from [\" + @tblName + \"] where \" + @strWhere + \" \" + @strOrder else set @strSQL = \"select top \" + str(@PageSize) +\" \"+@strGetFields+ \"　from [\"+ @tblName + \"] \"+ @strOrder --如果是第一页就执行以上代码，这样会加快执行速度 end else begin --以下代码赋予了@strSQL以真正执行的SQL代码 set @strSQL = \"select top \" + str(@PageSize) +\" \"+@strGetFields+ \"　from [\" + @tblName + \"] where [\" + @fldName + \"]\" + @strTmp + \"([\"+ @fldName + \"]) from (select top \" + str((@PageIndex-1)*@PageSize) + \" [\"+ @fldName + \"] from [\" + @tblName + \"]\" + @strOrder + \") as tblTmp)\"+ @strOrder if @strWhere != '' set @strSQL = \"select top \" + str(@PageSize) +\" \"+@strGetFields+ \"　from [\" + @tblName + \"] where [\" + @fldName + \"]\" + @strTmp + \"([\" + @fldName + \"]) from (select top \" + str((@PageIndex-1)*@PageSize) + \" [\" + @fldName + \"] from [\" + @tblName + \"] where \" + @strWhere + \" \" + @strOrder + \") as tblTmp) and \" + @strWhere + \" \" + @strOrder end end exec (@strSQL) GO 上面的这个存储过程是一个通用的存储过程，其注释已写在其中了。 在大数据量的情况下，特别是在查询最后几页的时候，查询时间一般不会超过9秒；而用其他存储过程，在实践中就会导致超时，所以这个存储过程非常适用于大容量数据库的查询。 笔者希望能够通过对以上存储过程的解析，能给大家带来一定的启示，并给工作带来一定的效率提升，同时希望同行提出更优秀的实时数据分页算法。 四、聚集索引的重要性和如何选择聚集索引 在上一节的标题中，笔者写的是：实现小数据量和海量数据的通用分页显示存储过程。这是因为在将本存储过程应用于“办公自动化”系统的实践中时，笔者发现这第三种存储过程在小数据量的情况下，有如下现象： 1、分页速度一般维持在1秒和3秒之间。 2、在查询最后一页时，速度一般为5秒至8秒，哪怕分页总数只有3页或30万页。 虽然在超大容量情况下，这个分页的实现过程是很快的，但在分前几页时，这个1－3秒的速度比起第一种甚至没有经过优化的分页方法速度还要慢，借用户的话说就是“还没有ACCESS数据库速度快”，这个认识足以导致用户放弃使用您开发的系统。 笔者就此分析了一下，原来产生这种现象的症结是如此的简单，但又如此的重要：排序的字段不是聚集索引！ 本篇文章的题目是：“查询优化及分页算法方案”。笔者只所以把“查询优化”和“分页算法”这两个联系不是很大的论题放在一起，就是因为二者都需要一个非常重要的东西――聚集索引。 在前面的讨论中我们已经提到了，聚集索引有两个最大的优势： 1、以最快的速度缩小查询范围。 2、以最快的速度进行字段排序。 第1条多用在查询优化时，而第2条多用在进行分页时的数据排序。 而聚集索引在每个表内又只能建立一个，这使得聚集索引显得更加的重要。聚集索引的挑选可以说是实现“查询优化”和“高效分页”的最关键因素。 但要既使聚集索引列既符合查询列的需要，又符合排序列的需要，这通常是一个矛盾。 笔者前面“索引”的讨论中，将fariqi，即用户发文日期作为了聚集索引的起始列，日期的精确度为“日”。这种作法的优点，前面已经提到了，在进行划时间段的快速查询中，比用ID主键列有很大的优势。 但在分页时，由于这个聚集索引列存在着重复记录，所以无法使用max或min来最为分页的参照物，进而无法实现更为高效的排序。而如果将ID主键列作为聚集索引，那么聚集索引除了用以排序之外，没有任何用处，实际上是浪费了聚集索引这个宝贵的资源。 为解决这个矛盾，笔者后来又添加了一个日期列，其默认值为getdate()。用户在写入记录时，这个列自动写入当时的时间，时间精确到毫秒。即使这样，为了避免可能性很小的重合，还要在此列上创建UNIQUE约束。将此日期列作为聚集索引列。 有了这个时间型聚集索引列之后，用户就既可以用这个列查找用户在插入数据时的某个时间段的查询，又可以作为唯一列来实现max或min，成为分页算法的参照物。 经过这样的优化，笔者发现，无论是大数据量的情况下还是小数据量的情况下，分页速度一般都是几十毫秒，甚至0毫秒。而用日期段缩小范围的查询速度比原来也没有任何迟钝。 聚集索引是如此的重要和珍贵，所以笔者总结了一下，一定要将聚集索引建立在： 1、您最频繁使用的、用以缩小查询范围的字段上； 2、您最频繁使用的、需要排序的字段上。 应用程序设计 应用程序设计在决定使用 Microsoft® SQL Server™ 2000 的系统的性能方面起关键作用。将客户端视为控制实体而非数据库服务器。客户端确定查询类型、何时提交查询以及如何处理查询结果。这反过来对服务器上的锁类型和持续时间、I/O 活动量以及处理 (CPU) 负荷等产生主要影响，并由此影响总体性能的优劣。 正因为如此，在应用程序的设计阶段做出正确决策十分重要。然而，即使在使用总控应用程序时（这种情况下似乎不可能更改客户端应用程序）出现性能问题，也不会改变影响性能的根本因素：客户端具有支配作用，如果不更改客户端则许多性能问题都无法解决。设计优秀的应用程序允许 SQL Server 支持成千上万的并发用户。反之，设计差的应用程序会防碍即使是最强大的服务器平台处理少数用户的请求。 客户端应用程序的设计准则包括： ·                     消除过多的网络流量。 客户端和 SQL Server 之间的网络往返通常是数据库应用程序性能较差的首要原因，甚至超过了服务器和客户端之间传送的数据量这一因素的影响。网络往返描述在客户端应用程序和 SQL Server 之间为每个批处理和结果集发送的会话流量。通过使用存储过程，可以将网络往返减到最小。例如，如果应用程序根据从 SQL Server 收到的数据值采取不同的操作，只要可能就应直接在存储过程中做出决定，从而消除过多的网络流量。 如果存储过程中有多个语句，则默认情况下，SQL Server 在每个语句完成时给客户端应用程序发送一条消息，详细说明每个语句所影响的行数。大多数应用程序不需要这些消息。如果确信应用程序不需要它们，可以禁用这些消息，以提高慢速网络的性能。请使用 SET NOCOUNT 会话设置为应用程序禁用这些消息。有关更多信息，请参见 SET NOCOUNT。 ·                     使用小结果集。 检索没必要大的结果集（如包含上千行）并在客户端浏览将增加 CPU 和网络 I/O 的负载，使应用程序的远程使用能力降低并限制多用户可伸缩性。最好将应用程序设计为提示用户输入足够的信息，以便查询提交后生成大小适中的结果集。有关更多信息，请参见使用高效数据检索优化应用程序性能。 可帮助实现上述目标的应用程序设计技术包括：在生成查询时对通配符进行控制，强制某些输入字段，不允许特殊查询，以及使用 TOP、PERCENT 或 SET ROWCOUNT 等 Transact-SQL 语句限制查询返回的行数。有关更多信息，请参见使用 TOP 和 PERCENT 限制结果集和 SET ROWCOUNT。 ·                     允许在用户需要重新控制应用程序时取消正在执行的查询。 应用程序决不应强迫用户重新启动客户机以取消查询。无视这一点将导致无法解决的性能问题。如果应用程序取消查询（例如使用开放式数据库连接 (ODBC) sqlcancel 函数取消查询），应对事务级别予以适当的考虑。例如，取消查询并不会提交或回滚用户定义的事务。取消查询后，所有在事务内获取的锁都将保留。因此，在取消查询后始终要提交或回滚事务。同样的情况也适用于可用于取消查询的 DB-Library 和其它应用程序接口 (API)。 ·                     始终实现查询或锁定超时。 不要让查询无限期运行。调用适当的 API 以设置查询超时。例如，使用 ODBC SQLSetStmtOption 函数。 有关设置查询超时的更多信息，请参见 ODBC API 文档。 有关设置锁定超时的更多信息，请参见自定义锁超时。 ·                     不要使用不允许显式控制发送到 SQL Server 的 SQL 语句的应用程序开发工具。 如果工具基于更高级的对象透明地生成 Transact-SQL 语句，而且不提供诸如查询取消、查询超时和完全事务控制等关键功能，则不要使用这类工具。如果应用程序生成透明的 SQL 语句，通常不可能维护好的性能或解决性能问题，因为在这种情况下不允许对事务和锁定问题进行显式控制，而这一点对性能状况至关重要。 ·                     不要将决策支持和联机事务处理 (OLTP) 查询混在一起。有关更多信息，请参见联机事务处理与决策支持。 ·                     只在必要时才使用游标。 游标是关系数据库中的有用工具，但使用游标完成任务始终比使用面向集合的 SQL 语句花费多。 当使用面向集合的 SQL 语句时，客户端应用程序让服务器更新满足指定条件的记录集。服务器决定如何作为单个工作单元完成更新。当通过游标更新时，客户端应用程序要求服务器为每行维护行锁或版本信息，而这只是为了客户端在提取行后请求更新行。 而且，使用游标意味着服务器通常要在临时存储中维护客户端的状态信息，如用户在服务器上的当前行集。为众多客户端维护这类状态信息需消耗大量的服务器资源。对于关系数据库，更好的策略是让客户端应用程序快速进出，以便在各次调用之间不在服务器上维护客户端的状态信息。面向集合的 SQL 语句支持此策略。 然而，如果查询使用游标，请确定如果使用更高效的游标类型（如快速只进游标）或单个查询能否更高效地编写游标查询。有关更多信息，请参见使用高效数据检索优化应用程序性能。 ·                     使事务尽可能简短。有关更多信息，请参见事务和批处理对应用程序性能的影响。 ·                     使用存储过程。有关更多信息，请参见存储过程对应用程序性能的影响。 ·                     使用 Prepared Execution 来执行参数化 SQL 语句。有关更多信息，请参见 Prepared Execution (ODBC)。 ·                     始终处理完所有结果。 不要设计或使用在未取消查询时就停止处理结果行的应用程序。否则通常会导致阻塞和降低性能。有关更多信息，请参见了解和避免阻塞。 ·                     确保将应用程序设计为可避免死锁。有关更多信息，请参见将死锁减至最少。 ·                     确保已设置所有能够优化分布式查询性能的适当选项。有关更多信息，请参见优化分布式查询。 在应用系统的设计中，要着重考虑以下几点： 　　1．合理使用索引 索引是数据库中重要的数据结构，它的根本目的就是为了提高查询效率。现在大多数的数据库产品都采用IBM最先提出的ISAM索引结构。索引的使用要恰到好处，其使用原则如下： ●在经常进行连接，但是没有指定为外键的列上建立索引，而不经常连接的字段则由优化器自动生成索引。 ●在频繁进行排序或分组（即进行group by或order by操作）的列上建立索引。 ●在条件表达式中经常用到的不同值较多的列上建立检索，在不同值少的列上不要建立索引。比如在雇员表的“性别”列上只有“男”与“女”两个不同值，因此就无必要建立索引。如果建立索引不但不会提高查询效率，反而会严重降低更新速度。 ●如果待排序的列有多个，可以在这些列上建立复合索引（compound index）。 ●使用系统工具。如Informix数据库有一个tbcheck工具，可以在可疑的索引上进行检查。在一些数据库服务器上，索引可能失效或者因为频繁操作而使得读取效率降低，如果一个使用索引的查询不明不白地慢下来，可以试着用tbcheck工具检查索引的完整性，必要时进行修复。另外，当数据库表更新大量数据后，删除并重建索引可以提高查询速度。 2．避免或简化排序 应当简化或避免对大型表进行重复的排序。当能够利用索引自动以适当的次序产生输出时，优化器就避免了排序的步骤。以下是一些影响因素： ●索引中不包括一个或几个待排序的列； ●group by或order by子句中列的次序与索引的次序不一样； ●排序的列来自不同的表。 为了避免不必要的排序，就要正确地增建索引，合理地合并数据库表（尽管有时可能影响表的规范化，但相对于效率的提高是值得的）。如果排序不可避免，那么应当试图简化它，如缩小排序的列的范围等。 3．消除对大型表行数据的顺序存取 在嵌套查询中，对表的顺序存取对查询效率可能产生致命的影响。比如采用顺序存取策略，一个嵌套3层的查询，如果每层都查询1000行，那么这个查询就要查询10亿行数据。避免这种情况的主要方法就是对连接的列进行索引。例如，两个表：学生表（学号、姓名、年龄……）和选课表（学号、课程号、成绩）。如果两个表要做连接，就要在“学号”这个连接字段上建立索引。 还可以使用并集来避免顺序存取。尽管在所有的检查列上都有索引，但某些形式的where子句强迫优化器使用顺序存取。下面的查询将强迫对orders表执行顺序操作： SELECT ＊ FROM orders WHERE (customer_num=104 AND order_num>1001) OR order_num=1008 虽然在customer_num和order_num上建有索引，但是在上面的语句中优化器还是使用顺序存取路径扫描整个表。因为这个语句要检索的是分离的行的集合，所以应该改为如下语句： SELECT ＊ FROM orders WHERE customer_num=104 AND order_num>1001 UNION SELECT ＊ FROM orders WHERE order_num=1008 这样就能利用索引路径处理查询。 4．避免相关子查询 一个列的标签同时在主查询和where子句中的查询中出现，那么很可能当主查询中的列值改变之后，子查询必须重新查询一次。查询嵌套层次越多，效率越低，因此应当尽量避免子查询。如果子查询不可避免，那么要在子查询中过滤掉尽可能多的行。 5．避免困难的正规表达式 MATCHES和LIKE关键字支持通配符匹配，技术上叫正规表达式。但这种匹配特别耗费时间。例如：SELECT ＊ FROM customer WHERE zipcode LIKE “98_ _ _” 即使在zipcode字段上建立了索引，在这种情况下也还是采用顺序扫描的方式。如果把语句改为SELECT ＊ FROM customer WHERE zipcode >“98000”，在执行查询时就会利用索引来查询，显然会大大提高速度。 另外，还要避免非开始的子串。例如语句：SELECT ＊ FROM customer WHERE zipcode[2，3] >“80”，在where子句中采用了非开始子串，因而这个语句也不会使用索引。 6．使用临时表加速查询 把表的一个子集进行排序并创建临时表，有时能加速查询。它有助于避免多重排序操作，而且在其他方面还能简化优化器的工作。例如： SELECT cust.name，rcvbles.balance，……other columns FROM cust，rcvbles WHERE cust.customer_id = rcvlbes.customer_id AND rcvblls.balance>0 AND cust.postcode>“98000” ORDER BY cust.name 如果这个查询要被执行多次而不止一次，可以把所有未付款的客户找出来放在一个临时文件中，并按客户的名字进行排序： SELECT cust.name，rcvbles.balance，……other columns FROM cust，rcvbles WHERE cust.customer_id = rcvlbes.customer_id 优化实用工具和工具性能 可在生产数据库上执行以获得最佳性能收益的三个操作包括： ·                     备份和还原操作。 ·                     将数据大容量复制到表中。 ·                     执行数据库控制台命令 (DBCC) 操作。 一般情况下，不需要优化这些操作。然而，在性能很关键的情形中，可采用一些技巧优化性能。 　Microsoft SQL Server数据库内核用1个基于费用的查询优化器自动优化向SQL提交的数据查询操作。数据操作查询是指支持SQL关键字WHERE或HAVING的查询，如SELECT、DELETE和UPDATE。基于费用的查询优化器根据统计信息产生子句的费用估算。 　　了解优化器数据处理过程的简单方法是检测SHOWPLAN命令的输出结果。如果用基于字符的工具(例如isql)，可以通过键入SHOW SHOWPLAN ON来得到SHOWPLAN命令的输出。如果使用图形化查询，比如SQL Enterprise Manager中的查询工具或isql/w，可以设定配置选项来提供这一信息。 　SQL Server的优化通过3个阶段完成:查询分析、索引选择、合并选择: 1.查询分析 　　在查询分析阶段，SQL Server优化器查看每一个由正规查询树代表的子句，并判断它是否能被优化。SQL Server一般会尽量优化那些限制扫描的子句。例如，搜索和/或合并子句。但是不是所有合法的SQL语法都可以分成可优化的子句，如含有SQL不等关系符“<>”的子句。因为“<>”是1个排斥性的操作符，而不是1个包括性的操作符，所在扫描整个表之前无法确定子句的选择范围会有多大。当1个关系型查询中含有不可优化的子句时，执行计划用表扫描来访问查询的这个部分，对于查询树中可优化的SQL Server子句，则由优化器执行索引选择。 2.索引选择 　　对于每个可优化的子句，优化器都查看数据库系统表，以确定是否有相关的索引能用于访问数据。只有当索引中的列的1个前缀与查询子句中的列完全匹配时，这个索引才被认为是有用的。因为索引是根据列的顺序构造的，所以要求匹配是精确的匹配。对于分簇索引，原来的数据也是根据索引列顺序排序的。想用索引的次要列访问数据，就像想在电话本中查找所有姓为某个姓氏的条目一样，排序基本上没有什么用，因为你还是得查看每一行以确定它是否符合条件。如果1个子句有可用的索引，那么优化器就会为它确定选择性。 　　所以在设计过程中，要根据查询设计准则仔细检查所有的查询，以查询的优化特点为基础设计索引。 　　(1)比较窄的索引具有比较高的效率。对于比较窄的索引来说，每页上能存放较多的索引行，而且索引的级别也较少。所以，缓存中能放置更多的索引页，这样也减少了I/O操作。 　　(2)SQL Server优化器能分析大量的索引和合并可能性。所以与较少的宽索引相比，较多的窄索引能向优化器提供更多的选择。但是不要保留不必要的索引，因为它们将增加存储和维护的开支。对于复合索引、组合索引或多列索引，SQL Se 优化服务器性能 Microsoft® SQL Server™ 2000 自动调整很多服务器配置选项，因此系统管理员只需做很少的调整（如果有）。这些配置选项可以由系统管理员修改，但一般建议保留为默认值，以使 SQL Server 能根据运行时的情况自动对自身进行调整。 不过，如果需要，可以配置下列组件以优化服务器性能： ·                     SQL Server 内存 ·                     I/O 子系统 ·                     Microsoft Windows NT® 选项 MSSQL是怎样使用内存的: 　　最大的开销一般是用于数据缓存，如果内存足够，它会把用过的数据和觉得你会用到的数据统统扔到内存中，直到内存不足的时候，才把命中率低的数据给清掉。所以一般我们在看statistics io的时候，看到的physics read都是0。 　　其次就是查询的开销，一般地说，hash join是会带来比较大的内存开销的，而merge join和nested loop的开销比较小，还有排序和中间表、游标也是会有比较大的开销的。 　　所以用于关联和排序的列上一般需要有索引。 　　再其次就是对执行计划、系统数据的存储，这些都是比较小的。 　　我们先来看数据缓存对性能的影响，如果系统中没有其它应用程序来争夺内存，数据缓存一般是越多越好，甚至有些时候我们会强行把一些数据pin在高速缓存中。但是如果有其它应用程序，虽然在需要的时候MSSQL会释放内存，但是线程切换、IO等待这些工作也是需要时间的，所以就会造成性能的降低。这样我们就必须设置MSSQL的最大内存使用。可以在SQL Server 属性（内存选项卡）中找到配置最大使用内存的地方，或者也可以使用sp_configure来完成。如果没有其它应用程序，那么就不要限制MSSQL对内存的使用。 　　然后来看查询的开销，这个开销显然是越低越好，因为我们不能从中得到好处，相反，使用了越多的内存多半意味着查询速度的降低。所以我们一般要避免中间表和游标的使用，在经常作关联和排序的列上建立索引。 不更改代码的情况下如何优化数据库系统 这个问题很多DBA可能都碰到过吧：比如刚接手一个旧有系统，原来的厂商不允许对代码修改，或者是系统应用比较关键。不允许作修改，或者是源代码出于商业目的，进行了一定程度的加密，还有的时候可能是行政因素--领导为了避免责任，不允许你这样做，但这个时候，系统的性能上的问题还比较严重，还有其他办法怎么对系统进行优化么? 在这里我尝试总结一下可能有的途径。 针对特定的SQL进行\"外科手术\" (Metalink 122812.1)，改进执行计划 ·                                 更新统计信息 (调整采样率/柱状图统计) ·                                 调整索引 (添加或调整合适的索引，删除不必要的索引) ·                                 创建物化试图(用空间开销来换取时间收益) 优化OS和数据库以外的其他东西 首先优化操作系统-比如核心参数的合理调整，操作系统资源的合理分配; 磁盘IO的调整,这是很重要的一部分，因为磁盘IO速度很容易造成系统瓶颈;网络资源的优化-TCP/IP的参数调整; 调整Oracle初始化参数 优化器模式的设定,db_cache 参数等设定,sga 大小等参数设定，都对数据库性能有着重要的影响。 合理的系统资源调度 在一些批处理操作为主的系统中，系统资源的调度是比较重要的，调度不合理，很容易造成资源争用。有的系统可能在系统创建之初调度是比较合理的，经过一段时间运行之后，可能因为数据量的变化，SQL语句的执行计划变化等会造成操作时间上的重叠，这肯定会给系统带来压力上的问题。 调整数据库对象 ·                                 调整pctfree ,freelist ，存储参数 ·                                 调整表空间文件和数据库对象（表、索引）的磁盘分布。 ·                                 cache 一些常用的数据库对象。 系统Bug问题带来的影响/升级改进性能 Oracle软件Bug多多，系统运行初期有的Bug带来的危害还不够明显，随着时间的推移，个别的Bug会给系统性能造成问题。这个时候对系统的Bug 修复已经对数据库系统进行升级就是必要的。通过升级，修正Oracle软件缺陷，同时在升级后也可能会增强数据库引擎的效率。当然，也要注意升级可能带来的不良的影响。 ·                     　                       操作系统相关优化 1. 操作系统性能的好坏直接影响数据库的使用性能，如果操作系统存在问题，如CPU过载、过度内存交换、磁盘I/O瓶颈等，在这种情况下，单纯进行数据库内部性能调整是不会改善系统性能的。我们可以通过Windows NT的系统监视器(System Monitor)来监控各种设备，发现性能瓶颈。　　CPU 一种常见的性能问题就是缺乏处理能力。系统的处理能力是由系统的CPU数量、类型和速度决定的。如果系统没有足够的CPU处理能力，它就不能足够快地处理事务以满足需要。我们可以使用System Monitor确定CPU的使用率，如果以75%或更高的速率长时间运行，就可能碰到了CPU瓶颈问题，这时应该升级CPU。但是升级前必须监视系统的其他特性，如果是因为SQL语句效率非常低，优化语句就有助于解决较低的CPU利用率。而当确定需要更强的处理能力，可以添加CPU或者用更快的CPU 替换。　　内存 SQL Server可使用的内存量是SQL Server性能最关键因素之一。而内存同I/O子系统的关系也是一个非常重要的因素。例如，在I/O操作频繁的系统中，SQL Server用来缓存数据的可用内存越多，必须执行的物理I/O也就越少。这是因为数据将从数据缓存中读取而不是从磁盘读取。同样，内存量的不足会引起明显的磁盘读写瓶颈，因为系统缓存能力不足会引起更多的物理磁盘I/O。　　可以利用System Monitor检查SQL Server的Buffer Cache Hit Ratio计数器，如果命中率经常低于90%，就应该添加更多的内存。　　I/O子系统由I/O子系统发生的瓶颈问题是数据库系统可能遇到的最常见的同硬件有关的问题。配置很差的I/O子系统引起性能问题的严重程度仅次于编写很差的SQL语句。I/O子系统问题是这样产生的，一个磁盘驱动器能够执行的I/O操作是有限的，一般一个普通的磁盘驱动器每秒只能处理85次I/O操作，如果磁盘驱动器超载，到这些磁盘驱动器的I/O操作就要排队，SQL的I/O延迟将很长。这可能会使锁持续的时间更长，或者使线程在等待资源的过程中保持空闲状态，其结果就是整个系统的性能受到影响。 解决I/O子系统有关的问题也许是最容易的，多数情况下，增加磁盘驱动器就可以解决这个性能问题。　 　当然，影响性能的因素很多，而应用又各不相同，找出一个通用的优化方案是很困难的，只能是在系统开发和维护的过程中针对运行的具体情况，不断加以调整。 2　与SQL Server相关的硬件系统 　　与SQL Server有关的硬件设计包括系统处理器、内存、磁盘子系统和网络，这4个部分基本上构成了硬件平台，Windows NT和SQL Server运行于其上。 2.1　系统处理器(CPU) 　　根据自己的具体需要确定CPU结构的过程就是估计在硬件平台上占用CPU的工作量的过程。从以往的经验看，CPU配置最少应是1个80586/100处理器。如果只有2～3个用户，这就足够了，但如果打算支持更多的用户和关键应用，推荐采用Pentium Pro或PⅡ级CPU。 2.2　内存(RAM) 　　为SQL Server方案确定合适的内存设置对于实现良好的性能是至关重要的。SQL Server用内存做过程缓存、数据和索引项缓存、静态服务器开支和设置开支。SQL Server最多能利用2GB虚拟内存，这也是最大的设置值。还有一点必须考虑的是Windows NT和它的所有相关的服务也要占用内存。 　　Windows NT为每个WIN32应用程序提供了4GB的虚拟地址空间。这个虚拟地址空间由Windows NT虚拟内存管理器(VMM)映射到物理内存上，在某些硬件平台上可以达到4GB。SQL Server应用程序只知道虚拟地址，所以不能直接访问物理内存，这个访问是由VMM控制的。Windows NT允许产生超出可用的物理内存的虚拟地址空间，这样当给SQL Server分配的虚拟内存多于可用的物理内存时，会降低SQL Server的性能。 　　这些地址空间是专门为SQL Server系统设置的，所以如果在同一硬件平台上还有其它软件(如文件和打印共享，应用程序服务等)在运行，那么应该考虑到它们也占用一部分内存。一般来说硬件平台至少要配置32MB的内存，其中，Windows NT至少要占用16MB。1个简单的法则是，给每一个并发的用户增加100KB的内存。例如，如果有100个并发的用户，则至少需要32MB+100用户*100KB=42MB内存，实际的使用数量还需要根据运行的实际情况调整。可以说，提高内存是提高系统性能的最经济的途径。 　2.3　磁盘子系统 　　设计1个好的磁盘I/O系统是实现良好的SQL Server方案的一个很重要的方面。这里讨论的磁盘子系统至少有1个磁盘控制设备和1个或多个硬盘单元，还有对磁盘设置和文件系统的考虑。智能型SCSI-2磁盘控制器或磁盘组控制器是不错的选择，其特点如下: 　　(1)控制器高速缓存。　　(2)总线主板上有处理器，可以减少对系统CPU的中断。　　(3)异步读写支持。　　(4)32位RAID支持。　　(5)快速SCSI—2驱动。　　(6)超前读高速缓存(至少1个磁道)。 3　检索策略 　　在精心选择了硬件平台，又实现了1个良好的数据库方案，并且具备了用户需求和应用方面的知识后，现在应该设计查询和索引了。有2个方面对于在SQL Server上取得良好的查询和索引性能是十分重要的，第1是根据SQL Server优化器方面的知识生成查询和索引;第2是利用SQL Server的性能特点，加强数据访问操作。","title":"数据库优化(超级详细),转文，值得一读"},{"content":"一.MYSQL的命令行模式的设置： 桌面->我的电脑->属性->环境变量->新建->PATH=\";path/mysql/bin;\"  其中path为MYSQL的安装 路径。 二.命令行进入MYSQL的方法： 1.C:\\>mysql -h hostname -u username -p 按ENTER键，等待然后输入密码，这里hostname为服务器的名称，如localhost，username为MYSQL 的用户名，如root.进入命令行就可以直接操作MYSQL了。 三.从数据库导出数据库文件： 1.将数据库mydb导出到e:\\mysql\\mydb.sql文件中： 打开开始->运行->输入cmd进入命令行模式 c:\\>mysqldump -h localhost -u root -p mydb >e:\\mysql\\mydb.sql 然后输入密码，等待一会导出就成功了，可以到目标文件中检查是否成功。 2.将数据库mydb中的mytable导出到e:\\mysql\\mytable.sql文件中： c:\\>mysqldump -h localhost -u root -p mydb mytable >e:\\mysql\\mytable.sql 3.将数据库mydb的结构导出到e:\\mysql\\mydb_stru.sql文件中： c:\\>mysqldump -h localhost -u root -p mydb --add-drop-table >e:\\mysql\\mydb_stru.sql //-h localhost可以省略，其一般在虚拟主机上用 四.从外部文件导入数据到数据库： 从e:\\mysql\\mydb2.sql中将文件中的SQL语句导入数据库中： c:\\>mysql -h localhost -u root -p mydb2 <e:\\mysql\\mydb2.sql 然后输入密码，就OK了 五.关于导入文件大小限制问题的解决: 默认情况下：mysql对导入的文件大小有限制的，最大为2M，所以当文件很大时，直接无法导入， 解决列举如下： 1.在php.ini中修改相关参数： 影响Mysql导入文件大小的参数有三个： memory_limit=128M, upload_max_filesize=2M, post_max_size=8M 修改upload_max_filesize=200M这里修改满足你需要的大小，可以同时修改其他两项 memory_limit=250M ,post_max_size=200M.这样就可以导入200M以下的.sql文件了。 上文是把mysql放置在系统路径下，其实不放也可以。如我的mysql安装目录为D:\\MySQL Server 5.0; 则首先打开dos窗口，然后输入D:(没有'\\')回车 此时应该会出现D:\\>这样的标志，然后在其后输入D:\\MySQL Server 5.0\\bin回车 出现D:\\MySQL Server 5.0\\bin>接着输入mysqldump -u root -p 数据库名 >数据库名.sql(也可 以输入路径); (具体参照上面) 导入文件同样，只是改了'>'为'<'就可以了，或者直接用source也许： 常用source命令 进入mysql数据库控制台  : 如 mysql -u root -p mysql>use 数据库 然后使用source命令，后面参数为脚本文件(这里用到的是.sql) mysql>source d:\\mydb.sql","title":"mysql导入导出.sql文件备份还原数据库"},{"content":"在创建数据库的时候，一直报的错误是 “No such table xxx” ,其中的原因可以可能是 ：1、没有调用 db.getWritableDatase()或readable 2. 数据库已经创建过就不会执行onCreate 和 onUpdate 第二种错误解决办法是 在 构造方法中将版本升级 ，在 onUpdata中在执行onCreate()方法，只要是数据库的名字存在，那么onCreate方法就不会在执行。","title":"创建数据库 出现No such table xxx"},{"content":"一.\"SQL Server 不存在或访问被拒绝\" 这个是最复杂的,错误发生的原因比较多,需要检查的方面也比较多. 一般说来,有以下几种可能性: 1,SQL Server名称或IP地址拼写有误 2,服务器端网络配置有误 3,客户端网络配置有误 要解决这个问题,我们一般要遵循以下的步骤来一步步找出导致错误的原因. ============= 首先,检查网络物理连接 ============= ping <服务器IP地址/服务器名称> 如果 ping <服务器IP地址> 不成功,说明物理连接有问题,这时候要检查硬件设备,如网卡,HUB,路由器等. 还有一种可能是由于客户端和服务器之间安装有防火墙软件造成的,比如 ISA Server.防火墙软件可能会屏蔽对 ping,telnet 等的响应 因此在检查连接问题的时候,我们要先把防火墙软件暂时关闭,或者打开所有被封闭的端口. 如果ping <服务器IP地址> 成功而,ping <服务器名称> 失败 则说明名字解析有问题,这时候要检查 DNS 服务是否正常. 有时候客户端和服务器不在同一个局域网里面,这时候很可能无法直接使用服务器名称来标识该服务器,这时候我们可以使用HOSTS文件来进行名字解析, 具体的方法是: 1.使用记事本打开HOSTS文件（一般情况下位于C:\\WINNT\\system32\\drivers\\etc）. 添加一条IP地址与服务器名称的对应记录,如: 172.168.10.24 myserver 2.或在 SQL Server 的客户端网络实用工具里面进行配置,后面会有详细说明. ============= 其次,使用 telnet 命令检查SQL Server服务器工作状态 ============ telnet <服务器IP地址> 1433 如果命令执行成功,可以看到屏幕一闪之后光标在左上角不停闪动,这说明 SQL Server 服务器工作正常,并且正在监听1433端口的 TCP/IP 连接 如果命令返回\"无法打开连接\"的错误信息,则说明服务器端没有启动 SQL Server 服务, 也可能服务器端没启用 TCP/IP 协议,或者服务器端没有在 SQL Server 默认的端口1433上监听. =============接着,我们要到服务器上检查服务器端的网络配置,检查是否启用了命名管道.是否启用了 TCP/IP 协议等等 ============= 可以利用 SQL Server 自带的服务器网络使用工具来进行检查. 点击:程序 -- Microsoft SQL Server -- 服务器网络使用工具 打开该工具后,在\"常规\"中可以看到服务器启用了哪些协议. 一般而言,我们启用命名管道以及 TCP/IP 协议. 点中 TCP/IP 协议,选择\"属性\",我们可以来检查 SQK Server 服务默认端口的设置 一般而言,我们使用 SQL Server 默认的1433端口.如果选中\"隐藏服务器\",则意味着客户端无法通过枚举服务器来看到这台服务器,起到了保护的作用,但不影响连接. ============= 接下来我们要到客户端检查客户端的网络配置 ============= 我们同样可以利用 SQL Server 自带的客户端网络使用工具来进行检查, 所不同的是这次是在客户端来运行这个工具. 点击:程序 -- Microsoft SQL Server -- 客户端网络使用工具 打开该工具后,在\"常规\"项中,可以看到客户端启用了哪些协议. 一般而言,我们同样需要启用命名管道以及 TCP/IP 协议. 点击 TCP/IP 协议,选择\"属性\",可以检查客户端默认连接端口的设置,该端口必须与服务器一致. 单击\"别名\"选项卡,还可以为服务器配置别名.服务器的别名是用来连接的名称, 连接参数中的服务器是真正的服务器名称,两者可以相同或不同.别名的设置与使用HOSTS文件有相似之处. 通过以上几个方面的检查,基本上可以排除第一种错误. 二.\"无法连接到服务器,用户xxx登陆失败\" 该错误产生的原因是由于SQL Server使用了\"仅 Windows\"的身份验证方式, 因此用户无法使用SQL Server的登录帐户（如 sa ）进行连接.解决方法如下所示: 1.在服务器端使用企业管理器,并且选择\"使用 Windows 身份验证\"连接上 SQL Server 2.展开\"SQL Server组\",鼠标右键点击SQL Server服务器的名称,选择\"属性\",再选择\"安全性\"选项卡 3.在\"身份验证\"下,选择\"SQL Server和 Windows \". 4.重新启动SQL Server服务. 在以上解决方法中,如果在第 1 步中使用\"使用 Windows 身份验证\"连接 SQL Server 失败, 那就通过修改注册表来解决此问题: 1.点击\"开始\"-\"运行\",输入regedit,回车进入注册表编辑器 2.依次展开注册表项,浏览到以下注册表键: [HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\MSSQLServer\\MSSQLServer]","title":"MSSQL数据库连接中的两个最常见错误（觉）"},{"content":"insert语句遇到错误,提示\"insert into附近有语法错误\"。 错误的原因：我用了password这个关键字。 不要使用sql server关键字作字段名！","title":"执行insert等SQL语句时遇到的错误"},{"content":"本人接触IT到现在貌似已经有半年了吧，呵呵，倒是很少写博文！         我已经学习JAVA 6个月啦，对java的封装，继承，多态，抽象，也是有了熟悉的掌握，学习时写过坦克大战游戏，山塞版QQ，学生成绩管理系统，酒店管理系统等等！算了在java语言上入门了！嘻嘻         貌似java本人花了一个月的时间学习，做项目花了一个月，时间很紧，记得那时候的生活真的很累，没人教，只能自己上网络上找资源自己学习，能学的相对较快，跟自己的努力是分不开的，问大家问题啊，是不是编程久了会上瘾呢，貌似我已经上瘾了，说说后面的事吧，后面本人先后学习了，PhotoShop，HTML，DIV+CSS页面布局，可以说在美工上也是入门了，不过做的东西相对没有大师级的那么美观，正在努力中...         后来，加入学校的项目组，开始学习J2EE，呵呵，花了大概两个月的时间，把J2EE的大概只是过了一遍，那时候不知道写博文，所以浪费很多写博文的机会，真是有点小遗憾，不然现在博文也不会少的这么可怜了，说说去了学校项目组学到了什么吧 第一： 前台的：DW这个软件的使用，PhotoShop，自己觉得前台真的很好玩，尤其是那么渲染效果，真心很喜欢，也有比较多的研究，比较擅长用DIV+CSS页面布局,JQuery做页面效果，先后做的东西也比较多，差不多有了半年的设计经验的样子，不过因为跟别人交流的比较少，最近感觉倒是学习进步不大，感觉被卡住了，真心想找个小公司来做兼职啊，主要是想更加的充实自己！ 后台：JSP+MVC模式+Mysql数据库，先后做过一些项目，第一个是在线考试系统，第二个是学校的实训基地网站，效果都还不错！后面还学了3大框架，主流数据库知识都有了解，尤其是Oracle数据库。因为本人觉得那个学了后学其他的数据库相对比较轻松！ 暂时就先写到这吧，以后会经常更新的，各种事都更新进来，不止于IT哈，呵呵！","title":"我的java学习过程"},{"content":"最后一章写的流水账了点大家见谅哈，毕竟我得下班了嘛。 来总结点经验吧，大家看看就好结合自己的情况嘛。          1.首先我能混成这样算是很满足了，其实我每次跳巢去一个新地方工资提高的时候我都很满足，最满足的一次莫过于才来北京的时候。我是幸运的，因为我选了一个好的学习方向，让自己的技术水平走在了平均线以上，恰好最近几年又开始流行这个市场供小于求所以才有我路顺风顺水的提升条件。但其实我更羡慕我那些在2007，08年买了房的同事，因为那时候软件园附近的房价才4000，现在已经8000-10000了。我面临越来越大的压力，甚至不能保证自己明年也能挣到这么高的工资（工资越高压力越大啊），但他们每月只需要面对2000元的月供就可以丰衣足食了。言归正传，做技术这行其实就得紧跟时代啊，时代炒什么扎就得会什么才能过得滋润啊，如果我还是一个.net开发人员哪怕是MVP工资也不过才1万多点而已（我到过得公司都有MVP）。          2.想一想当前这个社会真不是一个安份的社会，正是因为社会不安份所以那些想要安定的人才会去蜂拥的考公务员，大家未必真的是想去当贪官，不过只是要一份稳定罢了，而我们这个行业正是最不安分的那个几个行业中的前3名，所以你想要安定的呆在一个地方简直是做梦。想想我去过得公司，如果那个公司里面老人很少甚至几乎没有真是一件很恐怖的事情，而新来的还满高兴认为周围都是年轻人，我们这个行业在任一个地方呆一年就是老人了，呆三年就是元老了，如果呆了五年以上的话我想你该走了，要不你就该考虑养老或者转行了。哎这是中国当下IT行业的大致情况啊，外国可能不同但你真的要注意下，如果你在公司成了元老而你的职位却没有多大的提高的时候你真的小心了，这不是危言耸听。         3.英语真是个好东西，虽然我的英语一直不好，但我一直都没放弃过学习他，正是因为这样所以我才能混进很多外资公司吧，也许他们认为我不好的英语在一名技术人员身上还是可以接受的。所以大家不管做什么的有有事没事还是多看看英语吧，哪怕多看美剧都好，英语好真的能比别人多挣点可能是1000或者5000甚至…         4.最后回想一下，选择这个行业真的是我的幸运，在这个浮躁的社会中，这个行业里面的人都还算纯洁，每到一处跟同事相处都还很融洽，在这个处处不平的社会里面，在这个行业里你努力了还总能获得或多或少的回报，而且他总是充满了机遇，这样一个还算公平还算有前途的行业我不能不为之庆幸当年毕业时义无反顾的投它的简历。        这让我想起我一个从同事到老朋友常爱说的一句话：人不行不要怪路不平！        大家都多多努力，总还不会拖国家的后腿吧。","title":"我的6年职场人生从月薪800到2万（5）"},{"content":"         数据库优化的讨论可以说是一个永恒的主题。资深的Oracle优化人员通常会要求提出性能问题的人对数据库做一个statspack，贴出数据库配置等等。还有的人认为要抓出执行最慢的语句来进行优化。但实际情况是，提出疑问的人很可能根本不懂执行计划，更不要说statspack了。而我认为，数据库优化，应该首先从大的方面考虑：网络、服务器硬件配置、操作系统配置、Oracle服务器配置、数据结构组织、然后才是具体的调整。实际上网络、硬件等往往无法决定更换，应用程序一般也无法修改，因此应该着重从数据库配置、数据结构上来下手，首先让数据库有一个良好的配置，然后再考虑具体优化某些过慢的语句。我在给我的用户系统进行优化的过程中，总结了一些基本的，简单易行的办法来优化数据库，算是我的三板斧，呵呵。不过请注意，这些不一定普遍使用，甚至有的会有副作用，但是对OLTP系统、基于成本的数据库往往行之有效，不妨试试。（注：附件是Burleson写的用来报告数据库性能等信息的脚本，本文用到） 　　 　　一．设置合适的SGA 　　 　　常常有人抱怨服务器硬件很好，但是Oracle就是很慢。很可能是内存分配不合理造成的。 　　 　　(1)假设内存有512M，这通常是小型应用。建议Oracle的SGA大约240M，其中：共享池（SHARED_POOL_SIZE）可以设置60M到80M，根据实际的用户数、查询等来定。数据块缓冲区可以大致分配120M-150M，8i下需要设置DB_BLOCK_B?RS，DB_BLOCK_B?R*DB_BLOCK_SIZE等于数据块缓冲区大小。9i 下的数据缓冲区可以用db_cache_size来直接分配。 　　 　　(2)假设内存有1G，Oracle 的SGA可以考虑分配500M：共享池分配100M到150M，数据缓冲区分配300M到400M。 　　 　　(3)内存2G，SGA可以考虑分配1.2G，共享池300M到500M，剩下的给数据块缓冲区。 　　 　　(4)内存2G以上：共享池300M到500M就足够啦，再多也没有太大帮助；(Biti_rainy有专述)数据缓冲区是尽可能的大，但是一定要注意两个问题：一是要给操作系统和其他应用留够内存，二是对于32位的操作系统，Oracle的SGA有1.75G的限制。有的32位操作系统上可以突破这个限制，方法还请看Biti的大作吧。 　　 　　二．分析表和索引，更改优化模式 　　 　　Oracle默认优化模式是CHOOSE，在这种情况下，如果表没有经过分析，经常导致查询使用全表扫描，而不使用索引。这通常导致磁盘I/O太多，而导致查询很慢。如果没有使用执行计划稳定性，则应该把表和索引都分析一下，这样可能直接会使查询速度大幅提升。分析表命令可以用ANALYZE TABLE 分析索引可以用ANALYZE INDEX命令。对于少于100万的表，可以考虑分析整个表，对于很大的表，可以按百分比来分析，但是百分比不能过低，否则生成的统计信息可能不准确。可以通过DBA_TABLES的LAST_ANALYZED列来查看表是否经过分析或分析时间，索引可以通过DBA_INDEXES的LAST_ANALYZED列。 　　 　　下面通过例子来说明分析前后的速度对比。（表CASE_GA_AJZLZ大约有35万数据，有主键）首先在SQLPLUS中打开自动查询执行计划功能。(第一次要执行/RDBMS/ADMIN/utlxplan.sql来创建PLAN_TABLE这个表) 　　 　　SQL> SET AUTOTRACE ON 　　SQL>SET TIMING ON 　　 　　通过SET AUTOTRACE ON 来查看语句的执行计划，通过SET TIMING ON 来查看语句运行时间。 　　 　　SQL> select count(*) from CASE_GA_AJZLZ; 　　COUNT(*) 　　---------- 　　346639 　　 　　已用时间: 00: 00: 21.38 　　 　　Execution Plan 　　---------------------------------------------------------- 　　0 SELECT STATEMENT Optimizer=CHOOSE 　　1 0 SORT (AGGREGATE) 　　2 1 TABLE ACCESS (FULL) OF 'CASE_GA_AJZLZ' 　　…………………… 　　 　　请注意上面分析中的TABLE ACCESS(FULL)，这说明该语句执行了全表扫描。而且查询使用了21.38秒。这时表还没有经过分析。下面我们来对该表进行分析： 　　 　　SQL> analyze table CASE_GA_AJZLZ compute statistics; 　　 　　表已分析。 　　 　　已用时间: 00: 05: 357.63 　　 　　然后再来查询： 　　 　　SQL> select count(*) from CASE_GA_AJZLZ; 　　COUNT(*) 　　---------- 　　346639 　　 　　已用时间: 00: 00: 00.71 　　 　　Execution Plan 　　---------------------------------------------------------- 　　0 SELECT STATEMENT Optimizer=FIRST_ROWS (Cost=351 Card=1) 　　1 0 SORT (AGGREGATE) 　　2 1 INDEX (FAST FULL SCAN) OF 'PK_AJZLZ' (UNIQ\u000e) (Cost=351 　　Card=346351) 　　………………………… 　　 　　请注意，这次时间仅仅用了0.71秒！这要归功于INDEX(FAST FULL SCAN)。通过分析表，查询使用了PK_AJZLZ索引，磁盘I/O大幅减少，速度也大幅提升！下面的实用语句可以用来生成分析某个用户的所有表和索引，假设用户是GAXZUSR： 　　 　　SQL> set pagesize 0 　　SQL> spool d:/analyze_tables.sql; 　　SQL> select 'analyze table '||owner||'.'||table_name||' compute statistics;' from dba_tables where owner='GAXZUSR'; 　　SQL> spool off 　　SQL> spool spool d:/analyze_indexes.sql; 　　SQL> select 'analyze index '||owner||'.'||index_name||' compute statistics;' from dba_indexes where owner='GAXZUSR'; 　　SQL> spool off 　　SQL> @d:/analyze_tables.sql 　　SQL> @d:/analyze_indexes.sql 　　 　　解释：上面的语句生成了两个sql文件，分别分析全部的GAXZUSR的表和索引。如果需要按照百分比来分析表，可以修改一下脚本。通过上面的步骤，我们就完成了对表和索引的分析，可以测试一下速度的改进啦。建议定期运行上面的语句，尤其是数据经过大量更新。 　　 　　当然，也可以通过dbms_stats来分析表和索引，更方便一些。但是我仍然习惯上面的方法，因为成功与否会直接提示出来。 　　 　　另外，我们可以将优化模式进行修改。optimizer_mode值可以是RULE、CHOOSE、FIRST_ROWS和ALL_ROWS。对于OLTP系统，可以改成FIRST_ROWS，来要求查询尽快返回结果。这样即使不用分析，在一般情况下也可以提高查询性能。但是表和索引经过分析后有助于找到最合适的执行计划。 　　 　　三．设置cursor_sharing=FORCE 或SIMILAR 　　 　　这种方法是8i才开始有的，oracle805不支持。通过设置该参数，可以强制共享只有文字不同的语句解释计划。例如下面两条语句可以共享： 　　 　　SQL> SELECT * FROM MYTABLE WHERE NAME='tom' 　　SQL> SELECT * FROM MYTABLE WHERE NAME='turner' 　　 　　这个方法可以大幅降低缓冲区利用率低的问题，避免语句重新解释。通过这个功能，可以很大程度上解决硬解析带来的性能下降的问题。个人感觉可根据系统的实际情况，决定是否将该参数改成FORCE。该参数默认是exact。不过一定要注意，修改之前，必须先给ORACLE打补丁，否则改之后oracle会占用100%的CPU,无法使用。对于ORACLE9i，可以设置成SIMILAR，这个设置综合了FORCE和EXACT的优点。不过请慎用这个功能，这个参数也可能带来很大的负面影响！ 　　 　　四．将常用的小表、索引钉在数据缓存KEEP池中 　　 　　内存上数据读取速度远远比硬盘中读取要快，据称，内存中数据读的速度是硬盘的14000倍！如果资源比较丰富，把常用的小的、而且经常进行全表扫描的表给钉内存中，当然是在好不过了。可以简单的通过ALTER TABLE tablename CACHE来实现，在ORACLE8i之后可以使用ALTER TABLE table STORAGE(B?R_POOL KEEP)。一般来说，可以考虑把200数据块之内的表放在keep池中，当然要根据内存大小等因素来定。关于如何查出那些表或索引符合条件，可以使用本文提供的access.sql和access_report.sql。这两个脚本是著名的Oracle专家 Burleson写的，你也可以在读懂了情况下根据实际情况调整一下脚本。对于索引，可以通过ALTER INDEX indexname STORAGE(B?R_POOL KEEP)来钉在KEEP池中。 　　 　　将表定在KEEP池中需要做一些准备工作。对于ORACLE9i 需要设置DB_KEEP_CACHE_SIZE，对于8i，需要设置b?r_pool_keep。在8i中，还要修改db_block_lru_latches，该参数默认是1，无法使用b?r_pool_keep。该参数应该比2*3*CPU数量少，但是要大于1，才能设置DB_KEEP_CACHE_B?R。b?r_pool_keep从db_block_b?rs中分配，因此也要小于db_block_b?rs。设置好这些参数后，就可以把常用对象永久钉在内存里。 　　 　　五．设置optimizer_max_permutations 　　 　　对于多表连接查询，如果采用基于成本优化(CBO)，ORACLE会计算出很多种运行方案，从中选择出最优方案。这个参数就是设置oracle究竟从多少种方案来选择最优。如果设置太大，那么计算最优方案过程也是时间比较长的。Oracle805和8i默认是80000，8建议改成2000。对于9i，已经默认是2000了。 　　 　　六．调整排序参数 　　 　　(1) SORT_AREA_SIZE:默认的用来排序的SORT_AREA_SIZE大小是32K，通常显得有点小，一般可以考虑设置成1M（1048576）。这个参数不能设置过大，因为每个连接都要分配同样的排序内存。 　　 　　(2) SORT_MULTIBLOCK_READ_COUNT:增大这个参数可以提高临时表空间排序性能，该参数默认是2，可以改成32来对比一下排序查询时间变化。注意，这个参数的最大值与平台有关系。 　　 　　七．调整其它几个关键的性能参数 　　 　　很多人认为使用oracle数据库，系统的默认参数就是最好的，其实不是这样 ==================================================================================================== ● 配置和优化有什么不同 ● 获得最大的性能 ● 配置操作系统 ● 配置Oracle Oracle 性能 ● 调整和配置数据库对象  ● 优化Oracle 最大化 如果你问很多Oracle DBA“你工作中最大的一部分是什么?”几乎所有的回答都是“数据库的配置和优化。”Oracle 是一种真正复杂和强大的产品，而且它的强大的能力在于它对每个单独的数据库配置都可以以最好的性能运行。本章讲述我们配置和优化 Oracle 数据库的方法，并提供了为站点实现一个高性能数据库的指导方针。 大多数Oracle DBA 连续的、每天的职责是使 Oracle 数据库获得可能的最好性能。对于“性能”可能有许多定义，但是我们把性能定义为目标和在怀疑有问题的数据库中执行一个典型操作需要的可以测量的时间。是的，这是一个太简单的定义，它忽视了其他的测量尺度，如资源使用。但是让我们正视它：我们期望数据库尽可能地快，因此为了这个目的这是一个合理的定义。 整本书都是以Oracle 性能为主题写的（参见附录“DBA 使用的资源”以查看我们认为你应该注意的内容，注1），所以我们不能在一章中就阐述完复杂的Oracle 性能优化，我们希望提供一种直截了当的性能优化方法并提供能应用到各个不同安装上的实际指南。 从物理和逻辑的实现、处理的事务类型及这些事务的性能需求方面来看，每个Oracle 安装都是不同的，认识到这点很重要。结果是虽然一些厂商（包括 Oracle） 尝试提供，但仍没有一种自动的优化方法，而且也没有单一的一套规则可以提供一种使数据库性能最优的方法。然而，我们可以提供一种方法，在适当应用并结合DBA 知识和经验的情况下，该方法将使任何给定的数据库有好的性能。 注1：  我们尤其推荐Mark Gurry 和Peter Corrigan 的《Oracle Performance Tuning》第二    版（O'Reilly&Associates,1997）。  46    配置和优化有什么不同 使一个 Oracle 数据库获得最佳性能需要认真注意数据库的配置和优化两方面。这些术语经常交换使用，但是事实上，它们是两个不同的任务，无可否认的是在它们之间有一少部分内容是重叠的。 配置是设置数据库的物理和逻辑组件的过程，也是配置主机系统的过程，而优化是修改数据库的内部行为的过程，以便操作以特定方式运行。整个过程某种程度上是循环的，因为合适的优化经常包含修改配置，然后再一次查看优化结果。图 3-1 演示了配置和优化过程的基本步骤。 可以配置什么 能在一个 Oracle 数据库中配置的一些项目如下: ● 影响系统进程分配的数据库的组件，例如 : SQL*Net MTS（Multi-Threaded Server，多线程服务器） 并行查询（Parallel Q\u000ery） 并行服务器（Parallel Server） ● 物理存储的布局和大小  ● 数据库对象的大小，如： 表 索引 回滚段 排序区 临时表空间 重做日志   不是 图 3-1：配置和优化过程 分区表 惟一索引（Index-only）表 ● 内存的数量和分配，例如 : 数据库缓冲区 重做日志缓冲区 共享池 可以优化什么 Oracle 数据库可以优化的方面包括下列各项: ● 内存使用  ● 磁盘使用  ● SQL 语句执行 获得最大的性能 使你的Oracle数据库获得最大的性能并不是一下子就可以做到的，这通常是大量辛苦的工作、思考和计划的结果。然而，从付出努力所得到的回报来看，是非常值得的，你的数据库在最高效地运行，你的用户高兴，你也很满意。 我们使性能最大化的方法是按自然层次分类的。需要从3 个不同方面，并按照顺序来阐述。这3 个方面是: ● 操作系统配置  ● Oracle 资源配置  ● 对象创建和SQL 语句执行 这些方面不是互不相关的，实际上，对某方面的重要改变可能需要考虑其他方面。它们是顺序依赖的，也就是说，直到你已正确配置和调整了操作系统，你才能使Oracle 达到很好的性能。同样，查询的快速执行取决于是否合理地配置了Oracle 环境。 每个Oracle数据库的情况都是不同的，因此我们不能精确地告诉你该如何完成你的配置和优化目标，甚至你的目标是什么。我们要做的是为你提供一个我们已经成功的方法。 配置操作系统 这通常是容易的，因为那不是你的工作（在大部分情形下）! 在大多数安装中，有系统管理员或管理者负责操作系统和硬件事情。这个系统管理员通常是硬件和操作系统软件方面的专家，而且大多数DBA不用再管它。但在服从系统管理员专长的同时，这里有你必须确定的几点: ● 应该充分利用物理内存，但是交换（swapping）（在交换内存环境中）不应该发生。把内存交换到磁盘的过程非常慢，因此如果系统需要更多的内存，就再买一些内存。尤其是要确定你没有创建对于物理内存来说太大的SGA，因为SGA 交换将严重降低 Oracle 性能  ● CPU 在峰值时应达到100% 使用，但是进程不应该等待CPU  ● 磁盘和控制器应该运行在最佳容量（通常是最大值的60%~90% 或靠近最佳容量），而且没有输入/ 输出等待。作为一个DBA，你也有一些对这个区域的控制，我们将会在本章后面描述  ● 网络传输量不应该是一个瓶颈。考虑用主干网络把服务器连接在一起，并且如有可能把客户机/ 服务器通信和服务器/ 服务器通信分开  ● 尽量把Oracle 服务器放在一个单纯的机器上，把用户放到另外的机器上  ● 确保安装了任何可能影响Oracle 的操作系统组件（包括补丁） 因为Oracle 是数据库市场中的一个主要提供商，所以大多数硬件提供商中都有Oracle“专家”的职员，他们能提供可能影响Oracle 运行的硬件和操作系统方面的建议。要充分利用这些专业意见。 配置Oracle  Oracle 的总性能受所安装的组件以及这些组件如何配置的影响。Oracle 数据库的高性能对于从运行在数据库的事务中获得最大性能是很必要的。这一节为配置SQL*Net/Net8、MTS、并行查询（Parallel Q\u000ery）和并行服务器（Parallel Server） 提供了一般配置指南和一些具体建议。 配置指南 尽管每次安装都会不同，但总有一些能应用到大多数数据库的普遍适用的配置指南，而不管安装组件的不同和数据库应用的不同。下面章节将描述这些通用的指南。 查阅文档 这看起来显而易见，但还是有必要说。即使有经验的DBA 也会从开始Oracle 安装之前的快速阅读相关文档中受益。我们推荐你（至少）查阅下列文档: ● 特定于硬件的IUG（安装和用户指南）  ● 服务器管理员指南  ● 版本发布说明（通常打包在介质中）  ● README 文件，通常可以在安装介质中找到，它包含印刷文档中可能没有的最新信息 检查资源需求 在开始安装之前，确认是否有足够的系统资源。与使用平台相关的IUG 资料包含了有关磁盘存储和内存需求的全面信息。记住这些需求是最小需求，而实际上所需资源可能要更大，这与你做的其他配置有关。例如，如果你定义较大的SGA，就需要更多的内存。 尤其是要确保在你安装Oracle 软件（一般称为ORACLE_HOME）的设备上有足够的磁盘空间，以安装所有的软件和辅助文件。 检查系统特权 大多数操作系统要求执行Oracle安装的账户有特定的权限。一定要查看IUG进行确认，而且一定要确认系统管理员已经正确地进行了设置。注意这些特权可能包括在特定设备上创建目录和文件的权利。 确定控制文件所在位置 Oracle 要求至少有一个控制文件。你应该设置至少两个（通常更多）控制文件。这点极其重要，因为如果控制文件的所有拷贝丢失，你将不能挂接数据库。因此要把控制文件放在不同的磁盘上，如有可能放置在不同的磁盘控制器上。 SQL*Net 配置 要对SQL*Net（Oracle7）和 Net8（Oracle8）进行配置，通常使用Oracle 网络管理器或Net8助手。这通常在数据库软件安装后，并且至少有一个Oracle 实例运行后进行，但是配置应该预先计划好。在开始SQL*Net/Net8 配置之前，你应了解如下内容: ● 网络协议的类型：用来在你所在的环境中访问Oracle  ● 命名模式：用来识别 Oracle 网络节点  ● 你所在环境中的所有服务器、网关和多协议交换的名称和网络位置 一旦配置了SQL*Net/Net8，就要在每个服务器上设置如下文件: listener.ora 控制SQL*Net 监听进程的操作 tnsnames.ora 在未使用Oracle 命名软件时，维护网络中逻辑节点名称（别名）和物理位置之间的关系 sqlnet.ora 控制Oracle 网络操作的登录（不是必需但强烈要求） 如果你使用多线程服务器，也需要在INIT.ORA 文件中进行配置，如下小节所示。 MTS 的配置 MTS（多线程服务器）在INIT.ORA 文件中进行配置，INIT.ORA 样本的参数设置如下所示: mts_dispatchers=\"ipc,1\" mts_dispatchers=\"tcp,1\" mts_max_dispatchers=10 mts_servers=1 mts_max_servers=10 mts_service=TEST mts_listener_address=\"(ADDRESS=(PROTOCOL=ipc)(KEY=TEST))\" mts_listener_address=\"(ADDRESS=(PROTOCOL=tcp)(HOST=10.74.72.42)(PORT=1526))\" 这个例子将配置一个MTS，它将处理与TEST 数据库的TCP/IP 连接。它最多将启动10 个调度程序，而且将创建多达10 个服务器进程。 注意： 记住，每个MTS进程都占用在INIT.ORA参数进程中指定总数中的数量，而且占用在操作系统级为Oracle 用户开放最大的进程数中的数量。 并行查询的配置 PQO（并行查询选项）是 Oracle 的一个强大的特性，为了正确地使用它，一定要合理配置数据库。并行查询允许多CPU 系统把数据库任务（通常是全表扫瞄）划分为能同时（并行）执行的一些片。为执行该任务要求如下: ● 通过设置INIT.ORA 中的PARALLEL_MAX_SERVERS 参数为一个大于0 的值来使能多个并行进程  ● 创建表空间必须使用多个数据文件，数据文件要分配到不同设备上。理论上讲，分配给每个表空间的设备数等于系统中CPU 的数量  ● 利用并行查询的表应该将其并行度值（使用CREATE TABLE 语句中的PARALLEL 子句）设置为包含表空间（表在其中创建）的数据文件的数目 并行服务器的配置 为了使用OPS，并行服务器允许由多个Oracle 实例共享一个 Oracle 数据库，你可以通过在每个参与实例中使用INIT.ORA 参数来设定并行服务器特性，这些参数包括: PARALLEL_SERVER 一定要设为TR\u000e，以使能OPS（只对于 Oracle8）。 INSTANCE_NUMBER 标识数据库的实例。 ROLLBACK_SEGMENTS 指定每个实例私用的回滚段。也可以指定公用的回滚段，但是这不是必需的。 THREAD 识别与实例相关的重做日志线程。 GC_DB_LOCKS 实例锁总数（仅在Oracle7 中）。 GC_FILES_TO_LOCKS 数据库文件锁的数目。 GC_LCK_PROCS 分布锁的总数。 GC_ROLLBACK_LOCKS 回滚锁的总数。 GC_SAVE_ROLLBACK_LOCKS 回滚保存锁的数目（仅在Oracle7 中）。 GC_SEGMENTS 有影响空间管理行为的段的最大数目，该空间管理行为同时在段上执行（仅在Oracle 7 中）。 INSTANCE_GROUPS 把实例指定给一个或多个指定组（仅在Oracle8 中）。 LM_LOCKS 为锁管理器配置的锁数目（仅在Oracle8 中）。 LM_PROCS 锁管理器的进程数（仅在Oracle8 中）。 LM_RESS 能被每个锁管理器实例锁定的资源数目（仅在Oracle8 中）。 OPS_ADMIN_GROUP 把实例分配给一个组来监视（仅在Oracle8 中）。 PARALLEL_INSTANCE_GROUP 标识要用来产生并行查询从属的并行实例组（仅在Oracle8 中）。 ROW_LOCKING 应该总被设定为ALWAYS。 SERIALIZABLE 应该设定成FALSE（仅在Oracle7 中）。 SINGLE_PROCESS 应该设定成FALSE（仅在Oracle7 中）。 关于这些参数的详细信息参见第十二章“初始化参数”。因为OPS 是一个非常复杂的产品，所以你应该在尝试配置并行服务器环境之前查阅《Oracle Parallel Server Concepts》和《Administration Guide》。在做配置时，记住以下几点: ● 在 Unix 平台上，所有的数据文件一定要创建到裸分区中  ● 当创建一个数据库时，只自动创建重做线程1，额外的线程需要显式建立，而且你应指明重做日志属于哪个线程  ● 虽然不是必需的，但确保实例数目和线程数目相同将避免混淆 注意: 术语“并行查询”和“ 并行服务器”经常被混淆。并行查询指单个Oracle 实例把操作（比如一个全表扫描）在相同主机上的多CPU 间分布并且合并结果的能力。另一方面，并行服务器是多个在不同主机上的Oracle实例共享一个物理数据库的特性。在这种情况下，工作是通过把用户在多个实例间分布或通过在多实例间产生并行查询进程来在Oracle 实例间分布的。 调整和配置数据库对象 要获得最大的数据库性能，数据库对象的合理大小和配置是非常重要的。对象的合理大小是一个不断进行的工作，随着不断创建对象和修改对象，也需要不断地检查对象特性并在需要时将其改变。以下与调整大小相关的问题的数值与性能成反比： 表空间碎片（tablespace fragmentation） 表空间碎片使许多无法使用的小延伸区分散在表空间中。当创建对象时，如果延伸区的INITIAL 或NEXT 的值设置不合理就会产生碎片。 行链（row chaining） 这个问题将导致单行的数据驻留在多个Oracle块中，典型情况发生在PCTFREE 设置不足且表不断进行更新时。 多个延伸区（multiple extent） 多个延伸区，可能导致一个特定对象的数据分散在一个或几个数据文件之中，这是由在创建对象时指定了不合适的INITIAL或NEXT延伸区大小而引起的。这个问题可能会在MAXEXTENTS 参数被允许为默认值时变得很严重，因为尝试分派一个超过那个数目的延伸区将导致失败。 日志等待当写日志缓冲区记录到一个日志文件或当日志文件切换时，日志等待将引起一个进程等待，这时日志等待能大大增加处理时间。这通常由日志文件数目太少和日志文件太小等原因引起。 扩展一个回滚段失败这样的失败（能引起一个事务回滚）是由于没有分配充足的回滚段数目，或者是由于分配的回滚段不够大。 下列各节讲述了可以避免这些性能问题的一些指南和建议。 表 表是 Oracle 数据库中数据存储的基本单位，因此表的配置和由此产生的性能将对数据库总体性能产生很大的影响。下面是表配置的一些指导方针: ● 试着估计一个表将多大，并且分配一个足够大的初始延伸区来存放整个表。然而，如果你正在使用并行查询，则应跨越不同的数据文件来分配总的空间，使分配的延伸区数目和表的并行度相等  ● 考虑使用多个表空间，每个表空间对应于不同大小或类型的表。例如，你可能有3 个表空间：LARGE_DATA、MEDIUM_DATA 和SMALL_DATA，每个会用来存储大小不同的表。如果你使用多个表空间，要确保把每个表分配到恰当的表空间中  ● 确保分配一个DEFAULT TABLESPACE 给每个用户。如果没有分配，Oracle 将使用SYSTEM 表空间作为默认值  ● 如果可能，保证INITIAL和NEXT 延伸区大小总是相同大小的单元的整数倍，例如，是 512K 的整数倍。这样，延伸区将是统一的大小，而且会比较容易分配额外的延伸区，而不引起表空间碎片。如果可能，在一个表空间中可以使用大小相同的延伸区  ● 设定PCTINCREASE参数为 0，为了防止延伸区分配失控和保持统一的延伸区大小。  ● 设定MAXEXTENTS 参数为UNLIMITED。这将防止延伸区用完，因为多个延伸区对它们产生很小的性能影响（虽然广泛分布的延伸区对性能有负面影响）。这样做可以防止错误，但是不要把它作为INITIAL 大小的替代  ● 如果表没有更新，则设定PCTFREE 为0。如果表有更新，则估计行的列的增长程度，并分配一个PCTFREE 来防止块链接，而在块中没有过多的未使用空间  ● 如果有很多事务同时访问表，将INITRANS 设定为一个大于1（默认的）的数  ● 将 MAXTRANS 设定为在预期表上同时访问的最大数目。一个较小值将会导致一个或多个事务等待前一个事务完成 索引 正确使用索引可以使性能大大提高，这是任何Oracle 单一特性所不能做到的。虽然许多性能提高获益于优化 SQL 语句（见第八章“查询优化”），但我们也提供一些配置指南: ● 为索引创建一个单独的表空间，并且保证这个索引表空间的数据文件与包含索引表的表空间的数据文件不在同一个磁盘上  ● 试着去估计索引的大小而且分配一个足够的INITIAL延伸区来存储整个索引，除非你正在使用并行查询，否则在这种情况下，你应该在与索引的并行度相同的数据文件之间分配总的空间  ● 如果可能，保证INITIAL和NEXT 延伸区大小总是相同大小的单元的整数倍，例如，是 512K 的整数倍。这样，延伸区将会是统一的大小，而且会比较容易分配额外的延伸区而不引起表空间碎片  ● 设定 PCTINCREASE 参数为0 以防止延伸区分配失控并保持统一的延伸区大小  ● 设定 MAXEXTENTS 参数为UNLIMITED。这将防止延伸区用完，而多个延伸区可能产生的性能影响很小（虽然广泛分布的延伸区对性能有负面影响）。这样做可以防止错误，但是不要把它作为INITIAL 大小的替代 回滚段 Oracle 用回滚段来维护数据的一致性，允许事务的取消或回滚。回滚段使用很多的输入/ 输出，下面是配置回滚段的一些指导方针： ● 为回滚段创建一个单独的表空间，如果可能，把这个表空间的数据文件放在一个与其他数据文件不同的磁盘上  ● 永远不要在SYSTEM 表空间中创建回滚段（除了在数据库创建期间需要的临时回滚段以外，见第二章“安装”）  ● 确保为回滚表空间分配了足够大的空间，以允许回滚段为了适应大的更新事务来按照需要增长空间。记住批事务容易产生很大的回滚段  ● 总是保持回滚段的INITIAL 和NEXT 延伸区使用相同的数值（在CREATE TABLESPACE 语句中的DEFAULT STORAGE 子句中定义）。为回滚段分配大小相等的块可以防止空间碎片  ● 记得每个回滚段必须至少有两个延伸区，因此段的初始大小实际上是INITIAL + NEXT 的总和 ● 定义一个OPTIMAL值，以便使为了延伸适应一个大事务而增长的回滚段可以回缩到一个合理的大小。然而，不要让这个值太小，否则会浪费时间来为回滚段分配额外的延伸区 排序区 Oracle 使用INIT.ORA 参数SORT_AREA_SIZE 来为数据排序分配内存。当一个排序不能够在内存中完成时，Oracle 使用数据库中的临时段，但这非常慢。应当小心平衡SORT_AREA_SIZE，因为大的排序区可以通过减少输入/ 输出来显著增加性能，但是这将用光内存并引起分页。 注意： 记住这个参数应用到每个用户进程。每个执行排序的用户进程都将分配 SORT_AREA_ SIZE 内存。因此，如果 SORT_AREA_SIZE 被设定为/MB，而有100 个用户进程正在执行排序，那么将分配总数为100MB 的内存。 临时表空间 如果没有为执行排序的用户进程分配足够的内存，那么Oracle 将通过为用户在TEMPORARY TABLESPACE参数指定表空间中创建临时段来在磁盘上执行排序。除此之外，临时段用来执行复杂查询，如连接、UNION、MINUS 和索引创建。临时区的指南如下： ● 为临时段创建一个单独的表空间（通常叫做 TEMP），如果可能，把这个表空间对应的数据文件放在一个单独的磁盘上  ● 在CREATE TABLESPACE命令的DEFAULT STORAGE子句中指定INITIAL 和NEXT 参数。把两者的值设为相等，以消除空间碎片，在 TEMP 表空间中极易产生碎片，因为在那里不断地创建并删除对象  ● 要确保为每个用户指定一个TEMPORARY TABLESPACE。如果没有指定，Oracle 将把SYSTEM 作为默认的表空间，而这样对性能有负面的影响 重做日志 重做日志，也称联机重做日志文件，对 Oracle 的失效恢复能力至关重要。重做日 志的适当配置不但对数据库的总体性能很关键，而且对恢复数据库的能力也很重要（见第四章“防止数据丢失”）。相关指南如下： ● 使用Oracle 内嵌的镜像特性，把重做日志文件的多组放在不同的磁盘上  ● 分配足够的重做日志文件以便Oracle 无须为了重复使用一个文件而等待它。Oracle 至少要求有两个重做日志文件，但是4 个或更多个是必要的  ● 分配的重做日志文件要足够大以防止太多的日志文件切换，但又要适当的小以保证当前联机日志文件失效时很好地恢复。如果文件较小，可能恢复已经归档的所有事务，而大的日志文件使数据库有可能丢失更多的事务  ● 设置INIT.ORA参数 LOG_CHECKPOINT_INTERVAL值大于重做日志文件的大小，这样将避免检查点（checkpoint）进程，直到日志文件满为止（引起一个检查点进程）。这个参数以数据库块来表达 警告： 记住一个日志切换将导致从SGA 将脏缓冲区（例如有更新）写入到磁盘。 ● 如果你正在运行Oracle7，考虑设定INIT.ORA 参数CHECKPOINT_PROCESS 为TR\u000e。这么做将创建一个执行检查点进程的单独进程，而并非由LGWR（日志写入进程）处理。见第十章“Oracle 实例”，可以了解更多信息 归档日志目的地 在配置方面一个经常需要注意的问题是要保证归档日志目的地有足够的空间。如果数据库正在归档日志模式中运行，那么当一个联机重做日志文件填满时，Oracle 的ARCH进程将复制这个文件的内容到INIT.ORA参数ARCHIVE_LOG_DEST指定的目录。如果目的地太小，ARCH 就不能复制日志文件，而一旦所有的联机日志文件满，整个数据库就会停止，直到这个问题解决。有经验的DBA 已经意识到这种情况，这种情况大多数在半夜发生，就像REM 休眠一样。 优化 Oracle  或许DBA 的工作没有哪一方面能像优化这样消耗时间。成功的Oracle 优化既要求知识又要求经验，挑战和挫败也同时存在。整卷都在写Oracle优化（参见附录“DBA 使用的资源”），但我们不能在一节中包括优化的所有方面。相反，正如我们前面提到的，我们将列出可以应用到各种情况的优化方法的大纲。 结构化优化方案 Oracle 数据库的成功优化需要仔细的、有规则的方案。像整体系统配置一样，优化一定要包括下列各项: ● 硬件和操作系统性能● Oracle 实例性能 ● 单独的事务（SQL）性能 这些方面应该按顺序进行，因为没有硬件和操作系统的良好优化，Oracle 的性能优化是不可能的。没有数据库的有效运行，一个单独的SQL语句不可能很好地被优化。优化这些方面中的任何一方面时，都包括3 个步骤: 1. 测量目前的性能。  2. 做适当的变化。  3. 评估结果。  警告：对Oracle实例的一些改变可能引起对操作系统环境的改变。比如，分配附加的数据库缓冲区可能导致操作系统开始分页，而这可能要求额外的操作系统优化来消除。 优化进程几乎总是反复的。也就是说，在完成3 个步骤之后，DBA 必须回到第一步骤并且重复这个过程。这将一直持续到不会再有性能改善为止。 Oracle 实例优化 Oracle 实例层的大多数性能的提高将通过两个方面达到: 内存使用和磁盘输入/ 输出。 内存使用 基于内存的操作比磁盘操作快得多（有时成千上万倍），这一点是不值得惊讶的。结果将导致用内存访问数据来代替磁盘输入/ 输出，以使性能得到巨大的提高。相关的3 个主要方法描述如下: 分配额外的DB_BLOCK_B?RS 这或许是改善总体性能的单一的最有效的方法，特别是在查询上。更多的数据库缓冲区允许更多的数据块数据保持在内存中，因此可以按内存速度访问包含在这些块中的数据，而不需要磁盘输入/ 输出。缓冲区是由INIT.ORA 参数 DB_BLOCK_B?RS 来分配的，它的数值是要分配的数据块缓冲（block b?r）数目。因此，如果数据库块大小是8192，每个DB_BLOCK_B?R 将是8192 字节。注意改变DB_BLOCK_B?RS 值后直到下次数据库重启才生效。 注意： 注意不要分配太多的DB_BLOCK_B?RS以导致操作系统开始分页，分页将消除你获得的性能，而且将对整体性能产生负面影响。 分配额外的共享池共享池大小由INIT.ORA的参数SHARED_POOL_SIZE 控制，它指定了以字节为单位的共享池大小。共享池的主要内容是字典缓存区（dictionary cache）和共享SQL 区（shared SQL area）。由于字典缓存区的各部分组件由Oracle 自动分配，所以共享池的任何增加都会使字典缓存区和共享SQL 区增加。 共享SQL 区包含最近执行的SQL 语句的拷贝，连同相关信息，如它们的执行计划。共享池越大，特定SQL 语句被解析并且驻留在共享SQL 区就越有可能，因此节省了需要再次处理这个语句的时间。在相同的SQL语句被多次执行且对速度有要求的事务处理系统中，这是个特别重要的值。 分配更多的日志缓冲区空间日志缓冲区是用来存储将要写到联机重做日志文件上的数据的。日志缓冲区的大小由INIT.ORA 参数LOG_B?R 控制，其数值以字节表示。为日志缓冲区分配更多的内存，将减少磁盘输入/ 输出，尤其是在事务特别长或数量很多时。 磁盘输入/ 输出 磁盘访问是任何计算机系统上的最慢的操作。作为一个数据库系统，Oracle 的存储和访问数据非常依赖磁盘访问。考虑一个典型的更新一个表的一行的SQL 语句，将发生下列各项操作: 1. 读数据字典获得关于表和正在被操作的行的信息。  2. 读适当的索引来定位要更新的行。  3. 读包含行的数据块。  4. 写回滚信息到一个回滚段。  5. 写更新信息到联机日志文件。  6. 重写数据块。  7. 重写索引块。  虽然一些操作可以通过有效使用内存消除，正如我们前面提到的，但所有这些操作都潜在地要求磁盘输入/ 输出。通过尽可能使磁盘输入/ 输出有效，可增强总性能。使磁盘输入/ 输出最大值的基本指南如下： ● 只要可能，分离输入/输出操作到单独的磁盘上。这样，在执行另外一个时，不需要等待一个磁盘操作完成。例如，如果回滚段和日志文件在相同的磁盘上，需要写回滚记录，然后磁盘磁头需要移动到日志文件记录要写的那部分磁盘。这是非常耗时的  ● 把高输入/ 输出的磁盘放在不同的控制器上。现代的控制器可以处理有限数目的并发操作，但是尽可能使用更多的控制器将消除任何控制器等候并加速性能  ● 把最忙的文件和表空间（例如，日志文件、回滚段、一些索引）放在最快的可用磁盘上 关于RAID 的注释 磁盘技术的最新发展使 RAID（廉价磁盘冗余阵列）成为许多系统上很常用的一个选项。通常，当使用术语 RAID 时，硬件管理员会立刻想到RAID 5（或 RAID-5）， 它允许多个磁盘结合成一个大的设备。通过分配一个磁盘设备来存储冗余数据，一个 RAID-5 磁盘阵列可以承受阵列中的任何单一磁盘失效，并且经常是热交换的，也就是当一个磁盘失效时，其他的磁盘继续工作的同时更换这块磁盘，而不必关闭系统。 事实上RAID-5 是非常强大且廉价的。当配置Oracle 数据库时，在大多数情况下要避免使用这种技术。这可能听起来很刺耳，但是事实上虽然RAID-5 成本较低，而且提供了很好的数据保护级别，但是它的磁盘输入/输出花费很高。尤其是在RAID5 阵列上的写操作要比在单一磁盘上的写操作慢得多。RAID-5 阵列的一个好的替代品是RAID1，就是大家都知道的磁盘镜像。虽然比RAID-5（一半磁盘用来存储冗余数据）更贵，但是RAID-1提供了完全的数据保护，而在输入/ 输出效率上没用降低。 警告： RAID-1 要求有足够的硬件资源。尤其是由于每次写操作实际都要对磁盘进行两个写操作，所以控制器上的负荷是非RAID 的两倍。 现在性能最好的RAID 是RAID-0+1，有时叫做 RAID-10。RAID 的这个级别在多个驱动器上结合了带有数据条带（RAID-0）的镜像磁盘（同RAID-1），这可以消除等待磁盘头定位的延迟。而这在其他的RAID 控制器中都没有，RAID-0+1 是值得考虑的。 操作系统条带化 许多操作系统提供了在多个磁盘设备中磁盘扇区的自动条带化。条带化允许磁盘输入/ 输出连续，而没有头定位的延迟。虽然这个技术提供了比在一个单一磁盘上更好的性能，但也有一些缺点: 结合多个磁盘为一个单一的条带单元意味着DBA不能够控制单个文件在单独磁盘设备的位置。如果你的系统上只有少数的大磁盘，你应该考虑操作系统条带化，但是多磁盘设备或多 RAID-0+1 阵列通常会从Oracle 产生更好的性能。 Oracle 条带化 作为DBA，通过小心地把数据文件分配到单个磁盘设备或 RAID-0+1阵列，你可以达到与操作系统条带化相似的结果。例如，建立跨越4 个磁盘的Oracle 条带化需做下列各项工作: ● 创建一个有4 个数据文件的表空间，每个位于一个不同的磁盘设备上  ● 在表空间中创建对象，指定MINEXTENTS 4。Oracle 将把4 个延伸区分配到4个数据文件上，这样就实现了条带化。这个行动不是自动的，还需使用ALTER TABLE ... ALOCATE EXTENT 命令 Oracle 条带化技术非常强大，尤其和并行查询结合的时候，将通过多CPU 处理查询过程。 SQL 优化 假如主机服务器和操作系统正在你的站点顺利运行，而且你配置并优化了Oracle， 使其在最好状态运行，但是你的重要应用程序仍然运行很差。不幸的是这种情况经常发生。解决方法是通过检查和优化正在被执行的SQL 语句来优化应用程序。 SQL 优化这个题目值得写一本书。实际上，在市场上有很不错的书阐述得比这里更为详细。我们建议你检查附录中列出的DBA资源。在这小节中，我们将为你提供优化SQL 语句的一些概要建议和指南。 查询处理 第八章“查询最优化”描述了Oracle 如何为一个特定的SQL 语句创建一个计划。Oracle 现在用两个方法中的一个来决定该如何执行一个SQL 语句: 基于规则的方法应用一个标准的、固定的（但是经常有效的）规则集到语句中。 基于费用的方法 考虑由一个SQL语句（连同可得的索引一起）引用的对象的可用统计信息，并 基于这些统计建立一个计划。 优化一个SQL语句的关键是理解Oracle查询优化器如何工作和知道怎样改变Oracle 的行为，以便它能更有效地处理语句。 当然，在优化一个SQL 语句之前，必须知道它在做什么和如何做。今天市场上的许多工具将有助于完成这个工作，而且最有用的工具之一是SQL*Plus中的EXPLAIN PLAN 命令。通过创建一个计划表（通常为PLAN_TABLE）并且检查EXPLAIN PLAN 语句的结果，你会容易地看到Oracle 如何执行一个特定的语句。例如，SQL 语句: SELECT ename,loc,sal,hiredate FROM scott.emp, scott.dept WHERE emp.deptno=dept.deptno; 可用下面的命令解释: EXPLAIN PLAN SET STATEMENT_ID='DEMO' FOR SELECT ename,loc,sal,hiredate FROM scott.emp, scott.dept WHERE emp.deptno=dept.deptno; 存储在PLAN_TABLE 中的结果可以通过下面的简单查询看到: SELECT LPAD(' ',2*level) || operation || '' || options || ' '|| object_name EXPLAIN_PLAN FROM plan_table CONNECT BY PRIOR id = parent_id START WITH id=1 看起来像这样: EXPLAIN_PLAN NESTED LOOPS TABLE ACCESSFULL DEPT TABLE ACCESSFULL EMP 这个计划表明将使用全表扫描来对DEPT 和EMP 表访问。这对像EMP 和DEPT 一样的小表很好，事实上，我们想要它们全表扫描，因为表将缓存到内存中，并且不需要磁盘输入/ 输出（至少在第一次运行之后）。然而，如果表很大，这个查询将进行很长时间，所以我们想改变查询执行的方式。 有3 个基本方法可以改变Oracle 查询优化器的行为: ● 在执行查询时提供一个或多个索引来用  ● 重写SQL 来使用一个更为有效的方法  ● 以提示（hint）的形式提供查询优化器指导 如果我们试第一选项而且在EMP（deptno）上增加一个索引，计划将改变为: EXPLAIN_PLAN NESTED LOOPS TABLE ACCESSFULL DEPT TABLE ACCESSBY ROWID EMP INDEXRANGE SCAN EMPDEPT_IX 现在你能看见Oracle 使用索引通过ROWID 来从EMP 取回行，ROWID 是从新创建的索引中获得的，而不再需要全表扫描。通常使用SQL 会有不止一种实现一个特定功能的方法，在确定使用正确的SQL 语句之前尝试几种不同的方法（有适当的基准）是一种很好的实践方式。第八章“查询最优化”提供了关于SQL 优化的更详细信息。 其他有用的优化特性 Oracle 通过增加提高性能的新特性来不断改良数据库产品。检查即使只有很小更新的Oracle 版本注释是很重要的，因为这其中可能就包含了新的性能特性。你可能觉得有用的一些特性和工具列表如下： 分区表（partitioned table） 从Oracle8 开始分区表就允许在多个子表上创建表，每个子表包含了表数据的一个特定子集。例如，一个表可以按年分区，所有1998 年的数据在一个分区中，所有1999 年的数据在另一个分区中等等。分区对大的表特别有用，因为对包含在一个可识别的子集中的数据进行查询可以在对应的分区中操作，而不用访问其他的分区。例如，更新 1999 年的记录只要求Oracle 在1999 年的分区上执行输入/ 输出操作。可在CREATE TABLE 语句中指定分区。为了使用这个特性，你必须: ● 标识将要定义分区的数据字段（例如sales_year）  ● 在CREATE TABLE ... PARTITION BY RANGE 子句中指定值的范围  ● 为表的每个分区指定一个另外的表空间（为了得到最好的性能，把表的每个分区放置在不同的磁盘上）。注意单独的表空间不是必需的，但是这种做法可以允许表的一个分区脱机，而维持访问表的剩余部分分区表通常应该伴随着相应的分区索引，如下:  ● 使用CREATE INDEX 命令的LOCAL 关键字来告诉Oracle 为索引表的每个分区创建一个单独的索引  ● 使用CREATE INDEX 命令的GLOBAL 关键字，以便告诉Oracle 使用不会对应到索引表分区的值来创建一个单一索引。全局（GLOBAL）索引也可以分区 惟一索引表（index-only table） 在某些情况下，正常时存储在一个表中的所有数据可以存放在一个索引中，这样表就没必要了。从Oracle8 开始，一个惟一索引表就使数据按照主键列排序。对这种类型的对象有一些限制: ● 由于数据没有存储在一个表中，所以没有 ROWID 可用  ● 必须为表定义一个主键  ● 不能创建其他的索引，只有主键可以被创建为索引 惟一索引表通过使用CREATE TABLE命令的ORGANIZATION INDEX子句创建。 位图索引（bitmap index） 当被索引的数据有低基数（cardinality）时（也就是说索引列有相对较少的确定值时），创建位图索引可以大大改善性能。位图索引的一个好的例子就是性别（GENDER），它只有两个值“M”或“F”。对于销售总额（SALES_AMOUNT），将 不适合建立位图索引，因为它对于每行都可能有一个不同的值。 创建一个位图索引类似于创建一个标准的索引，你可以在CREATE INDEX 语句中包括关键字BITMAP。例如，在EMPLOYEE_MASTER 表的GENDER 列创建一个位图索引，指定下列语句: CREATE BITMAP INDEX empmast_ix ON employee_master(gender); 临时表空间 Oracle7 引进了临时表空间的概念，这专门为Oracle 的排序段使用。通过消除连续不断地分配和释放排序空间的空间管理操作，当排序很大以致内存不能容纳时，所有使用排序的操作将得到性能的提高。这在运行OPS 的时候尤为重要。 注意： 一个临时表空间只能用于排序段，不要在临时表空间中创建永久对象。 要创建一个临时表空间，需要在CREATE TABLESPACE 语句中使用关键字TEMPORARY。例如，下面语句将创建一个叫做TEMP 的临时表空间: CREATE TABLESPACE TEMP DATAFILE '/disk99/oracle/oradata/TEST/temp01.dbf' SIZE 50M DEFAULT STORAGE(INITIAL 64K NEXT 64K MAXEXTENTS UNLIMITED) TEMPORARY; 一个已存在的非临时表空间可以转变为临时表空间，如果它不包含永久对象，可使用下面SQL 语句进行转换： ALTER TABLESPACE tablespace TEMPORARY; 不能恢复的操作 由Oracle 7.2 开始，在创建表或索引时就可能不写重做日志记录。这个选项提供了较好的性能，因为需要的输入/ 输出少了很多。要利用这个特性在对象创建语句中指定UNRECOVERABLE（Oracle7语法）或 NOLOGGING（Oracle8 语法）。例如，你想使用数据库链接从另外一个数据库移动数据可使用下面这个语句: INSERT INTO newtable SELECT * from oldtable@oldlink; 这个方法当然会奏效，但是将为每次插入创建重做日志记录，这将浪费资源。可以用下面语句完成相同的任务： CREATE TABLE newtable AS SELECT * from oldtable@oldlink NOLOGGING; 当重建索引的时候，NOLOGGING 选项将特别有用。NOLOGGING 关键字可以大大减少索引创建的时间。SQL 语句与下面语句相似: CREATE INDEX indexname ON table(column) NOLOGGING; 注意，如果在执行一个不能恢复的语句之后，在某点发生了系统失效，你将不能使用回滚机制来恢复这个事务，你必须意识到一个系统失效已经发生并且要重新运行语句。","title":"oracle优化的几个简单步骤"},{"content":"数据库设计的简单小结： 数据库介绍 数据库的命令开启方式： 一：打开cmd 键入net startmssqlserver  开启数据库的相关服务 键入net stopmssqlserver  关闭数据库的相关服务 二：控制面板\\所有控制面板项\\管理工具\\服务中选择关于SQL的选项 数据库 一般采用的是SQL身份验证 可以通过localwindows登入更改SQL身份验证的密码 1 采用master数据库 2 删除与要建的数据库重名的数据库 3 建立数据库 4 切换已建立的数据库 5 删除要建立表格重名的表格 6 建立表格 7插入测试数据 8 查找数据 9 生成视图 参照class diagram 进行数据库的设计 用sql sever2008 建立数据库关系图的 下面贴出新建查询代码 USE MASTER   --在主数据库中建立数据表GOIF EXISTS (SELECT * FROM SYSDATABASES WHERE NAME='BBS')  --在所有的数据库中删除重名的数据库DROP DATABASE BBSGOCREATE DATABASE BBS   --建立数据表ON(   NAME='BBS_DATA.MDF',        --数据库   FILENAME='G:\\YSH\\BBS_DATA.MDF',   --数据库的物理存储地址    SIZE=10,                          --初始值大小  以下数据以兆计算   MAXSIZE=1000,                     --最大数据容量   FILEGROWTH=5                      --每次增长值)LOG ON(              --建立数据日志   NAME='BBS_LOG.LDF',   FILENAME='G:\\YSH\\BBS_LOG.LDF',      SIZE=10,   MAXSIZE=100,   FILEGROWTH=5);GOUSE BBS                                    --切换到建立后的数据库GOIF EXISTS (SELECT *FROM SYSOBJECTS WHERE NAME='users')    --在所有的数据表中删除重名的数据表 DROP TABLE usersGOIF EXISTS (SELECT *FROM SYSOBJECTS WHERE NAME='section')  DROP TABLE sectionGOIF EXISTS (SELECT *FROM SYSOBJECTS WHERE NAME='topic')  DROP TABLE topicGOIF EXISTS (SELECT *FROM SYSOBJECTS WHERE NAME='reply')  DROP TABLE replyGOCREATE TABLE users(     uid int primary key not null identity(1000,1),  -- 用户编号 定义主键 采用非空 起始初始化     uname varchar(40) not null,                     --用户名     pwd   varchar(40) not null default '123456',    --用户密码 非空 存在默认值     sex   char(8) not null default '男',            --性别 非空 默认男     regTime datetime,                               --注册时间 调用时间函数     pic   varchar(20) not null                     --头像)GOCREATE TABLE section(     sid int primary key not null identity(1,1),    --版块编号        sname varchar(40) not null                     --版块名)GOCREATE TABLE topic(   tid int primary key not null identity(1,1),  --主帖编号 主键 非空 初值   tname varchar(40) not null,                  --标题名   content varchar(4000) not null,              --内容   postime datetime,                            --发表时间 调用库时间   modtime datetime,                            --更新时间   uid int references users(uid),               --用户编号 外键   sid int references section(sid)                --版块编号 外键         ) GOCREATE TABLE reply(   rid int primary key not null identity(1,1),  --跟帖编号 主键 初值   rname varchar(40) not null,                  --标题名   content varchar(1000) not null,              --内容   postime datetime,                            --发表时间 调用库时间   modtime datetime,                            --更新时间   uid int references users(uid),               --用户编号 外键   tid int references topic(tid)                --主帖编号 外键)GO------------------------------------------------------------插入测试数据INSERT INTO users values('张三',default,default,GETDATE(),'1.jpg');INSERT INTO users values('李四','0311','女',GETDATE(),'2.jpg');GOselect *from users;INSERT INTO section values('新闻'); INSERT INTO section values('娱乐'); INSERT INTO section values('军事');INSERT INTO section values('计算机');GOselect *from section;INSERT INTO topic values('航母style','请看下面报道',GETDATE(),GETDATE(),1000,3);GOselect *from topic;INSERT INTO reply values('顶','顶起航母style',GETDATE(),GETDATE(),1001,1);GOselect *from reply;SELECT tid,tname,content,postime,modtime,topic.uid,uname,section.sid,sname  --发帖信息 人和栏目FROM topic,users,sectionWHERE topic.uid=users.uid and topic.sid=section.sid;  GO SELECT rid,rname,reply.content,reply.postime,reply.modtime,reply.rid,users.uname,reply--.tid--,tnameFROM reply,users--,topicWHERE reply.uid=users.uid --and users.uid=topic.uid --and users.uid=topic.uid;GOCREATE VIEW SHOW      --建立视图asSELECT tid,tname,content,postime,modtime,topic.uid,uname,section.sid,sname  --发帖信息 人和栏目FROM topic,users,sectionWHERE topic.uid=users.uid and topic.sid=section.sid;  GO SELECT * FROM SHOW; 还可以用 inner join 的形式进行查询 更简便","title":"网上书店系统 第二天 数据库设计啊"},{"content":"import java.lang.reflect.Field;import java.lang.reflect.Method;import java.util.ArrayList;import java.util.HashMap;import java.util.List;import java.util.Map;import android.content.ContentValues;import android.content.Context;import android.database.Cursor;import android.database.sqlite.SQLiteDatabase;import android.database.sqlite.SQLiteStatement;import android.util.Log;/** * 数据库管理类，具备增删改查操作。 * \t\t增删改 --> 操作一个sql语句，并且有返回值。 * \t\t查询    --> 1. 返回一个游标类型 * \t\t\t\t  2. 返回一个List<Object> * \t\t\t\t  3. 返回一个List<Map<String, Object>> * @author zxy * 时间： 2012-09-28 */public class DataBaseManager {\tprivate DBHelper dbHelper;\tpublic static DataBaseManager instance = null;\tprivate SQLiteDatabase sqliteDatabase;\t/**\t * 构造函数\t * @param context\t上下文对象\t */\tprivate DataBaseManager(Context context) {\t\tdbHelper = new DBHelper(context);\t\tsqliteDatabase = dbHelper.getReadableDatabase();\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t}\t\t/***\t * 获取本类对象实例\t * @param context\t上下文对象\t * @return\t */\tpublic static final DataBaseManager getInstance(Context context) {\t\tif (instance == null) \t\t\tinstance = new DataBaseManager(context);\t\treturn instance;\t}\t\t/**\t * 关闭数据库\t */\tpublic void close() {\t\tif(sqliteDatabase.isOpen()) sqliteDatabase.close();\t\tif(dbHelper != null) dbHelper.close();\t\tif(instance != null) instance = null;\t}\t/**\t * 插入数据\t * @param sql  \t\t执行更新操作的sql语句\t * @param bindArgs\t\tsql语句中的参数,参数的顺序对应占位符顺序\t * @return\tresult\t\t返回新添记录的行号，与主键id无关 \t */\tpublic Long insertDataBySql(String sql, String[] bindArgs) throws Exception{\t\tlong result = 0;\t\tif(sqliteDatabase.isOpen()){\t\t\tSQLiteStatement statement = sqliteDatabase.compileStatement(sql);\t\t\tif(bindArgs != null){\t\t\t\tint size = bindArgs.length;\t\t\t\tfor(int i = 0; i < size; i++){\t\t\t\t\t//将参数和占位符绑定，对应\t\t\t\t\tstatement.bindString(i+1, bindArgs[i]);\t\t\t\t}\t\t\t\tresult = statement.executeInsert();\t\t\t\tstatement.close();\t\t\t}\t\t}else{\t\t\tLog.i(\"info\", \"数据库已关闭\");\t\t}\t\treturn result;\t}\t\t/**\t * 插入数据\t * @param table \t\t表名\t * @param values\t\t要插入的数据\t * @return\tresult \t\t返回新添记录的行号，与主键id无关 \t */\tpublic Long insertData(String table, ContentValues values){\t\tlong result = 0;\t\tif(sqliteDatabase.isOpen()){\t\t\tresult = sqliteDatabase.insert(table, null, values);\t\t}\t\treturn result;\t}\t\t/**\t * 更新数据\t * @param sql  \t\t执行更新操作的sql语句\t * @param bindArgs\tsql语句中的参数,参数的顺序对应占位符顺序\t */\tpublic void updateDataBySql(String sql, String[] bindArgs) throws Exception{\t\tif(sqliteDatabase.isOpen()){\t\t\tSQLiteStatement statement = sqliteDatabase.compileStatement(sql);\t\t\tif(bindArgs != null){\t\t\t\tint size = bindArgs.length;\t\t\t\tfor(int i = 0; i < size; i++){\t\t\t\t\tstatement.bindString(i+1, bindArgs[i]);\t\t\t\t}\t\t\t\tstatement.execute();\t\t\t\tstatement.close();\t\t\t}\t\t}else{\t\t\tLog.i(\"info\", \"数据库已关闭\");\t\t}\t}\t\t/**\t * 更新数据\t * @param table\t\t\t表名\t * @param values\t\t表示更新的数据\t * @param whereClause\t表示SQL语句中条件部分的语句\t * @param whereArgs\t\t表示占位符的值\t * @return\t */\tpublic int updataData(String table, ContentValues values, String whereClause, String[] whereArgs){\t\tint result = 0;\t\tif(sqliteDatabase.isOpen()){\t\t\tresult = sqliteDatabase.update(table, values, whereClause, whereArgs);\t\t}\t\treturn result;\t}\t/**\t * 删除数据\t * @param sql  \t\t执行更新操作的sql语句\t * @param bindArgs\tsql语句中的参数,参数的顺序对应占位符顺序\t */\tpublic void deleteDataBySql(String sql, String[] bindArgs) throws Exception{\t\tif(sqliteDatabase.isOpen()){\t\t\tSQLiteStatement statement = sqliteDatabase.compileStatement(sql);\t\t\tif(bindArgs != null){\t\t\t\tint size = bindArgs.length;\t\t\t\tfor(int i = 0; i < size; i++){\t\t\t\t\tstatement.bindString(i+1, bindArgs[i]);\t\t\t\t}\t\t\t\tMethod[] mm = statement.getClass().getDeclaredMethods();\t\t\t\tfor (Method method : mm) {\t\t\t\t\tLog.i(\"info\", method.getName());\t\t\t\t\t\t\t/**\t\t\t\t\t *  反射查看是否能获取executeUpdateDelete方法\t\t\t\t\t *  查看源码可知 executeUpdateDelete是public的方法，但是好像被隐藏了所以不能被调用，\t\t\t\t\t *  \t利用反射貌似只能在root以后的机器上才能调用，小米是可以，其他机器却不行，所以还是不能用。\t\t\t\t\t */\t\t\t\t}\t\t\t\tstatement.execute();\t\t\t\t\tstatement.close();\t\t\t}\t\t}else{\t\t\tLog.i(\"info\", \"数据库已关闭\");\t\t}\t}\t/**\t * 删除数据\t * @param table\t\t\t表名\t * @param whereClause\t表示SQL语句中条件部分的语句\t * @param whereArgs\t\t表示占位符的值\t * @return\t\t\t\t\t */\tpublic int deleteData(String table, String whereClause, String[] whereArgs){\t\tint result = 0;\t\tif(sqliteDatabase.isOpen()){\t\t\tresult = sqliteDatabase.delete(table, whereClause, whereArgs);\t\t}\t\treturn result;\t}\t\t/**\t * 查询数据\t * @param searchSQL \t\t执行查询操作的sql语句\t * @param selectionArgs\t\t查询条件\t * @return \t\t\t\t\t返回查询的游标，可对数据自行操作，需要自己关闭游标\t */\tpublic Cursor queryData2Cursor(String sql, String[] selectionArgs) throws Exception{\t\tif(sqliteDatabase.isOpen()){\t\t\tCursor cursor = sqliteDatabase.rawQuery(sql, selectionArgs);\t\t\tif (cursor != null) {\t\t\t\tcursor.moveToFirst();\t\t\t}\t\t\treturn cursor;\t\t}\t\treturn null;\t}\t\t/**\t * 查询数据\t * @param sql\t\t\t\t执行查询操作的sql语句\t\t * @param selectionArgs\t\t查询条件\t * @param object\t\t\t\tObject的对象\t * @return List<Object>\t\t返回查询结果\t\t */\tpublic List<Object> queryData2Object(String sql, String[] selectionArgs, Object object) throws Exception{\t\tList<Object> mList = new ArrayList<Object>();\t\tif(sqliteDatabase.isOpen()){\t\t\tCursor cursor = sqliteDatabase.rawQuery(sql, selectionArgs);\t\t\tField[] f;\t\t\tif(cursor != null && cursor.getCount() > 0) {\t\t\t\twhile(cursor.moveToNext()){\t\t\t\t\tf = object.getClass().getDeclaredFields();\t\t\t\t\tfor(int i = 0; i < f.length; i++) {\t\t\t\t\t\t//为JavaBean 设值\t\t\t\t\t\tinvokeSet(object, f[i].getName(), cursor.getString(cursor.getColumnIndex(f[i].getName())));\t\t\t\t\t}\t\t\t\t\tmList.add(object);\t\t\t\t}\t\t\t}\t\t\tcursor.close();\t\t}else{\t\t\tLog.i(\"info\", \"数据库已关闭\");\t\t}\t\treturn mList;\t}\t\t/**\t * 查询数据\t * @param sql\t\t\t\t\t\t\t执行查询操作的sql语句\t\t * @param selectionArgs\t\t\t\t\t查询条件\t * @param object\t\t\t\t\t\t\tObject的对象\t * @return\tList<Map<String, Object>> \t返回查询结果\t\t * @throws Exception\t */\tpublic List<Map<String, Object>> queryData2Map(String sql, String[] selectionArgs, Object object)throws Exception{\t\tList<Map<String, Object>> mList = new ArrayList<Map<String,Object>>();\t\tif(sqliteDatabase.isOpen()){\t\t\tCursor cursor = sqliteDatabase.rawQuery(sql, selectionArgs);\t\t\tField[] f;\t\t\tMap<String, Object> map;\t\t\tif(cursor != null && cursor.getCount() > 0) {\t\t\t\twhile(cursor.moveToNext()){\t\t\t\t\tmap = new HashMap<String, Object>();\t\t\t\t\tf = object.getClass().getDeclaredFields();\t\t\t\t\tfor(int i = 0; i < f.length; i++) {\t\t\t\t\t\tmap.put(f[i].getName(), cursor.getString(cursor.getColumnIndex(f[i].getName())));\t\t\t\t\t}\t\t\t\t\tmList.add(map);\t\t\t\t}\t\t\t}\t\t\tcursor.close();\t\t}else{\t\t\tLog.i(\"info\", \"数据库已关闭\");\t\t}\t\treturn mList;\t} \t\t/**    \t * java反射bean的set方法    \t * @param objectClass    \t * @param fieldName    \t * @return    \t */       \t@SuppressWarnings(\"unchecked\")       \tpublic static Method getSetMethod(Class objectClass, String fieldName) {       \t    try {       \t        Class[] parameterTypes = new Class[1];       \t        Field field = objectClass.getDeclaredField(fieldName);       \t        parameterTypes[0] = field.getType();       \t        StringBuffer sb = new StringBuffer();       \t        sb.append(\"set\");       \t        sb.append(fieldName.substring(0, 1).toUpperCase());       \t        sb.append(fieldName.substring(1));       \t        Method method = objectClass.getMethod(sb.toString(), parameterTypes);       \t        return method;       \t    } catch (Exception e) {       \t        e.printStackTrace();       \t    }       \t    return null;       \t}       \t  \t/**    \t * 执行set方法    \t * @param object \t执行对象    \t * @param fieldName\t属性    \t * @param value\t\t值    \t */       \tpublic static void invokeSet(Object object, String fieldName, Object value) {       \t    Method method = getSetMethod(object.getClass(), fieldName);       \t    try {       \t    \tmethod.invoke(object, new Object[] { value });       \t    } catch (Exception e) {       \t        e.printStackTrace();       \t    }       \t}       }","title":"Android 封装的数据库管理操作类"},{"content":"  三个配置文件都放在$ORACLE_HOME\\network\\admin目录下。   1     sqlnet.ora 作用类似于linux 或者其他unix 的nsswitch.conf文件，通过这个文件来决定怎么样找一个连接中出现的连接字符串。  例如：在客户端输入 sqlplus sys/oracle@orcl          假如我的sqlnet.ora是下面这个样子 SQLNET.AUTHENTICATION_SERVICES= (NTS) NAMES.DIRECTORY_PATH= (TNSNAMES,HOSTNAME) 那么，客户端就会首先在tnsnames.ora文件中找orcl 的记录，如果没有相应的记录则尝试把orcl 当作一个主机名，通过网络的途径去解析它的 ip 地址然后去连接这个ip 上GLOBAL_DBNAME=orcl 这个实例，当然我这里orcl 并不是一个主机名 如果我是这个样子 NAMES.DIRECTORY_PATH= (TNSNAMES) 那么客户端就只会从tnsnames.ora查找orcl 的记录，括号中还有其他选项，如LDAP 等并不常用。 2 tnsnames.ora 这个文件类似于unix 的hosts 文件，提供tnsname 到主机名或者ip 的对应，只有当sqlnet.ora中类似 ： NAMES.DIRECTORY_PATH= (TNSNAMES) 也就是客户端解析连接字符串的顺序中有TNSNAMES是，才会尝试使用这个文件。  PROTOCOL ：客户端与服务器端通讯的协议，一般为TCP ，该内容一般不用改。 HOST ：数据库侦听所在的机器的机器名或IP 地址，数据库侦听一般与数据库在同一个机器上，所以当我说数据库侦听所在的机器一般也是指数据库所在的机器。在UNIX 或WINDOWS 下，可以通过在数据库侦听所在的机器的命令提示符下使用hostname 命令得到机器名，或通过ipconfig(for WINDOWS) or ifconfig （for UNIX ）命令得到IP 地址。需要注意的是，不管用机器名或IP 地址，在客户端一定要用ping 命令ping 通数据库侦听所在的机器的机器名，否则需要在 hosts 文件中加入数据库侦听所在的机器的机器名的解析。 PORT ：数据库侦听正在侦听的端口，可以察看服务器端的listener.ora 文件或在数据库侦听所在的机器的命令提示符下通过lnsrctl status [listener name] 命令察看。此处Port 的值一定要与数据库侦听正在侦听的端口一样。 SERVICE_NAME ：在服务器端，用system用户登陆后，sqlplus> show parameter service_name 命令察看。 ORCL: 对应的本机，SALES 对应的另外一个IP 地址，里边还定义了使用主用服务器还是共享服务器模式进行连接 连接的时候输入的 TNSNAME  ORCL = (DESCRIPTION = (ADDRESS_LIST = # 下面是这个TNSNAME 对应的主机，端口，协议 (ADDRESS = (PROTOCOL = TCP)(HOST = 127.0.0.1)(PORT = 1521)) ) (CONNECT_DATA = # 使用专用服务器模式去连接需要跟服务器的模式匹配，如果没有就根据服务器的模式自动调节  (SERVER = DEDICATED) # 对应service_name ，SQLPLUS>;show parameter service_name; 进行查看  (SERVICE_NAME = orcl) ) ) 下面这个类似  SALES = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = dg1)(PORT = 1521)) ) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = sales) ) )  注意：如果数据库服务器用MTS ，客户端程序需要用databaselink 时最好明确指明客户端用dedicated 直连方式, 不然会遇到很多跟分布式环境有关的ORACLE BUG 。一般情况下数据库服务器用直接的连接会好一些，除非你的实时数据库连接数接近1000 。 3 listener.ora 监听器进程的配置文件。 关于listener 进程就不多说了，接受远程对数据库的接入申请并转交给oracle的服务器进程。所以如果不是使用的远程的连接，并且不需要使用OEM时，listener 进程就不是必需的，同样的如果关闭listener 进程并不会影响已经存在的数据库连接。 Listener.ora 文件的例子 #listener.ora Network Configuration File: #E:\\oracle\\product\\10.1.0\\Db_2\\NETWORK\\ADMIN\\listener.ora # Generated by Oracle configuration tools. # 下面定义LISTENER 进程为哪个实例提供服务 这里是ORCL ，并且它对应的ORACLE_HOME 和GLOBAL_DBNAME 其中GLOBAL_DBNAME 不是必需的除非 # 使用HOSTNAME 做数据库连接 SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (GLOBAL_DBNAME = boway) (ORACLE_HOME = /u01/app/oracle) (SID_NAME = ORCL) ) )  # 监听器的名字，一台数据库可以有不止一个监听器 # 再向下面是监听器监听的协议，ｉｐ，端口等，这里使用的ｔｃｐ１５２１端口，并且使＃用的是主机名 LISTENER = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = dg1)(PORT = 1521)) )  上面的例子是一个最简单的例子，但也是最普遍的。一个listener 进程为一个instance(SID) 提供服务。 监听器的操作命令 $ORACLE_HOME/bin/lsnrctl start 其他诸如stop,status 等。具体敲完一个lsnrctl后看帮助。 其它说明： 1.      上面说到的三个文件都可以通过图形的配置工具来完成配置。 2.      $ORACLE_HOME/netca 向导形式的。 3.      profile 配置的是sqlnet.ora也就是名称解析的方式。 4.      service name 配置的是tnsnames.ora文件 。 5.      listeners 配置的是listener.ora文件，即监听器进程。 内容来源于网络，整理于此。非原创，暂时找不到出处，请作者跟帖，我再加上，抱歉！","title":"oracle数据库中listener.ora sqlnet.ora tnsnames.ora的区别"},{"content":"下列语句部分是MsSql语句，不可以在access中使用。 SQL分类：  DDL—数据定义语言(CREATE，ALTER，DROP，DECLARE)  DML—数据操纵语言(SELECT，DELETE，UPDATE，INSERT)  DCL—数据控制语言(GRANT，REVOKE，COMMIT，ROLLBACK) 首先,简要介绍基础语句： 1、说明：创建数据库 CREATE DATABASE database-name  2、说明：删除数据库 drop database dbname 3、说明：备份sqlserver --- 创建 备份数据的 device USE master EXEC sp_addumpdevice 'disk', 'testBack','c:\\mssql7backup\\MyNwind_1.dat' --- 开始 备份 BACKUP DATABASE pubs TO testBack  4、说明：创建新表 create table tabname(col1 type1 [not null][primary key],col2 type2 [not null],..) 根据已有的表创建新表：  A：create table tab_new like tab_old (使用旧表创建新表) B：create table tab_new as selectcol1,col2… from tab_old definition only 5、说明：删除新表 drop table tabname  6、说明：增加一个列 Alter table tabname add column col type 注：列增加后将不能删除。DB2中列加上后数据类型也不能改变，唯一能改变的是增加varchar类型的长度。 7、说明：添加主键： Alter table tabname add primary key(col)  说明：删除主键： Alter table tabname drop primary key(col)  8、说明：创建索引：create [unique] indexidxname on tabname(col….)  删除索引：drop index idxname 注：索引是不可更改的，想更改必须删除重新建。 9、说明：创建视图：createview viewname as select statement  删除视图：drop view viewname 10、说明：几个简单的基本的sql语句 选择：select* from table1 where 范围 插入：insertinto table1(field1,field2) values(value1,value2) 删除：deletefrom table1 where 范围 更新：updatetable1 set field1=value1 where 范围 查找：select* from table1 where field1 like’%value1%’ ---like的语法很精妙，查资料! 排序：select* from table1 order by field1,field2 [desc] 总数：selectcount * as totalcount from table1 求和：selectsum(field1) as sumvalue from table1 平均：selectavg(field1) as avgvalue from table1 最大：selectmax(field1) as maxvalue from table1 最小：selectmin(field1) as minvalue from table1 11、说明：几个高级查询运算词 A： UNION 运算符  UNION 运算符通过组合其他两个结果表（例如 TABLE1 和 TABLE2）并消去表中任何重复行而派生出一个结果表。当 ALL 随 UNION 一起使用时（即 UNION ALL），不消除重复行。两种情况下，派生表的每一行不是来自 TABLE1 就是来自 TABLE2。  B： EXCEPT 运算符  EXCEPT 运算符通过包括所有在 TABLE1 中但不在 TABLE2 中的行并消除所有重复行而派生出一个结果表。当 ALL 随 EXCEPT 一起使用时 (EXCEPT ALL)，不消除重复行。  C： INTERSECT 运算符 INTERSECT 运算符通过只包括 TABLE1 和 TABLE2 中都有的行并消除所有重复行而派生出一个结果表。当 ALL 随 INTERSECT 一起使用时 (INTERSECT ALL)，不消除重复行。  注：使用运算词的几个查询结果行必须是一致的。  12、说明：使用外连接  A、leftouter join：  左外连接（左连接）：结果集几包括连接表的匹配行，也包括左连接表的所有行。  SQL: select a.a, a.b, a.c, b.c, b.d, b.f from aLEFT OUT JOIN b ON a.a = b.c B：right outer join:  右外连接(右连接)：结果集既包括连接表的匹配连接行，也包括右连接表的所有行。  C：full outer join：  全外连接：不仅包括符号连接表的匹配行，还包括两个连接表中的所有记录。 其次，大家来看一些不错的sql语句 1、说明：复制表(只复制结构,源表名：a 新表名：b) (Access可用) 法一：select* into b from a where 1<>1 法二：selecttop 0 * into b from a 2、说明：拷贝表(拷贝数据,源表名：a 目标表名：b) (Access可用) insert into b(a, b, c) select d,e,f from b; 3、说明：跨数据库之间表的拷贝(具体数据使用绝对路径) (Access可用) insert into b(a, b, c) select d,e,f from b in ‘具体数据库’where条件 例子：..fromb in '\"&Server.MapPath(\".\")&\"\\data.mdb\"&\"' where.. 4、说明：子查询(表名1：a 表名2：b) select a,b,c from a where a IN (select d from b) 或者: select a,b,c from a where a IN (1,2,3) 5、说明：显示文章、提交人和最后回复时间 select a.title,a.username,b.adddate from table a,(select max(adddate)adddate from table where table.title=a.title) b 6、说明：外连接查询(表名1：a 表名2：b) select a.a, a.b, a.c, b.c, b.d, b.f from a LEFT OUT JOIN b ON a.a = b.c 7、说明：在线视图查询(表名1：a ) select * from (SELECT a,b,c FROM a) T where t.a> 1; 8、说明：between的用法,between限制查询数据范围时包括了边界值,not between不包括 select * from table1 where time between time1and time2 select a,b,c, from table1 where a not between 数值1 and数值2 9、说明：in的使用方法 select * from table1 where a [not] in (‘值1’,’值2’,’值4’,’值6’) 10、说明：两张关联表，删除主表中已经在副表中没有的信息  deletefrom table1 where not exists ( select * from table2 wheretable1.field1=table2.field1 ) 11、说明：四表联查问题： select * from a left inner join b on a.a=b.bright inner join c on a.a=c.c inner join d on a.a=d.d where ..... 12、说明：日程安排提前五分钟提醒  SQL:select * from 日程安排 where datediff('minute',f开始时间,getdate())>5 13、说明：一条sql语句搞定数据库分页 select top 10 b.* from (select top 20 主键字段,排序字段 from 表名 order by 排序字段 desc) a,表名 b where b.主键字段 = a.主键字段 order by a.排序字段 14、说明：前10条记录 select top 10 * form table1 where 范围 15、说明：选择在每一组b值相同的数据中对应的a最大的记录的所有信息(类似这样的用法可以用于论坛每月排行榜,每月热销产品分析,按科目成绩排名,等等.) select a,b,c from tablename ta where a=(selectmax(a) from tablename tb where tb.b=ta.b) 16、说明：包括所有在 TableA中但不在 TableB和TableC中的行并消除所有重复行而派生出一个结果表 (select a from tableA ) except (select a fromtableB) except (select a from tableC) 17、说明：随机取出10条数据 select top 10 * from tablename order by newid() 18、说明：随机选择记录 select newid() 19、说明：删除重复记录 Delete from tablename where id not in (selectmax(id) from tablename group by col1,col2,...) 20、说明：列出数据库里所有的表名 select name from sysobjects where type='U'  21、说明：列出表里的所有的 select name from syscolumns whereid=object_id('TableName') 22、说明：列示type、vender、pcs字段，以type字段排列，case可以方便地实现多重选择，类似select 中的case。 select type,sum(case vender when 'A' then pcselse 0 end),sum(case vender when 'C' then pcs else 0 end),sum(case vender when'B' then pcs else 0 end) FROM tablename group by type 显示结果： type vender pcs 电脑 A 1 电脑 A 1 光盘 B 2 光盘 A 2 手机 B 3 手机 C 3 23、说明：初始化表table1 TRUNCATE TABLE table1 24、说明：选择从10到15的记录 select top 5 * from (select top 15 * from tableorder by id asc) table_别名 order by id desc 随机选择数据库记录的方法（使用Randomize函数，通过SQL语句实现） 　　对存储在数据库中的数据来说，随机数特性能给出上面的效果，但它们可能太慢了些。你不能要求ASP“找个随机数”然后打印出来。实际上常见的解决方案是建立如下所示的循环：  Randomize  RNumber = Int(Rnd*499) +1  While Not objRec.EOF  If objRec(\"ID\") = RNumber THEN  ... 这里是执行脚本 ...  end if  objRec.MoveNext  Wend  　　这很容易理解。首先，你取出1到500范围之内的一个随机数（假设500就是数据库内记录的总数）。然后，你遍历每一记录来测试ID 的值、检查其是否匹配RNumber。满足条件的话就执行由THEN 关键字开始的那一块代码。假如你的RNumber 等于495，那么要循环一遍数据库花的时间可就长了。虽然500这个数字看起来大了些，但相比更为稳固的企业解决方案这还是个小型数据库了，后者通常在一个数据库内就包含了成千上万条记录。这时候不就死定了？  　　采用SQL，你就可以很快地找出准确的记录并且打开一个只包含该记录的recordset，如下所示：  Randomize  RNumber = Int(Rnd*499) + 1  SQL = \"SELECT * FROM Customers WHERE ID =\" & RNumber  set objRec = ObjConn.Execute(SQL)  Response.WriteRNumber & \" = \"& objRec(\"ID\") & \" \" &objRec(\"c_email\")  　　不必写出RNumber和ID，你只需要检查匹配情况即可。只要你对以上代码的工作满意，你自可按需操作“随机”记录。Recordset没有包含其他内容，因此你很快就能找到你需要的记录这样就大大降低了处理时间。  再谈随机数  　　现在你下定决心要榨干Random 函数的最后一滴油，那么你可能会一次取出多条随机记录或者想采用一定随机范围内的记录。把上面的标准Random 示例扩展一下就可以用SQL应对上面两种情况了。  　　为了取出几条随机选择的记录并存放在同一recordset内，你可以存储三个随机数，然后查询数据库获得匹配这些数字的记录：  SQL = \"SELECT * FROM Customers WHERE ID =\" & RNumber & \" OR ID = \" & RNumber2 & \" ORID = \" & RNumber3  　　假如你想选出10条记录（也许是每次页面装载时的10条链接的列表），你可以用BETWEEN 或者数学等式选出第一条记录和适当数量的递增记录。这一操作可以通过好几种方式来完成，但是 SELECT 语句只显示一种可能（这里的ID 是自动生成的号码）：  SQL = \"SELECT * FROM Customers WHERE IDBETWEEN \" & RNumber & \" AND \" & RNumber &\"+ 9\"  　　注意：以上代码的执行目的不是检查数据库内是否有9条并发记录。 随机读取若干条记录，测试过 Access语法：SELECT top 10 * From 表名 ORDER BY Rnd(id) Sql server语法：select top n * from 表名 order by newid() MySql语法：Select * From 表名 Order By rand() Limit n Access左连接语法(最近开发要用左连接,Access帮助什么都没有,网上没有Access的SQL说明,只有自己测试, 现在记下以备后查) 语法：Selecttable1.fd1,table1,fd2,table2.fd2 From table1 left join table2 ontable1.fd1,table2.fd1 where ... 使用SQL语句用...代替过长的字符串显示 语法： SQL数据库：select case when len(field)>10then left(field,10)+'...' else field end as news_name,news_id from tablename Access数据库：SELECT iif(len(field)>2,left(field,2)+'...',field)FROM tablename;  Conn.Execute说明 Execute方法 　　该方法用于执行SQL语句。根据SQL语句执行后是否返回记录集，该方法的使用格式分为以下两种： 　　1．执行SQL查询语句时，将返回查询得到的记录集。用法为： 　　Set 对象变量名=连接对象.Execute(\"SQL 查询语言\") 　　Execute方法调用后，会自动创建记录集对象，并将查询结果存储在该记录对象中，通过Set方法，将记录集赋给指定的对象保存，以后对象变量就代表了该记录集对象。 　　2．执行SQL的操作性语言时，没有记录集的返回。此时用法为： 　　连接对象.Execute\"SQL 操作性语句\" [, RecordAffected][, Option] 　　·RecordAffected为可选项，此出可放置一个变量，SQL语句执行后，所生效的记录数会自动保存到该变量中。通过访问该变量，就可知道SQL语句队多少条记录进行了操作。 　　·Option可选项，该参数的取值通常为adCMDText，它用于告诉ADO，应该将Execute方法之后的第一个字符解释为命令文本。通过指定该参数，可使执行更高效。 ·BeginTrans、RollbackTrans、CommitTrans方法 　　这三个方法是连接对象提供的用于事务处理的方法。BeginTrans用于开始一个事物；RollbackTrans用于回滚事务；CommitTrans用于提交所有的事务处理结果，即确认事务的处理。 　　事务处理可以将一组操作视为一个整体，只有全部语句都成功执行后，事务处理才算成功；若其中有一个语句执行失败，则整个处理就算失败，并恢复到处里前的状态。 　　BeginTrans和CommitTrans用于标记事务的开始和结束，在这两个之间的语句，就是作为事务处理的语句。判断事务处理是否成功，可通过连接对象的Error集合来实现，若Error集合的成员个数不为0，则说明有错误发生，事务处理失败。Error集合中的每一个Error对象，代表一个错误信息","title":"经典SQL语句集锦"},{"content":"一．导出指定数据库 语法： mysqldump -h ip地址 -u 用户名 -p -B 数据库名>存放目录+fileName.sql 示例： <linux下的路径>： mysqldump -h localhost -u dev01 -p123456 -B ecmall>~/20091127_ecmall.sql  <window下的路径>： mysqldump -h localhost -u dev01 -p123456 -B ecmall>E:\\ecmall.sql 二．导入指定数据库 语法： mysql -h ip地址 -u 用户名 -p -B 数据库名< E:\\zcy.sql 示例： mysql -h 10.0.0.135 -u zcy -p -B 123< E:\\zcy.sql 三．导出指定数据库的结构  语法： mysqldump -h ip地址 -u 用户名 -p -d 数据库名称 >存放目录+fileName.sql  示例： mysqldump -h localhost -u root -p123456 -d ecmall > E:\\ecmall.sql  四．向指定数据库中导入指定数据表结构 语法： mysql -h ip地址 -u 用户名 -p -B 数据库名称< 存放路径+fileName.sql 示例： mysql -h 10.0.0.135 -u zcy -p -B 123< E:\\zcy_s.sql 五．导出指定数据库中指定的表 语法： mysqldump -h ip地址-u 用户名-p -B 数据库名--tables tabName1 tabName2 >E:\\t_table.sql 示例： mysqldump -u root -p -B 数据库名 --tables t_user > E:\\t_user.sql 六．向指定数据库中导入指定表 <mysql 命令行>  source ~/backup/back.sql（没做实验） <windows系统命令行>  语法： mysql -h ip地址 -u 用户名 -p -B 数据库名 < 存放目录+fileName.sql 示例： mysql -u root -p -B 123 < E:\\t_user.sql 七．导出指定数据库中某表的数据表结构  语法： mysqldump -u用户名 -p -d 数据库名称 tabName1 tabName2  > 存放目录+fileName.sql  示例： mysqldump -u root -p123456 -d ecmall test1 test2 test3 > E:\\ecmall.sql  八．向指定数据库中导入指定数据表结构 语法： mysql -h ip地址 -u 用户名 -p -B 数据库名称< 存放路径+fileName.sql 示例： mysql -h 10.0.0.135 -u zcy -p -B 123< G:\\t_user.sql 说明： 1.所有的操作均是在安装有mysql数据库的机器上，cmd命令行下执行的。 2.所有导出功能都是有mysqldump命令执行的，所有导入功能都是有mysql命令执行的。 3.如果数据库服务器在本地，-h参数可以省略 4.-p参数后面可直接跟密码，两者之间不能有空格 5.要写什么呢  突然间给忘了 6.导出功能linux下和windows下好像只有路径问题不同（没做实验），导入的话linux下好像用source命令 备注： 1.如果运行出现类似以下错误 mysqldump: Got error: 23: Out of resources when opening file './discuz/ecs_user_ address.MYD' (Errcode: 24) when using LOCK TABLES 解决办法：加上 --skip-lock-tables选项即可 示例： mysqldump -h 10.0.0.135 -u root -p -B test --skip-lock-tables>E:/test.sql 参考：http://blog.csdn.net/long405581649/article/details/5766731 2.如果运行出现类似以下错误 mysqldump: Got error: 1449: The user specified as a definer (‘xxx’@'xxxxxx’) does not exist when using LOCK TABLES 解决办法：创建要求的用户并赋予权限，导出后编辑sql文件将‘xxx’@'xxxxxx’改为自己数据库用户即可 参考：http://blog.chinaunix.net/uid-17282739-id-3209767.html","title":"cmd命令行下导入导出mysql数据库的sql脚本文件"},{"content":"groupadd mysql //建立mysql用户组 useradd -g mysql mysql  //建立mysql帐户 tar -zxvf mysql-x.x.xx.tar.gz  //解压缩mysql cd mysql-5.0.45  //进入解压好的mysql目录 ./configure –prefix=/usr/local/mysql –with-charset=utf8 –with-collation=utf8_general_ci –with-extra-charsets=latin1  //设置参数 make make install  //开始安装 cp support-files/my-medium.cnf /etc/my.cnf  //拷贝my-medium.cnf文件到/etc/目录下并重命名为my.cnf 用编辑器打开my.cnf文件，找到log-bin=mysql-bin这一行，将其注释掉 :#log-bin=mysql-bin cd /usr/local/mysql   //进入mysql目录 bin/mysql_install_db --user=mysql chown -R root .  //设置目录权限属性 chown -R mysql /usr/local/mysql/var chgrp -R mysql bin/mysqld_safe --user=mysql &  //启动mysql 用编辑器打开/etc/rc.local文件，在exit 0前面加上，/usr/local/mysql/bin/mysqld_safe –user=mysql & 重新启动，输入mysql，如果能进入则说明启动成功！ ——————————-mysql常用命令———————— mysql -uroot -p //登陆本机mysql、root为用户名 mysqladmin -uroot -p password 1234  //1234为新密码 create database mydb;   //新建一个名为mydb的数据库 drop database mydb  //删除一个名为mydb的数据库 show databases  //查看数据库 desc func   //查看数据表的详细结构 —————————–关键的，常用数据库维护操作———— mysqldump -uroot -p -all -database>/Users/venmos/backup.sql  //备份全部数据库到/Users/venmos/目录下的backup.sql文件 mysqldump -uroot -p mydb>/Users/venmos/backup.sql  //备份mydb数据库到/Users/venmos/目录下的backup.sql文件 use /Users/venmos/backup.sql  //导入/Users/venmos/目录的backup.sql数据库","title":"mysql简单的操作"},{"content":"Oracle 学习笔记目录 ❀Oracle部分 第一章 数据库介绍 3 第二章 Oracle简介 4 第三章 用户、权限 6 第四章 Oracle数据类型 8 第五章 SQL语句概述 9 第六章 表空间 11 第七章 表 12 第八章 函数 14 第九章 约束 17 第十章 单查询查询 22 第十一章 多表查询-内连接 23 第十二章 多表查询-外连接 25 第十三章 多表查询-基本 26 第十四章 多表查询-连接 29 第十五章 子查询 32 第十七章 组函数及分组统计 34 第十八章 数据库对象-视图 37 第十九章 数据库对象-序列 40 第二十章 数据库对象-同义词 43 第二十一章 数据库对象-索引 44 第二十二章 网络配置 47 第二十三章 嵌套表、可变数组 48 ❀PL/SQL部分 第一章 PL/SQL 简介 51 第二章 PL/SQL数据类型 54 第三章 LP/SQL控制语句 58 第四章 动态SQL 63 第五章 错误处理 64 第六章 游标-隐式游标 66 第七章 游标-显式游标 68 第八章 游标-REF游标 72 第九章 子程序-过程 74 第十章 子程序-函数 77 第十一章 自主事物处理 80 第十二章 程序包 82 第十三章 触发器讲解 85 第十四章 触发器实例 89 第十五章 数据库设计和三大范式 92 第十六章 数据库的备份与恢复简介 97 第十七章 导入导出工具 99 第十八章 数据库归档方式 101 ❀JDBC部分 JDBC部分 104 第一章 jdbc简介 104 第二章 连接数据库 106 第三章 常用数据库的驱动程序和JDBC URL 108 第四章 连接池 109 第五章 数据操作-创建表 111 第六章 数据操作-查询 112 第七章 预处理 113 第八章 批处理 114 第九章 数据的数据 115 第十章 调用函数 116 第十一章 调用过程 119 第十二章 DAO封装 122 第一章 数据库介绍 一、数据的储存方法： 第一种方法：用大脑来记住数据 第二种方法：写在纸上 第三种方法：写在计算机的内存中 第四种方法:写成磁盘文件 二、数据库能做什么？ 1.存储大量数据，方便检索和访问 2.保持数据的一致、完整 3.共享和安全 4.通过组合分析，产生新的有用信息 三、数据库的发展史 萌芽阶段--文件系统   ★使用磁盘文件储存数据 初级阶段--第一代数据库   ★出现了网状模型、层次模型的数据库 中级阶段--第一代数据数据库   ★关系型数据库和结构化查询语言 高级阶段--新一代数据库   ★“关系-对象”型数据库 四、当前的数据库产品 Oracle ------甲骨文 BD2    -------IBM SQL Server ------微软 Sybase -------赛贝思 MySql  -------SUN 五、数据库和应用程序 六、数据库相关的基本概念 概念模型：基于客户的想法和观点所形成的认识和对象 实体(Entiy):客观存在的、可以被描述的事物。如员工 、部门 属性(Attribute):用于描述实体所具有的特征或特性，如使用编号、姓名、部门、工资等属性员工的特征。 关系(Relationship):实体之间的联系。如部门和员工之间有一对多的关系。 数据模型：也叫关系模型，是实体、属性、关系在数据库中的具体表现。 关系数据库：用于储存各种类型的“仓库”，是二维表的集合 表：实体的映射 行和列：行代表一个具体的实体数据。也叫一条记录。列是属性的映射，用于描述实体的 主键和外键 七、数据库管理系统(DBMS)                       第二章 Oracle简介 快速掌握Oracle 课程目标: ● Oracle安装及配置 ● 有关数据库的DDL操作 ● 有关数据表的DDL操作 ● 有关数据表的CRUD操作 ● 事物控制 ● 索引  视图 ● 存储过程 ● 触发器 ● 权限管理 ● 数据库的备份与恢复 ● 数据库设计 Oracle是一个生产中间件和数据库的较大生产商，Oracel的原本含义是“神喻”，指的是神说的话。在中国的商朝的时代，把一些刻在龟壳上的文字当成了上天的指示，所以在中国也将Oracle翻译成“甲骨文”。 Oracle的发展实际上依靠了IMB公司。 Oracle的创始人是：Larry Ellision创办了Oracle公司。 Oracle的版本分为： Oracle 8 Oracle 8i:Internet表示此时Oracle公司开始开始正式进军互联网. Oracle 9i: Oracle 8i和Oracle 9i相比是非常相似的 Oracle 10g: g表示网格技术 网格技术：如我们在百度上下载一个软件，那么这个软件在离我们的远处有一个，在我们的近处也有一个，有可能我们通过搜索引擎下载的是远的那个。忽略了近处的资源，这样就造成了资源的浪费。所以就产生了网格技术。就是将网络划为了多个小格。通过网络表示区域。 ◇Oracle 是由甲骨文公司生产的以高级结构化查询语言(SQL)为基础的大型关系数据库，通俗地讲它是用方便逻辑管理的语言操纵大量有规律数据的集合。是目前最流行的客户/服务器(CLIENT/SERVER)体系结构的数据库之一 。 ◇是目前市场占用率极高的一款数据库产品 特点: ◆提供了基于角色(ROLE)分工的安全保密管理。在数据库管理功能、完整性检查、安全性、一致性方面都有良好的表现。 ◆支持大量多媒体数据，如二进制图形、声音、动画以及多维数据结构等。  ◆提供了与第三代高级语言的接口  ◆提供了新的分布式数据库能力。可通过网络较方便地读写远端数据库里的数据，并有对称复制的技术。  一、存储结构： 物理结构： ORACLE数据库在物理上是存储于硬盘的各种文件。它是活动的，可扩充的，随着数据的添加和应用程序的增大而变化。  逻辑结构: ORACLE数据库在逻辑上是由许多表空间构成。主要分为系统表空间和非系统表空间。非系统表空间内存储着各项应用的数据、索引、程序等相关信息。 二、启动Oracle 在Window平台下必须启动的Oracle服务有： 1.OracleServiceSID  数据库服务，这个服务会自动地启动和停止数据库。如果安装了一个数据库，它的缺省启动类型为自动。服务进程为ORACLE.EXE. 2.OracleHOME_NAMETNSListener 监听器服务。 3.sqlplus工具 sqlplus工具 登录数据库有以下几种方式： (1).sqlplus:以命令的方式进入数据库连接 (2).sqlplusw：以窗口的形式启动命令行 在使用此命令时，会提示一个主机的字符串，如果一台电脑上有多个数据库的话，则要在此处输入数据库的名称，如果不输入，会进行默认的，一般默认的是最后一个数据库。 那么登录帐户以后，就可以在数据库中进行增、删、改、查等操作。 如我们可以查看表：SELECT * FROM emp;(emp表是数据库自带的表) 当我们对表进行查看时，有时候显示的表并不规范，如本来是一行的内容，可是有一部分被补到了下一行。这样看下来表就很混乱，不规范。所以我们要对其环境 进行一下设置。 如设置每行显示的长度：set linesize 300; 有时候标题行还会重复出现，在这因为在Oracle中数据是一页一页的显示方式进行输出的。所我们可修改每页显示行数。 如set pagesize 20; 4.命令 我们通常使用的sqlplusw 在sqlplusw中存在着大量的命令。 在sqlplusw下编辑代码时，出现了错误，不允许我们使用向左方向键向右移动到相应的位置上进行修改，很不方便，所以通常我们使用记事本进行代码的编辑，直接在命令行中输入“ed 文件名名称即可”。如 ed test，输入之后会提示找不到test.sql文件，要创建新文件吗？我们选择“是”，那么就创建了一个test文件，我们就可以在test文本中写相应的代码。创建完成之后，可以通过@文件名称的方式执行命令。如@test，就会执行在test中写的代码。 除了在sqlplus中创建文件之外，也可以通过@符找到磁盘上的文件，如我们在D盘上建立一个demo.txt的文件，里边写上查询指令。执行的时候，要指定文件的路径：@路径，如@D:\\demo.txt，也会执行demo中的指令。效果也完全一样的。 “\\”可以省略。如@D:demo.txt.如果文件的后缀是.sql，则不写后缀名称也可以找到。如：@D:demo。所以默认找到的后缀是“*.sql”。 在sqlplusw中可以使用“/”表示重复执行上一句命令的操作。   第三章 用户、权限 一、用SQLPLUS登录Oracle 1.Sqlplus 用户/密码 [as 身份] 如登录系统帐户：conn sys/system as sysdba; conn:连接到数据库的关键字 sys:系统用户名 system:是验证密码 as sysdba:是身份验证 2.Oracle 内置帐户 sys具有最大的权限。  Oracle数据库服务器启动后，一般至少有以下几个用户：  Internal，它不是一个真实的用户名，而是具有SYSDBA优先级的Sys用户的别名，它由DBA用户使用来完成数据库的管理任务，包括启动和关闭数据库； sys:它是一个 DBA用户名，具有最大的数据库操作权限； system:它也是一个 DBA用户名，权限仅次于 Sys用户  scott:它是一个oracle示例/学习帐户 3.停止和启动Oracle 启动/停止windows服务 Sqlplus /nolog  利用这个命令可以在DOS下不利用任何身份进入到SQL的状态。之后再利用身份登录 Connect /as sysdba Shutdown/startup /是以操作系统认证进行登录 Nolog不创建初始联接 4.创建、删除用户 △创建帐户： CREATE USER username  IDENTIFIED BY password                 [DEFAULT  TABLESPACE  tablespace1]------>默认表空间                 [TEMPORARY TABLESPACE  tablespace2]------>临时表空间                 [QUOTA      n  K  ON  tablespace1];------>不足时自动增加nK或nM                                  M                              UNLIMITED----------------------->没有限制 如创建一个hellen的帐户：create user hellen identified by abcd; △删除帐户： 基本语法：DROP USER userName [cascade]; 如果加上cascade关键字可删除该用户所创建的对象。 如：删除用户hellen:  drop user hellen; △用户修改密码： 基本语法：ALTER USER userName IDENTIFIED BY password; 如: alter user hellen identified by abc123; △用户解锁： 基本语法：ALTER USER userName ACCOUNT UNLOCK; 如：alter user hellen account unlock; △查看当前登录用户 SHOW USER; △查看系统有哪些用户： SELECT USERNAME FROM DBA_USERS;   如：   第一步：desc dba_users;   第二步：select username, USER_ID, ACCOUNT_STATUS FROM DBA_USERS; △查看用户的默认表空间 select username,default_tablespace from dba_users; △查看用户有哪些表空间 select distinct tablespace_name from dba_tables where owner=‘USER'; △确定用户帐户所授予的权限 select * from DBA_tab_privs ; 直接授予用户帐户的对象权限 select * from DBA_role_privs ; 授予用户帐户的角色 select * from DBA_sys_privs WHERE GRANTEE=?; 授予用户帐户的系统权限 5.授于用户连接Oracle数据库的权限 格式：grant 权限 to 帐户名。 如授予可以连接到数据库的权限：grant hellen to  scott; 常用的权限有：  connect  (8) 连上Oracle,做最基本操作  resource(5) 具有程序开发最基本的权限  dba      (77)数据库管理员所有权限  exp-full-database  可把数据库整个备份输出的权限  imp-full-datsabase 可把数据库整个备份恢复输入的权限 6.回收权限 基本语法： REVOKE 权限 FROM 用户名; REVOKE 实体权限|ALL ON 表空间 FROM 用户名|角色名|PUBLIC; 如授回连接到数据库的权限：revoke connect from hellen; 常见的实体权限：见附录 第四章 Oracle数据类型 Oracle 提供了22 种不同的SQL数据类型供我们使用: ★ CHAR：这是一个定长字符串，会用空格填充来达到其最大长度。非null 的CHAR(12.)总是包含12字节信息。CHAR 字段最多可以存储2,000 字节的信息。 ★ NCHAR：这是一个包含UNICODE 格式数据的定长字符串。最多可以存储2,000 字节的信息。 ★ VARCHAR2：这是一个变长字符串，与CHAR 类型不同，它不会用空格填充至最大长度。VARCHAR2(12)可能包含0～12字节的信息。VARCHAR2 最多可以存储4,000 字节的信息。 ★ NVARCHAR2：这是一个包含UNICODE 格式数据的变长字符串。NVARCHAR2(12)可以包含0～12字符的信息。NVARCHAR2 最多可以存储4,000 字节的信息。 ★ NUMBER：这种数据类型能存储精度最多达38 位的数字。这些数介于12×12(-130)-1— —12×12(126)之间。 用法:number(p,s);p和s是可以选的,用于表示整数部分和小数部分的精度 ★ BINARY_FLOAT：这是Oracle 10g Release 1 及以后版本中才有的一种新类型。它是一个32位单精度浮点数，可以支持至少6 位精度，占用磁盘上5 字节的存储空间。 ★ BINARY_DOUBLE:这也是10g中新的一种类型 ★ CLOB：在Oracle9i 及以前的版本中，这种数据类型允许存储最多4GB 的数据，在Oracle 10g及以后的版本中允许存储最多（4GB）×（数据库块大小）字节的数据。这种数据类型很适合存储纯文本信息。 ★ BLOB：在Oracle9i 及以前的版本中，这种数据类型允许存储最多4GB 的数据，在Oracle 10g及以后的版本中允许存储最多（4GB）×（数据库块大小）字节的数据。适合于存储图片/文档 ★ LONG：这种类型能存储最多2G 的字符数据----建议使用CLOB代替 ★ DATE：这是一个7 字节的定宽日期/时间数据类型。其中总包含7 个属性，包括：世纪、世纪中哪一年、月份、月中的哪一天、小时、分钟和秒。 ★ TIMESTAMP：这是一个7 字节或12.字节的定宽日期/时间数据类型。它与DATE 数据类型不同，因为TIMESTAMP 可以包含小数秒（fractional second）；带小数秒的TIMESTAMP 在小数点右边最多可以保留9 位。 ★ TIMESTAMP WITH TIME ZONE：与前一种类型类似，这是一个12.字节的定宽TIMESTAMP，不过它还提供了时区(TIME ZONE)支持。数据中会随TIMESTAMP 存储有关时区的额外信息，所以原先插入的TIME ZONE 会与数据一同保留。 ★ ROWID：ROWID 实际上是数据库中一行的12字节地址。ROWID 中编码有足够的信息，足以在磁盘上定位这一行，以及标识ROWID 指向的对象。 (1)Oracle 中伪列就像一个表列，但是它并没有存储在表中 (2)伪列可以从表中查询，但不能插入、更新和删除它们的值 (3)常用的伪列有ROWID和ROWNUM    ROWID 是表中行的存储地址，该地址可以唯一地标识数据库中的一行，可以使用 ROWID 伪列快速地定位表中的一行。    ROWNUM 是查询返回的结果集中行的序号，可以使用它来限制查询返回的行数 例： 列的类型主要有如下几种： NUMBER(4):表示是数字，长度为4 VARCAHR2(10):表示的是字符串，只能10的个的长度 DATE:表示日期 NUMBER(7,2): 表示是数字，其中小数位占2位，整数位占5位，总共是7位。   第五章 SQL语句概述 SQL语句概述 ○ SQL结构化查询语言(Structured Query Language) 一般读作：[si:kju:] 或者是字母 S Q L 的发音。 ○ 目前数据库厂商实现的都是SQL92标准,还没有任何一家厂商通过SQL99标准认证 ○ Oracle对SQL92做了扩展,所以称自己为加强版SQL(SQLPLUS)。 对于不同的数据库来讲，重点都是掌握SQL语句，因为现在的数据库全部是以SQL操作的标准，在实际中，各个数据库就是提供的函数不同。 SQL语言主要用于与数据库的通讯。SQL语言功能强大 ，主要分为以下同种：DML DDL DCL 事物控制语言。 一、SQL语句分类 1.DDL(Data Definition Language)数据定义语言:定义数据库对象(表空间,表,列,索引等)   如：CREATE,DROP,ALTER，TRUNCATE 等 2.DML(Data Manipulation Language)数据操纵语言:完成对数据记录的操作   如：INSERT,DELETE,UPDATE,SELECT 等。 3.DCL(Data Control Language)数据控制语言:定义用户的访问权限和安全级别   如：GRANT,REVOKE 4.事物控制(Transaction Control)事物控制:如：COMMIT,ROLLBACK (1)事务是最小的工作单元，作为一个整体进行工作 (2)保证事务的整体成功或失败，称为事务控制 用于事务控制的语句有： (4)COMMIT - 提交并结束事务处理 当向表插入一个新值的时候，该事物并没有被永久的写到磁盘上去 ，重新打开窗口再次查询该表中的数据时，发现并没有刚才插入的记录，这是因为这个事物还没有结束，当遇到commit或rollback才认为是结束了。 如果要永久性的提交可以执行：commit命令，再次打开新的窗口时该记录已被写到表中了。 (5)ROLLBACK -  撤销事务中已完成的工作 当我们做了和系列的操作以后，都没有执行commit命令，也就是没有提交，我们执行了rollback就可要回到原点了，也就是刚才所做的都等于没做，所有rollback回退是将所有的回退。 (6)SAVEPOINT – 标记事务中可以回滚的点 因为rollback回退是将所有的都回退了，这明显不太好，那么我们可以设置几个回退点，使再次回退的时候，不让其回退到原点，而是回退到我们固定的位置上去。 如： UPDATE 表名 set id=2 WHERE id=3----->将id=3改为id=2 SAVEPOINT mark1------>设置一个还原点mark1 DELETE FROM 表名 WHERE id=5---->删除id=5 SAVEPOINT mark2;----->再设置一个还原点mark2 二、Oracle支持的SQL操作符的分类：算术操作符 比较操作符 逻辑操作符 集合操作符 连接操作符 1.算术操作符： 算术操作符用于执行数值计算 可以在SQL语句中使用算术表达式，算术表达式由数值数据类型的列名、数值常量和连接它们的算术操作符组成 算术操作符包括加(+)、减(-)、乘(*)、除(/)。 2.连接操作符用于将多个字符串或数据值合并成一个字符串 例：要求查出雇员的编号、姓名、工作但是显示的格式是： 编号是：7369的雇员，姓名是：SMITH,工作是:CLERK SELECT '编号是：'||empno||'的雇员，姓名是：'||ename||'工作是'||job;---->使用了连接操作符 在查询中也可以 使用四则运算功能。如我们要查每个雇员的姓名及年薪。 SELECT  ename,sal*12 FROM emp;----->月薪*12表示年薪------>使用了算术操作符 3.比较操作符用于比较两个表达式的值 比较操作符包括 =、!=、<、>、<=、>=、BETWEEN…AND、IN、LIKE 和 IS NULL等 例： SQL> SELECT itemdesc, re_level      FROM  itemfile      WHERE qty_hand < max_level/2; SQL> SELECT orderno FROM order_master       WHERE del_date IN (‘06-1月-05’,‘05-2月-05'); SQL> SELECT vencode,venname,tel_no       FROM vendor_master       WHERE venname LIKE 'j___s'; 4.逻辑操作符 逻辑操作符用于组合多个计较运算的结果以生成一个或真或假的结果。 逻辑操作符包括与(AND)、或(OR)和非(NOT)。  例：显示 2005-5月-10 至 2005-5月-26的订单信息 SQL> SELECT * FROM order_master       WHERE odate > ‘10-5月-05'       AND del_date < ‘26-5月-05’; 5.集合操作符将两个查询的结果组合成一个结果，集合操作符有：UNION、UNION ALL、INTERSECT、MINUS (1)UNION:将两个表中的所有的记录合到一起，但重复的只合一遍 如：用法有两个表(id 和 name) SELECT * FROM 表A UNION SELECT * FROM 表B; 结果：A与B重复的行只拿一次 (2)UNION ALL:重复的行复取，也就是取出所有的(A+B) SELECT * FROM A UNION ALL SELECT * FROM B; (3)INTERSECT:返回公有的(A与B的交集) (4)MINUS 差积(A-B或B-A) 用法都与UNION相同。 注一：在求差积时，如果A放前，去掉公共的行时，剩余的都是A中的，而B中剩余了什么并不管。如果B放前去掉公共行时，剩余都是B中的。 注二、在使用集合操作符时，两个表的类型一定要相同。 三、SQL 操作符的优先级从高到低的顺序是： 算术操作符           --------最高优先级 连接操作符 比较操作符 NOT 逻辑操作符 AND 逻辑操作符 OR   逻辑操作符   --------最低优先级    第六章 表空间  表空间 1.创建表空间   基本语法：   CREATE TABLESPACE spacename   [LOGGING] | NOLOGGING   DATAFILE ‘d:\\javasky.dbf’    SIZE 200M    AUTOEXTEND ON NEXT 200M; 如：   create tablespace javasky ---->表空间名   datafile 'd:\\javasky.dbf'----->目录地址   size 20M----------------------->大小为20M   autoextend on next 5M;-------->当空间不足时自动增加5M; 2.删除表空间   基本语法：   DROP TABLESPACE “TABLESPANCENAME”   注意表空间的名字需要使用双引号包围,并且表空间的名称需要大写。   如：drop tablespace \"JAVASKY\"; 3.查看表空间的名称和状态   select tablespace_name,status from dba_tablespaces;    表空间的状态属性主要有在线（ONLINE）、离线（OFFLINE）、只读（READ ONLY）和读写（READ WRITE）4种  4.修改表空间的状态   alter tablespace 表空间名 状态;可以修改表空间的状态   第七章 表 查看该帐户下所有的表： 第一种、select * from cat; 第二种、select * from tab; ● 建表 CREATE TABLE 表名(列名 列类型,…); 如：create table student(id int,name varchar2(5),address varchar2(10));     --创建一个具有ID NAME ADDRESS 的学生信息表 创建完表以后可以利用:desc 表名 来查看 如 dest student; 如名称、类型、是否为空。 ● 修改表 1.增加新列   ALTER TABLE 表名 ADD 列名 列类型 [ADD 列 类型];   如新一个电话的列：alter table student add tel number;   增加一个新的列后给其赋值：update student set tel=15114562383 where id=2; 2.删除旧列   ALTER TABLE 表名 DROP COLUMN 列名; 3.修改列类型(要求,列中无数据)   ALTER TABLE 表名 MODIFY 列名 列类型 4.修改列名   ALTER TABLE 表名 RENAME COLUMN 列名 TO 新列名;  5.修改表名   RENAME 表名 TO 新表名; ● 插入(记录)数据，也就是给列赋值 1.给其相应的字段赋值：INSERT INTO表名[(列名1,,,,)]  VALUES(值1,,,); 注：[]中的内容可写可不写 如：INSERT INTO student(id,name,addredd) VALUES(1,'李小龙','河北省'); 2.赋全值  INSERT INTO student VALUES(1,'李小龙','河北省'); 3.赋值以后查看该表的内容： select * from student; 4.插入日期格式的值： INSERT INTO 列名(列名) VALUES (TO_DATE('2005-10-18', 'YYYY-MM-DD')); ● 修改记录 UPDATE 表名 SET 列名=值,…. [WHERE 条件]; 如 update 表名 set tname='李小龙'    where tname='李建龙'; ----->这是一个条件限制 ● 删除(记录)数据 第一种方法： DELETE FROM 表名               [WHERE 条件];         第二种方法： TRUNCATE TABLE 表名; ● 利用现有的表创建表    语法： CREATE TABLE <new_table_name> AS SELECT column_names FROM <old_table_name>; 如： SQL> CREATE TABLE newitemfile      AS SELECT * FROM itemfile;------>所有的列 SQL> CREATE TABLE newitemfile1       AS SELECT itemcode, itemdesc, qty_hand ----->选择特定的列      FROM itemfile; SQL> CREATE TABLE newitemfile2       AS SELECT * FROM itemfile      WHERE 1 = 2;------>建表时的条件，这里是1=2，明显为假，但是可是以建表，但是空的内容为空。      ● 不带条件的DELETE和TRUNCATE TABLE的区别： *在功能上，TRUNCATE TABLE是清空一个表的内容，它相当于DELETE FROM  table_name。 *DELETE是dml操作，truncate table是ddl操作；因此DELETE可以回滚,TRUNCATE TABLE不可回滚。 *TRUNCATE TABLE 调整high water mark 而DELETE不；TRUNCATE TABLE之后，TABLE的HWM退回到 INITIAL和    NEXT的位置（默认）delete 则不可以。 *TRUNCATE TABLE 只能对TABLE进行操作， DELETE可以是table,view,synonym。 *TRUNCATE TABLE不会触发 DELETE触发器 *日志记录方式不同, DELETE逐行记录删除日志,TRUNCATE TABLE只记录在磁盘上某一  第八章 函数  函数 数据库系统中，每个数据库之中唯一最大的区别就是函数的支持上，使用函数可以完成一系列的操作能。Oracle 提供一系列用于执行特定操作的函数。 SQL 函数带有一个或多个参数并返回一个值 以下是SQL函数的分类：单行函数、分组函数、分析函数 一、单行函数 单行函数对于从表中查询的每一行只返回一个值 可以出现在 SELECT 子句中和 WHERE 子句中  单行函数可以大致划分为：  字符函数：接受字符输入并且返回字符或数值  数值函数：接受数值输入并返回数值  日期函数：对日期型数据进行操作  转换函数：从一种数据类型转换为另一种数据类型  通用函数：NVL函数、DECODE函数 单行函数的的语法：  function_name(columnle expression,[arg1,arg2.....])  function_name:函数的名称  culumnle:数据库列名  expression:字符串或计算表达式  arg1,arg2:函数中使用的参数 时间类型函数 SYSDATE返回当前的系统时间 ADD_MONTHS(date,x)返回加上x月后的日期DATE的值，X可以是任意的整数，如果结果的月份中所包含的日份量不于DATE的月份的日份量，则返回结果月份的最后一天，如果不小于，则结果与DATE的日份量相同。 LAST_DAY(日期)指定日期所在月份的最后一天的日期， TRUNC(日期，‘MONTH\\YEAR’)返回指定月份的第一天。 日期运算： 日期函数对日期值进行运算，并生成日期数据类型或数值类型的结果 日期函数包括：ADD_MONTHS、MONTHS_BETWEEN、LAST_DAY、ROUND、NEXT_DAY、TRUNC 范例一： 返回date1与date2之间相差的天数。该值是一个数值，其小数部分代表一天的几分之几。 SQL> select to_date('2010-01-31','yy-mm-dd')-to_date('2010-01-01','yy-mm-dd') as 相差天数 from dual;（相差天数是一个别名）   相差天数 ----------         30 范例二： 返回date1与date2之间的时间间隔 select to_date('2010-01-01 10:30','yy-mm-dd hh:mi') -to_date('2010-01-31 09:31','yy-mm-dd hh:mi') from dual; TO_DATE('2010-01-0110:30','YY-MM-DDHH:MI')-TO_DATE('2010-01-3109:31','YY-MM-DDHH:MI') -------------------------------------------------------------------------------                                                                         -29.959028 2、字符函数 Initcap(char)：将首字母转换为大写   eg：Select initcap('hello')from dual;------->Hello  Lower(char)：转化为小写 eg：Select lower(‘FUN’) from dual;------->fun  Upper(char)：转化为大这与 eg：Select upper(‘sun’) from dual;------->SUN  Ltrim(char,set)：从左边开始截取字符(一般用来截取空格) eg：Select ltrim( ‘xyzadams’,’xyz’) from dual;------->adams Trim():从两端截取 eg：SQL> SELECT TRIM('a' FROM 'abcda') FROM dual;---->abc Rtrim(char,set)：从右边开始截取字符(右截空格) eg：Select rtrim(‘xyzadams’,’ams’) from dual;-------> xyzad  Translate(char, from, to)：替换单个字符 eg：Select translate(‘jack’,’j’ ,’b’) from dual; -------> back  Replace(char, searchstring,[rep string])：替换多个字符 eg：Select replace(‘jack and jue’ ,’j’,’bl’) from dual;------->black and blue  Instr (char, m, n) ：返回一个数值型，标识截取的字符的位置，从1开始计，第一次出现的位置  eg：Select instr (‘worldwide’,’d’) from dual; ------->5  Substr (char, m, n)：从第m开始截取n个字符   eg：Select substr(‘abcdefg’,3,2) from dual;------->cd  Concat (expr1, expr2)：合并 eg：Select concat (‘Hello’,’ world’) from dual;------->Hello world 作用：以UPPER()为例 1.UPPER()强制大写 如：SELECT UPPER('hellen') FROM dual; 范例：一般用户在查询一个人的姓名的时候可能考虑到这个人的姓名是以大写字母保存的还是以小写字母保存的呢？ SELECT * FROM emp WHERE ename=UPPER('smith'); 3、字符函数 以下是一些其它的字符函数：CHR和ASCII、LPAD和RPAD、TRIM、LENGTH、DECODE 1、CHR和ASCII：通过一个字符求ASCII码 SQL> select chr(67) from dual; C ----- C 2、LPAD和RPAD：左填充、右填充 SQL> SELECT LPAD('abc',10,'*') FROM dual; LPAD('ABC' ---------- *******abc 'abc'不足10个字符，在其左边填加7个补齐10个，右填充同理 3.LENGTH():求给定的字符的长度 如： SQL> SELECT LENGTH('abcd') FROM dual; LENGTH('ABCD') -----------------------------              4 如果是“中国”结果也是2，因为这是按字符算的 LENGTH()与LENGTHC()是等同的。 还有一个LENGTHB():'中国'的结果是4，是按字节算的。 LENGTH2()和LENTH4()都是按字符算的，我们常用的是LENGTH()和LENGTHB() 4.DECODE:相当于if语句 如： SQL> SELECT DECODE(id,1,'tom',2,'jack',3,'hellen') FROM student; DECODE ------ tom jack hellen 如果id是1 2 3 分别返回 tom jack helen 相当于做了一个多行的判断 5.数字函数 函数 范例 结果 Abs(n) Select abs(-15) from dual; 15 Ceil(n) Select ceil(44.778) from dual; 45 Cos(n) Select cos(180) from dual; -.5984601 Cosh(n) Select cosh(0) from  dual; 1 Floor(n) Select floor(100.2) from  dual; 100 Power(m,n) Select power(4,2) from dual; 16 Mod(m,n) Select mod(10,3) from  dual; 1 Round(m,n) Select round(100.256,2) from dual; 100.26 Trunc(m,n) Select trunc(100.256,2) from dual; 100.25 Sqrt(n) Select sqrt(4) from dual; 2 Mod(m,n) Select mod(4,2) from dual; 0 Sign(n) Select sign(-30) from  dual; -1 dbms_random.value(x,y) Select dbms_random.value(2,4) from dual; 3.980765 6.转换函数 转换函数将值从一种数据类型转换为另一种数据类型 常用的转换函数有：TO_CHAR、TO_DATE、TO_NUMBER 1、TO_DATE SQL> SELECT TO_DATE('2005-12-06','yyyy-mm-dd') FROM dual; TO_DATE('2005- -------------- 06-12月-05 2、TO_NUMBER SQL> SELECT TO_NUMBER('100') FROM dual; TO_NUMBER('100') ----------------              100 3、TO_CHAR SQL> SELECT TO_CHAR(sysdate,'YYYY\"年\"fmMM\"月\"fmDD\"日\"HH24:MI:SS') FROM dual; TO_CHAR(SYSDATE,'YYYY\" ---------------------- 2010年11月13日11:01:45 7.其它函数:NVL、NVL2、NULLIF 1、NVL SELECT comm,NVL(comm,0) FROM 表 如果为空就用0来代替，不为空自己。 2、NVL2 有3个参数，如果第1个为空，就走第3个表达式，若不为空，走第2个表达式 SELECT comm,NVL(comm,comm,0) FROM 表 3.NULLIF 如果两个表达式的值相等返回空，不相等返回第一个表达式 SQL> SELECT NULLIF(22,23) FROM dual; NULLIF(22,23) -------------            22 SQL> SELECT NULLIF(22,23) FROM dual; NULLIF(22,23) -------------            22 二、组函数 详细见组函数及分组统计一章                      第九章 约束  CREATE TABLE深入 ● 为表增加约束 NOT NULL 非空约束 要求值不能为空 UNIQUE 唯一约束   要求值不能重复 PRIMARY KEY主键约束  对于整个表表中的记录不能重复 FOREIGN KEY外键约束  当多个表建立关联时设置的一个引用约束 CHECK 检查   检查某一个列的值要符合某一个规范，如 年龄(age>18) ● 设置表所在的表空间 ● 使用序列实现自动增长 一、什么是约束? 约束是在表上强制执行的一些数据校验规则,被插入/修改/删除的数据必须符合在相关字段上设置的这些约束条件 二、约束定义的语法 列级约束：在定义列的同时定义约束           语法：列定义 约束类型 表级约束：在定义了所有的列之后定义的约束           语法：           列定义......           [CONSTRAINT 约束名] 约束类型(列名) 约束名的命名规则：                 推荐采用：表名_列名_约束类型简写 约束可以在创建表时就定义，也可以在创建完表后再添加 语法：ALTER TABLE 表名       ADD CONSTRAINT 约束名 约束类型(要约束的列名) 三、各约束介绍 1.NOT NULL  (1)该列的值不能为空 (2)列级约束 如名字不能为空 create table depts(dept_id int,name varchar(20) NOT NULL,description varchar(100)); 如果创建了以后再加不能为空的约束可以以修改列的形式：如 alter table employee modify empname varchar2(6) not null; 2.UNIQUE (1)要求该列的值唯一，允许为空。注：Oracle允许有多个空什和null (2)列级约束、表级约束 (3)取名：表名_列名_uk 如：名字不能为空且唯一 create table depts(dept_id int,name varchar(20) NOT NULL UNIQUE,descriptionvarchar(100)); 如果是先创建了表来要增加约束可以写成： alter table depts add constraint depts_name_uk unique(name);--将名字加上唯一约束 3.PRIMARY KEY (1)用来唯一标识这一行记录，一个表中只能有一个主键 (2)功能上相当于非空且唯一 (3)列给约束、表级约束 (4)取名：表名_列名_pk 例1：将id号设置主键(在列级上定义) create table depts( id int primary key,---->将id设置为主键 name varchar(10) unique not null,---->名字不为空且唯一 description varchar(100)); 例2：在表级上定义 CREATE TABLE student( firstname VARCHAR(20), lastname  VARCHAR(20), description VARCHAR(100), [CONSTRAINT student_name_pk] PRIMARY KEY(firstname,lastname)); 这个例子是联合主键，所谓联合主键就是firstname和lastname他们的组合不重复，就认为是有效。如A B和A C这不算是重复。 (5)主键有一个最主要的作用是：当两个表关联时，主外键时，要求引用的主表中的字段一定要为主键。 4.FOREIGN KEY (1)用于两表间建立关系,需要指定引用主表的那列 (2)列级约束 表级约束 (3)命名:主表名_子表名_FK (4)语法:        [CONSTRAINT 约束名] FOREIGN KEY(子表外键列名)          REFERENCES 主表名(主键列名) 如我们把depts表和employees表的通过dept_id关联起来。 --部门表 注表 create table depts( dept_id int primary key, description varchar(20) ); --员工表 子表 create table employees( emp_id int primary key, address varchar(20), dept_id int, constraint depts_employees_fk foreign key(dept_id) references depts (dept_id)--主键  ); 表之间的关联关系，建议创建好表之后通过 ALTER TABLE 语句来添加： 语法：      ALTER TABLE 表名      ADD CONSTRAINT 外键约束名      FOREIGN KEY (本表外键列名)      REFERENCES 主表名(主表主键列名)      [ON DELETE [RESTRICT|CASCADE|SET NULL|NO ACTION]] 例： alter table employees add constraint depts_employees_fk foreign key (depts_id) references depts(depts_id); ON DELETE:用来指定在删除主表中的数据时，对关联表(从表)所做的相关操作。 RESTRICT(限制):跟NO ACTION(没有动作)，效果一样，不采取动作，即当主表中的主键在子表中被使用，则不允许修改此主键值。 CASCADE(级联)：级联更新子表 SET NULL(设置为空)：主表删除(更新)行，则设置子表中的外键列为NULL。 示例：图 如上表employees表和depts表本来没有关系的，但是通过dept_id可以将他们联系起来。 注：depts表中的dept_id必须为主键。才能通过dept_id与employees表联合起来。 录depts表与employees表进行联合的时候，他们之间便有了联系，如：在depts表中一共有四个部门部，部门号代号分别是1、2、3、4。 但是如果我们在employeess表中插记录时，就不能给某个人所在部门号设置为5，因为根本没有这个部门。 如果我们在employees表中加了两个人都是2号部门 ，那么两个表关联下来以后就不允许我们删除depts表的2号部门了。别的部门只要是在employees表中没有被引用的都可以被删除。 当子表中引用了主表中的某一个记录时，那么这个主记录不允许删除。也不允许更改。 我们可以在删除以后做一些操作如： 例： SQL> alter table employees   2  add constraint depts_employees_id   3  foreign key (dept_id)   4  references depts (dept_id)   5  on delete set null;--->删除后设置为空 也就是主表的部门被删除后，子表的记录走向为空。也就是原来引用该部门的记录现在部门不存在了，该记录的引用就就变为空了。         5.CHECK (1)对某列的值进行范围限制、格式限制等 (2)列级约束、表级约束 (3)取名：表名_列名_ck 例： SQL> create table student(   2  id int primary key,   3  name varchar(10) unique not null,   4  age int check(age>18)--可以使用like等   5  ); 6.删除约束 先找到表的约束名称，执行： select TABLE_NAME,CONSTRAINT_NAME from user_constraints where owner=‘’ 其中 CONSTRAINT_NAME 为表的约束名称 然后删除约束： alter table TABLE_NAME drop constraint CONSTRAINT_NAME [cascade]; 使用CASCADE关键字使相关约束也失效. 如：删除sal上的约束 alter table employee drop constraint employee_sal_ck; 例： SQL> desc user_constraints;   名称                                      是否为空? 类型  ----------------------------------------- -------- ----------------------------  OWNER                                     NOT NULL VARCHAR2(30)  CONSTRAINT_NAME                           NOT NULL VARCHAR2(30)  CONSTRAINT_TYPE                                    VARCHAR2(1)  TABLE_NAME                                NOT NULL VARCHAR2(30)  SEARCH_CONDITION                                   LONG   SQL> select CONSTRAINT_NAME,TABLE_NAME,CONSTRAINT_TYPE from user_constraints whe re table_name='employees'; 可以看到employees表的表名、约束名字和类型等。 7.指定表空间 CREATE TABLE() TABLESPACE spacename 如： desc user_tablespace ;----->查看所有的表空间 create table student(id int) tablespace system; 8.创建序列 序列 :是Oracle的一个对象，表也是一个对象。所谓序列是指生成了一个有顺序的数字对象。 序号生成器 创建语法: CREATE SEQUENCE 序列名 MINVALUE number1 START WITH number2 INCREMENT BY number3 nocache|cache number3; MINVALUE：最小的值 INCREMENT BY：从那开始 START WITH：增量、步长 是否可被缓存 是否可以循环 从序列中取值: Select 序列名.nextval from dual;--nextval序列中的下一个值 读取下一个值：Select seq.nextval from dual; 读取当前值：Select seq.currval from dual; 如创建一个序列： SQL> create sequence seq_dept   2  start with 1   3  increment by 2   4  maxvalue 10; 查看： SQL> select seq_dept.nextval from dual;    NEXTVAL ----------          1 第执行一次就+2. SQL> select seq_dept.currval from dual;    NEXTVAL ----------          1 currval不论执行多少次都是1. 往部门表中插： insert into depts values(seq_dept.nextval,\"财务部\"); seq_dept.nextval是一个数字对象，与部门号对应。 修改序列：如将最大值改为100. alter sequence seq_dept maxvalue 100; 删除序列：drop sequence seq_dept;   第十章 单查询查询 SQL查询的基本语法结构: SELECT selection_list             选择哪些列 FROM table_list                  从何处选择 WHERE primary_constraint        行必须满足的条件 GROUP BY grouping_columns      结果怎样分组 OREDER BY sort_columns         怎样对结果排序 ROWNUM offset                 结果限定 以emp表和部门表(dept)为例 ： 一、普通查询 1.查询所有记录的所有列 SELECT * FROM emp 2.查询特定行 SELECT * FROM empWHERE name='纪小岚'; 3.查询特定列 SELECT name,sarlary FROM emp; 4.去掉重复的值 SELECT DISTINCT dept_id FROM emp; 5.给列取别名 SELECT name AS 姓名 FROM employees; SELECT name n FROM employee;  二、条件查询 SELECT 列名.... FROM  表名.... WHERE 条件 WHERER 条件子句中的表达式： 可以包括运算符（算术、比较、逻辑等） 可以使用圆括号将一个表达式分成几个部分 可以使用常量、列和函数来完成运算 注：WHERE子句中不能有聚合运算。 条件查询示例： 1.除了张三以外的所有员工： select * form employees where name!='张三';--或可以写成name<>'张三' 2.工资在2000-5000的员工。 第一种写法：where sal>=2000 and sal<=5000; 第二种写法：where sal between 2000 and 5000; --注：包含两端 3.部门编号是1、3、5的员工名字 select name form employees impno=1 or impno=3 or empno=5; 4.有奖金的 where comm is not null; 注：0也算是有 5.所有姓张的 where name like '张%' ;--这里%是一个通配符。like是一个正则表达式匹配的关键字 6.姓张的且名字是3个字的。 where name like  '张_ _'; 7.在2008.1.1入职的女员工 where data='01-01-08' and sex='女'; 三、查询排序 SELECT 列名.... FROM 表名.... [WHERE 条件] ORDER BY 排序列名1[ASC|DESC]，排序列名2[ASC|DESC]... ASC:升序 缺省 DESC:降序 例： select * from employees  order by sal,comm desc; 四、在Oracel用“||”表示字符串的连接。如实现如下查询： 要求查出雇员的编号、姓名、工作但是显示的格式是： 编号是：7369的雇员，姓名是：SMITH,工作是:CLERK SELECT '编号是：'||empno||'的雇员，姓名是：'||ename||'工作是'||job; 在查询中也可以 使用四则运算功能。如我们要查每个雇员的姓名及年薪。 SELECT  ename,sal*12 FROM emp;----->月薪*12表示年薪 但是在查询的结果中是以sal*12的字段显示的，这样的看起来让人不太明白，不知道到底是表示什么意思。所以我们最好为这样运算结果起一个别名，但是在起别名的时候，一定要回避中文。如：SELECT  ename,sal*12 income FROM emp;【income表示年薪】。   第十一章 多表查询-内连接 SELECT 深入查询:多表联接查询、记录联合 ● 多表连接查询 1.使用单个SELECT语句从多个表中取出多个相关的数据，通过多表之间的关系 ，构建相关数据的查询。 2.多表连接通常是建立在相互关系的父子表上的。 3.SQL1999标准连接的语法： -------------------------------------  SELECT...FROM join_table  JOIN_TYPE join_table  ON join_condition  WHERE where_condition  ------------------------------------- join_table:参与连接的表 join_condition:连接条件 JOIN_TYPE:连接类型：内连接、外连接、交叉连接、自连接。 where_condition: where 过虑条件 ● 内连接 1.语法 SELECT 要查询的列 表1 [INNER] JOIN 表2 ON 连接条件 WHERE  例1，以emp表和dept表为例：这是一个等值连接 SELECT empno,dname,ename,dept.loc FROM dept--第一个表 INNER JOIN emp--另外一个要连接的表(内连接) ON emp.deptno=dept.deptno ;--连接条件，部门号相同(去除笛卡尔乘积) 注意：如果两个表中有相同的字段，则可能通过他的的表名来区别， 如：dept.address 或 emp.address 范例2. select * from dept,emp  where dept.deptno=emp.deptno; 如果有第三个表C（用where表示）如： select * from dept,emp,c where dept.deptno=emp.deptno,and c.deptno=dept.deptno; 用 JOIN IN(如有三个表分别是a b c ) select a.id,b.name,c.score from a inner join b on a.id=b.id inner join c on c.id=b.id [where]; 2.只列出这些连接表中与连接条件相匹配的数据行 3.内连接分类 等值连接：在连接条件中使用等号(=)运算符来比较被连接列的列值（常用） 如：dept.deptno=emp.deptno 非等值连接：在连接条件中使用除了等号运算符以外其它比较运算符来比较被连接的列值.使用不等值连接容易产生笛卡尔乘积（不常用）。 自连接：在连接条件中使用等号(=)运算符来比较被连接列的列值，但他使用选择列表指出查询结果集合中所包括的列，并删除连接表中的重复列。不用写ON条件，如果两个表中字段、类型完全相同的会自动连接（不常用）。 内连接示例一： select * from emp inner join dept on emp.deptid=depts.deptid; 如果表的名字很长，可以给其起一个别名如： SELECT * FROM emp AS e,dept d WHERE a.id=d.id;   第十二章 多表查询-外连接 不仅列出与连接条件相匹配的行，还列出左表（左外连接）、右表（右外连接）、或两个表 （全外连接）中所有符合WHERE 过虑条件的数据行。 分类：左外连接 (LEFT  JOIN)       右外连接 (RIGHT JOIN)       全外连接 (FULL  JOIN) 一、左外连接 示例： SELECT * FROM emp LEFT JOIN dept ON emp.deptno=dept.deptno;-->这是通用标准 以上示例与以下示例是等效的 如： select * from emp join dept on emp.deptno=dept.deptno(+);-->这是特殊符号 还可以写成： select * from emp,dept where emp.deptno=dept.deptno(+); 关键字之前的是左表关键字之后的是右表。 左处连接：取出左表中所有数据，右表中符合条件的 右外连接：取出右表中所有数据，左表中符合条件的】 当左处连接时，（+）在等号右边。 当右外连接时，（+）在等号左边。 右外连接和全外连接同理,将LEFT写成RIGHT、FULL。 全连接范例： select ename,empno,dname from emp full join dept on dept.deptno=emp.deptno; ● 记录联合  UNION UNION ALL UNION指令的的是将两个SQL语句的结果合并起来 UNION 在进行表链接后会筛选掉重复的记录，所以在表链接后会对所产生的结果集进行排序运算，删除重复的记录再返回结果。 UNION ALL，它的用法和UNION一样，只不过UNION含有DESTINCT的功能，它会把两个张表重复的记录去掉，而UNION ALL不会，所以从效率上，UNION ALL 会高一点。 注：UNION 用法中，两个SELECT 语句的字段类型匹配，而且字段个数要相同。 ● 子查询中的 in 和 exists 用in和exists查询出表B的name在表A中的记录。       表A                            表B              1.select from B where name in(select name from A) 2.select from B where exists(select temp.* from B temp.a where a.name=b.name AND a.name=temp.name) 通过上例比较 ，如果只有一个条件name使用in很方便，同理not in和not exits也是如此。 exists需要把表进行关联，in 不一定需要。 如何选择in还是exsits? 主要是看你筛选 条件是在主查询上还是在子查询上，如果条件作用在主查询上使用in，如果作用在子查询上使用exists。 在数据量较大时，exists的效率高于in. 第十三章 多表查询-基本  查询语句：  SELECT {DISTINCT} *|查询列1 别名1，查询列2 别名2....---->distinct是不可重复意思  FROM 表名称 别名  WHERE 条件(s)}----->条件可以是多个 {ORDER BY 排序字段 ASC|DESC,排序字段 ASC|DESC} 一、学习目标： 1.多表查询，SQL:1999语法对多表查询的支持 2.分组统计级统计函数的使用 3.子查询，并结合多表查询，分组统计做复杂查询 4.数据库的更新操作 5.数据库的更新操作 6.事务处理及数据库死锁 二、具体内容 多表查询  之前在查询的时候都是在一张表中查询，那么在一张表以上的查询就叫做多表查询。 基本语法： SELECT {DISTINCT} *|查询列1 别名1，查询列2 别名2..---->distinct是不可重复意思 FROM 表名称1 别名1，表名称2 别名2，表名称3 别名3..--->写多少都可以只要电脑够快 WHERE 条件(s)}----->条件可以是多个 {ORDER BY 排序字段 ASC|DESC,排序字段 ASC|DESC} 范例：下面使用了多表查询，同时查询emp表和dept表 1.select *from emp,dept;--->一共出现了56行的记录  查询emp表中的记录数: select count(*) from emp;---->14  查询dept表中的记录数:select count(*) from dept;--->4 以上同量使用了两张表进行查询，共出现了56(4*14)行，这是一个笛卡尔乘积。所以在多表查询的时候会产生笛卡尔积，如果表的数据越多，那么产生的笛卡尔成绩越大。如现在假设有5张表每张表有100000记录，那么就会产生100000的5次方条记录。所以多表查询在开发中不介意过多的使用的。 要想去掉笛卡尔积，必须使用字段进行关联的操作。 在emp表中存在一个deptno的字段,在dept表中也存在一个deptno的字段。 而且emp表的deptno的字段在dept表的deptno字段的范围之内。 emp表的deptno=dept表的deptno，这属于关联字段。 在多有查询中加入 WHERE 语句，就可以消除笛卡尔积。 范例：修改之前的查询操作： select * from dept,emp where emp.deptno=dept.deptno--->这样写比较明确，也可以写成deptno=deptno. 此时只有14行记录了，消除掉了笛卡尔积。此时又存在了一个新的问题，那么现在表名称过长的话，怎么办？ 所以在使用的时候会为表起一个别名：如：  select * from emp e,dept d ---->e 和 d 都是别名  where e.deptno=d.deptno; 所以要使用多表查询的时候，最好指定别名。 范例：要求查询出雇员的编号、雇员的姓名、部门的编号、部门的名称及部门位置。  select e.empno,e.ename,d.deptno,d.dname,d.loc  from emp e,dept d  where e.deptno=d.deptno; 结果：      EMPNO ENAME          DEPTNO DNAME          LOC ---------- ---------- ---------- -------------- -------------       7369 SMITH              20 RESEARCH       DALLAS       7499 ALLEN              30 SALES          CHICAGO       7521 WARD               30 SALES          CHICAGO 范例：要求查询每个雇员的姓名、工作、雇员的直接上司的姓名。 在emp表中的mgr字段始终没有使用过，其表示一个雇员的上级领导的编号。现在要查询一个雇员的上级领导，则肯定要将emp表和emp表自己进行关联。 select e.ename,e.job,m.ename from emp e,emp m where e.mgr=m.empno; 范例：进上步扩展之前的程序，将雇员的所有部门名称同时列出。       部门名称在demp表的定义 select e.ename,e.job,m.ename,d.dname from emp e,emp m,dept d where e.mgr=m.empno and e.deptno=d.deptno; 现在进上步深入查询 现在要求查询每个雇员的姓名、工资、部门名称，工资在公司的等级（salgrade）,及其领导的姓名及工资所在公司的等级。 先查询工资表的内容(salgrade) SELECT * FROM salgrade;  GRADE      LOSAL      HISAL ------     ----------      ----------      1        700         1200      2       1201         1400      3       1401         2000      4       2001         3000      5       3001         9999 分解： 1.查每个雇员的姓名、工资、部门名称，工资在公司的等级（salgrade），需要三张表进行关联。 select e.ename,e.sal,d.dname,s.grade from emp e,dept d,salgrade s where e.deptno=d.deptno and e.sal between s.losal and s.hisal; 2.此时雇员的工资等级已经求出，现在再求其领导的姓名及工资所在公司的等级。 select e.ename,e.sal,d.dname,s.grade,m.ename,m.sal,ms.grade from emp e,dept d,salgrade s,emp m,salgrade ms where e.deptno=d.deptno and       e.sal between s.losal and s.hisal and e.mgr=m.empno       and m.sal between ms.losal and ms.hisal; 范例：现在要求按照以下的样式写出工资的等级       1.第五等级工资       2.第四等级工资       3.第三等级工资       4.第二等级工资       5.第一等级工资     此时只能使用DECODE()函数  select e.ename,e.sal,d.dname, DECODE(s.grade,1,'第五等工资',2,'第四等工资',3,'第三等工资',4,'第二等工资',5,'第一等工资'), m.ename,m.sal, DECODE(ms.grade,1,'第五等工资',2,'第四等工资',3,'第三等工资',4,'第二等工资',5,'第一等工资') from emp e,dept d,salgrade s,emp m,salgrade ms where e.deptno=d.deptno and       e.sal between s.losal and s.hisal and e.mgr=m.empno       and m.sal between ms.losal and ms.hisal; 结果： ENAME SAL DNAME DECODE(S.G ENAME SAL DECODE(MS. JAMES 950 SALES 第五等工资 BLAKE 2850 第二等工资 ALLEN 1000 SALES 第五等工资 BLAKE 2850 第二等工资 ADAMS 1100 RESEARCH 第五等工资 SCOTT 3000 第二等工资 MILLER 1235 ACCOUNTING 第四等工资 CLARK 2450 第二等工资 WARD 1250 SALES 第四等工资 BLAKE 2850 第二等工资 MARTIN 1250 SALES 第四等工资 BLAKE 2850 第二等工资 TURNER 1500 SALES 第三等工资 BLAKE 2850 第二等工资 CLARK 2450 ACCOUNTING 第二等工资 KING 5000 第一等工资 BLAKE 2850 SALES 第二等工资 KING 5000 第一等工资 FORD 3000 RESEARCH 第二等工资 JONES 3421.25 第一等工资 SCOTT 3000 RESEARCH 第二等工资 JONES 3421.25 第一等工资 SMITH 3100 SALES 第一等工资 FORD 3000 第二等工资 JONES 3421.25 RESEARCH 第一等工资 KING 5000 第一等工资                      第十四章 多表查询-连接  多表查询连接问题 一、左、右连接 现在dept表中存在4条数据： SELECT *FROM dept;    DEPTNO DNAME          LOC --------- -------------- -------------        10 ACCOUNTING     NEW YORK        20 RESEARCH       DALLAS        30 SALES          CHICAGO        40 OPERATIONS     BOSTON 现在将emp表和dept表关联查询，查询一下指定的字段。 SELECT e.empno,e.ename,d.deptno,d.dname,d.loc FROM emp e,dept d WHERE e.deptno=d.deptno; 结果：      EMPNO ENAME DEPTNO DNAME LOC 7369 SMITH 20 RESEARCH DALLAS 7499 ALLEN 30 SALES CHICAGO 7566 JONES 20 RESEARCH DALLAS 7698 BLAKE 30 SALES CHICAGO 7782 CLARK 10 ACCOUNTING NEWYORK                   .............部分已省略 共有14行记录 此时发生了变化，部门中一共有四个部门的信息，但此时只列出了三个，因为在雇员表中没有指定40部门的雇员。现在如果我想让40部门显示出来的时候，就需要左右连接了。如我们添加一个(+)符号. SELECT e.empno,e.ename,d.deptno,d.dname,d.loc FROM emp e,dept d WHERE e.deptno=d.deptno(+);---->以e表为准 默认是左连接，所以这个(+)写与不写是一样的，肯定无法显示40部门的信息。 结果：      EMPNO ENAME DEPTNO DNAME LOC 7369 SMITH 20 RESEARCH DALLAS 7499 ALLEN 30 SALES CHICAGO 7566 JONES 20 RESEARCH DALLAS 7698 BLAKE 30 SALES CHICAGO 7782 CLARK 10 ACCOUNTING NEW YORK   .             .............部分已省略 共有14行记录      显然与不加是一个样的。那么现在把（+）放在等号的左边。 SELECT e.empno,e.ename,d.deptno,d.dname,d.loc FROM emp e,dept d WHERE e.deptno(+)=d.deptno;---->以d表为准    结果：      EMPNO ENAME   DEPTNO DNAME   LOC ---------- ----------    - --------- -------------- -------------       7782  CLARK      10  ACCOUNTING  NEW YORK       7566  JONES       20  RESEARCH     DALLAS       7499  ALLEN      30  SALES          CHICAGO                          40  OPERATIONS    BOSTON--------->出现了40部门       ..............部分已省略       共15行记录 可以发现40部门出现了，所以此时就使用到了右连接。 (+)在等号左边表示右连接 (+)在等号右边表示左连接 因为把(+)放在等号右边的时候没有变化，跟不加一样，所以默认是左连接。 左右连接在开发中使用较多，实际上之前在查找雇员姓名及每一位雇员领导的时候就该使用左右连接了。 范例：查询雇员的姓名、编号、及其领导的编号、姓名。 SELECT e.ename,e.empno,m.ename,m.empno FROM emp e,emp m WHERE e.mgr=m.empno; 结果： ENAME      EMPNO  ENAME           EMPNO ---------- ---------- ---------- ------------------------------------ SMITH        7369    FORD              7902 ALLEN        7499    BLAKE            7698 WARD         7521    BLAKE            7698 JONES         7566    KING              7839 ..............部分已省略 已选择13行。 发现查询出来的结果缺少了一条记录，因为其是最高领导，所以mgr为空。那么怎么把这个空显示出来呢。 SELECT e.ename,e.empno,m.ename,m.empno FROM emp e,emp m WHERE e.mgr=m.empno(+); 结果： ENAME      EMPNO     ENAME      EMPNO ---------- ---------- ---------- -------------------------------------------- SMITH       7369        FORD        7902 CLARK      7782        KING         7839 SCOTT       7788        JONES        7566 KING        7839 --------------->已显示 TURNER     7844        BLAKE       7698 ..............部分已省略 已选择14行。 加入了左连接之后可以发现KING出现了。 二、SQL:1999语法对SQL的支持。 1.交叉连接(CROSS JOIN)：作用是产生笛卡尔积【了解】 范例：SELECT * FROM emp CROSS JOIN dept;------>也是产生56行记录，说明产生了笛卡积 2.自然连接(NATURAL JOIN)：自动进行关联字段的匹配【了解】 范例：SELECT * FROM emp NATURAL JOIN dept;---->产生了14条记录，消除笛卡尔积(自动进行了字段匹配) 3.USINT子句：直接指定关联的操作列【了解】 范例： SELECT * FROM emp e JOIN dept d USING(deptno) WHERE deptno=30;-------->产生了6行记录 打印两张表所有的30部门的信息 4.ON 子句：表示自己编写连接条件【了解】 范例： SELECT * FROM emp e JOIN dept d ON(e.deptno=d.deptno) WHERE e.deptno=30;------>与上面产生的结果是一样的 5.左连接（左外连接）、右连接（右外连接）LEFT JOIN,RIGTH JOIN【重点】 范例： SELECT * FROM  emp e RIGHT OUTER JOIN dept d ON(e.deptno=d.deptno);   第十五章 子查询 子查询：在一个查询内部还包括另外一个查询，则称为子查询 。 子查询的格式： SELECT {DISTINCT} *|查询列1 别名1|查询列2 别名2.... FROM 表1 别名1，表2 别名2.... ( SELECT {DISTINCT} *|查询列1 别名1|查询列2 别名2.... FROM 表1 别名1，表2 别名2.... {WHERE条件} {GROUP BY 分组条件} {ORDER BY 排序字段 DESC|ASC,排序字段 DESC|ASC....} )别名 {WHERE条件 ( SELECT {DISTINCT} *|查询列1 别名1|查询列2 别名2.... FROM 表1 别名1，表2 别名2.... {WHERE条件} {GROUP BY 分组条件} {ORDER BY 排序字段 DESC|ASC,排序字段 DESC|ASC....} ) } {GROUP BY 分组条件{HAVING 分组条件}} {ORDER BY 排序字段 DESC|ASC,排序字段 DESC|ASC....} 范例：要求查出比7654工资要高的全部雇员信息 首先要清楚知道7654雇员工资是多少？ SELECT sal FROM emp WHERE empno=7654; 结果：        SAL ----------------       1250 之后要以以上的结果作为后续查询的依据，只要有其它人的工资大于SAL，则表示符合条件 SELECT * FROM emp WHERE sal>(SELECT sal FROM emp WHERE empno=7654);---->使用子查询 所有的子查询必须在“（）”中编写代码。 子查询在操作中又分为以下三类 1.单列子查询：返回的结果是一列的一个内容 2.单行子查询：返回多个列，有可能是一个完整的记录 3.多行子查询：反回多条记录 一般在程序开发中单列子查询是用的最多的。 范例：查询出工资比7654高，同时与7788从事相同工作的全部雇员信息 第1步：查询出工资比7654高的 SELECT salFROM emp WHERE empno=7654; 第2步：7788从事的工作 SELECT job FROM emp WHERE empno=7788 第3步将两个条件进行综合查找 SELECT * FROM emp WHERE sal>(SELECT sal FROM emp WHERE empno=7654) AND job=(SELECT job FROM emp WHERE empno=7788); 范例：工资最低的雇员姓名、工资、工作 第1步：求最低的工资 SELECT MIN(sal) FROM emp; 第2步：以最低工资为条件进行下一步查询 SELECT ename,job,sal FROM emp WHERE sal=(SELECT MIN(sal) FROM emp); 范例：要求查询出:部门的名称、部门的员工数、部门的平均工资、部门的最低收入雇员的姓名。 分析：需要两张表关联：dept emp 第1步：如果要想求出每个部门的员工数量及平均工资，则肯定要使用分组统计，按照dept进行分组。 SELECT deptno,COUNT(empno),AVG(sal) FROM emp GROUP BY deptno; 第2步：但是如果要想查出部门的名称，需要与dept表进行关联。 SELECT d.dname,ed.c,ed.a FROM dept d,( SELECT deptno,COUNT(empno) c,AVG(sal) a【a c都是另起的别名】 FROM emp GROUP BY deptno) ed【ed是别名】 WHERE d.deptno=ed.deptno; 第3步;最低收入雇员的姓名 SELECT d.dname,ed.c,ed.a,e.ename FROM dept d,( SELECT deptno,COUNT(empno) c,AVG(sal) a,MIN(sal) min,MAX(sal) max FROM emp GROUP BY deptno) ed,emp e WHERE d.deptno=ed.deptno AND e.sal=ed.min; 如果此时在一个部门之中同时出现两个雇员的工资是最低的，那么这个程序是错误的。 在子查询中存在以下3种操作符号(IN ANY ALL) ： 1.IN操作符指定一个查询的范围 范例：求出每个部门的最低工资的雇员的信息 每个部门的最低工资，返回的工资肯定是多个，所以此时可以使用IN指定一个操作的范围 SELECT * FROM emp WHERE sal IN(SELECT MIN(sal) FROM emp GROUP BY deptno) 2.ANY操作，存在3种情况分别是 >ANY =ANY <ANY   (1)=ANY与IN的功能完全一样    如：SELECT * FROM emp        WHERE sal =ANY(SELECT MIN(sal) FROM emp GROUP BY deptno);   (2)>ANY 比最小的值要大   如：SELECT * FROM emp       WHERE sal>ANY(SELECT MIN(sal) FROM emp GROUP BY deptno);   (3)<ANY 比最大的值要小   如：SELECT * FROM emp        WHERE sal <ANY(SELECT MIN(sal) FROM emp GROUP BY deptno); 3.ALL 操作(分为：>ALL <ALL)   (1)>ALL 比最大的值要大   如：SELECT * FROM emp        WHERE sal >ALL(SELECT MIN(sal) FROM emp GROUP BY deptno);   (2)<ALL 比最小的值要小    如：SELECT * FROM emp        WHERE sal <ALL(SELECT MIN(sal) FROM emp GROUP BY deptno); 对于子查询来讲,还可以进行多列子查询，一个子查询中同时可以返回多个查询的列。 【了解】 SELECT * FROM emp WHERE (sal,NVL(comm,-1)) IN ( SELECT sal,NVL(comm,-1) FROM emp WHERE deptno=20);   第十七章 组函数及分组统计 分组：如将男生分为一组女生分为一组。 如果想求出每一组的平均身高、平均年龄，这就是使用到分组函数。 组函数： 在SQL中常用的组函数有： COUNT()：求出全部的记录数 MAX()：求出一组中的最大值 MIN()：求出一组值中的最小值 AVG()：求出平均值 SUM()：求和 组函数及分组统计 一、组函数 范例：COUNT()函数 select count(empno) from emp; 结果： COUNT(EMPNO) ----------------------           14 范例：MAX() MIN()求最大最小值,一般针对于数字 求所有员工最低工资 select min(sal) from emp; 结果：   MIN(SAL) -------------------        800 求所有员工的最高工资 select max(sal) from emp; 求和及平均值 范例：求20部门中的总工资 SELECT SUM(sal) FROM emp WHERE deptno=20; 求所有员工的平均工资 SELECT AVG(sal) FROM emp; 二、分组统计 要想使用分组统计，首先应该固定其语法，使用GROUP BY 进行分组，此时SQL语法格式如下： SELECT {DISTINCT} *|查询列1 别名1|查询列2 别名2.... FROM 表1 别名1，表2 别名2.... {WHERE条件} {GROUP BY 分组条件} {ORDER BY 排序字段 DESC|ASC,排序字段 DESC|ASC....} 范例：求出每个部门的雇员数量，应该按照部门编号划分，按照deptno分组。 SELECT deptno,COUNT(empno) FROM emp GROUP BY deptno; 结果：      DEPTNO COUNT(EMPNO) --------- -----------------------        30            6        20            5        10            3 求每个部门的平均工资 SELECT deptno,AVG(sal) FROM emp GROUP BY deptno; 要分组时要注意： SELECT COUNT(empno) FROM emp;---->可以 SELECT deptno,COUNT(empno) FROM emp;---->不可以，不是单组分组函数 在查询的时候，以上的代码不能正确的执行是因为： 1.如果程序中使用了分组函数，则有两种可以使用的情况： (1)程序中存在了GROUP BY,并指定了分组条件，这样可以将分组条件一起查询出来。 (2)如果不使用分组的话，则只能单独的使用分组函数。 2.在使用分组函数时，不能出现分组函数和分组条件之外的字段。 SELECT deptno,empno,COUNT(empno)---->empno属于分组以外的字段，这样不可以 FROM emp GROUP BY deptno; 此时提示empno不是GROUP BY的表达式所以无法使用。 范例：按部门分组，并显示部门的名称及部门的员工数。 SELECT d.dname,COUNT(e.empno) FROM emp e,dept d WHERE e.deptno=d.deptno GROUP BY d.dname; 范例：要求写出平均工资大于2000的部门编号和平均工资。 错误的代码： SELECT deptno,AVG(sal) FROM emp WHERE AVG(sal)>2000 GROUP BY deptno; ----------------------->这是不行的，因为在WHERE句中不能使用分组函数（AVG()）。 分组函数只能在分组中使用不能在WHERE中出现。如果现在要指定分组的条件，只能通过第二种条件的指令： HAVING 此时的语法结构为： SELECT {DISTINCT} *|查询列1 别名1|查询列2 别名2.... FROM 表1 别名1，表2 别名2.... {WHERE条件} {GROUP BY 分组条件{HAVING 分组条件}} {ORDER BY 排序字段 DESC|ASC,排序字段 DESC|ASC....} 范例：使用HAVING完成以上的操作 SELECT deptno,AVG(sal) FROM emp GROUP BY deptno HAVING AVG(sal)>2000;---->将以前WHERE中的条件句放在HAVING 范例：显示非销售人员工作名称以及从事同一工作雇员的月工资的总和，并且在满足从事同一工作的雇员月工资合计大于$5000，输出结果按月工资的合计升序排列。 第1步：显示全部的非销售人员：job<>'SALESMAN' SELECT * FROM emp WHERE job<>'SALESMAN';------>SALESMAN一定要大写，因为他在表中的字段值就是大写的 第2步：按工作分组，同时求出工资的总和 SELECT job,SUM(sal) FROM emp WHERE job<>'SALESMAN' GROUP BY job; 第3步：对分组的条件进行限制，工资总和大于5000 SELECT job,SUM(sal) FROM emp WHERE job<>'SALESMAN' GROUP BY job HAVING SUM(sal)>5000; 第4步：工资的合计升序排列 SELECT job,SUM(sal) sum<--别名 FROM emp WHERE job<>'SALESMAN' GROUP BY job HAVING SUM(sal)>5000 ORDER BY sum; 分组的简单原则：只要一列上存在重复的内容才有可能考虑到分组。 注意：分组函数可以嵌套使用，但是在组函数嵌套使用的时候不能再出现分组条件的查询语句。 范例：求出平均工资最高的部门 错误的代码： SELECT deptno,MAX(AVG(sal)) FROM emp GROUP BY deptno;--->出现不是单组分组函数错误 正确的代码： SELECT MAX(AVG(sal))--->去掉deptno FROM emp GROUP BY deptno;                      第十八章 数据库对象-视图 数据库对象之视图 学习目标： 1.掌握视图的作用及定义 2.掌握序列的使用：SEQUENCE 3.掌握PowerDesigner设计工具的使用 4.了解同义词、用户管理、嵌套及可变数组 5.理解数据库的设计范式 一、视图(重点) 视图的功能：一个视图实际上就是封装了一个复杂的子查询。 创建视图的语法： CREATE VIEW 视图名称 AS 子查询  实际上此时的子查询就表示一个非常复杂的语句。 范例： 建立一个视图，此视图包含了全部的20部门的雇员信息(雇员姓名、编号、工作、雇佣日期)。 在创建之们先保证Oracel的OracleServiceMLDN和监听服务开启。 CREATE VIEW empv20 AS SELECT empno,ename,job,hiredate FROM emp WHERE deptno=20; 结果：视图创建完成 视图在创建完成之后，我们就可以像查找表一样直接对视图进行查询操作。 查询视图：SELECT * FROM empv20; 结果：      EMPNO ENAME   JOB      HIREDATE ---------- ---------- --------- ---------------------       7369  SMITH    CLERK     17-12月-80       7566  JONES    MANAGER  02-4月 -81       7788  SCOTT    ANALYST   19-4月 -87       7876  ADAMS   CLERK     23-5月 -87       7902  FORD     ANALYST   03-12月-81 此时是通过视图找到20部门的全部信息，也就是可以发现，可以使用视图包装需要的的查询语句，此时视图只包含了四个字段的信息，如果我们想多增加一个字段的信息。如我们增加一个sal字段。 CREATE VIEW empv20 AS SELECT empno,ename,job,sal,hiredate FROM emp WHERE deptno=20; 结果：名称已由现有对象使用 说明视图是无法重名的。此时只能先删除后重新建立 。 删除视图的语法：DROP VIEW 视图名称 范例：删除empv20视图 DROP VIEW empv20; 删除之后重新执行创建视图的语句： CREATE VIEW empv20 AS SELECT empno,ename,job,sal,hiredate FROM emp WHERE deptno=20; 但是如果所有的操作都是这样操作很麻烦。因为如果要想修改视图必须先删除视图，在Oracel中，为了方便用户修改视图，提供了一个替换的命令，此时完整的视图创建语法： CREATE OR REPLACE VIEW 视图名称 AS 子查询; 作用以上的语法，在更改视图之前就不用再删除重建了。 CREATE OR REPLACE VIEW empv20 AS SELECT empno,ename,job,sal,hiredate FROM emp WHERE deptno=20; 所以视图的作用：可以封装复杂的查询，那么下面封装一个已经存在的复杂查询。 如这是一个复杂的子查询： SELECT d.dname,ed.c,ed.a FROM dept d,( SELECT deptno,COUNT(empno) c,AVG(sal) a FROM emp GROUP BY deptno) ed WHERE d.deptno=ed.deptno; 如果在开发中每次都写如此之长的语句，肯定不方便，因此要将其建立为视图，为了以后方便使用。 如： CREATE OR REPLACE VIEW myempv AS SELECT d.dname,ed.c,ed.a FROM dept d,( SELECT deptno,COUNT(empno) c,AVG(sal) a FROM emp GROUP BY deptno) ed WHERE d.deptno=ed.deptno; 以后直接查询视图就可以得到之前的查询结果：如 SELECT * FROM myempv;这跟之前用子查询的结果是一样的。 范例：创建一个只包含一个20部门的雇员的信息 CREATE OR REPLACE VIEW empv20 AS SELECT * FROM emp WHERE deptno=20; SQL> select * from empv20;      EMPNO ENAME JOB MGR HIREDATE SAL COMM DEPTNO 7369 SMITH CLERK 7902 17-12月-80 800 20 7566 JONES MANAGER 7839 02-4月 -81 2975 20 7788 SCOTT ANALYST 7566 19-4月 -87 3000 20 7876 ADAMS CLERK 7788 23-5月 -87 1100 20 7902 FORD ANALYST 7566 03-12月-81 3000 20 下面进行更新视图的操作，在视图中不应该包含真实数据的，而且在此程序中，创建的视图实际上是存在条件的，此条件是deptno=20,如果现在将视图中的7369的部门编号修改为30.理论上是不允许修改的。 范例：将视图中的7369的部门编号修改为30。 UPDATE empv20 SET deptno=30 WHERE empno=7369;---->结果：已更新一行  SQL> select * from empv20;    EMPNO ENAME      JOB       MGR    HIREDATE          SAL       COMM     DEPTNO ------ ---------- --------- ---------- -------------- ---------- ---------- -------------------------------------------------------------   7566 JONES      MANAGER         7839   02-4月 -81        3421.25                    20   7788 SCOTT      ANALYST         7566   19-4月 -87         3000                      20   7876 ADAMS      CLERK           7788   23-5月 -87         1100                      20   7902 FORD       ANALYST         7566    03-12月-81        3000                      20 已经提示更新，重新查询视图时，但是在重新查看该视图后，已经没有7369这个雇员了。那么emp表中呢? SELECT * FROM emp查看后发现在emp中7369雇员的部门编号成为30了。 SQL> select * from emp;      EMPNO ENAME  JOB              MGR HIREDATE             SAL     COMM   DEPTNO ---------- ---------- --------- ---------- -------------- ---------- ---------- ---------------------------------------------------------       7369 SMITH      CLERK           7902  17-12月-80            800                    30       7499 ALLEN      SALESMAN       7698  20-2月 -81           1600        300        30       7521 WARD       SALESMAN       7698  22-2月 -81           1250        500        30       7566 JONES      MANAGER        7839  02-4月 -81           2975                   20       ................部分已省略 这样明显不合适，因为在创建视图的时候是有条件的。一但修改之后此条件就破坏了，所以在创建视图时，SQL中提供了两个重要的参数： (1)WITH CHECK OPTION:不能更新视图的创建条件 范例：在视图创建中使用此参数  CREATE OR REPLACE VIEW empv20 AS SELECT * FROM emp WHERE deptno=20 WITH CHECK OPTION;---->参数 结果：视图已创建 然后再更新操作：将视图中的7369的部门编号修改为30 UPDATE empv20 SET deptno=30 WHERE empno=7369;----->视图 WITH CHECK OPTIDN where 子句违规 说明创建条件再更改，那么其它字段呢，现在将7369的雇员姓名修改为“hellen” 范例：修改7369雇员的姓名 UPDATE empv20 SET ename='hellen' WHERE empno=7566;----->已更新一行 SQL> select * from emp;      EMPNO ENAME      JOB       MGR    IREDATE              SAL       COMM     DEPTNO ------ ---------- --------- ---------- -------------- ---------- ---------- --------------------------------------------------------------------------       7369 SMITH      CLERK          7902  17-12月-80            800                    30       7499 ALLEN      SALESMAN      7698  20-2月 -81           1600        300         30       7521 WARD       SALESMAN      7698  22-2月 -81           1250        500         30       7566 hellen     MANAGER          7839  02-4月 -81            2975                    20--已改       7654 MARTIN     SALESMAN      7698  28-9月 -81           1250        1400         30       ...............部分已省略 但是，视图的本身作用还是用来查询的，所以不应该允许更改，所以此时可以使用第二个参数 (2)WITH READ ONLY：创建视图只读 那现在创建视图： CREATE OR REPLACE VIEW empv20 AS SELECT * FROM emp WHERE deptno=20 WITH READ ONLY;---->参数 然后进行同样的改动，更新雇员姓名： UPDATE empv20 SET ename='hellen' WHERE empno=7566;---->此处不允许虚拟列 视图无法更改，是只读的操作。   第十九章 数据库对象-序列 数据库对象之序列 序列（重点） 在很多数据库系统中存在一个自动增长的列，如果现在要想在Oracle中完成自动增长的功能，则只能依靠序列完成，所有的自动增长操作，需要用户手工完成处理。 序列的创建格式： CREATE SEQUENCE sequence [INCREMENT BY n][START WITH n]---->增长的步长 从几开始 [{MAXVALUE n|NOMAXVALUE}]------>最大值是多少，没有最大值 [{MINVALUE n|NOMINVALUE}]------>最小值 [{CYCLE|NOCYCLE}]--------------->是否循环 [{CACHE n|NOCACHE}]----------->是否缓存 范例：创建一个mysep的序列，验证自动增长的操作。 CREATE SEQUENCE myseq;--->序列已创建 序列创建完成之后，所有的自动增长应该由用户自己处理，所以在序列中提供了以下两种操作， (1)vextVal：取得序列的下一个内容 (2)currVal：取得序列的当前内容 范例：建立一张表以验证序列的操作 CREATE TABLE testseq(  next NUMBER,  curr NUMBER )------------->表已创建 向表中添加数据，添加数据的时候，需要手工的使用序列。 范例：使用序列 INSERT INTO testseq(next,curr) VALUES (myseq.nextval,myseq.currval);--->已创建一行 将以上的语句执行5次： INSERT INTO testseq(next,curr) VALUES (myseq.nextval,myseq.currval); ...... INSERT INTO testseq(next,curr) VALUES (myseq.nextval,myseq.currval); ...... 范例：查询myseq表，观察序列的变化       NEXT       CURR ---------- -------------------          1          1          2          2          3          3          4          4          5          5 从结果中可以发现，nextval始终在进行自动增长的操作，而currval使用取出当前操作的序列结果。 也就是说现在的这种序列，每次增长的幅度的是1，那么也可以修改序列的增长幅度。 可以用以下的一个参数：     第次增长的幅度：INCREMENT BY 长度 范例：重新建立序列  先删除序列 ：DROP SEQUENCE myseq; 重新创建序列：CREATE SEQUENCE myseq INCREMENT BY 2;--->序列已创建 创建之后来进行一个测试，为了能说明问题，将testseq表从新创建，创建完成之后，重新进行数据插入操作。 插入5次数据。 其结果为： SQL> select * from testseq;       NEXT       CURR ---------- ----------------          1          1          3          3          5          5          7          7          9          9------->每次增长的幅度是2 默认情况下序列是从1开始的，可以通过START WITH 来指定开始的位置。 DROP SEQUENCE myseq; CREATE SEQUENCE myseq INCREMENT BY 2 START WITH 10; 序列开始的位置是10;再次进行插入操作（5次） 其结果为： SQL> select * from  testseq;       NEXT       CURR ---------- ---------------          1          1          3          3          5          5          7          7          9          9         10         10         12         12         14         14         16         16         18         18 重新创建一个序列，让其序列固定在1 3 5 7 9 循环序列 CREATE SEQUENCE myseq  MAXVALUE 10 START WITH 1 INCREMENT BY 2  CACHE 2 CYCLE; 重新建立testseq表，插入数据。 其结果为： SQL> select * from testseq;       NEXT       CURR ---------- ----------          1          1          3          3          5          5          7          7          9          9          1          1 现在序列的内容是循环的，但是从实际来看序列使用最多的语法是：CREATE SEQUENCE 序列名;   第二十章 数据库对象-同义词  数据库对象之同义词 同义词（了解） 什么是同义词 同义词是数据库的一个对象。 数据库的对象包括：同义词、序列、视图、索引。 之前一直存在这样的查询语句： SELECT SYSDATE FROM dual; SQL> SELECT SYSDATE FROM dual; SYSDATE -------------- 12-11月-10 那么dual到底是什么东西？dual是一张虚拟表，他虽然是虚拟表，可是此表到底是在那里定义的呢？如果现在使用SYSTEM连接数据库，查询此张表是否属于SYSTEM用户，则找不到，但是在SYS用户下可以找到。 conn sys/system as sysdba; SQL> SELECT * FROM tab WHERE TNAME='DUAL'; TNAME                    TABTYPE  CLUSTERID ------------------------------ ------- ---------- DUAL                           TABLE 很奇怪dual表是在SYS帐户下的，但是我们在SCOTT帐户下就可以访问，正常的访问应该是 用户.表名。 如： conn sys/system as sysdba; select * from scott.emp; 此时实际上就是同义词的作用了。同义词可以让其它用户通过一个名称方便的访问“用户名.表名称” 如：select * from dual 代替了 select * from scott.emp; 1.创建同义词的语法：CREATE SYNONYM 同义词名称 FOR 用户名.表名称 范例：将scott.emp定义emp的同义词 CREATE SYNONYM emp FOR scott.emp; 原来在SYS帐户下不能看emp表的内容，因为emp表就不是SYS帐户下的，那么创建了同义词之后就可以了。 show user  select * from emp; 2.创建同义词 DROP SYNONYM 同义词名称; 如：drop synonym emp; 现在在SYS帐户下就不能查看emp表了。 注：这种特性只适合于Oracel数据库。 所以： 同义词是现有对象的一个别名。 一、他的作用是： 1.简化SQL语句 2.隐藏对象的名称和所有者 3.提供对对象的公共访问 二、同义词共有两种类型：私有同义词 公有同义词 1.私有同义词只能在其模式内访问，且不能与当前模式的对象同名。（这里的模式可以理解为帐户） 2.创建一个私有的同义词：CREATE SYNONYM emp FOR SCOTT.emp;（所以默认私有） 3.创建一个公有的同义词：CREATE PUBLIC SYNONYM emp_syn FOR SCOTT.emp;   在创建公有同义词时，赋于其权限：grant all on 公有同义词 to 用户 三、创建或替换现有的同义词：     CREATE OR REPLACE SYNONYM emp_syn FOR SCOTT.emp; 四、删除同义词：     SQL> DROP SYNONYM emp;      SQL> DROP PUBLIC SYNONYM emp_syn;        第二十一章 数据库对象-索引 数据库对象之索引 索引的作用：最主要的目的是提高查询速度和性能的。所有索引都基于了一种技术B-Tree(二叉树)。 索引对表说来相当于一个目录的作用，索引是占空间的。 ● 索引是与表相关的一个可选结构 1.用以提高 SQL 语句执行的性能 2.减少磁盘I/O 3.使用 CREATE INDEX 语句创建索引 4.在逻辑上和物理上都独立于表的数据 Oracle 自动维护索引 ● 索引有各种类型，除了标准索引外，还有一些特殊类型的索引：唯一索引、位图索引、组合索引、基于函数的索引、反向键索引。 ● 创建标准索引： SQL> CREATE INDEX item_index ON itemfile (itemcode)--表（列）      TABLESPACE index_tbs; 创建以后，如果我们在itemcode列上进行查询时，会自动启用。 范例：在emp表的empno列上创建一个索引 CREATE INDEX a ON emp(empno); 重建索引： SQL> ALTER INDEX item_index REBUILD;  删除索引： SQL> DROP INDEX item_index;  ● 唯一索引 唯一索引确保在定义索引的列中没有重复值 Oracle 自动在表的主键列上创建唯一索引。如果在表中的某一列创建一个唯一索引，他里边的值是不能得复的，我们在创建主键时会自动创建一个唯一索引。所以表中如果有主键了，就不用去创建唯一索引了。 使用CREATE UNIQUE INDEX语句创建唯一索引： SQL> CREATE UNIQUE INDEX item_index      ON itemfile (itemcode); ● 组合索引 组合索引是在表的多个列上创建的索引。就像我们在创建主键时，可以多列的进行创建。 索引中列的顺序是任意的。 如果 SQL 语句的 WHERE 子句中引用了组合索引的所有列或大多数列，则可以提高检索速度 SQL> CREATE INDEX comp_index      ON itemfile(p_category, itemrate); ● 反向键索引 反向键索引反转索引列键值的每个字节 通常建立在值是连续增长的列上，使数据均匀地分布在整个索引上 创建索引时使用REVERSE关键字 SQL> CREATE INDEX rev_index       ON itemfile (itemcode) REVERSE; 如： 1002--->2001 1003--->3001 主要减少叉的密度，将其打散 将个反射键索引恢复成正常索引：注：但是普通索引是不能变成反向键索引的  SQL> ALTER INDEX rev_index REBUID NOREVERSE; ● 位图索引： 位图索引适合创建在低基数列上 位图索引不直接存储ROWID，而是存储字节位到ROWID的映射 减少响应时间 节省空间占用 Oracle位图索引主要是应用在数据仓库方面,其目的是查询效率更高,占用更小的索引空间,使用存储更有效,位图索引使用压缩形式存储 SQL> CREATE BITMAP INDEX bit_index      ON order_master (orderno); 使用位图索引的注意事项： 如果要使用位图索引，初始化参数STAR_TRANSFORMATION_ENABLED应该设置为TRUE.(alter system set STAR_TRANSFORMATION_ENABLED= true;) 优化模式应该是CBO。对于数据仓库的环境中，总是应该考虑使用CBO(COST-BASEDOPTIMIZER)。 位图索引应该建立在每一个事实表的外键列上。(这只是一个一般的规则.) 在OLTP上有更新的表不建议使用位图索引 位图索引适用在低基数列上(大量重复数据) ● 索引的创建原则 在经常做为条件的字段上创建索引 一个表允许创建几百个索引,通常我们都不会这样做,因为索引提高了查询效率,同时也给INSERT/UPDATE/DELETE的效率带来了影响,因为需要重新组织索引。 如果某几个字段经常一起出来做为条件,则创建多列索引(组合索引)。 使用以上的索引都是为了提高查询速度的，大数据库量才使用索引，创建索引以后不要进行频繁更新。 ● 聚簇索引  聚簇是根据码值找到数据的物理存储位置，从而达到快速检索数据的目的。Oracle聚簇索引的顺序就是数据的物理存储顺序，叶节点就是数据节点。非聚簇索 引的顺序与数据物理排列顺序无关，叶节点仍然是索引节点，只不过有一个指针指向对应的数据块。 注意：一个表最多只能有一个聚簇索引。  BTREE索引–聚簇 聚簇索引一般用于表的联接字段,比如,部门表的部门编号与员工表的所属部门, 创建聚簇索引要先创建聚簇,然后把表的字段放置到簇中 创建聚簇 CREATE CLUSTER clusterName(column Type) [OTHER OPTIONS] 添加簇中的字段 CREATE TABLE(col type,,FOREIGNKEY (deptno),,,) CLUSTER clusterName(column); 向部门表插入数据之前,需要先创建聚簇索引 CREATE INDEX indexName ON CLUSTER clusterName Oracle聚簇索引保证两个表的记录按照deptno值尽量存放到同一个物理块当中。 ORACLE中的聚簇表是指两个表有一个字段完全相同，并且在业务中经常会按这个字段为目标连接这两个表，这时建立聚簇表，两个表公用一个字段，能减少占用空间，并能明显提高连接查询速度。 范例： 创建一个簇：CREATE CLUSTER clsdept(deptno varchar2(10)); 创建一个簇表： create table departments(deptno varchar2(10),deptname varchar2(12)) CLUSTER clus(deptno); 再创建一个： create table employees(deptno varchar2(10),empNo char(3),empName varchar(12)) CLUSTER clus(deptno); 当多个表总是基于一个字段一起查时，用到簇比较合适。 ● 索引组织表  索引组织表的数据存储在与其关联的索引中 索引中存储的是行的实际数据，而不是ROWID 基于主键访问数据 CREATE TABLE 命令与 ORGANIZATION INDEX 子句一起用于创建索引组织表 SQL> CREATE TABLE ind_org_tab (        vencode NUMBER(4) PRIMARY KEY,        venname VARCHAR2(20)      )       ORGANIZATION INDEX; 普通表与索引组织表的比较： ---------------------------------------------------------------- 普通表                索引组织表 ---------------------------------------------------------------- ROWID 唯一地标识行 主键唯一地标识行 隐式的 ROWID 列       没有隐式的 ROWID 列 基于 ROWID 的访问       基于主键的访问 顺序扫描返回所有行 完全索引扫描返回所有行，并按主键顺序排列 支持分区             不支持分区 ---------------------------------------------------------------- ● 基于函数的索引 基于一个或多个列上的函数或表达式创建的索引 表达式中不能出现聚合函数 不能在LOB类型的列上创建 创建时必须具有 QUERY REWRITE 权限 SQL> CREATE INDEX lowercase_idx       ON toys (LOWER(toyname)); SQL> SELECT toyid FROM toys      WHERE LOWER(toyname)='doll'; ● 获取索引的信息 与索引有关的数据字典视图有： USER_INDEXES － 用户创建的索引的信息 USER_IND_COLUMNS － 与索引相关的表列的信息 SQL> SELECT INDEX_NAME, TABLE_NAME, COLUMN_NAME      FROM USER_IND_COLUMNS      ORDER BY INDEX_NAME, COLUMN_POSITION; ● 使用索引 当索引被创建之后Oracle的查询会自动使用索引,对于用户来讲是透明的 以下情况索引无效: 使用<>比较时,索引无效,建议使用< or > 使用前置模糊匹配%时无效 使用函数 使用不匹的数据类型 ● 数据库对象总结： 同义词是现有数据库对象的别名 序列用于生成唯一、连续的序号 视图是基于一个或多个表的虚拟表 索引是与表相关的一个可选结构，用于提高 SQL 语句执行的性能 索引类型有标准索引、唯一索引、反向键索引、位图索引和基于函数的索引 索引组织表基于主键访问数据   第二十二章 网络配置 Oracle网络配置 如果其它的服务齐全，我们可以后添加一个监听。 服务器端监听器配置信息包括监听协议、地址及其他相关信息。 配置信息保存在名为listener.ora的文件中。在安装服务器软件时自动配置一个监听器 客户端的网络服务名配置信息包括服务器地址、监听端口号和数据库SID等，与服务器的监听器建立连接。配置信息保存在名为tnsnames.ora的文件中 Oracle中的 Net Configuration Assistant和Net Manager工具都能用来配置监听器和网络服务名 ● Oracle查询工具 Oracle 提供的工具非常容易使用。Oracle 的查询工具包括：SQL*Plus、iSQL*Plus、PL/SQL PL/SQL 是 SQL 的扩展。PL/SQL 结合了SQL语言的数据操纵能力和过程语言的流程控制能力 ● Oracle 默认用户 只有用合法的用户帐号才能访问Oracle数据库 Oracle 有几个默认的数据库用户：SYS SYSTEM SCOTT SCOTT用户是Oracle 数据库的一个示范帐户，在数据库安装时创建 ● 更改和删除用户 ALTER USER 命令可用于更改口令  修改 MARTIN 用户的密码:ALTER USER MARTIN IDENTIFIED BY martinpass; DROP USER 命令用于删除用户  删除 MARTIN 用户模式:DROP USER MARTIN CASCADE;  ● Windows 中的 Oracle 服务 OracleHOME_NAMETNSListener 该服务启动数据库服务器的监听器，监听器接受来自客户端应用程序的连接请求 若监听器未启动，则客户端将无法连接到数据库服务器 OracleServiceSID 该服务启动系统标识符为SID的数据库实例，其中 SID 是在安装 Oracle 9i 时输入的数据库名称 第二十三章 嵌套表、可变数组  一、嵌套表(了解) 嵌套表：在一个表中嵌套另外一个子表 例如：现在有如下一种情况，一个部门可能承接多个项目，如果此时按照原来的方法高设计，需定义两张表， department表和project表。 CREATE TABLE department( deptno NUMBER(2) PRIMARY KEY NOT NULL, dname   VARCHAR2(50) NOT NULL ) CREATE TABLE project( proid NUMBER(4) PRIMARY KEY NOT NULL, proname VARCHAR2(50) NOT NULL, prodate DATE NOT NULL, deptno NUMBER(2) CONTRAINT department_project_deptno_fk FOREIGN KEY(deptno) NO DELETE CASCADE ) 以上操作是最通用的操作，而且本身也是属于最正确的操作，但是是在Oracle引入了嵌套表的概念，可以直接将项目表的类型作为一个department表的字段类型，达到嵌套的功能。 但是如果想完成一个嵌套表的制作，则首先要保证一点：因为数据库在创建表的时候要指定字段的类型，所在嵌套表本身也需要同样指定类型，那么这种类型就需要单独定义。 CREATE TYPE project_ty AS OBJECT(--------->创建一个类型 proid NUMBER(4), proname VARCHAR2(50), prodate DATE  ); / 知识点：show errors.可以查看错误 类型创建成功以后并不意味着此类型可以直接使用，因为此类型是一个完整的类型，所以要为此类型指定一个名称。 CREATE TYPE project_nt AS TABLE OF project_ty; / 以上操作表示以后直接使用project_nt表示project_ty类型，就类似于VARCHAR(2)表示字符串是一样的。此时可以利用此类型创建department表。 CREATE TABLE department( deptno NUMBER(2) PRIMARY KEY, dname   VARCHAR2(50) NOT NULL, projects project_nt ) NESTED TABLE projects STORE AS project_nt_tab_temp; 对于插入数据来讲，需要需要指定每一个project_ty的类型。 INSERT INTO department(deptno,dname,projects) VALUES(1,'技术部',     project_nt(             project_ty(0001,'CRM',SYSDATE),//CRM为项目     project_ty(0002,'ERP',SYSDATE),//ERP为项目     project_ty(0003,'OA',SYSDATE)//OA为项目     ) ); 此时查询嵌套表，可以返回多个项目。 SQL> select * from department;     DEPTNO DNAME ---------- -------------------------------------------------- PROJECTS(PROID, PRONAME, PRODATE) ------------------------------------------------------------------------------------------------          1 技术部 PROJECT_NT(PROJECT_TY(1, 'CRM', '21-11月-10'), PROJECT_TY(2, 'ERP', '21-11月-10'), PROJECT_TY(3, 'OA 如果此时需要查询一个部门的全部项目的话，则需要查询嵌套表。 SQL> SELECT * FROM TABLE(SELECT projectS FROM department WHERE deptno=1);      PROID PRONAME                    PRODATE ---------- -------------------------------------------------- --------------        1   CRM                          21-11月-10        2   ERP                           21-11月-10        3   OA                            21-11月-10 可见将一个部门中的统一的全部项目查询出来了。 范例：更新项目编号为1的项目名称，将此名称的项目更新为“JAVA” SQL> UPDATE  TABLE (SELECT projectS FROM department WHERE deptno=1) pro   2  SET VALUE(pro)=project_ty('1','JAVA',TO_DATE('1988_10_1','yyyy-mm-dd'))   3  WHERE pro.proid=1; 已更新 1 行。 再次查询： SQL> SELECT * FROM TABLE(SELECT projectS FROM department WHERE deptno=1);      PROID PRONAME                    PRODATE ---------- -------------------------------------------------- --------------          1 JAVA                           01-10月-88          2 ERP                            21-11月-10          3 OA                             21-11月-10 二、可变数组(了解) 可变数组就是嵌套表的升级版，在可变数组中，实际上就是将内部的嵌套表的内容的长度进行了限制。 例如： 1.在一个部门有多个工人，如果按照可变数组的做法，肯定首先要做出一个工人的类型。 SQL> CREATE TYPE worker_info AS OBJECT(   2     id NUMBER,   3     name VARCHAR2(50),   4     sex  VARCHAR2(6)   5  )   6  / 类型已创建。 2.面再定义数组类型：worker_info_list SQL> CREATE TYPE  AS VARRAY(10) OF worker_info;   2  / 类型已创建。 3.定义部门表，一个部门可能存在多个工人 SQL> CREATE TABLE department(   2    deptno NUMBER(2) PRIMARY KEY,   3    dname   VARCHAR2(50) NOT NULL,   4    workers  worker_info_list   5  ); 表已创建。 4.插入测试数据 SQL> INSERT INTO department(deptno,dname,workers) VALUES(10,'财务部',   2 worker_info_list(   3 worker_info(1,'李小龙','男'),   4 worker_info(2,'张三','男'),   5 worker_info(3,'李君','女')   6      )   7  );   查询：   SQL> select * from department;     DEPTNO DNAME ---------- -------------------------------------------------- WORKERS(ID, NAME, SEX) ----------------------------------------------------------         10 财务部 WORKER_INFO_LIST(WORKER_INFO(1, '李小龙', '男'), WORKER_INFO(2, '张三', '男'), WORKER_INFO(3, '李君' 第一章 PL/SQL 简介 PL/SQL课程内容： PL/SQL程序设计简介 PL/SQL块结构和组成元素 PL/SQL流程控制语句 -------------------------------------以上是基础，以下是高级对象 PL/SQL游标的使用-----------子程序 PL/SQL存储过程和函数-------子程序 PL/SQL包的创建和应用 PL/SQL触发器 本章目标： 理解 PL/SQL 功能和特点、了解数据类型及其用法、理解逻辑比较、理解控制结构、掌握错误处理 1.PL/SQL 是过程语言(Procedural Language)与结构化查询语言(SQL)结合而成的编程语言，所以说QL/SQL语言是由两种语言结合下来的。他俩合到一起为目的是为了对SQL的扩展来达到功能更复杂的一些操作。 2.PL/SQL 是对 SQL 的扩展。过程化语言比如说循环、条件都是属于过程化语言其中的一部分，如插值的时候有一万条，必须得一条一条的插，比较慢，如果我们借助循环可能就非常快的完成了操作。 3.PL/SQL支持多种数据类型，如大对象和集合类型，可使用条件和循环等控制结构 4.可用于创建一些高级对象如存储过程、触发器和程序包，给SQL语句的执行添加程序逻辑。比如什么时候插值，什么时候修改，可以有条件来限定了。如给一个班级的每个人都提10分，就可以用循环为完成操作。 5.PL/SQL与 Oracle 服务器和 Oracle 工具紧密集成，具备可移植性、灵活性和安全性。 二、PL/SQL 的优点  1.支持 SQL，在 PL/SQL 中可以使用：数据操纵命令、事务控制命令、游标控制、SQL 函数和 SQL 运算符。 2.支持面向对象编程 (OOP)  3.可移植性，可运行在任何操作系统和平台上的Oralce 数据库。也就是说我们所写的PL/SQL代码包括触发器、储存过程包等写完之后可以放到任何操作系统平台上运行，这就是可移植性。 4.更佳的性能，PL/SQL 经过编译执行。如我们在使用SQL的时候我们要把在客户端写的发送到服务器端编译执行，然后返回给客户端一个请求结果，语句得逐个一条一条的进行编译，如果写了100条得一条一条的发，服务器一条一条的响应，那么每一次再请求的时候，他都会占带宽，在C/S底层要有一个网络传输。而PL/SQL中经过编译执行的。如我们创建一个储存过程里边有100条语句，在创建它时，编译了一次，等到下次有100个人或者是1000个人只需调用一次就可以了。所以这一点就可以节约带宽，减少了网络流通量。 运行过程： 客户写的程序，如SQL语句、其它的一些储存过程、或者是自己写的一个过程语句，客户缩写完之后，它发送给 Oracle服务器，用户将整个语句，不管是用什么写的，一次都交给服务器。那么服务器做何处理呢？他是一个整合的。也就PL/SQL和SQL是合成的。合成这后，在Oracle数据库中专门有一个处理他俩的引擎，叫做PL/SQL引擎，当发到服务器的时候，服务器有两个引擎，一个是SQL引擎，一个是PL/SQL引擎，所以引擎就是一个处理代码的服务器，服务器会将不同的代码发给不同的引擎，当处理完之后，会给服务器一个集中，将结果返回给客户端。这是整个过程。 还有一个优点是在语法上： 1.与 SQL 紧密集成，简化数据处理。 2.支持所有 SQL 数据类型 3..支持 NULL 值 4.支持 %TYPE 和 %ROWTYPE 属性类型 5.安全性，可以通过存储过程限制用户对数据的访问。如我们写了一个存储过程，这里边可能存了N个表，只给一个权限，其别人访问这个存储过程，别人只操作其中赋于的几个值就可以，至于里边操作的是那一个表，对那个表执行了什么操作，不必知道 。 6.PL/SQL 引擎驻留在 Oracle 服务器中。也就是在Oracle中有专门处理PL/SQL语句的引擎。该引擎接受PL/SQL块并对其进行编译执行。用户发出请求时候是一个合成，有SQL的有PL/SQL的。那么放到服务器接受他的时候会对其进行分类筛选。PL/SQL引擎的功能主要是完成过程语句的执行， SQL引擎主要是执行SQL语句，他俩都是驻留在Oracle服务器端的。 他的执行完之后，Oracle服务器把结果合成之后，返回给客户端。 7.PL/SQL 块是构成 PL/SQL 程序的基本单元。将逻辑上相关的声明和语句组合在一起   PL/SQL 分为三个部分，声明部分、可执行部分和异常处理部分    [DECLARE------------声明（在Oracel中的所有变量必须先声明后作用）      declarations]     BEGIN     executable statements ----------------------------------------可执行部分     [EXCEPTION ---------异常处理部分     handlers]     END; 在整个PL/SQL块中声明部分和异常部分是可选的。可执行部分是必须的。 例： DECLARE---声明   qty_on_hand NUMBER(5);----注：先是变量名，后是类型 注：分号 --------------------------------------------------上：声明部分 --------------------------------------------------下：主体部分(包括可执行部分和异常部分)                                                                       BEGIN   SELECT quantity INTO qty_on_hand                                         FROM Products   WHERE product = '芭比娃娃'                                               FOR UPDATE OF quantity;                                          IF qty_on_hand > 0 THEN                                            UPDATE Products SET quantity = quantity + 1                                            WHERE product = '芭比娃娃';                                            INSERT INTO purchase_record                                            VALUES ('已购买芭比娃娃', SYSDATE);                                          END IF;   COMMIT;                                        ----------------------------------------上：可执行部分 ----------------------------------------下：异常部分                                        EXCEPTION  /* 异常处理语句 */                                          WHEN OTHERS THEN                                            DBMS_OUTPUT.PUT_LINE('出错:'|| SQLERRM);                                          END; ----------------------------------------------------------- 在声明部分定义变量、游标、自定义常量 可执行部分包含SQL语句和PL/SQL语句。 三、变量与常量 PL/SQL 块中可以使用变量和常量 在声明部分声明，使用前必须先声明 声明时必须指定数据类型，每行声明一个标识符 在可执行部分的 SQL 语句和过程语句中使用 声明变量和常量的语法： identifier [CONSTANT] datatype [NOT NULL]    [:= | DEFAULT expr]; 给变量赋值有两种方法： 使用赋值语句 := 使用 SELECT INTO 语句（基于查询得到的值） 如： DECLARE   icode VARCHAR2(6);---变量   p_catg VARCHAR2(20);   p_rate NUMBER;   c_rate CONSTANT NUMBER := 0.10;--常量  BEGIN   ...   icode := 'i205';---第一种赋值   SELECT p_category, itemrate * c_rate---第二种赋值   INTO  p_catg, p_rate   FROM itemfile WHERE itemcode = icode;   ... END; 范例：第1种赋值 SQL> declare   2  v_test number:=90;   3  begin   4  DBMS_OUTPUT.PUT_LINE(v_test);   5  end;   6  / PL/SQL 过程已成功完成。 SQL> set serverout on;---打开会话命令 SQL> / 90----结果 PL/SQL 过程已成功完成。 第2种赋值：将表中某个员工的工资赋值给一个变量 SQL> declare   2  v_sal number;   3  begin   4  select sal into v_sal from emp where empno=7499;   5  DBMS_OUTPUT.PUT_LINE('员工工资为：'||v_sal);   6  end;   7  / 员工工资为：1600 PL/SQL 过程已成功完成。   第二章 PL/SQL数据类型  PL/SQL 支持的内置数据类型 数据类型：标量类型、 LOB类型 、属性类型 标量类型：数字类型、字符类型、布尔类型、日期类型 一、数字类型 LOB类型：BFILE(从Oracle中向系统中存二进制文件)   BLOB(二进制数据)   CLOB(大的字符)   NCLOB 属性类型： %TYPE :提供某个变量或数据库表列的数据类型 %ROWTYPE:提供表示表中一行的记录类型 NUMBER类型：BINARY_INTEGER、NUMBER、PLS_INTEGER 1.BINARY_INTEGER(-231-231) 子类型: 1.Natural(0-231)（非负及null） 2.Positive(1-231)(正数和null) 3.NaturalN(非空及非负) 4.positiveN(正数和非null) 5.signtype (要将整型变量限制为值-1,0,1) 1,2,3,4用于防止将空值赋予整型变量。 2.Number(1E-130~~ 10E125) Number子类型： 子类型：DEC 、DECIMAL 、NUMERIC 用于声明最高精度为３８位十进制数字的定点数。定点数的精确度要比浮点数的精确度高。因为定点数是以十进制算的。如果我们保存货币一类的尽量用定点数。 子类型：DOUBLE、 PRECISION 和FLOAT用于声明最高精度为126个二进制位（大约相当于38位十进制数字）浮点数. 子类型：real:用于声明最高精度为63个二进制位（大约相当于１８位十进制数字）浮点数。 子类型：INTEGER、ＩＮＴ、SMALLINT用于声明最高精度为３８位十进制数字的整数。 3.PLS_INTEGER:（-231~~231） 此数据类型用于存储带符号的整数。 特点：它比以上两种数据类型的执行速度更快。PLS_INTEGER运算以机机器运算为基础。而NUMBER和BINARY_INTEGER运算以库算术运算为基础。比ＮUMBER需要的存储空间小。 二、字符类型 字符数据类型包括：CHAR、VARCHAR2、LONG、RAW、LONG RAW PL/SQL 的数据类型与 SQL数据类型的比较： 数据类型 SQL类型 PL/SQL类型 CHAR 1..2000 1..32767 LONG 1..2GB 1..32760 LONG RAW 1..2GB 1..32760 RAW 1..2000 1..32767 VARCHAR2 1..4000 1..32767 从上可以看出同一类型可以出现放不下的可能，所有用的时候有注意。 三、日期类型 日期时间类型 存储日期和时间数据 常用的两种日期时间类型 DATE TIMESTAMP 四、布尔类型(在SQL中没有而在PL/SQL中存在) 此类别只有一种类型，即BOOLEAN类型，用于存储逻辑值(TRUE、FALSE和NULL)。 需要注意的是：1.不能向数据库中插入BOOLEAN数据  2.不能将列值保存到BOOLEAN变量中 3.只能对BOOLEAN变量执行逻辑操作 五、LOB数据类型(大对象数据类型) 大对象数据类型主要用于存储大文本、图像、视频剪辑和声音剪辑等非结构化数据。 LOB 数据类型可存储最大4GB的数据。 LOB 类型包括： BLOB   将大型二进制对象存储在数据库中 CLOB   将大型字符数据存储在数据库中 NCLOB  存储大型UNICODE字符数据 BFILE  将大型二进制对象存储在操作系统文件中 六、属性类型 用于引用数据库列的数据类型，以及表示表中一行的记录类型 属性类型有两种： %TYPE  -  引用变量和数据库列的数据类型，数据库中是什么类型，它会自动匹配，不用指定类型 %ROWTYPE  -  提供表示表中一行的记录类型 范例一： SQL> declare   2  v_ename emp.ename%type;   3  v_empno emp.empno%type;   4  begin   5  select empno,ename into v_empno,v_ename from emp--赋值   6  where empno=7499;   7  DBMS_OUTPUT.PUT_LINE('员工号为:'||v_empno||'员工名为:'||v_ename);   8  end;   9  / 员工号为:7499员工名为:ALLEN PL/SQL 过程已成功完成。 范例二 SQL> declare   2  v_rec_emp emp%rowtype;   3  begin   4  select empno,ename into v_rec_emp.empno,v_rec_emp.ename from emp   5  where empno=7499;   6  DBMS_OUTPUT.PUT_LINE('员工号为:'||v_rec_emp.empno||'员工名为:'||v_rec_emp.ename);   7  end;   8  / 员工号为:7499员工名为:ALLEN PL/SQL 过程已成功完成。 好处：不光写方便，而且当数据表的结构发生变化时，不用改动PL/SQL代码。 使用属性类型的优点： 不需要知道被引用的表列的具体类型 如果被引用对象的数据类型发生改变，PL/SQL 变量的数据类型也随之改变 以上都是Oracle自带的记录类型，自己也可以创建记录类型。类似于JAVA中的结构可以自己定义。 记录类型是把逻辑相关的数据作为一个单元存储起来，它必须包括至少一个标量型或RECORD 数据类型的成员，称作PL/SQL RECORD 的域(FIELD)，其作用是存放互不相同但逻辑相关的信息。 定义记录类型语法如下: TYPE record_type IS RECORD(    Field1 type1  [NOT NULL]  [:= exp1 ],    Field2 type2  [NOT NULL]  [:= exp2 ],    . . .   . . .    Fieldn typen  [NOT NULL]  [:= expn ] ) ;  范例： SQL> declare----声明一个记录类型rec_emp   2  type rec_emp is record   3  (   4  v_sal emp.sal%type,   5  v_empno emp.empno%type,   6  v_ename emp.ename%type);   7  v_emp rec_emp;---声明一个记录类型的变量v_emp   8  begin   9  select sal,empno,ename into v_emp from emp  10  where empno=7499;  11 DBMS_OUTPUT.PUT_LINE('员工信息为：'||v_emp.v_sal||v_emp.v_empno||v_emp.v_ename);  12  end;  13  / 员工信息为：16007499ALLEN PL/SQL 过程已成功完成。 七、逻辑比较 逻辑比较用于比较变量和常量的值，这些表达式称为布尔表达式 布尔表达式由关系运算符与变量或常量组成 布尔表达式的结果为TRUE、FALSE或NULL，通常由逻辑运算符AND、OR和NOT连接 布尔表达式有三种类型：数字布尔型、字符布尔型、日期布尔型 ----------------------------------------------------------------------------------------- 关系运算符S                  说明 -----------------------------------------------------------------------------------------     =       比较两个变量是否相等，如果值相当，则返回 True   <>, !=     比较两个变量，如果不相等，则返回 True     <       比较两个变量，检查值 1 是否小于值 2     >       比较两个变量，检查值 1 是否大于 值 2     <=      比较两个变量，检查变量 1 是否小于等于变量 2     >=      比较两个变量，检查变量 1 是否大于等于变量 2 ------------------------------------------------------------------------------------------ 八、PL/SQL可用的SQL语句 PL/SQL是ORACLE系统的核心语言，现在ORACLE的许多部件都是由PL/SQL写成。在PL/SQL中可以使用的SQL语： INSERT，UPDATE，DELETE，SELECT INTO，COMMIT，ROLLBACK，SAVEPOINT。 注意：在 PL/SQL中只能用 SQL语句中的 DML 部分，不能用 DDL 部分，如果要在PL/SQL中使用DDL(如CREATE  table  等)的话，只能以动态的方式来使用。 九、标识符 PL/SQL程序设计中的标识符定义与SQL 的标识符定义的要求相同。要求和限制有： 标识符名不能超过30字符； 第一个字符必须为字母； 不分大小写； 不能用’-‘(减号); 不能是SQL保留字。 注意:  一般不要把变量名声明与表中字段名完全一样,如果这样可能得到不正确的结果. 十、PL/SQL程序变量命名   第三章 LP/SQL控制语句 控制结构 PL/SQL 支持的流程控制结构： 条件控制:   IF 语句   CASE 语句 循环控制:   LOOP 循环   WHILE 循环   FOR 循环 顺序控制:   GOTO 语句   NULL 语句 1、IF 语句根据条件执行一系列语句，有三种形式：IF-THEN、IF-THEN-ELSE 和 IF-THEN-ELSIF 范例一： 先插入一个表 create table toys(id int primary key,toyname varchar2(2),toyprice number); insert into toys values(1,'a',200); insert into toys values(2,'b',100); insert into toys values(3,'c',90); SQL> select * from toys;         ID TO   TOYPRICE ---------- -- ----------          1 a         200          2 b         100          3 c          90 进行价格调整： SQL> declare   2  v_toyprice toys.toyprice%type;   3  begin   4  select toyprice into v_toyprice from toys where   5  id=1;   6  if v_toyprice>=200 then   7  update toys set toyprice=toyprice-50 where id=1;   8  elsif v_toyprice<100 then   9  update toys set toyprice=toyprice+20 where  10  id=1;  11  end if;  12  end;  13  / PL/SQL 过程已成功完成。 SQL> select * from toys;         ID TO   TOYPRICE ---------- -- ----------          1 a         150          2 b         100          3 c          90 范例二： SQL> declare   2  v_toyprice toys.toyprice%type;   3  v_id toys.id%type;   4  begin   5  v_id:=&id;   6  select toyprice into v_toyprice from toys where   7  id=v_id;   8  if v_toyprice>=200 then   9  update toys set toyprice=toyprice-50 where id=1;  10  elsif v_toyprice<100 then  11  update toys set toyprice=toyprice+20 where  12  id=v_id;  13  end if;  14  end;  15  / 输入 id 的值:  2 原值    5: v_id:=&id; 新值    5: v_id:=2; PL/SQL 过程已成功完成。 SQL> / 输入 id 的值:  3 原值    5: v_id:=&id; 新值    5: v_id:=3; PL/SQL 过程已成功完成。 SQL> select * from toys;         ID TO   TOYPRICE ---------- -- ----------          1 a         150          2 b         100          3 c         110 2、CASE 语句用于根据单个变量或表达式与多个值进行比较 执行 CASE 语句前，先计算选择器的值 范例： SQL> BEGIN   2      CASE '&grade'--之所以输入的时候不带引号，是因为这里带了，如果这里写成&grade，输入里必须                       --带引号   3        WHEN 'A' THEN DBMS_OUTPUT.PUT_LINE('优异');   4        WHEN 'B' THEN DBMS_OUTPUT.PUT_LINE ('优秀');   5        WHEN 'C' THEN DBMS_OUTPUT.PUT_LINE ('良好');   6        WHEN 'D' THEN DBMS_OUTPUT.PUT_LINE ('一般');   7        WHEN 'F' THEN DBMS_OUTPUT.PUT_LINE ('较差');   8        ELSE DBMS_OUTPUT.PUT_LINE ('没有此成绩');---其它语句都不满足时执行   9      END CASE;  10  END;  11  / 输入 grade 的值:  A 原值    2:     CASE '&grade' 新值    2:     CASE 'A' PL/SQL 过程已成功完成。 SQL> / 输入 grade 的值:  B 原值    2:     CASE '&grade' 新值    2:     CASE 'B' PL/SQL 过程已成功完成。 也可以写成： SQL> DECLARE   2  grade varchar2(2);   3  BEGIN   4  grade :='&grade';   5      CASE '&grade'   6        WHEN 'A' THEN DBMS_OUTPUT.PUT_LINE('优异');   7        WHEN 'B' THEN DBMS_OUTPUT.PUT_LINE ('优秀');   8        WHEN 'C' THEN DBMS_OUTPUT.PUT_LINE ('良好');   9        WHEN 'D' THEN DBMS_OUTPUT.PUT_LINE ('一般');  10        WHEN 'F' THEN DBMS_OUTPUT.PUT_LINE ('较差');  11        ELSE DBMS_OUTPUT.PUT_LINE ('没有此成绩');  12      END CASE;  13  END;  14  / 输入 grade 的值:  A 原值    4: grade :='&grade'; 新值    4: grade :='A'; 输入 grade 的值:   3、循环控制 循环控制用于重复执行一系列语句 循环控制语句包括： LOOP、EXIT 和 EXIT WHEN----有条件退出和无条件退出 循环控制的三种类型： LOOP   -   无条件循环 WHILE  -   根据条件循环 FOR    -   循环固定的次数 范例： SQL>  begin   2  loop   3  if &score>60 then   4  DBMS_OUTPUT.PUT_LINE('成绩通过');   5  exit;   6  DBMS_OUTPUT.PUT_LINE('继续');   7  end if;   8  end loop;   9  end;  10  / 输入 score 的值:  70 原值    3: if &score>60 then 新值    3: if 70>60 then 成绩通过 PL/SQL 过程已成功完成。 范例二： SQL> declare   2  monthly_value number :=0;--月销量   3  daily_value number:=0;--日销量   4  begin   5  while monthly_value <=2000   6  loop   7  monthly_value:=daily_value*31;   8  daily_value:=daily_value+10;   9  dbms_output.put_line('每日销量：'||daily_value);  10  end loop;  11  dbms_output.put_line('每月销量：'||monthly_value);  12  end;  13  / 每日销量：10 每日销量：20 每日销量：30 每日销量：40 每日销量：50 每日销量：60 每日销量：70 每日销量：80 每月销量：2170 PL/SQL 过程已成功完成。 范例三： SQL> declare   2  i int:=0;   3  begin   4  while i<10 loop   5  dbms_output.put_line(i);   6  i:=i+1;   7  end loop;   8  end;   9    10  / 结果：0 1 2 3 4 5 6 7 8 9 PL/SQL 过程已成功完成。 范例四： begin for i in 1.. 10 loop dbms_output.put_line(i); end loop; end; 带有reverse的 begin for i in reverse 1.. 100 loop dbms_output.put_line(i); end loop; end; 4.顺序结构 顺序控制用于按顺序执行语句 顺序控制语句包括： GOTO 语句 -  无条件地转到标签指定的语句，早期的语言使用标签，现在不介意使用。 NULL 语句 -  什么也不做的空语句 例： DECLARE   qtyhand itemfile.qty_hand%type;   relevel itemfile.re_level%type; BEGIN   SELECT qty_hand,re_level INTO qtyhand,relevel   FROM itemfile WHERE itemcode = 'i201';   IF qtyhand < relevel THEN     GOTO updation;--->goto到一个标签。满足的时候走这个标签   ELSE     GOTO quit;------>不满足走这个标签   END IF;   <<updation>>----->定义标签用双引号   UPDATE itemfile SET qty_hand = qty_hand + re_level   WHERE itemcode = 'i201';   <<quit>>----->标签   NULL; END;                      第四章 动态SQL 动态 SQL 是指在PL/SQL程序执行时生成的 SQL 语句 编译程序对动态 SQL 不做处理，而是在程序运行时动态构造语句、对语句进行语法分析并执行。跳过了编译器 DDL 语句命令和会话控制语句不能在 PL/SQL 中直接使用，但是可以通过动态 SQL 来执行 执行动态 SQL 的语法：  EXECUTE IMMEDIATE dynamic_sql_string----->EXECUTE IMMEDIATE：立即执行的意思       [INTO  define_variable_list]       [USING bind_argument_list]; 范例： SQL> begin   2  execute immediate 'create table test(id int)';--->语句放在单引号中，   3  end;   4  / PL/SQL 过程已成功完成。 动态的查询实例： SQL> declare   2  sql_stmt varchar2(200);   3  emp_id number(4):=7566;   4  emp_rec emp%rowtype;   5  begin   6  sql_stmt := 'select * from emp where empno = :id';   7  execute immediate sql_stmt into emp_rec using emp_id;--->using用于绑定变量   8  dbms_output.put_line(emp_rec.ename);   9  end;  10  / PL/SQL 过程已成功完成。 所谓动态的SQL就是条件没有确定下来。 注：动态SQL编译的时候不被编译。   第五章 错误处理 在运行程序时出现的错误叫做异常 发生异常后，语句将停止执行，控制权转移到 PL/SQL 块的异常处理部分 异常有两种类型： 预定义异常 -- 当 PL/SQL 程序违反 Oracle 规则或超越系统限制时隐式引发.所谓预定义异常就是Oracle系统根据用户经常出现的错误，预先定义出来的一些异常。如返回多行时，就会触发一个预定义异常。 用户定义异常 -- 用户可以在 PL/SQL 块的声明部分定义异常，自定义的异常通过 RAISE 语句显式引发 范例： SQL> declare   2  v_rec emp%rowtype;   3  begin   4  select sal into v_rec.sal from emp;   5  exception--自己定义一个异常   6  when too_many_rows then   7  dbms_output.put_line('返回太多行');   8  end;   9  / 返回太多行 PL/SQL 过程已成功完成。 如果不加异常处理部分： SQL> declare   2  v_rec emp%rowtype;   3  begin   4  select sal into v_rec.sal from emp;--不定义异常，直接结束，返回系统的预定义异常   5  end;   6  / declare * 第 1 行出现错误: ORA-01422: 实际返回的行数超出请求的行数--注：这里同时产生了一个号 ORA-06512: 在 line 4 一、处理预定义异常 在Oracle中的常见异常: 详情见附录 范例： SQL> declare   2  v_rec emp%rowtype;   3  begin   4  select sal into v_rec.sal from emp where empno=90;--并没有90号员工   5  exception   6  when no_data_found then--no_data_found就是一个系统的预定义异常   7  dbms_output.put_line('无符合条件的数据');   8  end;   9  / 无符合条件的数据 PL/SQL 过程已成功完成。 二、处理用户定义异常 处理用户定义异常需要三步： 1.声明异常(EXCEPTION) 2.引发异常(RAISE)  3.处理异常 预定义异常只需第3步就可以了。 范例： SQL> declare   2  e_test exception;--声明异常 e_test   3  v_name varchar2(10);   4  begin   5  v_name:='&name';   6  if v_name not in('a','b','c') then   7  raise e_test;--引发异常   8  end if;   9  --处理异常  10  exception  11  when e_test then  12  dbms_output.put_line('输入的信息不在规定的范围内');  13  end;  14  / 输入 name 的值:  a 原值    5:  v_name:='&name';--如果这此处不加单引号，输入的时候一定要带上单引号 新值    5:  v_name:='a'; PL/SQL 过程已成功完成。 SQL> / 输入 name 的值:  e 原值    5:  v_name:='&name'; 新值    5:  v_name:='e'; 输入的信息不在规定的范围骨 PL/SQL 过程已成功完成。 三、引发应用程序错误 用于创建用户定义的错误信息 可以在可执行部分和异常处理部分使用 错误编号必须介于 –20000 和 –20999 之间 错误消息的长度可长达 2048 个字节 引发应用程序错误的语法：    RAISE_APPLICATION_ERROR(error_number, error_message); 范例： SQL> declare   2  e_test exception;--声明异常   3  v_name varchar2(10);   4  begin   5  v_name:='&name';   6  if v_name not in('a','b','c') then   7  raise e_test;--引发异常   8  end if;   9  --处理异常  10  exception  11  when e_test then  12  raise_application_error(-20001,'输入的信息不在规定的范围内');      --产生错误的时候，同时生成一个号，类似于预定义错误。  13  end;  14  / 输入 name 的值:  / 原值    5:  v_name:='&name'; 新值    5:  v_name:='/'; declare * 第 1 行出现错误: ORA-20001: 输入的信息不在规定的范围内--自己编的 ORA-06512: 在 line 12--ORA-06512: Oracle系统自动生成的 注：异常是有针对性的。   第六章 游标-隐式游标 游标 ●执行原理： Oracle服务器---->执行PL/SQL程序---检索行--->保存到游标中--提取行--->一次处理一行   ●作用：逐行处理查询结果，以编程的方式访问数据 ●游标的类型：隐式游标、显式游标、REF游标(REF 游标用于处理运行时才能确定的动态 SQL 查询的结果) 当每次查询的时候，如EMP表的所有信息，他会将查询的所有信息按行排序排布像一个表一样。将结果存到内存区域里边，然后Oracle提供了一种机制，游标就像一个指针一样，可以指定他的记录，第一次指向第一条，一直往下，直到结束。 隐式游标 在PL/SQL中使用DML语句时自动创建隐式游标。 隐式游标自动声明、打开和关闭，其名为 SQL。声明、打开、关闭分部是自己完成的。 通过检查隐式游标的属性可以获得最近执行的DML 语句的信息 隐式游标的属性有： %FOUND    –SQL 语句影响了一行或多行时为 TRUE，可以利用这个特性判断语句是否执行成功了。 %NOTFOUND –SQL 语句没有影响任何行时为TRUE。 %ROWCOUNT –SQL 语句影响的行数。 %ISOPEN    -游标是否打开，始终为FALSE。对于隐式游标始终是假的。 当我们执行insert update delete等语句时，就会自动创建一个隐式的游标 原toys表的内容为： SQL> select * from toys;         ID TO   TOYPRICE ---------- -- ------------------------          1 a         200          2 b         100          3 c          90 范例(%FOUND )： SQL> declare   2  begin   3  update toys set toyprice=120 where id=1;   4  --这时就会有一个隐式游标SQL   5  if sql%found then   6  dbms_output.put_line('已更新');   7  end if;   8  end;   9  / 已更新----打印出来了，说明更新，是真 SQL> select * from toys;         ID TO   TOYPRICE ---------- -- ----------          1 a         120          2 b         100          3 c          90 范例(%notfount) SQL> declare   2  begin   3  update toys set toyprice=120 where id=11;--不存在id=11   4  --这时就会有一个隐式游标SQL   5  if sql%notfound then   6  dbms_output.put_line('没有更新');   7  else   8  dbms_output.put_line('已更新');   9  end if;  10  end;  11  / 没有更新. 因为没有id=11记录存在。 范例(%rowcount)： SQL> declare   2  begin   3  update toys set toyprice=120 ;   4  --这时就会有一个隐式游标SQL   5  if sql%notfound then   6  dbms_output.put_line('没有相关更新');   7  else   8  dbms_output.put_line('已更新的数量为：'||sql%rowcount);   9  end if;  10  end;  11  / 已更新的数量为：3 范例(%isopen)： SQL> declare   2  begin   3  update toys set toyprice=120 ;   4  --这时就会有一个隐式游标SQL   5  if sql%notfound then   6  dbms_output.put_line('没有相关更新');   7  else   8  dbms_output.put_line('已更新的数量为：'||sql%rowcount);   9  if sql%isopen then  10        dbms_output.put_line('游标已打开');  11        else  12        dbms_output.put_line('游标已关');--始终都是关着的  13         end if ;  14  end if;  15  end;  16  / 已更新的数量为：3 游标已关                     第七章 游标-显式游标 显式游标(重点) 显式游标在 PL/SQL 块的声明部分定义查询，该查询可以返回多行。也就是处理返回多行的查询，用的最多。 以前只能查一行，现在可以返回多行的查询结果。 基本步聚:声明游标 打开游标 提取 关闭 toy表内容： SQL> select * from toys;         ID TOPRICE   TOYPRICE ---------- ------   -----------------------          1 a         200          2 b         100          3 c          90          4 d         250          5 e         300          6 f         600 已选择6行。 范例：查看emp表中的记录 打印出员工的姓名、员工号、工资 DECLARE CURSOR emp_cur IS select * from emp;--声明游标 关键字为CURSOR emp_rec emp%rowtype;--可以在放得下整行记录的变量 BEGIN OPEN emp_cur ;--打开游标 loop FETCH emp_cur INTO emp_rec;--提取游标放到变量中 exit when emp_cur%notfound;--找不到数据时退出 dbms_output.put_line(emp_rec.empno||emp_rec.ename||emp_rec.sal); end loop; END; 1.带参数的显式游标 声明显式游标时可以带参数以提高灵活性 声明带参数的显式游标的语法如下： ------------------------------------------------ CURSOR <cursor_name>(<param_name> <param_type>)      IS select_statement; ------------------------------------------------ 范例： SQL> select * from toys;         ID TO   TOYPRICE ---------- -- ----------          1 a         200          2 b         100          3 c          90 SQL> declare   2  cursor toy_cur(x number) is select * from toys where toyprice>x;--声明游标   3  --注：定义参数时，只需要给定一个类型就可以了， 不用给定长度   4  a toys%rowtype;--定义一个变量   5  begin   6  open toy_cur(&price);--需要输入的值   7  loop   8  fetch toy_cur into a;--提取   9  exit when toy_cur%notfound ;--有条件退出  10  dbms_output.put_line('玩具名:'||a.toyname||'价格为:'||a.toyprice);  11  end loop;  12  close toy_cur;--关闭  13  end;  14  / 输入 price 的值:  100 原值    6: open toy_cur(&price);--需要输入的值 新值    6: open toy_cur(100);--需要输入的值 玩具名:a价格为:200 玩具名:d价格为:250 玩具名:e价格为:300 玩具名:f价格为:600 PL/SQL 过程已成功完成。 -------------------------------->很明显带有参数的游标要给不带参的灵活。其>100元的结果是一样的。 还可以写多个参数如： toy_cur(p_toyprice number,b varchar2)) where toyprice=p_toyprice and name=b; 2.使用显式游标更新行  允许使用游标删除或更新活动集中的行 声明游标时必须使用 SELECT … FOR UPDATE语句 ---------------------------------------------- --创建游标       CURSOR <cursor_name> IS  SELECT statement FOR UPDATE; UPDATE <table_name> SET <set_clause> WHERE CURRENT OF <cursor_name> ---------------------------------------------- 删除语法： DELETE FROM <table_name> WHERE CURRENT OF <cursor_name> ----------------------------------------------- 更新范例： 首先查看原表中的记录:  select * from toys;     ID TO   TOYPRICE ------ -- ----------      1 a         200      2 b         100      3 c          90      4 d         250   再进行更改 --将toys有中所有价格在100内加20元 declare CURSOR toys_cur IS select * from toys where toyprice<=100 FOR UPDATE; toys_rec toys%rowtype; begin open toys_cur; loop FETCH toys_cur INTO toys_rec; exit when toys_cur%notfound; update toys set toyprice=toyprice+20 where CURRENT OF toys_cur;//注：一定要是当前的 dbms_output.put_line('符合要求的有:'||'玩具名'||toys_rec.toyname||'价格为'||toys_rec.toyprice); end loop; end; 结果： 符合要求的有:玩具名b价格为100 符合要求的有:玩具名c价格为90 再重新查看toys表 select * from toys;    ID TO   TOYPRICE ----- -- ----------     1 a         200     2 b         120     3 c         110     4 d         250   删除范例：将所有价格在100元以内的玩具删除 select * from toys;    ID TO   TOYPRICE ----- -- ----------     1 a         200     2 b         100     3 c          90   因为在表中只在c玩具大小100元，所以预计结果是将c玩具删除 进行删除 declare CURSOR toys_cur IS select * from toys where toyprice<100 FOR UPDATE; toys_rec toys%rowtype; begin open toys_cur; loop FETCH toys_cur INTO toys_rec; exit when toys_cur%notfound; DELETE FROM toys where CURRENT OF toys_cur; dbms_output.put_line('符合要求的有:'||toys_rec.toyname); end loop; end; 结果：符合要求的有:c 再次查看toys表的结果：  select * from toys;     ID TO   TOYPRICE ------ -- ----------      1 a         200      2 b         100 3.循环游标  循环游标用于简化游标处理代码 当用户需要从游标中提取所有记录时使用 循环游标的语法如下： ------------------------------------- FOR <record_index> IN <cursor_name> LOOP <executable statements> END LOOP; -------------------------------------- 范例：取表中的所有字段 declare --toy_rec toys%rowtype;--toy_rec变量在此处定义可不定义，就像if语句中的i变量,不用另外声明 cursor toy_cur is select * from toys; begin --open toy_cur;注：这里千万不能使游标打开 for toy_rec in toy_cur loop dbms_output.put_line(toy_rec.toyname||toy_rec.id||toy_rec.toyprice); end loop; --close toy_cur;注：同理不用关闭 end; 结果： a 1 200 b 2 100 c 3 90   第八章 游标-REF游标 ● REF游标和游标变量 REF 游标和游标变量用于处理运行时动态执行的 SQL 查询。也就是SQL语句没有确定，要在执行时给游标设定一个查询。使用的频率很少。主要是以游标变量的形式进行操作的。 创建游标变量需要两个步骤： 1.声明 REF 游标类型 2.声明 REF 游标类型的变量 用于声明 REF 游标类型的语法为： -------------------------------------- TYPE <ref_cursor_name> IS REF CURSOR [RETURN <return_type>]; -------------------------------------- REF游标分为两种类型：弱类型和强类型。它们的区别差一个return语句 弱类型：TYPE <ref_cursor_name> IS REF CURSOR; 强类型：TYPE <ref_cursor_name> IS REF CURSOR         [RETURN <return_type>]; 弱类型游标不能放入包中。 打开游标变量的语法如下：  OPEN cursor_name FOR select_statement; 范例： SQL> declare   2  type ref_toy_cur is ref cursor--声明一个REF游标   3  return toys%rowtype;--强类型   4  v_rec toys%rowtype;   5  cur_toy ref_toy_cur;--声明一个REF类型的变量   6  begin   7       open cur_toy for select * from toys;--注：是操作REF类型的变量   8       loop   9       fetch cur_toy into v_rec;  10       exit when cur_toy%notfound;--退出条件  11       dbms_output.put_line(v_rec.toyname);  12       end loop;  13       close cur_toy;  14  end;  15    16  / a b c PL/SQL 过程已成功完成。 ● 使用游标变量执行动态 SQL 范例： SQL> DECLARE   2    r_emp emp%ROWTYPE;   3    TYPE c_type IS REF CURSOR;--弱类型的无RETURN   4    cur c_type;   5    p_salary NUMBER;   6  BEGIN   7    p_salary := 2500;   8    OPEN cur FOR 'select * from emp where sal>:1--这是一个占位符   9                  order by sal desc'--排序  10    USING p_salary;  11    DBMS_OUTPUT.PUT_LINE('薪水大于'|| p_salary ||'的员工有：');  12    LOOP  13      FETCH cur INTO r_emp;  14      EXIT WHEN cur%NOTFOUND;  15      DBMS_OUTPUT.PUT_LINE('编号：'|| r_emp.empno  16        || ' 姓名：' || r_emp.ename|| ' 薪水：' || r_emp.sal );  17    END LOOP;  18    CLOSE cur;   19  END;  20    21  / 薪水大于2500的员工有： 编号：7839 姓名：KING 薪水：5000 编号：7788 姓名：SCOTT 薪水：3000 编号：7902 姓名：FORD 薪水：3000 编号：7566 姓名：JONES 薪水：2975 编号：7698 姓名：BLAKE 薪水：2850 PL/SQL 过程已成功完成。 点位符：需要一个值，这个值目前没有，先用1先占着这个位置。 ● 游标变量的优点和限制 游标变量的功能强大，可以简化数据处理。 ▲游标变量的优点有： (1)可从不同的 SELECT 语句中提取结果集 (2)可以作为过程的参数进行传递 (3)可以引用游标的所有属性 (4)可以进行赋值运算 ▲使用游标变量的限制： (1)不能在程序包中声明游标变量 (2)FOR UPDATE子句不能与游标变量一起使用 (3)不能使用比较运算符                      第九章 子程序-过程 子程序之过程 以前的写的PL/SQL语句，从declare到end没有一个统一名字，用的时候都是将整个块拿来使用，我们叫这个为匿名块，没名字。 目标：创建和使用子程序  子程序 ：命名的 PL/SQL 块，编译并存储在数据库中。在数据库作为一个对象存在。 子程序的各个部分：声明部分、可执行部分、异常处理部分(可选) 子程序的分类：1.过程－执行某些操作 2.函数－执行操作并返回值 注：过程与函数的最本质上的区别就是函数有返回值。过程也可以有返回值，但是需要参数。 子程序的优点： 模块化：将程序分解为逻辑模块 可重用性：可以被任意数目的程序调用 可维护性：简化维护操作 安全性：通过设置权限，使数据更安全 ● 子程序-过程  过程是用于完成特定任务的子程序。  创建过程的语法： ----------------------------------------- CREATE [OR REPLACE] PROCEDURE     <procedure name> [(<parameter list>)] IS|AS --选一个，两个意义是一样的    <local variable declaration>--本过程要使用的变量 BEGIN    <executable statements> [EXCEPTION    <exception handlers>] END; ------------------------------------------ 范例： SQL> create or replace procedure p_emp(p_empno number)   2  as   3  v_ename varchar2(20);   4  begin   5  select ename into v_ename from emp where empno=p_empno;   6  dbms_output.put_line('员工名称'||v_ename);   7  exception   8  when no_data_found then   9  dbms_output.put_line('没有此人：');  10  end;  11  / 过程已创建。 SQL> execute p_emp(7499);--调用过程 员工名称：ALLEN PL/SQL 过程已成功完成。 过程参数的三种模式： IN：用于接受调用程序的值，默认的参数模式 OUT：用于向调用程序返回值  IN OUT：用于接受调用程序的值，并向调用程序返回更新的值 执行过程的语法：   EXECUTE procedure_name(parameters_list); 范例一(IN和OUT)： SQL> create or replace procedure    --带有两个参数 第1个默认有个IN，第2个为OUT   2  p_emp(p_empno number,p_sal out number)--创建过程p_emp 注：out   3  as   4  v_ename emp.ename%type;   5  v_sal number;   6  begin   7  select ename,sal into v_ename,v_sal from emp where empno=p_empno;--赋值   8  if v_sal<=2000 then--如果工资小于2000就改为2000   9  p_sal:=2000;  10  end if;  11  dbms_output.put_line('员工名为:'||v_ename);  12  end;  13  / 过程已创建。 --调用子程序过程  SQL> declare   2  v_sal number;   3  begin   4  p_emp(7499,v_sal);--将第2个参数输了出来   5  dbms_output.put_line('工资标准:'||v_sal);   6  end;   7  / 员工名为:ALLEN 工资标准:2000 范例二(IN OUT):数值的交换 SQL> create or replace procedure   2  swap(x in out number,y in out number)--声明   3  as   4  temp number;   5  begin   6  temp:=x;   7  x:=y;   8  y:=temp;   9  end;  10  / 过程已创建。 --调用参数 SQL> declare   2  a number:=50;   3  b number:=100;   4  begin   5  swap(a,b);   6  dbms_output.put_line(a);   7  dbms_output.put_line(b);   8  end;   9  / 100 50 PL/SQL 过程已成功完成。 将过程的执行权限授予其他用户： SQL> GRANT EXECUTE ON find_emp TO MARTIN; SQL> GRANT EXECUTE ON swap TO PUBLIC; 删除过程： SQL> DROP PROCEDURE find_emp;                        第十章 子程序-函数  子程序之函数  ● 函数是可以返回值的命名的 PL/SQL 子程序。  创建函数的语法： ------------------------------------   CREATE [OR REPLACE] FUNCTION    <function name> [(param1,param2)] RETURN <datatype>  IS|AS --注：一定要有一个返回类型，没有长度   [local declarations] BEGIN   Executable Statements;   RETURN result; EXCEPTION   Exception handlers; END; -------------------------------------- 定义函数的限制： 函数常用 IN 参数，也可接受 IN OUT 或 OUT 参数 形参不能是 PL/SQL 类型。也就是使用的是SQL类型 函数的返回类型也必须是数据库类型 访问函数的两种方式：1.使用 PL/SQL 块  2.使用 SQL 语句 创建函数： CREATE OR REPLACE FUNCTION fun_hello   RETURN  VARCHAR2--注：返回SQL类型的 IS BEGIN   RETURN '朋友，您好'; END; / 从 SQL 语句调用函数： SQL> SELECT fun_hello FROM DUAL;--注：从dual表中调用  注：函数是不能单独存在的，要跟其它部分共同构成语句。 范例： SQL> create or replace function fun_emp(p_sal number)   2  return varchar2   3  as   4  v_max number;   5  v_min number;   6  begin   7  select max(sal),min(sal) into v_max,v_min from emp where deptno=20;   8  if p_sal>v_min and p_sal<v_max then   9   return '工资在范围内';  10  else  11   return '不在范围内';  12  end if;  13  end;  14  / 函数已创建。 SQL> select fun_emp(900) from dual;--注：不能从原表emp表调用 FUN_EMP(900) ----------------------------------------------- 不在范围内 SQL> select fun_emp(1500) from dual; FUN_EMP(1500) ----------------------------------------------- 工资在范围内 ● 调用自定义函数 当有多个函数时，可以用使用三种方法为函数传递参数 位置表示法   functionName(arg1[,arg2,arg3…]) 名称表示法   functionName(argName=>argvalue,[…..]) 混合表示法： 同时使用位置表示法和名称表示法为函数传递参数。 即在调用一个函数时，同时使用位置表示法和名称表示法为函数传递参数。采用这种参数传递方法时，使用位置表示法所传递的参数必须放在名称表示法传递的参数的前面，也就是说无论函数具有多少个参数，只要其中有一个使用了名称表示法，其后所有的参数都必须使用名称表示法。 调用get_salary函数 按顺序为参数赋值 按参数名称赋值 创建参数带有默认值的函数 调用带有默认值的函数 范例：获取某部门工资总和 SQL> create or replace function  fun1(p_deptno number,v_count out number)   2  return number   3  as   4  v_sum number;   5  begin   6  select sum(sal),count(*) into v_sum,v_count from emp   7  where deptno=p_deptno;   8  return v_sum;   9  exception  10  when no_data_found then  11  dbms_output.put_line('没有选定的信息');  12  when others then  13  dbms_output.put_line('错误代号'||sqlcode);  14  end;  15  / 函数已创建。 --调用函数 SQL> declare   2  v_sum number;   3  v_count number;   4  begin   5  v_sum:=fun1(20,v_count);--按顺序调   6  dbms_output.put_line('工资总和为:'||v_sum||'人员个数为:'||v_count);   7  end;   8  / 工资总和为:10075人员个数为:4 PL/SQL 过程已成功完成。 --按名称调用 v_sum:=fun1(v_count=>v_count，p_deptno=>20); 注：v_sum:=fun1(v_count=>v_count，20);--不可以 --混合调用 v_sum:=fun1(20,v_count=>v_coun); ● 创建参数带有默认值的函数 范例： SQL> create or replace function   2  fun_def(name varchar2,age int ,sex varchar2 default '男')   3  return varchar2   4  as    5  v_result varchar2(50);   6  begin   7  v_result:='姓名:'||name||'年龄:'||age||'性别:'||sex;   8  return v_result;   9  end;  10  / 函数已创建。 PL/SQL 过程已成功完成。 SQL> declare   2  v_result varchar2(50);   3  begin   4  --v_result:=fun_def('李龙',20);   5  v_result:=fun_def(age=>23,name=>'杰克');   6  dbms_output.put_line(v_result);   7  end;   8  / 姓名:杰克年龄:23性别:男--------默认为男 也可以加上性别：  SQL> declare   2  v_result varchar2(50);   3  begin   4   v_result:=fun_def(age=>23,name=>'多莉',sex=>'女');   5  dbms_output.put_line(v_result);   6  end;   7  / 姓名:多莉 年龄:23 性别:女 ● 过程和函数的比较： 过 程 函  数 作为 PL/SQL语句执行 作为表达式的一部分调用 在规格说明中不包RETURN 子句 必须在规格说明中包含 RETURN 子句 不返回任何值 必须返回单个值 可以包含 RETURN 语句，但是与函数不同， 它不能用于返回值 必须包含至少一条 RETURN语句 第十一章 自主事物处理 自主事物处理是与过程相关的。 实例验证： 范例一： SQL> select * from dept;     DEPTNO DNAME          LOC ---------- -------------- -------------         10 ACCOUNTING     NEW YORK         20 RESEARCH       DALLAS         30 SALES          CHICAGO         40 OPERATIONS     BOSTON SQL> create or replace procedure first--创建第1个过程   2  is   3  v_loc varchar2(30);   4  begin   5  select loc into v_loc from dept where deptno=10;   6  dbms_output.put_line(v_loc);   7  rollback;--注：回滚   8  end;   9  / 过程已创建。 SQL> create or replace procedure second--创建第2个过程   2  is    3  v_loc varchar2(20);   4  begin   5  update dept set loc='haerbin' where deptno=10;--将10号部门的地址改为haerbing   6  first();--在第2个过程中调用第1个过程   7  select loc into v_loc from dept where deptno=10;--被回滚了   8  dbms_output.put_line(v_loc);   9  end;  10  / 过程已创建。 SQL> execute second; haerbin NEW YORK--回滚后 SQL> select * from dept;     DEPTNO DNAME          LOC ---------- -------------- -------------         10 ACCOUNTING     NEW YORK--没有变         20 RESEARCH       DALLAS         30 SALES          CHICAGO         40 OPERATIONS     BOSTON 之所以改动后的值没有被保留，是因为在first中有一个rollback; 如果想使first回滚自己的，不要回滚调用者：可以在first中加一句：PRAGMA AUTONOMOUS_TRANSACTION  范例二： SQL> create or replace procedure first   2  is   3  v_loc varchar2(30);   4  PRAGMA AUTONOMOUS_TRANSACTION;   5  begin   6  select loc into v_loc from dept where deptno=10;   7  dbms_output.put_line(v_loc);   8  rollback;   9  end;  10  / 过程已创建。 SQL> create or replace procedure second   2  is    3  v_loc varchar2(20);   4  begin   5  update dept set loc='haerbin' where deptno=10;   6  first();   7  select loc into v_loc from dept where deptno=10;   8  dbms_output.put_line(v_loc);   9  end;  10  / 过程已创建。 SQL> execute second; NEW YORK haerbin PL/SQL 过程已成功完成。 SQL> select * from dept;     DEPTNO DNAME          LOC ---------- -------------- -------------         10 ACCOUNTING     haerbin--已变化         20 RESEARCH       DALLAS         30 SALES          CHICAGO         40 OPERATIONS     BOSTON 所以自主事物处理特点为： 主事(first)务处理启动独立事务处理 然后主事务处理被暂停 自主事务处理子程序内(second)的 SQL 操作 然后终止自主事务处理 恢复主事务处理 PRAGMA AUTONOMOUS_TRANSACTION  用于标记子程序为自主事务处理 自主事务处理的特征为： 1.与主事务处理的状态无关 2.提交或回滚操作不影响主事务处理 3.自主事务处理的结果对其他事务是可见的 4.能够启动其他自主事务处理   第十二章 程序包 目标：创建和使用程序包 程序包是对相关过程、函数、变量、游标和异常等对象的封装。 程序包由规范和主体两部分组成。 规范声明和主体两部分是要单独拿出来的： 在规范中可以声明：包括类型、变量、常量、异常、游标规范和子程序规范等 在主体中可以声明：对象和实现在包规范中声明的子程序和游标 ● 创建程序包  1.程序包规范 CREATE [OR REPLACE] PACKAGE package_name --包名 IS|AS [Public item declarations] [Subprogram specification] END [package_name]; 2.程序包主体 CREATE [OR REPLACE] PACKAGE BODY package_name  IS|AS [Private item declarations] [Subprogram bodies] [BEGIN Initialization] END [package_name]; 注：包规范声明的名和主体声明的名一定要相同。 规范声明范例： SQL> create or replace package pack_emp   2  as    3  --公共项区   4  --过程及函数的规格声明   5  --实现创建一个过程   6  --实现创建一个函数   7  procedure pro_first(p_empno number);--过程   8  function fun_first return varchar2;--函数   9  end pack_emp;--结束包名，为了与其它的区别  10  / 程序包已创建。 主体声明范例： SQL> SQL> create or replace package body pack_emp SP2-0734: 未知的命令开头 \"SQL> creat...\" - 忽略了剩余的行。 SQL>   2  as  SQL>   3  procedure pro_first(p_empno number) SQL>   4  is SQL>   5  --本过程使用的变量 SQL>   6  v_ename emp.ename%type; SQL>   7  begin SQL>   8  --将员工的名字打印 SQL>   9  select ename into v_ename from emp where empno=p_empno; SQL>  10  dbms_output.put_line('员工名:'||v_ename); SQL>  11  end pro_first; SQL>  12  --返回一个字符串 SQL>  13  function fun_first return varchar2 SQL>  14  is  SQL>  15  begin SQL>  16  return '你好'; SQL>  17  end fun_first; SQL>  18  end pack_emp; SQL>  19  / SQL>  SQL> 程序包体已创建。 调用程序包中的函数和过程范例：execute 包名.对象名 SQL> execute pack_emp.pro_first(7499); 员工名:ALLEN PL/SQL 过程已成功完成。 ● 程序包的优点：模块化、更轻松的应用程序设计、信息隐藏、新增功能、性能更佳 ● 程序包中的游标 ： 注：游标的定义分为游标规范和游标主体两部分 在包中声明游标的要求： 在包规范中声明游标规范时必须使用 RETURN 子句指定游标的返回类型 RETURN子句指定的数据类型可以是： 1.用 %ROWTYPE 属性引用表定义的记录类型 2.程序员定义的记录类型 创建游标程序包范例： SQL> --包规范声明 SQL> create or replace package pack_cur   2  as   3  cursor emp_cur(p_deptno number)--声明一个游标   4  return emp%rowtype;   5  procedure pro_emp_cur(p_dept number);--需要一个过程操作游标   6  end pack_cur;    7  / 程序包已创建。 SQL> --声明包主体 SQL> create or replace package body pack_cur   2  as   3  cursor emp_cur(p_deptno number)--声明一个游标   4  return emp%rowtype--注：一定要有RETURN   5  IS   6  select * from emp where deptno=p_deptno;   7  procedure pro_emp_cur(p_dept number)--需要一个过程操作游标   8  as   9  v_rec_emp emp%rowtype;  10  begin  11  open emp_cur(p_dept);  12  loop  13  fetch emp_cur into v_rec_emp;  14  exit when emp_cur%notfound;  15  dbms_output.put_line('名为:'||v_rec_emp.ename||'工资:'||v_rec_emp.sal);  16  end loop;  17  close emp_cur;  18  end pro_emp_cur;  19  end pack_cur;   20  / 程序包体已创建。 --调用包中的过程 SQL> execute pack_cur.pro_emp_cur(20);--查看20部门的全体员工 名为:JONES工资:2975 名为:SCOTT工资:3000 名为:ADAMS工资:1100 名为:FORD工资:3000 PL/SQL 过程已成功完成。 ● 有关子程序和程序包的信息 USER_OBJECTS 视图包含用户创建的子程序和程序包的信息 USER_SOURCE 视图存储子程序和程序包的源代码 ● 总结： 子程序是命名的 PL/SQL 块，可带参数并可在需要时随时调用 有两种类型的PL/SQL子程序，即过程和函数 过程用户执行特定的任务，函数用于执行任务并返回值 程序包是对相关类型、变量、常量、游标、异常、过程和函数等对象的封装 程序包由两部分组成，即包规范和包主体 使用程序包的优点是：模块化、更轻松的程序设计、信息隐藏、新增功能以及性能更佳   第十三章 触发器讲解 触发器 定义：触发器是当特定事件出现时自动执行的存储过程 特定事件可以是执行更新的DML语句和DDL语句 特点：触发器不能被显式调用 触发器的功能： 1.自动生成数据（可以从多个表中合成由他来创建一组新的数据） 2.自定义复杂的安全权限（从多个表中限制，是跨多个表存在的） 3.提供审计和日志记录（在我的数据库执行了什么样的操作都可以记录下来） 4.启用复杂的业务逻辑（是与多个表相关的如：从一个员工辞职了，其中的一个表中删除了这个员工 ，其它表中关于此员工的信息都可以同时删除掉了）。 所以触发器是数据库的高级使用。 ● 触发器的组成部分 触发器由三部分组成： 1.触发器语句（事件）：定义激活触发器的 DML 事件和 DDL 事件 2.触发器限制：执行触发器的条件，该条件必须为真才能激活触发器 3.触发器操作（主体）： 包含一些 SQL 语句和代码，它们在发出了触发器语句且触发限制的值为真时运行，也就是只有触发器的条件为真是，触发器的主体才会运行。 触发事件：即在何种情况下触发TRIGGER; 例如：INSERT, UPDATE, DELETE。 触发时间：即该TRIGGER 是在触发事件发生之前（BEFORE）还是之后(AFTER)触发，也就是触发事件和该TRIGGER 的操作顺序。 如：当触发器在执行时，如果是之前，就先执行触发器，后操作表，如果是多后，先操作表 ，后执行触发器的主体。 触发器本身：即该TRIGGER 被触发之后的目的和意图，正是触发器本身要做的事情。 例如：PL/SQL 块。 触发频率：说明触发器内定义的动作被执行的次数。即语句级(STATEMENT)触发器和行级(ROW)触发器。语句级：如数据更改100条，触发器只执行一次，这样不适合于单条的改动。行级：每一个符合条件的行，他都会去执行，常用的是行级。 语句级(STATEMENT)触发器：是指当某触发事件发生时，该触发器只执行一次； 行级(ROW)触发器：是指当某触发事件发生时，对受到该操作影响的每一行数据，触发器都单独执行一次。 如：SQL>  … FOR EACH ROW WHEN (NEW.empsal>OLD.empsal) DECLARE Sal_diff NUMBER; 如果WHEN子句中的条件得到满足，将执行BEGIN 块中的代码 触发器最常用的对象是表。 ● 创建触发器语法 CREATE [OR REPLACE] TRIGGER trigger_name {BEFORE | AFTER } {INSERT | DELETE | UPDATE [OF column [, column …]]} ON [schema.] table_name  [REFERENCING {OLD [AS] old | NEW [AS] new| PARENT as parent}]-->引用条件 [FOR EACH ROW ] [WHEN condition] trigger_body;  语法分析： 1.BEFORE 和AFTER指出触发器的触发时序分别为前触发和后触发方式，前触发是在执行触发事件之前触发当前所创建的触发器，后触发是在执行触发事件之后触发当前所创建的触发器。 2.FOR EACH ROW选项说明触发器为行触发器。行触发器和语句触发器的区别表现在：行触发器要求当一个DML语句操作影响数据库中的多行数据时，对于其中的每个数据行，只要它们符合触发约束条件，均激活一次触发器；而语句触发器将整个语句操作作为触发事件，当它符合约束条件时，激活一次触发器。当省略FOR EACH ROW 选项时，BEFORE 和AFTER 触发器为语句触发器，而INSTEAD OF 触发器则为行触发器。 3.EFERENCING 子句说明相关名称，在行触发器的PL/SQL块和WHEN 子句中可以使用相关名称参照当前的新、旧列值，默认的相关名称分别为OLD和NEW。触发器的PL/SQL块中应用相关名称时，必须在它们之前加冒号(:)，但在WHEN子句中则不能加冒号。 4.WHEN 子句说明触发约束条件。Condition 为一个逻辑表达时，其中必须包含相关名称，而不能包含查询语句，也不能调用PL/SQL 函数。WHEN 子句指定的触发约束条件只能用在BEFORE 和AFTER 行触发器中，不能用在INSTEAD OF 行触发器和其它类型的触发器中。  BEFORE触发器的工作原理：是先激活触发器后保存到Oracle数据库 AFTER触发器的工作原理：是行保存以数据库后后激活触发器 范例：以toys表为例AFTER 如果输入信息的ID为零，则不能输入 ● 每张表最多可建立12 种类型的触发器，它们是： BEFORE INSERT BEFORE INSERT FOR EACH ROW AFTER INSERT AFTER INSERT FOR EACH ROW BEFORE UPDATE BEFORE UPDATE FOR EACH ROW AFTER UPDATE AFTER UPDATE FOR EACH ROW BEFORE DELETE BEFORE DELETE FOR EACH ROW AFTER DELETE AFTER DELETE FOR EACH ROW 如果12个都创建时容易落入一个灾难，因为创建以后，只要一符合条件就会自动触发，有可能产生递归，所以触发器要适量而止。 触发器的执行顺序：     --->执行 BEFORE语句级触发器;     --->执行 BEFORE行级触发器     --->执行 DML语句     --->执行 AFTER行级触发器?     --->执行 AFTER语句级触发器 ● 触发器的限制： CREATE TRIGGER语句文本的字符长度不能超过32KB； 触发器体内的SELECT 语句只能为SELECT … INTO …结构，或者为定义游标所使用的SELECT 语句。 触发器中不能使用数据库事务控制语句 COMMIT; ROLLBACK, SVAEPOINT 语句； 由触发器所调用的过程或函数也不能使用数据库事务控制语句； 触发器中不能使用LONG, LONG RAW 类型； 触发器内可以参照LOB 类型列的列值，但不能通过 :NEW 修改LOB列中的数据； 触发器被激活时的特殊对象： :NEW  修饰符访问操作完成后列的值 :OLD  修饰符访问操作完成前列的值 特性 INSERT UPDATE DELETE OLD NULL 有效 有效 NEW 有效 有效 NULL 注：语句级触发器不能引用:OLD和:NEW的值 触发器的发、创建： SQL> CREATE OR REPLACE TRIGGER trig_sal AFTER UPDATE OF empsal ON salary_records 为 salary_records 表创建  trig-sal 触发器 ● 触发器的类型有： 模式(DDL)触发器、数据库级触发器、DML触发器 DML触发器包括：行级触发器、语句级触发器、INSTEAD OF 触发器 DDL 触发器：在模式中执行 DDL 语句时执行 数据库级触发器：在发生打开、关闭、登录和退出数据库等系统事件时执行 DML 触发器：在对表或视图执行DML语句时执行 语句级触发器：无论受影响的行数是多少，都只执行一次 行级触发器：对DML语句修改的每个行执行一次 INSTEAD OF 触发器：用于用户不能直接使用 DML 语句修改的视图 触发器被激活时的特殊对象： :NEW 和 :OLD 1. :NEW 修饰符访问操作完成后列的值 2. :OLD 修饰符访问操作完成前列的值 ● 触发器的组成部分示例 例1：为 salary_records 表创建trig-sal 触发器    CREATE OR REPLACE TRIGGER trig_sal    AFTER UPDATE OF empsal ON salary_records    … 例2：在更新 emp_sal 列之后激活触发器 CREATE OR REPLACE TRIGGER trig_sal AFTER UPDATE OF empsal ON salary_records 例3：只有在WHEN子句中的条件得到满足时，才激活trig_sal 触发器 FOR EACH ROW WHEN (NEW.empsal>OLD.empsal) DECLARE Sal_diff NUMBER; 操作： BEGIN sal_diff:=:NEW.empsal-:OLD.empsal; DBMS_OUTPUT.PUT_LINE(‘工资差额：’sal_diff); END; ● 工作原理： 1.AFTER触发器的工作原理 先保存更新到数据库，然后激活触发器 2.BEFORE触发器的工作原理 先激活触发器，后保存到更新到数据库 ● 总结： 触发器是当特定事件出现时自动执行的存储过程  触发器分为 DML 触发器、DDL 触发器和数据库级触发器三种类型 DML 触发器的三种类型包括行级触发器、语句级触发器和 INSTEAD OF 触发器   第十四章 触发器实例 触发器之实例 toys表内容：  ID TONAME   TOYPRICE ---  --      ------------------   1  a         200   2  b         100   3  c          90 有toys表上创建一个AFTER触发器：如果插入的数据的价格为0，则触动触发器，提示相关的信息 create or replace trigger trig after insert  on toys --频率 for each row  --主体 begin if(:new.toyprice=0) then  dbms_output.put_line('有一个玩具的价格为0'); end if; end; --插入一条数据启动触发器 SQL> insert into toys values(4,'水枪',0);--触动了触发器 有一个玩具的价格为0 SQL> insert into toys values(5,'游戏机',10);--没有触动触发器 已创建 1 行。 二、触发器的分类： 模式(DDL)触发器、数据库级触发器、DML触发器 最常用的是DML触发器，DML触发器分为行级触发器、语句级触发器、INSTEAD OF触发器. 1.模式(DDL)触发器:在模式中执行DDL语句时执行 2.数据库级触发器：在发生打开、关闭、登录和退出数据库等系统事件时执行。 3.DML触发器：在对表或视图执行DML语句时执行 4.语句级触发器：无论受影响的行数是多少，都只执行一次 5.行级触发器：对DML语句修改的每个行执行一次 6.INSTEAD OF触发器：用于用户不能直接使用DML语句修改的视图。 范例一：行级触发器 创建一个表A 包含ID 和 NAME 两个字段 再创建一个序列 create sequence seq;  创建一个触发器：当给A表中的ID插入值，ID值要用序列中的值 create or replace TRIGGER trig before insert or update of id on A for each row begin --如果插入ID值就用序列值代替 --inserting 谓词，插入 if inserting then select seq.nextval into :new.id from dual; else   dbms_output.put_line('不能修改ID的值'); end if; end; 给A表中插入值：insert into A values(10,'jack'); 查看表：  select * from A;     ID NAME ------ ----------      1 jack------->产生的ID并不是10，而是1 进行修改 ：update A set id=5 where id=1;   不能修改ID的值 再次查看 ： select * from A;    ID NAME ----- ----------     5 jack 表中的数据发生了变化，这是因为触发器的具体功能还没有实现，我们可以引发一个应用程序异常 create or replace TRIGGER trig before insert or update of id on A for each row-->行级触发器 begin if inserting then select seq.nextval into :new.id from dual; else   dbms_output.put_line('不能修改ID的值');   raise_application_error(20003,'不能修改ID的值'); end if; end; 范例二：语句级触发器 创建一个触发器： create or replace trigger trig  after insert or delete or update on toys begin if inserting then     dbms_output.put_line('在表中执行了插入操作'); elsif updating then    dbms_output.put_line('在表中执行了更新操作'); else    dbms_output.put_line('在表中执行了 删除操作'); end if; end; 触发器创建完成之后，对表进行一系列操作 如：  SQL> update toys set toyname='x ' where toyname='a';  在表中执行了更新操作  SQL> delete from toys;  在表中执行了 删除操作 范例二：INSTEAD OF触发器 SQL> CREATE OR REPLACE TRIGGER upd_ord_view INSTEAD OF UPDATE ON ord_view FOR EACH ROW BEGIN UPDATE order_master SET vencode=:NEW.vencode  WHERE orderno = :NEW.orderno; DBMS_OUTPUT.PUT_LINE(‘已激活触发器'); END; 范例三：模式触发器 创建一个表用来记录： create table dropTable(objName varchar2(20),objType varchar2(20),dropTime date); 创建一个触发器： CREATE OR REPLACE TRIGGER trig  AFTER DROP ON SCHEMA BEGIN   insert into dropTable values(ORA_DICT_OBJ_NAME,ORA_DICT_OBJ_TYPE,SYSDATE); END; 然后对一个表进行创建删除操作： SQL> create table B(id int); 表已创建。 SQL> drop table B; 表已删除。 在dropTable表中查看操作记录 SQL> select * from dropTable; OBJNAME              OBJTYPE              DROPTIME -------------------- -------------------- -------------- B                    TABLE                29-11月-10 触发器的禁用和启用 SQL> ALTER TRIGGER aiu_itemfile DISABLE; SQL> ALTER TRIGGER aiu_itemfile ENABLE; 删除触发器: SQL> DROP TRIGGER aiu_itemfile; 查看有关触发器的信息 USER_TRIGGERS 数据字典视图包含有关触发器的信息 SQL> SELECT TRIGGER_NAME FROM USER_TRIGGERS WHERE TABLE_NAME='EMP'; SQL> SELECT TRIGGER_TYPE, TRIGGERING_EVENT, WHEN_CLAUSE FROM USER_TRIGGERS WHERE TRIGGER_NAME = 'BIU_EMP_DEPTNO'; 总结： 重点是DML触发器 INSTEAD OF 触发器原理：当我们执行UPDATE INSERT 时，这条语句并不被执行，而是执行触发器里边的语句，相当于回滚，如别人要在自己的数据库中执行操作，我们就可以达到一个限制。他主要是对视图进行操作的，如果不对视图操作没什么意义。   第十五章 数据库设计和三大范式  目标： 1.了解设计数据库的步骤 2.掌握如何绘制数据库的E-R图 3.理解数据库的规范化－三大范式 ● 为什么需要设计数据库？ 良好的数据库设计可以： 1.节省数据的存储空间 2.能够保证数据的完整性 3.方便进行数据库应用系统的开发 糟糕的数据库设计： 1.数据冗余、存储空间浪费 2.内存空间浪费 3.数据更新和插入的异常 ● 软件项目开发周期   现实世界-->建模-->信息世界-->模型转换-->数据库世界-->规范化为数据库 1.需求分析阶段：分析客户的业务和数据处理需求; 2.概要设计阶段：设计数据库的E-R模型图，确认需求信息的正确和完整; 3.详细设计阶段：将E-R图转换为多张表，进行逻辑设计，并应用数据库设计的三大范式进行审核; 4.代码编写阶段：选择具体数据库进行物理实现，并编写代码实现前端应用; 5.软件测试阶段：…… 6.安装部署：…… ● 设计数据库的步骤 1.收集信息：   与该系统有关人员进行交流、坐谈，充分理解数据库需要完成的任务。 如：BBS论坛的基本功能： 用户注册和登录，后台数据库需要存放用户的注册信息和在线状态信息； 用户发贴，后台数据库需要存放贴子相关信息，如贴子内容、标题等； 论坛版块管理：后台数据库需要存放各个版块信息，如版主、版块名称、贴子数等； 2.标识对象（实体－Entity）   标识数据库要管理的关键对象或实体  如：实体一般是名词： 用户：论坛普通用户、各版块的版主。 用户发的主贴 用户发的跟贴（回贴） 版块：论坛的各个版块信息 3.标识每个实体的属性（Attribute） 如：论坛用户：呢称、密码、电子邮件、生日、性别、用户的等级、备注信息、注册信息、状态、积分等 主贴：发贴人、发贴表情、回复数量、标题、正文、点击数、状态、最后回复时间。 回贴：帖子编号、回帖人、回帖表情、标题、正文、回帖时间、点击数。 版块：版块名称、本版格言、点击率、发贴数 4.标识对象之间的关系（Relationship） 如：跟贴和主贴有主从关系：我们需要在跟贴对象中表明它是谁的跟贴； 版块和用户有关系：从用户对象中可以根据版块对象查出对应的版主用户的情况； 主贴和版块有主从关系：需要表明发贴是属于哪个版块的； 跟贴和版块有主从关系：需要表明跟贴是属于哪个版块的； 5.绘制E-R（Entity－Relationship）实体关系图  如用矩形表示实体，一般是名词 用椭圆表示属性，一般也是名词 用棱形表示实体间的关系，一般是动词 如： 映射基数：其中关系包括：一对一、一对多、多对一、多对多 如图： 6.将E-R图转换为表 将各实体转换为对应的表，将各属性转换为各表对应的列 标识每个表的主键列，需要注意的是：没有主键的表添加ID编号列，它没有实际含义，用于做主键或外键，例如用户表中的“UID”列，版块表中添加“SID”列，发贴表和跟贴表中的“TID”列  在表之间建立主外键，体现实体之间的映射关系  ● 数据规范化 仅有好的RDBMS并不足以避免数据冗余，必须在数据库的设计中创建好的表结构 Dr E.F.codd 最初定义了规范化的三个级别，范式是具有最小冗余的表结构。这些范式是： 第一范式(1st NF －First  Normal Fromate) 第二范式(2nd NF－Second  Normal Fromate) 第三范式(3rd NF－ Third  Normal Fromate) 1.第一范式 第一范式的目标是确保每列的原子性 如果每列都是不可再分的最小数据单元（也称为最小的原子单元），则满足第一范式（1NF） 如在一个表中的一列的值为：中国北京，这就违反了第一范式，可以分为中国 和 北京 如图： 2.第二范式 如果一个关系满足1NF，并且除了主键以外的其他列，都依赖与该主键，则满足第二范式（2NF）  第二范式要求每个表只描述一件事情。每列都和主键相关 如有一个表其字段为： 订单编号、产品编号、订购日期、价格。这就违反了第二范式 这个表可以分为两个表其字段分别为： 第一个表字段为：订单编号、订购日期 第二个表字段为：产品编号、价格 3.第三范式 如果一个关系满足2NF，并且除了主键以外的其他列都不传递依赖于主键列，则满足第三范式（3NF）  如在一个表中有3个字段分别为：A B C 本来A与C没有任何关系，但是他们可以通过B建立起来关系。 存在这样关系的字段是不能同时存在于一个表中的，也就是要直接关联的不要间接关联的。 ● 规范化实例 假设某建筑公司要设计一个数据库。公司的业务规则概括说明如下： 公司承担多个工程项目，每一项工程有：工程号、工程名称、施工人员等 公司有多名职工，每一名职工有：职工号、姓名、性别、职务（工程师、技术员）等 公司按照工时和小时工资率支付工资，小时工资率由职工的职务决定（例如，技术员的小时工资率与工程师不同） 我们可以直接制作一张表所有的信息都包含在其中，但是如果这样表中包含大量的冗余，可能会导致数据异常 更新异常：       例如，修改职工号=1001的职务，则必须修改所有职工号=1001的行 添加异常：      若要增加一个新的职工时，首先必须给这名职工分配一个工程。或者为了添加一名新职工的数据，先给这名职工分配一个虚拟的工程。（因为主关键字不能为空） 删除异常：       例如，1001号职工要辞职，则必须删除所有职工号＝1001的数据行。这样的删除操作，很可能丢失了其它有用的数据 采用一个表的设计结构，虽然很容易产生工资报表，但是每当一名职工分配一个工程时，都要重复输入大量的数据。这种重复的输入操作，很可能导致数据的不一致性。 那么我们可以应用范式规范化设计 可以设计4张表来达到目的： 第1张表的字段包括：工程号、工程名称---->以工程号为主键 第2张表的字体包括：职工号、姓名、职务--->以职工号为主键 第3张表的字段包括：职务、小时工资率 第4张表的字段包括：工程号、职工号、工时---->以工程号和职工号同时为主键，这是一个联合主键 ● 规范化和性能的关系  1.为满足某种商业目标，数据库性能比规范化数据库更重要 2.通过在给定的表中添加额外的字段，以大量减少需要从中搜索信息所需的时间 3.通过在给定的表中插入计算列（如成绩总分），以方便查询 4.进行规范化的同时，还需要综合考虑数据库的性能。 ● 总结 在需求分析阶段，设计数据库的一般步骤为：收集信息、标识对象、标识每个对象的属性、标识对象之间的关系。 在概要设计阶段和详细设计阶段，设计数据库的步骤为： 1.绘制E-R图 2.将E-R图转换为表格 3.应用三大范式规范化表格 为了设计结构良好的数据库，需要遵守一些专门的规则，称为数据库的设计范式。 第一范式（1NF）的目标：确保每列的原子性。 第二范式（2NF）的目标：确保表中的每列，都和主键相关 。 第三范式（3NF）的目标：确保每列都和主键列直接相关，而不是间接相关 。 在制作数据库时冗余是不可能是完全避免的，而且适当的冗余还可以提高性能。   第十六章 数据库的备份与恢复简介 数据库的备份与恢复简介 备份是数据库中数据的副本，它可以保护数据在出现意外损失时最大限度的恢复 Oracle数据库的备份包括两种类型：物理备份和逻辑备份 物理备份是对数据库的操作系统物理文件（如数据文件、控制文件和日志文件等）的备份 逻辑备份是对数据库逻辑组件（如表、视图和存储过程等数据库对象）的备份 ● 故障类型 导致数据库操作终止的故障包括四种类型：语句故障、用户进程故障、实例故障、介质故障 在执行 SQL 语句过程中发生的逻辑故障可导致语句故障。如果用户编写的 SQL 语句无效，就会发生逻辑故障 当用户程序出错而无法访问数据库时发生用户进程故障。导致用户进程故障的原因是异常断开连接或异常终止进程   当 Oracle 的数据库实例由于硬件或软件问题而无法继续运行时，就会发生实例故障 在数据库无法正确读取或写入某个数据库文件时，会发生介质故障   ● 导出和导入实用程序  导出和导入实用程序用于实施数据库的逻辑备份和恢复 导出实用程序将数据库中的对象定义和数据备份到一个操作系统二进制文件中 导入实用程序读取二进制导出文件并将对象和数据载入数据库中 导出和导入实用程序的特点有： 可以按时间保存表结构和数据 允许导出指定的表，并重新导入到新的数据库中 可以把数据库迁移到另外一台异构服务器上 在两个不同版本的Oracle数据库之间传输数据 在联机状态下进行备份和恢复 可以重新组织表的存储结构，减少链接及磁盘碎片 使用以下三种方法调用导出和导入实用程序： 1.命令参数行、交互提示符、参数文件 命令参数行：在命令行指定执行程序的参数和参数值。 交互提示符：以交互的方式提示用户逐个输入参数的值。  参数文件：允许用户将运行参数和参数值存储在参数文件中，以便重复使用参数 ● 导出和导入数据库对象的四种模式是： 1.完全数据库：导出和导入整个数据库中的所有对象 2.表：导出和导入一个或多个指定的表或表分区 3.用户：导出和导入一个用户模式中的所有对象 4.表空间：导出和导入一个或多个指定的表空间中的所有对象 导出实用程序有以下常用命令参数： --------------------------------------------------------------------------------------------------------------      参数                       说明 --------------------------------------------------------------------------------------------------------------   USERID        确定执行导出实用程序的用户名和口令   BUFFER        确定导出数据时所使用的缓冲区大小，其大小用字节表示   FILE          指定导出的二进制文件名称，默认的扩展名是.dmp   FULL          指定是否以全部数据库方式导出，只有授权用户才可使用此参数   OWNER         要导出的数据库用户列表   HELP          指定是否显示帮助消息和参数说明   ROWS          确定是否要导出表中的数据   TABLES        按表方式导出时，指定需导出的表和分区的名称   PARFILE       指定传递给导出实用程序的参数文件名   TABLESPACES   按表空间方式导出时，指定要导出的表空间名 ----------------------------------------------------------------------------------------------------------------- 格式: 按用户方式导出数据:exp scott/tiger@accp file=scott_back owner=scott 按表方式导出数据:exp scott/tiger@accp tables=(emp, dept) file=scott_back_tab 按表空间方式导出数据:exp scott/tiger@accp tables=(emp, dept) file=scott_back_tab 使用参数文件导出数据:exp system/aptech parfile='C:\\parameters.txt' ● 导入实用程序有如下常用命令参数： -----------------------------------------------------------------------     参数              说明 -----------------------------------------------------------------------   USERID   指定执行导入的用户名和密码   BUFFER   指定用来读取数据的缓冲区大小，以字节为单位   COMMIT   指定是否在每个数组（其大小由BUFFER参数设置）插入后进行提交   FILE       指定要导入的二进制文件名   FROMUSER 指定要从导出转储文件中导入的用户模式   TOUSER   指定要将对象导入的用户名。FROMUSER与TOUSER可以不同   FULL      指定是否要导入整个导出转储文件   TABLES   指定要导入的表的列表   ROWS     指定是否要导入表中的行   PARFILE  指定传递给导入实用程序的参数文件名，此文件可以包含这里列出的所有参数   IGNORE   导入时是否忽略遇到的错误，默认为N   TABLESPACES 按表空间方式导入，列出要导入的表空间名 ------------------------------------------------------------------------ 格式： 将整个文件导入数据库：imp accp/accp@accp file=item_back.dmp ignore=y full=y 将scott用户的表导入到martin用户： imp system/aptech@accp file=scott_back fromuser=scott touser=martin tables=(emp,dept) 使用参数文件导入数据：imp system/oracle parfile='C:\\parameters.txt' 数据库在运行期间需要不断进行备份，万一假设每户崩溃了，可以从数据中恢复数据。Oralce在安装完成之后可以使用两个命令进行数据库的备份与恢复。 数据库的备份：exp 数据库的恢复：imp  如我们在D盘上新建一个data的文件夹保存所要备份的数据，如果要备份则需要使用命令行方式，进入到d:\\data文件夹之中。进入到data文件夹之后，执行exp命令，会提示用户名和口令（scott/tiger）,进入到帐户以后，我们看一下在这个帐户下都有那些表（SELECT * FROM tab）,我们要把些所有的表都备份，都先默认状态，回车即可，一直等到所有的表都导出完成之后，备份就完成了。  检验备份的效果，我们把数据库中的表全部表删除，然后再进行恢复。  全部删除以后，使用imp命令将备份的数据全部恢复（过程中都先yes）。   第十七章 导入导出工具 常用工具 EXPDP和IMPDP orale10G引入了最新的数据泵（DATA dump)技术，它使得DBA或应用程序开发人员可以 将数据库的元数据（对象定义）和数据快速转移到另一个ORacle数据库中。 数据泵导出和导入的作用: 1.数据泵导出和导入可以实现逻辑备份和逻辑恢复。 2.数据泵导出和导入可以在数据库用户之间移动对象。 3.使用数据泵导入（impdp)可以在数据库之间移动对象。 4.使用数据泵导入可以实现表空间搬移 数据泵导入与传统的导出导入的区别： 在oracle10G之前，传统的导出和导入分别使用exp工具和IMP工具来完成。 10G保留了传统的EXP和IMP工具，而且还提供了数据泵EXPDP和IMPDP。 由于数据泵EXPDP和IMPDP 的速度要优于EXP和IMP工具，所以oracle建议使用EXPDP和IMPDP工具。 使用注意事项： 1.EXP和IMP是客户端工具程序，它们既可以在客户端使用，也可以在服务器端使用。 2.EXPDP和IMPDP是服务器端的工具程序，它们只能在oracle服务器端使用。而不能在oracle客户端使用。 3.两个工具的导出只能用各自对应的导入工具。 --1导出表 各参数说明 1.scott/tiger 指定由哪个一有户导出、 2.directory:指定导出文体的路径 3.dumpfile:指定导出的文件名 4.tables:指定导出的表的集合 导出操作，先由管理员创建目录并授于该目录的读写权限给某一个用户 如下： sql>conn sys/system as sysdba sql>create directory dump_dir as  'd:\\dump'; sql>grant read,write  on directory  dump_dir to scott; sql>grant read,write on directory dump_dir to sun; sql>grant read,write on directory dump_dir to mytest; 进入DOS  命令行执行如下操作 1.expdp scott/tiger  directory=dump_dir dumpfile=Tab.dmp tables=dept,emp  2.导出方案 导出方案是指将一个或多个方案的所有对象结构及数据存储到转储文件中，导出方案是通过使用 schemas选 项来完成的。 普通用户只能导出自身方案，如果要导出其他方案，由要求用户必须具有DBA角色或者EXP_FULL_DATABASE角色 ，下面经导出system方案和scott方案的所有对象为例， 说明导出方案的方法 expdp system/system   DIRECTORY=dump_DIR dumpFIle=schema.dmp schemas=system,scott 3.导出表空间 导出表空间是指将一个或多个表空间的所有对象及数据存储到转储文件 中，导出表空间是通过使用tablespaces选 项来完成的。需要注意导出 表空间要求用户必须具有DBA或EXP_FULL_DATABASE角色。示例如下 expdp  system/system DIRECTORY=dump_dir dumpFIle=tablespace.dmp tablespaces =users,system 4.导出数据库 导出数据库是指将数据库所有对象及数据存储到转储文件中，导出数据库是通过使用FULL选项来完成的。 要求用户具有DBA和Exp_FULL_DATABASE角色 需要注意：当导出数据库时，不会导出sys\\ordsys\\ordplugins\\ctxsys\\MDSYS\\LBACSYS以及XDB等方案的对象。 expdp system/system DIRECTORY=DUMP_DIR DUMPFILE=FULL.DMP FULL=Y 参数文件的使用： parm.txt tables=dept,emp Directory=dump dumpfile=tab.dmp expdb scott/tiger parfile=d:\\dump\\parm.txt; 使用IMPDP（35个参数) 数据泵导入包括：导入表、导入方案、导入表空间、导入数据库等四种模式。 需要注意的是：转储文件被存放在DIRECTORY对象所对应的OS目录中，而不能直接指定转储文件所在的OS目录。 1.导入表： 普通用户可以将导入其自身的方案。但如果以其他用户身份导入表，则要求该用户必须具有imp_full_Database或dba角色。 当导入表时，既可以将表导入到源方案中，也可以将表导入到其他方案中。如果要将表导入到其他方案中，则必须指定remap_schema选项。下面 以表dept,emp导入自身方案为例 impdp scott/tiger DIRECTORY=dump_dir dumpfile=TAB.DMP SCHEMAS=scott 导入到其他方案中 impdp system/system directory=dump_dir dumpFile=TAB.DMP TABLES=scott.dept,scott.emp  SCHEMAS=scott REMAP_SCHEMA=scott:system impdp system/system directory=dump_dir dumpFile=TABS.DMP TABLES=scott.dept,scott.emp   remap_schema=scott:sun impdp sun/sun directory=dump_dir dumpfile=tab.dmp tables=emp remap_schema=scott:sun--成功 --使用系统帐户 impdp system/system directory=dump_dir dumpfile=tab.dmp leremap_schema=scott:sun--成功 2.导入方案： impdp scott/tiger directory=dump_dir dumpfile=schema.dmp schemas=scott impdp system/system directory=dump_dir dumpfile=schema.dmp schemas=scott REMAP_schema=scott:system 3.导入表空间 impdp system/system directory=dump_dir dumpfile=tablespace.dmp TABLESPACES=USERS,SYSTEM 4.导入数据库 impdp system/system directory=dump_dir dumpFile=full.dmp full=y 使用EXP和IMP实现导出导入 调用：EXP 当在客户端使用该工具时，必须要带有连接字符串;当在服务器端使用时 可以不带连接字符串。导出包括：导出表、方案、数据库三种模式 1.导出表 当导出表时，默认情况下导出相应表的所有索引，触发器、约束。 下面以system用户和scott用户分别导出scott.dept和scott.emp为例 exp system/system tables=scott.dept,scott.emp file=tab1.dmp exp scott/tiger tables=dept,emp file=tab2.dmp 2.导出方案： exp system/system owner =scott file=schema1.dmp exp scott/tiger file=schema2.dmp 3.导出数据库，使用FULL选项 exp system/system Full=y file=full.dmp 导入:imp 1.导入表 imp scott/tiger file=tab2.dmp tables=dept,emp imp system/system file=tab2.dmp tables=dept,emp fromuser=scott touser=system 2.导入方案: imp scott/tiger file=schema2.dmp imp system/system file=schema2.dmp fromuser=scott touser=system 3.导入数据库 imp system/system file=full.dmp full=y imp help=y--可以查看帮指令帮助信息 第十八章 数据库归档方式   Oracle 数据库可以运行在两种归档方式： 非归档日志方式归档日志方式: 非归档日志方式可以避免实例故障，但无法避免介质故障。在此方式下，数据库只能实施冷备份 归档日志方式产生归档日志，用户可以使用归档日志完全恢复数据库 非归档日志方式下数据库的工作原理： 表空间脱机--->备份表空间---->恢复表空间---->表空间联机 归档日志方式下数据库的工作原理： 日志文件1填满 --->准备向日志文件2写入信息 --->备份日志文件2--->向日志文件2写入信息--->清空日志文件 2  配置数据库在归档日志方式下运行，包括以下三个步骤：  确保数据库当前不处于归档方式--->设置相关数据库初始化参数--->在归档日志方式下启动数据库  查看当前数据库的归档方式： SQL> conn sys/system as sysdba 已连接。 SQL> archive log list 数据库日志模式             非存档模式 自动存档             禁用 存档终点            USE_DB_RECOVERY_FILE_DEST 最早的联机日志序列     37 当前日志序列           39 数据库的日志归档方式有两种： 1.自动归档：自动归档对非活动日志文件文件进行自动归档 2.手动归档：手动归档允许用户手动归档非活动日志文件文件的已填充组 获取归档日志信息 可以通过数据字典视图查看归档日志信息 V$ARCHIVE_DEST － 显示当前所有归档日志存储位置及其状态 V$ARCHIVE_LOG － 显示历史归档日志信息 SQL> SELECT DEST_ID,NAME,ARCHIVED       FROM V$ARCHIVED_LOG; SQL> SELECT DEST_ID,DEST_NAME,STATUS,DESTINATION FROM V$ARCHIVE_DEST WHERE STATUS='VALID'; 总结： 数据库备份用于保护数据库中的数据，有两种类型的备份：物理备份和逻辑备份 导致数据库操作中止的故障类型有：语句故障、用户进程故障、实例故障和介质故障 Oracle 提供导出和导入实用程序实施数据库的逻辑备份 导出导入实用程序有四种工作模式：完全数据库、表、用户和表空间 数据库可在两种方式下运行：非归档日志方式和归档日志方式   JDBC部分 第一章 jdbc简介 JDBC(java database connectivity)是JAVA存取数据库系统的一个解决方案 以前使用同一个java程序连接数据库时，不同数据库厂商都有各自不同的API，也就是你写的程序语言要想与我们的数据库相连接，必须实现我们的这个API，所以各个数据库对要实现自己都有一个要求。因为主动权一直都是由数据库厂商把握，所以早期的java程序员要知道各个数据库的API程序。 随着JAVA的逐渐发展，开始掌握了主动权，开始自己来实现这个API。也就是你们数据库厂商想想和我的这个程序相连着，必须实现我们自己提供的这个API。 JDBC就是现在这个接口不用数据库厂商来做了，sun公司自己推出一个API接口， 由数据库厂商来实现，那个数据库要和java相连，必须实现sun公司推出的这个接口。所以对于现在java程序员来说，只需要知道一个API接口就可以了。实现一个写一个java程序适应所有数据库的目的。 JDBC的本质就是一个与数据库操作无关的java操作接口。 JDBC数据库驱动程序依实现方式可以分为四个类型： Type 1：JDBC-ODBC Bridge Type 2：Native-API Bridge Type 3：JDBC-middleware Type 4：Pure Java Driver 前3种使用桥连接，第4种是纯的java连接。 怎么实现java与数据库的连接 java与Oracle相连时，需要的信息有: 1.Oracle数据库驱动  如：Oracle数据库的驱动是:(oracle.jdbc.driver.OracleDriver) 2.提供JDBC URL JDBC URL定义了连接数据库时的协议、子协议、数据源识别。 协议：子协议：数据源识别 “协议”在JDBC中总是jdbc开始；“子协议”是桥接的驱动程序或是数据库管理系统名称，使用MySQL的话是“mysql”;“数据源识别”标出找出数据库来源的地址与连接端口。例如，MySQL的JDBC URL编写如下： jdbc:mysql://主机名:端口/数据库名称?参数=值&参数=值 主机名称可以是本机 localhost或是其他连接主机，连接端口为3306,假如要连接 demo数据库，并指明用户名称与密码，如下： jdbc:mysql://localhost:3306/demo?user=root&password=123 如果要使用中文存取的话，还必须给定参数useUnicode及characterEncoding，表明 是否使用Unicode，并指定字符编码方式，例如： jdbc:mysql://localhost:3306/demo?user=root&password=123&useUnicode =true&characterEncoding=UTF-8 数据源识别符是标出数据源来源的地址与连接连接端口 如：(jdbc:oracle:thin:@localhost:1521:orcl) 这是一个Oracle数据库的URL信息。 用户 如:(scott) 密码 如: (tiger) 连接步聚： 第1步：动态加载JDBC驱动程序(只需要执行一次) 首先必须通过java.lang.Class类的forName()动态加载驱动程序类，并向DriverManager注册JDBC驱动程序(驱动程序会自动通过DriverManager.registerDriver()方法注册)。 如：一个加载Oracle的驱动程序类的程序片段如下： try{ Class.forName(“oracle.jdbc.driver.OracleDriver”); }catch(ClassNotFoundException e){ System.out.println(“找不到驱动程序类”); } 第2步：利用DriverManager类中的getConnection()方法获得URL、用户、密码等信息。 如：DriverManager.getConnection(url, user, pwd); getConnection()一共有三种类型，我们常用的是带有三个参数的。他返回的是Connection类型 static Connection getConnection(String url)            试图建立到给定数据库 URL 的连接。  static Connection getConnection(String url, Properties info)            试图建立到给定数据库 URL 的连接。  static Connection getConnection(String url, String user, String password)            试图建立到给定数据库 URL 的连接。  所以我们可以定义一个Connection类型的变量来接受获得的信息，如： Connecton conn=DriverManager.getConnection(url, user, pwd); 范例： public class dataSourse {  //驱动程序名  public String driver=\"oracle.jdbc.driver.OracleDriver\";  //URL信息  public String url=\"jdbc:oracle:thin:@localhost:1521:orcl\";  //用户名  public String user=\"scott\";  //密码  public String pwd=\"abcd\";  public Connection conn=null;  //获取连接的方法 注:Connection()是一个接口，所以这是一个接口类型的方法  public Connection getConnection() throws ClassNotFoundException, SQLException{   //动态加载驱动程序    Class.forName(driver);//加载驱动 Class类的forName()方法    conn=DriverManager.getConnection(url, user, pwd);   return conn;   }   public static void main(String[] args) throws ClassNotFoundException, SQLException {   //创建对象   dataSourse ds=new dataSourse();   Connection con=ds.getConnection();   //输出连接对象   System.out.println(con);  } }   第二章 连接数据库 我们可以把驱动、URL、帐户、密码等信息以一个字符串的形式定义到一个类中，可以我们平时不这么做，而是将这些信息放到一个属性文件中。属性文件是以properties为扩展名的，如我们可以新建一个oracl.properties文件，里边在放的信息内容为： #jdbc的配置文件 注：属性文件中是以#作为注释开始的 driver=oracle.jdbc.driver.OracleDriver url=jdbc\\:oracle\\:thin\\:@localhost\\:1521\\:orcl pwd=abcd user=scott 然后我们可以在类中加载这个文件，加载properties文件有两个方法，一是利用构造器，二是利用静态区块，利用构造器是因为利用构造器在一创建对象时他就可以扫行了。而利用静态区块也是在创建对象时执行，而且只执行一次，我们平时常用构造进行器加载。 范例：定义一个接口 //用户获得数据库连接和关闭数据库的API接口 public interface IdataSource {      //获得数据库连接      public Connection getConnection() throws SQLException;      //关闭数据库连接      public void closeConnection(Connection conn)throws SQLException;      } 写一个工具类： public class dataSource implements IdataSource {      //获取连接所需要的信息      public String driver=\"\";      public String url=\"\";      public String user=\"\";      public String pwd=\"\";      //在构造器初始化时。加载属jdbc.propertied文件，获取相关信息      public dataSource(){      //创建properties属性文件对象      Properties pro=new Properties();       try {      //加载属性文件      pro.load(new FileInputStream(\"D:\\\\jdbc.properties\"));//文件所在路径      //通过Properties对象的getProperty()方法获得相应的值       driver=pro.getProperty(\"driver\");      url=pro.getProperty(\"url\");      user=pro.getProperty(\"user\");      pwd=pro.getProperty(\"pwd\");      try {      //动态加载驱动      Class.forName(driver);         } catch (ClassNotFoundException e) {             e.printStackTrace();         }        } catch (FileNotFoundException e) {            e.printStackTrace();        } catch (IOException e) {      e.printStackTrace();      }   } //获取数据库连接 public Connection getConnection() throws SQLException{      return DriverManager.getConnection(url, user, pwd);;    }  //关闭数据库连接  public void closeConnection(Connection conn)throws SQLException{            if(conn!=null&&!conn.isClosed()){          conn.close();         }     } } 获得Connection对象后，可以使用isClosed()方法测试与数据库的连接是否关闭，在操作完数据库之后 ，如果确定不在需要连接，则必须用close()方法来关闭与数据库的连接，以释放连接时相关的必要资源。   第三章 常用数据库的驱动程序和JDBC URL  ● Oracle 数据库 :  驱动程序包名： ojdbc14.jar  驱动类的名字： oracle.jdbc.driver.OracleDriver  JDBC URL ： jdbc:oracle:thin:@ dbip:port:databasename  说明：驱动程序包名有可能会变  JDBC URL 中黑色字体部分必须原封不动的保留，为该驱动识别的 URL 格式。红色字体部分需要根据数据库的安装情况填写。其中各个部分含义如下：  dbip – 为数据库服务器的 IP 地址，如果是本地可写： localhost 或 127.0.0.1 。  port – 为数据库的监听端口，需要看安装时的配置，缺省为 1521 。  databasename – 为数据库的 SID ，通常为全局数据库的名字。  举例如果要访问本地的数据库 allandb ，端口 1521 ，那么 URL 写法如下：  jdbc:oracle:thin:@localhost:1521:allandb  ● SQL Server 数据库  驱动程序包名： msbase.jar mssqlserver.jar msutil.jar  驱动类的名字： com.microsoft.jdbc.sqlserver.SQLServerDriver  JDBC URL ：  jdbc:microsoft:sqlserver:// dbip:port;DatabaseName=databasename  说明：驱动程序包名有可能会变  JDBC URL 中黑色字体部分必须原封不动的保留，为该驱动识别的 URL 格 式。红色字体部需要根据数据库的安装情况填写。其中各个部分含义如下：  dbip – 为数据库服务器的 IP 地址，如果是本地可写： localhost 或 127.0.0.1 。  port – 为数据库的监听端口，需要看安装时的配置，缺省为 1433 。  databasename – 数据库的名字 。  举例如果要访问本地的数据库 allandb ，端口 1433 ，那么 URL 写法如下：  jdbc: microsoft: sqlserver:@localhost:1433; DatabaseName =allandb  ● MySQL 数据库  驱动程序包名： mysql-connector-java-5.1.7-bin.jar  驱动类的名字： com.mysql.jdbc.Driver  JDBC URL ： jdbc:mysql:// dbip:port/databasename  说明：驱动程序包名有可能会变  JDBC URL 中黑色字体部分必须原封不动的保留，为该驱动识别的 URL 格式。红色字体部需要根据数据库的安装情况填写。其中各个部分含义如下：  dbip – 为数据库服务器的 IP 地址，如果是本地可写： localhost 或 127.0.0.1 。  port – 为数据库的监听端口，需要看安装时的配置，缺省为 3306 。  databasename – 数据库的名字 。  举例如果要访问本地的数据库 allandb ，端口 1433 ，那么 URL 写法如下：  jdbc:mysql://localhost:3306/allandb    第四章 连接池 数据库连接的取得是一个非常消耗时间和资源的动作。取得一个数据库的连接包括： 建立Socket connection、交换数据（用户密码验证和相关的参数）、数据库初始会话（Session）、日志（logging）、分配行程(Proess)...... 如进行数据库连接动作很频繁，则要考虑到重复使用连接的需求，以节省在获得连接时的时间和资源，通常会实现一个连接池。如果有了连接池，那么我们有需要时可以从池中获得 ，不需要时就将连接放回到池中，而不是直接关闭连接。使用ArrayList来实现连接池。 范例：实现一个简单的数据库连接池 接口： public interface IdataSource {       //获得连接       public  Connection getConnection() throws SQLException;      //关闭连接 需要关闭其对象      public  void closeConnection(Connection connection, Statement stmt,    ResultSet rs)throws SQLException;  } 为什么这里有三个参数？ 当我们使用单一连接时，关闭连接的时候自动会把所有使用的对象全部关掉，现在使用连接池，有时关有时是存着不关的，可是如果不关，他里面的对象还存在，一直占着资源，所以我们要手动将他连带的对象关掉，如执行语句的对象和结果集，所以这里有三个参数  这里要注意一个问题，关闭他们时是有一个顺序的，关闭的先后顺序是：Result-->Statement-->Connection 现在创建一个连接池： public class ConnectioPool implements IdataSource {  public String driver=\"\";//驱动  public String url=\"\";//jdbc URL  public String user=\"\";//用户  public String pwd=\"\";//密码  private int max;//连接池中允许存放的最大连接数  //用ArrayList实现连接池  List<Connection> pool=new ArrayList<Connection>();  //在构造器初始化时，加载到jdbc.propertied 属性文件，获取相关信息  public ConnectioPool (){   //创建Properties属性文件对象   Properties pro=new Properties();   //加属性文件   try {    pro.load(new FileInputStream(\"D:\\\\jdbc.properties\"));    //通过Properties对象的getProperty()方法获得相应的值    driver=pro.getProperty(\"driver\");    url=pro.getProperty(\"url\");    user=pro.getProperty(\"user\");    pwd=pro.getProperty(\"pwd\");    max=Integer.parseInt(pro.getProperty(\"poolsize\"));    //加载驱动程序类    Class.forName(driver);       }catch (ClassNotFoundException e) {     e.printStackTrace();    }    catch (FileNotFoundException e) {    e.printStackTrace();   } catch (IOException e) {    e.printStackTrace();   }  }  //线程的安全关闭Connection  public synchronized void closeConnection(Connection connection, Statement stmt, ResultSet rs) {   // 注意：关闭和先后顺序 rs stmt connection   if(rs!=null){    try {     rs.close();    } catch (SQLException e) {     // TODO Auto-generated catch block     e.printStackTrace();    }   }   if(stmt!=null){    try {     stmt.close();    } catch (SQLException e) {     e.printStackTrace();    }   }   //如果池中的Connection达到了所允许的最大数，   if(pool.size()==max){    //真正关闭Connection    try {     connection.close();    } catch (SQLException e) {      e.printStackTrace();    }   }else{    //连接池中的Connection没有达到所允许的最大值，将Connection放入池中    pool.add(connection);   }  }     //线程安全获得Connecton  public synchronized Connection getConnection() throws SQLException{   //如果池没有Connection   if(pool.size()==0){    return DriverManager.getConnection(url,user,pwd);   }else{    //连接池中有空闲的 的Connection，则从池中取出Connection      return pool.remove(pool.size()-1);   }  } } 第三方连接池 dbcp: DBCP是apache下面的一个开源的数据库连接池 ,tomcat自带 c3p0(推荐): C3P0是Hibernate3.0默认的自带数据库连接池  proxool(推荐) : proxool连接池是sourceforge下的一个开源项目,这个项目提供一个健壮、易用的连接池，最为关键的是这个连接池提供监控的功能，方便易用，便于发现连接泄漏的情况。     第五章 数据操作-创建表  数据操作之创建表 Connection对象是Java连接的代表对象，接下来要执行SQL语句的话，必须获java.sql.Statement对象，他是JAVA中的一个SQL 叙述的具体代表对象，可以使用Connection的createStatement()来建立Statement对象： 如: Connection conn=new Connection(); Statement stmt=conn.createStatement(); 获得他的对象后，可以使用executeUpdate()、executeQuery()等方法来执行SQL语句，executeUpdate()主要是用来执行CREATE table ,INSERT,DROP table,ALTER table等会改变数据库内容的SQL。如我们在数据库中建立一个表： 建表范例： public class CreateTableDemo {  public static void main(String[] args) throws SQLException {   //声明数据库连接池对象   IdataSource ds =  new dataSource();   //获得数据库连接    Connection con = ds.getconnection();//连接，加载URL USER PWD等信息    //获得Statement对象     Statement stmt = con.createStatement();    //创建SQL语句 创建表    String sql=\"create table A(id int,name varchar2(10))\";    stmt.executeUpdate(sql);//注：executeUpdate()返回的一个整型    //所以我们可以根据他的值是否大于0，来测试这个语句是否执行了    //关闭Statement对象    if(stmt!=null){     stmt.close();    }    //关闭连接    ds.closeconn(con);  } }  如果要在表中插入数据，更新数据，删除数据都可以使用Statement的executeUpdate()方法 stmt.executeUpdate(\"inser into A(1001,'Jack')\"); 而Statement的executeQuery()方法主要是用来查询的。                      第六章 数据操作-查询  数据库操作之查询 Statement的executeQuery()方法主要是用来SELECT等查询的。executeUpdate()方法返回的是int 类型的，表示记录变动的数据 。 而executeQurey()方法返回的是一个java.sql.ResultSet对象，代表查询的结果，查询的结果会一条一条的记录，可以使用ResultSet的next()方法来移至下一条记录，它会返回true或false表示 是否有下一条记录，接着可以使用getXXX()方法来获得数据。例如 ： getString() getInt() getFloat()等方法分别获得相应字段类型的记录，getXXX()方法提供了按字段名称获得记录 ，也可以按字段的顺序 例如 ： result.getInt(\"id\");//建议使用这种方式 result.getInt(1); public class SlectTableValueDemo {  public static void main(String[] args) throws SQLException {   //创建数据库连接池   IdataSource ds =  new dataSource();   //获得数据库连接    Connection con = ds.getconnection();//连接，加载URL USER PWD等信息   try {    //获得Statement对象    Statement stmt = con.createStatement();    //声明用于查询的SQL语句    String sql=\"select ename,empno,deptno from emp where deptno=20\";    //执行查询 等到一个结果集    ResultSet rs = stmt.executeQuery(sql);    //循环读取结果集中的数据    while(rs.next()){     System.out.print(rs.getString(\"ename\")+\"\\t\");     System.out.print(rs.getInt(\"empno\")+\"\\t\");     System.out.println(rs.getInt(\"deptno\"));    }   } catch (SQLException e) {    e.printStackTrace();   }finally{     //关闭Result对象    //ds.closeconn(rs);    //关闭Statement对象    //ds.closeconn(stmt);    //关闭连接对象    ds.closeconn(con);   }     } }  Connection()方法： Statement createStatement() :创建一个 Statement 对象来将 SQL 语句发送到数据库。 返回的是一个Statement类型。 Statement接口中有一方法：  ResultSet executeQuery(String sql)           执行给定的 SQL 语句，该语句返回单个 ResultSet 对象。 返回ResultSet类型 ResultSet 是一个接口 他中有一个方法：  boolean next()            将指针从当前位置下移一行。    第七章 预处理 Statement的execute()方法可以用来执行SQL语句，并测试所执行的SQL是执行查询或是更新，返回TURE的话表示执行SQL将返回ResultSet的查询结果 ，此时可以使用Statement对象的getResultSet()获得ResultSet对象。如果execute()方法返回false，表示执行SQL会返回更新数目或没有结果，此时可以 使用Statement对象的getUpdateCount()方法获取更新数目。 如果事先无法得知进行查询或是更新，就可以使用execute()方法。 Statement主要用于静态的SQL语句，也就是在执行executeUpdate() executeQuery() execute()等方法时，指定内容固定不变的SQL语句字符串，第一句SQL语句只能用于当时的执行。如果有些操作只是SQL语句某些参数会有些不同，其余的SQL子句皆相同，则可以使用java.sql.prepareStatement. 可以使用Connection的prepareStatement()方法建好一个预先编译好的SQL语句，其中参数会变动的部分，先制定“？”做为占位符，如在jdbc表中插入数据  PrepareStatement stmt=conn.prepareStatement(\"insert into jdbc(id,name)(?,?)\"); 等到真正在需要参数执行时，再使用相对应的 setInt() setString() setXXX()方法，制定?处真正应该有的参数，如： stmt.setInt(1001); stmt.setString(\"lixiaolong\"); 范例：动态的给jdbc表中插入值 public class prepareStatementDemo {  public static void main(String[] args) throws SQLException{   //创建数据库连接池   IdataSource ds=new dataSource();   //获得数据库连接   Connection conn=ds.getconnection();   // 使用占位符声明SQL语句   String sql=\"insert into jdbc values(?,?)\";   Scanner scan=new Scanner(System.in);   conn.setAutoCommit(false);//ture为自动提交 false为手动提交 不写默认为自动提交   //获得PrepareStatement对象   PreparedStatement pstt = conn.prepareStatement(sql);//预处理   System.out.println(\"请输入ID\");   //给参数赋值 ID 和 姓名   int id = scan.nextInt();   pstt.setInt(1, id);//有两个参数第一个 表示索引值，第二个是列名   System.out.println(\"请输入姓名\");   String name=scan.next();   pstt.setString(2, name);   pstt.executeUpdate();   conn.commit();//提交事物 注：事物有四个特性   System.out.println(\"赋值成功\");   } }   第八章 批处理 Statement中的execute()方法一次只能执行一个SQL语句 ，如果有多个SQL语句要的执行的话，可以使用executeBatch()方法，在一次方法调用中执行多个SQL语句，以增加执行的效率，可以使用addBatch()方法将要执行的SQL语句加入，然后执行executeBatch()方法即可。 一般步骤： conn.setAutoCommit(false); Statement stmt=conn.createStatement(); stmt.addBatch(\"......\");//SQL语句 stmt.addBatch(\"......\");//SQL语句 stmt.addBatch(\"......\");//SQL语句 stmt.executeBatch(); stmt.commit(): 范例： public class BatchDemo {  public static void main(String[] args) throws SQLException{   IdataSource ds=new dataSource();   Connection conn=ds.getconnection();   String sql=\"insert into jdbc values(?,?)\";   conn.setAutoCommit(false);//ture为自动提交 false为手动提交 不写默认为自动 提交    PreparedStatement pstt = conn.prepareStatement(sql);//预处理   //插入一万条记录 作批量处理   for(int i=1;i<5;i++){    pstt.setInt(1, i);    pstt.setString(2, \"JACK\"+i);    pstt.addBatch();   }   pstt.executeBatch();//批执行语句   conn.commit();//提交事物    System.out.println(\"赋值成功\");  } }   第九章 数据的数据 Meta Data 即“数据的数据”（Data about data）,ResultSet用来表示查询到的数据，而ResultSet数据的数据，即描述所查到的数据的背后的数据描述，用来表示表的名称，字段名称，字段类型等，这些信息可以通过ResultSetMetaData来获得。 范例： public class Demo{   public static void main(String[] args) throws SQLException{    //声明 数据库连接池对象    IdataSource stSource=new dataSource();    //获得数据库连接    Connection conn = stSource.getconnection();    //获得Statement对象    Statement stmt = conn.createStatement();    //声明SQL语句    String sql=\"select * from emp\";    //声明结果集对象    ResultSet rs=null;    try {     //执行查询     rs=stmt.executeQuery(sql);     //获得ResultSet的ResultSetMetaData(数据对象)     ResultSetMetaData metaData=rs.getMetaData();     //获取表的名称     String tableName=metaData.getTableName(1);     //获取数据中的字段数     int columnCount=metaData.getColumnCount();     //循环打印出每个字段的名称及类型     for(int i=1;i<columnCount;i++){//注：是从1开始的      //取字段名称      String columnaName=metaData.getColumnName(i);      //取字段的类型      String columnType=metaData.getColumnTypeName(i);      //打印      System.out.printf(\"%s\\t%s\\t%s\\t\",tableName,columnaName,columnType);     }     System.out.println();     //打印出数据     while(rs.next()){      System.out.printf(\"%d%S%d\",rs.getInt(\"empno\"),rs.getString(\"ename\"),rs.getInt(\"sal\"));     }    } catch (SQLException e) {     // TODO Auto-generated catch block     e.printStackTrace();    }finally{     //关闭ResultSet对象     //关闭Statement对象     //关闭Connection对象     stSource.closeconn(conn);    }     }  }     第十章 调用函数 在JDBC中调用函数需要涉及到一个新的接口 CallableStatement ，他是继承 PreparedStatement 的一个接口，这个接口主要是做储存过程和函数调用的。调用储存过程一般要用到事物。开始先设为setAutoCommit(false);然后再进行手动的提交（commit( )）。 在java要调用一个函数，大致的步聚可分为以下几步： 1. 创建连接池对象 2. 获得连接 3. 定义一个String类型的SQL语句，要注意的是函数的SQL语句写法比较特殊 ，调用函数的语法格式是 {？=  call 函数名（？，？）}。 4. 用Connecton接口中prepareCall( )的调用函数，他返回的是一个CallableStatement类型的值，CallableStatement他也是一个接口，是一个用于执行 SQL 存储过程的接口。JDBC API 提供了一个存储过程 SQL 转义语法，该语法允许对所有 RDBMS 使用标准方式调用存储过程。此转义语法有一个包含结果参数的形式和一个不包含结果参数的形式。如果使用结果参数，则必须将其注册为 OUT 型参数。其他参数可用于输入、输出或同时用于二者。参数是根据编号按顺序引用的，第一个参数的编号是 1。 5. 分别对函数中各个参数的值进行赋值  ，如果第一个是要输出的值，需要CallableStatement中的一个方法：registerOutParameter(int parameterIndex, int sqlType)  按顺序位置 parameterIndex 将 OUT 参数注册为 JDBC 类型 sqlType。这里第二个参数比较特殊，我们这里用 java 下特有的如：java.sql.Types.BIGINT 。 6. 执行SQL语句 7. 进行手动的提交 commit()。 范例：在JDBC中调用这两个函数 public class InvokeFunction {  //输入参数的函数  private static void  InFunction(){ //创建连接池对象   PoolDataSource ds=new PoolDataSource(); //获得连接   Connection conn=ds.getconnection();   //调用函数的语法格式为：{?=call 函数名（？，？）}   String sql=\"{?=call fun1(?,?)}\";//注意写调用函数时的语句格式    CallableStatement cs=null;//CallableStatement是个接口   try {    conn.setAutoCommit(false);//进行手动的事物 处理    cs=conn.prepareCall(sql);//prepareCall(String sql)方法             //创建一个 CallableStatement 对象来调用数据库存储过程。    cs.registerOutParameter(1, java.sql.Types.BIGINT);    /*registerOutParameter(int parameterIndex, int sqlType)       按顺序位置 parameterIndex 将 OUT 参数注册为 JDBC 类型 sqlType。*/    cs.setInt(2, 30);//给第2个参数赋值    cs.setInt(3, 70);//给第3个参数赋值    cs.execute();    System.out.println(\"结果为:\"+cs.getInt(1));//打印的是第3个参数    conn.commit();//提交事物    } catch (SQLException e) {    // TODO Auto-generated catch block    e.printStackTrace();   }finally{    ds.closeconn(conn, cs, null);   }  }  //输出参数的函数  private static void  OutFunction(){   PoolDataSource ds=new PoolDataSource();   Connection conn=ds.getconnection();   String sql=\"{?=call fun2(?,?)}\";   CallableStatement cs=null;   try {    conn.setAutoCommit(false);    cs=conn.prepareCall(sql);    cs.registerOutParameter(1, Types.INTEGER);    cs.setInt(2,30);    cs.registerOutParameter(3, Types.INTEGER);    cs.execute();    //获取结果    int avg=cs.getInt(1);    int count=cs.getInt(3);    System.out.println(\"平均工资为:\"+avg+\"该部门的人数为:\"+count);    conn.commit();   } catch (SQLException e) {    // TODO Auto-generated catch block    e.printStackTrace();       }finally{    ds.closeconn(conn, cs, null);    }   }  public static void main(String[] args) {   // 1.调用输入参数的函数   InFunction();   //2.调用输出参数的函数     OutFunction();  } } 程序执行过程中所到的访方法  prepareCall(String sql)   创建一个 CallableStatement 对象来调用数据库存储过程。 返回的CallableStatement类型。 registerOutParameter(String parameterName, int sqlType)  将名为 parameterName 的 OUT 参数注册为 JDBC 类型 sqlType。空的返回类型  函数的具体内容 首先写两个函数fun1()和fun2() //第一个函数 求两个数的和 create or  replace function fun1(n1 in int,n2 in int ) return integer is Result integer; begin Result :=n1+n2; return(Result); end; //调用第一个函数 declare i integer; begin i:=fun1(10,30); dbms_output.put_line('结果为'||i); end; //第二函数 返回一个部门的平均工资 create or replace function fun2(v_dept in int,v_count out int)  return number  as Result number; begin select avg(sal),count(*) into Result,v_count from emp where deptno=v_dept; return(Result); end ;  //调用第二个 函数  declare i integer; v_count int; begin i:=fun2(20,v_count=>v_count); dbms_output.put_line('平均工资'||i); dbms_output.put_line('人数为：'||v_count); end;   第十一章 调用过程  在java中调用过程与调用函数相似大致可以分为以下几步： 1、 创建连接池对象 2、 获得连接  3、 定义一个过程的SQL语句 ，语法为：{call 过程名（？，？）} 4、 然后执行 prepareCall() 范例：调用储存过程 public class InvokeProcedure {  //第1个储存过程 给jdbc表中插值  public static void InProduce(){   PoolDataSource ds=new PoolDataSource(); //创建连接池对象   Connection conn=ds.getconnection();  //获得连接    String sql=\"{call In_proc(?,?)}\";  //定义 一个关于过程 的SQL语句   CallableStatement cs=null; //定义一个CallableStatement类型的对象   try {       conn.setAutoCommit(false); //设置为手动提交事物     cs=conn.prepareCall(sql);  //调用SQL语句执行过程    cs.setInt(1, 1002); //给第1个参数赋值    cs.setString(2, \"Tom\"); //给第2个参数赋值    cs.execute(); //执行SQL语句     conn.commit(); //提交事物    } catch (SQLException e) {    e.printStackTrace();   }finally{    ds.closeconn(conn, cs, null); //关闭连接    }   }  //第二个过程，给定一个部门号，求出这个部门的工资总  public static  void  OutProduce(){   PoolDataSource ds=new PoolDataSource();   Connection conn=ds.getconnection();   String sql=\"{call out_proc(?,?)}\";   CallableStatement cs=null;   try {    conn.setAutoCommit(false);    cs=conn.prepareCall(sql);    cs.setInt(1, 20);    cs.registerOutParameter(2, Types.INTEGER);    cs.execute();    conn.commit();    System.out.println(\"部门的工资总数为:\"+cs.getInt(2));   } catch (SQLException e) {    e.printStackTrace();   }finally{    ds.closeconn(conn, cs, null);   }  }  //第三个过程：一个带有游标的过程，打印出某个部门的全体员工的信息  public static void CursorProduce(){   PoolDataSource ds=new PoolDataSource();   Connection conn=ds.getconnection();   String sql=\"{call cur_proc(?,?)}\";   CallableStatement cs=null;   try {    conn.setAutoCommit(false);    cs=conn.prepareCall(sql);    cs.setInt(1, 10);    cs.registerOutParameter(2, oracle.jdbc.OracleTypes.CURSOR);    cs.execute();    conn.commit();    //获取结果    ResultSet rs = (ResultSet)cs.getObject(2);    while(rs.next()){     int number = rs.getInt(\"empno\");     String ename = rs.getString(\"ename\");     int sal=rs.getInt(\"sal\");     System.out.printf(\"员工号为%d姓名为%s工资为%d\\n\",number,ename,sal);    }   } catch (SQLException e) {    // TODO Auto-generated catch block    e.printStackTrace();   }finally{    ds.closeconn(conn, cs, null);   }  }  //主函数  public static void main(String[] args) {        InProduce();       OutProduce();       CursorProduce()  } }  三个过程： //创建一个存储过程 给jdbc表插入数据 create or replace procedure In_proc(id in int,name in varchar2)  is begin insert into jdbc values(id , name); end; //过程二 求某个部门的工资总数 create or replace procedure out_proc(v_dept in int,v_sum out int) as begin select sum(sal) into v_sum from emp where deptno=v_dept; end; //带有游标的过程 打印某个部门的全体员工的信息 create or replace procedure cur_proc(v_deptno in int,emp_cur out sys_refcursor)  is  begin open emp_cur for select * from emp where deptno=v_deptno; end;   第十二章 DAO封装 数据操作对象(data access object) 一、描述EMP表中信息的类 public class Emp {  private int empno;  private String ename;  private int sal;  private int dept;  public int getEmpno() {   return empno;  }  public void setEmpno(int empno) {   this.empno = empno;  }  public String getEname() {   return ename;  }  public void setEname(String ename) {   this.ename = ename;  }  public int getSal() {   return sal;  }  public void setSal(int sal) {   this.sal = sal;  }  public int getDept() {   return dept;  }  public void setDept(int dept) {   this.dept = dept;  } } 二、进行操作的类 public class EmpDao {  //增  public int add(Emp emp){   ConectionPool ds= new ConectionPool();   Connection conn=ds.getConnection();   PreparedStatement ppt=null;   String sqlAdd=\"insert into emp(empno,ename,sal,deptno) values(?,?,?,?)\";   try {    ppt= conn.prepareStatement(sqlAdd);    ppt.setInt(1, emp.getEmpno());    ppt.setString(2, emp.getEname());    ppt.setInt(3, emp.getSal());    ppt.setInt(4, emp.getDept());    return ppt.executeUpdate();//执行   } catch (SQLException e) {    e.printStackTrace();    return 0;   }finally{    ds.closeConnection(conn, ppt, null);   }   }  //删  public int delete(int Empno){   ConectionPool ds= new ConectionPool();   Connection conn=ds.getConnection();   String sqlDelete=\"delete from emp where empno=?\";   PreparedStatement ppt=null;   try {     ppt= conn.prepareStatement(sqlDelete);   ppt.setInt(1, Empno);    return ppt.executeUpdate();//执行   } catch (SQLException e) {    // TODO Auto-generated catch block    e.printStackTrace();    return 0;   }finally{    ds.closeConnection(conn, ppt, null);   }  }  //改  public int update(Emp emp) throws SQLException{      ConectionPool ds= new ConectionPool();   Connection conn=ds.getConnection();   String sqlUpdate=\"update emp set sal=? where empno=?\";   try {    PreparedStatement ppt= conn.prepareStatement(sqlUpdate);    ppt.setInt(1, emp.getEmpno());    ppt.setInt(2, emp.getSal());    return ppt.executeUpdate();//执行   } catch (SQLException e) {    e.printStackTrace();    return 0;   }  }  //单行查  public Emp getSingleRecord(int empno){   Emp emp=new Emp();   ConectionPool ds= new ConectionPool();   Connection conn=ds.getConnection();   String sqlSingleRecord=\"select * from emp where empno=?\";   PreparedStatement ppt=null;   ResultSet rs=null;   try {    ppt=conn.prepareStatement(sqlSingleRecord);    ppt.setInt(1, empno);      rs= ppt.executeQuery();    while(rs.next()){     int empnumber=rs.getInt(\"empno\");     String ename=rs.getString(\"ename\");     int sal = rs.getInt(\"sal\");     int deptno=rs.getInt(\"deptno\");     emp.setEmpno(empnumber);     emp.setEname(ename);     emp.setSal(sal);     emp.setDept(deptno);      }   } catch (SQLException e) {    // TODO Auto-generated catch block    e.printStackTrace();       }finally{    ds.closeConnection(conn, ppt, rs);   }   return emp;     }  //多行查询 查所有的员工 信息  public List<Emp> getAllEmp(){   List<Emp> empList=new ArrayList<Emp>();//定义一个Emp类型的容器   ConectionPool ds= new ConectionPool();   Connection conn=ds.getConnection();   String sqlAllEmp=\"select * from emp\";   PreparedStatement ppt=null;   ResultSet rs=null;   try {    ppt=conn.prepareStatement(sqlAllEmp);    rs=ppt.executeQuery();    while(rs.next()){    Emp emp=new Emp();    int empnumber=rs.getInt(\"empno\");    String ename=rs.getString(\"ename\");    int sal = rs.getInt(\"sal\");    int deptno=rs.getInt(\"deptno\");    emp.setEmpno(empnumber);    emp.setEname(ename);    emp.setSal(sal);    emp.setDept(deptno);    //放入集合    empList.add(emp);    }   } catch (SQLException e) {    e.printStackTrace();    return empList;   }finally{     ds.closeConnection(conn, ppt, rs);   }   return empList;  } } 三、演示类 增： public class AddDemo {  public static void main(String[] args) {   Emp emp=new Emp();   emp.setEmpno(1001);   emp.setEname(\"lixiao\");   emp.setSal(5000);   emp.setDept(10);     EmpDao dao=new EmpDao();   dao.add(emp);     System.out.println(\"添加员工成功\");    } } 删除： public class DeleteDemo {  public static void main(String[] args) {  Emp emp=new Emp();  EmpDao dao=new EmpDao();  dao.delete(1001);  System.out.println(\"删除成功\");  } } 改： public class UpdateDemo {  public static void main(String[] args) {   Emp emp=new Emp();   emp.setEmpno(7499);   emp.setSal(4000);   EmpDao dao = new EmpDao();   try {    dao.update(emp);   } catch (SQLException e) {    // TODO Auto-generated catch block    e.printStackTrace();   }   System.out.println(\"修改成功\");   } } 单行查： public class SingleRecordDemo {  public static void main(String[] args) {   EmpDao dao=new EmpDao();   Emp emp=new Emp();   emp=dao.getSingleRecord(7499);   System.out.println(\"查询成功\");   System.out.println(\"员工号为：\"+emp.getEmpno());   System.out.println(\"姓名为：\"+emp.getEname());   System.out.println(\"工资为：\"+emp.getSal());   System.out.println(\"所在部门为:\"+emp.getDept()+\"部门\");   } } 多行查： public class getAllEmpDemo {  public static void main(String[] args) {   EmpDao dao=new EmpDao();   List<Emp> lists=dao.getAllEmp();   //读取集合   System.out.println(\"员工号\"+\" \"+\"员工名\"+\" \"+\"工资\"+\" \"+\"部门号\");   for(int i=0 ;i<lists.size();i++){    Emp emp=lists.get(i);    System.out.println(emp.getEmpno()+\" \"+emp.getEname()+\" \"+emp.getSal()+\" \"+emp.getDept());   }   System.out.println(\"表中一共有\"+lists.size()+\"条记录\");  } } 附录 实体权限 ----------------------------------------------------- alter any cluster 修改任意簇的权限 alter any index 修改任意索引的权限 alter any role 修改任意角色的权限 alter any cluster alter any sequence 修改任意序列的权限 alter any snapshot 修改任意快照的权限 alter any table 修改任意表的权限 alter any trigger 修改任意触发器的权限 alter cluster 修改拥有簇的权限 alter database 修改数据库的权限 analyze 使用analyze命令分析数据库中任意的表、索引和簇 audit any 为任意的数据库对象设置审计选项 audit system 允许系统操作审计 backup any table 备份任意表的权限 become user 切换用户状态的权限 commit any table 提交表的权限 create any cluster 为任意用户创建簇的权限 create any index 为任意用户创建索引的权限 create any procedure 为任意用户创建存储过程的权限 create any sequence 为任意用户创建序列的权限 create any snapshot 为任意用户创建快照的权限 create any synonym 为任意用户创建同义名的权限 create any table 为任意用户创建表的权限 create any trigger 为任意用户创建触发器的权限 create any view 为任意用户创建视图的权限 create cluster 为用户创建簇的权限 create database link 为用户创建的权限 create procedure 为用户创建存储过程的权限 create profile 创建资源限制简表的权限 create public database link 创建公共数据库链路的权限 create public synonym 创建公共同义名的权限 create role 创建角色的权限 create rollback segment 创建回滚段的权限 create session 创建会话的权限 create sequence 为用户创建序列的权限 create snapshot 为用户创建快照的权限 create synonym 为用户创建同义名的权限 create table 为用户创建表的权限 create tablespace 创建表空间的权限 create user 创建用户的权限 create view 为用户创建视图的权限 delete any table 删除任意表行的权限 delete any view 删除任意视图行的权限 delete snapshot 删除快照中行的权限 delete table 为用户删除表行的权限 delete view 为用户删除视图行的权限 drop any cluster 删除任意簇的权限 drop any index 删除任意索引的权限 drop any procedure 删除任意存储过程的权限 drop any role 删除任意角色的权限 drop any sequence 删除任意序列的权限 drop any snapshot 删除任意快照的权限 drop any synonym 删除任意同义名的权限 drop any table 删除任意表的权限 drop any trigger 删除任意触发器的权限 drop any view 删除任意视图的权限 drop profile 删除资源限制简表的权限 drop public cluster 删除公共簇的权限 drop public database link 删除公共数据链路的权限 drop public synonym 删除公共同义名的权限 drop rollback segment 删除回滚段的权限 drop tablespace 删除表空间的权限 drop user 删除用户的权限 execute any procedure 执行任意存储过程的权限 execute function 执行存储函数的权限 execute package 执行存储包的权限 execute procedure 执行用户存储过程的权限 force any transaction 管理未提交的任意事务的输出权限 force transaction 管理未提交的用户事务的输出权限 grant any privilege 授予任意系统特权的权限 grant any role 授予任意角色的权限 index table 给表加索引的权限 insert any table 向任意表中插入行的权限 insert snapshot 向快照中插入行的权限 insert table 向用户表中插入行的权限 insert view 向用户视图中插行的权限 lock any table 给任意表加锁的权限 manager tablespace 管理（备份可用性）表空间的权限 references table 参考表的权限 restricted session 创建有限制的数据库会话的权限 select any sequence 使用任意序列的权限 select any table 使用任意表的权限 select snapshot 使用快照的权限 select sequence 使用用户序列的权限 select table 使用用户表的权限 select view 使用视图的权限 unlimited tablespace 对表空间大小不加限制的权限 update any table 修改任意表中行的权限 update snapshot 修改快照中行的权限 update table 修改用户表中的行的权限 update view 修改视图中行的权限 在Oracle常见的异常： -------------------------------------------------------------------------------------------------------- 命名的系统异常                   产生原因  -------------------------------------------------------------------------------------------------------- ACCESS_INTO_NULL          未定义对象  CASE_NOT_FOUND           CASE 中若未包含相应的 WHEN ，并且没有设置 ELSE 时  COLLECTION_IS_NULL        集合元素未初始化  CURSER_ALREADY_OPEN      游标已经打开  DUP_VAL_ON_INDEX         唯一索引对应的列上有重复的值  INVALID_CURSOR            在不合法的游标上进行操作  INVALID_NUMBER           内嵌的 SQL 语句不能将字符转换为数字  NO_DATA_FOUND            使用 select into 未返回行，或应用索引表未初始化的元素时  TOO_MANY_ROWS            执行 select into 时，结果集超过一行  ZERO_DIVIDE                除数为 0  SUBSCRIPT_BEYOND_COUNT   元素下标超过嵌套表或 VARRAY 的最大值  SUBSCRIPT_OUTSIDE_LIMIT   使用嵌套表或 VARRAY 时，将下标指定为负数  VALUE_ERROR               赋值时，变量长度不足以容纳实际数据  LOGIN_DENIED              PL/SQL 应用程序连接到 oracle 数据库时，提供了不正确的用户名或密码  NOT_LOGGED_ON            PL/SQL 应用程序在没有连接 oralce 数据库的情况下访问数据  PROGRAM_ERROR            PL/SQL 内部问题，可能需要重装数据字典＆ pl./SQL 系统包  ROWTYPE_MISMATCH         宿主游标变量与 PL/SQL 游标变量的返回类型不兼容  SELF_IS_NULL              使用对象类型时，在 null 对象上调用对象方法  STORAGE_ERROR            运行 PL/SQL 时，超出内存空间  SYS_INVALID_ID             无效的 ROWID 字符串  TIMEOUT_ON_RESOURCE      Oracle 在等待资源时超时  ----------------------------------------------------------------------------------------------------------------------","title":"Oracle学习笔记"},{"content":"1.我最常用的备份命令 1 mysqldump  -u username -ppassword --add-drop-database -B databaseName | gzip > backupfile.sql.gz 2.备份MySQL数据库(最基本) 1 mysqldump -h hostname -u username -ppassword -B databasename > backupfile.sql 3.备份MySQL数据库（带drop语句） mysqldump -–add-drop-table - uusername -ppassword -B databasename > backupfile.sql 4.备份MySQL数据库（压缩） 1 mysqldump -h hostname -u username -ppassword -B databasename | gzip > backupfile.sql.gz 5.备份MySQL数据库（所有库） 1 mysqldump -u root -ppassword --all-databases > all_databases.sql 6.备份MySQL数据库（仅仅备份数据库结构） 1 mysqldump -u root  -ppassword --add-drop-database -d -B databaseName > backupfile.sql 7.还原MySQL数据库 1 mysql> mysql -u username -ppassword 2 mysql> source backupfile.sql 注意： 1.-p后面没有空格 2.mysqldump有很多缩写，比如--databases可以缩写为-B","title":"MySQL数据库的备份与还原"},{"content":"Android中通过SQLite数据库引擎来实现结构化数据存储。SQLite是一个嵌入式数据库引擎，针对内存等资源有限的设备（如手机、PDA、MP3）提供的一种高效的数据库引擎。 SQLite数据库不像其他的数据库（如Oracle），它没有服务器进程。所有的内容包含在同一个单文件中。该文件是跨平台的，可以自由复制。基于其自身的先天优势，SQLite在嵌入式领域得到广泛应用。 SQLite最大的特点是你可以把各种类型的数据保存到任何字段中，而不用关心字段声明的数据类型是什么。 但如何利用SQLite来开发数据库应用呢？我们如何才能实现在用户初次使用或升级软件时自动在用户的手机上创建出应用需要的数据库表呢？为了解决这一问题，在Android系统，为我们提供了一个名为SQLiteOpenHelper的抽象类，必须继承它才能使用。 SQLiteOpenHelper类提供了两个重要的方法，分别是onCreate(SQLiteDatabase db)和onUpgrade(SQLiteDatabase db, int oldVersion, int newVersion)，前者用于初次使用软件时生成数据库表，后者用于升级软件时更新数据库表结构。当调用SQLiteOpenHelper的getWritableDatabase()或者getReadableDatabase()方法获取用于操作数据库的SQLiteDatabase实例的时候，如果数据库不存在，Android系统会自动生成一个数据库，接着调用onCreate()方法，onCreate()方法在初次生成数据库时才会被调用，在onCreate()方法里可以生成数据库表结构及添加一些应用使用到的初始化数据。onUpgrade()方法在数据库的版本发生变化时会被调用，一般在软件升级时才需改变版本号，而数据库的版本是由程序员控制的，假设数据库现在的版本是1，由于业务的变更，修改了数据库表结构，这时候就需要升级软件，升级软件时希望更新用户手机里的数据库表结构，为了实现这一目的，可以把原来的数据库版本设置为2。 下面就以个人日记本为例来更好地学习SQLite... 首先展示一下层次结构，项目的命名、包及其类的命名：                                                      阶段一：新建Android项目，命名为MyDiary .然后使用SQLiteOpenHelper(抽象类)来完成数据库的创建.新建DBHelper类，让它继承SQLiteOpenHelper类，具体代码如下： import android.content.Context;import android.database.sqlite.SQLiteDatabase;import android.database.sqlite.SQLiteDatabase.CursorFactory;import android.database.sqlite.SQLiteOpenHelper;public class DBHelper extends SQLiteOpenHelper {\tprivate static final String DATABASE_NAME = \"diary.db\";\tprivate static final int DATABASE_VERSION = 1;\tpublic DBHelper(Context context) {\t\tsuper(context, DATABASE_NAME, null, DATABASE_VERSION);\t}\t@Override\tpublic void onCreate(SQLiteDatabase db) {\t\tdb.execSQL(\"create table diary(_id integer primary key autoincrement,title varchar(20),content varchar(1000),pubdate)\");\t}\t@Override\tpublic void onUpgrade(SQLiteDatabase db, int oldVersion, int newVersion) {\t}} 阶段二：配置好单元测试的环境： <uses-library android:name=\"android.test.runner\" /> <instrumentation         android:name=\"android.test.InstrumentationTestRunner\"         android:targetPackage=\"com.lks.mydiary\" > <\/instrumentation> 然后进行单元测试：看数据库究竟有没有被创建出来.. package com.lks.mydiary.test;import java.text.SimpleDateFormat;import java.util.Date;import com.lks.mydiary.entity.Diary;import com.lks.mydiary.service.DBHelper;import com.lks.mydiary.service.DiaryService;import android.test.AndroidTestCase;public class DiaryServiceTest extends AndroidTestCase {\tpublic void testOncreate() {\t\tDBHelper dbHelper = new DBHelper(getContext());\t\tdbHelper.getWritableDatabase();\t}}    执行单元测试，创建好的数据库是以文件的形式进行存放的...   进入DDMS观察存放位置：data/data/应用的包名/databases/diary.db   如何观察数据库中建立的表呢？   打开数据库：借助于第三方工具SQLiteDeveloper（注册数据库）   导出数据库后，借助于第三方工具注册数据库 阶段三：定义实体类Diary类. package com.lks.mydiary.entity;public class Diary {\tprivate Integer id;\tprivate String title;\tprivate String content;\tprivate String pubdate;\tpublic Diary(String title, String content, String pubdate) {\t\tsuper();\t\tthis.title = title;\t\tthis.content = content;\t\tthis.pubdate = pubdate;\t}\tpublic Integer getId() {\t\treturn id;\t}\t\tpublic void setId(Integer id) {\t\tthis.id = id;\t}\tpublic String getTitle() {\t\treturn title;\t}\tpublic void setTitle(String title) {\t\tthis.title = title;\t}\tpublic String getContent() {\t\treturn content;\t}\tpublic void setContent(String content) {\t\tthis.content = content;\t}\tpublic String getPubdate() {\t\treturn pubdate;\t}\tpublic void setPubdate(String pubdate) {\t\tthis.pubdate = pubdate;\t}} 阶段四：定义数据库访问类DiaryService类，搭建框架. package com.lks.mydiary.service;import java.util.ArrayList;import java.util.List;import android.content.Context;import android.database.Cursor;import android.database.sqlite.SQLiteDatabase;import com.lks.mydiary.entity.Diary;public class DiaryService {\tprivate SQLiteDatabase sqLiteDatabase;\tprivate DBHelper dbHelper;\tpublic DiaryService(Context context) {\t\tdbHelper = new DBHelper(context);\t}    /*     * 保存日记     */\tpublic void save(Diary diary) {\t\tsqLiteDatabase = dbHelper.getWritableDatabase();\t\tString sql = \"insert into diary(title,content,pubdate) values(?,?,?)\";\t\tsqLiteDatabase.execSQL(\t\t\t\tsql,\t\t\t\tnew String[] { diary.getTitle(), diary.getContent(),\t\t\t\t\t\tdiary.getPubdate() });\t}    /*     * 更新日记     */\tpublic void update(Diary diary){\t\tsqLiteDatabase = dbHelper.getWritableDatabase();\t\tString sql = \"update diary set title=?,content=?,pubdate=? where _id=?\";\t\tsqLiteDatabase.execSQL(\t\t\t\tsql,\t\t\t\tnew Object[] { diary.getTitle(), diary.getContent(),\t\t\t\t\t\tdiary.getPubdate(), diary.getId()});\t}\t/*\t * 根据id删除日记\t */\tpublic void delete(Integer id) {\t\tsqLiteDatabase = dbHelper.getWritableDatabase();// 得到的是同一个数据库实例\t\tsqLiteDatabase.execSQL(\"delete from diary where _id=?\",new Object[]{id});\t}\t/*\t * 根据id查询日记\t */\tpublic Diary find(Integer id) {\t\tDiary diary = null;\t\tsqLiteDatabase = dbHelper.getReadableDatabase();\t\t// 得到游标，最多只有一条数据\t\tCursor cursor = sqLiteDatabase.rawQuery(\t\t\t\t\"select * from diary where _id=?\",\t\t\t\tnew String[] { id.toString() });\t\t// 如果移动成功就代表存在\t\tif (cursor.moveToFirst()) {\t\t\t// 只能根据列的索引来获得相应的字段值\t\t\tString title = cursor.getString(cursor.getColumnIndex(\"title\"));\t\t\tString content = cursor.getString(cursor.getColumnIndex(\"content\"));\t\t\tString pubdate = cursor.getString(cursor.getColumnIndex(\"pubdate\"));\t\t\tdiary = new Diary(title, content, pubdate);\t\t}\t\treturn diary;\t}\t/*\t * 分页查询\t */\tpublic List<Diary> getDiariesByPage(Integer offset, Integer maxResult) {\t\tDiary diary = null;\t\tList<Diary> diaryList = new ArrayList<Diary>();\t\tsqLiteDatabase = dbHelper.getReadableDatabase();\t\t// 得到游标，最多只有一条数据\t\tCursor cursor = sqLiteDatabase.rawQuery(\t\t\t\t\"select * from diary limit ?,?\",\t\t\t\tnew String[] { offset.toString(), maxResult.toString() });\t\twhile (cursor.moveToNext()) {\t\t\tString title = cursor.getString(cursor.getColumnIndex(\"title\"));\t\t\tString content = cursor.getString(cursor.getColumnIndex(\"content\"));\t\t\tString pubdate = cursor.getString(cursor.getColumnIndex(\"pubdate\"));\t\t\tdiary = new Diary(title, content, pubdate);\t\t\tdiaryList.add(diary);\t\t}\t\tcursor.close();\t\treturn diaryList;    }    /*     * 获取所有日记     */\tpublic Cursor getAllDiaries(){\t\tsqLiteDatabase=dbHelper.getReadableDatabase();\t\tCursor cursor=sqLiteDatabase.rawQuery(\"select * from diary\", null);\t\treturn cursor;\t}    /*     * 获取记录总数     */\tpublic long count() {\t\tlong count=0;\t\tsqLiteDatabase=dbHelper.getReadableDatabase();\t\tCursor cursor=sqLiteDatabase.rawQuery(\"select count(*) from diary \",null);\t\tcursor.moveToFirst();\t\tcount=cursor.getLong(0);\t\treturn count;\t}\t} 阶段五：界面和功能设计。当运行程序，主界面显示日志列表。当没有日记时显示“你好懒，还没开始写日记呢”，如下图：     具体代码如下： activity_diary.xml: <LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\"    xmlns:tools=\"http://schemas.android.com/tools\"    android:layout_width=\"match_parent\"    android:layout_height=\"match_parent\"     android:orientation=\"vertical\"    android:background=\"@drawable/bg\" >    <ListView         android:id=\"@id/android:list\"        android:layout_width=\"wrap_content\"        android:layout_height=\"wrap_content\" >           <\/ListView>    <TextView         android:id=\"@id/android:empty\"        android:layout_width=\"wrap_content\"        android:layout_height=\"wrap_content\"        android:text=\"你好懒，还没开始写日记呢\"/><\/LinearLayout> item_diary.xml: <?xml version=\"1.0\" encoding=\"utf-8\"?><LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\"    android:layout_width=\"fill_parent\"    android:layout_height=\"fill_parent\"    android:orientation=\"horizontal\" >    <TextView        android:id=\"@+id/title\"        android:layout_width=\"wrap_content\"        android:layout_height=\"wrap_content\"        android:padding=\"10dp\" />    <TextView        android:id=\"@+id/pubdate\"        android:layout_width=\"fill_parent\"        android:layout_height=\"wrap_content\"        android:gravity=\"right\"        android:padding=\"10dp\" /><\/LinearLayout> 当点击菜单键时，会弹出菜单：                               当点击“添加一篇日记”，跳转至另一页面SaveActivity.                               具体代码如下： activity_save.xml: <LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\"    xmlns:tools=\"http://schemas.android.com/tools\"    android:layout_width=\"match_parent\"    android:layout_height=\"match_parent\"    android:orientation=\"vertical\"    android:background=\"@drawable/bg\" >    <TextView        android:layout_width=\"fill_parent\"        android:layout_height=\"wrap_content\"        android:text=\"@string/title\" />    <EditText        android:id=\"@+id/title\"        android:layout_width=\"fill_parent\"        android:layout_height=\"wrap_content\" />    <TextView        android:layout_width=\"fill_parent\"        android:layout_height=\"wrap_content\"        android:text=\"@string/content\" />    <EditText        android:id=\"@+id/content\"        android:layout_width=\"fill_parent\"        android:layout_height=\"wrap_content\"        android:minLines=\"6\" />    <Button        android:id=\"@+id/save\"        android:layout_width=\"wrap_content\"        android:layout_height=\"wrap_content\"        android:text=\"@string/save\" /><\/LinearLayout> 填写好标题和内容，保存之后页面自动跳转到显示日志列表的主界面。可以点击某一篇日记进行查看，同时进行编辑修改。                              当选中某篇日记，点击菜单中的删除日记按钮可以删除当前选中的日记。                             阶段六：编辑Activity,进行对个人日记本增删改查的功能实现。具体代码如下： DiaryActivity.java: package com.lks.mydiary;import com.lks.mydiary.entity.Diary;import com.lks.mydiary.service.DiaryService;import android.os.Bundle;import android.app.AlertDialog;import android.app.ListActivity;import android.content.DialogInterface;import android.content.DialogInterface.OnClickListener;import android.content.Intent;import android.database.Cursor;import android.view.Menu;import android.view.MenuItem;import android.view.View;import android.widget.AdapterView;import android.widget.AdapterView.OnItemClickListener;import android.widget.AdapterView.OnItemSelectedListener;import android.support.v4.widget.SimpleCursorAdapter;public class DiaryActivity extends ListActivity {\tprivate DiaryService diaryService;\tprivate int idSelect;\tpublic static final int MENU_INSERT = 0;// 关于菜单\tpublic static final int MENU_DELETE = 1;// 退出菜单\t@Override\tpublic void onCreate(Bundle savedInstanceState) {\t\tsuper.onCreate(savedInstanceState);\t\tsetContentView(R.layout.activity_diary);\t\trefreshList();\t\t//点击事件，当点击某篇日记时..\t\tgetListView().setOnItemClickListener(new OnItemClickListener() {            \t\t\tpublic void onItemClick(AdapterView<?> adapter, View view,\t\t\t\t\tint position, long id) {\t\t\t\tIntent intent = new Intent();\t\t\t\tintent.putExtra(\"button\", \"find\");\t\t\t\tintent.setClass(DiaryActivity.this, SaveActivity.class);\t\t\t\tBundle bundle = new Bundle();\t\t\t\tDiary diary = diaryService.find((int) id);\t\t\t\tbundle.putString(\"title\", diary.getTitle());\t\t\t\tbundle.putString(\"content\", diary.getContent());\t\t\t\tbundle.putInt(\"id\", (int)id);\t\t\t\tintent.putExtras(bundle);\t\t\t\tstartActivity(intent);\t\t\t\t\t\t\t}\t\t});\t\tgetListView().setOnItemSelectedListener(new OnItemSelectedListener() {\t\t\tpublic void onItemSelected(AdapterView<?> adapterView, View view,\t\t\t\t\tint position, long id) {\t\t\t\tidSelect = (int) id;\t\t\t}\t\t\tpublic void onNothingSelected(AdapterView<?> arg0) {\t\t\t}\t\t});\t}\tprivate void refreshList() {\t\tdiaryService = new DiaryService(this);\t\tCursor cursor = diaryService.getAllDiaries();\t\tstartManagingCursor(cursor);\t\tSimpleCursorAdapter simpleCursorAdapter = new SimpleCursorAdapter(this,\t\t\t\tR.layout.item_diary, cursor, new String[] { \"title\", \"pubdate\" },\t\t\t\tnew int[] { R.id.title, R.id.pubdate });\t\tsetListAdapter(simpleCursorAdapter);\t}\t@Override\tpublic boolean onCreateOptionsMenu(Menu menu) {\t\tmenu.add(0, MENU_INSERT, 0, R.string.insert);// 第一个参数为组号，便于对整个组进行操作；第二个参数为菜单的ID，为了标识菜单项；第三个参数为显示顺序\t\tmenu.add(0, MENU_DELETE, 1, R.string.delete);\t\treturn true;\t}\t/**\t * 当点击菜单项时调用此方法\t */\t@Override\tpublic boolean onOptionsItemSelected(MenuItem item) {\t\tint itemId = item.getItemId();// 获取菜单项的唯一编号\t\tswitch (itemId) {\t\t//添加日记\t\tcase MENU_INSERT:\t\t\tIntent intent = new Intent();\t\t\tintent.putExtra(\"button\", \"insert\");\t\t\tintent.setClass(DiaryActivity.this, SaveActivity.class);\t\t\tstartActivity(intent);\t\t\tbreak;\t\t//删除日记\t\tcase MENU_DELETE:\t\t\tAlertDialog.Builder builder = new AlertDialog.Builder(this);\t\t\tbuilder.setIcon(android.R.drawable.ic_menu_delete)\t\t\t\t\t.setTitle(R.string.delete)\t\t\t\t\t.setMessage(R.string.info)\t\t\t\t\t.setPositiveButton(R.string.ok, new OnClickListener() {\t\t\t\t\t\tpublic void onClick(DialogInterface dialog, int which) {\t\t\t\t\t\t\tdiaryService = new DiaryService(DiaryActivity.this);\t\t\t\t\t\t\t\t\t\t\t\t\t\tdiaryService.delete(idSelect);\t\t\t\t\t\t\trefreshList();\t\t\t\t\t\t}\t\t\t\t\t})\t\t\t\t\t.setNegativeButton(R.string.cancel, new OnClickListener() {\t\t\t\t\t\tpublic void onClick(DialogInterface dialog, int which) {\t\t\t\t\t\t}\t\t\t\t\t}).create().show();\t\t\tbreak;\t\tdefault:\t\t\tbreak;\t\t}\t\treturn true;\t}} SaveActivity.java: package com.lks.mydiary;import java.text.SimpleDateFormat;import java.util.Date;import com.lks.mydiary.entity.Diary;import com.lks.mydiary.service.DiaryService;import android.os.Bundle;import android.app.Activity;import android.content.Intent;import android.view.Menu;import android.view.MenuItem;import android.view.View;import android.view.View.OnClickListener;import android.widget.Button;import android.widget.EditText;import android.widget.Toast;public class SaveActivity extends Activity {\tprivate EditText titleText;\tprivate EditText contentText;\tprivate Button save;\tprivate DiaryService diaryService;\t@Override\tpublic void onCreate(Bundle savedInstanceState) {\t\tsuper.onCreate(savedInstanceState);\t\tsetContentView(R.layout.activity_save);\t\ttitleText = (EditText) this.findViewById(R.id.title);\t\tcontentText = (EditText) this.findViewById(R.id.content);\t\tsave = (Button) this.findViewById(R.id.save);\t\tIntent intent = this.getIntent();\t\tString msg = intent.getStringExtra(\"button\");\t\t//实现添加日记\t\tif (msg.equals(\"insert\")) {\t\t\tsave.setOnClickListener(new OnClickListener() {\t\t\t\tpublic void onClick(View v) {\t\t\t\t\tDiary diary = new Diary(titleText.getText().toString(),\t\t\t\t\t\t\tcontentText.getText().toString(),\t\t\t\t\t\t\tgetCurrentTime(new Date()));\t\t\t\t\tdiaryService = new DiaryService(SaveActivity.this);\t\t\t\t\tdiaryService.save(diary);\t\t\t\t\tIntent intent=new Intent();\t\t\t\t\tintent.setClass(SaveActivity.this, DiaryActivity.class);\t\t\t\t\tstartActivity(intent);\t\t\t\t\tToast.makeText(SaveActivity.this, R.string.save_success,\t\t\t\t\t\t\tToast.LENGTH_LONG).show();\t\t\t\t}\t\t\t});\t\t//实现修改日记\t\t} else if (msg.equals(\"find\")) {\t\t\tfinal Bundle bundle = this.getIntent().getExtras();\t\t\tif (bundle != null) {\t\t\t\tString title = bundle.getString(\"title\");\t\t\t\tString content = bundle.getString(\"content\");\t\t\t\t\t\t\t\tif (titleText != null) {\t\t\t\t\ttitleText.setText(title);\t\t\t\t}\t\t\t\tif (contentText != null) {\t\t\t\t\tcontentText.setText(content);\t\t\t\t}\t\t\t}\t\t\tsave.setOnClickListener(new OnClickListener() {\t\t\t\t\t\t\t\tpublic void onClick(View v) {\t\t\t\t\tDiary diary = new Diary(titleText.getText().toString(),\t\t\t\t\t\t\tcontentText.getText().toString(),\t\t\t\t\t\t\tgetCurrentTime(new Date()));\t\t\t\t\tdiary.setId(bundle.getInt(\"id\"));\t\t\t\t\tdiaryService = new DiaryService(SaveActivity.this);\t\t\t\t\tdiaryService.update(diary);\t\t\t\t\tIntent intent = new Intent(SaveActivity.this,DiaryActivity.class);\t\t\t\t\tstartActivity(intent);\t\t\t\t\tToast.makeText(SaveActivity.this, R.string.update_success,\t\t\t\t\t\t\tToast.LENGTH_LONG).show();\t\t\t\t}\t\t\t});\t\t\t\t\t}\t}\tpublic String getCurrentTime(Date date) {\t\tSimpleDateFormat simpleDateFormat = new SimpleDateFormat(\t\t\t\t\"yyyy年MM月dd日hh时mm分ss秒\");\t\treturn simpleDateFormat.format(date);\t}\t@Override\tpublic boolean onCreateOptionsMenu(Menu menu) {\t\tgetMenuInflater().inflate(R.menu.activity_save, menu);\t\treturn true;\t}} 这样，个人日记本的小项目就完成啦~对应的完成的项目已上传到资源~欢迎下载~","title":"android数据存储之SQLite（个人日记本）"},{"content":"部分SQLSERVER数据类型 1、char 固定长度，非Unicode字符数据，取值范围为1至8,000字节。 2、varchar：可变长度，非Unicode字符数据，取值范围为1至8,000字节。 3、nchar：n个字符的固定长度的Unicode字符数据。n值必须在1到4,000之间（含）。 4、 nvarchar：可变长度Unicode字符数据。n值在1到4,000之间（含）。 5、char，varchar：最多8000个英文，4000个汉字。 6、nchar，nvarchar：可存储4000个字符，无论英文还是汉字。 7、char，nchar：定长，速度快，占空间大，需处理    varchar，nvarchar：变长，速度慢，占空间小，无需处理。 8、Unicode字符集就是为了解决字符集这种不兼容的问题而产生的，它所有的字符都用两个字节表示，即英文字符也是用两个字节表示。 9、bit 整型    bit 数据类型是整型，其值只能是0、1或空值。这种数据类型用于存储只有两种可能值的数据，如Yes 或No、True 或False 、On 或Off。 10、int 整型    int 数据类型可以存储从-231(-2147483648)到231 (2147483 647)之间的整数。存储到数据库的几乎所有数值型的数据都可以用这种数据类型。这种数   据类型在数据库里占用4个字节。 11、numeric 精确数值型    numeric数据类型与decimal 型相同 12、decimal 精确数值型     decimal 数据类型能用来存储从-1038-1到1038-1的固定精度和范围的数值型数据。使用这种数据类型时，必须指定范围和精度。 范围是小数点左右    所能存储的数字的总位数。精度是小数点右边存储的数字的位数 13、money 货币型    money 数据类型用来表示钱和货币值。这种数据类型能存储从-9220亿到9220 亿之间的数据，精确到货币单位的万分之一 14、smallmoney 货币型    smallmoney 数据类型用来表示钱和货币值。这种数据类型能存储从-214748.3648 到214748.3647 之间的数据，精确到货币单位的万分之一 15、float 近似数值型     float 数据类型是一种近似数值类型，供浮点数使用。说浮点数是近似的，是因为在其范围内不是所有的数都能精确表示。浮点数可以是从-    1.79E+308到1.79E+308 之间的任意数 16、real 近似数值型     real 数据类型像浮点数一样，是近似数值类型。它可以表示数值在-3.40E+38到3.40E+38之间的浮点数 17、datetime 日期时间型    datetime数据类型用来表示日期和时间。这种数据类型存储从1753年1月1日到9999年12月3 1日间所有的日期和时间数据， 精确到三百分之一秒或3.33   毫秒 18、Smalldatetime 日期时间型     smalldatetime 数据类型用来表示从1900年1月1日到2079年6月6日间的日期和时间，精确到一分钟 19、cursor 特殊数据型     cursor 数据类型是一种特殊的数据类型，它包含一个对游标的引用。这种数据类型用在存储过程中，而且创建表时不能用 20、timestamp 特殊数据型    timestamp 数据类型是一种特殊的数据类型，用来创建一个数据库范围内的唯一数码。 一个表中只能有一个timestamp列。每次插入或修改一行时，   timestamp列的值都会改变。尽管它的名字中有“time”， 但timestamp列不是人们可识别的日期。在一个数据库里，timestamp值是唯一的 21、Uniqueidentifier 特殊数据型     Uniqueidentifier数据类型用来存储一个全局唯一标识符，即GUID。GUID确实是全局唯一的。这个数几乎没有机会在另一个系统中被重建。可以使用     NEWID 函数或转换一个字符串为唯一标识符来初始化具有唯一标识符的列 22、text 字符型     text 数据类型用来存储大量的非统一编码型字符数据。这种数据类型最多可以有231-1或20亿个字符 23、ntext 统一编码字符型     ntext 数据类型用来存储大量的统一编码字符型数据。这种数据类型能存储230 -1或将近10亿个字符，且使用的字节空间增加了一倍 24、binary 二进制数据类型     binary数据类型用来存储可达8000 字节长的定长的二进制数据。当输入表的内容接近相同的长度时，你应该使用这种数据类型 25、varbinary 二进制数据类型     varbinary 数据类型用来存储可达8000 字节长的变长的二进制数据。当输入表的内容大小可变时，你应该使用这种数据类型 26、image 二进制数据类型     image 数据类型用来存储变长的二进制数据，最大可达231-1或大约20亿字节","title":"部分SQLSERVER数据类型"},{"content":"下图是程序的最终效果，包含了数据的显示，添加，修改，删除这几项数据库操作的常用功能。 　 　　我的调试环境是xp，mysql版本是mysql4.0.23 　 　　1.安装Mysql的ODBC驱动     从http://www.mysql.com上下载驱动程序     地址：http://dev.mysql.com/downloads/connector/odbc/3.51.html#win32     我是下载的Windows ZIP/Setup.EXE     下载到本机之后从zip包中解压出setup.exe文件，双击安装，没什么可说的，完全的傻瓜式安装 　 　　2.设置ODBC数据源     配置MySQL的ODBC数据源有两种方法     第一种：手工设置     比较麻烦，但是确是比较安全的办法。 　 　　步骤如下：     开始 -> 控制面板 -> 管理工具 -> 数据源 （ODBC），双击数据源（ODBC）之后会出来如下的界面 　 　　点击右上角的\"添加\"按钮之后会出现如下的界面 　 　　可以看到，我们刚才安装的驱动程序已经出现在列表中了，选中它，然后单击完成，此时会出来下面的界面 　 　　按上图所示，填写好各项连接所需要的信息点击“Test”可以进行测试，如果出现sucessful字样就表示成功了 我解释一下填写的信息：Data Source Name：缩写就是DSN，中文翻译过来就是数据源名称，就是给数据源取个名，为了安全还是取英文名吧，省得出现意外。 　 　　Description：描述，可填可不填，我比较懒，就没填，想填也行，就是描述一下这个数据源是哪家的，干啥用的等等，随便吧Server：服务器，不能省，我填的是localhost，如果你有远程主机，不妨试试填上远程主机的IP地址，我没试过，不清楚User：用户名，我本地数据库用的是root，你们如果有别的就根据自己的情况填吧Password：密码，我没设置密码，有则填之，没有就留空Database：数据库，这是一个listbox，可以自己填，也可以从下拉列表中选，如果你前面的Server，User，Password都正确的话，下拉列表中会出来可选的数据库，这个就是我们要连接的数据库资源。 　 　　解释完毕，点了OK之后，我们就算设置完成了。 　 　　第二种：动态设置这种办法是指在程序执行时才添加数据源，SQLConfigDataSource是所用的方法，查msdn可以查到它的用法第一个参数一般设置成NULL就可以了，第二个参数我用的是ODBC_ADD_DSN，表示是新增数据源第三个参数是驱动的名称，在数据源（ODBC）中抄过来就OK了第四个参数是连接字符串，多个参数用\\0分隔开，DSN就是数据源名称，UID是用户名，PWD是密码，SERVER是主机名，DATABASE是数据库名称，最后用两个\\0结束。 　 　　只要在程序中加上这一行，当程序执行到它时，就会在数据源中加上你所设置的数据源，并且可以在控制面板 -> 管理工具 -> 数据源（ODBC）中查到。如图二所示，里面的odbctest和odbctestqqqq，前者就是动态创建的，后者是最初手工创建的。 　 　　SQLConfigDataSource（NULL，ODBC_ADD_DSN，\"MySQL ODBC 3.51 Driver\"，\"DSN=odbctest\\0 UID=root\\0 PWD=\\0 SERVER=localhost\\0 DATABASE=odbc\\0\\0\"）； 　 　　3.编写连接程序我用的是VC6.0，VC这东西好是好，就是封装得太多了，像我等这样初来乍到之人一时半会是狗咬乌龟——找不到下口的地方下面我就按我的方式来说说，肯定有高手有更高明的办法，不妨评论一二，也好让我等开开眼界。 　 　　（1）。创建一个基于对话框的工程在VC中点击菜单中 File -> New，在Projects的下拉菜单中选择MFC AppWizard （exe）；在右上角的输入框中填写一个工程的名字，我取名叫ODBCTest；选择一个存放目录，我的是存在E：\\c\\ODBCTest；点击OK进入下一步，选择基于对话框，然后点finish完成设置。 　 　　（2）。包含头文件切换到file view，在header files中找到stdafx.h，这是MFC第一个要包含的头文件，我们在里面加上如下两行，将odbc及数据库操作所需的头文件引入到工程中。没这两个头文件编译时会出错。 　 　　…… 　 　　#include <odbcinst.h> #include \"afxdb.h\"// 用的时候把引号换成尖括号，编辑器自动给转成了非源码形式，郁闷 　 　　//{{AFX_INSERT_LOCATION}}…… （3）。画主体对话框     主体对话框是用来列表显示数据，并放置其他操作入口的界面，在这个程序中，我们的主体对话框上会放置一个列表控件和五个按钮控件。 　 　　在资源视图上选择对话框资源，然后绘制如下图如示的对话框 　 　　对图上的控件作一下说明     1）。列表，用的是list control，注意在styles中的view要设置成report（报表），　 　　2）。依次添加了三个按钮，添加，修改，删除。 　 　　在这里做下说明，一般看网上的教程或是书，上面讲的程序的编写过程都是按步就班，没有多余的过程，因为作者都已经重新做了排版和设计工作，力求简洁。但实际编程中确是不一样的，常常要经过多次修改，重排，优化，所以这里我打算按实际程序的编写过程来说明，而不是按步就班的说明，力求还原程序编写的全过程。作为一个初学VC的新手，相信有很多跟我一样的新手也会遇到同样的困难，没关系，万事开头难。 　 　　一般的教程讲到这里就可能会去将后面所要用到的资源准备好，然后进行“系统的”编程。我这里不这样走，而是回到主窗口的编程上来，一个功能一个功能的实现。 　 　　1）。实现数据的列表显示晕了，很多人肯定会晕了。这不扯淡吗，我们的数据库（库名叫：odbc）里啥东西都还没有，显示啥呀。 　 　　没关系，好在俺也搞过Mysql几年，别的不会，管理Mysql的工具倒是知道不少，比如：EMS，phpMyAdmin，DBtools…… 　 　　我为了简单就用了phpMyadmin这个工具，这个工具需要在本地安装了php和mysql才能使用，如果本地没有装php就用不了了，不过没关系，去下载一个EMS也不错，非常强大的工具，华丽的界面，丰富的功能。用过SQL server的可能更习惯于使用DBTools Manager，这也是个强大的工具，值得一试。 　 　　二毛说，学VC，在还没有入门之前机器上就会有一堆的工具。初始还不信，现在我信了，这不，刚学没几天，机器上就跑上了VC，msdn，另外还有一堆的入门电子书，阅读器，视频播放软件……既然已经有这么多了，再多几个也无所谓了。 　 　　跑题了哈，我先刹车倒回来，接着讲数据的显示，第一步：在odbc库中建一张表list，都怪我，这库名取得有点误导观众，这里再次申明一下，这里的odbc是我建的一个MySQL数据库，不是那个该死的缩写。下面是建好之后的表 　 id：是一个自增，非负的10位整型字段，用来存放用户的ID     name：是一个40位变长的字符串，用来存放用户名     age：是一个3位的小整型字段，因为没有启用非负设置，最大可以到127，此字段存放用户年龄     这就是list表的结构，然后我们在表中插入几条初始数据，用来显示。 　 　　phpMyAdmin的使用我就不多说了，这属于工具的使用，不在本文的说明范围之内。 　 　　添加好数据之后，我们可以在phpmyadmin中浏览到它们，如下图：　 　　2）。编程显示数据列表     回到VC中来，在类视图中，找到CODBCTestDlg并展开，找到里面的OnInitDialog（）方法，此方法是对话框的初始化方法，我的最初想法就是在这里面完成数据库的连接，查询，并输出数据到列表中。于是我写了如下的代码 　   CDatabase db; db.Open(NULL,FALSE,FALSE,\"ODBC;DSN=odbctest;UID=root;PWD=\"); CRecordset rs( &db ); rs.Open( CRecordset::forwardOnly, _T(\"SELECT * FROM list order by id Asc\")); short nFields = rs.GetODBCFieldCount(); while(!rs.IsEOF()) {     CString varID;     rs.GetFieldValue(\"id\", varID);      m_list.InsertItem(0,varID);     CString varName;     rs.GetFieldValue(\"name\", varName);      m_list.SetItemText(0, 1, varName);     CString varAge;     rs.GetFieldValue(\"age\", varAge);      m_list.SetItemText(0, 2, varAge);     rs.MoveNext(); } rs.Close(); db.Close(); 但后来发现有问题，因为在后面每添加一条记录之后都需要更新列表，重新输出，这就需要再次写一段跟上面一模一样的代码，我靠，这不浪费时间吗。于是，我将上面的这段代码放到了类的一个方法中。步骤如下：     1）。在类视图中选中CODBCTestDlg，点右建，选择新增function，然后创建一个void GetRecord（）的方法，如下图 　　2）。将上面的代码放到方法中，最终的代码如下   void CODBCTestDlg::GetRecord() {     m_list.DeleteAllItems();     CDatabase db;     db.Open(NULL,FALSE,FALSE,\"ODBC;DSN=odbctest;UID=root;PWD=\");     CRecordset rs( &db );     rs.Open( CRecordset::forwardOnly, _T(\"SELECT * FROM list order by id Asc\"));     //short nFields = rs.GetODBCFieldCount();// 此行原是用来遍历表中字段，现在没有用上     while(!rs.IsEOF())     {         CString varID;         rs.GetFieldValue(\"id\", varID);         m_list.InsertItem(0,varID);         CString varName;         rs.GetFieldValue(\"name\", varName);         m_list.SetItemText(0, 1, varName);         CString varAge;         rs.GetFieldValue(\"age\", varAge);         m_list.SetItemText(0, 2, varAge);         rs.MoveNext();     }     rs.Close();     db.Close();     m_list.AdjustColumnWidth();//新增了一个CMyListCtrl类，这是里面我新增的一个方法，用来自适应数据宽度 } 　　这样，以后在需要重新取列表数据时就可以调用此方法了，这就叫重用。 　 　　ODBC连接数据库，有两个类是需要关心的，第一个是CDatabase，另一个是CRecordset     前者用于数据库连接的建立，后者用于数据集的取得     建立连接，用如下的代码来实现 　　CDatabase db；//声明一个对象     db.Open（NULL，FALSE，FALSE，\"ODBC；DSN=odbctest；UID=root；PWD=\"）；// 连接数据源     至于为什么这么写，查msdn吧 　 　　取数据集合     CRecordset rs（ &db ）；// 绑定数据源     rs.Open（ CRecordset：：forwardOnly， _T（\"SELECT * FROM list order by id Asc\"））；//查询数据 　 　　要执行sql，我并没有用ODBC提供的方法，而是用更直接的办法     CString sql；     sql.Format（\"update list set name='%s'， age='%s' where id=%d\"，str_name， str_age， item_id）；     db.ExecuteSQL（sql）； 　 　　这种办法的好处是可以不用从CRecordSet继承新类，且对我这样了解一部分sql的新手比较直观。  ","title":"MFC ODBC连接mysql数据库"},{"content":"有时回顾一下还真是唏嘘，6年就走过了6家公司，难道我不是个安分的人吗？ 第一家公司我工作满一年的时候我发现回成都能挣的更多而且生活环境更好，于是我跳了。 第二家公司因为上班地方比较远我挑了。 第三家我觉得是跳的最靠谱的为了更好地发展，于是我来到了北京。 第四家是一个机会和一个推荐，我是完全奔钱去的。           第五家也就是上一家，想来我真是还混的不错，进去就是后台的Team Leader,这时第一次正真意思上的小头目，手下有几个完全听我的安排工作的组员，其实才去的时候真的还不适应，PM把任务大把大把的安排下来，每周汇报承接新工作的时候都让我菊花一紧，会后都回去小解一把，真是压力啊，不过还好我挺过来了，渐渐的把从什么都抓在手里的习惯改为重点的抓在手里，更多的分派下去，真算是一大转变吧。然后还兼任培训，就像我说的一样的这个行业真的缺少熟手，自己培训人的感觉也不一样，开始挺好的很有成就感，后来 一有什么问题就来问你就感觉有点烦了，但是还是那句话，我对新人的态度都很好，我真心希望他们能够多学多问，哪怕自己烦点。           这回的项目是国内电信行业的大项目，国内的项目真是累人，甲方得像大爷一样伺候着，加班是越来越厉害，最后部署时去到广州更是7*16的干活哦，哎头发都白了几根，第一次觉得什么叫拿命换钱，说实在我运气还真不错，除了第一年比较累，其后的都还可以，但这次真是拼了，人生难得一回拼啊，当我离职的时候我的调休时间还有280个小时。哎，没有加班费，我用我最后的5个月的工作时间干了8个月的活，想想真是疯狂，更恐怖的是电信行业就是这样，个个厂家都很疯狂，华为也不过是其中之一罢了，这家公司我是真心觉得累了才准备闪的，开始7月份的时候找了个老家的公司，是搞电商的月薪12000，我本来是准备辞职了结果经理是苦口婆心啊，HR也是轰炸，最终没走成。后来10月底这个项目总算搞完了，我另一家的offer也拿下了才最终走人，真是舍不得啊，项目组里面的人的BI技术基本上是我带出来的，不过在干下去可能会没命啊。          第六家公司是一个著名的外企咨询公司的子公司，我光荣的成为了一名BI 顾问，当然最重要的是我的月薪2万了，哎但是我已经不激动了，只是每每回想起早年家家乡火锅店里的身影，心中还留有余香。","title":"我的6年职场人生从月薪800到2万（4）"},{"content":"由于控制文件中记录了数据库中数据文件、日志文件的位置信息，检查点信息等重要信息，在数据库的OPEN阶段，Oracle将根据控制文件中记录的这些信息找到这些文件，然后进系检查点及完整性检查。 一、OPEN阶段的一致性校验 在数据库OPEN的过程中，Oralce进行的检查中包括一下两项： 第一次检查文件头中的检查点计数（Checkpoint CNT）是否和控制文件中的检查点计数一致。此步骤检查用以确认数据文件是否来自同一版本，而不是从备份中恢复而来（因为Checkpoint CNT不会被冻结，会一直被修改）。 第二次检查文件头的开始SCN和控制文件中记录的该文件的结束SCN是否一致，如果控制文件中记录的结束SCN等于数据文件头的开始SCN，则不需要对那个文件进行恢复。对每个数据文件都完成检查后，打开数据库，锁定数据文件，同时将每个数据文件的结束SCN设置为无穷大。 如果某个数据文件丢失，在mount数据库时Oracle会在后台将文件丢失信息记录在告警日志文件中；而在open阶段，则会在前台发出错误警告，数据库将停止启动。 二、Oracle 11g Automatic Diagnostic Repository新特性 告警日志文件的存储位置收到一个新的参数影响，这个参数时diagnostic_dest: SQL> show parameter diag;NAME\t\t\t\t     TYPE\t VALUE------------------------------------ ----------- ------------------------------diagnostic_dest \t\t     string\t /home/oracle/app/oracle该目录用于存放数据库诊断日志、跟踪文件等，通常称作ADR Base。diagnostic_dest参数的缺省值和环境变量ORACLE_BASE有关： 如果设置了ORACLE_BASE，则DIAGNOSTIC_DEST=ORACLE_BASE； 如果未设置ORACLE_BASE，则DIAGNOSTIC_DEST=ORACLE_HOME/log。 ADR信息可以通过v$diag_info视图查询，其中Diag Alert和Diag Trace对应的目录分别存储了XML和文本格式的告警日志文件： SQL> select * from v$diag_info;INST_ID NAME                     VALUE--------------------------------------------------      1 Diag Enabled    \t TRUE      1 ADR Base                 /home/oracle/app/oracle      1 ADR Home                 /home/oracle/app/oracle/diag/rdbms/orcl/orcl      1 Diag Trace               /home/oracle/app/oracle/diag/rdbms/orcl/orcl/trace      1 Diag Alert               /home/oracle/app/oracle/diag/rdbms/orcl/orcl/alert      1 Diag Incident            /home/oracle/app/oracle/diag/rdbms/orcl/orcl/incident      1 Diag Cdump               /home/oracle/app/oracle/diag/rdbms/orcl/orcl/cdump      1 Health Monitor           /home/oracle/app/oracle/diag/rdbms/orcl/orcl/hm      1 Default Trace File       /home/oracle/app/oracle/diag/rdbms/orcl/orcl/trace/orcl_ora_5824.trc      1 Active Problem Count     0      1 Active Incident Count    011 rows selected.","title":"ORACLE学习笔记（三）——数据库启动（open）"},{"content":"           Effective MySQL之SQL语句最优化，性能改进的实用知识。MySQL数据库由于性能高、成本低、可靠性好等优点，已经成为最流行的开源关系型数据库产品，广泛地被使用在互联网上的中小型网站中。作为一名日常DBA，最常重复的任务就是在生产环境中检查和优化运行的SQL语句。在MYSQL软件安装、配置以及正常运行之后，监控数据库的性能问题就成为一项经常重复的工作...更多详情<< ","title":"Effective MySQL之SQL语句最优化，性能改进的实用知识。"},{"content":"一直以来，数据库就是我薄弱的地方，这次我把这些知识点稍稍整理一下。如果有机会阅读这篇文章的话，稍稍指点一下。 这篇文字写的是在[Oracle SQL*Plus]中执行的操作。 --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 我们发现，在Plus中不好操作，我们可以通过 (image) ed b 命令，创建文本文件。 我们选择是。这样我们就可以在文本中编写指令了,以分号结尾。如果我们说想修改b.sql中的指令，我们再次输ed b 就可以重新把文本调出来。  编辑完成之后，就可以通过@[文件名称]的方式执行指令了。例：（image） @b      也可以通过@找到磁盘上的文件，执行的时候要跟路径，@[路径]  （image）我们也可以省略\\   如果后缀名称是.sql，那么也可以省略后缀名，默认的后缀名是.sql如果在不同用户下查询另一个 用户的表，那么需要在表的前面加上用户名 例:select * from accp.news; accp是一个用户。因为news是属于accp用户的表。而sys用户本身没有。 如果我们不知道当前连接的用户是那一个，我们可以通过show user来查询当前连接的用户.(图) 如果我们需要从当前用户转到另一个用户,我们可以用conn sys/123456的形式,转到sys用户 如果需要得到用户所有表的名称，那么可以通过（image）命令得到。(result) 如果要查看一个表的完整结构，我们可以用desc [表名] 例: 当我们执行SQL命令，我们还需要执行上一步操作，我们可以输入 ‘/ ’执行操作。例: 暂时写到这里。------------------------------","title":"（1）Oracle数据库总结 这篇文字写的是在[Oracle SQL*Plus]中执行的操作。"},{"content":"一、整型          整数类型是数据库中最基本的数据类型。标准SQL中支持INTEGER和SMALLINT这两种整数类型。MySQL数据库除了支持这两种类型外，还扩展支持了TINYINT、MEDIUMINT和BIGINT。          各种整数类型的取值范围、存储的字节数如下：          整型        字节数  无符号数的取值范围  有符号数的取值范围          TINYINT     1       0~255                   -128~127          SMALLINT    2       0~65535                 -32768~12767          MEDIUMINT   3       0~16777215              -8388608~8388607          INT         4       0~4294967295            -2147483648~2147483647          INTEGER     4       0~4294967295            -2147483648~2147483647            BIGINT      8       0~18446744073709551615  -9223372036954775808~9223372036854775807            二、浮点数类型和定点数类型          MySQL使用浮点数类型和定点数类型来表示小数。浮点数类型包括单精度浮点数(FLOAT类型)和双精度浮点数(DOUBLE类型)。定点数类型就是DECIMAL型。          FLOAT型、DOUBLE型、DECIMAL型的取值范围、存储的字节数如下：          小数类型     字节数  负数取值范围             无符号取值范围          FLOAT        4       -3.402823466E+38~        0和1.175494351E-38~                   -1.175494351E-38         3.402823466E+38          DOUBLE       8       1.7976931348623157E+308~ 0和2.2250738585072014E~                   -2.2250738585072014E-308 1.7976931348623157E+308          DECIMAL(M,D) M+2     DOUBLE型                 同DOUBLE型          或DEC(M,D)          M:最大长度（包括小数部分，但不包括小数点）          D:小数点后保留长度          对于浮点数和定点数，当插入值的精度高于实际定义的精度，系统会自动进行四舍五入处理。其目的是为了使该值的精度达到要求。浮点数进行四舍五入不会报警，定点数出现警告。          在未指定精度的情况下，浮点数和定点数有其默认的精度。FLOAT类型和DOUBLE类型默认会保存实际精度。这个精度与操作系统和硬件的精度有关。DECIMAL类型默认整数位为10, 小数位为0，即默认为整数。          在MySQL中，定点数精度比浮点数要高。而且，浮点数会出现误差。如果要对数据的精度要求比较高，应该选择定点数。  三、日期和时间类型  1、DATETIME类型          DATETIME类型表示同时包含日期和时间信息的值。MySQL以'YYYY-MM-DD HH:MM:SS'格式检索和显示DATETIME值。支持的范围为'1000-01-01 00:00:00'～'9999-12-31 23:59:59'。  2、DATE类型          DATE类型表示只有日期值而没有时间值的值。MySQL用'YYYY-MM-DD'格式检索和显示DATE值。支持的范围为'1000-01-01'～'9999-12-31'。  3、TIME类型          TIME值可以使用多种表示格式。          'D HH:MM:SS.fraction'格式的字符串。还可以使用下面任何一种“非严格”语法'HH:MM:SS.fraction'、'HH:MM:SS'、'HH:MM'、'D HH:MM:SS'、'D HH:MM'、'D HH'或'SS'。这里D表示日，可以取0～34的值。请注意MySQL不保存分数。          'HHMMSS'格式的没有间隔符的字符串，被假定为是有意义的时间。例如，'101112'被理解为'10:11:12'，但'109712'是不合法的(它有一个没有意义的分钟部分)，其将变为'00:00:00'。          HHMMSS格式的数值，被假定为是有意义的时间。例如，101112被理解为'10:11:12'。下面的格式也可以理解：SS、MMSS、HHMMSS、HHMMSS.fraction。请注意MySQL不保存分数。  4、YEAR类型          YEAR类型是一个单字节类型，用于表示年。MySQL以YYYY格式检索和显示YEAR值。范围为1901～2155。          可以指定各种格式的YEAR值。          四位字符串，范围为'1901'～'2155'。          四位数字，范围为1901～2155。          两位字符串，范围为'00'～'99'。'00'～'69'和'70'～'99'范围的值分别被转换为2000～2069和1970～1999范围的YEAR值。          两位整数，范围为1～99。1～69和70～99范围的值分别被转换为2001～2069和1970～1999范围的YEAR值。请注意两位整数范围与两位字符串范围稍有不同，因为不能直接将零指定为数字并将它解释为2000。必须将它指定为一个字符串'0'或'00'或它被解释为0000。  5、TIMESTAMP类型          TIMESTAMP类型使用４个字节来表示日期和时间。TIMESTAMP类型的范围从1970-01-001 08:00:01到2038-01-19 11:14:07。MySQL中也是以'YYYY-MM-DD HH:MM:SS'的形式显示TIMESTAMP类型的值。从其形式可以看出，TIMESTAMP类型与DATETIME类型显示的格式一样的。给TIMESTAMP类型的字段赋值的表示方法基本与DATETIME类型相同。值的注意的是，TIMESTAMP类型范围比较小，没有DATETIME类型的范围大。因此，输入值时要保证在TIMESTAMP类型时有效范围内。            四、字符串类型          字符串类型是在数据库中存储字符串的数据类型。  1、CHAR类型和VARCHAR类型          CHAR类型和VARCHAR类型都是在创建表时指定最大长度，其基本形式如下：          字符串类型(M)          例如，CHAR(4)就是指数据类型为CHAR类型，其最大长度为4。            CHAR类型的长度是固定的，在创建表时就指定了。其长度可以是0~255的任意值。          例如，CHAR(100)就是指定CHAR类型的长度为100。          VARCHAR类型的长度是可变的，在创建时指定了最大长度。定义时，其最大值可以取0~65535之间的任意值。指定VARCHAR类型的最大值以后，其长度可以在0到最大长度之间。例如，VARCHAR(100)的最大长度是100。但是，不是每条记录都要占100个位置。而是在这个最大值范围内，使用多少分配多少。VARCHAR类型实际占用的空间为字符串的实际长度加1。这样，可以有效的节约系统的空间。  2、TEXT类型          TEXT类型是一种特殊的字符串类型。TEXT只能保存字符数据，如文章等。TEXT类型包含TINYTEXT、TEXT、MEDIUMTEXT和LONGTEXT。          类型        允许的长度       存储空间          TINYTEXT    0~255字节        值的长度+2个字节          TEXT        0~65535字节      值的长度+2个字节          MEDIUMTEXT  0~167772150字节  值的长度+3个字节          LONGTEXT    0~4294967295字节 值的长度+4个字节          从表可以看出，各种TEXT类型的区别在于允许的长度和存储空间不同。因此在这几种TEXT中，根据需求选取既能满足需要以最节约空间的类型即可。    3、ENUM类型(枚举类型)          ENUM类型又称为枚举类型。在创建表时，ENUM类型的取值范围就以列表的形式指定了。          属性名 ENUM('值1', '值2',...., '值n');          其中， '属性名'参数指定字段名称；'值n'参数表示列表中的第n个值，这些值末尾的空格将会被系统直接删除。          ENUm类型的值只能列表中的一个元素。其取值列表中最多能有65535个值。列表中的每个值都有一个顺序排序的编号，MySQL中存入的是这个编号，而不是列表中的值。          如果ENUm类型加上了NOT NULL属性，其默认值为取值列表的第1个元素。如果不加NOT NULL属性，ENUm类型将允许插入NULL，而且NULL为默认值。          CREATE TABLE IF NOT EXISTS `test`.`enum_tbl`(          `a` ENUM('male','female'),          `b` ENUM('true','false') NOT NULL          );          INSERT INTO `test`.`enum_tbl`           VALUES('male', 'true'),(NULL, 'false'), (NULL, NULL),(20, 20);          SELECT * FROM `enum_tbl`;  4、SET类型          基本形式如下：          属性名 set('值1','值2','值3'...'值n');          其中，'属性名'参数指定字段名称；'值n'参数列表中的第n个值,这些值末尾的空格将会被系统直接删除。其基本形式与ENUM类型一样。          SET类型的值可以取列表中一个元素或者多个元素的组合。取多个元素时，不同元素之间用逗号隔开。SET类型的值最多只能是64个元素构成的组合。列表中的每一个值都有一个顺序排列的编号。MySQL中存入的是这个编号，而不是列表中的值。          插入记录时，SET字段里的元素顺序无关紧要。存入MySQL数据库后，数据库系统会自动按照定义时的顺序显示。          CREATE TABLE IF NOT EXISTS `test`.`set_tbl`(          `a` SET('a','b','c','d','e','f','g')          );          INSERT INTO `test`.`set_tbl`    VALUES('f'),('a,b,c'),('d,e,a');          INSERT INTO `test`.`set_tbl` VALUES('h');          SELECT * FROM `set_tbl`;            五、二进制类型          二进制类型是在数据库中存储二进制数据的数据类型。          二进制类型   取值范围          BINARY(M)    字节数为M，允许长度为0~M的定长二进制字符串          VARBINARY(M) 允许长度为0~M的变长二进制字符串，字节数为值的长度加一          BIT(M)       M位二进制数据，M最大值为64          TINYBLOB     可变长二进制数据，最多255个字节          BLOB         可变长二进制数据，最多(2[16]-1)个字节          MEDIUMBLOB   可变长二进制数据，最多(2[24]-1)个字节          LONGBLOB     可变长二进制数据，最多(2[32]-1)个字节  1、BINARY和VARBINARY类型          BINARY和VARBINARY类型都是在创建表时指定了最大长度，其基本形式如下 ：          字符串类型(M)          这与CHAR类型和VARCHAR类型相似。          例如，BINARY(10)就是指数据类型为BINARY类型，其最大长度为10。          BINARY类型的长度是固定的，在创建表是就指定了。不足最大长度的空间由\"\\0\"补全。例如，BINARY(50)就是指定BINARY类型的长度为50。          VARBINARY类型的长度是可变的，在创建表时指定了最大长度。指定好了VARBINARY类型的最大值以后，基长度可以在0到最大长度之间。例如，VARBINARY(50)的最大字节长度是50。但是，不是每条记录的字节长度都是50。在这个最大范围内，使用多少分配多少。VARBINARY类型实际占用的空间为实际长度加一。这样，可以有效的节约系统的空间。  2、BIT类型          BIT类型也是创建表时指定了最大长度，其基本形式如下：          BIT(M)          其中，'M'指定了该二进制的数的最大字节长度为M，M的最大值为64。例如，BIT(4)就是数据类型BIT类型，长度为4.若字段的类型BIT(4)，存储的数据是从0到15。因为，变成二进制以后，15的值为1111，其长度为4。如果插入的值为16，其二进制数为10000，长度为5，超过了最大长度。因此大于等于16的数是不能插入到BIT(4)类型的字段中的。在查询BIT类型的数据时，要用BIN(字段名+0)来将值转换为二进制显示。  3、BLOB类型          BLOB类型是一种特殊的二进制类型。BLOB可以用来保存数据量很大的二进制数据，如图片等。BLOB类型包括TINYBLOB、BLOB、MEDIUMBLOB和LONGBLOB。这几种BLOB类型最大的区别就是能够保存的最大长度不同。LONGBLOB的长度最大，TINYBLOB的长度最小。          BLOB类型与TEXT类型很类似。不同点在于BLOB类型用于存储二进制数据，BLOB类型数据是根据其二进制编码进行比较和排序。而TEXT类型是文本模式进行比较和排序的。","title":"MYSQL入门学习之四：MYSQL的数据类型"},{"content":"使用一种特殊的编程语言、编程很牛，单单靠这个并不能说一名程序员/开发者就是优秀程序员/开发者。快速发展的开发环境使得这个行业比我今天看到的任何一个行业都要发展迅速，这既有积极的一面也有消极的一面：今天的程序员/开发者有很多编程语言、开发工具和开发平台可选，但是建立一个安全、可扩展的环境却变得难了很多；硬件和软件正日新月异地变得更加复杂，但现在学习新技术比过去要难太多了。 以下是优秀程序员应当具备的品质： 语言和工具（Languages and Tools:） 任何程序员/开发者需要具备的第一个技能就是，能够用编程语言工作并会使用与之相关的主要开发工具，包括：工具、IDEs, web 框架, messaging APIs。 程序设计方法（Programming Paradigm:） 举例来说，很好地理解面向对象，这对使用强制式语言(Imperative Language也称过程式语言)写出可维护的代码至关重要。在企业开发中你会遇到各种不同的问题，理解多种程序设计方法并知道何时使用，将使这些问题迎刃而解。 领域专长的知识（Domain Specific Knowledge:） 如果想编写系统来解决特定领域内的问题，那么拥有该领域的专长知识将非常重要。尽管许多这样的知识是由项目的商业分析员（Business Analyst）来获悉，但如果开发者也能获取，那么跟用户的交流将会更加容易，而且更能够理解他们的专业词汇。 人际关系（People Skills：） 软件开发中最重要的技能之一就是能够与其他开发者一起高效工作——同事、质量/商业分析员（Quality/Business Analysts），客户，用户，很多很多……如果你能够很好地处理这些关系，那么成功的大路也离你不远矣。 解决问题（Problem Solving：） 有能力解决那些没有明显解决方法的问题，这一点在软件开发中很重要。当把你的应用配置到JBoss或者通过一个测试找到一个棘手bug的时候，理智地编程将成为调试一个类路径(class path)问题。 沟通能力（Good Communication skills：） 在软件世界中，人们通常认为好的沟通能力就是流利地说话，事实上这远不是。这指的是：你能够多么有效地与其他人交流。作为一名优秀的开发者，你应当能够很好地表达你的想法，很好地听，以及很好地掌控你与他人沟通的过程。 读书（Read Books：） 读大量书将了解很多不同的技术，读书使你对一种技术有了快速、直接的视角。通常你应当选择知名学者的书，他们推崇实践和用技术解决问题的多种方法。在这个过程中，你将学到很多并逐渐形成自己的方法。没准哪天你也就能出书了呢。 实践、实践再实践（Practice, Practice and Practice） 许多开发者拥有大量理论知识，他们饱览书籍和技术资料。然而，怎样运用这些知识却让他们望而却步。这是因为他们缺乏实践。你工作的效率和效力只能通过你实践中编写代码来获得。唯一能使你成为优秀开发者的方法就是实践、实践再实践。 遵循范例和最好的实践（Follow Patterns and Best Practices :） 范例和实践反映了技术指导、常见技术问题和基于真实事件的实践。学习的过程是循序渐进的，但是一劳永逸。这会节省你非常多的时间和精力，让你的工作更加有效。遵循一本“代码编程指南”（Code Design Guideline），经常使用代码分析工具将检测和分析你的代码。 讨论/小组沟通（Discussion/Newsgroup:） 参加开发社区会提高你的领导能力以及贡献感，二者都是成功的必需品。在社区内参加一场含量较高的技术讨论将使你充满成就感，而且会增长你的知识，因为其中的智者会查看和评点你的解决方法，你也会查看和评点他们的。而且这个过程教会你接纳并感激别人的建议。如果她/他做出了积极的贡献，不要忘了赞扬和鼓励（'pat someone on the back'）。 网络和数据库知识（Knowledge of Networking and Databases:） 有人也许不赞成这点，但是一个优秀的开发者应当知道网络和数据库的基本东西。而且在思考解决方法的时候，不要忘记将二者考虑在内。拥有二者的知识，能够帮你写出更好的代码并节省你很多时间。 博客、写文章（Blog/ Write Articles:） 我们中有谁能够记住每件事？我不能，所以我把他们记下来。当我需要的时候，可以回头翻阅参考。除此之外，我可以借此从读者那里获得反馈，让我对同样的问题收获更多的方法。我已经获悉了许多与我工作有关的反馈，虽然有好有坏，但我会一一验证，这个过程也让我受益匪浅。 KISS 不要想歪了，这里的KISS不是你想的那样，是指让应用/方法直短、简单（Keep Implementations/Approaches Short and Simple的简写）。不要使用行话来让事情更加复杂，因为人们很难理解它们。最好的方法是简化你的设计并避免过度设计（over-engineering）的东西。 像测试者一样思考（Think as a Tester:） 开发者和测试者，来自两个不同阵营的两类人群，随时准备同彼此较量。我发现二者的合作将产生非常好的结果。既不会损害开发者的利益也不会损害测试者的利益。实际上，长期来看，像测试者一样思考有利于减少你代码的bug，而且会形成很好的编程习惯和思维。 坚持一致是游戏规则（Consistency is the name of the game:） 你是否经常跳槽或者被你的薪水所打击？如果是，那么静坐下来放松下并重新规划。好好想想不要让你的决定天马行空，为了不断向前，你需要一个坚实的决定并坚持不懈。 参加技术研讨会/大事件（Attend technology seminars and events:） 如果你所在的城市有技术研讨会，一定要抽出时间参加。大部分的研讨会是免费的，而且会提供新技术的重要信息。 万家通吃还是一门独大？（Jack of all or Master of One?:） 嗯……这个问题不好回答。在现在的环境下，你必须掌握一种以上的技术。尽管这不容易，但是好的开发者还是能够做到。其中的关键就在于适应性：如果你精于某种技术，那么给以机会你将较容易地在短期内掌握一种新技术。你不妨试试，多掌握一种技术可以让你在使用中对比、选择。 停止抱怨（Stop complaining：） 是否软件没有做成，是否测试人员给你检查出一堆bug？许多开发者的本能反应是抵制情绪进而非常抵制这种情况。由于这种情绪是自然反应未经控制，所以它不可取。静心分析为什么软件失败、为什么有如此多bug，这是一个学习的经历将使你未来的工作受益良多。 最后，请记住你不是要永远做个程序员。所以一旦你自我满足并觉得自己是个优秀的程序员，你就得重新规划你自己（re-program yourself）。扩展你的兴趣。开发只是这个过程的一部分，了解用户和商业实际上是一种艺术，每个人应当以此为目标并努力掌握它。","title":"18条提升程序员水平的建议"},{"content":"MYSQL备份方法 本文总结了MySQL数据库备份及恢复常用命令mysqldump,source的用法。还原一个数据库:mysql -h localhost -u root -p123456 www 　　备份一个数据库:mysqldump -h localhost -u root -p123456 www >d:\\www2008-2-26.sql //以下是在程序中进行测试 　　//$command =\"mysqldump --opt -h $dbhost -u$dbuser -p $dbpass $dbname | gzip > $backupFile\"; 　　$command=\"mysqldump -h localhost -u root-p123456 guestbook > guestbook2-29.sql\"; 　　system($command); 　　echo \"success\"; ************************************************ 　　备份MySQL数据库的命令 　　mysqldump -hhostname -uusername -ppassword databasename >backupfile.sql 　　备份MySQL数据库为带删除表的格式 　　备份MySQL数据库为带删除表的格式，能够让该备份覆盖已有数据库而不需要手动删除原有数据库。 　　mysqldump -–add-drop-table -uusername -ppassword databasename >backupfile.sql 　　直接将MySQL数据库压缩备份 　　mysqldump -hhostname -uusername -ppassword databasename | gzip >backupfile.sql.gz 　　备份MySQL数据库某个(些)表 　　mysqldump -hhostname -uusername -ppassword databasenamespecific_table1 specific_table2 > backupfile.sql 　　同时备份多个MySQL数据库 　　mysqldump -hhostname -uusername -ppassword –databases databasename1databasename2 databasename3 > multibackupfile.sql 　　仅仅备份数据库结构 　　mysqldump –no-data –databases databasename1 databasename2databasename3 > structurebackupfile.sql 　　备份服务器上所有数据库 　　mysqldump –all-databases > allbackupfile.sql 　　还原MySQL数据库的命令 　　mysql -hhostname -uusername -ppassword databasename <backupfile.sql 　　还原压缩的MySQL数据库 　　gunzip < backupfile.sql.gz | mysql -uusername -ppassworddatabasename 　　将数据库转移到新服务器 　　mysqldump -uusername -ppassword databasename | mysql –host=*.*.*.*-C databasename   　　几个常用用例： 　　1.导出整个数据库 　　mysqldump -u 用户名 -p 数据库名 > 导出的文件 名                                                                                                                             　　mysqldump -u root -p dataname >dataname.sql 这个时候会提示要你输入root用户名的密码,输入密码后dataname数据库就成功备份在mysql/bin/目录中. 　　2.导出一个表 　　mysqldump -u 用户名 -p 数据库名 表名> 导出的文件名 　　mysqldump -u root -p dataname users> dataname_users.sql 　　3.导出一个数据库结构 　　mysqldump -u wcnc -p -d –add-drop-table smgp_apps_wcnc>d:\\wcnc_db.sql 　　-d 没有数据 –add-drop-table 在每个create语句之前增加一个drop table 　　4.导入数据库 　　常用source 命令 　　进入mysql数据库控制台， 　　如mysql -u root -p 　　mysql>use 数据库 　　然后使用source命令，后面参数为脚本文件(如这里用到的.sql) 　　mysql>source d:\\wcnc_db.sql 　　mysqldump支持下列选项： 　　–add-locks 　　在每个表导出之前增加LOCK TABLES并且之后UNLOCK TABLE。(为了使得更快地插入到MySQL)。 　　–add-drop-table 　　在每个create语句之前增加一个drop table。 　　–allow-keywords 　　允许创建是关键词的列名字。这由表名前缀于每个列名做到。 　　-c, –complete-insert 　　使用完整的insert语句(用列名字)。 　　-C, –compress 　　如果客户和服务器均支持压缩，压缩两者间所有的信息。 　　–delayed 　　用INSERT DELAYED命令插入行。 　　-e, –extended-insert 　　  　　使用全新多行INSERT语法。(给出更紧缩并且更快的插入语句)   　　-#, –debug[=option_string] 　　跟踪程序的使用(为了调试)。 　　–help 　　显示一条帮助消息并且退出。 　　–fields-terminated-by=… 　　–fields-enclosed-by=… 　　–fields-optionally-enclosed-by=… 　　–fields-escaped-by=… 　　–fields-terminated-by=…  　　这些选择与-T选择一起使用，并且有相应的LOAD DATA INFILE子句相同的含义。 　　LOAD DATA INFILE语法。 　　-F, –flush-logs 　　在开始导出前，洗掉在MySQL服务器中的日志文件。 　　-f, –force, 　　即使我们在一个表导出期间得到一个SQL错误，继续。 　　-h, –host=.. 　　从命名的主机上的MySQL服务器导出数据。缺省主机是localhost。 　　-l, –lock-tables. 　　为开始导出锁定所有表。 　　-t, –no-create-info 　　不写入表创建信息(CREATE TABLE语句) 　　-d, –no-data 　　不写入表的任何行信息。如果你只想得到一个表的结构的导出，这是很有用的! 　　–opt 　　同–quick –add-drop-table –add-locks –extended-insert –lock-tables。 　　应该给你为读入一个MySQL服务器的尽可能最快的导出。 　　-pyour_pass, –password[=your_pass] 　　与服务器连接时使用的口令。如果你不指定“=your_pass”部分，mysqldump需要来自终端的口令。 　　-P port_num, –port=port_num 　　与一台主机连接时使用的TCP/IP端口号。(这用于连接到localhost以外的主机，因为它使用 Unix套接字。) 　　-q, –quick 　　不缓冲查询，直接导出至stdout;使用mysql_use_result()做它。 　　-S /path/to/socket, –socket=/path/to/socket 　　与localhost连接时(它是缺省主机)使用的套接字文件。 　　-T, –tab=path-to-some-directory 　　对于每个给定的表，创建一个table_name.sql文件，它包含SQL CREATE 命令，和一个table_name.txt文件，它包含数据。注意：这只有在mysqldump运行在mysqld守护进程运行的同一台机器上的时候才工作。.txt文件的格式根据–fields-xxx和 –lines–xxx选项来定。 　　-u user_name, –user=user_name 　　与服务器连接时，MySQL使用的用户名。缺省值是你的Unix登录名。 　　-O var=option, –set-variable var=option 　　设置一个变量的值。可能的变量被列在下面。 　　-v, –verbose 　　冗长模式。打印出程序所做的更多的信息。 　　-V, –version 　　打印版本信息并且退出。 　　-w, –where=’where-condition’ 　　只导出被选择了的记录;注意引号是强制的! 　　“–where=user=’jimf’” “-wuserid>1″ “-wuserid<1″  　　最常见的mysqldump使用可能制作整个数据库的一个备份： mysqldump –opt database > backup-file.sql  　　但是它对用来自于一个数据库的信息充实另外一个MySQL数据库也是有用的： mysqldump –opt database | mysql –host=remote-host -C database  　　由于mysqldump导出的是完整的SQL语句，所以用mysql客户程序很容易就能把数据导入了： 　　shell> mysqladmin createtarget_db_name 　　shell> mysql target_db_name < backup-file.sql  　　就是 shell> mysql 库名 < 文件名  ","title":"MYSQL备份方法"},{"content":"  SQL语法大全     为了建立交互站点，你需要使用数据库来存储来自访问者的信息。例如，你要建立一个职业介绍服务的站点，你就需要存储诸如个人简历，所感兴趣的工作等等这样的信息。创建动态网叶也需要使用数据库，如果你想显示符合来访者要求的最好的工作，你就需要从数据库中取出这份工作的信息。你将会发现，在许多情况下需要使用数据库。     在这一章里，你将学会怎样使用“结构化查询语言”（SQL〕来操作数据库。SQL语言是数据库的标准语言。在Active Sever Pages 中，无论何时你要访问一个数据库，你就要使用SQL语言。因此，掌握好SQL对ASP编程是非常重要的。          注意：     你可以把“SQL”读作“sequel”，也可以按单个字母的读音读作S－Q－L。                        两种发音都是正确的，每种发音各有大量的支持者。在本书里，认为“SQL”读作“sequel”。       通过这一章的学习，你将理解怎样用SQL实现数据库查询，你将学会怎样使用这种查询从数据表中取出信息，最后，你将学会怎样设计和建立自己的数据库。                 注意：     通过下面几章对SQL的介绍，你将对SQL有足够的了解，从而可以有效地使用Active Sever Pages。但是，SQL是一种复杂的语言，本书不可能包括它的全部细节。要全面掌握SQL语言，你需要学习在Microsoft SQL Sever 中使用SQL。你可以到附近的书店去买一本Microsoft SQL Sever 6.5。   SQL介绍：     本书假设你是在SQL操作Microsoft SQL Sever 的数据库。你也可以用SQL操作许多其它类型的数据库。SQL是操作数据库的标准语言。（事实上，关于SQL语言有一个专门的ANSI标准〕       注意：     不要在你的站点上试图用Microsoft Access代替Microsoft SQL Sever。SQL Sever可以同时服务于许多用户，如果你希望你的站点有较高的访问率，MSAccess是不能胜任的。       在学习SQL的细节之前，你需要理解它的两大特点。一个特点容易掌握，另一个掌握起来有点困难。     第一个特点是所有SQL数据库中的数据都存储在表中。一个表由行和列组成。例如，下面这个简单的表包括name和e-mail address：     Name                  Email Address    ................................................................     Bill Gates               billg@microsoft.com     president Clinton         president@whitehouse.com     StephenWalther         swalther@somewhere.com     这个表有两列（列也称为字段，域〕：Name和Email Address。有三行，每一行包含一组数据。一行中的数据组合在一起称为一条记录。     无论何时你向表中添加新数据，你就添加了一条新记录。一个数据表可以有几十个记录，也可以有几千甚至几十亿个记录。虽然你也许永远不需要存储十亿个Email地址，但知道你能这样做总是好的，也许有一天你会有这样的需要。     你的数据库很有可能包含几十个表，所有存储在你数据库中的信息都被存储在这些表中。当你考虑怎样把信息存储在数据库中时，你应该考虑怎样把它们存储在表中。     SQL的第二个特点有些难于掌握。这种语言被设计为不允许你按照某种特定的顺序来取出记录，因为这样做会降低SQL Sever取记录的效率。使用SQL，你只能按查询条件来读取记录。     当考虑如何从表中取出记录时，自然会想到按记录的位置读取它们。例如，也许你会尝试通过一个循环，逐个记录地扫描，来选出特定的记录。在使用SQL时，你必须训练自己，不要有这种思路。     假如你想选出所有的名字是“Bill Gates”的记录，如果使用传统的编程语言，你也许会构造一个循环，逐个查看表中的记录，看名字域是否是“Bill Gates”。     这种选择记录的方法是可行的，但是效率不高。使用SQL，你只要说，“选择所有名字域等于Bill Gates的记录”，SQL就会为你选出所有符合条件的记录。SQL会确定实现查询的最佳方法。     建设你想取出表中的前十个记录。使用传统的编程语言，你可以做一个循环，取出前十个记录后结束循环。但使用标准的SQL查询，这是不可能实现的。从SQL的角度来说，在一个表中不存在前十个记录这种概念。     开始时，当你知道你不能用SQL实现某些你感觉应该能实现的功能，你会受到挫折。你也许会以头撞墙甚至想写恶毒的信件给SQL的设计者们。但后来你会认识到，SQL的这个特点不仅不是个限制，反而是其长处。因为SQL不根据位置来读取记录，它读取记录可以很快。     综上所述，SQL有两个特点：所有数据存储在表中，从SQL的角度来说，表中的记录没有顺序。在下一节，你将学会怎样用SQL从表中选择特殊的记录。   使用SQL从表中取记录。     SQL的主要功能之一是实现数据库查询。如果你熟悉Internet 引擎，那么你已经熟悉查询了。你使用查询来取得满足特定条件的信息。例如，如果你想找到有ASP信息的全部站点，你可以连接到 Yahoo!并执行一个对Active Sever Pages的搜索。在你输入这个查询后，你会收到一个列表，表中包括所有其描述中包含搜索表达式的站点。     多数Internet 引擎允许逻辑查询。在逻辑查询中，你可以包括特殊的运算符如AND、OR和NOT，你使用这些运算符来选择特定的记录。例如，你可以用AND来限制查询结果。如果你执行一个对Active Sever Pages  AND SQL的搜索。你将得到其描述中同时包含Active Sever Pages 和SQL的记录。当你需要限制查询结果时，你可以使用AND。     如果你需要扩展查询的结果，你可以使用逻辑操作符OR。例如，如果你执行一个搜索，搜索所有的其描述中包含Active SeverPages  OR SQL的站点，你收到的列表中将包括所有其描述中同时包含两个表达式或其中任何一个表达式的站点。     如果你想从搜索结果中排除特定的站点，你可以使用NOT。例如，查询“Active Sever Pages  ”AND NOT “SQL”将返回一个列表，列表中的站点包含Active  Sever Pages，但不包含SQL。当必须排除特定的记录时，你可以使用NOT。     用SQL执行的查询与用Internet搜索引擎执行的搜索非常相似。 当你执行一个SQL查询时，通过使用包括逻辑运算符的查询条件，你可以得到一个记录列表。此时查询结果是来自一个或多个表。     SQL查询的句法非常简单。假设有一个名为email_table 的表，包含名字和地址两个字段，要得到Bill Gates 的e_mail地址,你可以使用下面的查询：       SELECT email from email_table WHEREname=\"Bill Gates\"       当这个查询执行时，就从名为email_table的表中读取Bill Gates的e_mail 地址。这个简单的语句包括三部分：     ■  SELECT语句的第一部分指名要选取的列。在此例中，只有email列被选取。当执行 时，只显示email列的值 billg@microsoft.com。     ■  SELECTT语句的第二部份指明要从哪个（些）表中查询数据。在此例中，要查询的表名为email_table 。     ■  最后，SELECT语句的WHERE子句指明要选择满足什么条件的记录。在此例中，查询条件为只有name列的值为Bill Gates 的记录才被选取。     Bill Gates很有可能拥有不止一个email地址。如果表中包含Bill Gates的多个email地址。用上述的SELECT语句可以读取他所有的email地址。SELECT语句从表中取出所有name字段值为Bill Gates 的记录的email 字段的值。     前面说过，查询可以在查询条件中包含逻辑运算符。假如你想读取Bill Gates 或Clinton总统的所有email地址，你可以使用下面的查询语句：       SELECT email  FROM  email_table WHERE  name=\"Bill Gates\"OR                                                   name=\"president Clinton\"       此例中的查询条件比前一个复杂了一点。这个语句从表email_table中选出所有name列为Bill Gates或president Clinton的记录。如果表中含有Bill Gates或president Clinton的多个地址，所有的地址都被读取。     SELECT语句的结构看起来很直观。如果你请一个朋友从一个表中为你选择一组记录，你也许以非常相似的方式提出你的要求。在SQL SELECT语句中，你“SELECT特定的列FROM一个表WHERE某些列满足一个特定的条件”。     下一节将介绍怎样执行SQL查询来选取记录。这将帮助你熟悉用SELECT语句从表中取数据的各种不同方法。   使用ISQL执行SELECT查询     当你安装SQL Sever时，你同时安装了一个叫作ISQL/w的应用程序。ISQL/w允许你执行交互的SQL查询。在把查询包括到你的ASP网页中之前，用ISQL/w对其进行测试是非常有用的。       注意：     在这本书的第一部份，你学习了怎样安装和配置Microsoft SQL Sever 。如果没有安装SQL Sever或者SQL Sever不能运行，请参阅第三章“安装和使用SQL Sever”。       选择任务上SQL Sever程序组中的ISQL_w以启动该程序。程序启动时，首先会出现一个对话框，要求输入服务器信息和登录信息（见图10.1）。在Sever框中，输入你的SQL服务器的名字。如果服务器正运行在本地计算机上，服务器名字就是你计算机的名字。在登录信息框中，输入一个登录帐号和密码或选择使用“可信连接”，然后单击Connect按钮。         图10。1           注意：     如果你将SQL Sever配置为使用完整安全或混合安全，那么你可以使用可信连接。如果你使用标准安全，你则需要提供用户帐号和密码。要了解更多信息，参见第三章。       如果一切正常，在你单击连接按钮后会出现一个查询窗口，如图10.2所示。（如果有异常，请参考第三章）             图10.2         在执行查询之前，你需要选择数据库。安装 SQL Sever时你已为自己创建了一个数据库，SQL Sever还有许多系统数据库，如master，model，msdb，和tempdb。     方便的是，SQL Sever带有一个特殊的名为pubs的例子数据库。库 pubs中包含供一个虚拟的出版商使用的各个表。文档中所有的例子程序都是针对这个库来设计的。本书中的许多例子也使用这个数据库。     在查询窗口顶部的DB下拉框中选择数据库pubs，这样你就选择了数据库。你所有的查询都将针对这个库中的各个表来执行。现在你可以执行你的第一个查询了。这真让人兴奋！     你的第一个查询将针对一个名为autrors的表，表中包含所有为某个虚拟出版商工作的作者的相关数据。单击查询窗口并输入以下的语句：       SELECT phone  FROM authors WHEREau_name=\"Ringer\"       输入完成后，单击执行查询按钮（一个绿色三角形，看起来像VCR播放键）。单击此按钮后，任何出现在查询窗口中的语句均会被执行。查询窗口会自动变成结果显示窗口，你可以看到查询的结果（见图10.3）。     你看到的查询结果也许与图10.3所示的不同。在SQL Sever的不同版本中，库pubs中的数据会有所不同。对SQL Sever 6.5来说，将会找到两条记录。结果显示窗口中应显示如下内容：         phone ………………. 801 826_0752 801 826_0752     (2 row(s)  affected)         图10.3           你所执行的SELECT语句从表authors中取出所有名字为Ringer的作者的电话号码。你通过在WHERE子句中使用特殊的选择条件来限制查询的结果。你也可以忽略选择条件，从表中取出所有作者的电话号码。要做到这一点，单击Query标签，返回到查询窗口，输入以下的SELECT语句：   SELECTPhone  FROM authors     这个查询执行后，会取出表authors中的所有电话号码（没有特定的顺序）。如果表authors中包含一百个电话号码，会有一百个记录被取出，如果表中有十亿个电话号码，这十亿条记录都会被取出（这也许需要一些时间）。     表authrs的字段包括姓，名字，电话号码，地址，城市，州和邮政编码。通过在SELECT语句的第一部份指定它们，你可以从表中取出任何一个字段。你可以在一个SELECT语句中一次取出多个字段，比如：       SELECT au_fname ,au_lname, phone FROMauthors       这个SELECT语句执行后，将取出这三个列的所有值。下面是这个查询的结果的一个示例（为了节省纸张，只显示查询结果的一部分，其余记录用省略号代替）：       au_fname          au_lname                 phone     ………………………………………………………………………….     Johnson            White                    408  496_7223     Marjorie            Green                    415  986_7020     Cheryl              Carson                  415  548_7723     Michael             O’Leary                 408  286_2428     …     (23 row(s)  affected)       在SELECT语句中，你需要列出多少个字段，你就可以列出多少。不要忘了把字段名用逗号隔开。你也可以用星号（*）从一个表中取出所有的字段。这里有一个使用星号的例子：       SELECT *  FROM  authors       这个SELECT语句执行后，表中的所有字段的值都被取出。你会发现你将在SQL查询中频繁使用星号。       技巧：     你可以使用星号来查看一个表的所有列的名字。要做到这一点，只需要在执行完SELECT语句后看一下查询结果的列标题。   操作多个表     到现在为止，你只尝试了用一句SQL查询从一个表中取出数据。你也可以用一个SELECT语句同时从多个表中取出数据，只需在SELECT语句的FROM从句中列出要从中取出数据的表名称即可：             SELECT au_lname ,title  FROM authors, titles         这个SELECT语句执行时，同时从表authors和表titles中取出数据。从表authors中取出所有的作者名字，从表titles中取出所有的书名。在ISQL/w程序中执行这个查询，看一下查询结果。你会发现一些奇怪的出乎意料的情况：作者的名字并没有和它们所著的书相匹配，而是出现了作者名字和书名的所有可能的组合，这也许不是你所希望见到的。     出了什么差错？问题在于你没有指明这两个表之间的关系。你没有通过任何方式告诉SQL如何把表和表关联在一起。由于不知道如何关联两个表，服务器只能简单地返回取自两个表中的记录的所有可能组合。     要从两个表中选出有意义的记录组合，你需要通过建立两表中字段的关系来关联两个表。要做到这一点的途径之一是创建第三个表，专门用来描述另外两个表的字段之间的关系。     表authors有一个名为au_id的字段，包含有每个作者的唯一标识。表titles有一个名为title_id的字段，包含每个书名的唯一标识。如果你能在字段au_id和字段title_id 之间建立一个关系，你就可以关联这两个表。数据库pubs中有一个名为titleauthor的表，正是用来完成这个工作。表中的每个记录包括两个字段，用来把表titles和表authors关联在一起。下面的SELECT语句使用了这三个表以得到正确的结果：       SELECT au_name,title FROM authors,titles,titleauthor                             WHERE authors.au_id=titleauthor.au_id                              AND   titles.title_id=titleauthor.title_id          当这个SELECT语句执行时，每个作者都将与正确的书名相匹配。表titleauthor指明了表authors和表titles的关系，它通过包含分别来自两个表的各一个字段实现这一点。第三个表的唯一目的是在另外两个表的字段之间建立关系。它本身不包含任何附加数据。     注意在这个例子中字段名是如何书写的。为了区别表authors和表titles中相同的字段名au_id，每个字段名前面都加上了表名前缀和一个句号。名为author.au_id 的字段属于表authors，名为titleauthor.au_id的字段属于表titleauthor，两者不会混淆。     通过使用第三个表，你可以在两个表的字段之间建立各种类型的关系。例如，一个作者也许写了许多不同的书，或者一本书也许由许多不同的作者共同完成。当两个表的字段之间有这种“多对多”的关系时，你需要使用第三个表来指明这种关系。     但是，在许多情况下，两个表之间的关系并不复杂。比如你需要指明表titles和表publishers之间的关系。因为一个书名不可能与多个出版商相匹配，你不需要通过第三个表来指明这两个表之间的关系。要指明表titles和表publishers之间的关系，你只要让这两个表有一个公共的字段就可以了。在数据库pubs中，表titles和表publishers都有一个名为pub_id的字段。如果你想得到书名及其出版商的一个列表，你可以使用如下的语句：     SELECT title,pub_name  FROM  titles,publishers                                WHERE titles.pub_id=publishers.pub_id       当然，如果一本书是由两个出版商联合出版的，那么你需要第三个表来代表这种关系。     通常，当你予先知道两个表的字段间存在“多对多”关系时，就使用第三个表来关联这两个表。反之，如果两个表的字段间只有“一对一”或“一对多”关系，你可以使用公共字段来关联它门。   操作字段     通常，当你从一个表中取出字段值时，该值与创建该表时所定义的字段名联系在一起。如果你从表authors中选择所有的作者名字，所有的值将会与字段名au_lname相联系。但是在某些情况下，你需要对字段名进行操作。在SELECT语句中，你可以在缺省字段名后面仅跟一个新名字来取代它。例如，可以用一个更直观易读的名字Author Last Name来代替字段名au_lname：       SELECT au_lname \"Author LastName\" FROM authors       当这个SELECT语句执行时，来自字段au_lname的值会与“Author Last Name”相联系。查询结果可能是这样：                Author Last Name       ……………………………………………………………………..        White       Green       Carson       O’Leary       Straight       …       (23 row(s)affected)   注意字段标题不再是au_lname，而是被Author Last Name所取代。     你也可以通过执行运算，来操作从一个表返回的字段值。例如，如果你想把表titles中的所有书的价格加倍，你可以使用下面的SELECT语句：         SELECT price*2 FROM titles             当这个查询执行时，每本书的价格从表中取出时都会加倍。但是，通过这种途径操作字段不会改变存储在表中的书价。对字段的运算只会影响SELECT语句的输出，而不会影响表中的数据。为了同时显示书的原始价格和涨价后的新价格，你可以使用下面的查询：   SELECT  price \"Original  price\",price*2  \"New price\" FROM  titles       当数据从表titles中取出时，原始价格显示在标题Original price下面，加倍后的价格显示在标题New price下面。结果可能是这样：                 original  price        new  price       ………………………………………………………………. 19.99                       39.98 11.95                 23.90 2.99                        5.98 19.99                       39.98 … (18 row(s)  affected)             你可以使用大多数标准的数学运算符来操作字段值，如加（+），减（-），乘（*）和除（/）。你也可以一次对多个字段进行运算，例如：        SELECT price*ytd_sales \"total revenue\" FROM titles       在这个例子中，通过把价格与销售量相乘，计算出了每种书的总销售额。这个SELECT语句的结果将是这样的：              total  revenue       ……………………………………………..       81,859,05       46,318,20       55,978,78       81,859,05       40,619,68       …       (18 row(s)  affected)        最后，你还可以使用连接运算符（它看起来像个加号）来连接两个字符型字段：         SELECT au_fname+\" \"+au_lname  \"author name\" FROM authors       在这个例子中，你把字段au_fname和字段au_lname粘贴在一起，中间用一个逗号 隔开，并把查询结果的标题指定为author name。这个语句的执行结果将是这样的：          author  names        …………………………………………………………        Johnson White        Marjorie Green        Cheryl  Carson       Michael O’Leary       Dean Straight       …       (23 row(s)  affected)       可以看到，SQL为你提供了对查询结果的许多控制。你应该在ASP编程过程中充分利用这些优点。使用SQL来操作查询结果几乎总是比使用有同样作用的脚本效率更高。   排序查询结果     本章的介绍中曾强调过，SQL表没有内在的顺序。例如，从一个表中取第二个记录是没有意义的。从SQL的角度看来，没有一个记录在任何其他记录之前。 然而，你可以操纵一个SQL查询结果的顺序。在缺省情况下，当记录从表中取出时，记录不以特定的顺序出现。例如，当从表authors中取出字段au_lname时，查询结果显示成这样：          au_lname        …………………………………….        White        Green        Carson        O’Leary        Straight        …        (23 row(s)affected)        看一列没有特定顺序的名字是很不方便的。如果把这些名字按字母顺序排列，读起来就会容易得多。通过使用ORDER BY子句，你可以强制一个查询结果按升序排列，就像这样：       SELECT au_lname FROM  authors ORDER  BY  au_lname       当这个SELECT语句执行时，作者名字的显示将按字母顺序排列。ORDER BY子句将作者名字按升序排列。     你也可以同时对多个列使用ORDER BY子句。例如，如果你想同时按升序显示字段au_lname和字段au_fname，你需要对两个字段都进行排序：       SELECT au_lname,au_fname FROM authors ORDERBY au_lname ,au_fname       这个查询首先把结果按au_lname字段进行排序，然后按字段au_fname排序。记录将按如下的顺序取出：         au_lname                         au_fname       …………………………………………………………………….       Bennet                           Abraham       Ringer                            Albert       Ringer                            Anne       Smith                             Meander       …       (23 row(s)affected)       注意有两个作者有相同的名字Ringer。名为Albert Ringer的作者出现名为Anne Ringer的作者之前，这是因为姓Albert按字母顺序应排在姓Anne之前。 如果你想把查询结果按相反的顺序排列，你可以使用关键字DESC。关键字DESC把查询结果按降序排列，如下例所示：             SELECT au_lname,au_fname  FROM authors               WHERE au_lname=”Ringer” ORDER BY  au_lname ,au_fname  DESC       这个查询从表authors中取出所有名字为Ringer的作者记录。ORDER BY子句根据作者的名字和姓，将查询结果按降序排列。结果是这样的：         au_lname                          au_fname       ……………………………………………………………………………………….       Ringer                             Anne       Ringer                             Albert       (2 row(s)  affectec)       注意在这个表中，姓Anne出现在姓Albert之前。作者名字按降序显示。 你也可以按数值型字段对一个查询结果进行排序。例如，如果你想按降序取出所有书的价格，你可以使用如下的SQL查询：          SELECT price  FROM titles  ORDER BY price  DESC       这个SELECT语句从表中取出所有书的价格，显示结果时，价格低的书先显示，价格高的书后显示。       警告：     不是特别需要时，不要对查询结果进行排序，因为服务器完成这项工作要费些力气。这意味着带有ORDER BY 子句的SELECT语句执行起来比一般的SELECT语句花的时间长。   取出互不相同的记录     一个表有可能在同一列中有重复的值。例如，数据库pubs的表authors中有两个作者的名字是Ringer。如果你从这个表中取出所有的名字，名字Ringer将会显示两次。     在特定情况下，你可能只有兴趣从一个表中取出互不相同的值。如果一个字段有重复的值，你也许希望每个值只被选取一次，你可以使用关键字DISTINCT来做到这一点：        SELCET DISTINCT au_lname  FROM  authors  WHERE  au_lname=\"Ringer\"       当这个SELECT语句执行时，只返回一个记录。通过在SELECT语句中包含关键字DISTINCT，你可以删除所有重复的值。例如，假设有一个关于新闻组信息发布的表，你想取出所有曾在这个新闻组中发布信息的人的名字，那么你可以使用关键字DISTINCT。每个用户的名字只取一次——尽管有的用户发布了不止一篇信息。     警告：     如同ORDER BY子句一样，强制服务器返回互不相同的值也会增加运行开销。福气不得不花费一些时间来完成这项工作。因此，不是必须的时候不要使用关键字DISTINCT。   创建新表     前面说过，数据库中的所有数据存储在表中。数据表包括行和列。列决定了表中数据的类型。行包含了实际的数据。     例如，数据库pubs中的表authors有九个字段。其中的一个字段名为为au_lname，这个字段被用来存储作者的名字信息。每次向这个表中添加新作者时，作者名字就被添加到这个字段，产生一条新记录。     通过定义字段，你可以创建一个新表。每个字段有一个名字和一个特定的数据类型（数据类型在后面的“字段类型”一节中讲述），例如字段au_lname存储的是字符型数据。一个字段也可以存储其它类型的数据。     使用SQL Sever，创建一个新表的方法是很多的。你可以可执行一个SQL语句或使用SQL事务管理器（SQL Enterprise Manager）来创建一个新表。在下一节里，你将学会如何用SQL语句来创建一个新表。   用SQL创建新表     注意：     如果你还没有建立自己的数据库，现在就跳回到第三章创建这个库。你绝不能向master,tempdb或任何其他任何系统数据库中添加数据。       从SQL Sever程序组（在任务栏中）中启动ISQL/w程序。出现查询窗口后，从窗口顶部的下拉列表中选择你在第三章所创建的数据库。下一步，在查询窗口中键入下面的SQL语句，单击执行查询按钮，执行这个语句：         CREATE TABLE  guestbook (visitorVARCHAR(40),comments TEXT,entrydate                                         DATETIME)   如果一切正常，你会在结果窗口中看到如下的文字（如果出现异常，请参阅第三章）：         This command dit not return data ,and itdid not return any rows         祝贺你，你已经建立了你的第一个表！     你所创建的表名为guestbook，你可以使用这个表来存储来字你站点访问者的信息。你是用REEATETABLE语句创建的这个表，这个语句有两部分：第一部份指定表的名子；第二部份是括在括号中的各字段的名称和属性，相互之间用逗号隔开。     表guestbook有三个字段：visitor,comments 和entrydate。visitor字段存储访问者的名字，comments字段存储访问者对你站点的意见，entrydate字段存储访问者访问你站点的日期和时间。     注意每个字段名后面都跟有一个专门的表达式。例如，字段名comments后面跟有表达式TEXT。这个表达式指定了字段的数据类型。数据类型决定了一个字段可以存储什么样的数据。因为字段comments包含文本信息，其数据类型定义为文本型。     字段有许多不同的数据类型。下一小节讲述SQL所支持的一些重要的数据类型。   字段类型     不同的字段类型用来存放不同类型的数据。创建和使用表时，更你应该理解五种常用的字段类型：字符型，文本型，数值型，逻辑性和日期型。   字符型数据     字符型数据非常有用。当你需要存储短的字符串信息时，你总是要用到字符型数据。例如，你可以把从HTML form的文本框中搜集到的信息放在字符型字段中。     要建立一个字段用来存放可变长度的字符串信息，你可以使用表达式 VARCHAR。考虑你前面创建的表guestbook：        CREATE TABLE  guestbook (visitorVARCHAR(40),comments TEXT,entrydate                                         DATETIME)       在这个例子中，字段visitor的数据类型为VARCHAR。注意跟在数据类型后面的括号中的数字。这个数字指定了这个字段所允许存放的字符串的最大长度。在这个例子中，字段visitor能存放的字符串最长为四十个字符。如果名字太长，字符串会被截断，只保留四十个字符。     VARCHAR类型可以存储的字符串最长为255个字符。要存储更长的字符串数据，可以使用文本型数据（下一节中讲述）。     另一种字符型数据用来存储固定长度的字符数据。下面是一个使用这种数据类型的例子：        CREATE TABLE guestbook (visitorCHAR(40),comments TEXT,entrydate                                         DATETIME)       在这个例子中，字段visitor被用来存储四十个字符的固定长度字符串。表达式CHAR指定了这个字段应该是固定长度的字符串。     VARCHAR型和CHAR型数据的这个差别是细微的，但是非常重要。假如你向一个长度为四十个字符的VARCHAR型字段中输入数据Bill Gates。当你以后从这个字段中取出此数据时，你取出的数据其长度为十个字符——字符串Bill Gates的长度。     现在假如你把字符串输入一个长度为四十个字符的CHAR型字段中，那么当你取出数据时，所取出的数据长度将是四十个字符。字符串的后面会被附加多余的空格。     当你建立自己的站点时，你会发现使用VARCHAR型字段要比CHAR型字段方便的多。使用VARCHAR型字段时，你不需要为剪掉你数据中多余的空格而操心。     VARCHAR型字段的另一个突出的好处是它可以比CHAR型字段占用更少的内存和硬盘空间。当你的数据库很大时，这种内存和磁盘空间的节省会变得非常重要。   文本型数据     字符型数据限制了字符串的长度不能超过２55个字符。而使用文本型数据，你可以存放超过二十亿个字符的字符串。当你需要存储大串的字符时，应该使用文本型数据。     这里有一个使用文本型数据的例子：       CREATE TABLE  guestbook (visitorVARCHAR(40),comments TEXT,entrydate                                         DATETIME)       在这个例子中，字段comments被用来存放访问者对你站点的意见。注意文本型数据没有长度，而上一节中所讲的字符型数据是有长度的。一个文本型字段中的数据通常要么为空，要么很大。     当你从HTML form的多行文本编辑框（TEXTAREA）中收集数据时，你应该把收集的信息存储于文本型字段中。但是，无论何时，只要你能避免使用文本型字段，你就应该不适用它。文本型字段既大且慢，滥用文本型字段会使服务器速度变慢。文本型字段还会吃掉大量的磁盘空间。     警告：     一旦你向文本型字段中输入了任何数据（甚至是空值），就会有2K的空间被自动分配给该数据。除非删除该记录，否则你无法收回这部分存储空间。   数值型数据     SQL Sever支持许多种不同的数值型数据。你可以存储整数、小数、和钱数。     通常，当你需要在表中的存放数字时，你要使用整型（INT）数据。INT型数据的表数范围是从-2，147，483，647到2，147，483，647的整数。下面是一个如何使用INT型数据的例子：          CREATE TABLE  visitlog (visitorVARCHAR(40),numvisits  INT)       这个表可以用来记录你站点被访问的次数。只要没有人访问你的站点超过2，147，483，647次，nubvisits字段就可以存储访问次数。     为了节省内存空间，你可以使用SMALLINT型数据。SMALLINT 型数据可以存储从-32768到32768的整数。这种数据类型的使用方法与INT型完全相同。     最后，如果你实在需要节省空间，你可以使用TINYINT型数据。同样，这种类型的使用方法也与INT型相同，不同的是这种类型的字段只能存储从０到255的整数。TINYINT型字段不能用来存储负数。     通常，为了节省空间，应该尽可能的使用最小的整型数据。一个TINYINT型数据只占用一个字节；一个INT型数据占用四个字节。这看起来似乎差别不大，但是在比较大的表中，字节数的增长是很快的。另一方面，一旦你已经创建了一个字段，要修改它是很困难的。因此，为安全起见，你应该预测以下，一个字段所需要存储的数值最大有可能是多大，然后选择适当的数据类型。     为了能对字段所存放的数据有更多的控制，你可以使用NUMERIC型数据来同时表示一个数的整数部分和小数部分。NUMERIC型数据使你能表示非常大的数——比INT型数据要大得多。一个NUMERIC型字段可以存储从-1038到1038范围内的数。NUMERIC型数据还使你能表示有小数部分的数。例如，你可以在NUMERIC型字段中存储小数3.14。     当定义一个NUMERIC型字段时，你需要同时指定整数部分的大小和小数部分的大小。这里有一个使用这种数据类型的例子：             CREATETABLE  numeric_data (bignumber  NUMERIC(28,0),                                    fraction    NUMERIC (5,4) )       当这个语句执行时，将创建一个名为numeric_data的包含两个字段的表。字段bignumber可以存储直到28位的整数。字段fraction可以存储有五位整数部分和四位小数部分的小数。     一个NUMERIC型数据的整数部分最大只能有28位，小数部分的位数必须小于或等于整数部分的位数，小数部分可以是零。     你可以使用INT型或NUMERIC型数据来存储钱数。但是，专门有另外两种数据类型用于此目的。如果你希望你的网点能挣很多钱，你可以使用MONEY型数据。如果你的野心不大，你可以使用SMALLMONEY型数据。MONEY型数据可以存储从-922，337，203，685，477.5808到922，337，203，685，477.5807的钱数。如果你需要存储比这还大的金额，你可以使用NUMERIC型数据。     SMALLMONEY型数据只能存储从-214，748.3648到214，748.3647 的钱数。同样，如果可以的话，你应该用SMALLMONEY型来代替MONEY型数据，以节省空间。下面的例子显示了如何使用这两种表示钱的数据类型：         CREATE TABLE products (productVARCHAR(40),price  MONEY,                                Discount_priceSMALLMONEY)            这个表可以用来存储商品的折扣和普通售价。字段price 的数据类型是MONEY，字段discount_price的数据类型是SMALLMONEY。   存储逻辑值     如果你使用复选框（CHECKBOX）从网页中搜集信息，你可以把此信息存储在BIT型字段中。BIT型字段只能取两个值：0或1。这里有一个如何使用这种字段的例子：       CREATE TABLE  opinion (visitorVARCHAR(40),good BIT)       这个表可以用来存放对你的网点进行民意调查所得的信息。访问者可以投票表示他们是否喜欢你的网点。如果他们投YES，就在BIT型字段中存入1。反之，如果他们投NO，就在字段中存入0（在下一章里，你将学会如何计算投票）。     当心，在你创建好一个表之后，你不能向表中添加BIT型字段。如果你打算在一个表中包含BIT型字段，你必须在创建表时完成。   存储日期和时间     当你建立一个网点时，你也许需要记录在一段时间内的访问者数量。为了能够存储日期和时间，你需要使用DATETIME型数据，如下例所示：       CREATE  TABL visitorlog( visitor VARCHAR (40),arrivaltime DATETIME ,                               departuretime  DATETIME)       这个表可以用来记录访问者进入和离开你网点的时间和日期。一个DATETIME型的字段可以存储的日期范围是从１７５３年１月１日第一毫秒到9999年12月31日最后一毫秒。     如果你不需要覆盖这么大范围的日期和时间，你可以使用SMALLDATETIME型数据。它与DATETIME型数据同样使用，只不过它能表示的日期和时间范围比DATETIME型数据小，而且不如DATETIME型数据精确。一个SMALLDATETIME型的字段能够存储从１９00年１月１日到２０７９年６月６日的日期，它只能精确到秒。    DATETIME型字段在你输入日期和时间之前并不包含实际的数据，认识这一点是重要的。在下一章，你将学习怎样使用大量的SQL函数来读取和操作日期和时间（参见下面的“缺省值”一节）。你也可以在VBScript和JScript 中使用日期和时间函数来向一个DATETIME型字段中输入日期和时间。   字段属性    上一节介绍了如何建立包含不同类型字段的表。在这一节中，你将学会如何使用字段的三个属性。这些属性允许你控制空值，缺省值和标识值。   允许和禁止空值    大多数字段可以接受空值（NULL）。当一个字段接受了空值后，如果你不改变它，它将一直保持空值。空值（NULL）和零是不同的，严格的说，空值表示没有任何值。 为了允许一个字段接受空值，你要在字段定义的后面使用表达式NULL。例如，下面的表中两个字段都允许接受空值：             CREATE TABLE empty (empty1 CHAR (40)NULL,empty2 INT NULL(        注意：     BIT型数据不能是空值。一个这种类型的字段必须取0或者１。      有时你需要禁止一个字段使用空值。例如，假设有一个表存储着信用卡号码和信用卡有效日期，你不会希望有人输入一个信用卡号码但不输入有效日期。为了强制两个字段都输入数据，你可以用下面的方法建立这个表：             CREATE TABLE creditcards (creditcard_number CHAR(20) NOT NULL,                                 Creditcard_expire  DATETIME  NOT NULL)    注意字段定义的后面跟有表达式NOT NULL。通过包含表达式NOT NULL，你可以禁止任何人只在一个字段中插入数据，而不输入另一个字段的数据。    你将会发现，在你建设自己的网点过程中，这种禁止空值的能力是非常有用的。如果你指定一个字段不能接受空值，那么当你试图输入一个空值时，会有错误警告。这些错误警告可以为程序调试提供有价值的线索。   缺省值    假设有一个存储地址信息的表，这个表的字段包括街道、城市、州、邮政编码和国家。如果你预计地址的大部分是在美国，你可以把这个值作为country字段的缺省值。    为了在创建一个表时指定缺省值，你可以使用表达式DEFAULT。请看下面这个在创建表时使用缺省值的例子：              CREATE TABLE addresses (streetVARCHAR(60)  NULL,                                city VARCHAR(40)NULL,                                stateVARCHAR(20) NULL                                zip  VARCHAR(20) NULL,                                country VARCHAR(30) DEFAULT  ‘USA’)      在这个例子中，字段country的缺省值被指定为美国。注意单引号的使用，引号指明这是字符型数据。为了给非字符型的字段指定缺省值，不要把该值扩在引号中：           CREATE TABLE orders(price  MONEY DEFAULT $38.00,                            quantity INT DEFAULT50,                             entrydate DATETIME DEFAULT GETDATE())      在这个CREATE TABLE语句中，每个字段都指定了一个缺省值。注意DATETIME型字段entrydate所指定的缺省值,该缺省值是函数Getdate()的返回值,该函数返回当前的日期和时间。   标识字段    每个表可以有一个也只能有一个标识字段。一个标识字段是唯一标识表中每条记录的特殊字段。例如，数据库pubs中的表jobs包含了一个唯一标识每个工作标识字段：           job_id  job_desc       ……………………………………………………………. 1                        New Hire Job not specified 2                        Chief Executive officer 3                        Bushness Operations Manager 4                        Chief Financial Officier 5                        Publisher      字段job_id为每个工作提供了唯一的一个数字。如果你决定增加一个新工作，新增记录的job_id字段会被自动赋给一个新的唯一值。    为了建立一个标识字段，你只需在字段定义后面加上表达式IDENTITY即可。你只能把NUMERIC型或INT型字段设为标识字段，这里有一个例子：          CREATE TABLE visitorID (theIDNUBERIC(18) IDENTITY,name VARCHAR(40))       这个语句所创建的表包含一个名为theid的标识字段。每当一个新的访问者名字添加到这个表中时，这个字段就被自动赋给一个新值。你可以用这个表为你的站点的每一个用户提供唯一标识。     技巧：    建立一个标示字段时，注意使用足够大的数据类型。例如你使用TINYINT型数据，那么你只能向表中添加255个记录。如果你预计一个表可能会变得很大，你应该使用NUMERIC型数据。      标识字段的存在会使你想尝试许多不可能的事情。例如，你也许想利用标识字段来对记录进行基于它们在表中位置的运算。你应该抛弃这种意图。每个记录的标识字段的值是互不相同的，但是，这并不禁止一个标识字段的标识数字之间存在间隔。例如，你永远不要试图利用一个表的标识字段来取出表中的前十个记录。这种操作会导致失败，比如说６号记录和7号记录根本不存在。   使用SQL事务管理器创建新表     你可以使用前面几节所讲的方法创建新表。但是，使用事务管理器创建新表会更容易。这一节介绍如何使用这个程序创建新表。    从任务栏的SQL Sever程序组中选择SQL Enterprise Manager，启动该程序，你会看到如图10.4所示的窗口。浏览服务管理器窗口中的树形结构，选择名为Database的文件夹。打开文件夹Database后，选择你在第三章中所建立的数据库。     注意：    如果你还没有创建自己的数据库，回到第三章创建它。你决不要向master,tempdb或任何其它系统数据库中添加数据。      在选择了数据库之后，你会看到一个名为Group/users的文件夹和一个名为objects的文件夹。打开文件夹objects，你会看到许多文件夹，其中一个名为Tables。用右键单击文件夹Tables并选择New table，就会出现如图10.5所示的窗口。    你可以使用Manager  Tables窗口来创建一个新表。Manager Tables窗口有７个列：Key,Column,Name,Datatype,Size,Nulls和Default。Manager Tables窗口中的每一行标明表中一个字段的信息。           图10.4            10.5      要建立一个新表，你至少要输入一行信息。在名为Column  Name的列下面键入mycolumn。下一步，选择Datatype列，并从下拉列表中选择CHAR。当你在这两个列中输入信息后，窗口将是如图10.6所示的样子。    图10.6      你已经建立了一个只有一个字段的简单的表。单击保存按扭保存这个新表。当要求你输入新表的名字时，输入mytable并单击OK。现在这个表已经保存到了你的数据库中。 如果你打开服务管理器窗口中的文件夹Tables，你会看到你所建立的新表被列出。你可以双击该表的图表来编辑它，这时Manager Tables窗口会重新出现，你可以增加新的字段并重新保存。    用SQL事务管理器可以做的工作，你都可以用SQL语句来实现。但是，事务管理器使得建表过程变得更加简单。   向表中添加数据    下一章将讨论如何使用SQL向一个表中插入数据。但是，如果你需要向一个表中添加许多条记录，使用SQL语句输入数据是很不方便的。幸运的是，Microsoft  SQL Sever带有一个称为Microsoft Query 的客户端应用程序，这个程序使得向表中添加数据变得容易了。    启动位于任务栏SQL Sever程序组中的Microsoft Query程序。从窗口顶部的菜单中选择File|New Query。这时会显示一个Select Data Source对话框（见图10.7）。选择你的数据源名字并单击Use。     图10。7      输入你的登录帐号和密码后，程序要求你选择一个表和一个数据库。选择你在上一节中所建立的表（mytable ），单击按钮Add，然后单击按钮Close关闭该对话框。    在窗口的左上角会出现一个对话框，框中是取自表mytable的一列字段名。你可以双击任何一个字段，把它添加到主窗口中。如果你双击星号（*）字符，所有的字段都会被添加到主窗口中。    如果你的表中有记录，它们现在已经出现在主窗口的字段标题下面了。但是，因为你刚刚建立了这个表，表还是空的。要添加新记录，选择Records|Allow Editing，主窗口中就会出现一条新记录。输入一行数据完成这个记录，就向表中添加了一条新记录。                         图10。8      当你转到下一条新记录时，你向上一条记录中输入的值会自动被保存。如果你需要，你可以用Microsoft Query 向表中输入几百条记录。   删除和修改表    你应该在建立表之前仔细设计它们，因为你在改变一个已经存在的表时会受到很大的限制。例如，一旦已经建立了一个表，你就不能删除表中的字段或者改变字段的数据类型。在这种情况你所能做的是删除这个表，然后重头开始（参见第十一章“中级SQL”中的“使用SQL创建记录和表”一节）。    要删除一个表，你可以使用SQL语句DROP TABLE。例如，又从数据库中彻底删除表mytable，你要使用如下的语句：            DROP TABLE mytable       警告：    使用DROP TABLE命令时一定要小心。一旦一个表被删除之后，你将无法恢复它。      当你建设一个站点时，你很可能需要向数据库中输入测试数据。而当你准备向世界提供你的网点时，你会想清空表中的这些测试信息。如果你想清除表中的所有数据但不删除这个表，你可以使用TRUNCATE TABLE语句。例如，下面的这个SQL语句从表mytable中删除所有数据：           TRUNCATE TABLE mytable      虽然你不能删除和修改已经存在的字段，但你可以增加新字段。最容易的实现方法是使用SQL事务管理器中的Manager Tables窗口。你也可以使用SQL语句ALTER TABLE。下面是一个如何使用这种语句的例子：        ALTER TABLE mytable ADD mynewcolumn INTNULL      这个语句向表mytable中增加了一个新字段mynewcolumn。当你增加新字段时，你必须允许它接受空值，因为表中原来可能已经有了许多记录。   总结    这一章向你介绍了SQL。使用SQL，你可以操作Microsoft  SQL Sever数据库。你已经学会了使用SELECT语句从数据库中取出数据，你还学会了怎样使用CREATE TABLE语句和SQL事务管理器来创建新表。最后，你学会了如何指明一系列重要的字段属性。 下一章将介绍如何使用索引来增强SQL查询的操作。还将通过许多其它的SQL语句和函数，使你的SQL知识得到进一步扩充。     第十一章  中级SQL                  本章内容                ■创建索引                ■SQL核心语句                ■集合函数 ■其它常用的SQL表达式，   函数，和过程        第十章“SQL基础”向你初步介绍了SQL。你学会了如何用SELECT语句进行查询，你还学会了如何建立自己的表。在这一章里，你将加深你的SQL知识。你将学习如何建立索引来加快查询速度。你还将学会如果用更多的SQL语句和函数来操作表中的数据。   建立索引    假设你想找到本书中的某一个句子。你可以一页一页地逐页搜索，但这会花很多时间。而通过使用本书的索引，你可以很快地找到你要搜索的主题。    表的索引与附在一本书后面的索引非常相似。它可以极大地提高查询的速度。对一个较大的表来说，通过加索引，一个通常要花费几个小时来完成的查询只要几分钟就可以完成。因此没有理由对需要频繁查询的表增加索引。     注意：    当你的内存容量或硬盘空间不足时，也许你不想给一个表增加索引。对于包含索引的数据库，SQL Sever需要一个可观的额外空间。例如，要建立一个聚簇索引，需要大约１.２倍于数据大小的空间。要看一看一个表的索引在数据库中所占的空间大小，你可以使用系统存储过程sp_spaceused，对象名指定为被索引的表名。   聚簇索引和非聚簇索引    假设你已经通过本书的索引找到了一个句子所在的页码。一旦已经知道了页码后，你很可能漫无目的翻寻这本书，直至找到正确的页码。通过随机的翻寻，你最终可以到达正确的页码。但是，有一种找到页码的更有效的方法。    首先，把书翻到大概一半的地方，如果要找的页码比半本书处的页码小，就书翻到四分之一处，否则，就把书翻到四分之三的地方。通过这种方法，你可以继续把书分成更小的部分，直至找到正确的页码附近。这是找到书页的非常有效的一种方法。 SQL Sever的表索引以类似的方式工作。一个表索引由一组页组成，这些页构成了一个树形结构。根页通过指向另外两个页，把一个表的记录从逻辑上分成和两个部分。而根页所指向的两个页又分别把记录分割成更小的部分。每个页都把记录分成更小的分割，直至到达叶级页。    索引有两种类型：聚簇索引和非聚簇索引。在聚簇索引中，索引树的叶级页包含实际的数据：记录的索引顺序与物理顺序相同。在非聚簇索引中，叶级页指向表中的记录：记录的物理顺序与逻辑顺序没有必然的联系。    聚簇索引非常象目录表，目录表的顺序与实际的页码顺序是一致的。非聚簇索引则更象书的标准索引表，索引表中的顺序通常与实际的页码顺序是不一致的。一本书也许有多个索引。例如，它也许同时有主题索引和作者索引。同样，一个表可以有多个非聚簇索引。    通常情况下，你使用的是聚簇索引，但是你应该对两种类型索引的优缺点都有所理解。    每个表只能有一个聚簇索引，因为一个表中的记录只能以一种物理顺序存放。通常你要对一个表按照标识字段建立聚簇索引。但是，你也可以对其它类型的字段建立聚簇索引，如字符型，数值型和日期时间型字段。    从建立了聚簇索引的表中取出数据要比建立了非聚簇索引的表快。当你需要取出一定范围内的数据时，用聚簇索引也比用非聚簇索引好。例如，假设你用一个表来记录访问者在你网点上的活动。如果你想取出在一定时间段内的登录信息，你应该对这个表的DATETIME型字段建立聚簇索引。    对聚簇索引的主要限制是每个表只能建立一个聚簇索引。但是，一个表可以有不止一个非聚簇索引。实际上，对每个表你最多可以建立249个非聚簇索引。你也可以对一个表同时建立聚簇索引和非聚簇索引。    假如你不仅想根据日期，而且想根据用户名从你的网点活动日志中取数据。在这种情况下，同时建立一个聚簇索引和非聚簇索引是有效的。你可以对日期时间字段建立聚簇索引，对用户名字段建立非聚簇索引。如果你发现你需要更多的索引方式，你可以增加更多的非聚簇索引。    非聚簇索引需要大量的硬盘空间和内存。另外，虽然非聚簇索引可以提高从表中取数据的速度，它也会降低向表中插入和更新数据的速度。每当你改变了一个建立了非聚簇索引的表中的数据时，必须同时更新索引。因此你对一个表建立非聚簇索引时要慎重考虑。如果你预计一个表需要频繁地更新数据，那么不要对它建立太多非聚簇索引。另外，如果硬盘和内存空间有限，也应该限制使用非聚簇索引的数量。   索引属性    这两种类型的索引都有两个重要属性：你可以用两者中任一种类型同时对多个字段建立索引（复合索引）；两种类型的索引都可以指定为唯一索引。    你可以对多个字段建立一个复合索引，甚至是复合的聚簇索引。假如有一个表记录了你的网点访问者的姓和名字。如果你希望根据完整姓名从表中取数据，你需要建立一个同时对姓字段和名字字段进行的索引。这和分别对两个字段建立单独的索引是不同的。当你希望同时对不止一个字段进行查询时，你应该建立一个对多个字段的索引。如果你希望对各个字段进行分别查询，你应该对各字段建立独立的索引。    两种类型的索引都可以被指定为唯一索引。如果对一个字段建立了唯一索引，你将不能向这个字段输入重复的值。一个标识字段会自动成为唯一值字段，但你也可以对其它类型的字段建立唯一索引。假设你用一个表来保存你的网点的用户密码，你当然不希望两个用户有相同的密码。通过强制一个字段成为唯一值字段，你可以防止这种情况的发生。   用SQL建立索引    为了给一个表建立索引，启动任务栏SQL Sever程序组中的ISQL/w程序。进入查询窗口后，输入下面的语句：          CREATE INDEX mycolumn_index ON mytable(myclumn)      这个语句建立了一个名为mycolumn_index的索引。你可以给一个索引起任何名字，但你应该在索引名中包含所索引的字段名，这对你将来弄清楚建立该索引的意图是有帮助的。     注意：    在本书中你执行任何SQL语句，都会收到如下的信息：     This command did not return data,and it did not return any rows 这说明该语句执行成功了。 索引mycolumn_index对表mytable的mycolumn字段进行。这是个非聚簇索引，也是个非唯一索引。（这是一个索引的缺省属性） 如果你需要改变一个索引的类型，你必须删除原来的索引并重建一个。建立了一个索引后，你可以用下面的SQL语句删除它：   DROPINDEX mytable.mycolumn_index   注意在DROP INDEX 语句中你要包含表的名字。在这个例子中，你删除的索引是mycolumn_index，它是表mytable的索引。 要建立一个聚簇索引，可以使用关键字CLUSTERED。）记住一个表只能有一个聚簇索引。（这里有一个如何对一个表建立聚簇索引的例子：   CREATECLUSTERED INDEX mycolumn_clust_index ON mytable(mycolumn)   如果表中有重复的记录，当你试图用这个语句建立索引时，会出现错误。但是有重复记录的表也可以建立索引；你只要使用关键字ALLOW_DUP_ROW把这一点告诉SQL Sever即可：   CREATECLUSTERED INDEX mycolumn_cindex ON mytable(mycolumn)                      WITH ALLOW_DUP_ROW   这个语句建立了一个允许重复记录的聚簇索引。你应该尽量避免在一个表中出现重复记录，但是，如果已经出现了，你可以使用这种方法。 要对一个表建立唯一索引，可以使用关键字UNIQUE。对聚簇索引和非聚簇索引都可以使用这个关键字。这里有一个例子：   CREATEUNIQUE COUSTERED INDEX myclumn_cindex ON mytable(mycolumn)   这是你将经常使用的索引建立语句。无论何时，只要可以，你应该尽量对一个对一个表建立唯一聚簇索引来增强查询操作。 最后，要建立一个对多个字段的索引──复合索引──在索引建立语句中同时包含多个字段名。下面的例子对firstname和lastname两个字段建立索引：   CREATEINDEX name_index ON username(firstname,lastname)   这个例子对两个字段建立了单个索引。在一个复合索引中，你最多可以对16个字段进行索引。   用事务管理器建立索引 用事务管理器建立索引比用SQL语句容易的多。使用事务管理器，你可以看到已经建立的索引的列表，并可以通过图形界面选择索引选项。 使用事务管理器你可以用两种方式建立索引：使用Manage Tables窗口或使用Manage Indexes窗口。    要用Manage Tables 窗口建立一个新索引，单击按钮AdvancedOptions(它看起来象一个前面有一加号的表)。这样就打开了AdvancedOptions对话框。这个对话框有一部分标名为Primary Key（见图11.1）。   图11。1   要建立一个新索引，从下拉列表中选择你想对之建立索引的字段名。如果你想建立一个对多字段的索引，你可以选择多个字段名。你还可以选择索引是聚簇的还是非聚簇的。在保存表信息后，索引会自动被建立。在Manage Tables窗口中的字段名旁边，会出现一把钥匙。 你已经为你的表建立了“主索引”。主索引必须对不包含空值的字段建立。另外，主索引强制一个字段成为唯一值字段。 要建立没有这些限制的索引，你需要使用Manage Indexes窗口。从菜单中选择Manage|Indexes，打开Manage Indexes 窗口。在Manage Indexes 窗口中，你可以通过下拉框选择表和特定的索引。（见图11.2）。要建立一个新索引，从Index下拉框中选择New Index.，然后就可以选择要对之建立索引的字段。单击按钮Add，把字段加人到索引中。   图11。2   你可以为你的索引选择许多不同的选项。例如，你可以选择该索引是聚簇的还是非聚簇的。你还可以指定该索引为唯一索引。设计好索引后，单击按钮Build，建立该索引。   注意： 唯一索引是指该字段不能有重复的值，而不是只能建立这一个索引。   SQL核心语句 在第十章，你学会了如何用SQL SELECT 语句从一个表中取数据。但是，到现在为止，还没有讨论如何添加，修改或删除表中的数据。在这一节中，你将学习这些内容。   插入数据 向表中添加一个新记录，你要使用SQL INSERT 语句。这里有一个如何使用这种语句的例子：        INSERT mytable (mycolumn) VALUES (‘some data’)   这个语句把字符串’some data’插入表mytable的mycolumn字段中。将要被插入数据的字段的名字在第一个括号中指定，实际的数据在第二个括号中给出。 INSERT语句的完整句法如下：   INSERT[INTO]  {table_name|view_name}[(column_list)] {DEFAULT VALUES |                 Values_list | select_statement}   如果一个表有多个字段，通过把字段名和字段值用逗号隔开，你可以向所有的字段中插入数据。假设表mytable有三个字段first_column,second_column,和third_column。下面的INSERT语句添加了一条三个字段都有值的完整记录：   INSERTmytable (first_column,second_column,third_column)         VALUES (‘some data’,’some more data’,’yet more data’)   注意： 你可以使用INSERT语句向文本型字段中插入数据。但是，如果你需要输入很长的字符串，你应该使用WRITETEXT语句。这部分内容对本书来说太高级了，因此不加讨论。要了解更多的信息，请参考Microsoft SQL Sever 的文档。   如果你在INSERT 语句中只指定两个字段和数据会怎么样呢？换句话说，你向一个表中插入一条新记录，但有一个字段没有提供数据。在这种情况下，有下面的四种可能： ■如果该字段有一个缺省值，该值会被使用。例如，假设你插入新记录时没有给字段third_column提供数据，而这个字段有一个缺省值’some value’。在这种情况下，当新记录建立时会插入值’some value’。 ■如果该字段可以接受空值，而且没有缺省值，则会被插入空值。 ■如果该字段不能接受空值，而且没有缺省值，就会出现错误。你会收到错误信息： The columnin table mytable may not be null. ■最后，如果该字段是一个标识字段，那么它会自动产生一个新值。当你向一个有标识字段的表中插入新记录时，只要忽略该字段，标识字段会给自己赋一个新值。       注意：    向一个有标识字段的表中插入新记录后，你可以用SQL变量@@identity来访问新记录 的标识字段的值。考虑如下的SQL语句：        INSERT mytable (first_column) VALUES(‘some value’)       INSERT anothertable(another_first,another_second)          VALUES(@@identity,’some value’)      如果表mytable有一个标识字段，该字段的值会被插入表anothertable的another_first字段。这是因为变量@@identity总是保存最后一次插入标识字段的值。 字段another_first应该与字段first_column有相同的数据类型。但是，字段another_first不能是应该标识字段。Another_first字段用来保存字段first_column的值。   删除记录 要从表中删除一个或多个记录，需要使用SQL DELETE语句。你可以给DELETE 语句提供WHERE 子句。WHERE子句用来选择要删除的记录。例如，下面的这个DELETE语句只删除字段first_column的值等于’Delete Me’的记录：   DELETEmytable WHERE first_column=’DeltetMe’   DELETE 语句的完整句法如下：          DELETE [FROM] {table_name|view_name}  [WHERE clause]   在SQL SELECT 语句中可以使用的任何条件都可以在DELECT 语句的WHERE子句 中使用。例如，下面的这个DELETE语句只删除那些first_column字段的值为’goodbye’或second_column字段的值为’so long’的记录：   DELETEmytable WHERE first_column=’goodby’ ORsecond_column=’solong’   如果你不给DELETE 语句提供WHERE 子句，表中的所有记录都将被删除。你不应该有这种想法。如果你想删除应该表中的所有记录，应使用第十章所讲的TRUNCATE TABLE语句。   注意： 为什么要用TRUNCATE TABLE 语句代替DELETE语句？当你使用TRUNCATE TABLE语句时，记录的删除是不作记录的。也就是说，这意味着TRUNCATE TABLE 要比DELETE快得多。   更新记录 要修改表中已经存在的一条或多条记录，应使用SQL UPDATE语句。同DELETE语句一样，UPDATE语句可以使用WHERE子句来选择更新特定的记录。请看这个例子：   UPDATEmytable SET first_column=’Updated!’ WHEREsecond_column=’UpdateMe!’   这个UPDATE 语句更新所有second_column字段的值为’Update Me!’的记录。对所有被选中的记录，字段first_column的值被置为’Updated!’。 下面是UPDATE语句的完整句法：   UPDATE{table_name|view_name} SET [{table_name|view_name}]       {column_list|variable_list|variable_and_column_list}       [,{column_list2|variable_list2|variable_and_column_list2}…        [,{column_listN|variable_listN|variable_and_column_listN}]]         [WHERE clause]   注意： 你可以对文本型字段使用UPDATE语句。但是，如果你需要更新很长的字符串，应使用UPDATETEXT语句。这部分内容对本书来说太高级了，因此不加讨论。要了解更多的信息，请参考Microsoft SQL Sever 的文档。       如果你不提供WHERE子句，表中的所有记录都将被更新。有时这是有用的。例如，如果你想把表titles中的所有书的价格加倍，你可以使用如下的UPDATE 语句： 你也可以同时更新多个字段。例如，下面的UPDATE语句同时更新first_column,second_column,和third_column这三个字段：   UPDATEmytable  SET  first_column=’Updated!’                      Second_column=’Updated!’                      Third_column=’Updated!’                  WHERE first_column=’Update Me1’   技巧： SQL忽略语句中多余的空格。你可以把SQL语句写成任何你最容易读的格式。     用SELECT 创建记录和表 你也许已经注意到，INSERT 语句与DELETE语句和UPDATE语句有一点不同，它一次只操作一个记录。然而，有一个方法可以使INSERT 语句一次添加多个记录。要作到这一点，你需要把INSERT 语句与SELECT 语句结合起来，象这样：   INSERTmytable (first_column,second_column) SELECTanother_first,another_second FROManothertable WHEREanother_first=’CopyMe!’   这个语句从anothertable拷贝记录到mytable.只有表anothertable中字段another_first的值为’Copy Me！’的记录才被拷贝。 当为一个表中的记录建立备份时，这种形式的INSERT 语句是非常有用的。在删除一个表中的记录之前，你可以先用这种方法把它们拷贝到另一个表中。 如果你需要拷贝整个表，你可以使用SELECT  INTO 语句。例如，下面的语句创建了一个名为newtable的新表，该表包含表mytable的所有数据：   SELECT* INTO newtable FROM mytable   你也可以指定只有特定的字段被用来创建这个新表。要做到这一点，只需在字段列表中指定你想要拷贝的字段。另外，你可以使用WHERE 子句来限制拷贝到新表中的记录。下面的例子只拷贝字段second_columnd的值等于’Copy Me!’的记录的first_column字段。   SELECTfirst_column INTO newtable FROMmytable WHEREsecond_column=’CopyMe!’   使用SQL修改已经建立的表是很困难的。例如，如果你向一个表中添加了一个字段，没有容易的办法来去除它。另外，如果你不小心把一个字段的数据类型给错了，你将没有办法改变它。但是，使用本节中讲述的SQL语句，你可以绕过这两个问题。 例如，假设你想从一个表中删除一个字段。使用SELECT INTO 语句，你可以创建该表的一个拷贝，但不包含要删除的字段。这使你既删除了该字段，又保留了不想删除的数据。 如果你想改变一个字段的数据类型，你可以创建一个包含正确数据类型字段的新表。创建好该表后，你就可以结合使用UPDATE语句和SELECT 语句，把原来表中的所有数据拷贝到新表中。通过这种方法，你既可以修改表的结构，又能保存原有的数据。   集合函数 到现在为止，你只学习了如何根据特定的条件从表中取出一条或多条记录。但是，假如你想对一个表中的记录进行数据统计。例如，如果你想统计存储在表中的一次民意测验的投票结果。或者你想知道一个访问者在你的站点上平均花费了多少时间。要对表中的任何类型的数据进行统计，都需要使用集合函数。 MicrosoftSQL 支持五种类型的集合函数。你可以统计记录数目，平均值，最小值，最大值，或者求和。当你使用一个集合函数时，它只返回一个数，该数值代表这几个统计值之一。   注意： 要在你的ASP网页中使用集合函数的返回值，你需要给该值起一个名字。要作到这一点，你可以在SELECT语句中，在集合函数后面紧跟一个字段名，如下例所示：   SELECTAVG(vote) ‘the_average’ FROM opinion   在这个例子中，vote的平均值被命名为 the_average。现在你可以在你的ASP网页的数据库方法中使用这个名字。   统计字段值的数目 函数COUNT（）也许是最有用的集合函数。你可以用这个函数来统计一个表中有多少条记录。这里有一个例子：   SELECTCOUNT(au_lname) FROM authors   这个例子计算表authors中名字（last name）的数目。如果相同的名字出现了不止一次，该名字将会被计算多次。如果你想知道名字为某个特定值的作者有多少个，你可以使用WHERE子句，如下例所示：   SELECTCOUNT(au_lname) FROM authors WHERE au_lname=’Ringer’   这个例子返回名字为’Ringer’的作者的数目。如果这个名字在表authors中出现了两次，则次函数的返回值是2。 假如你想知道有不同名字的作者的数目。你可以通过使用关键字DISTINCT来得到该数目。如下例所示：   SELECTCOUNT(DISTINCT au_lname) FROM authors   如果名字’Ringer’出现了不止一次，它将只被计算一次。关键字DISTINCT 决定了只有互不相同的值才被计算。 通常，当你使用COUNT（）时，字段中的空值将被忽略。一般来说，这正是你所希望的。但是，如果你仅仅想知道表中记录的数目，那么你需要计算表中所有的记录─不管它是否包含空值。下面是一个如何做到这一点的例子：   SELECTCOUNT(*) FROM authors   注意函数COUNT（）没有指定任何字段。这个语句计算表中所有记录所数目，包括有空值的记录。因此，你不需要指定要被计算的特定字段。 函数COUNT（）在很多不同情况下是有用的。例如，假设有一个表保存了对你站点的质量进行民意调查的结果。这个表有一个名为vote的字段，该字段的值要么是0，要么是1。0表示反对票，1表示赞成票。要确定赞成票的数量，你可以所有下面的SELECT 语句：   SELECTCOUNT(vote) FROM opinion_table WHERE vote=1   计算字段的平均值 使用函数COUNT（），你可以统计一个字段中有多少个值。但有时你需要计算这些值的平均值。使用函数AVG（），你可以返回一个字段中所有值的平均值。 假如你对你的站点进行一次较为复杂的民意调查。访问者可以在1到10之间投票，表示他们喜欢你站点的程度。你把投票结果保存在名为vote的INT型字段中。要计算你的用户投票的平均值，你需要使用函数AVG（）：   SELECTAVG(vote) FROM opinion   这个SELECT语句的返回值代表用户对你站点的平均喜欢程度。函数AVG（）只能对数值型字段使用。这个函数在计算平均值时也忽略空值。   计算字段值的和 假设你的站点被用来出售卡片，已经运行了两个月，是该计算赚了多少钱的时候了。假设有一个名为orders的表用来记录所有访问者的定购信息。要计算所有定购量的总和，你可以使用函数SUM（）：   SELECTSUM(purchase_amount) FROM orders   函数SUM（）的返回值代表字段purchase_amount中所有值的平均值。字段purchase_amount的数据类型也许是MONEY型，但你也可以对其它数值型字段使用函数SUM（）。   返回最大值或最小值 再一次假设你有一个表用来保存对你的站点进行民意调查的结果。访问者可以选择从1到10 的值来表示他们对你站点的评价。如果你想知道访问者对你站点的最高评价，你可以使用如下的语句：   SELECTMAX(vote) FROM opinion   你也许希望有人对你的站点给予了很高的评价。通过函数MAX（），你可以知道一个数值型字段的所有值中的最大值。如果有人对你的站点投了数字10，函数MAX（）将返回该值。 另一方面，假如你想知道访问者对你站点的的最低评价，你可以使用函数MIN（），如下例所示：   SELECTMIN(vote) FROM opinion   函数MIN（）返回一个字段的所有值中的最小值。如果字段是空的，函数MIN（）返回空值。   其它常用的SQL表达式，函数，和过程 这一节将介绍一些其它的SQL技术。你将学习如何从表中取出数据，其某个字段的值处在一定的范围，你还将学习如何把字段值从一种类型转换成另一种类型，如何操作字符串和日期时间数据。最后，你将学会一个发送邮件的简单方法。   通过匹配一定范围的值来取出数据 假设你有一个表用来保存对你的站点进行民意调查的结果。现在你想向所有对你的站点的评价在7到10之间的访问者发送书面的感谢信。要得到这些人的名字，你可以使用如下的SELECT 语句：   SELECTusername FROM opinion WHERE vote>6 and  vote<11   这个SELECT 语句会实现你的要求。你使用下面的SELECT 语句也可以得到同样的结果：   SELECTusername FROM opinion WHERE vote BETWEEN 7 AND 10   这个SELECT 语句与上一个语句是等价的。使用哪一种语句是编程风格的问题，但你会发现使用表达式BETWEEN 的语句更易读。 现在假设你只想取出对你的站点投了1或者10的访问者的名字。要从表opinion中取出这些名字，你可以使用如下的SELECT 语句：   SELECTusername FROM opinion WHERE vote=1 or vote     这个SELECT语句会返回正确的结果，没有理由不使用它。但是，存在一种等价的方式。使用如下的SELECT可以得到相同的结果：   SELECTusername FROM opinion WHERE vote IN (1,10)   注意表达式IN 的使用。这个SELECT 语句只取出vote的值等于括号中的值之一的记录。 你也可以使用IN来匹配字符数据。例如，假设你只想取出Bill Gates或President Clinton的投票值。你可以使用如下的SELECT 语句：   SELECTvote FROM opinion  WHERE  username IN (‘Bill Gates’,’President Clinton’)   最后，你可以在使用BETWEEN或IN的同时使用表达式NOT。例如，要取出那些投票值不在7到10之间的人的名字，你可以使用如下的SELECT语句：   SELECTusername FROM opinion WHERE vote NOT BETWEEN 7 and 10   要选取那些某个字段的值不在一列值之中的记录，你可以同时使用NOT 和IN，如下例所示：   SELECTvote FROM opinion             WHERE username NOT IN (‘Bill Gates’,’PresidentClinton’)   你不是必须在SQL语句中使用BETWEEN或IN，但是，要使你的查询更接近自然语言，这两个表达式是有帮助的。   转换数据 SQLSever足够强大，可以在需要的时候把大部分数值从一种类型转换为另一种类型。例如，要比较SMALLINT型和INT型数据的大小，你不需要进行显式的类型转换。SQL Sever会为你完成这项工作。但是，当你想在字符型数据和其它类型的数据之间进行转换时，你的确需要自己进行转换操作。例如，假设你想从一个MONEY型字段中取出所有的值，并在结果后面加上字符串“US Dollars”。你需要使用函数CONVERT（），如下例所示：   SELECTCONVERT(CHAR(8),price)+’USDollars’ FROMorders   函数CONVERT（）带有两个变量。第一个变量指定了数据类型和长度。第二个变量指定了要进行转换的字段。在这个例子中，字段price被转换成长度为8个字符的CHAR型字段。字段price要被转换成字符型，才可以在它后面连接上字符串’US Dollars’。 当向BIT型，DATETIME型，INT型，或者NUMERIC型字段添加字符串时，你需要进行同样的转换操作。例如，下面的语句在一个SELECT语句的查询结果中加入字符串’The vote is’，该SELECT语句返回一个BIT型字段的值:   SELECT‘Thevote is’+CONVERT(CHAR(1),vote)FROM opinion   下面是这个语句的结果示例：   Thevote is 1 Thevote is 1 Thevote is 0 (3row(s) affected)   如果你不进行显式的转换，你会收到如下的错误信息： Implicitconversion from datatype ‘varchar’ to ‘bit’ is not allowec. Usethe CONVERT function to run this query.   操作字符串数据 SQLSever有许多函数和表达式，使你能对字符串进行有趣的操作，包括各种各样的模式匹配和字符转换。在这一节中，你将学习如何使用最重要的字符函数和表达式。   匹配通配符 假设你想建立一个与Yahoo功能相似的Internet目录。你可以建立一个表用来保存一系列的站点名称，统一资源定位器（URL），描述，和类别，并允许访问者通过在HTML form中输入关键字来检索这些内容。 假如有一个访问者想从这个目录中得到其描述中包含关键字trading card的站点的列表。要取出正确的站点列表，你也许试图使用这样的查询：   SELECTsite_name FROM site_directory  WHEREsite_desc=’tradingcard’   这个查询可以工作。但是，它只能返回那些其描述中只有trading card这个字符串的站点。例如，一个描述为We have thegreatest collection of trading cards in the world!的站点不会被返回。 要把一个字符串与另一个字符串的一部分相匹配，你需要使用通配符。你使用通配符和关键字LIKE来实现模式匹配。下面的语句使用通配符和关键字LIKE重写了上面的查询，以返回所有正确站点的名字：   SELECTSITE_name FROM site_directory                  WHERE site_desc LIKE ‘%trading cark%’      在这个例子中，所有其描述中包含表达式trading card的站点都被返回。描述为We have the greatestcollection of trading cards in the world!的站点也被返回。当然，如果一个站点的描述中包含I am trading cardboard boxes online ，该站点的名字也被返回。 注意本例中百分号的使用。百分号是通配符的例子之一。它代表0个或多个字符。通过把trading card括在百分号中，所有其中嵌有字符串trading card的字符串都被匹配。 现在，假设你的站点目录变得太大而不能在一页中完全显示。你决定把目录分成两部分。在第一页，你想显示所有首字母在A到M之间的站点。在第二页，你想显示所有首字母在N到Z之间的站点。要得到第一页的站点列表，你可以使用如下的SQL语句：   SELECTsite_name FROM site_directory WHERE site_name LIKE ‘[A-M]%’   在这个例子中使用了表达式[A-M]，只取出那些首字母在A到M之间的站点。中括号（[]）用来匹配处在指定范围内的单个字符。要得到第二页中显示的站点，应使用这个语句：   SELECTsite_name FROM  site_directory                  WHERE site_name LIKE ‘[N-Z]%’   在这个例子中，括号中的表达式代表任何处在N到Z之间的单个字符。 假设你的站点目录变得更大了，你现在需要把目录分成更多页。如果你想显示那些以A，B或C开头的站点，你可以用下面的查询来实现：   SELECTsite_name FROM site_directory WHERE site_name LIKE  ‘[ABC]%’   在这个例子中，括号中的表达式不再指定一个范围，而是给出了一些字符。任何一个其名字以这些字符中的任一个开头的站点都将被返回。 通过在括号内的表达式中同时包含一个范围和一些指定的字符，你可以把这两种方法结合起来。例如，用下面的这个查询，你可以取出那些首字母在C到F之间，或者以字母Y开头的站点：   SELECTsite_name FROM site_directory WHERE site_name LIKE ‘[C-FY]%’   在这个例子中，名字为Collegescape和Yahoo的站点会被选取，而名字为Magicw3的站点则不会被选取。 你也可以使用脱字符（^）来排除特定的字符。例如，要得到那些名字不以Y开头的站点，你可以使用如下的查询：   SELECTsite_name FROM site_directory WHERE site_name LIKE ‘[^Y]%’   对给定的字符或字符范围均可以使用脱字符。 最后，通过使用下划线字符（_），你可以匹配任何单个字符。例如，下面这个查询返回每一个其名字的第二个字符为任何字母的站点：   SELECTsite_name FROM site_directory WHERE site_name LIKE ‘M_crosoft’   这个例子既返回名为Microsoft的站点，也返回名为Macrosoft的站点。但是，名字为Moocrosoft的站点则不被返回。与通配符’％’不同，下划线只代表单个字符。   注意： 如果你想匹配百分号或下划线字符本身，你需要把它们括在方括号中。如果你想匹配连字符(-)，应把它指定为方括号中的第一个字符。如果你想匹配方括号，应把它们也括在方括号中。例如，下面的语句返回所有其描述中包含百分号的站点：       SELECT site_name FROM site_directory WHEREsite_desc LIKE ‘%[%]%’ 匹配发音 MicrosoftSQL 有两个允许你按照发音来匹配字符串的函数。函数SOUNDEX（）给一个字符串分配一个音标码，函数DIFFERENCE（）按照发音比较两个字符串。当你不知道一个名字的确切拼写，但多少知道一点它的发音时，使用这两个函数将有助于你取出该记录。 例如，如果你建立一个Internet目录，你也许想增加一个选项，允许访问者按照站点名的发音来搜索站点，而不是按名字的拼写。考虑如下的语句：   SELECTsite_name FROM site_directory                  WHERE DIFFERENCE(site_name , ‘Microsoft’>3   这个语句使用函数DEFFERENCE（）来取得其名字的发音与Microsoft非常相似的站点。函数DIFFERENCE（）返回一个0到4之间的数字。如果该函数返回4，表示发音非常相近；如果该函数返回0，说明这两个字符串的发音相差很大。 例如，上面的语句将返回站点名Microsoft和Macrosoft。这两个名字的发音与Microsoft都很相似。如果你把上一语句中的大于3改为大于2，那么名为Zicrosoft和Megasoft的站点也将被返回。最后，如果你只需要差别等级大于1即可，则名为Picosoft和Minisoft的站点也将被匹配。 要深入了解函数DIFFERENCE（）是如何工作的，你可以用函数SOUNDEX（）来返回函数DIFFERENCE（）所使用的音标码。这里有一个例子：   SELECTsite_name ‘sitename’,SOUNDEX(site_name)‘soundslike’   这个语句选取字段site_name的所有数据及其音标码。下面是这个查询的结果：   sitename                     sounds like ………………………………………………………………. Yahoo                         Y000 Mahoo                         M000 Microsoft                     M262 Macrosoft                     M262 Minisoft                      M521 Microshoft                    M262 Zicrosoft                     Z262 Zaposoft                      Z121 Millisoft                     M421 Nanosoft                      N521 Megasoft                      M221 Picosoft                      P221 (12row(s) affected)   如果你仔细看一下音标码，你会注意到音标码的第一个字母与字段值的第一个字母相同。例如，Yahoo和Mahoo的音标码只有第一个字母不同。你还可以发现Microsoft和Macrosoft的音标码完全相同。 函数DIFFERENDE（）比较两个字符串的第一个字母和所有的辅音字母。该函数忽略任何元音字母（包括y），除非一个元音字母是一个字符串的第一个字母。 不幸的是，使用SOUNDEX（）和DIFFERENCE()有一个欠缺。WHERE子句中包含这两个函数的查询执行起来效果不好。因此，你应该小心使用这两个函数。   删除空格 有两个函数，TTRIM（）和LTRIM（），可以用来从字符串中剪掉空格。函数LTRIM（）去除应该字符串前面的所有空格；函数RTRIM（）去除一个字符串尾部的所有空格。这里有一个任何使用函数RTRIM（）的例子：   SELECTRTRIM(site_name) FROM site_directory   在这个例子中，如果任何一个站点的名字尾部有多余的空格，多余的空格将从查询结果中删去。 你可以嵌套使用这两个函数，把一个字符串前后的空格同时删去：   SELECTLTRIM(RTRIM(site_name) FROM site_directory   你会发现，在从CHAR型字段中剪掉多余的空格时，这两个函数非常有用。记住，如果你把一个字符串保存在CHAR型字段中，该字符串会被追加多余的空格，以匹配该字段的长度。用这两个函数，你可以去掉无用的空格，从而解决这个问题。   操作日期和时间 日期和时间函数对建立一个站点是非常有用的。站点的主人往往对一个表中的数据何时被更新感兴趣。通过日期和时间函数，你可以在毫秒级跟踪一个表的改变。   返回当前日期和时间 通过函数GETDATE（），你可以获得当前的日期和时间。例如，语句SELECTGETDATE()返回如下的结果： ……………………………..     NOV 30 1997 3:29AM (1row(s) affected)   显然，如果你将来使用这个函数，你得到的日期将比这个时间晚，或者梗早。 函数GETDATE（）可以用来作为DATEDIME（）型字段的缺省值。这对插入记录时保存当时的时间是有用的。例如，假设有一个表用来保存你站点上的活动日志。每当有一个访问者访问到你的站点时，就在表中添加一条新记录，记下访问者的名字，活动，和进行访问的时间。要建立一个表，其中的记录包含有当前的日期和时间，可以添加一个DATETIME型字段，指定其缺省值为函数GETDATE（）的返回值，就象这样：   CREATETABLE site_log (        username VARCHAR(40),        useractivity VARCHAR(100),        entrydate DATETIME DEFAULT GETDATE())   转换日期和时间 你也许已经注意到，在上一节的例子中，函数GETDATE（）的返回值在显示时只显示到秒。实际上，SQL Sever内部时间可以精确到毫秒级（确切地说，可以精确到3.33毫秒）。 要得到不同格式的日期和时间，你需要使用函数CONVERT（）。例如，当下面的这个语句执行时，显示的时间将包括毫秒：   SELECTCONVERT(VARCHAR(30),GETDATE(),9)   注意例子中数字9的使用。这个数字指明了在显示日期和时间时使用哪种日期和时间格式。当这个语句执行时，将显示如下的日期和时间： ………………………………….. Nov 30 19973:29:55:170AM (1row(s) affected)   在函数CONVERT（）中你可以使用许多种不同风格的日期和时间格式。表11.1显示了所有的格式。   表11.1  日期和时间的类型 类型值            标准             输出   0                 Default           mon dd yyyy hh:miAM   1                 USA               mm/dd/yy   2                 ANSI              yy.mm.dd   3                British/French    dd/mm/yy   4                 German            dd.mm.yy   5                 Italian           dd-mm-yy   6                 -                 dd mon yy   7                 -                 mon dd,yy   8                 -                 hh:mi:ss 9                                        Default + milliseconds--mondd yyyy hh:mi:ss:mmmAM(or)   10                USA              mm-dd-yy   11                JAPAN            yy/mm/dd   12                ISO              yymmdd   13                Europe           Default + milliseconds--dd mon yyyy                                       hh:mi:ss:mmm(24h)   14                 -                hh:mi:ss:mmm(24h)      类型0，9，和13总是返回四位的年。对其它类型，要显示世纪，把style值加上100。类型13和14返回24小时时钟的时间。类型0，7，和13返回的月份用三位字符表示（用Nov代表November）.   对表11.1中所列的每一种格式，你可以把类型值加上100来显示有世纪的年（例如，00年将显示为2000年）。例如，要按日本标准显示日期，包括世纪，你应使用如下的语句：   SELECTCONVERT（VARCHAR（30），GETDATE（），111）       在这个例子中，函数CONVERT（）把日期格式进行转换，显示为1997/11/30   抽取日期和时间 在许多情况下，你也许只想得到日期和时间的一部分，而不是完整的日期和时间。例如，假设你想列出你的站点目录中每个站点被查询的月份。这时你不希望完整的日期和时间把网页弄乱。为了抽取日期的特定部分，你可以使用函数DATEPART（），象这样：   SELECTsite_name ‘SiteName’, DATEPART(mm,site_entrydate)‘MonthPosted’ FROMsite_directory   函数DATEPART（）的参数是两个变量。第一个变量指定要抽取日期的哪一部分；第二个变量是实际的数据。在这个例子中，函数DATEPART（）抽取月份，因为mm代表月份。下面是这个SELECT 语句的输出结果：   SiteName                         Month Posted ……………………………………………………………… Yahoo                              2 Microsoft                          5 Magicw3                            5 (3row(s) affected)     Month Posted列显示了每个站点被查询的月份。函数DATEPART（）的返回值是一个整数。你可以用这个函数抽取日期的各个不同部分，如表11.2所示。   表11.2  日期的各部分及其简写 日期部分           简写               值 year                yy                1753--9999 quarter             qq                1--4 month               mm                1--12 day of year         dy                1--366 day                 dd                1--31 week                wk                1--53 weekday             dw                1--7(Sunday--Saturday) hour                hh                0--23 minute              mi                0--59 second              ss                0--59 milisecond          ms                0--999   当你需要进行日期和时间的比较时，使用函数DATEPART（）返回整数是有用的。但是，上例中的查询结果（2，5）不是十分易读。要以更易读的格式得到部分的日期和时间，你可以使用函数DATENAME（），如下例所示：   SELECTsite_name ‘SiteName’ DATENAME(mm,site_entrydate)‘MonthPosted’ FROMsite_directory   函数DATENAME（）和函数DATEPART（）接收同样的参数。但是，它的返回值是一个字符串，而不是一个整数。下面是上例该用DATENAME（）得到的结果：   SiteName                           MonthPostec …………………………………………………………………. Yahoo                               February Microsoft                           June Magicw3                             June (3row(s) affected)   你也可以用函数DATENAE（）来抽取一个星期中的某一天。下面的这个例子同时抽取一周中的某一天和日期中的月份：   SELECTsite_name ‘SiteName’, DATENAME(dw,site_entrydate)+‘-’ + DATENAME（mm,site_entrydate）          ‘Day and Month Posted’ FORM  site_directory   这个例子执行时，将返回如下的结果：   SiteName                       Day and MonthPosted ……………………………………………………………………… Yahoo                           Friday - February Microsoft                       Tuesday - June Magicw3                         Monday - June (3row(s) affected)   返回日期和时间范围 当你分析表中的数据时，你也许希望取出某个特定时间的数据。你也许对特定的某一天中――比如说2000年12月25日――访问者在你站点上的活动感兴趣。要取出这种类型的数据，你也许会试图使用这样的SELECT语句：   SELECT* FROM weblog WHERE entrydate=”12/25/20000”   不要这样做。这个SELECT语句不会返回正确的记录――它将只返回日期和时间是12/25/200012:00:00:000AM的记录。换句话说，只有刚好在午夜零点输入的记录才被返回。   注意： 在本节的讨论中，假设字段entrydate是DATETIME型，而不是SMALLDATETIME型。本节的讨论对SMALLDATETIME型字段也是适用的，不过SMALLDATETIME型字段只能精确到秒。   问题是SQL Sever将用完整的日期和时间代替部分日期和时间。例如，当你输入一个日期，但不输入时间时，SQL Sever将加上缺省的时间“12：00：00：000AM”。当你输入一个时间，但不输入日期时，SQL Sever将加上缺省的日期“Jan 1 1900”。 要返回正确的记录，你需要适用日期和时间范围。有不止一种途径可以做到这一点。例如，下面的这个SELECT 语句将能返回正确的记录：   SELECT* FROM weblog WHERE  entrydate>=”12/25/2000” AND entrydate<”12/26/2000”   这个语句可以完成任务，因为它选取的是表中的日期和时间大于等于12/25/2000 12:00:00:000AM并小于12/26/200012:00:00:000AM的记录。换句话说，它将正确地返回2000年圣诞节这一天输入的每一条记录。 另一种方法是，你可以使用LIKE来返回正确的记录。通过在日期表达式中包含通配符“％”，你可以匹配一个特定日期的所有时间。这里有一个例子：   SELECT* FROM weblog WHERE entrydate LIKE ‘Dec25 2000%’   这个语句可以匹配正确的记录。因为通配符“％”代表了任何时间。 使用这两种匹配日期和时间范围的函数，你可以选择某个月，某一天，某一年，某个小时，某一分钟，某一秒，甚至某一毫秒内输入的记录。但是，如果你使用LIKE 来匹配秒或毫秒，你首先需要使用函数CONVERT（）把日期和时间转换为更精确的格式（参见前面“转换日期和时间”一节）。   比较日期和时间 最后，还有两个日期和时间函数对根据日期和时间取出记录是有用的。使用函数DATEADD（）和DATEDIFF（），你可以比较日期的早晚。例如，下面的SELECT语句将显示表中的每一条记录已经输入了多少个小时：   SELECTentrydate ‘TimeEntered’ DATEDIFF(hh,entrydate,GETDATE())‘HoursAgo’ FROMweblog   如果当前时间是2000年11月30号下午6点15分，则会返回如下的结果：   TimeEntered                Hours Ago ………………………………………………….. Dec30 2000  4:09PM          2 Dec30 2000  4:13PM          2 Dec 12000  4:09PM           698 (3row(s) affected)   函数DADEDIFF（）的参数是三个变量。第个变量指定日期的某一部分。在这个例子中，是按小时对日期进行比较，（要了解日期各部分的详细内容，请参考表11.2）在日期2000年11月1日和2000年11月30日的指定时间之间有689个小时。另外两个参数是要进行比较的时间。为了返回一个正数，较早的时间应该先给。 函数DATEADD（）把两个日期相加。当你需要计算截止日期这一类的数据时，这个函数是有用处的。例如，假设访问者必须先注册才能使用你的站点。注册以后，他们可以免费使用你的站点一个月。要确定什么时候他们的免费时间会用完，你可以使用如下的SELECT语句：   SELECTusername ‘UserName’, DATEADD(mm,1,firstvisit_date)‘RegistrationExpires’ FROMregistration_table   函数DATEADD（）的参数有三个变量。第一个变量代表日期的某一部分（参见表11.2），这个例子用到了代表月份的mm。第二个变量指定了时间的间隔――在本例中是一个月。最后一个变量是一个日期，在这个例子中，日期是取自DATETIME型字段firstvisit_date.假设当前日期是June 30,2000，这个语句将返回如下的内容：   UserName                         RegistrationExpires …………………………………………………………………………… BillGates                        Jul 302000  4:09PM PresidentClinton                 Jul 30 2000  4:13PM WilliamShakespeare               Jul 1 2000  4:09PM (3row(s) affected)   注意： 与你预料的相反，使用函数DATEADD（）把一个日期加上一个月，它并不加上30天。这个函数只简单地把月份值加1。这意味着在11月注册的人将比在2月注册的人多得到2天或3天的时间。要避免这个问题，你可以用函数DATEADD（）直接增加天数，而不是月份。   发送邮件 你可以用SQL Sever发送简单的e_mail信息。要做到这一点，你需要在你的系统中安装邮件服务器，如Microsoft Exchange Sever(参见第四章“ExchangeActive Sever,Index Sever,和NetShow”)。你还需要配置SQL Sever 以识别邮件服务器。 要让SQL Sever 能识别邮件服务器，启动事务管理器并从菜单中选择Sever|SQLMail|Configue，这时会出现一个如图11.3所示的对话框。输入你在邮件服务器中注册的用户名和口令，然后单击OK。   注意： 如果你使用Microsoft ExchangeSever,配置SQL Sever的过程将会大大不同。你需要在同一个（域）用户帐号下运行Microsoft SQL Sever和Exchange Sever。你还需要在安装了SQL Sever的机器上安装Exchange Cliect并给这个帐号创建一个一个配置文件。完成这些之后，你就可以在SQL Mail Configuration对话框中输入该配置文件的名字。   图11。3   在发送邮件之前，你要先启动SQL Mail。从菜单中选择Sever|SQL Mail|Start。如果你的邮件服务器配置正确，并且你输入了正确的用户名和口令，则SQL Mail会成功启动。   注意： 你可以把SQL Sever配置为自动启动邮件服务。要做到这一点，在Set Sever Optons对话框（从菜单中选择Sever|SQLSever|Configure）中选择Auto Start Mail Client即可。   要发送一个邮件，你可以使用名为xp_sendmail的扩展存储过程。这里有一个如何使用这个过程的例子：   master..xp_sendmail“president@whitehouse.gov”,”Hello Mr.President”   这个过程调用向e_mail地址president@whitehouse.gov发送一个简单的email信息：“Hello Mr. President”。你可以用任何其它的email地址和信息取代上例中相应的内容，但是，你所发送的信息不能超过255个字符长度。    当你想随时了解你的站点数据库的状态时，存储过程xp_sendmail是有用处的。例如，你可以向一个页面管理程序发送信息。如果你的站点出了什么问题，你马上就可以知道。下一章将讲述更多有关存储过程的内容。   总结 这一章加深了你的SQL知识。你学会了如何建立索引，使你的查询速度更快。你还学会了如何插入，删除和更新一个表中的数据，如何使用集合函数得到一个表中数据的统计信息。最后，你学会了许多有价值的表达式，函数和过程，用来操作字符串，日期和时间及邮件。 下一章将进一步加深你对Microsoft SQL Sever的掌握。你将学习如何用SQL来进行程序设计，如何建立存储过程，触发器和执行计划。更另人兴奋的是，你将学会让SQL Sever自动创建网页的一个简单方法。  ","title":"SQL语法大全"},{"content":"一、ADO概述 　　ADO是Microsoft为最新和最强大的数据访问范例 OLE DB 而设计的，是一个便于使用的应用程序层接口。ADO 使您能够编写应用程序以通过 OLE. DB 提供者访问和操作数据库服务器中的数据。ADO 最主要的优点是易于使用、速度快、内存支出少和磁盘遗迹小。ADO 在关键的应用方案中使用最少的网络流量，并且在前端和数据源之间使用最少的层数，所有这些都是为了提供轻量、高性能的接口。之所以称为 ADO，是用了一个比较熟悉的暗喻，OLE 自动化接口。 　　OLE DB是一组”组件对象模型”(COM) 接口，是新的数据库低层接口，它封装了ODBC的功能，并以统一的方式访问存储在不同信息源中的数据。OLE DB是Microsoft UDA(Universal Data Access)策略的技术基础。OLE DB 为任何数据源提供了高性能的访问，这些数据源包括关系和非关系数据库、电子邮件和文件系统、文本和图形、自定义业务对象等等。也就是说，OLE DB 并不局限于 ISAM、Jet 甚至关系数据源，它能够处理任何类型的数据，而不考虑它们的格式和存储方法。在实际应用中，这种多样性意味着可以访问驻留在 Excel 电子数据表、文本文件、电子邮件/目录服务甚至邮件服务器，诸如 Microsoft Exchange 中的数据。但是，OLE DB 应用程序编程接口的目的是为各种应用程序提供最佳的功能，它并不符合简单化的要求。您需要的API 应该是一座连接应用程序和OLE DB 的桥梁，这就是 ActiveX Data Objects (ADO)。  二、在VC中使用ADO(开发步骤如下：)  1、引入ADO库文件  　　使用ADO前必须在工程的stdafx.h头文件里用直接引入符号#import引入ADO库文件,以使编译器能正确编译。代码如下所示：  用#import引入ADO库文件  #import \"c:\\program files\\common files\\system\\ado\\msado15.dll\"no_namespaces rename(\"EOF\" adoEOF\") 　　这行语句声明在工程中使用ADO，但不使用ADO的名字空间，并且为了避免常数冲突，将常数EOF改名为adoEOF。现在不需添加另外的头文件，就可以使用ADO接口了。  2、初始化OLE/COM库环境 　　必须注意的是，ADO库是一组COM动态库，这意味应用程序在调用ADO前，必须初始化OLE/COM库环境。在MFC应用程序里，一个比较好的方法是在应用程序主类的InitInstance成员函数里初始化OLE/COM库环境。  BOOL CMyAdoTestApp：：InitInstance() { if(!AfxOleInit())//这就是初始化COM库 { AfxMessageBox(“OLE初始化出错!”); return FALSE; }  ……  } 3、ADO接口简介  　　ADO库包含三个基本接口:_ConnectionPtr接口、_CommandPtr接口和_RecordsetPtr接口。 　　_ConnectionPtr接口返回一个记录集或一个空指针。通常使用它来创建一个数据连接或执行一条不返回任何结果的SQL语句，如一个存储过程。使用_ConnectionPtr接口返回一个记录集不是一个好的使用方法。对于要返回记录的操作通常用_RecordserPtr来实现。而用_ConnectionPtr操作时要想得到记录条数得遍历所有记录，而用_RecordserPtr时不需要。  　　_CommandPtr接口返回一个记录集。它提供了一种简单的方法来执行返回记录集的存储过程和SQL语句。在使用_CommandPtr接口时，你可以利用全局_ConnectionPtr接口，也可以在_CommandPtr接口里直接使用连接串。如果你只执行一次或几次数据访问操作，后者是比较好的选择。但如果你要频繁访问数据库，并要返回很多记录集，那么，你应该使用全局_ConnectionPtr接口创建一个数据连接，然后使用_CommandPtr接口执行存储过程和SQL语句。  　　_RecordsetPtr是一个记录集对象。与以上两种对象相比，它对记录集提供了更多的控制功能，如记录锁定，游标控制等。同_CommandPtr接口一样，它不一定要使用一个已经创建的数据连接，可以用一个连接串代替连接指针赋给_RecordsetPtr的connection成员变量，让它自己创建数据连接。如果你要使用多个记录集，最好的方法是同Command对象一样使用已经创建了数据连接的全局_ConnectionPtr接口 ，然后使用_RecordsetPtr执行存储过程和SQL语句。　  4、使用_ConnectionPtr接口 　　_ConnectionPtr主要是一个连接接口，取得与数据库的连接。它的连接字符串可以是自己直接写，也可以指向一个ODBC　DSN。　 _ConnectionPtr pConn; if (FAILED(pConn.CreateInstance(\"ADODB.Connection\"))) { AfxMessageBox(\"Create Instance failed!\"); return; } CString strSRC; strSRC=\"Driver=SQL Server;Server=\"; strSRC+=\"suppersoft\"; strSRC+=\";Database=\"; strSRC+=\"mydb\"; strSRC+=\";UID=SA;PWD=\"; CString strSQL = \"Insert into student(no,name,sex,address) values(3,'aaa','male','beijing')\"; _variant_t varSRC(strSRC); _variant_t varSQL(strSQL); _bstr_t bstrSRC(strSRC); if (FAILED(pConn->Open(bstrSRC,\"\",\"\",-1))) { AfxMessageBox(\"Can not open Database!\"); pConn.Release(); return; } COleVariant vtOptional((long)DISP_E_PARAMNOTFOUND,VT_ERROR); pConn->Execute(_bstr_t(strSQL),&vtOptional,-1); pConn.Release(); AfxMessageBox(\"ok!\"); 5、使用_RecordsetPtr接口(以连接SQL Server为例) _RecordsetPtr pPtr; if (FAILED(pPtr.CreateInstance(\"ADODB.Recordset\"))) { AfxMessageBox(\"Create Instance failed!\"); return FALSE; } CString strSRC; strSRC=\"Driver=SQL Server;Server=\"; strSRC+=\"210.46.141.145\"; strSRC+=\";Database=\"; strSRC+=\"mydb\"; strSRC+=\";UID=sa;PWD=\"; strSRC+=\"sa\"; CString strSQL = \"select id,name,gender,address from personal\"; _variant_t varSRC(strSRC); _variant_t varSQL(strSQL); if(FAILED(pPtr->Open(varSQL,varSRC,adOpenStatic,adLockOptimistic,adCmdText))) { AfxMessageBox(\"Open table failed!\"); pPtr.Release(); return FALSE; } while(!pPtr->GetadoEOF()) { _variant_t varNo; _variant_t varName; _variant_t varSex; _variant_t varAddress; varNo = pPtr->GetCollect (\"id\"); varName = pPtr->GetCollect (\"name\"); varSex = pPtr->GetCollect (\"gender\"); varAddress = pPtr->GetCollect (\"address\"); CString strNo =(char *)_bstr_t(varNo); CString strName =(char *)_bstr_t(varName); CString strSex =(char *)_bstr_t(varSex); CString strAddress =(char *)_bstr_t(varAddress); strNo.TrimRight(); strName.TrimRight(); strSex.TrimRight(); strAddress.TrimRight(); int nCount = m_list.GetItemCount(); int nItem = m_list.InsertItem (nCount,_T(\"\")); m_list.SetItemText (nItem,0,strNo); m_list.SetItemText (nItem,1,strName); m_list.SetItemText (nItem,2,strSex); m_list.SetItemText (nItem,3,strAddress); pPtr->MoveNext(); } pPtr->Close(); pPtr.Release(); 6、使用_CommandPtr接口 　　_CommandPtr接口返回一个Recordset对象，并且提供了更多的记录集控制功能，以下代码示例了使用_CommandPtr接口的方法：  　　代码:使用_CommandPtr接口获取数据 _CommandPtr pCommand; _RecordsetPtr pRs; pCommand.CreateInstance(__uuidof(Command)); pCommand->ActiveConnection=pConn; pCommand->CommandText=\"select * from student\"; pCommand->CommandType=adCmdText; pCommand->Parameters->Refresh(); pRs=pCommand->Execute(NULL,NULL,adCmdUnknown); _variant_t varValue = pRs->GetCollect(\"name\"); Cstring strValue=(char*)_bstr_t(varValue); 7、关于数据类型转换由于COM对象是跨平台的，它使用了一种通用的方法来处理各种类型的数据，因此Cstring 类和COM对象是不兼容的，我们需要一组API来转换COM对象和C++类型的数据。_vatiant_t和_bstr_t就是这样两种对象。它们提供了通用的方法转换COM对象和C++类型的数据。","title":"VC用ADO访问数据库全攻略"},{"content":"为什么需要监听？     什么是server process？作用？         当客户端有用户想要操作数据库的时候，比如说在数据库下建表，插入、删除数据，这个时候用户需要登录认证，而用户的登录就是一次连接请求，是客户端与服务器的连接，oracle服务器需要监听到这个请求，然后对此连接的用户名密码进行判断，因此必须要有一个监听进程，就是用来监听客户端的连接以及断开请求，这就决定了运行连接命令 SQL>conn /as sysdba之前必须已经启动了监听进程，linux下监听的启动方法是 lsnrctl start ，当监听进程监听到客户端的连接请求的时候，监听进程会将此连接请求发送到oracle服务器，由服务器来判断，此连接是否有效。如果有效，会生成一个服务器进程server process，专门用来协调数据库与实例之间的通信，数据库与实例之间是不能够之间传送数据的，中间需要经过 server process，  为什么数据库实例之间要进行通信？      任何对数据库做的更改，都需要底层操作系统的支持，而实例就是用来在操作系统和数据库之间来进行解析的。大致等同于 数据库是一个硬件，而实例属于该硬件的驱动。重要性可想而知。   对数据库的整体操作流程大致是：       用户连接请求—》服务器监听到请求--》连接成功并创建server process进程--》用户对数据库进行更改--》通过server process进程将更改信息传送至数据库实例--》数据库实例调用相关操作系统函数来使更改生效   全局数据库名就是 数据库名加上数据库域名      orcl.domain表示形式     ","title":"oracle 的数据库，数据库实例、监听之间的关系"},{"content":"本例说明如何开发一个简单的有文字信息，好友上下线事件等基本功能功能的即时通讯程序，若配合Flash，还可以实现与web文字信息发送互通效果。 PRTX 即时通讯SDK适合软件公司将即时通讯与ERP，OA，CRM等系统整合。PRTX即时通讯也可用于企业办公或者网站类似旺旺与QQ。 要完成即时通讯功能，您不需要注重实现细节，使用低成本的PRTX SDK的ZhWebim.ocx只需要调用几个函数就可实现。以下以无数据库版本为例。 1. 安装组件ZhWebIM.ocx 2. 初始化Start_Up 本函数非常简单，是开始的第一步，就是创建通讯socket，初始化组件。 3. 登录IM服务器LoginWebIM 本函数需要输入用户号码(类似QQ号)和密码，以及服务器IP地址和端口。调用此函数，服务器即会收到用户号和密码，通过验证后，将登录成功或者不成功发回。将触发组件的OnWebIMLoginReply事件。 4. 上传好友列表WebIMUpoadContactList和在线状态 本函数将好友列表以字符串方式传到服务器，列表中的好友同时将收到好友上线的事件OnUserOnline。如果不需要好友的上线状态，则不需要调用此函数。 例如，10000号用户有10001,10002,10003 这3个好友，则如下调用: WebIMUpoadContactList (“10001,10002,10003,”) 5. 发消息WebIMSendMsg 本函数发消息给任何指定用户号码，收到消息是OnGetMsg事件。消息可定义不同类型，方便不同处理，比如聊天内容是27，加好友请求是28 比如10000号发消息给10002号，消息内容是”您好”，则如下 WebIMSendMsg(27, 10002, “您好”) 6. 接收消息 调用WebIMSendMsg后，消息接收者将触发OnGetMsg事件，事件中包括发送者号码，消息类型和消息内容，您只需要显示出来即可。 7. 与Web互通 若需要与Web聊天互通，只需要打开以下页面，即可互发信息。 http://bbs.webp2p.com:8004/webim2/testPage.htm 8. 带数据库高级版本 PRTX除了上述无数据库版本，也有数据库版本，功能可包括有P2P文件传输，P2P语音视频，图文发送等，可与ERP，OA，CRM等系统整合。 具体可参考 http://www.webp2p.com/Product/LiveIMSDK.htm 源码 如果需要源码，请与纵横网络联系。 网站: www.webim.cn QQ: 1113562905","title":"5个函数开发可与Web互通即时通讯聊天系统"},{"content":"在查看Android的soucre code的时候，经常会遇到查询数据库的代码，如 final ContentResolver cr = mContext.getContentResolver(); final int networkPrefSetting = Settings.Secure.getInt(cr, Settings.Secure.NETWORK_PREFERENCE, -1); 这就是一个查询数据库的操作，这个值是多少，怎么查看呢？ 原来有两种办法： 1. 利用Android提供的查询数据库接口，自己写程序查看数据库的值。     1) 将写好的程序push到手机中，查看执行结果。     2) 将写好的程序在模拟器上执行，但是这样查看，只能看到模拟器上数据库中的值，也就是标准Android的默认值。 2. 进入adb shell，通过sqlite3工具来查询。     进入adb shell，执行cd /data/data/，执行ls会发现有好多目录： com.android.musicfx com.android.nfc com.android.packageinstaller com.android.phone com.android.protips com.android.providers.applications com.android.providers.calendar com.android.providers.contacts com.android.providers.downloads com.android.providers.downloads.ui com.android.providers.drm com.android.providers.media com.android.providers.partnerbookmarks com.android.providers.settings 这些目录就是软件的工程包名，进入你需要查询的目录，例如com.android.providers.settings目录，目录下有以db结尾的文件(settings.db)就是数据库文件， 执行命令sqlite3 settings.db，就可以进入数据库，然后就可以执行SQL语句了。","title":"android中的数据库"},{"content":"有时候事物真是很奇妙，800到1500你不会觉得，1500到3000你不会觉得，3000到4500你也不会觉得，4500到9000的时候你就...我从小的终极梦想就是月薪一万！它对我来说就像从小到高中时语文老师给我们念过的一个个所谓满分作文一样，那时传说中的存在啊，我曾今幻想过我能有月薪1万的那天吗？真是不敢想啊，我没奢望过，更没想过月薪1万能过怎样幸福的生活，但是...哥现在9000了看不是只差1000嘛，我直接忽略了，说实在对方说能给这个数的时候我的心咯噔了一下，在之后的时间里我查阅了很多这个公司相关的资料怕他是骗人滴，怕他忽悠啊，最终确认他是国内一家大型外包公司，我曾想过是不是让他先把路费打过来再去，后来我顶住了，俺得大气点，俺也是挣1万的人了啊。        怀着这样的心情我取出了3年来存下的8000块钱踏上了北漂的旅途…        过程不表，租了一家离公司近的单间开始了我北京第一年的BI人生，才开始去的时候还真是畏畏缩缩的，生怕一个不好砸了，但是没混多久发现俺的技术属第一啊，原来大家都是才开始做BI工作没多久，从经理到同事大家都没撒经验，于是混得风声水起，成为了所谓的技术牛人，半年后成为Team Leader，这时遇到了我人生中的第一位大师级人物，说实在的真不好意思英文名字不好记已经忘了，但是从他那里学到了ETL和BI的系统知识和第一个完整的的从数据抽取到处理再到模型….的完整架构，总之很多Blabla…         人生就是这样，当你成为牛人你就得指点人，说实在很多题我也是百度出来，哎架不住人问啊，不过我从中学到了不少。就这样1年就过去了，薪水涨到了11000，但是早已没了之前的新鲜，哎1万在北京什么都不是，这真是疯狂的时代啊，不过吃的还行，2010年正是团购火的时候，我在糯米上买了全北京很多地方的团购，有时候为了去吃个饭来回要4个小时，算是把吃进行到底了吧，还跟以前武汉的2个朋友联系上了，现在在北京都混得比我好，于是大家继续聚餐中…         有时机会就是这样，一不小心他就来了，有天我接到一个电话，是我这个公司以前的同事，推荐我去他现在的公司，说是有个职位可以帮我推荐下，还说他现在这个公司比这边怎么怎么好，我来了工资能提升多少，对于这种八字没一撇的我一般都报着试一试的想法，之前也有猎头联系过我不过因为英语问题后来都吹了。         于是我去面试了，在面试，在面试，再面试，过4关斩5将，我通过了，说实在我是得知通过之后才考虑是不是要跳巢的，跳巢有风险啊，开始给我13000，但是我本公司当时也给我涨到11000了，所以我想了想拒绝了，但是对方HR很有毅力，一直跟我扯了一周，最后他说了句那再给你涨1000吧，你看这样不行就没办法了，接着我就答应了，厚着脸皮跟当时的OF主管辞了职，哎他人挺好的，还给我一本数据库相关的英语资料书籍，但是钱的面前我向来免疫力低，后来他也没怎么留我，说实在我还挺失落的，也许外包就是这样一个快速流动的行业吧，大家都习惯了。        2011年5月我月薪14000了","title":"我的6年职场人生从月薪800到2万（3）"},{"content":"MySQL5.0版本的安装图解教程是给新手学习的,当前mysql5.0.91是最新的稳定版本。 mysql 下载地址 http://www.jb51.net/softs/2193.html 下面的是MySQL安装的图解，用的可执行文件安装的，详细说明了一下！打开下载的mysql安装文件mysql-5.0.27-win32.zip，双击解压缩，运行“setup.exe”，出现如下界面 mysql安装图文教程1 mysql安装向导启动，按“Next”继续 mysql图文安装教程2 选择安装类型，有“Typical（默认）”、“Complete（完全）”、“Custom（用户自定义）”三个选项，我们选择“Custom”，有更多的选项，也方便熟悉安装过程: mysql图文安装教程3 在“Developer Components（开发者部分）”上左键单击，选择“This feature, and all subfeatures, will be installed on local hard drive.”，即“此部分，及下属子部分内容，全部安装在本地硬盘上”。在上面的“MySQL Server（mysql服务器）”、“Client Programs（mysql客户端程序）”、“Documentation（文档）”也如此操作，以保证安装所有文件。点选“Change...”，手动指定安装目录。 mysql图文安装教程4 填上安装目录，我的是“F:\\Server\\MySQL\\MySQL Server 5.0”，也建议不要放在与操作系统同一分区，这样可以防止系统备份还原的时候，数据被清空。按“OK”继续。 mysql图文安装教程5 返回刚才的界面，按“Next”继续 mysql图文安装教程6 确认一下先前的设置，如果有误，按“Back”返回重做。按“Install”开始安装。 mysql图文安装教程7 正在安装中，请稍候，直到出现下面的界面 mysql图文安装教程8 这里是询问你是否要注册一个mysql.com的账号，或是使用已有的账号登陆mysql.com，一般不需要了，点选“Skip Sign-Up”，按“Next”略过此步骤。 mysql图文安装教程9 现在软件安装完成了，出现上面的界面，这里有一个很好的功能，mysql配置向导，不用向以前一样，自己手动乱七八糟的配置my.ini了，将 “Configure the Mysql Server now”前面的勾打上，点“Finish”结束软件的安装并启动mysql配置向导。 mysql图文安装教程10 mysql配置向导启动界面，按“Next”继续 mysql图文安装教程10 选择配置方式，“Detailed Configuration（手动精确配置）”、“Standard Configuration（标准配置）”，我们选择“Detailed Configuration”，方便熟悉配置过程。 mysql图文安装教程11 选择服务器类型，“Developer Machine（开发测试类，mysql占用很少资源）”、“Server Machine（服务器类型，mysql占用较多资源）”、“Dedicated MySQL Server Machine（专门的数据库服务器，mysql占用所有可用资源）”，大家根据自己的类型选择了，一般选“Server Machine”，不会太少，也不会占满。 mysql图文安装教程12 选择mysql数据库的大致用途，“Multifunctional Database（通用多功能型，好）”、“Transactional Database Only（服务器类型，专注于事务处理，一般）”、“Non-Transactional Database Only（非事务处理型，较简单，主要做一些监控、记数用，对MyISAM数据类型的支持仅限于non-transactional），随自己的用途而选择了，我这里选择“Transactional Database Only”，按“Next”继续。 mysql图文安装教程13 对InnoDB Tablespace进行配置，就是为InnoDB 数据库文件选择一个存储空间，如果修改了，要记住位置，重装的时候要选择一样的地方，否则可能会造成数据库损坏，当然，对数据库做个备份就没问题了，这里不详述。我这里没有修改，使用用默认位置，直接按“Next”继续 mysql图文安装教程14 选择您的网站的一般mysql访问量，同时连接的数目，“Decision Support(DSS)/OLAP（20个左右）”、“Online Transaction Processing(OLTP)（500个左右）”、“Manual Setting（手动设置，自己输一个数）”，我这里选“Online Transaction Processing(OLTP)”，自己的服务器，应该够用了，按“Next”继续 mysql图文安装教程15 是否启用TCP/IP连接，设定端口，如果不启用，就只能在自己的机器上访问mysql数据库了，我这里启用，把前面的勾打上，Port Number：3306，在这个页面上，您还可以选择“启用标准模式”（Enable Strict Mode），这样MySQL就不会允许细小的语法错误。如果您还是个新手，我建议您取消标准模式以减少麻烦。但熟悉MySQL以后，尽量使用标准模式，因为它可以降低有害数据进入数据库的可能性。按“Next”继续 mysql图文安装教程16 西文编码，第二个是多字节的通用utf8编码，都不是我们通用的编码，这里选择第三个，然后在Character Set那里选择或填入“gbk”，当然也可以用“gb2312”，区别就是gbk的字库容量大，包括了gb2312的所有汉字，并且加上了繁体字、和其它乱七八糟的字——使用mysql的时候，在执行数据操作命令之前运行一次“SET NAMES GBK;”（运行一次就行了，GBK可以替换为其它值，视这里的设置而定），就可以正常的使用汉字（或其它文字）了，否则不能正常显示汉字。按 “Next”继续。 mysql图文安装教程17 选择是否将mysql安装为windows服务，还可以指定Service Name（服务标识名称），是否将mysql的bin目录加入到Windows PATH（加入后，就可以直接使用bin下的文件，而不用指出目录名，比如连接，“mysql.exe -uusername -ppassword;”就可以了，不用指出mysql.exe的完整地址，很方便），我这里全部打上了勾，Service Name不变。按“Next”继续。选择是否将mysql安装为windows服务，还可以指定Service Name（服务标识名称），是否将mysql的bin目录加入到Windows PATH（加入后，就可以直接使用bin下的文件，而不用指出目录名，比如连接，“mysql.exe -uusername -ppassword;”就可以了，不用指出mysql.exe的完整地址，很方便），我这里全部打上了勾，Service Name不变。按“Next”继续。 mysql图文安装教程18 这一步询问是否要修改默认root用户（超级管理）的密码（默认为空），“New root password”如果要修改，就在此填入新密码（如果是重装，并且之前已经设置了密码，在这里更改密码可能会出错，请留空，并将“Modify Security Settings”前面的勾去掉，安装配置完成后另行修改密码），“Confirm（再输一遍）”内再填一次，防止输错。“Enable root access from remote machines（是否允许root用户在其它的机器上登陆，如果要安全，就不要勾上，如果要方便，就勾上它）”。最后“Create An Anonymous Account（新建一个匿名用户，匿名用户可以连接数据库，不能操作数据，包括查询）”，一般就不用勾了，设置完毕，按“Next”继续。 mysql图文安装教程19 确认设置无误，如果有误，按“Back”返回检查。按“Execute”使设置生效。 mysql图文安装教程20 设置完毕，按“Finish”结束mysql的安装与配置——这里有一个比较常见的错误，就是不能“Start service”，一般出现在以前有安装mysql的服务器上，解决的办法，先保证以前安装的mysql服务器彻底卸载掉了；不行的话，检查是否按上面一步所说，之前的密码是否有修改，照上面的操作；如果依然不行，将mysql安装目录下的data文件夹备份，然后删除，在安装完成后，将安装生成的 data文件夹删除，备份的data文件夹移回来，再重启mysql服务就可以了，这种情况下，可能需要将数据库检查一下，然后修复一次，防止数据出错。 您可能感兴趣的文章: win2003 MySQL5安装图文教程与设置方法 PHP开发环境配置(MySQL数据库安装图文教程)","title":"mysql安装图解 mysql图文安装教程(详细说明)（转载自脚本之家http://www.jb51.net/article/23876.htm）"},{"content":"VS2010连接SQL Server 2008并执行查询操作 先在SQL Server 2008中建一个Student数据库，含有一个表student，4个字段，分别为姓名(varchar)学号(varchar)性别(varchar)年龄(int)，并指定一个用户登录该数据库，用户名为cam，密码为123456，注意要修改cam用户的权限 新建控制台应用程序，连接数据库，输出student表中的所有字段，并执行插入删除操作 using System;using System.Data;using System.Data.SqlClient;using System.Collections.Generic;using System.Linq;using System.Text;namespace 连接数据库{    class Program    {        public static int Insert(string name, string pwd,string sex,int age)        {            SqlConnection conn = new SqlConnection(\"Data Source=(local);Initial Catalog=Student;Integrated Security=True\");//Initial Catalog后面跟你数据库的名字            conn.Open();            string sql = \"insert into student(姓名,学号,性别,年龄) values(@name,@pwd,@sex,@age)\";            SqlCommand cmd = new SqlCommand(sql, conn);            SqlParameter parn1 = new SqlParameter(\"@name\", name);            cmd.Parameters.Add(parn1);            SqlParameter parn2 = new SqlParameter(\"@pwd\", pwd);            cmd.Parameters.Add(parn2);            SqlParameter parn3 = new SqlParameter(\"@sex\", sex);            cmd.Parameters.Add(parn3);            SqlParameter parn4 = new SqlParameter(\"@age\", age);            cmd.Parameters.Add(parn4);            int result = cmd.ExecuteNonQuery();//result接收受影响行数，也就是说result大于0的话表示添加成功            conn.Close();            cmd.Dispose();            return result;        }        public static int Update(string name)        {            SqlConnection conn = new SqlConnection(\"Data Source=(local);Initial Catalog=Student;Integrated Security=True\");//Initial Catalog后面跟你数据库的名字            conn.Open();            string sql = \"delete from student where 姓名=@name\";            SqlCommand cmd = new SqlCommand(sql, conn);            SqlParameter parn = new SqlParameter(\"@name\",name);            cmd.Parameters.Add(parn);            int result = cmd.ExecuteNonQuery();//result接收受影响行数，也就是说result大于0的话表示删除成功            conn.Close();            cmd.Dispose();            return result;        }        static void Main(string[] args)        {            //指定Sql Server提供者的连接字符串            string connString = \"server=CAMBRIDGE-PC;database =Student;uid=cam;pwd=123456\";            //建立连接对象            SqlConnection Sqlconn = new SqlConnection(connString);            //打开连接            Sqlconn.Open();            //为上面的连接指定Command对象            SqlCommand thiscommand = Sqlconn.CreateCommand();            thiscommand.CommandText = \"select 姓名,学号,性别,年龄 from student\";            //为指定的command对象执行DataReader            SqlDataReader thisSqlDataReader = thiscommand.ExecuteReader();            while (thisSqlDataReader.Read())            {                Console.WriteLine(\"{0} {1} {2} {3}\", thisSqlDataReader[\"姓名\"], thisSqlDataReader[\"学号\"], thisSqlDataReader[\"性别\"], thisSqlDataReader[\"年龄\"]);            }            //关闭读取            thisSqlDataReader.Close();            int result = Insert(\"关羽\", \"E01014307\", \"男\", 25);            Console.WriteLine(\"影响的行数为:{0}\", result);            result = Update(\"关羽\");            Console.WriteLine(\"影响的行数为:{0}\", result);            //关闭连接            Sqlconn.Close();            Console.ReadLine();        }    }} 建Windows窗体应用程序也可以,在Form窗体中拖一个DataGridView控件，插入一个学生的信息，在DataGridView控件中显示所有学生的信息 using System;using System.Collections.Generic;using System.ComponentModel;using System.Data;using System.Data.SqlClient;using System.Drawing;using System.Linq;using System.Text;using System.Windows.Forms;namespace cam{    public partial class Form1 : Form    {        public Form1()        {            InitializeComponent();        }        public static int Insert(string name, string pwd, string sex, int age)        {            SqlConnection conn = new SqlConnection(\"Data Source=(local);Initial Catalog=Student;Integrated Security=True\");//Initial Catalog后面跟你数据库的名字            conn.Open();            string sql = \"insert into student(姓名,学号,性别,年龄) values(@name,@pwd,@sex,@age)\";            SqlCommand cmd = new SqlCommand(sql, conn);            SqlParameter parn1 = new SqlParameter(\"@name\", name);            cmd.Parameters.Add(parn1);            SqlParameter parn2 = new SqlParameter(\"@pwd\", pwd);            cmd.Parameters.Add(parn2);            SqlParameter parn3 = new SqlParameter(\"@sex\", sex);            cmd.Parameters.Add(parn3);            SqlParameter parn4 = new SqlParameter(\"@age\", age);            cmd.Parameters.Add(parn4);            int result = cmd.ExecuteNonQuery();//result接收受影响行数，也就是说result大于0的话表示添加成功            conn.Close();            cmd.Dispose();            return result;        }        public static int Update(string name)        {            SqlConnection conn = new SqlConnection(\"Data Source=(local);Initial Catalog=Student;Integrated Security=True\");//Initial Catalog后面跟你数据库的名字            conn.Open();            string sql = \"delete from student where 姓名=@name\";            SqlCommand cmd = new SqlCommand(sql, conn);            SqlParameter parn = new SqlParameter(\"@name\", name);            cmd.Parameters.Add(parn);            int result = cmd.ExecuteNonQuery();//result接收受影响行数，也就是说result大于0的话表示删除成功            conn.Close();            cmd.Dispose();            return result;        }        public DataTable sel()        {            SqlConnection conn = new SqlConnection(\"Data Source=(local);Initial Catalog=Student;Integrated Security=True\");//Initial Catalog后面跟你数据库的名字,如果你的SqlServer服务器名称后面不带SQLEXPRESS，那么Data Source=.            conn.Open();            string sql = \"select * from student\";            SqlCommand cmd = new SqlCommand(sql, conn);            SqlDataAdapter sda = new SqlDataAdapter(cmd);            DataTable dt = new DataTable();            sda.Fill(dt);            conn.Close();            cmd.Dispose();            return dt;        }         private void Form1_Load(object sender, EventArgs e)        {            Insert(\"关羽\", \"E01014307\", \"男\", 25);            dataGridView1.DataSource = sel();        }    }}","title":"VS2010连接SQL Server 2008并执行查询操作"},{"content":"刚才发了一帖自己回顾一下才发现很多地方不通顺加错字，真是希望大家包涵啊，俺不专业啊。           为什么想写点什么呢？绝对没有炫耀的意思，因为我周围都是跟我一样的人，这点从来没变过，所以才知自己什么都不是啊。可能是我自己也没想到自己能走到现在样吧所以来发发牢骚，打击轻拍，谢谢哦。           接上文，回成都对我来说只是一个比较好的选择，我这样的人英语不是很好（现在仍然如此），技术一般去北上广毫无竞争力可言，最多也就4000打顶了，而回成都能拿到2500对我来说是不小的吸引力，因为我从小的心愿就是月薪2000，这个愿望一直到我大学毕业，说来可笑为什么会这么想呢？因为我贪吃，从小贪吃，我小时候给自己算过每天的70元的伙食费能让生活在天堂一样，事实也的确如此2007年之前的成都2000已经能让让生活的很美好了，至于现在...我只能说往事不堪回首啊，从2007年回去后到2010年是我人生中最幸福的3年，每天能够睡到8点起床，每月有2000的零花钱，能够想去哪吃去哪吃，父母对我的管控也减轻了不少，人生就是如此啊，只要比去年过的好你就是幸福的，对比之下我已经在天堂了！          一年后我从这家公司跳去了成都另外一个大型外资企业，去的原因说来可笑，就是因为每天我能看到他们公司的班车能从我家门前过于是我就投了，于是我就去了，工资涨到了3000，于是我更幸福了，这是第一家外企，外企真是不一样啊，在这家公司我没加过班，真么加过班，在CSDN上发牢骚的习惯都是在这憋出来的，但是我真的从这家公司学到不少东西，确定了我以后发展的方向，如果哪天我回到成都的话我还希望能回到这家公司，当然工资得给高点，呵呵说到兴头上我就把他报出来了成都新电（NCS）。它的确很养人，着这里我要谢谢我的经理，每当我闲的想搞小动作的时候他总会从旁提醒我一下，于是我的英语水平提高了，数据库的学习方向也在这里确立。          为什么学数据库，当时真的没想那么深，仅仅只是因为我觉得我自己在这方面比较有天赋，学数据库比较不累而已，后来我又渐渐接触了BI对他的知识理论深表震惊，于是我就一路学了过来。有时候真的觉得知识就像是一个猜猜看的游戏，才开始的时候猜的很吃力，不知道他是什么，越到后面你就觉得越学越顺，越学越有成就感。          学了1年半以后就开始想做这方面的工作了，越是给经理提出要换组，在这里真的要再次感谢下，虽然他在技术上真的不乍样，但是对员工的关怀是我遇到过最好的上司，哎但是公司里面当时的确没有我喜欢的职位和工作，后来我找了找发现整个成都都很少有这方面的工作于是把眼光放向了北上广。          当是觉得自己就是一个志向饱满学有成就的要出山一闯的有为青年，加上父母的鼓励和支持于是不出意外我来到了北京成为一位公司的BI工程师。工资涨到9000了（注：当时在成都也有4500）。          这是一个值得骄傲的事（自认为），为此我还在天涯上发过贴，当然最后被拍的很厉害，人真的不傲娇啊。          于是2010年5月我到了北京，开始了我人生的第二站！","title":"我的6年职场人生从月薪800到2万（2）"},{"content":" 有1年半没来CSDN更新微博了，纵观6年来我的微博更新轨迹，总结出每当我跳槽到一个新公司或者快从一个公司离开的时候通常是我更新微博的时候。         可能这个时期比较闲吧，北京真实一个忙碌的城市，至少比我的家乡成都忙多了，每当我早晨赶公交挤地铁的看着身旁汹涌而过的人群，总不知道他们奔跑这一会能节省多少时间。可能是我不怕迟到吧，所在的公司都是弹性工作时间，9点到9点半都行哪怕再迟点也没关系，呵呵这也许是做IT的好处，唯一能让我感到欣慰的是我没有被这个忙碌的城市感染的太深，我仍然用着成都特有的休闲意境每日穿梭在这个大都市里，看着上下班时冲冲而过的人群，我是一个在北京打工的成都人。          遥想当年那个撒来着，真实比较酸的开头，为了1500/月的薪水我从成都去到武汉成为了一个位.net软件开发工程师，从大三到大四我的梦想一直是成为一位游戏策划师，我为之付出了很大的努力，这整整一年的时间里我只投过游戏公司的职位，我的简历的字数比我的大学论文写的还多，而且完全是原创的，还自己花3个月的时间开发一个ARPG的游戏，当然也有不少公司给了我回应，但最终一家没成，其实我要求真不高，可是我是一个毕业生。最终我放低了要求，想先进个相关行业吧，但是才发现原来也不简单啊，最后背井离乡的去了武汉这家软件公司。         1500不多但是对那时候的我真的时足够了，我其实只是要一个工作的理由，就会去为了它付出，这也是我现在对那些公司招进来的应届生实习生的态度：对他们宽容些都是过来人。到了武汉，不包吃住，试用期3个月月薪800，我也没绝对他少，因为我和几个一起去的同事在光谷外面的城中村租了一个农名房，7个人平摊下来每人每月80块加网费就算100吧，物理只有7张床，没热水，没空调，什么都没有，但是我们就这样7个人在那个屋里度过了2006.10--2007.10 整整1年的时光，现在我经常把这段经历给老婆讲，老婆都说听出茧了，这也许就是我迈出社会的第一步吧。        我的第一个公司，不算太大也不算太小在光谷有接近400多人的开发团队，算是当时比较中大型的了，我们一起进公司的有40多人，来自成都，西安和武汉本地，大家都是没撒经验的人，有大学或技校毕业的，有做销售想转行的，有1年甚至不到开发经验的，在前3个月时间里真实难熬啊，撒都不懂，每天下班后回家都在不断自学中，还好一个屋里的7个人都还互相帮助，3个月后大家都坚持下来了，西安那边来的人也都在，就是本地的那些走的差不多了，看来在外地招人是比本地的好啊，有毅力的多，因为没退路了嘛，虽然那时候什么都不会，但是公司的要求是遵守的最好的，穿着西服打着领带挎着电脑包，据说有人因此被门卫拦过说是怕来的是推销保险的（汗！） 。      那时候认识的同事是保持联系最久的，现在仍然有事没事的聊着，大家天蓝海北到处都是，但不外乎北上广和回老家，算来做这行还算不错，现在还坐着的基本月薪也在万八千左右，有些或创业或转行做销售的只要还在业内都还没给国家拖后腿。IT还算是个公平的朝阳行业，我无不想到并为之庆幸，这里面没有太多的事故也没有太多的不平，大家的关系都还单纯。      2007.10左右的时候不知怎么的大家陆续开始想着跳巢了，真实奇怪的现象啊：     1.因为我们涨的工资少，还不如新来的有1年工作经验的工资高（当时我已经1800了但是有的才来就2500）。     2.有的跳巢了工资翻番，惹得大家羡慕啊。（我在本地找了几家最高只给到2500）     3.有的去了上海据说有6000。（我透过那边的也只给4000）     于是我们的有的回老家了比如说我，有的去了北上广，当时做java开发的比作.net开发的待遇好，那时我无不羡慕，2007.10我回到了我的故乡，没花几周找到了我家乡的第一个工作仍然是.net工程师，工资2500啦，我一直觉得这才是我人生的起点，不知为何？","title":"[置顶] 我的6年职场人生从800/月到2万"},{"content":"Qt开发环境的搭建请参考网址：http://blog.csdn.net/fan_hai_ping/article/details/8273669 MySQL库编译 在使用MySQL数据库的时候，报如下错误： QSqlDatabase: QMYSQL driver not loaded QSqlDatabase: available drivers: QSQLITEQODBC3 QODBC QPSQL7 QPSQL 缺省情况下，对于QSqlDatabase可用的库有QSQLITEQODBC3 QODBC QPSQL7 QPSQL，如果需要使用MySQL库或者Oracle库就要自己进行手动编译，方法如下： 首先下载Mysql的开发库，下载网址如下： http://cdn.mysql.com/Downloads/Connector-C/mysql-connector-c-noinstall-6.0.2-win32.zip 然后解压缩文件到Qt安装目录下，修改目录名为mysql，现在开始编译MySQL驱动： 进入到D:\\Qt\\4.8.4\\src\\plugins\\sqldrivers\\mysql目录（QT SDK安装目录）下，找到mysql.pro文件，在第二行添加： INCLUDEPATH +=D:/Qt/mysql/include LIBS +=D:/Qt/mysql/lib/libmysql.lib 在该目录下执行qmake生成makefile文件： qmake -oMakefile mysql.pro  （或） qmake 执行make进行编译（VS使用nmake命令）Debug和Release版本： make （or） nmake nmake /fMakefile.Debug nmake /f Makefile.Release 此时，会在当前目录下debug和release目录中生成dll和lib文件，把这些动态库文件(qsqlmysqld4.dll/lib和qsqlmysql4.dll/lib)拷贝到D:\\Qt\\4.8.4\\plugins\\sqldrivers目录下。 同时，也要把mysql/lib/libmysql.dll这个文件复制到qt的bin目录(D:\\Qt\\4.8.4\\bin)下。 Oracle库编译   搭建开发环境需下载两个文件： 下载网址：http://www.oracle.com/technetwork/topics/winsoft-085727.html instantclient-basic-nt-11.2.0.3.0.zip。这个包包含运行OCCI程序的动态链接库。 instantclient-sdk-nt-11.2.0.3.0.zip。这个包包含开发库的头文件、静态链接库以及occi示例程序。 注：在Oracle官网上下载文件时需要注册一个账号（free）。 解压缩instantclient-sdk-nt-11.2.0.3.0.zip，修改instantclient-sdk-nt-11.2.0.3.0为oracle，然后把oracle目录拷贝到QT安装目录D:\\Qt下。 进入到D:\\Qt\\4.8.4\\src\\plugins\\sqldrivers\\oci目录下，修改oci.pro，添加下面两行： INCLUDEPATH +=D:/Qt/oracle/instantclient_11_2/sdk/include LIBS +=D:/Qt/oracle/instantclient_11_2/sdk/lib/msvc/oci.lib 执行qmake生成makefile项目，打开Makefile.Debug和Makefile.Release文件修改第18行，删除掉红色字体标注的oci.lib字符串： LIBS          = D:/Qt/oracle/instantclient_11_2/sdk/lib/msvc/oci.lib oci.lib 使用nmake进行编译生成Debug和Release动态库： nmakerelease  （or） nmake debug 此时，会在当前目录下debug和release文件夹中生成的动态库（qsqloci4.dll/.lib和qsqlocid4.dll/.lib），把它们拷贝到D:\\Qt\\4.8.4\\plugins\\sqldrivers目录下。 同时，把instantclient-basic-nt-11.2.0.3.0.zip压缩文件中的oci.dll提取到D:\\Qt\\4.8.4\\bin目录中，这样QSqlDatabase可以正确的加载plugins\\sqldrivers目录中的Oracle动态库。","title":"如何在QT中编译数据库驱动"},{"content":"正确使用Statement的批量SQL命令执行方法 1、现象：问题描述    系统在对定时导入用户数据到系统数据库功能做大规模数据导入测试，导入用户数据量达到1000万以上，出现“out of memory”严重问题，系统宕机。 2、关键过程：根本原因分析 分析系统用户数据导入过程，该过程分两部分执行： 第一步，从外部部件的数据库中读取所有用户数据，将读取到的数据写入到文件中，文件以10M大小进行分割； 第二步，当所有数据写入到文件中后，创建一个PreparedStatement对象（PreparedStatement类继承了 Statement类），根据文件中的每一条记录创建一条insert的SQL命令语句，再调用addBatch(String sql)方法将创建的SQL命令语句添加到刚刚创建的PreparedStatement对象的命令列表中，最后调用executeBatch()方法将命令列表中的所有SQL命令逐一执行。出现“out of memory”的原因恰恰就出在第二步中的调用addBatch(String sql)方法将创建的String型SQL语句添加到PreparedStatement对象的命令列表中，代码中是将所有数据文件中的数据一次性读入，根据每一条数据创建一条SQL语句，全部添加到PreparedStatement对 象的命令列表后，再调用executeBatch()方法，这样，1400万条用户数据就要创建1400万条SQL语句保存在内存中，一条String型的SQL语句至少有164个字节，1400万条就是14000000*164=2296000000字节，也就是说至少需要2.296G内存容量，而安装系统的服务器的内存容量配置只有1G，这样显然要“out of memory”了。 3、结论：解决方案及效果    根据以上的分析结果，将第二步数据库操作修改为，当PreparedStatement对象命令列表中的SQL语句达到一定数量（该数量由配置文件配置，可以根据服务器的不同配置来设定该值）后，就调用一次executeBatch()方法，执行命令列表中的SQL语句，然后调用clearBatch()方法清空命令列表中的SQL语句，再继续向命令列表中添加SQL语句，如此循环，直到将数据文件中的所有数据全部导入到MCS的数据表。经过以上修改，再次进行1400万用户数据的导入测试，“out of memory”的问题再也没有出现了。 4、经验总结：预防措施和规范建议    在使用Statement的批量SQL命令操作的时候，一定要注意写入到内存中命令列表的SQL语句的数量级，在小规模的数据量下，可以将所有SQL语句添加到命令列表中，一次性执行executeBatch()方法，但是在大规模数据量的情况下，就应该分批将SQL语句添加到命令列表中，并在每次调用executeBatch()方法后，调用clearBatch()方法将命令列表中的SQL语句清空，注意了，一定要记得调用clearBatch()方法清空命令列表，不然即使分批添加SQL语句，一样要“out of memory”。同时由这个问题，我们也可以引申开来考虑考虑在编写将数据保存在内存中的操作的时候，也应该注意实际系统运行环境的内存配置所能支持的数据量，千万不能不管三七二十一的将数据一股脑儿往内存里塞。","title":"如何正确的进行大规模SQL语句的批量操作"},{"content":"               1.昨天因为作为外协人员到项目组去做支持工作，项目经理要我去用ODBC连接ORACLE数据库并能导出数据库中的数据，因为以前没做过，所以从网上找了很多资料加上问别人最终搞定了，所以在这里跟大家分享一下，希望对你们有所帮助。                     ODBC与oracle的连接及使用并用Excel导出数据库数据 首先安装Oracle，以Oracle 10g为例。 一、建立服务名 1、选择“Net Configuration Assistant” ，选择“本地网络服务名配置”。 2、下一步,选择“添加”。 3、输入服务名。此为远程数据库已经定制好的数据库服务名字，比如“ORCL”,注意这里的服务名是你连接数据库的那个数据库名称。 5、下一步选择网络协议“TCP”。 6、输入主机名和端口名。比如“DB”和“1521”。 7、下一步选择是否测试。 8、下一步输入本地网络服务名，缺省跟远程一样。可以输入“myorcl”等,这里的名称是相当于起别名。 9.点击完成。   二、 配置ODBC 1、点击控制面板，进入控制面板中选择管理工具 2. 管理工具面板中点击如下图数据源(ODBC)   3.弹出下面对话框 4.选择系统DSN出现下图 5.点击添加，弹出对话框选择Microsoft ODBC for Oracle系统数据源 6.点击完成弹出   7.自己填写     1，数据源名称：mytest可随便起，客户程序将用它。 　2，描述：一段说明文字，自己能看懂即可。 　3，用户名称：mytestuser你最终需要访问的数据库所认可的用户名。     4，服务器：ABCD(即OCI设置中的服务命名。这是中文版最容易引起误解的地方。笔者开始就误以为要填写Oracle服务器的主机名) 可以这样写 8.点击确定完成,以后就可以使用ODBC进行连接ORACLE数据库了。                 EXCEL通过ODBC查询数据库 1. 打开EXCEL点击菜单\"数据\"，出现下拉条点击---》导入外部数据。出现下面图片   (本人使用的是金山的EXCEL)    2. 选择数据源选择。。。。。。。。for ODBC Drivers    3. 点击完成。  出现下图::: 4. 点击下一步出现下图 5. 选择你要导入的表名,并且选好你要导入表的字段。 选好之后点击下一步出现下图,自己去刷选要出来的数据以便于生成查询语句。 6 点击完成，也可以点击下一步进一步设置,完成数据导入。(等于不需要  用空代替)      ","title":"ODBC与ORCLE的连接及并导出数据库数据到Excel"},{"content":"  Preface Working with object-oriented software and a relational database can be cumbersome and time consuming in today's enterprise environments. NHibernate is an object/relational mapping tool for .NET environments. The term object/relational mapping (ORM) refers to the technique of mapping a data representation from an object model to a relational data model with a SQL-based schema. NHibernate not only takes care of the mapping from .NET classes to database tables (and from .NET data types to SQL data types), but also provides data query and retrieval facilities and can significantly reduce development time otherwise spent with manual data handling in SQL and ADO.NET. NHibernate's goal is to relieve the developer from 95 percent of common data persistence related programming tasks. NHibernate may not be the best solution for data-centric applications that only use stored-procedures to implement the business logic in the database, it is most useful with object-oriented domain models and business logic in the .NET-based middle-tier. However, NHibernate can certainly help you to remove or encapsulate vendor-specific SQL code and will help with the common task of result set translation from a tabular representation to a graph of objects. If you are new to NHibernate and Object/Relational Mapping or even .NET Framework, please follow these steps: Read Chapter 1, Quickstart with IIS and Microsoft SQL Server for a 30 minute tutorial, using Internet Information Services (IIS) web server. Read Chapter 2, Architecture to understand the environments where NHibernate can be used. Use this reference documentation as your primary source of information. Consider readingHibernate in Action (javahttp://www.manning.com/bauer/) orNHibernate in Action (http://www.manning.com/kuate/) orNHibernate 3.0 Cookbook (https://www.packtpub.com/nhibernate-3-0-cookbook/book) orNHibernate 2 Beginner's Guide (http://www.packtpub.com/nhibernate-2-x-beginners-guide/book)if you need more help with application design or if you prefer a step-by-step tutorial. Also visit http://nhibernate.sourceforge.net/NHibernateEg/ for NHibernate tutorial with examples. FAQs are answered on the NHibernate users group. The Community Area on the NHibernate website is a good source for design patterns and various integration solutions (ASP.NET, Windows Forms). If you have questions, use the NHibernate user forum. We also provide a JIRA issue trackings system for bug reports and feature requests. If you are interested in the development of NHibernate, join the developer mailing list. If you are interested in translating this documentation into your language, contact us on thedeveloper mailing list. Chapter 1. Quickstart with IIS and Microsoft SQL Server 1.1. Getting started with NHibernate This tutorial explains a setup of NHibernate 2.1.0 within a Microsoft environment. The tools used in this tutorial are: Microsoft Internet Information Services (IIS) - web server supporting ASP.NET. Microsoft SQL Server 2005 - the database server. This tutorial uses the desktop edition (SQL-EXPRESS), a free download from Microsoft. Support for other databases is only a matter of changing the NHibernate SQL dialect and driver configuration. Microsoft Visual Studio .NET (at leats 2005) - the development environment. First, we have to create a new Web project. We use the name QuickStart, the project web virtual directory will http://localhost/QuickStart. In the project, add a reference toNHibernate.dll. Visual Studio will automatically copy the library and its dependencies to the project output directory. If you are using a database other than SQL Server, add a reference to the driver assembly to your project. We now set up the database connection information for NHibernate. To do this, open the fileWeb.config automatically generated for your project and add configuration elements according to the listing below: \t\t\t\t<?xml version=\"1.0\" encoding=\"utf-8\" ?><configuration>    <!-- Add this element -->    <configSections>        <section            name=\"hibernate-configuration\"            type=\"NHibernate.Cfg.ConfigurationSectionHandler, NHibernate\"        />    <\/configSections>    <!-- Add this element -->    <hibernate-configuration xmlns=\"urn:nhibernate-configuration-2.2\">        <session-factory>            <property name=\"dialect\">NHibernate.Dialect.MsSql2005Dialect<\/property>            <property name=\"connection.provider\">NHibernate.Connection.DriverConnectionProvider<\/property>            <property name=\"connection.connection_string\">Server=localhost\\SQLEXPRESS;initial catalog=quickstart;Integrated Security=True<\/property>            <property name=\"proxyfactory.factory_class\">NHibernate.ByteCode.LinFu.ProxyFactoryFactory, NHibernate.ByteCode.LinFu<\/property>            <mapping assembly=\"QuickStart\" />        <\/session-factory>    <\/hibernate-configuration>    <!-- Leave the system.web section unchanged -->    <system.web>        ...    <\/system.web><\/configuration> The <configSections> element contains definitions of sections that follow and handlers to use to process their content. We declare the handler for the configuration section here. The<hibernate-configuration> section contains the configuration itself, telling NHibernate that we will use a Microsoft SQL Server 2000 database and connect to it through the specified connection string. The dialect is a required setting, databases differ in their interpretation of the SQL \"standard\". NHibernate will take care of the differences and comes bundled with dialects for several major commercial and open source databases. An ISessionFactory is NHibernate's concept of a single datastore, multiple databases can be used by creating multiple XML configuration files and creating multipleConfiguration andISessionFactory objects in your application. The last element of the <hibernate-configuration> section declaresQuickStart as the name of an assembly containing class declarations and mapping files. The mapping files contain the metadata for the mapping of the POCO class to a database table (or multiple tables). We'll come back to mapping files soon. Let's write the POCO class first and then declare the mapping metadata for it. 1.2. First persistent class NHibernate works best with the Plain Old CLR Objects (POCOs, sometimes called Plain Ordinary CLR Objects) programming model for persistent classes. A POCO has its data accessible through the standard .NET property mechanisms, shielding the internal representation from the publicly visible interface: namespace QuickStart{    public class Cat    {        private string id;        private string name;        private char   sex;        private float  weight;        public Cat()        {        }        public virtual string Id        {            get { return id; }            set { id = value; }        }        public virtual string Name        {            get { return name; }            set { name = value; }        }        public virtual char Sex        {            get { return sex; }            set { sex = value; }        }        public virtual float Weight        {            get { return weight; }            set { weight = value; }        }    }} NHibernate is not restricted in its usage of property types, all .NET types and primitives (likestring,char and DateTime) can be mapped, including classes from theSystem.Collections namespace. You can map them as values, collections of values, or associations to other entities. TheId is a special property that represents the database identifier (primary key) of that class, it is highly recommended for entities like aCat. NHibernate can use identifiers only internally, without having to declare them on the class, but we would lose some of the flexibility in our application architecture. No special interface has to be implemented for persistent classes nor do we have to subclass from a special root persistent class. NHibernate also doesn't use any build time processing, such as IL manipulation, it relies solely on .NET reflection and runtime class enhancement (through Castle.DynamicProxy library). So, without any dependency in the POCO class on NHibernate, we can map it to a database table. For the above mentioned runtime class enhancement to work, NHibernate requires that all public properties of an entity class are declared asvirtual. 1.3. Mapping the cat The Cat.hbm.xml mapping file contains the metadata required for the object/relational mapping. The metadata includes declaration of persistent classes and the mapping of properties (to columns and foreign key relationships to other entities) to database tables. Please note that the Cat.hbm.xml should be set to an embedded resource. <?xml version=\"1.0\" encoding=\"utf-8\" ?><hibernate-mapping xmlns=\"urn:nhibernate-mapping-2.2\"    namespace=\"QuickStart\" assembly=\"QuickStart\">    <class name=\"Cat\" table=\"Cat\">        <!-- A 32 hex character is our surrogate key. It's automatically            generated by NHibernate with the UUID pattern. -->        <id name=\"Id\">            <column name=\"CatId\" sql-type=\"char(32)\" not-null=\"true\"/>            <generator class=\"uuid.hex\" />        <\/id>        <!-- A cat has to have a name, but it shouldn' be too long. -->        <property name=\"Name\">            <column name=\"Name\" length=\"16\" not-null=\"true\" />        <\/property>        <property name=\"Sex\" />        <property name=\"Weight\" />    <\/class><\/hibernate-mapping> Every persistent class should have an identifer attribute (actually, only classes representing entities, not dependent value objects, which are mapped as components of an entity). This property is used to distinguish persistent objects: Two cats are equal if catA.Id.Equals(catB.Id) is true, this concept is calleddatabase identity. NHibernate comes bundled with various identifer generators for different scenarios (including native generators for database sequences, hi/lo identifier tables, and application assigned identifiers). We use the UUID generator (only recommended for testing, as integer surrogate keys generated by the database should be prefered) and also specify the columnCatId of the table Cat for the NHibernate generated identifier value (as a primary key of the table). All other properties of Cat are mapped to the same table. In the case of theName property, we mapped it with an explicit database column declaration. This is especially useful when the database schema is automatically generated (as SQL DDL statements) from the mapping declaration with NHibernate'sSchemaExport tool. All other properties are mapped using NHibernate's default settings, which is what you need most of the time. The tableCat in the database looks like this:  Column |     Type     | Modifiers--------+--------------+---------------------- CatId  | char(32)     | not null, primary key Name   | nvarchar(16) | not null Sex    | nchar(1)     | Weight | real         | You should now create the database and this table manually, and later read Chapter 20, Toolset Guide if you want to automate this step with the SchemaExport tool. This tool can create a full SQL DDL, including table definition, custom column type constraints, unique constraints and indexes. If you are using SQL Server, you should also make sure the ASPNET user has permissions to use the database. 1.4. Playing with cats We're now ready to start NHibernate's ISession. It is thepersistence manager interface, we use it to store and retrieveCats to and from the database. But first, we've to get anISession (NHibernate's unit-of-work) from the ISessionFactory: ISessionFactory sessionFactory =            new Configuration().Configure().BuildSessionFactory(); An ISessionFactory is responsible for one database and may only use one XML configuration file (Web.config orhibernate.cfg.xml). You can set other properties (and even change the mapping metadata) by accessing theConfiguration before you build theISessionFactory (it is immutable). Where do we create theISessionFactory and how can we access it in our application? An ISessionFactory is usually only built once, e.g. at startup insideApplication_Start event handler. This also means you should not keep it in an instance variable in your ASP.NET pages, but in some other location. Furthermore, we need some kind ofSingleton, so we can access theISessionFactory easily in application code. The approach shown next solves both problems: configuration and easy access to aISessionFactory. We implement a NHibernateHelper helper class: using System;using System.Web;using NHibernate;using NHibernate.Cfg;namespace QuickStart{    public sealed class NHibernateHelper    {        private const string CurrentSessionKey = \"nhibernate.current_session\";        private static readonly ISessionFactory sessionFactory;        static NHibernateHelper()        {            sessionFactory = new Configuration().Configure().BuildSessionFactory();        }        public static ISession GetCurrentSession()        {            HttpContext context = HttpContext.Current;            ISession currentSession = context.Items[CurrentSessionKey] as ISession;            if (currentSession == null)            {                currentSession = sessionFactory.OpenSession();                context.Items[CurrentSessionKey] = currentSession;            }            return currentSession;        }        public static void CloseSession()        {            HttpContext context = HttpContext.Current;            ISession currentSession = context.Items[CurrentSessionKey] as ISession;            if (currentSession == null)            {                // No current session                return;            }            currentSession.Close();            context.Items.Remove(CurrentSessionKey);        }        public static void CloseSessionFactory()        {            if (sessionFactory != null)            {                sessionFactory.Close();            }        }    }} This class does not only take care of the ISessionFactory with its static attribute, but also has code to remember theISession for the current HTTP request. An ISessionFactory is threadsafe, many threads can access it concurrently and requestISessions. AnISession is a non-threadsafe object that represents a single unit-of-work with the database.ISessions are opened by anISessionFactory and are closed when all work is completed: ISession session = NHibernateHelper.GetCurrentSession();ITransaction tx = session.BeginTransaction();Cat princess = new Cat();princess.Name = \"Princess\";princess.Sex = 'F';princess.Weight = 7.4f;session.Save(princess);tx.Commit();NHibernateHelper.CloseSession(); In an ISession, every database operation occurs inside a transaction that isolates the database operations (even read-only operations). We use NHibernate'sITransaction API to abstract from the underlying transaction strategy (in our case, ADO.NET transactions). Please note that the example above does not handle any exceptions. Also note that you may call NHibernateHelper.GetCurrentSession(); as many times as you like, you will always get the currentISession of this HTTP request. You have to make sure theISession is closed after your unit-of-work completes, either inApplication_EndRequest event handler in your application class or in aHttpModule before the HTTP response is sent. The nice side effect of the latter is easy lazy initialization: theISession is still open when the view is rendered, so NHibernate can load unitialized objects while you navigate the graph. NHibernate has various methods that can be used to retrieve objects from the database. The most flexible way is using the Hibernate Query Language (HQL), which is an easy to learn and powerful object-oriented extension to SQL: ITransaction tx = session.BeginTransaction();IQuery query = session.CreateQuery(\"select c from Cat as c where c.Sex = :sex\");query.SetCharacter(\"sex\", 'F');foreach (Cat cat in query.Enumerable()){    Console.Out.WriteLine(\"Female Cat: \" + cat.Name);}tx.Commit(); NHibernate also offers an object-oriented query by criteria API that can be used to formulate type-safe queries. NHibernate of course usesIDbCommands and parameter binding for all SQL communication with the database. You may also use NHibernate's direct SQL query feature or get a plain ADO.NET connection from anISession in rare cases. 1.5. Finally We only scratched the surface of NHibernate in this small tutorial. Please note that we don't include any ASP.NET specific code in our examples. You have to create an ASP.NET page yourself and insert the NHibernate code as you see fit. Keep in mind that NHibernate, as a data access layer, is tightly integrated into your application. Usually, all other layers depend on the persistence mechanism. Make sure you understand the implications of this design. Chapter 2. Architecture 2.1. Overview A (very) high-level view of the NHibernate architecture: This diagram shows NHibernate using the database and configuration data to provide persistence services (and persistent objects) to the application. We would like to show a more detailed view of the runtime architecture. Unfortunately, NHibernate is flexible and supports several approaches. We will show the two extremes. The \"lite\" architecture has the application provide its own ADO.NET connections and manage its own transactions. This approach uses a minimal subset of NHibernate's APIs: The \"full cream\" architecture abstracts the application away from the underlying ADO.NET APIs and lets NHibernate take care of the details. Heres some definitions of the objects in the diagrams: ISessionFactory (NHibernate.ISessionFactory) A threadsafe (immutable) cache of compiled mappings for a single database. A factory forISession and a client ofIConnectionProvider. Might hold an optional (second-level) cache of data that is reusable between transactions, at a process- or cluster-level. ISession (NHibernate.ISession) A single-threaded, short-lived object representing a conversation between the application and the persistent store. Wraps an ADO.NET connection. Factory forITransaction. Holds a mandatory (first-level) cache of persistent objects, used when navigating the object graph or looking up objects by identifier. Persistent Objects and Collections Short-lived, single threaded objects containing persistent state and business function. These might be ordinary POCOs, the only special thing about them is that they are currently associated with (exactly one)ISession. As soon as the Session is closed, they will be detached and free to use in any application layer (e.g. directly as data transfer objects to and from presentation). Transient Objects and Collections Instances of persistent classes that are not currently associated with a ISession. They may have been instantiated by the application and not (yet) persisted or they may have been instantiated by a closedISession. ITransaction (NHibernate.ITransaction) (Optional) A single-threaded, short-lived object used by the application to specify atomic units of work. Abstracts application from underlying ADO.NET transaction. AnISession might span severalITransactions in some cases. IConnectionProvider (NHibernate.Connection.IConnectionProvider) (Optional) A factory for ADO.NET connections and commands. Abstracts application from the concrete vendor-specific implementations ofIDbConnection andIDbCommand. Not exposed to application, but can be extended/implemented by the developer. IDriver (NHibernate.Driver.IDriver) (Optional) An interface encapsulating differences between ADO.NET providers, such as parameter naming conventions and supported ADO.NET features. ITransactionFactory (NHibernate.Transaction.ITransactionFactory) (Optional) A factory for ITransaction instances. Not exposed to the application, but can be extended/implemented by the developer. Given a \"lite\" architecture, the application bypasses the ITransaction/ITransactionFactory and/or IConnectionProvider APIs to talk to ADO.NET directly. 2.2. Instance states An instance of a persistent classes may be in one of three different states, which are defined with respect to apersistence context. The NHibernateISession object is the persistence context: transient The instance is not, and has never been associated with any persistence context. It has no persistent identity (primary key value). persistent The instance is currently associated with a persistence context. It has a persistent identity (primary key value) and, perhaps, a corresponding row in the database. For a particular persistence context, NHibernateguarantees that persistent identity is equivalent to CLR identity (in-memory location of the object). detached The instance was once associated with a persistence context, but that context was closed, or the instance was serialized to another process. It has a persistent identity and, perhaps, a corrsponding row in the database. For detached instances, NHibernate makes no guarantees about the relationship between persistent identity and CLR identity. 2.3. Contextual Sessions Most applications using NHibernate need some form of \"contextual\" sessions, where a given session is in effect throughout the scope of a given context. However, across applications the definition of what constitutes a context is typically different; and different contexts define different scopes to the notion of current. Starting with version 1.2, NHibernate added the ISessionFactory.GetCurrentSession() method. The processing behindISessionFactory.GetCurrentSession() is pluggable. An extension interface (NHibernate.Context.ICurrentSessionContext) and a new configuration parameter (hibernate.current_session_context_class) have been added to allow pluggability of the scope and context of defining current sessions. See the API documentation for the NHibernate.Context.ICurrentSessionContext interface for a detailed discussion of its contract. It defines a single method,CurrentSession(), by which the implementation is responsible for tracking the current contextual session. Out-of-the-box, NHibernate comes with several implementations of this interface: NHibernate.Context.ManagedWebSessionContext - current sessions are tracked byHttpContext. However, you are responsible to bind and unbind anISession instance with static methods on this class, it never opens, flushes, or closes anISession itself. NHibernate.Context.CallSessionContext - current sessions are tracked byCallContext. You are responsible to bind and unbind anISession instance with static methods of class CurrentSessionContext. NHibernate.Context.ThreadStaticSessionContext - current session is stored in a thread-static variable. This context only supports one session factory. You are responsible to bind and unbind anISession instance with static methods of class CurrentSessionContext. NHibernate.Context.WebSessionContext - analogous to ManagedWebSessionContext above, stores the current session in HttpContext. You are responsible to bind and unbind an ISessioninstance with static methods of classCurrentSessionContext. NHibernate.Context.WcfOperationSessionContext - current sessions are tracked by WCFOperationContext. You need to register theWcfStateExtension extension in WCF. You are responsible to bind and unbind anISessioninstance with static methods of class CurrentSessionContext. The hibernate.current_session_context_class configuration parameter defines whichNHibernate.Context.ICurrentSessionContext implementation should be used. Typically, the value of this parameter would just name the implementation class to use (including the assembly name); for the out-of-the-box implementations, however, there are corresponding short names: \"managed_web\", \"call\", \"thread_static\", \"web\" and \"wcf_operation\", respectively. Chapter 3. ISessionFactory Configuration Because NHibernate is designed to operate in many different environments, there are a large number of configuration parameters. Fortunately, most have sensible default values and NHibernate is distributed with an exampleApp.config file (found in src\\NHibernate.Test) that shows the various options. You usually only have to put that file in your project and customize it. 3.1. Programmatic Configuration An instance of NHibernate.Cfg.Configuration represents an entire set of mappings of an application's .NET types to a SQL database. TheConfiguration is used to build an (immutable)ISessionFactory. The mappings are compiled from various XML mapping files. You may obtain a Configuration instance by instantiating it directly. Heres an example of setting up a datastore from mappings defined in two XML configuration files: Configuration cfg = new Configuration()    .AddFile(\"Item.hbm.xml\")    .AddFile(\"Bid.hbm.xml\"); An alternative (sometimes better) way is to let NHibernate load a mapping file from an embedded resource: Configuration cfg = new Configuration()    .AddClass(typeof(NHibernate.Auction.Item))    .AddClass(typeof(NHibernate.Auction.Bid)); Then NHibernate will look for mapping files named NHibernate.Auction.Item.hbm.xml andNHibernate.Auction.Bid.hbm.xml embedded as resources in the assembly that the types are contained in. This approach eliminates any hardcoded filenames. Another alternative (probably the best) way is to let NHibernate load all of the mapping files contained in an Assembly: Configuration cfg = new Configuration()    .AddAssembly( \"NHibernate.Auction\" ); Then NHibernate will look through the assembly for any resources that end with.hbm.xml. This approach eliminates any hardcoded filenames and ensures the mapping files in the assembly get added. If a tool like Visual Studio .NET or NAnt is used to build the assembly, then make sure that the.hbm.xml files are compiled into the assembly asEmbedded Resources. A Configuration also specifies various optional properties: IDictionary props = new Hashtable();...Configuration cfg = new Configuration()    .AddClass(typeof(NHibernate.Auction.Item))    .AddClass(typeof(NHibernate.Auction.Bind))    .SetProperties(props); A Configuration is intended as a configuration-time object, to be discarded once anISessionFactory is built. 3.2. Obtaining an ISessionFactory When all mappings have been parsed by the Configuration, the application must obtain a factory forISession instances. This factory is intended to be shared by all application threads: ISessionFactory sessions = cfg.BuildSessionFactory(); However, NHibernate does allow your application to instantiate more than one ISessionFactory. This is useful if you are using more than one database. 3.3. User provided ADO.NET connection An ISessionFactory may open an ISession on a user-provided ADO.NET connection. This design choice frees the application to obtain ADO.NET connections wherever it pleases: IDbConnection conn = myApp.GetOpenConnection();ISession session = sessions.OpenSession(conn);// do some data access work The application must be careful not to open two concurrent ISessions on the same ADO.NET connection! 3.4. NHibernate provided ADO.NET connection Alternatively, you can have the ISessionFactory open connections for you. TheISessionFactory must be provided with ADO.NET connection properties in one of the following ways: Pass an instance of IDictionary mapping property names to property values toConfiguration.SetProperties(). Add the properties to a configuration section in the application configuration file. The section should be namednhibernate and its handler set toSystem.Configuration.NameValueSectionHandler. Include <property> elements in a configuration section in the application configuration file. The section should be namedhibernate-configuration and its handler set toNHibernate.Cfg.ConfigurationSectionHandler. The XML namespace of the section should be set tourn:nhibernate-configuration-2.2. Include <property> elements in hibernate.cfg.xml (discussed later). If you take this approach, opening an ISession is as simple as: ISession session = sessions.OpenSession(); // open a new Session// do some data access work, an ADO.NET connection will be used on demand All NHibernate property names and semantics are defined on the class NHibernate.Cfg.Environment. We will now describe the most important settings for ADO.NET connection configuration. NHibernate will obtain (and pool) connections using an ADO.NET data provider if you set the following properties: Table 3.1. NHibernate ADO.NET Properties Property name Purpose connection.provider_class The type of a custom IConnectionProvider. eg. full.classname.of.ConnectionProvider if the Provider is built into NHibernate, orfull.classname.of.ConnectionProvider, assembly if using an implementation ofIConnectionProvider not included in NHibernate. connection.driver_class The type of a custom IDriver, if using DriverConnectionProvider. full.classname.of.Driver if the Driver is built into NHibernate, orfull.classname.of.Driver, assembly if using an implementation of IDriver not included in NHibernate. This is usually not needed, most of the time the dialect will take care of setting theIDriver using a sensible default. See the API documentation of the specific dialect for the defaults. connection.connection_string Connection string to use to obtain the connection. connection.connection_string_name The name of the connection string (defined in <connectionStrings> configuration file element) to use to obtain the connection. connection.isolation Set the ADO.NET transaction isolation level. Check System.Data.IsolationLevel for meaningful values and the database's documentation to ensure that level is supported. eg. Chaos, ReadCommitted, ReadUncommitted, RepeatableRead, Serializable, Unspecified connection.release_mode Specify when NHibernate should release ADO.NET connections. See Section 11.7, “Connection Release Modes”. eg. auto (default) | on_close | after_transaction Note that this setting only affects ISessions returned fromISessionFactory.OpenSession. ForISessions obtained throughISessionFactory.GetCurrentSession, theICurrentSessionContext implementation configured for use controls the connection release mode for thoseISessions. SeeSection 2.3, “Contextual Sessions”. command_timeout Specify the default timeout of IDbCommands generated by NHibernate. adonet.batch_size Specify the batch size to use when batching update statements. Setting this to 0 (the default) disables the functionality. SeeSection 19.6, “Batch updates”. This is an example of how to specify the database connection properties inside aweb.config: <?xml version=\"1.0\" encoding=\"utf-8\" ?><configuration>\t<configSections>\t\t<section name=\"hibernate-configuration\"\t\t\t\t type=\"NHibernate.Cfg.ConfigurationSectionHandler, NHibernate\" />\t<\/configSections>\t<hibernate-configuration xmlns=\"urn:nhibernate-configuration-2.2\">\t\t<session-factory>\t\t\t<property name=\"dialect\">NHibernate.Dialect.MsSql2005Dialect<\/property>\t\t\t<property name=\"connection.connection_string\">\t\t\t\tServer=(local);initial catalog=theDb;Integrated Security=SSPI\t\t\t<\/property>\t\t\t<property name=\"connection.isolation\">ReadCommitted<\/property>\t\t\t<property name=\"proxyfactory.factory_class\">\t\t\t\tNHibernate.ByteCode.LinFu.ProxyFactoryFactory, NHibernate.ByteCode.LinFu\t\t\t<\/property>\t\t<\/session-factory>\t<\/hibernate-configuration>    <!-- other app specific config follows --><\/configuration> NHibernate relies on the ADO.NET data provider implementation of connection pooling. You may define your own plugin strategy for obtaining ADO.NET connections by implementing the interfaceNHibernate.Connection.IConnectionProvider. You may select a custom implementation by settingconnection.provider_class. 3.5. Optional configuration properties There are a number of other properties that control the behaviour of NHibernate at runtime. All are optional and have reasonable default values. System-level properties can only be set manually by setting static properties ofNHibernate.Cfg.Environment class or be defined in the<nhibernate> section of the application configuration file. These properties cannot be set usingConfiguration.SetProperties or be defined in the<hibernate-configuration> section of the application configuration file. Table 3.2. NHibernate Configuration Properties Property name Purpose dialect The classname of a NHibernate Dialect - enables certain platform dependent features. eg. full.classname.of.Dialect, assembly default_schema Qualify unqualified tablenames with the given schema/tablespace in generated SQL. eg. SCHEMA_NAME max_fetch_depth Set a maximum \"depth\" for the outer join fetch tree for single-ended associations (one-to-one, many-to-one). A0 disables default outer join fetching. eg. recommended values between 0 and 3 use_reflection_optimizer Enables use of a runtime-generated class to set or get properties of an entity or component instead of using runtime reflection (System-level property). The use of the reflection optimizer inflicts a certain startup cost on the application but should lead to better performance in the long run. You can not set this property in hibernate.cfg.xml or <hibernate-configuration> section of the application configuration file. eg. true | false bytecode.provider Specifies the bytecode provider to use to optimize the use of reflection in NHibernate. Usenull to disable the optimization completely,lcg to use lightweight code generation. eg. null | lcg cache.provider_class The classname of a custom ICacheProvider. eg. classname.of.CacheProvider, assembly cache.use_minimal_puts Optimize second-level cache operation to minimize writes, at the cost of more frequent reads (useful for clustered caches). eg. true | false cache.use_query_cache Enable the query cache, individual queries still have to be set cacheable. eg. true | false cache.query_cache_factory The classname of a custom IQueryCacheFactory interface, defaults to the built-inStandardQueryCacheFactory. eg. classname.of.QueryCacheFactory, assembly cache.region_prefix A prefix to use for second-level cache region names. eg. prefix query.substitutions Mapping from tokens in NHibernate queries to SQL tokens (tokens might be function or literal names, for example). eg. hqlLiteral=SQL_LITERAL, hqlFunction=SQLFUNC show_sql Write all SQL statements to console. eg. true | false hbm2ddl.auto Automatically export schema DDL to the database when the ISessionFactory is created. With create-drop, the database schema will be dropped when theISessionFactory is closed explicitly. eg. create | create-drop hbm2ddl.keywords Automatically import reserved/keywords from the database when theISessionFactory is created. none : disable any operation regarding RDBMS KeyWords keywords : imports all RDBMS KeyWords where the Dialect can provide the implementation of IDataBaseSchema. auto-quote : imports all RDBMS KeyWords and auto-quote all table-names/column-names . eg. none | keywords | auto-quote use_proxy_validator Enables or disables validation of interfaces or classes specified as proxies. Enabled by default. eg. true | false transaction.factory_class The classname of a custom ITransactionFactory implementation, defaults to the built-inAdoNetWithDistributedTransactionFactory. eg. classname.of.TransactionFactory, assembly 3.5.1. SQL Dialects You should always set the dialect property to the correctNHibernate.Dialect.Dialect subclass for your database. This is not strictly essential unless you wish to usenative orsequence primary key generation or pessimistic locking (with, eg.ISession.Lock() orIQuery.SetLockMode()). However, if you specify a dialect, NHibernate will use sensible defaults for some of the other properties listed above, saving you the effort of specifying them manually. Table 3.3. NHibernate SQL Dialects (dialect) RDBMS Dialect Remarks DB2 NHibernate.Dialect.DB2Dialect   DB2 for iSeries (OS/400) NHibernate.Dialect.DB2400Dialect   Ingres NHibernate.Dialect.IngresDialect   PostgreSQL NHibernate.Dialect.PostgreSQLDialect   PostgreSQL 8.1 NHibernate.Dialect.PostgreSQL81Dialect This dialect supports FOR UPDATE NOWAIT available in PostgreSQL 8.1. PostgreSQL 8.2 NHibernate.Dialect.PostgreSQL82Dialect This dialect supports IF EXISTS keyword in DROP TABLE and DROP SEQUENCE available in PostgreSQL 8.2. MySQL 3 or 4 NHibernate.Dialect.MySQLDialect   MySQL 5 NHibernate.Dialect.MySQL5Dialect   Oracle NHibernate.Dialect.Oracle8iDialect   Oracle 9 NHibernate.Dialect.Oracle9iDialect   Oracle 10g NHibernate.Dialect.Oracle10gDialect   Sybase Adaptive Server Enterprise 15 NHibernate.Dialect.SybaseASE15Dialect   Sybase Adaptive Server Anywhere 9 NHibernate.Dialect.SybaseASA9Dialect   Sybase Adaptive Server Anywhere 10 NHibernate.Dialect.SybaseASA10Dialect Deprecated. Use the Sybase SQL Anywhere 10 Dialect instead. Sybase SQL Anywhere 10 NHibernate.Dialect.SybaseSQLAnywhere10Dialect   Sybase SQL Anywhere 11 NHibernate.Dialect.SybaseSQLAnywhere11Dialect   Microsoft SQL Server 7 NHibernate.Dialect.MsSql7Dialect   Microsoft SQL Server 2000 NHibernate.Dialect.MsSql2000Dialect   Microsoft SQL Server 2005 NHibernate.Dialect.MsSql2005Dialect   Microsoft SQL Server 2008 NHibernate.Dialect.MsSql2008Dialect   Microsoft SQL Server Compact Edition NHibernate.Dialect.MsSqlCeDialect   Firebird NHibernate.Dialect.FirebirdDialect Set driver_class to NHibernate.Driver.FirebirdClientDriver for Firebird ADO.NET provider 2.0. SQLite NHibernate.Dialect.SQLiteDialect Set driver_class to NHibernate.Driver.SQLite20Driver for System.Data.SQLite provider for .NET 2.0. Additional dialects may be available in the NHibernate.Dialect namespace. 3.5.2. Outer Join Fetching If your database supports ANSI or Oracle style outer joins, outer join fetching might increase performance by limiting the number of round trips to and from the database (at the cost of possibly more work performed by the database itself). Outer join fetching allows a graph of objects connected by many-to-one, one-to-many or one-to-one associations to be retrieved in a single SQL SELECT. By default, the fetched graph when loading an objects ends at leaf objects, collections, objects with proxies, or where circularities occur. For a particular association, fetching may be configured (and the default behaviour overridden) by setting thefetch attribute in the XML mapping. Outer join fetching may be disabled globally by setting the propertymax_fetch_depth to0. A setting of1 or higher enables outer join fetching for one-to-one and many-to-one associations which have been mapped withfetch=\"join\". See Section 19.1, “Fetching strategies” for more information. In NHibernate 1.0, outer-join attribute could be used to achieve a similar effect. This attribute is now deprecated in favor offetch. 3.5.3. CustomICacheProvider You may integrate a process-level (or clustered) second-level cache system by implementing the interfaceNHibernate.Cache.ICacheProvider. You may select the custom implementation by settingcache.provider_class. See the Section 19.2, “The Second Level Cache” for more details. 3.5.4. Query Language Substitution You may define new NHibernate query tokens using query.substitutions. For example: query.substitutions true=1, false=0 would cause the tokens true and false to be translated to integer literals in the generated SQL. query.substitutions toLowercase=LOWER would allow you to rename the SQL LOWER function. 3.6. Logging NHibernate logs various events using Apache log4net. You may download log4net from http://logging.apache.org/log4net/. To use log4net you will need alog4net configuration section in the application configuration file. An example of the configuration section is distributed with NHibernate in thesrc/NHibernate.Test project. We strongly recommend that you familiarize yourself with NHibernate's log messages. A lot of work has been put into making the NHibernate log as detailed as possible, without making it unreadable. It is an essential troubleshooting device. Also don't forget to enable SQL logging as described above (show_sql), it is your first step when looking for performance problems. 3.7. Implementing anINamingStrategy The interface NHibernate.Cfg.INamingStrategy allows you to specify a \"naming standard\" for database objects and schema elements. You may provide rules for automatically generating database identifiers from .NET identifiers or for processing \"logical\" column and table names given in the mapping file into \"physical\" table and column names. This feature helps reduce the verbosity of the mapping document, eliminating repetitive noise (TBL_ prefixes, for example). The default strategy used by NHibernate is quite minimal. You may specify a different strategy by calling Configuration.SetNamingStrategy() before adding mappings: ISessionFactory sf = new Configuration()    .SetNamingStrategy(ImprovedNamingStrategy.Instance)    .AddFile(\"Item.hbm.xml\")    .AddFile(\"Bid.hbm.xml\")    .BuildSessionFactory(); NHibernate.Cfg.ImprovedNamingStrategy is a built-in strategy that might be a useful starting point for some applications. 3.8. XML Configuration File An alternative approach is to specify a full configuration in a file named hibernate.cfg.xml. This file can be used as a replacement for the <nhibernate;> or <hibernate-configuration> sections of the application configuration file. The XML configuration file is by default expected to be in your application directory. Here is an example: <?xml version='1.0' encoding='utf-8'?><hibernate-configuration xmlns=\"urn:nhibernate-configuration-2.2\">    <!-- an ISessionFactory instance -->    <session-factory>        <!-- properties -->        <property name=\"connection.provider\">NHibernate.Connection.DriverConnectionProvider<\/property>        <property name=\"connection.driver_class\">NHibernate.Driver.SqlClientDriver<\/property>        <property name=\"connection.connection_string\">Server=localhost;initial catalog=nhibernate;User Id=;Password=<\/property>        <property name=\"show_sql\">false<\/property>        <property name=\"dialect\">NHibernate.Dialect.MsSql2000Dialect<\/property>        <!-- mapping files -->        <mapping resource=\"NHibernate.Auction.Item.hbm.xml\" assembly=\"NHibernate.Auction\" />        <mapping resource=\"NHibernate.Auction.Bid.hbm.xml\" assembly=\"NHibernate.Auction\" />    <\/session-factory><\/hibernate-configuration> Configuring NHibernate is then as simple as ISessionFactory sf = new Configuration().Configure().BuildSessionFactory(); You can pick a different XML configuration file using ISessionFactory sf = new Configuration()    .Configure(\"/path/to/config.cfg.xml\")    .BuildSessionFactory(); Chapter 4. Persistent Classes Persistent classes are classes in an application that implement the entities of the business problem (e.g. Customer and Order in an E-commerce application). Persistent classes have, as the name implies, transient and also persistent instance stored in the database. NHibernate works best if these classes follow some simple rules, also known as the Plain Old CLR Object (POCO) programming model. 4.1. A simple POCO example Most .NET applications require a persistent class representing felines. using System;using Iesi.Collections;namespace Eg{    public class Cat    {        long id; // identifier            public virtual long Id        {            get { return id; }            protected set { id = value; }        }        public virtual string Name { get; set; }         public virtual Cat Mate { get; set; }         public virtual DateTime Birthdate { get; set; }         public virtual float Weight { get; set; }         public virtual Color Color { get; set; }         public virtual ISet Kittens { get; set; }         public virtual char Sex { get; set; }         // AddKitten not needed by NHibernate        public virtual void AddKitten(Cat kitten)        {            kittens.Add(kitten);        }    }} There are four main rules to follow here: 4.1.1. Declare properties for persistent fields Cat declares properties for all the persistent fields. Many other ORM tools directly persist instance variables. We believe it is far better to decouple this implementation detail from the persistence mechanism. NHibernate persists properties, using their getter and setter methods. Properties need not be declared public - NHibernate can persist a property with aninternal,protected, protected internal orprivate visibility. As shown in the example, both automatic properties and properties with a backing field are supported. 4.1.2. Implement a default constructor Cat has an implicit default (no-argument) constructor. All persistent classes must have a default constructor (which may be non-public) so NHibernate can instantiate them usingActivator.CreateInstance(). 4.1.3. Provide an identifier property (optional) Cat has a property called Id. This property holds the primary key column of a database table. The property might have been called anything, and its type might have been any primitive type,string or System.DateTime. (If your legacy database table has composite keys, you can even use a user-defined class with properties of these types - see the section on composite identifiers below.) The identifier property is optional. You can leave it off and let NHibernate keep track of object identifiers internally. However, for many applications it is still a good (and very popular) design decision. What's more, some functionality is available only to classes which declare an identifier property: Cascaded updates (see \"Lifecycle Objects\") ISession.SaveOrUpdate() We recommend you declare consistently-named identifier properties on persistent classes. 4.1.4. Prefer non-sealed classes and virtual methods (optional) A central feature of NHibernate, proxies, depends upon the persistent class being non-sealed and all its public methods, properties and events declared as virtual. Another possibility is for the class to implement an interface that declares all public members. You can persist sealed classes that do not implement an interface and don't have virtual members with NHibernate, but you won't be able to use proxies - which will limit your options for performance tuning. 4.2. Implementing inheritance A subclass must also observe the first and second rules. It inherits its identifier property fromCat. using System;namespace Eg{    public class DomesticCat : Cat    {        public virtual string Name { get; set; }    }} 4.3. ImplementingEquals() andGetHashCode() You have to override the Equals() and GetHashCode() methods if you intend to mix objects of persistent classes (e.g. in anISet). This only applies if these objects are loaded in two differentISessions, as NHibernate only guarantees identity ( a == b, the default implementation ofEquals()) inside a singleISession! Even if both objects a and b are the same database row (they have the same primary key value as their identifier), we can't guarantee that they are the same object instance outside of a particularISession context. The most obvious way is to implement Equals()/GetHashCode() by comparing the identifier value of both objects. If the value is the same, both must be the same database row, they are therefore equal (if both are added to an ISet, we will only have one element in theISet). Unfortunately, we can't use that approach. NHibernate will only assign identifier values to objects that are persistent, a newly created instance will not have any identifier value! We recommend implementingEquals() andGetHashCode() usingBusiness key equality. Business key equality means that the Equals() method compares only the properties that form the business key, a key that would identify our instance in the real world (anatural candidate key): public class Cat{    ...    public override bool Equals(object other)    {        if (this == other) return true;                Cat cat = other as Cat;        if (cat == null) return false; // null or not a cat        if (Name != cat.Name) return false;        if (!Birthday.Equals(cat.Birthday)) return false;        return true;    }    public override int GetHashCode()    {        unchecked        {            int result;            result = Name.GetHashCode();            result = 29 * result + Birthday.GetHashCode();            return result;        }    }} Keep in mind that our candidate key (in this case a composite of name and birthday) has to be only valid for a particular comparison operation (maybe even only in a single use case). We don't need the stability criteria we usually apply to a real primary key! 4.4. Dynamic models Note that the following features are currently considered experimental and may change in the near future. Persistent entities don't necessarily have to be represented as POCO classes at runtime. NHibernate also supports dynamic models (usingDictionaries ofDictionarys at runtime) . With this approach, you don't write persistent classes, only mapping files. By default, NHibernate works in normal POCO mode. You may set a default entity representation mode for a particularISessionFactory using thedefault_entity_mode configuration option (seeTable 3.2, “NHibernate Configuration Properties”. The following examples demonstrates the representation using Maps (Dictionary). First, in the mapping file, an entity-name has to be declared instead of (or in addition to) a class name: <hibernate-mapping>    <class entity-name=\"Customer\">        <id name=\"id\"            type=\"long\"            column=\"ID\">            <generator class=\"sequence\"/>        <\/id>        <property name=\"name\"            column=\"NAME\"            type=\"string\"/>        <property name=\"address\"            column=\"ADDRESS\"            type=\"string\"/>        <many-to-one name=\"organization\"            column=\"ORGANIZATION_ID\"            class=\"Organization\"/>        <bag name=\"orders\"            inverse=\"true\"            lazy=\"false\"            cascade=\"all\">            <key column=\"CUSTOMER_ID\"/>            <one-to-many class=\"Order\"/>        <\/bag>    <\/class>    <\/hibernate-mapping> Note that even though associations are declared using target class names, the target type of an associations may also be a dynamic entity instead of a POCO. After setting the default entity mode to dynamic-map for theISessionFactory, we can at runtime work withDictionaries of Dictionaries: using(ISession s = OpenSession())using(ITransaction tx = s.BeginTransaction()){    // Create a customer    var frank = new Dictionary<string, object>();    frank[\"name\"] = \"Frank\";    // Create an organization    var foobar = new Dictionary<string, object>();    foobar[\"name\"] = \"Foobar Inc.\";    // Link both    frank[\"organization\"] =  foobar;    // Save both    s.Save(\"Customer\", frank);    s.Save(\"Organization\", foobar);    tx.Commit();} The advantages of a dynamic mapping are quick turnaround time for prototyping without the need for entity class implementation. However, you lose compile-time type checking and will very likely deal with many exceptions at runtime. Thanks to the NHibernate mapping, the database schema can easily be normalized and sound, allowing to add a proper domain model implementation on top later on. Entity representation modes can also be set on a per ISession basis: using (ISession dynamicSession = pocoSession.GetSession(EntityMode.Map)){    // Create a customer    var frank = new Dictionary<string, object>();    frank[\"name\"] = \"Frank\";    dynamicSession.Save(\"Customer\", frank);    ...}// Continue on pocoSession Please note that the call to GetSession() using an EntityMode is on the ISession API, not the ISessionFactory. That way, the new ISession shares the underlying ADO connection, transaction, and other context information. This means you don't have tocallFlush() andClose() on the secondaryISession, and also leave the transaction and connection handling to the primary unit of work. 4.5. Tuplizers NHibernate.Tuple.Tuplizer, and its sub-interfaces, are responsible for managing a particular representation of a piece of data, given that representation'sNHibernate.EntityMode. If a given piece of data is thought of as a data structure, then a tuplizer is the thing which knows how to create such a data structure and how to extract values from and inject values into such a data structure. For example, for the POCO entity mode, the correpsonding tuplizer knows how create the POCO through its constructor and how to access the POCO properties using the defined property accessors. There are two high-level types of Tuplizers, represented by theNHibernate.Tuple.Entity.IEntityTuplizer andNHibernate.Tuple.Component.IComponentTuplizer interfaces.IEntityTuplizers are responsible for managing the above mentioned contracts in regards to entities, whileIComponentTuplizers do the same for components. Users may also plug in their own tuplizers. Perhaps you require that a System.Collections.IDictionary implementation other than System.Collections.Hashtable be used while in the dynamic-map entity-mode; or perhaps you need to define a different proxy generation strategy than the one used by default. Both would be achieved by defining a custom tuplizer implementation. Tuplizers definitions are attached to the entity or component mapping they are meant to manage. Going back to the example of our customer entity: <hibernate-mapping>    <class entity-name=\"Customer\">        <!--            Override the dynamic-map entity-mode            tuplizer for the customer entity        -->        <tuplizer entity-mode=\"dynamic-map\"                class=\"CustomMapTuplizerImpl\"/>        <id name=\"id\" type=\"long\" column=\"ID\">            <generator class=\"sequence\"/>        <\/id>        <!-- other properties -->        ...    <\/class><\/hibernate-mapping>public class CustomMapTuplizerImpl : NHibernate.Tuple.Entity.DynamicMapEntityTuplizer{    // override the BuildInstantiator() method to plug in our custom map...    protected override IInstantiator BuildInstantiator(NHibernate.Mapping.PersistentClass mappingInfo)    {        return new CustomMapInstantiator(mappingInfo);    }    private sealed class CustomMapInstantiator : NHibernate.Tuple.DynamicMapInstantiator    {        // override the generateMap() method to return our custom map...        protected override IDictionary GenerateMap()        {            return new CustomMap();        }    }} 4.6. Lifecycle Callbacks Optionally, a persistent class might implement the interface ILifecycle which provides some callbacks that allow the persistent object to perform necessary initialization/cleanup after save or load and before deletion or update. The NHibernate IInterceptor offers a less intrusive alternative, however. public interface ILifecycle{                                                                    (1)        LifecycleVeto OnSave(ISession s);                            (2)        LifecycleVeto OnUpdate(ISession s);                          (3)        LifecycleVeto OnDelete(ISession s);                          (4)        void OnLoad(ISession s, object id);} (1) OnSave - called just before the object is saved or inserted (2) OnUpdate - called just before an object is updated (when the object is passed toISession.Update()) (3) OnDelete - called just before an object is deleted (4) OnLoad - called just after an object is loaded OnSave(), OnDelete() and OnUpdate() may be used to cascade saves and deletions of dependent objects. This is an alternative to declaring cascaded operations in the mapping file.OnLoad() may be used to initialize transient properties of the object from its persistent state. It may not be used to load dependent objects since theISession interface may not be invoked from inside this method. A further intended usage ofOnLoad(),OnSave() and OnUpdate() is to store a reference to the currentISession for later use. Note that OnUpdate() is not called every time the object's persistent state is updated. It is called only when a transient object is passed toISession.Update(). If OnSave(), OnUpdate() or OnDelete() return LifecycleVeto.Veto, the operation is silently vetoed. If aCallbackException is thrown, the operation is vetoed and the exception is passed back to the application. Note that OnSave() is called after an identifier is assigned to the object, except when native key generation is used. 4.7. IValidatable callback If the persistent class needs to check invariants before its state is persisted, it may implement the following interface: public interface IValidatable{        void Validate();} The object should throw a ValidationFailure if an invariant was violated. An instance ofValidatable should not change its state from insideValidate(). Unlike the callback methods of the ILifecycle interface,Validate() might be called at unpredictable times. The application should not rely upon calls toValidate() for business functionality. Chapter 5. Basic O/R Mapping 5.1. Mapping declaration Object/relational mappings are defined in an XML document. The mapping document is designed to be readable and hand-editable. The mapping language is object-centric, meaning that mappings are constructed around persistent class declarations, not table declarations. Note that, even though many NHibernate users choose to define XML mappings by hand, a number of tools exist to generate the mapping document, including NHibernate.Mapping.Attributes library and various template-based code generators (CodeSmith, MyGeneration). Let's kick off with an example mapping: <?xml version=\"1.0\"?><hibernate-mapping xmlns=\"urn:nhibernate-mapping-2.2\" assembly=\"Eg\"    namespace=\"Eg\">        <class name=\"Cat\" table=\"CATS\" discriminator-value=\"C\">                <id name=\"Id\" column=\"uid\" type=\"Int64\">                        <generator class=\"hilo\"/>                <\/id>                <discriminator column=\"subclass\" type=\"Char\"/>                <property name=\"BirthDate\" type=\"Date\"/>                <property name=\"Color\" not-null=\"true\"/>                <property name=\"Sex\" not-null=\"true\" update=\"false\"/>                <property name=\"Weight\"/>                <many-to-one name=\"Mate\" column=\"mate_id\"/>                <set name=\"Kittens\">                        <key column=\"mother_id\"/>                        <one-to-many class=\"Cat\"/>                <\/set>                <subclass name=\"DomesticCat\" discriminator-value=\"D\">                        <property name=\"Name\" type=\"String\"/>                <\/subclass>        <\/class>        <class name=\"Dog\">                <!-- mapping for Dog could go here -->        <\/class><\/hibernate-mapping> We will now discuss the content of the mapping document. We will only describe the document elements and attributes that are used by NHibernate at runtime. The mapping document also contains some extra optional attributes and elements that affect the database schemas exported by the schema export tool. (For example the not-null attribute.) 5.1.1. XML Namespace All XML mappings should declare the XML namespace shown. The actual schema definition may be found in thesrc\\nhibernate-mapping.xsd file in the NHibernate distribution. Tip: to enable IntelliSense for mapping and configuration files, copy the appropriate.xsd files as part of any project in your solution, (Build Action can be \"None\") or as \"Solution Files\" or in your\"Lib\" folder and then add it to the Schemas property of the xml file. You can copy it in <VS installation directory>\\Xml\\Schemas, take care because you will have to deal with different version of the xsd for different versions of NHibernate. 5.1.2. hibernate-mapping This element has several optional attributes. The schema attribute specifies that tables referred to by this mapping belong to the named schema. If specified, tablenames will be qualified by the given schema name. If missing, tablenames will be unqualified. The default-cascade attribute specifies what cascade style should be assumed for properties and collections which do not specify acascade attribute. Theauto-import attribute lets us use unqualified class names in the query language, by default. Theassembly andnamespace attributes specify the assembly where persistent classes are located and the namespace they are declared in.            <hibernate-mapping                         (1)         schema=\"schemaName\"                          (2)         default-cascade=\"none|save-update\"           (3)         auto-import=\"true|false\"                     (4)         assembly=\"Eg\"                                (5)         namespace=\"Eg\"                               (6)         default-access=\"field|property|field.camecase(7)...\"         default-lazy=\"true|false\" /> (1) schema (optional): The name of a database schema. (2) default-cascade (optional - defaults to none): A default cascade style. (3) auto-import (optional - defaults to true): Specifies whether we can use unqualified class names (of classes in this mapping) in the query language. (4)(5) assembly and namespace(optional): Specify assembly and namespace to assume for unqualified class names in the mapping document. (6) default-access (optional - defaults to property): The strategy NHibernate should use for accessing a property value (7) default-lazy (optional - defaults to true): Lazy fetching may be completely disabled by setting default-lazy=\"false\". If you are not using assembly and namespace attributes, you have to specify fully-qualified class names, including the name of the assembly that classes are declared in. If you have two persistent classes with the same (unqualified) name, you should setauto-import=\"false\". NHibernate will throw an exception if you attempt to assign two classes to the same \"imported\" name. 5.1.3. class You may declare a persistent class using the class element: <class        name=\"ClassName\"                              (1)        table=\"tableName\"                             (2)        discriminator-value=\"discriminator_value\"     (3)        mutable=\"true|false\"                          (4)        schema=\"owner\"                                (5)        proxy=\"ProxyInterface\"                        (6)        dynamic-update=\"true|false\"                   (7)        dynamic-insert=\"true|false\"                   (8)        select-before-update=\"true|false\"             (9)        polymorphism=\"implicit|explicit\"              (10)        where=\"arbitrary sql where condition\"         (11)        persister=\"PersisterClass\"                    (12)        batch-size=\"N\"                                (13)        optimistic-lock=\"none|version|dirty|all\"      (14)        lazy=\"true|false\"                             (15)        abstract=\"true|false\"                         (16)/> (1) name: The fully qualified .NET class name of the persistent class (or interface), including its assembly name. (2) table(optional - defaults to the unqualified class name): The name of its database table. (3) discriminator-value (optional - defaults to the class name): A value that distiguishes individual subclasses, used for polymorphic behaviour. Acceptable values includenull andnot null. (4) mutable (optional, defaults to true): Specifies that instances of the class are (not) mutable. (5) schema (optional): Override the schema name specified by the root<hibernate-mapping> element. (6) proxy (optional): Specifies an interface to use for lazy initializing proxies. You may specify the name of the class itself. (7) dynamic-update (optional, defaults to false): Specifies that UPDATE SQL should be generated at runtime and contain only those columns whose values have changed. (8) dynamic-insert (optional, defaults to false): Specifies that INSERT SQL should be generated at runtime and contain only the columns whose values are not null. (9) select-before-update (optional, defaults to false): Specifies that NHibernate should never perform an SQLUPDATE unless it is certain that an object is actually modified. In certain cases (actually, only when a transient object has been associated with a new session usingupdate()), this means that NHibernate will perform an extra SQLSELECT to determine if anUPDATE is actually required. (10) polymorphism (optional, defaults to implicit): Determines whether implicit or explicit query polymorphism is used. (11) where (optional) specify an arbitrary SQL WHERE condition to be used when retrieving objects of this class (12) persister (optional): Specifies a custom IClassPersister. (13) batch-size (optional, defaults to 1) specify a \"batch size\" for fetching instances of this class by identifier. (14) optimistic-lock (optional, defaults to version): Determines the optimistic locking strategy. (15) lazy (optional): Lazy fetching may be completely disabled by settinglazy=\"false\". (16) abstract (optional): Used to mark abstract superclasses in<union-subclass> hierarchies. It is perfectly acceptable for the named persistent class to be an interface. You would then declare implementing classes of that interface using the<subclass> element. You may persist any inner class. You should specify the class name using the standard form ie.Eg.Foo+Bar, Eg. Due to an HQL parser limitation inner classes can not be used in queries in NHibernate 1.0. Changes to immutable classes, mutable=\"false\", will not be persisted. This allows NHibernate to make some minor performance optimizations. The optional proxy attribute enables lazy initialization of persistent instances of the class. NHibernate will initially return proxies which implement the named interface. The actual persistent object will be loaded when a method of the proxy is invoked. See \"Proxies for Lazy Initialization\" below. Implicit polymorphism means that instances of the class will be returned by a query that names any superclass or implemented interface or the class and that instances of any subclass of the class will be returned by a query that names the class itself. Explicit polymorphism means that class instances will be returned only be queries that explicitly name that class and that queries that name the class will return only instances of subclasses mapped inside this <class> declaration as a <subclass> or <joined-subclass>. For most purposes the default,polymorphism=\"implicit\", is appropriate. Explicit polymorphism is useful when two different classes are mapped to the same table (this allows a \"lightweight\" class that contains a subset of the table columns). The persister attribute lets you customize the persistence strategy used for the class. You may, for example, specify your own subclass ofNHibernate.Persister.EntityPersister or you might even provide a completely new implementation of the interfaceNHibernate.Persister.IClassPersister that implements persistence via, for example, stored procedure calls, serialization to flat files or LDAP. SeeNHibernate.DomainModel.CustomPersister for a simple example (of \"persistence\" to aHashtable). Note that the dynamic-update and dynamic-insert settings are not inherited by subclasses and so may also be specified on the<subclass> or<joined-subclass> elements. These settings may increase performance in some cases, but might actually decrease performance in others. Use judiciously. Use of select-before-update will usually decrease performance. It is very useful to prevent a database update trigger being called unnecessarily. If you enable dynamic-update, you will have a choice of optimistic locking strategies: version check the version/timestamp columns all check all columns dirty check the changed columns none do not use optimistic locking We very strongly recommend that you use version/timestamp columns for optimistic locking with NHibernate. This is the optimal strategy with respect to performance and is the only strategy that correctly handles modifications made outside of the session (ie. when ISession.Update() is used). Keep in mind that a version or timestamp property should never be null, no matter whatunsaved-value strategy, or an instance will be detected as transient. Beginning with NHibernate 1.2.0, version numbers start with 1, not 0 as in previous versions. This was done to allow using 0 asunsaved-value for the version property. 5.1.4. id Mapped classes must declare the primary key column of the database table. Most classes will also have a property holding the unique identifier of an instance. The<id> element defines the mapping from that property to the primary key column. <id        name=\"PropertyName\"                      (1)        type=\"typename\"                          (2)        column=\"column_name\"                     (3)        unsaved-value=\"any|none|null|id_value\"   (4)        access=\"field|property|nosetter|ClassName(5)\">        <generator class=\"generatorClass\"/><\/id> (1) name (optional): The name of the identifier property. (2) type (optional): A name that indicates the NHibernate type. (3) column (optional - defaults to the property name): The name of the primary key column. (4) unsaved-value (optional - defaults to a \"sensible\" value): An identifier property value that indicates that an instance is newly instantiated (unsaved), distinguishing it from transient instances that were saved or loaded in a previous session. (5) access (optional - defaults to property): The strategy NHibernate should use for accessing the property value. If the name attribute is missing, it is assumed that the class has no identifier property. The unsaved-value attribute is almost never needed in NHibernate 1.0. There is an alternative <composite-id> declaration to allow access to legacy data with composite keys. We strongly discourage its use for anything else. 5.1.4.1. generator The required generator names a .NET class used to generate unique identifiers for instances of the persistent class. The generator can be declared using the <generator> child element. If any parameters are required to configure or initialize the generator instance, they are passed using<param> elements. <id name=\"Id\" type=\"Int64\" column=\"uid\" unsaved-value=\"0\">        <generator class=\"NHibernate.Id.TableHiLoGenerator\">                <param name=\"table\">uid_table<\/param>                <param name=\"column\">next_hi_value_column<\/param>        <\/generator><\/id> If no parameters are required, the generator can be declared using a generator attribute directly on the <id> element, as follows: <id name=\"Id\" type=\"Int64\" column=\"uid\" unsaved-value=\"0\" generator=\"native\" /> All generators implement the interface NHibernate.Id.IIdentifierGenerator. This is a very simple interface; some applications may choose to provide their own specialized implementations. However, NHibernate provides a range of built-in implementations. There are shortcut names for the built-in generators: increment generates identifiers of any integral type that are unique only when no other process is inserting data into the same table.Do not use in a cluster. identity supports identity columns in DB2, MySQL, MS SQL Server and Sybase. The identifier returned by the database is converted to the property type usingConvert.ChangeType. Any integral property type is thus supported. sequence uses a sequence in DB2, PostgreSQL, Oracle or a generator in Firebird. The identifier returned by the database is converted to the property type usingConvert.ChangeType. Any integral property type is thus supported. hilo uses a hi/lo algorithm to efficiently generate identifiers of any integral type, given a table and column (by defaulthibernate_unique_key andnext_hi respectively) as a source of hi values. The hi/lo algorithm generates identifiers that are unique only for a particular database.Do not use this generator with a user-supplied connection. You can use the \"where\" parameter to specify the row to use in a table. This is useful if you want to use a single tabel for your identifiers, with different rows for each table. seqhilo uses a hi/lo algorithm to efficiently generate identifiers of any integral type, given a named database sequence. uuid.hex uses System.Guid and its ToString(string format) method to generate identifiers of type string. The length of the string returned depends on the configuredformat. uuid.string uses a new System.Guid to create a byte[] that is converted to a string. guid uses a new System.Guid as the identifier. guid.comb uses the algorithm to generate a new System.Guid described by Jimmy Nilsson in the article http://www.informit.com/articles/article.asp?p=25862. native picks identity, sequence or hilo depending upon the capabilities of the underlying database. assigned lets the application to assign an identifier to the object before Save() is called. foreign uses the identifier of another associated object. Usually used in conjunction with a<one-to-one> primary key association. 5.1.4.2. Hi/Lo Algorithm The hilo and seqhilo generators provide two alternate implementations of the hi/lo algorithm, a favorite approach to identifier generation. The first implementation requires a \"special\" database table to hold the next available \"hi\" value. The second uses an Oracle-style sequence (where supported). <id name=\"Id\" type=\"Int64\" column=\"cat_id\">        <generator class=\"hilo\">                <param name=\"table\">hi_value<\/param>                <param name=\"column\">next_value<\/param>                <param name=\"max_lo\">100<\/param>        <\/generator><\/id> <id name=\"Id\" type=\"Int64\" column=\"cat_id\">        <generator class=\"seqhilo\">                <param name=\"sequence\">hi_value<\/param>                <param name=\"max_lo\">100<\/param>        <\/generator><\/id> Unfortunately, you can't use hilo when supplying your ownIDbConnection to NHibernate. NHibernate must be able to fetch the \"hi\" value in a new transaction. 5.1.4.3. UUID Hex Algorithm <id name=\"Id\" type=\"String\" column=\"cat_id\">        <generator class=\"uuid.hex\">            <param name=\"format\">format_value<\/param>            <param name=\"seperator\">seperator_value<\/param>        <\/generator><\/id> The UUID is generated by calling Guid.NewGuid().ToString(format). The valid values forformat are described in the MSDN documentation. The defaultseperator is- and should rarely be modified. Theformat determines if the configuredseperator can replace the default seperator used by the format. 5.1.4.4. UUID String Algorithm The UUID is generated by calling Guid.NewGuid().ToByteArray() and then converting thebyte[] into achar[]. The char[] is returned as aString consisting of 16 characters. 5.1.4.5. GUID Algorithms The guid identifier is generated by calling Guid.NewGuid(). To address some of the performance concerns with using Guids as primary keys, foreign keys, and as part of indexes with MS SQL theguid.comb can be used. The benefit of using theguid.comb with other databases that support GUIDs has not been measured. 5.1.4.6. Identity columns and Sequences For databases which support identity columns (DB2, MySQL, Sybase, MS SQL), you may useidentity key generation. For databases that support sequences (DB2, Oracle, PostgreSQL, Interbase, McKoi, SAP DB) you may usesequence style key generation. Both these strategies require two SQL queries to insert a new object. <id name=\"Id\" type=\"Int64\" column=\"uid\">        <generator class=\"sequence\">                <param name=\"sequence\">uid_sequence<\/param>        <\/generator><\/id> <id name=\"Id\" type=\"Int64\" column=\"uid\" unsaved-value=\"0\">        <generator class=\"identity\"/><\/id> For cross-platform development, the native strategy will choose from theidentity,sequence and hilo strategies, dependent upon the capabilities of the underlying database. 5.1.4.7. Assigned Identifiers If you want the application to assign identifiers (as opposed to having NHibernate generate them), you may use theassigned generator. This special generator will use the identifier value already assigned to the object's identifier property. Be very careful when using this feature to assign keys with business meaning (almost always a terrible design decision). Due to its inherent nature, entities that use this generator cannot be saved via the ISession's SaveOrUpdate() method. Instead you have to explicitly specify to NHibernate if the object should be saved or updated by calling either theSave() or Update() method of the ISession. 5.1.5. composite-id <composite-id        name=\"PropertyName\"        class=\"ClassName\"        unsaved-value=\"any|none\"        access=\"field|property|nosetter|ClassName\">        <key-property name=\"PropertyName\" type=\"typename\" column=\"column_name\"/>        <key-many-to-one name=\"PropertyName class=\"ClassName\" column=\"column_name\"/>        ......<\/composite-id> For a table with a composite key, you may map multiple properties of the class as identifier properties. The<composite-id> element accepts<key-property> property mappings and<key-many-to-one> mappings as child elements. <composite-id>        <key-property name=\"MedicareNumber\"/>        <key-property name=\"Dependent\"/><\/composite-id> Your persistent class must override Equals() and GetHashCode() to implement composite identifier equality. It must also beSerializable. Unfortunately, this approach to composite identifiers means that a persistent object is its own identifier. There is no convenient \"handle\" other than the object itself. You must instantiate an instance of the persistent class itself and populate its identifier properties before you can load() the persistent state associated with a composite key. We will describe a much more convenient approach where the composite identifier is implemented as a seperate class inSection 7.4, “Components as composite identifiers”. The attributes described below apply only to this alternative approach: name (optional, required for this approach): A property of component type that holds the composite identifier (see next section). access (optional - defaults to property): The strategy NHibernate should use for accessing the property value. class (optional - defaults to the property type determined by reflection): The component class used as a composite identifier (see next section). 5.1.6. discriminator The <discriminator> element is required for polymorphic persistence using the table-per-class-hierarchy mapping strategy and declares a discriminator column of the table. The discriminator column contains marker values that tell the persistence layer what subclass to instantiate for a particular row. A restricted set of types may be used:String,Char, Int32, Byte, Short, Boolean, YesNo, TrueFalse. <discriminator        column=\"discriminator_column\"  (1)        type=\"discriminator_type\"      (2)        force=\"true|false\"             (3)        insert=\"true|false\"            (4)        formula=\"arbitrary SQL expressi(5)on\"/> (1) column (optional - defaults to class) the name of the discriminator column. (2) type (optional - defaults to String) a name that indicates the NHibernate type (3) force (optional - defaults to false) \"force\" NHibernate to specify allowed discriminator values even when retrieving all instances of the root class. (4) insert (optional - defaults to true) set this tofalse if your discriminator column is also part of a mapped composite identifier. (5) formula (optional) an arbitrary SQL expression that is executed when a type has to be evaluated. Allows content-based discrimination. Actual values of the discriminator column are specified by the discriminator-value attribute of the <class> and <subclass> elements. The force attribute is (only) useful if the table contains rows with \"extra\" discriminator values that are not mapped to a persistent class. This will not usually be the case. Using the formula attribute you can declare an arbitrary SQL expression that will be used to evaluate the type of a row: <discriminator    formula=\"case when CLASS_TYPE in ('a', 'b', 'c') then 0 else 1 end\"    type=\"Int32\"/> 5.1.7. version (optional) The <version> element is optional and indicates that the table contains versioned data. This is particularly useful if you plan to uselong transactions (see below). <version        column=\"version_column\"                            (1)        name=\"PropertyName\"                                (2)        type=\"typename\"                                    (3)        access=\"field|property|nosetter|ClassName\"         (4)        unsaved-value=\"null|negative|undefined|value\"      (5)        generated=\"never|always\"                           (6)/> (1) column (optional - defaults to the property name): The name of the column holding the version number. (2) name: The name of a property of the persistent class. (3) type (optional - defaults to Int32): The type of the version number. (4) access (optional - defaults to property): The strategy NHibernate should use for accessing the property value. (5) unsaved-value (optional - defaults to a \"sensible\" value): A version property value that indicates that an instance is newly instantiated (unsaved), distinguishing it from transient instances that were saved or loaded in a previous session. (undefined specifies that the identifier property value should be used.) (6) generated (optional - defaults to never): Specifies that this version property value is actually generated by the database. See the discussion ofSection 5.5, “Generated Properties”. Version numbers may be of type Int64, Int32, Int16, Ticks, Timestamp, or TimeSpan (or their nullable counterparts in .NET 2.0). 5.1.8. timestamp (optional) The optional <timestamp> element indicates that the table contains timestamped data. This is intended as an alternative to versioning. Timestamps are by nature a less safe implementation of optimistic locking. However, sometimes the application might use the timestamps in other ways. <timestamp        column=\"timestamp_column\"           (1)        name=\"PropertyName\"                 (2)        access=\"field|property|nosetter|Clas(3)sName\"        unsaved-value=\"null|undefined|value\"(4)        generated=\"never|always\"            (5)/> (1) column (optional - defaults to the property name): The name of a column holding the timestamp. (2) name: The name of a property of .NET type DateTime of the persistent class. (3) access (optional - defaults to property): The strategy NHibernate should use for accessing the property value. (4) unsaved-value (optional - defaults to null): A timestamp property value that indicates that an instance is newly instantiated (unsaved), distinguishing it from transient instances that were saved or loaded in a previous session. (undefined specifies that the identifier property value should be used.) (5) generated (optional - defaults to never): Specifies that this timestamp property value is actually generated by the database. See the discussion ofSection 5.5, “Generated Properties”. Note that <timestamp> is equivalent to <version type=\"timestamp\">. 5.1.9. property The <property> element declares a persistent property of the class. <property        name=\"propertyName\"                 (1)        column=\"column_name\"                (2)        type=\"typename\"                     (3)        update=\"true|false\"                 (4)        insert=\"true|false\"                 (4)        formula=\"arbitrary SQL expression\"  (5)        access=\"field|property|ClassName\"   (6)        optimistic-lock=\"true|false\"        (7)        generated=\"never|insert|always\"     (8)        lazy=\"true|false\"                   (9)/> (1) name: the name of the property of your class. (2) column (optional - defaults to the property name): the name of the mapped database table column. (3) type (optional): a name that indicates the NHibernate type. (4) update, insert (optional - defaults to true) : specifies that the mapped columns should be included in SQL UPDATE and/or INSERT statements. Setting both to false allows a pure \"derived\" property whose value is initialized from some other property that maps to the same column(s) or by a trigger or other application. (5) formula (optional): an SQL expression that defines the value for acomputed property. Computed properties do not have a column mapping of their own. (6) access (optional - defaults to property): The strategy NHibernate should use for accessing the property value. (7) optimistic-lock (optional - defaults to true): Specifies that updates to this property do or do not require acquisition of the optimistic lock. In other words, determines if a version increment should occur when this property is dirty. (8) generated (optional - defaults to never): Specifies that this property value is actually generated by the database. See the discussion ofSection 5.5, “Generated Properties”. (9) lazy (optional - defaults to false): Specifies that this property is lazy. A lazy property is not loaded when the object is initially loaded, unless the fetch mode has been overriden in a specific query. Values for lazy properties are loaded when any lazy property of the object is accessed. typename could be: The name of a NHibernate basic type (eg. Int32, String, Char, DateTime, Timestamp, Single, Byte[], Object, ...). The name of a .NET type with a default basic type (eg. System.Int16, System.Single, System.Char, System.String, System.DateTime, System.Byte[], ...). The name of an enumeration type (eg. Eg.Color, Eg). The name of a serializable .NET type. The class name of a custom type (eg. Illflow.Type.MyCustomType). Note that you have to specify full assembly-qualified names for all except basic NHibernate types (unless you setassembly and/ornamespace attributes of the<hibernate-mapping> element). NHibernate supports .NET 2.0 Nullable types. These types are mostly treated the same as plain non-Nullable types internally. For example, a property of typeNullable<Int32> can be mapped using type=\"Int32\" or type=\"System.Int32\". If you do not specify a type, NHibernate will use reflection upon the named property to take a guess at the correct NHibernate type. NHibernate will try to interpret the name of the return class of the property getter using rules 2, 3, 4 in that order. However, this is not always enough. In certain cases you will still need the type attribute. (For example, to distinguish between NHibernateUtil.DateTime andNHibernateUtil.Timestamp, or to specify a custom type.) The access attribute lets you control how NHibernate will access the value of the property at runtime. The value of theaccess attribute should be text formatted asaccess-strategy.naming-strategy. The .naming-strategy is not always required. Table 5.1. Access Strategies Access Strategy Name Description property The default implementation. NHibernate uses the get/set accessors of the property. No naming strategy should be used with this access strategy because the value of thename attribute is the name of the property. field NHibernate will access the field directly. NHibernate uses the value of the name attribute as the name of the field. This can be used when a property's getter and setter contain extra actions that you don't want to occur when NHibernate is populating or reading the object. If you want the name of the property and not the field to be what the consumers of your API use with HQL, then a naming strategy is needed. nosetter NHibernate will access the field directly when setting the value and will use the Property when getting the value. This can be used when a property only exposes a get accessor because the consumers of your API can't change the value directly. A naming strategy is required because NHibernate uses the value of the name attribute as the property name and needs to be told what the name of the field is. ClassName If NHibernate's built in access strategies are not what is needed for your situation then you can build your own by implementing the interfaceNHibernate.Property.IPropertyAccessor. The value of theaccess attribute should be an assembly-qualified name that can be loaded withActivator.CreateInstance(string assemblyQualifiedName). Table 5.2. Naming Strategies Naming Strategy Name Description camelcase The name attribute is converted to camel case to find the field.<property name=\"FooBar\" ... > uses the fieldfooBar. camelcase-underscore The name attribute is converted to camel case and prefixed with an underscore to find the field.<property name=\"FooBar\" ... > uses the field_fooBar. camelcase-m-underscore The name attribute is converted to camel case and prefixed with the characterm and an underscore to find the field.<property name=\"FooBar\" ... > uses the field m_fooBar. lowercase The name attribute is converted to lower case to find the Field.<property name=\"FooBar\" ... > uses the fieldfoobar. lowercase-underscore The name attribute is converted to lower case and prefixed with an underscore to find the Field.<property name=\"FooBar\" ... > uses the field_foobar. pascalcase-underscore The name attribute is prefixed with an underscore to find the field.<property name=\"FooBar\" ... > uses the field_FooBar. pascalcase-m The name attribute is prefixed with the character m to find the field. <property name=\"FooBar\" ... > uses the fieldmFooBar. pascalcase-m-underscore The name attribute is prefixed with the character m and an underscore to find the field. <property name=\"FooBar\" ... > uses the fieldm_FooBar. 5.1.10. many-to-one An ordinary association to another persistent class is declared using a many-to-one element. The relational model is a many-to-one association. (It's really just an object reference.) <many-to-one        name=\"PropertyName\"                                (1)        column=\"column_name\"                               (2)        class=\"ClassName\"                                  (3)        cascade=\"all|none|save-update|delete\"              (4)        fetch=\"join|select\"                                (5)        update=\"true|false\"                                (6)        insert=\"true|false\"                                (6)        property-ref=\"PropertyNameFromAssociatedClass\"     (7)        access=\"field|property|nosetter|ClassName\"         (8)        unique=\"true|false\"                                (9)        optimistic-lock=\"true|false\"                       (10)        not-found=\"ignore|exception\"                       (11)/> (1) name: The name of the property. (2) column (optional): The name of the column. (3) class (optional - defaults to the property type determined by reflection): The name of the associated class. (4) cascade (optional): Specifies which operations should be cascaded from the parent object to the associated object. (5) fetch (optional - defaults to select): Chooses between outer-join fetching or sequential select fetching. (6) update, insert (optional - defaults to true) specifies that the mapped columns should be included in SQL UPDATE and/or INSERT statements. Setting both to false allows a pure \"derived\" association whose value is initialized from some other property that maps to the same colum(s) or by a trigger or other application. (7) property-ref: (optional) The name of a property of the associated class that is joined to this foreign key. If not specified, the primary key of the associated class is used. (8) access (optional - defaults to property): The strategy NHibernate should use for accessing the property value. (9) unique (optional): Enable the DDL generation of a unique constraint for the foreign-key column. (10) optimistic-lock (optional - defaults to true): Specifies that updates to this property do or do not require acquisition of the optimistic lock. In other words, dertermines if a version increment should occur when this property is dirty. (11) not-found (optional - defaults to exception): Specifies how foreign keys that reference missing rows will be handled:ignore will treat a missing row as a null association. The cascade attribute permits the following values: all, save-update, delete, none. Setting a value other than none will propagate certain operations to the associated (child) object. See \"Lifecycle Objects\" below. The fetch attribute accepts two different values: join Fetch the association using an outer join select Fetch the association using a separate query A typical many-to-one declaration looks as simple as <many-to-one name=\"product\" class=\"Product\" column=\"PRODUCT_ID\"/> The property-ref attribute should only be used for mapping legacy data where a foreign key refers to a unique key of the associated table other than the primary key. This is an ugly relational model. For example, suppose theProduct class had a unique serial number, that is not the primary key. (Theunique attribute controls NHibernate's DDL generation with the SchemaExport tool.) <property name=\"serialNumber\" unique=\"true\" type=\"string\" column=\"SERIAL_NUMBER\"/> Then the mapping for OrderItem might use: <many-to-one name=\"product\" property-ref=\"serialNumber\" column=\"PRODUCT_SERIAL_NUMBER\"/> This is certainly not encouraged, however. 5.1.11. one-to-one A one-to-one association to another persistent class is declared using a one-to-one element. <one-to-one        name=\"PropertyName\"                                (1)        class=\"ClassName\"                                  (2)        cascade=\"all|none|save-update|delete\"              (3)        constrained=\"true|false\"                           (4)        fetch=\"join|select\"                                (5)        property-ref=\"PropertyNameFromAssociatedClass\"     (6)        access=\"field|property|nosetter|ClassName\"         (7)/> (1) name: The name of the property. (2) class (optional - defaults to the property type determined by reflection): The name of the associated class. (3) cascade (optional) specifies which operations should be cascaded from the parent object to the associated object. (4) constrained (optional) specifies that a foreign key constraint on the primary key of the mapped table references the table of the associated class. This option affects the order in whichSave() andDelete() are cascaded (and is also used by the schema export tool). (5) fetch (optional - defaults to select): Chooses between outer-join fetching or sequential select fetching. (6) property-ref: (optional) The name of a property of the associated class that is joined to the primary key of this class. If not specified, the primary key of the associated class is used. (7) access (optional - defaults to property): The strategy NHibernate should use for accessing the property value. There are two varieties of one-to-one association: primary key associations unique foreign key associations Primary key associations don't need an extra table column; if two rows are related by the association then the two table rows share the same primary key value. So if you want two objects to be related by a primary key association, you must make sure that they are assigned the same identifier value! For a primary key association, add the following mappings to Employee and Person, respectively. <one-to-one name=\"Person\" class=\"Person\"/> <one-to-one name=\"Employee\" class=\"Employee\" constrained=\"true\"/> Now we must ensure that the primary keys of related rows in the PERSON and EMPLOYEE tables are equal. We use a special NHibernate identifier generation strategy calledforeign: <class name=\"Person\" table=\"PERSON\">    <id name=\"Id\" column=\"PERSON_ID\">        <generator class=\"foreign\">            <param name=\"property\">Employee<\/param>        <\/generator>    <\/id>    ...    <one-to-one name=\"Employee\"        class=\"Employee\"        constrained=\"true\"/><\/class> A newly saved instance of Person is then assigned the same primar key value as theEmployee instance refered with theEmployee property of thatPerson. Alternatively, a foreign key with a unique constraint, from Employee to Person, may be expressed as: <many-to-one name=\"Person\" class=\"Person\" column=\"PERSON_ID\" unique=\"true\"/> And this association may be made bidirectional by adding the following to the Person mapping: <one-to-one name=\"Employee\" class=\"Employee\" property-ref=\"Person\"/> 5.1.12. natural-id <natural-id mutable=\"true|false\"/>        <property ... />        <many-to-one ... />        ......<\/natural-id> Even though we recommend the use of surrogate keys as primary keys, you should still try to identify natural keys for all entities. A natural key is a property or combination of properties that is unique and non-null. If it is also immutable, even better. Map the properties of the natural key inside the <natural-id> element. NHibernate will generate the necessary unique key and nullability constraints, and your mapping will be more self-documenting. We strongly recommend that you implement Equals() andGetHashCode() to compare the natural key properties of the entity. This mapping is not intended for use with entities with natural primary keys. mutable (optional, defaults to false): By default, natural identifier properties as assumed to be immutable (constant). 5.1.13. component, dynamic-component The <component> element maps properties of a child object to columns of the table of a parent class. Components may, in turn, declare their own properties, components or collections. See \"Components\" below. <component         name=\"PropertyName\"                                (1)        class=\"ClassName\"                                  (2)        insert=\"true|false\"                                (3)        upate=\"true|false\"                                 (4)        access=\"field|property|nosetter|ClassName\"         (5)        optimistic-lock=\"true|false\">                      (6)                <property ...../>        <many-to-one .... />        ........<\/component> (1) name: The name of the property. (2) class (optional - defaults to the property type determined by reflection): The name of the component (child) class. (3) insert: Do the mapped columns appear in SQL INSERTs? (4) update: Do the mapped columns appear in SQL UPDATEs? (5) access (optional - defaults to property): The strategy NHibernate should use for accessing the property value. (6) optimistic-lock (optional - defaults to true): Specifies that updates to this component do or do not require acquisition of the optimistic lock. In other words, determines if a version increment should occur when this property is dirty. The child <property> tags map properties of the child class to table columns. The <component> element allows a <parent> subelement that maps a property of the component class as a reference back to the containing entity. The <dynamic-component> element allows an IDictionary to be mapped as a component, where the property names refer to keys of the dictionary. 5.1.14. properties The <properties> element allows the definition of a named, logical grouping of the properties of a class. The most important use of the construct is that it allows a combination of properties to be the target of aproperty-ref. It is also a convenient way to define a multi-column unique constraint. For example: <properties      name=\"logicalName\"                                   (1)      insert=\"true|false\"                                  (2)      update=\"true|false\"                                  (3)      optimistic-lock=\"true|false\"                         (4)      unique=\"true|false\">                                 (5)      <property .../>      <many-to-one .../>      ........<\/properties> (1) name: the logical name of the grouping. It is not an actual property name. (2) insert: do the mapped columns appear in SQL INSERTs? (3) update: do the mapped columns appear in SQL UPDATEs? (4) optimistic-lock (optional - defaults to true): specifies that updates to these properties either do or do not require acquisition of the optimistic lock. It determines if a version increment should occur when these properties are dirty. (5) unique (optional - defaults to false): specifies that a unique constraint exists upon all mapped columns of the component. For example, if we have the following <properties> mapping: <class name=\"Person\">      <id name=\"personNumber\" />      <properties name=\"name\" unique=\"true\" update=\"false\">          <property name=\"firstName\" />          <property name=\"lastName\" />          <property name=\"initial\" />      <\/properties><\/class> You might have some legacy data association that refers to this unique key of thePerson table, instead of to the primary key: <many-to-one name=\"owner\" class=\"Person\" property-ref=\"name\">        <column name=\"firstName\" />        <column name=\"lastName\" />        <column name=\"initial\" /><\/many-to-one> The use of this outside the context of mapping legacy data is not recommended. 5.1.15. subclass Finally, polymorphic persistence requires the declaration of each subclass of the root persistent class. For the (recommended) table-per-class-hierarchy mapping strategy, the<subclass> declaration is used. <subclass        name=\"ClassName\"                              (1)        discriminator-value=\"discriminator_value\"     (2)        proxy=\"ProxyInterface\"                        (3)        lazy=\"true|false\"                             (4)        dynamic-update=\"true|false\"        dynamic-insert=\"true|false\">        <property .... />        <properties .... />        .....<\/subclass> (1) name: The fully qualified .NET class name of the subclass, including its assembly name. (2) discriminator-value (optional - defaults to the class name): A value that distiguishes individual subclasses. (3) proxy (optional): Specifies a class or interface to use for lazy initializing proxies. (4) lazy (optional, defaults to true): Settinglazy=\"false\" disables the use of lazy fetching. Each subclass should declare its own persistent properties and subclasses. <version> and <id> properties are assumed to be inherited from the root class. Each subclass in a hierarchy must define a uniquediscriminator-value. If none is specified, the fully qualified .NET class name is used. For information about inheritance mappings, see Chapter 8, Inheritance Mapping. 5.1.16. joined-subclass Alternatively, a subclass that is persisted to its own table (table-per-subclass mapping strategy) is declared using a<joined-subclass> element. <joined-subclass        name=\"ClassName\"                    (1)        proxy=\"ProxyInterface\"              (2)        lazy=\"true|false\"                   (3)        dynamic-update=\"true|false\"        dynamic-insert=\"true|false\">        <key .... >        <property .... />        <properties .... />        .....<\/joined-subclass> (1) name: The fully qualified class name of the subclass. (2) proxy (optional): Specifies a class or interface to use for lazy initializing proxies. (3) lazy (optional): Setting lazy=\"true\" is a shortcut equalivalent to specifying the name of the class itself as theproxy interface. No discriminator column is required for this mapping strategy. Each subclass must, however, declare a table column holding the object identifier using the<key> element. The mapping at the start of the chapter would be re-written as: <?xml version=\"1.0\"?><hibernate-mapping xmlns=\"urn:nhibernate-mapping-2.2\" assembly=\"Eg\"    namespace=\"Eg\">        <class name=\"Cat\" table=\"CATS\">                <id name=\"Id\" column=\"uid\" type=\"Int64\">                        <generator class=\"hilo\"/>                <\/id>                <property name=\"BirthDate\" type=\"Date\"/>                <property name=\"Color\" not-null=\"true\"/>                <property name=\"Sex\" not-null=\"true\"/>                <property name=\"Weight\"/>                <many-to-one name=\"Mate\"/>                <set name=\"Kittens\">                        <key column=\"MOTHER\"/>                        <one-to-many class=\"Cat\"/>                <\/set>                <joined-subclass name=\"DomesticCat\" table=\"DOMESTIC_CATS\">                    <key column=\"CAT\"/>                        <property name=\"Name\" type=\"String\"/>                <\/joined-subclass>        <\/class>        <class name=\"Dog\">                <!-- mapping for Dog could go here -->        <\/class><\/hibernate-mapping> For information about inheritance mappings, see Chapter 8, Inheritance Mapping. 5.1.17. union-subclass A third option is to map only the concrete classes of an inheritance hierarchy to tables, (the table-per-concrete-class strategy) where each table defines all persistent state of the class, including inherited state. In NHibernate, it is not absolutely necessary to explicitly map such inheritance hierarchies. You can simply map each class with a separate<class> declaration. However, if you wish use polymorphic associations (e.g. an association to the superclass of your hierarchy), you need to use the<union-subclass> mapping. <union-subclass        name=\"ClassName\"                    (1)        table=\"tablename\"                   (2)        proxy=\"ProxyInterface\"              (3)        lazy=\"true|false\"                   (4)        dynamic-update=\"true|false\"        dynamic-insert=\"true|false\"        schema=\"schema\"        catalog=\"catalog\"        extends=\"SuperclassName\"        abstract=\"true|false\"        persister=\"ClassName\"        subselect=\"SQL expression\"        entity-name=\"EntityName\"        node=\"element-name\">        <property .... />        <properties .... />        .....<\/union-subclass> (1) name: The fully qualified class name of the subclass. (2) table: The name of the subclass table. (3) proxy (optional): Specifies a class or interface to use for lazy initializing proxies. (4) lazy (optional, defaults to true): Settinglazy=\"false\" disables the use of lazy fetching. No discriminator column or key column is required for this mapping strategy. For information about inheritance mappings, see Chapter 8, Inheritance Mapping. 5.1.18. join Using the <join> element, it is possible to map properties of one class to several tables, when there's a 1-to-1 relationship between the tables. <join        table=\"tablename\"                        (1)        schema=\"owner\"                           (2)        fetch=\"join|select\"                      (3)        inverse=\"true|false\"                     (4)        optional=\"true|false\">                   (5)        <key ... />        <property ... />        ...<\/join> (1) table: The name of the joined table. (2) schema (optional): Override the schema name specified by the root<hibernate-mapping> element. (3) fetch (optional - defaults to join): If set tojoin, the default, NHibernate will use an inner join to retrieve a<join> defined by a class or its superclasses and an outer join for a<join> defined by a subclass. If set toselect then NHibernate will use a sequential select for a<join> defined on a subclass, which will be issued only if a row turns out to represent an instance of the subclass. Inner joins will still be used to retrieve a<join> defined by the class and its superclasses. (4) inverse (optional - defaults to false): If enabled, NHibernate will not try to insert or update the properties defined by this join. (5) optional (optional - defaults to false): If enabled, NHibernate will insert a row only if the properties defined by this join are non-null and will always use an outer join to retrieve the properties. For example, the address information for a person can be mapped to a separate table (while preserving value type semantics for all properties): <class name=\"Person\"    table=\"PERSON\">    <id name=\"id\" column=\"PERSON_ID\">...<\/id>    <join table=\"ADDRESS\">        <key column=\"ADDRESS_ID\"/>        <property name=\"address\"/>        <property name=\"zip\"/>        <property name=\"country\"/>    <\/join>    ... This feature is often only useful for legacy data models, we recommend fewer tables than classes and a fine-grained domain model. However, it is useful for switching between inheritance mapping strategies in a single hierarchy, as explained later. 5.1.19. map, set, list, bag Collections are discussed later. 5.1.20. import Suppose your application has two persistent classes with the same name, and you don't want to specify the fully qualified name in NHibernate queries. Classes may be \"imported\" explicitly, rather than relying uponauto-import=\"true\". You may even import classes and interfaces that are not explicitly mapped. <import class=\"System.Object\" rename=\"Universe\"/> <import        class=\"ClassName\"              (1)        rename=\"ShortName\"             (2)/> (1) class: The fully qualified class name of any .NET class, including its assembly name. (2) rename (optional - defaults to the unqualified class name): A name that may be used in the query language. 5.2. NHibernate Types 5.2.1. Entities and values To understand the behaviour of various .NET language-level objects with respect to the persistence service, we need to classify them into two groups: An entity exists independently of any other objects holding references to the entity. Contrast this with the usual .NET model where an unreferenced object is garbage collected. Entities must be explicitly saved and deleted (except that saves and deletions may be cascaded from a parent entity to its children). This is different from the ODMG model of object persistence by reachability - and corresponds more closely to how application objects are usually used in large systems. Entities support circular and shared references. They may also be versioned. An entity's persistent state consists of references to other entities and instances ofvalue types. Values are primitives, collections, components and certain immutable objects. Unlike entities, values (in particular collections and components)are persisted and deleted by reachability. Since value objects (and primitives) are persisted and deleted along with their containing entity they may not be independently versioned. Values have no independent identity, so they cannot be shared by two entities or collections. All NHibernate types except collections support null semantics if the .NET type is nullable (i.e. not derived fromSystem.ValueType). Up until now, we've been using the term \"persistent class\" to refer to entities. We will continue to do that. Strictly speaking, however, not all user-defined classes with persistent state are entities. Acomponent is a user defined class with value semantics. 5.2.2. Basic value types The basic types may be roughly categorized into three groups -System.ValueType types,System.Object types, andSystem.Object types for large objects. Just like the .NET Types, columns for System.ValueType typescan not storenull values and System.Object typescan storenull values. Table 5.3. System.ValueType Mapping Types NHibernate Type .NET Type Database Type Remarks AnsiChar System.Char DbType.AnsiStringFixedLength - 1 char   Boolean System.Boolean DbType.Boolean Default when no type attribute specified. Byte System.Byte DbType.Byte Default when no type attribute specified. Char System.Char DbType.StringFixedLength - 1 char Default when no type attribute specified. DateTime System.DateTime DbType.DateTime - ignores the milliseconds Default when no type attribute specified. LocalDateTime System.DateTime DbType.DateTime - ignores the milliseconds Ensures the DateTimeKind is set to DateTimeKind.Local UtcDateTime System.DateTime DbType.DateTime - ignores the milliseconds Ensures the DateTimeKind is set to DateTimeKind.Utc Decimal System.Decimal DbType.Decimal Default when no type attribute specified. Double System.Double DbType.Double Default when no type attribute specified. Guid System.Guid DbType.Guid Default when no type attribute specified. Int16 System.Int16 DbType.Int16 Default when no type attribute specified. Int32 System.Int32 DbType.Int32 Default when no type attribute specified. Int64 System.Int64 DbType.Int64 Default when no type attribute specified. PersistentEnum A System.Enum The DbType for the underlying value. Do not specify type=\"PersistentEnum\" in the mapping. Instead specify the Assembly Qualified Name of the Enum or let NHibernate use Reflection to \"guess\" the Type. The UnderlyingType of the Enum is used to determine the correctDbType. Single System.Single DbType.Single Default when no type attribute specified. Ticks System.DateTime DbType.Int64 type=\"Ticks\" must be specified. TimeSpan System.TimeSpan DbType.Int64 Default when no type attribute specified. Timestamp System.DateTime DbType.DateTime - as specific as database supports. type=\"Timestamp\" must be specified. TrueFalse System.Boolean DbType.AnsiStringFixedLength - 1 char either 'T' or 'F' type=\"TrueFalse\" must be specified. YesNo System.Boolean DbType.AnsiStringFixedLength - 1 char either 'Y' or 'N' type=\"YesNo\" must be specified. Table 5.4. System.Object Mapping Types NHibernate Type .NET Type Database Type Remarks AnsiString System.String DbType.AnsiString type=\"AnsiString\" must be specified. CultureInfo System.Globalization.CultureInfo DbType.String - 5 chars for culture Default when no type attribute specified. Binary System.Byte[] DbType.Binary Default when no type attribute specified. Type System.Type DbType.String holding Assembly Qualified Name. Default when no type attribute specified. String System.String DbType.String Default when no type attribute specified. Table 5.5. Large Object Mapping Types NHibernate Type .NET Type Database Type Remarks StringClob System.String DbType.String type=\"StringClob\" must be specified. Entire field is read into memory. BinaryBlob System.Byte[] DbType.Binary type=\"BinaryBlob\" must be specified. Entire field is read into memory. Serializable Any System.Object that is marked with SerializableAttribute. DbType.Binary type=\"Serializable\" should be specified. This is the fallback type if no NHibernate Type can be found for the Property. NHibernate supports some additional type names for compatibility with NHibernate (useful for those coming over from NHibernate or using some of the tools to generatehbm.xml files). Atype=\"integer\" ortype=\"int\" will map to anInt32 NHibernate type,type=\"short\" to anInt16 NHibernateType. To see all of the conversions you can view the source of static constructor of the classNHibernate.Type.TypeFactory. 5.2.3. Custom value types It is relatively easy for developers to create their own value types. For example, you might want to persist properties of typeInt64 toVARCHAR columns. NHibernate does not provide a built-in type for this. But custom types are not limited to mapping a property (or collection element) to a single table column. So, for example, you might have a propertyName { get; set; } of type String that is persisted to the columnsFIRST_NAME,INITIAL, SURNAME. To implement a custom type, implement either NHibernate.UserTypes.IUserType orNHibernate.UserTypes.ICompositeUserType and declare properties using the fully qualified name of the type. Check outNHibernate.DomainModel.DoubleStringType to see the kind of things that are possible. <property name=\"TwoStrings\" type=\"NHibernate.DomainModel.DoubleStringType, NHibernate.DomainModel\">    <column name=\"first_string\"/>    <column name=\"second_string\"/><\/property> Notice the use of <column> tags to map a property to multiple columns. The ICompositeUserType, IEnhancedUserType,INullableUserType,IUserCollectionType, andIUserVersionType interfaces provide support for more specialized uses. You may even supply parameters to an IUserType in the mapping file. To do this, yourIUserType must implement theNHibernate.UserTypes.IParameterizedType interface. To supply parameters to your custom type, you can use the<type> element in your mapping files. <property name=\"priority\">    <type name=\"MyCompany.UserTypes.DefaultValueIntegerType\">        <param name=\"default\">0<\/param>    <\/type><\/property> The IUserType can now retrieve the value for the parameter nameddefault from theIDictionary object passed to it. If you use a certain UserType very often, it may be useful to define a shorter name for it. You can do this using the<typedef> element. Typedefs assign a name to a custom type, and may also contain a list of default parameter values if the type is parameterized. <typedef class=\"MyCompany.UserTypes.DefaultValueIntegerType\" name=\"default_zero\">    <param name=\"default\">0<\/param><\/typedef> <property name=\"priority\" type=\"default_zero\"/> It is also possible to override the parameters supplied in a typedef on a case-by-case basis by using type parameters on the property mapping. Even though NHibernate's rich range of built-in types and support for components means you will very rarelyneed to use a custom type, it is nevertheless considered good form to use custom types for (non-entity) classes that occur frequently in your application. For example, aMonetaryAmount class is a good candidate for anICompositeUserType, even though it could easily be mapped as a component. One motivation for this is abstraction. With a custom type, your mapping documents would be future-proofed against possible changes in your way of representing monetary values. 5.2.4. Any type mappings There is one further type of property mapping. The <any> mapping element defines a polymorphic association to classes from multiple tables. This type of mapping always requires more than one column. The first column holds the type of the associated entity. The remaining columns hold the identifier. It is impossible to specify a foreign key constraint for this kind of association, so this is most certainly not meant as the usual way of mapping (polymorphic) associations. You should use this only in very special cases (eg. audit logs, user session data, etc). <any name=\"AnyEntity\" id-type=\"Int64\" meta-type=\"Eg.Custom.Class2TablenameType\">    <column name=\"table_name\"/>    <column name=\"id\"/><\/any> The meta-type attribute lets the application specify a custom type that maps database column values to persistent classes which have identifier properties of the type specified byid-type. If the meta-type returns instances of System.Type, nothing else is required. On the other hand, if it is a basic type likeString orChar, you must specify the mapping from values to classes. <any name=\"AnyEntity\" id-type=\"Int64\" meta-type=\"String\">    <meta-value value=\"TBL_ANIMAL\" class=\"Animal\"/>    <meta-value value=\"TBL_HUMAN\" class=\"Human\"/>    <meta-value value=\"TBL_ALIEN\" class=\"Alien\"/>    <column name=\"table_name\"/>    <column name=\"id\"/><\/any> <any        name=\"PropertyName\"                                (1)        id-type=\"idtypename\"                               (2)        meta-type=\"metatypename\"                           (3)        cascade=\"none|all|save-update\"                     (4)        access=\"field|property|nosetter|ClassName\"         (5)        optimistic-lock=\"true|false\"                       (6)>        <meta-value ... />        <meta-value ... />        .....        <column .... />        <column .... />        .....<\/any> (1) name: the property name. (2) id-type: the identifier type. (3) meta-type (optional - defaults to Type): a type that maps System.Type to a single database column or, alternatively, a type that is allowed for a discriminator mapping. (4) cascade (optional - defaults to none): the cascade style. (5) access (optional - defaults to property): The strategy NHibernate should use for accessing the property value. (6) optimistic-lock (optional - defaults to true): Specifies that updates to this property do or do not require acquisition of the optimistic lock. In other words, define if a version increment should occur if this property is dirty. 5.3. SQL quoted identifiers You may force NHibernate to quote an identifier in the generated SQL by enclosing the table or column name in backticks in the mapping document. NHibernate will use the correct quotation style for the SQLDialect (usually double quotes, but brackets for SQL Server and backticks for MySQL). <class name=\"LineItem\" table=\"`Line Item`\">    <id name=\"Id\" column=\"`Item Id`\"/><generator class=\"assigned\"/><\/id>    <property name=\"ItemNumber\" column=\"`Item #`\"/>    ...<\/class> 5.4. Modular mapping files It is possible to define subclass and joined-subclass mappings in seperate mapping documents, directly beneath hibernate-mapping. This allows you to extend a class hierachy just by adding a new mapping file. You must specify anextends attribute in the subclass mapping, naming a previously mapped superclass. Use of this feature makes the ordering of the mapping documents important! <hibernate-mapping>        <subclass name=\"Eg.Subclass.DomesticCat, Eg\"            extends=\"Eg.Cat, Eg\" discriminator-value=\"D\">             <property name=\"name\" type=\"string\"/>        <\/subclass><\/hibernate-mapping> 5.5. Generated Properties Generated properties are properties which have their values generated by the database. Typically, NHibernate applications needed toRefresh objects which contain any properties for which the database was generating values. Marking properties as generated, however, lets the application delegate this responsibility to NHibernate. Essentially, whenever NHibernate issues an SQL INSERT or UPDATE for an entity which has defined generated properties, it immediately issues a select afterwards to retrieve the generated values. Properties marked as generated must additionally be non-insertable and non-updateable. OnlySection 5.1.7, “version (optional)”,Section 5.1.8, “timestamp (optional)”, and Section 5.1.9, “property” can be marked as generated. never (the default) - means that the given property value is not generated within the database. insert - states that the given property value is generated on insert, but is not regenerated on subsequent updates. Things like created-date would fall into this category. Note that even thoughSection 5.1.7, “version (optional)” and Section 5.1.8, “timestamp (optional)” properties can be marked as generated, this option is not available there... always - states that the property value is generated both on insert and on update. 5.6. Auxiliary Database Objects Allows CREATE and DROP of arbitrary database objects, in conjunction with NHibernate's schema evolution tools, to provide the ability to fully define a user schema within the NHibernate mapping files. Although designed specifically for creating and dropping things like triggers or stored procedures, really any SQL command that can be run via aIDbCommand.ExecuteNonQuery() method is valid here (ALTERs, INSERTS, etc). There are essentially two modes for defining auxiliary database objects. The first mode is to explicitly list the CREATE and DROP commands out in the mapping file: <nhibernate-mapping>    ...    <database-object>        <create>CREATE TRIGGER my_trigger ...<\/create>        <drop>DROP TRIGGER my_trigger<\/drop>    <\/database-object><\/nhibernate-mapping> The second mode is to supply a custom class which knows how to construct the CREATE and DROP commands. This custom class must implement theNHibernate.Mapping.IAuxiliaryDatabaseObject interface. <hibernate-mapping>    ...    <database-object>        <definition class=\"MyTriggerDefinition, MyAssembly\"/>    <\/database-object><\/hibernate-mapping> You may also specify parameters to be passed to the database object: <hibernate-mapping>    ...    <database-object>        <definition class=\"MyTriggerDefinition, MyAssembly\">            <param name=\"parameterName\">parameterValue<\/param>        <\/definition>    <\/database-object><\/hibernate-mapping> NHibernate will call IAuxiliaryDatabaseObject.SetParameterValues passing it a dictionary of parameter names and values. Additionally, these database objects can be optionally scoped such that they only apply when certain dialects are used. <hibernate-mapping>    ...    <database-object>        <definition class=\"MyTriggerDefinition\"/>        <dialect-scope name=\"NHibernate.Dialect.Oracle9Dialect\"/>        <dialect-scope name=\"NHibernate.Dialect.OracleDialect\"/>    <\/database-object><\/hibernate-mapping> Chapter 6. Collection Mapping 6.1. Persistent Collections NHibernate requires that persistent collection-valued fields be declared as an interface type, for example: public class Product{    private string serialNumber;    private ISet parts = new HashedSet();        public ISet Parts    {        get { return parts; }        set { parts = value; }    }    public string SerialNumber    {        get { return serialNumber; }        set { serialNumber = value; }    }} The actual interface might be Iesi.Collections.ISet, System.Collections.ICollection, System.Collections.IList,System.Collections.IDictionary,System.Collections.Generic.ICollection<T>,System.Collections.Generic.IList<T>,System.Collections.Generic.IDictionary<K, V>, Iesi.Collections.Generic.ISet<T> or ... anything you like! (Where \"anything you like\" means you will have to write an implementation ofNHibernate.UserType.IUserCollectionType.) Notice how we initialized the instance variable with an instance of HashedSet. This is the best way to initialize collection valued properties of newly instantiated (non-persistent) instances. When you make the instance persistent - by callingSave(), for example - NHibernate will actually replace theHashedSet with an instance of NHibernate's own implementation ofISet. Watch out for errors like this: Cat cat = new DomesticCat();Cat kitten = new DomesticCat();....ISet kittens = new HashedSet();kittens.Add(kitten);cat.Kittens = kittens;session.Save(cat);kittens = cat.Kittens; //Okay, kittens collection is an ISetHashedSet hs = (HashedSet) cat.Kittens; //Error! Collection instances have the usual behavior of value types. They are automatically persisted when referenced by a persistent object and automatically deleted when unreferenced. If a collection is passed from one persistent object to another, its elements might be moved from one table to another. Two entities may not share a reference to the same collection instance. Due to the underlying relational model, collection-valued properties do not support null value semantics; NHibernate does not distinguish between a null collection reference and an empty collection. You shouldn't have to worry much about any of this. Just use NHibernate's collections the same way you use ordinary .NET collections, but make sure you understand the semantics of bidirectional associations (discussed later) before using them. Collection instances are distinguished in the database by a foreign key to the owning entity. This foreign key is referred to as thecollection key. The collection key is mapped by the<key> element. Collections may contain almost any other NHibernate type, including all basic types, custom types, entity types and components. This is an important definition: An object in a collection can either be handled with \"pass by value\" semantics (it therefore fully depends on the collection owner) or it can be a reference to another entity with an own lifecycle. Collections may not contain other collections. The contained type is referred to as thecollection element type. Collection elements are mapped by<element>, <composite-element>,<one-to-many>, <many-to-many> or<many-to-any>. The first two map elements with value semantics, the other three are used to map entity associations. All collection types except ISet and bag have an index column - a column that maps to an array or IList index or IDictionary key. The index of an IDictionary may be of any basic type, an entity type or even a composite type (it may not be a collection). The index of an array or list is always of typeInt32. Indexes are mapped using<index>,<index-many-to-many>, <composite-index> or<index-many-to-any>. There are quite a range of mappings that can be generated for collections, covering many common relational models. We suggest you experiment with the schema generation tool to get a feeling for how various mapping declarations translate to database tables. 6.2. Mapping a Collection Collections are declared by the <set>, <list>, <map>, <bag>, <array> and <primitive-array> elements. <map> is representative: <map    name=\"propertyName\"                                         (1)    table=\"table_name\"                                          (2)    schema=\"schema_name\"                                        (3)    lazy=\"true|false\"                                           (4)    inverse=\"true|false\"                                        (5)    cascade=\"all|none|save-update|delete|all-delete-orphan\"     (6)    sort=\"unsorted|natural|comparatorClass\"                     (7)    order-by=\"column_name asc|desc\"                             (8)    where=\"arbitrary sql where condition\"                       (9)    fetch=\"select|join\"                                         (10)    batch-size=\"N\"                                              (11)    access=\"field|property|ClassName\"                           (12)    optimistic-lock=\"true|false\"                                (13)    generic=\"true|false\"                                        (14)>    <key .... />    <index .... />    <element .... /><\/map> (1) name the collection property name (2) table (optional - defaults to property name) the name of the collection table (not used for one-to-many associations) (3) schema (optional) the name of a table schema to override the schema declared on the root element (4) lazy (optional - defaults to true) may be used to disable lazy fetching and specify that the association is always eagerly fetched. (5) inverse (optional - defaults to false) mark this collection as the \"inverse\" end of a bidirectional association (6) cascade (optional - defaults to none) enable operations to cascade to child entities (7) sort (optional) specify a sorted collection with natural sort order, or a given comparator class (8) order-by (optional) specify a table column (or columns) that define the iteration order of theIDictionary,ISet or bag, together with an optionalasc ordesc (9) where (optional) specify an arbitrary SQL WHERE condition to be used when retrieving or removing the collection (useful if the collection should contain only a subset of the available data) (10) fetch (optional) Choose between outer-join fetching and fetching by sequential select. (11) batch-size (optional, defaults to 1) specify a \"batch size\" for lazily fetching instances of this collection. (12) access (optional - defaults to property): The strategy NHibernate should use for accessing the property value. (13) optimistic-lock (optional - defaults to true): Species that changes to the state of the collection results in increment of the owning entity's version. (For one to many associations, it is often reasonable to disable this setting.) (14) generic (optional): Choose between generic and non-generic collection interface. If this option is not specified, NHibernate will use reflection to choose the interface. The mapping of an IList or array requires a seperate table column holding the array or list index (thei infoo[i]). If your relational model doesn't have an index column, e.g. if you're working with legacy data, use an unorderedISet instead. This seems to put people off who assume thatIList should just be a more convenient way of accessing an unordered collection. NHibernate collections strictly obey the actual semantics attached to theISet,IList and IDictionary interfaces.IList elements don't just spontaneously rearrange themselves! On the other hand, people who planned to use the IList to emulatebag semantics have a legitimate grievance here. A bag is an unordered, unindexed collection which may contain the same element multiple times. The .NET collections framework lacks anIBag interface, hence you have to emulate it with anIList. NHibernate lets you map properties of type IList orICollection with the <bag> element. Note that bag semantics are not really part of theICollection contract and they actually conflict with the semantics of theIList contract (however, you can sort the bag arbitrarily, discussed later in this chapter). Note: Large NHibernate bags mapped with inverse=\"false\" are inefficient and should be avoided; NHibernate can't create, delete or update rows individually, because there is no key that may be used to identify an individual row. 6.3. Collections of Values and Many-To-Many Associations A collection table is required for any collection of values and any collection of references to other entities mapped as a many-to-many association (the natural semantics for a .NET collection). The table requires (foreign) key column(s), element column(s) and possibly index column(s). The foreign key from the collection table to the table of the owning class is declared using a<key> element. <key column=\"column_name\"/> (1) column (required): The name of the foreign key column. For indexed collections like maps and lists, we require an <index> element. For lists, this column contains sequential integers numbered from zero. Make sure that your index really starts from zero if you have to deal with legacy data. For maps, the column may contain any values of any NHibernate type. <index        column=\"column_name\"                (1)        type=\"typename\"                     (2)/> (1) column (required): The name of the column holding the collection index values. (2) type (optional, defaults to Int32): The type of the collection index. Alternatively, a map may be indexed by objects of entity type. We use the <index-many-to-many> element. <index-many-to-many        column=\"column_name\"                (1)        class=\"ClassName\"                   (2)/> (1) column (required): The name of the foreign key column for the collection index values. (2) class (required): The entity class used as the collection index. For a collection of values, we use the <element> tag. <element        column=\"column_name\"                (1)        type=\"typename\"                     (2)/> (1) column (required): The name of the column holding the collection element values. (2) type (required): The type of the collection element. A collection of entities with its own table corresponds to the relational notion ofmany-to-many association. A many to many association is the most natural mapping of a .NET collection but is not usually the best relational model. <many-to-many        column=\"column_name\"                               (1)        class=\"ClassName\"                                  (2)        fetch=\"join|select\"                                (3)        not-found=\"ignore|exception\"                       (4)    /> (1) column (required): The name of the element foreign key column. (2) class (required): The name of the associated class. (3) fetch (optional, defaults to join): enables outer-join or sequential select fetching for this association. This is a special case; for full eager fetching (in a single SELECT) of an entity and its many-to-many relationships to other entities, you would enable join fetching not only of the collection itself, but also with this attribute on the<many-to-many> nested element. (4) not-found (optional - defaults to exception): Specifies how foreign keys that reference missing rows will be handled:ignore will treat a missing row as a null association. Some examples, first, a set of strings: <set name=\"Names\" table=\"NAMES\">    <key column=\"GROUPID\"/>    <element column=\"NAME\" type=\"String\"/><\/set> A bag containing integers (with an iteration order determined by the order-by attribute): <bag name=\"Sizes\" table=\"SIZES\" order-by=\"SIZE ASC\">    <key column=\"OWNER\"/>    <element column=\"SIZE\" type=\"Int32\"/><\/bag> An array of entities - in this case, a many to many association (note that the entities are lifecycle objects,cascade=\"all\"): <array name=\"Foos\" table=\"BAR_FOOS\" cascade=\"all\">    <key column=\"BAR_ID\"/>    <index column=\"I\"/>    <many-to-many column=\"FOO_ID\" class=\"Eg.Foo, Eg\"/><\/array> A map from string indices to dates: <map name=\"Holidays\" table=\"holidays\" schema=\"dbo\" order-by=\"hol_name asc\">    <key column=\"id\"/>    <index column=\"hol_name\" type=\"String\"/>    <element column=\"hol_date\" type=\"Date\"/><\/map> A list of components (discussed in the next chapter): <list name=\"CarComponents\" table=\"car_components\">    <key column=\"car_id\"/>    <index column=\"posn\"/>    <composite-element class=\"Eg.Car.CarComponent\">            <property name=\"Price\" type=\"float\"/>            <property name=\"Type\" type=\"Eg.Car.ComponentType, Eg\"/>            <property name=\"SerialNumber\" column=\"serial_no\" type=\"String\"/>    <\/composite-element><\/list> 6.4. One-To-Many Associations A one to many association links the tables of two classesdirectly, with no intervening collection table. (This implements aone-to-many relational model.) This relational model loses some of the semantics of .NET collections: No null values may be contained in a dictionary, set or list An instance of the contained entity class may not belong to more than one instance of the collection An instance of the contained entity class may not appear at more than one value of the collection index An association from Foo to Bar requires the addition of a key column and possibly an index column to the table of the contained entity class,Bar. These columns are mapped using the<key> and <index> elements described above. The <one-to-many> tag indicates a one to many association. <one-to-many        class=\"ClassName\"                                  (1)        not-found=\"ignore|exception\"                       (2)    /> (1) class (required): The name of the associated class. (2) not-found (optional - defaults to exception): Specifies how foreign keys that reference missing rows will be handled:ignore will treat a missing row as a null association. Example: <set name=\"Bars\">    <key column=\"foo_id\"/>    <one-to-many class=\"Eg.Bar, Eg\"/><\/set> Notice that the <one-to-many> element does not need to declare any columns. Nor is it necessary to specify thetable name anywhere. Very Important Note: If the <key> column of a <one-to-many> association is declaredNOT NULL, NHibernate may cause constraint violations when it creates or updates the association. To prevent this problem,you must use a bidirectional association with the many valued end (the set or bag) marked asinverse=\"true\". See the discussion of bidirectional associations later in this chapter. 6.5. Lazy Initialization Collections (other than arrays) may be lazily initialized, meaning they load their state from the database only when the application needs to access it. Initialization happens transparently to the user so the application would not normally need to worry about this (in fact, transparent lazy initialization is the main reason why NHibernate needs its own collection implementations). However, if the application tries something like this: s = sessions.OpenSession();ITransaction tx = sessions.BeginTransaction();User u = (User) s.Find(\"from User u where u.Name=?\", userName, NHibernateUtil.String)[0];IDictionary permissions = u.Permissions;tx.Commit();s.Close();int accessLevel = (int) permissions[\"accounts\"];  // Error! It could be in for a nasty surprise. Since the permissions collection was not initialized when theISession was committed, the collection will never be able to load its state. The fix is to move the line that reads from the collection to just before the commit. (There are other more advanced ways to solve this problem, however.) Alternatively, use a non-lazy collection. Since lazy initialization can lead to bugs like that above, non-laziness is the default. However, it is intended that lazy initialization be used for almost all collections, especially for collections of entities (for reasons of efficiency). Exceptions that occur while lazily initializing a collection are wrapped in a LazyInitializationException. Declare a lazy collection using the optional lazy attribute: <set name=\"Names\" table=\"NAMES\" lazy=\"true\">    <key column=\"group_id\"/>    <element column=\"NAME\" type=\"String\"/><\/set> In some application architectures, particularly where the code that accesses data using NHibernate, and the code that uses it are in different application layers, it can be a problem to ensure that theISession is open when a collection is initialized. There are two basic ways to deal with this issue: In a web-based application, an event handler can be used to close the ISession only at the very end of a user request, once the rendering of the view is complete. Of course, this places heavy demands upon the correctness of the exception handling of your application infrastructure. It is vitally important that theISession is closed and the transaction ended before returning to the user, even when an exception occurs during rendering of the view. The event handler has to be able to access theISession for this approach. We recommend that the currentISession is stored in the HttpContext.Items collection (see chapter 1,Section 1.4, “Playing with cats”, for an example implementation). In an application with a seperate business tier, the business logic must \"prepare\" all collections that will be needed by the web tier before returning. This means that the business tier should load all the data and return all the data already initialized to the presentation/web tier that is required for a particular use case. Usually, the application callsNHibernateUtil.Initialize() for each collection that will be needed in the web tier (this call must occur before the session is closed) or retrieves the collection eagerly using a NHibernate query with aFETCH clause. You may also attach a previously loaded object to a new ISession withUpdate() orLock() before accessing unitialized collections (or other proxies). NHibernate can not do this automatically, as it would introduce ad hoc transaction semantics! You can use the Filter() method of the NHibernate ISession API to get the size of a collection without initializing it: ICollection countColl = s.Filter( collection, \"select count(*)\" );IEnumerator countEn = countColl.GetEnumerator();countEn.MoveNext();int count = (int) countEn.Current; Filter() or CreateFilter() are also used to efficiently retrieve subsets of a collection without needing to initialize the whole collection. 6.6. Sorted Collections NHibernate supports collections implemented by System.Collections.SortedList andIesi.Collections.SortedSet. You must specify a comparer in the mapping file: <set name=\"Aliases\" table=\"person_aliases\" sort=\"natural\">    <key column=\"person\"/>    <element column=\"name\" type=\"String\"/><\/set><map name=\"Holidays\" sort=\"My.Custom.HolidayComparer, MyAssembly\" lazy=\"true\">    <key column=\"year_id\"/>    <index column=\"hol_name\" type=\"String\"/>    <element column=\"hol_date\" type=\"Date\"/><\/map> Allowed values of the sort attribute are unsorted, natural and the name of a class implementingSystem.Collections.IComparer. If you want the database itself to order the collection elements use the order-by attribute of set, bag ormap mappings. This performs the ordering in the SQL query, not in memory. Setting the order-by attribute tells NHibernate to useListDictionary orListSet class internally for dictionaries and sets, maintaining the order of the elements.Note that lookup operations on these collections are very slow if they contain more than a few elements. <set name=\"Aliases\" table=\"person_aliases\" order-by=\"name asc\">    <key column=\"person\"/>    <element column=\"name\" type=\"String\"/><\/set><map name=\"Holidays\" order-by=\"hol_date, hol_name\" lazy=\"true\">    <key column=\"year_id\"/>    <index column=\"hol_name\" type=\"String\"/>    <element column=\"hol_date type=\"Date\"/><\/map> Note that the value of the order-by attribute is an SQL ordering, not a HQL ordering! Associations may even be sorted by some arbitrary criteria at runtime using a Filter(). sortedUsers = s.Filter( group.Users, \"order by this.Name\" ); 6.7. Using an<idbag> If you've fully embraced our view that composite keys are a bad thing and that entities should have synthetic identifiers (surrogate keys), then you might find it a bit odd that the many to many associations and collections of values that we've shown so far all map to tables with composite keys! Now, this point is quite arguable; a pure association table doesn't seem to benefit much from a surrogate key (though a collection of composite valuesmight). Nevertheless, NHibernate provides a feature that allows you to map many to many associations and collections of values to a table with a surrogate key. The <idbag> element lets you map a List (or Collection) with bag semantics. <idbag name=\"Lovers\" table=\"LOVERS\" lazy=\"true\">    <collection-id column=\"ID\" type=\"Int64\">        <generator class=\"hilo\"/>    <\/collection-id>    <key column=\"PERSON1\"/>    <many-to-many column=\"PERSON2\" class=\"Eg.Person\" fetch=\"join\"/><\/idbag> As you can see, an <idbag> has a synthetic id generator, just like an entity class! A different surrogate key is assigned to each collection row. NHibernate does not provide any mechanism to discover the surrogate key value of a particular row, however. Note that the update performance of an <idbag> is much better than a regular <bag>! NHibernate can locate individual rows efficiently and update or delete them individually, just like a list, map or set. As of version 2.0, the native identifier generation strategy is supported for<idbag> collection identifiers. 6.8. Bidirectional Associations A bidirectional association allows navigation from both \"ends\" of the association. Two kinds of bidirectional association are supported: one-to-many set or bag valued at one end, single-valued at the other many-to-many set or bag valued at both ends Please note that NHibernate does not support bidirectional one-to-many associations with an indexed collection (list, map or array) as the \"many\" end, you have to use a set or bag mapping. You may specify a bidirectional many-to-many association simply by mapping two many-to-many associations to the same database table and declaring one end asinverse (which one is your choice). Here's an example of a bidirectional many-to-many association from a class back toitself (each category can have many items and each item can be in many categories): <class name=\"NHibernate.Auction.Category, NHibernate.Auction\">    <id name=\"Id\" column=\"ID\"/>    ...    <bag name=\"Items\" table=\"CATEGORY_ITEM\" lazy=\"true\">        <key column=\"CATEGORY_ID\"/>        <many-to-many class=\"NHibernate.Auction.Item, NHibernate.Auction\" column=\"ITEM_ID\"/>    <\/bag><\/class><class name=\"NHibernate.Auction.Item, NHibernate.Auction\">    <id name=\"id\" column=\"ID\"/>    ...    <!-- inverse end -->    <bag name=\"categories\" table=\"CATEGORY_ITEM\" inverse=\"true\" lazy=\"true\">        <key column=\"ITEM_ID\"/>        <many-to-many class=\"NHibernate.Auction.Category, NHibernate.Auction\" column=\"CATEGORY_ID\"/>    <\/bag><\/class> Changes made only to the inverse end of the association are not persisted. This means that NHibernate has two representations in memory for every bidirectional association, one link from A to B and another link from B to A. This is easier to understand if you think about the .NET object model and how we create a many-to-many relationship in C#: category.Items.Add(item);          // The category now \"knows\" about the relationshipitem.Categories.Add(category);     // The item now \"knows\" about the relationshipsession.Update(item);                     // No effect, nothing will be saved!session.Update(category);                 // The relationship will be saved The non-inverse side is used to save the in-memory representation to the database. We would get an unneccessary INSERT/UPDATE and probably even a foreign key violation if both would trigger changes! The same is of course also true for bidirectional one-to-many associations. You may map a bidirectional one-to-many association by mapping a one-to-many association to the same table column(s) as a many-to-one association and declaring the many-valued endinverse=\"true\". <class name=\"Eg.Parent, Eg\">    <id name=\"Id\" column=\"id\"/>    ....    <set name=\"Children\" inverse=\"true\" lazy=\"true\">        <key column=\"parent_id\"/>        <one-to-many class=\"Eg.Child, Eg\"/>    <\/set><\/class><class name=\"Eg.Child, Eg\">    <id name=\"Id\" column=\"id\"/>    ....    <many-to-one name=\"Parent\" class=\"Eg.Parent, Eg\" column=\"parent_id\"/><\/class> Mapping one end of an association with inverse=\"true\" doesn't affect the operation of cascades, both are different concepts! 6.9. Ternary Associations There are two possible approaches to mapping a ternary association. One approach is to use composite elements (discussed below). Another is to use anIDictionary with an association as its index: <map name=\"Contracts\" lazy=\"true\">    <key column=\"employer_id\"/>    <index-many-to-many column=\"employee_id\" class=\"Employee\"/>    <one-to-many class=\"Contract\"/><\/map> <map name=\"Connections\" lazy=\"true\">    <key column=\"node1_id\"/>    <index-many-to-many column=\"node2_id\" class=\"Node\"/>    <many-to-many column=\"connection_id\" class=\"Connection\"/><\/map> 6.10. Heterogeneous Associations The <many-to-any> and <index-many-to-any> elements provide for true heterogeneous associations. These mapping elements work in the same way as the<any> element - and should also be used rarely, if ever. 6.11. Collection examples The previous sections are pretty confusing. So lets look at an example. This class: using System;using System.Collections;namespace Eg        public class Parent    {        private long id;        private ISet children;            public long Id        {            get { return id; }            set { id = value; }        }                private ISet Children        {            get { return children; }            set { children = value; }        }            ....        ....    }} has a collection of Eg.Child instances. If each child has at most one parent, the most natural mapping is a one-to-many association: <hibernate-mapping xmlns=\"urn:nhibernate-mapping-2.2\"    assembly=\"Eg\" namespace=\"Eg\">    <class name=\"Parent\">        <id name=\"Id\">            <generator class=\"sequence\"/>        <\/id>        <set name=\"Children\" lazy=\"true\">            <key column=\"parent_id\"/>            <one-to-many class=\"Child\"/>        <\/set>    <\/class>    <class name=\"Child\">        <id name=\"Id\">            <generator class=\"sequence\"/>        <\/id>        <property name=\"Name\"/>    <\/class><\/hibernate-mapping> This maps to the following table definitions: create table parent ( Id bigint not null primary key )create table child ( Id bigint not null primary key, Name varchar(255), parent_id bigint )alter table child add constraint childfk0 (parent_id) references parent If the parent is required, use a bidirectional one-to-many association: <hibernate-mapping xmlns=\"urn:nhibernate-mapping-2.2\"    assembly=\"Eg\" namespace=\"Eg\">    <class name=\"Parent\">        <id name=\"Id\">            <generator class=\"sequence\"/>        <\/id>        <set name=\"Children\" inverse=\"true\" lazy=\"true\">            <key column=\"parent_id\"/>            <one-to-many class=\"Child\"/>        <\/set>    <\/class>    <class name=\"Child\">        <id name=\"Id\">            <generator class=\"sequence\"/>        <\/id>        <property name=\"Name\"/>        <many-to-one name=\"parent\" class=\"Parent\" column=\"parent_id\" not-null=\"true\"/>    <\/class><\/hibernate-mapping> Notice the NOT NULL constraint: create table parent ( Id bigint not null primary key )create table child ( Id bigint not null                     primary key,                     Name varchar(255),                     parent_id bigint not null )alter table child add constraint childfk0 (parent_id) references parent On the other hand, if a child might have multiple parents, a many-to-many association is appropriate: <hibernate-mapping xmlns=\"urn:nhibernate-mapping-2.2\"    assembly=\"Eg\" namespace=\"Eg\">    <class name=\"Parent\">        <id name=\"Id\">            <generator class=\"sequence\"/>        <\/id>        <set name=\"Children\" lazy=\"true\" table=\"childset\">            <key column=\"parent_id\"/>            <many-to-many class=\"Child\" column=\"child_id\"/>        <\/set>    <\/class>    <class name=\"eg.Child\">        <id name=\"Id\">            <generator class=\"sequence\"/>        <\/id>        <property name=\"Name\"/>    <\/class><\/hibernate-mapping> Table definitions: create table parent ( Id bigint not null primary key )create table child ( Id bigint not null primary key, name varchar(255) )create table childset ( parent_id bigint not null,                        child_id bigint not null,                        primary key ( parent_id, child_id ) )alter table childset add constraint childsetfk0 (parent_id) references parentalter table childset add constraint childsetfk1 (child_id) references child Chapter 7. Component Mapping The notion of a component is re-used in several different contexts, for different purposes, throughout NHibernate. 7.1. Dependent objects A component is a contained object that is persisted as a value type, not an entity. The term \"component\" refers to the object-oriented notion of composition (not to architecture-level components). For example, you might model a person like this: public class Person{    private DateTime birthday;    private Name name;    private string key;        public string Key    {        get { return key; }        set { key = value; }    }        public DateTime Birthday    {        get { return birthday; }        set { birthday = value; }    }    public Name Name    {        get { return name; }        set { name = value; }    }    ......    ......} public class Name{    char initial;    string first;    string last;        public string First    {        get { return first; }        set { first = value; }    }        public string Last    {        get { return last; }        set { last = value; }    }    public char Initial    {        get { return initial; }        set { initial = value; }    }} Now Name may be persisted as a component of Person. Notice that Name defines getter and setter methods for its persistent properties, but doesn't need to declare any interfaces or identifier properties. Our NHibernate mapping would look like: <class name=\"Eg.Person, Eg\" table=\"person\">    <id name=\"Key\" column=\"pid\" type=\"string\">        <generator class=\"uuid.hex\"/>    <\/id>    <property name=\"Birthday\" type=\"date\"/>    <component name=\"Name\" class=\"Eg.Name, Eg\"> <!-- class attribute optional -->        <property name=\"Initial\"/>        <property name=\"First\"/>        <property name=\"Last\"/>    <\/component><\/class> The person table would have the columns pid, Birthday, Initial, First andLast. Like all value types, components do not support shared references. The null value semantics of a component aread hoc. When reloading the containing object, NHibernate will assume that if all component columns are null, then the entire component is null. This should be okay for most purposes. The properties of a component may be of any NHibernate type (collections, many-to-one associations, other components, etc). Nested components shouldnot be considered an exotic usage. NHibernate is intended to support a very fine-grained object model. The <component> element allows a <parent> subelement that maps a property of the component class as a reference back to the containing entity. <class name=\"Eg.Person, Eg\" table=\"person\">    <id name=\"Key\" column=\"pid\" type=\"string\">        <generator class=\"uuid.hex\"/>    <\/id>    <property name=\"Birthday\" type=\"date\"/>    <component name=\"Name\" class=\"Eg.Name, Eg\">        <parent name=\"NamedPerson\"/> <!-- reference back to the Person -->        <property name=\"Initial\"/>        <property name=\"First\"/>        <property name=\"Last\"/>    <\/component><\/class> 7.2. Collections of dependent objects Collections of components are supported (eg. an array of type Name). Declare your component collection by replacing the <element> tag with a <composite-element> tag. <set name=\"SomeNames\" table=\"some_names\" lazy=\"true\">    <key column=\"id\"/>    <composite-element class=\"Eg.Name, Eg\"> <!-- class attribute required -->        <property name=\"Initial\"/>        <property name=\"First\"/>        <property name=\"Last\"/>    <\/composite-element><\/set> Note: if you define an ISet of composite elements, it is very important to implementEquals() andGetHashCode() correctly. Composite elements may contain components but not collections. If your composite element itself contains components, use the<nested-composite-element> tag. This is a pretty exotic case - a collection of components which themselves have components. By this stage you should be asking yourself if a one-to-many association is more appropriate. Try remodelling the composite element as an entity - but note that even though the object model is the same, the relational model and persistence semantics are still slightly different. Please note that a composite element mapping doesn't support null-able properties if you're using a<set>. NHibernate has to use each columns value to identify a record when deleting objects (there is no separate primary key column in the composite element table), which is not possible with null values. You have to either use only not-null properties in a composite-element or choose a<list>,<map>, <bag> or <idbag>. A special case of a composite element is a composite element with a nested <many-to-one> element. A mapping like this allows you to map extra columns of a many-to-many association table to the composite element class. The following is a many-to-many association fromOrder toItem where PurchaseDate, Price and Quantity are properties of the association: <class name=\"Order\" .... >    ....    <set name=\"PurchasedItems\" table=\"purchase_items\" lazy=\"true\">        <key column=\"order_id\">        <composite-element class=\"Purchase\">            <property name=\"PurchaseDate\"/>            <property name=\"Price\"/>            <property name=\"Quantity\"/>            <many-to-one name=\"Item\" class=\"Item\"/> <!-- class attribute is optional -->        <\/composite-element>    <\/set><\/class> Even ternary (or quaternary, etc) associations are possible: <class name=\"Order\" .... >    ....    <set name=\"PurchasedItems\" table=\"purchase_items\" lazy=\"true\">        <key column=\"order_id\">        <composite-element class=\"OrderLine\">            <many-to-one name=\"PurchaseDetails class=\"Purchase\"/>            <many-to-one name=\"Item\" class=\"Item\"/>        <\/composite-element>    <\/set><\/class> Composite elements may appear in queries using the same syntax as associations to other entities. 7.3. Components as IDictionary indices The <composite-index> element lets you map a component class as the key of anIDictionary. Make sure you overrideGetHashCode() and Equals() correctly on the component class. 7.4. Components as composite identifiers You may use a component as an identifier of an entity class. Your component class must satisfy certain requirements: It must be Serializable. It must re-implement Equals() and GetHashCode(), consistently with the database's notion of composite key equality. You can't use an IIdentifierGenerator to generate composite keys. Instead the application must assign its own identifiers. Since a composite identifier must be assigned to the object before saving it, we can't useunsaved-value of the identifier to distinguish between newly instantiated instances and instances saved in a previous session. You may instead implement IInterceptor.IsTransient() if you wish to useSaveOrUpdate() or cascading save / update. As an alternative, you may also set theunsaved-value attribute on a <version> (or<timestamp>) element to specify a value that indicates a new transient instance. In this case, the version of the entity is used instead of the (assigned) identifier and you don't have to implementIInterceptor.IsTransient() yourself. Use the <composite-id> tag (same attributes and elements as<component>) in place of<id> for the declaration of a composite identifier class: <class name=\"Foo\" table=\"FOOS\">    <composite-id name=\"CompId\" class=\"FooCompositeID\">        <key-property name=\"String\"/>        <key-property name=\"Short\"/>        <key-property name=\"Date\" column=\"date_\" type=\"Date\"/>    <\/composite-id>    <property name=\"Name\"/>    ....<\/class> Now, any foreign keys into the table FOOS are also composite. You must declare this in your mappings for other classes. An association toFoo would be declared like this: <many-to-one name=\"Foo\" class=\"Foo\"><!-- the \"class\" attribute is optional, as usual -->    <column name=\"foo_string\"/>    <column name=\"foo_short\"/>    <column name=\"foo_date\"/><\/many-to-one> This new <column> tag is also used by multi-column custom types. Actually it is an alternative to thecolumn attribute everywhere. A collection with elements of typeFoo would use: <set name=\"Foos\">    <key column=\"owner_id\"/>    <many-to-many class=\"Foo\">        <column name=\"foo_string\"/>        <column name=\"foo_short\"/>        <column name=\"foo_date\"/>    <\/many-to-many><\/set> On the other hand, <one-to-many>, as usual, declares no columns. If Foo itself contains collections, they will also need a composite foreign key. <class name=\"Foo\">    ....    ....    <set name=\"Dates\" lazy=\"true\">        <key>   <!-- a collection inherits the composite key type -->            <column name=\"foo_string\"/>            <column name=\"foo_short\"/>            <column name=\"foo_date\"/>        <\/key>        <element column=\"foo_date\" type=\"Date\"/>    <\/set><\/class> 7.5. Dynamic components You may even map a property of type IDictionary: <dynamic-component name=\"UserAttributes\">    <property name=\"Foo\" column=\"FOO\"/>    <property name=\"Bar\" column=\"BAR\"/>    <many-to-one name=\"Baz\" class=\"Baz\" column=\"BAZ\"/><\/dynamic-component> The semantics of a <dynamic-component> mapping are identical to<component>. The advantage of this kind of mapping is the ability to determine the actual properties of the component at deployment time, just by editing the mapping document. (Runtime manipulation of the mapping document is also possible, using a DOM parser.) Chapter 8. Inheritance Mapping 8.1. The Three Strategies NHibernate supports the three basic inheritance mapping strategies. table per class hierarchy table per subclass table per concrete class In addition, NHibernate supports a fourth, slightly different kind of polymorphism: implicit polymorphism It is possible to use different mapping strategies for different branches of the same inheritance hierarchy, and then make use of implicit polymorphism to achieve polymorphism across the whole hierarchy. However, NHibernate does not support mixing<subclass>, and <joined-subclass> and<union-subclass> mappings under the same root<class> element. It is possible to mix together the table per hierarchy and table per subclass strategies, under the the same<class> element, by combining the<subclass> and<join> elements (see below). It is possible to define subclass, union-subclass, and joined-subclass mappings in separate mapping documents, directly beneathhibernate-mapping. This allows you to extend a class hierachy just by adding a new mapping file. You must specify anextends attribute in the subclass mapping, naming a previously mapped superclass.  <hibernate-mapping>     <subclass name=\"DomesticCat\" extends=\"Cat\" discriminator-value=\"D\">          <property name=\"name\" type=\"string\"/>     <\/subclass> <\/hibernate-mapping> 8.1.1. Table per class hierarchy Suppose we have an interface IPayment, with implementorsCreditCardPayment,CashPayment,ChequePayment. The table-per-hierarchy mapping would look like: <class name=\"IPayment\" table=\"PAYMENT\">    <id name=\"Id\" type=\"Int64\" column=\"PAYMENT_ID\">        <generator class=\"native\"/>    <\/id>    <discriminator column=\"PAYMENT_TYPE\" type=\"String\"/>    <property name=\"Amount\" column=\"AMOUNT\"/>    ...    <subclass name=\"CreditCardPayment\" discriminator-value=\"CREDIT\">        ...    <\/subclass>    <subclass name=\"CashPayment\" discriminator-value=\"CASH\">        ...    <\/subclass>    <subclass name=\"ChequePayment\" discriminator-value=\"CHEQUE\">        ...    <\/subclass><\/class> Exactly one table is required. There is one big limitation of this mapping strategy: columns declared by the subclasses may not haveNOT NULL constraints. 8.1.2. Table per subclass A table-per-subclass mapping would look like: <class name=\"IPayment\" table=\"PAYMENT\">    <id name=\"Id\" type=\"Int64\" column=\"PAYMENT_ID\">        <generator class=\"native\"/>    <\/id>    <property name=\"Amount\" column=\"AMOUNT\"/>    ...    <joined-subclass name=\"CreditCardPayment\" table=\"CREDIT_PAYMENT\">        <key column=\"PAYMENT_ID\"/>        ...    <\/joined-subclass>    <joined-subclass name=\"CashPayment\" table=\"CASH_PAYMENT\">        <key column=\"PAYMENT_ID\"/>        ...    <\/joined-subclass>    <joined-subclass name=\"ChequePayment\" table=\"CHEQUE_PAYMENT\">        <key column=\"PAYMENT_ID\"/>        ...    <\/joined-subclass><\/class> Four tables are required. The three subclass tables have primary key associations to the superclass table (so the relational model is actually a one-to-one association). 8.1.3. Table per subclass, using a discriminator Note that NHibernate's implementation of table-per-subclass requires no discriminator column. Other object/relational mappers use a different implementation of table-per-subclass which requires a type discriminator column in the superclass table. The approach taken by NHibernate is much more difficult to implement but arguably more correct from a relational point of view. If you would like to use a discriminator column with the table per subclass strategy, you may combine the use of<subclass> and <join>, as follow: <class name=\"Payment\" table=\"PAYMENT\">    <id name=\"Id\" type=\"Int64\" column=\"PAYMENT_ID\">        <generator class=\"native\"/>    <\/id>    <discriminator column=\"PAYMENT_TYPE\" type=\"string\"/>    <property name=\"Amount\" column=\"AMOUNT\"/>    ...    <subclass name=\"CreditCardPayment\" discriminator-value=\"CREDIT\">        <join table=\"CREDIT_PAYMENT\">            <key column=\"PAYMENT_ID\"/>            <property name=\"CreditCardType\" column=\"CCTYPE\"/>            ...        <\/join>    <\/subclass>    <subclass name=\"CashPayment\" discriminator-value=\"CASH\">        <join table=\"CASH_PAYMENT\">            <key column=\"PAYMENT_ID\"/>            ...        <\/join>    <\/subclass>    <subclass name=\"ChequePayment\" discriminator-value=\"CHEQUE\">        <join table=\"CHEQUE_PAYMENT\" fetch=\"select\">            <key column=\"PAYMENT_ID\"/>            ...        <\/join>    <\/subclass><\/class> The optional fetch=\"select\" declaration tells NHibernate not to fetch theChequePayment subclass data using an outer join when querying the superclass. 8.1.4. Mixing table per class hierarchy with table per subclass You may even mix the table per hierarchy and table per subclass strategies using this approach: <class name=\"Payment\" table=\"PAYMENT\">    <id name=\"Id\" type=\"Int64\" column=\"PAYMENT_ID\">        <generator class=\"native\"/>    <\/id>    <discriminator column=\"PAYMENT_TYPE\" type=\"string\"/>    <property name=\"Amount\" column=\"AMOUNT\"/>    ...    <subclass name=\"CreditCardPayment\" discriminator-value=\"CREDIT\">        <join table=\"CREDIT_PAYMENT\">            <property name=\"CreditCardType\" column=\"CCTYPE\"/>            ...        <\/join>    <\/subclass>    <subclass name=\"CashPayment\" discriminator-value=\"CASH\">        ...    <\/subclass>    <subclass name=\"ChequePayment\" discriminator-value=\"CHEQUE\">        ...    <\/subclass><\/class> For any of these mapping strategies, a polymorphic association to IPayment is mapped using <many-to-one>. <many-to-one name=\"Payment\" column=\"PAYMENT\" class=\"IPayment\"/> 8.1.5. Table per concrete class There are two ways we could go about mapping the table per concrete class strategy. The first is to use<union-subclass>. <class name=\"Payment\">    <id name=\"Id\" type=\"Int64\" column=\"PAYMENT_ID\">        <generator class=\"sequence\"/>    <\/id>    <property name=\"Amount\" column=\"AMOUNT\"/>    ...    <union-subclass name=\"CreditCardPayment\" table=\"CREDIT_PAYMENT\">        <property name=\"CreditCardType\" column=\"CCTYPE\"/>        ...    <\/union-subclass>    <union-subclass name=\"CashPayment\" table=\"CASH_PAYMENT\">        ...    <\/union-subclass>    <union-subclass name=\"ChequePayment\" table=\"CHEQUE_PAYMENT\">        ...    <\/union-subclass><\/class> Three tables are involved for the subclasses. Each table defines columns for all properties of the class, including inherited properties. The limitation of this approach is that if a property is mapped on the superclass, the column name must be the same on all subclass tables. (We might relax this in a future release of NHibernate.) The identity generator strategy is not allowed in union subclass inheritance, indeed the primary key seed has to be shared accross all unioned subclasses of a hierarchy. If your superclass is abstract, map it with abstract=\"true\". Of course, if it is not abstract, an additional table (defaults toPAYMENT in the example above) is needed to hold instances of the superclass. 8.1.6. Table per concrete class, using implicit polymorphism An alternative approach is to make use of implicit polymorphism: <class name=\"CreditCardPayment\" table=\"CREDIT_PAYMENT\">    <id name=\"Id\" type=\"Int64\" column=\"CREDIT_PAYMENT_ID\">        <generator class=\"native\"/>    <\/id>    <property name=\"Amount\" column=\"CREDIT_AMOUNT\"/>    ...<\/class><class name=\"CashPayment\" table=\"CASH_PAYMENT\">    <id name=\"Id\" type=\"Int64\" column=\"CASH_PAYMENT_ID\">        <generator class=\"native\"/>    <\/id>    <property name=\"Amount\" column=\"CASH_AMOUNT\"/>    ...<\/class><class name=\"ChequePayment\" table=\"CHEQUE_PAYMENT\">    <id name=\"Id\" type=\"Int64\" column=\"CHEQUE_PAYMENT_ID\">        <generator class=\"native\"/>    <\/id>    <property name=\"Amount\" column=\"CHEQUE_AMOUNT\"/>    ...<\/class> Notice that nowhere do we mention the IPayment interface explicitly. Also notice that properties ofIPayment are mapped in each of the subclasses. If you want to avoid duplication, consider using XML entities (e.g.[ <!ENTITY allproperties SYSTEM \"allproperties.xml\"> ] in theDOCTYPE declartion and&allproperties; in the mapping). The disadvantage of this approach is that NHibernate does not generate SQL UNIONs when performing polymorphic queries. For this mapping strategy, a polymorphic association to IPayment is usually mapped using<any>. <any name=\"Payment\" meta-type=\"string\" id-type=\"Int64\">    <meta-value value=\"CREDIT\" class=\"CreditCardPayment\"/>    <meta-value value=\"CASH\" class=\"CashPayment\"/>    <meta-value value=\"CHEQUE\" class=\"ChequePayment\"/>    <column name=\"PAYMENT_CLASS\"/>    <column name=\"PAYMENT_ID\"/><\/any> 8.1.7. Mixing implicit polymorphism with other inheritance mappings There is one further thing to notice about this mapping. Since the subclasses are each mapped in their own<class> element (and sinceIPayment is just an interface), each of the subclasses could easily be part of another table-per-class or table-per-subclass inheritance hierarchy! (And you can still use polymorphic queries against theIPayment interface.) <class name=\"CreditCardPayment\" table=\"CREDIT_PAYMENT\">    <id name=\"Id\" type=\"Int64\" column=\"CREDIT_PAYMENT_ID\">        <generator class=\"native\"/>    <\/id>    <discriminator column=\"CREDIT_CARD\" type=\"String\"/>    <property name=\"Amount\" column=\"CREDIT_AMOUNT\"/>    ...    <subclass name=\"MasterCardPayment\" discriminator-value=\"MDC\"/>    <subclass name=\"VisaPayment\" discriminator-value=\"VISA\"/><\/class><class name=\"NonelectronicTransaction\" table=\"NONELECTRONIC_TXN\">    <id name=\"Id\" type=\"Int64\" column=\"TXN_ID\">        <generator class=\"native\"/>    <\/id>    ...    <joined-subclass name=\"CashPayment\" table=\"CASH_PAYMENT\">        <key column=\"PAYMENT_ID\"/>        <property name=\"Amount\" column=\"CASH_AMOUNT\"/>        ...    <\/joined-subclass>    <joined-subclass name=\"ChequePayment\" table=\"CHEQUE_PAYMENT\">        <key column=\"PAYMENT_ID\"/>        <property name=\"Amount\" column=\"CHEQUE_AMOUNT\"/>        ...    <\/joined-subclass><\/class> Once again, we don't mention IPayment explicitly. If we execute a query against theIPayment interface - for example,from IPayment - NHibernate automatically returns instances ofCreditCardPayment (and its subclasses, since they also implementIPayment),CashPayment and ChequePayment but not instances ofNonelectronicTransaction. 8.2. Limitations There are certain limitations to the \"implicit polymorphism\" approach to the table per concrete-class mapping strategy. There are somewhat less restrictive limitations to<union-subclass> mappings. The following table shows the limitations of table per concrete-class mappings, and of implicit polymorphism, in NHibernate. Table 8.1. Features of inheritance mappings Inheritance strategy Polymorphic many-to-one Polymorphic one-to-one Polymorphic one-to-many Polymorphic many-to-many Polymorphic load()/get() Polymorphic queries Polymorphic joins Outer join fetching table per class-hierarchy <many-to-one> <one-to-one> <one-to-many> <many-to-many> s.Get(typeof(IPayment), id) from IPayment p from Order o join o.Payment p supported table per subclass <many-to-one> <one-to-one> <one-to-many> <many-to-many> s.Get(typeof(IPayment), id) from IPayment p from Order o join o.Payment p supported table per concrete-class (union-subclass) <many-to-one> <one-to-one> <one-to-many> (for inverse=\"true\" only) <many-to-many> s.Get(typeof(IPayment), id) from IPayment p from Order o join o.Payment p supported table per concrete class (implicit polymorphism) <any> not supported not supported <many-to-any> use a query from IPayment p not supported not supported Chapter 9. Manipulating Persistent Data 9.1. Creating a persistent object An object (entity instance) is either transient orpersistent with respect to a particularISession. Newly instantiated objects are, of course, transient. The session offers services for saving (ie. persisting) transient instances: DomesticCat fritz = new DomesticCat();fritz.Color = Color.Ginger;fritz.Sex = 'M';fritz.Name = \"Fritz\";long generatedId = (long) sess.Save(fritz); DomesticCat pk = new DomesticCat();pk.Color = Color.Tabby;pk.Sex = 'F';pk.Name = \"PK\";pk.Kittens = new HashSet();pk.AddKitten(fritz);sess.Save( pk, 1234L ); The single-argument Save() generates and assigns a unique identifier tofritz. The two-argument form attempts to persistpk using the given identifier. We generally discourage the use of the two-argument form since it may be used to create primary keys with business meaning. Associated objects may be made persistent in any order you like unless you have aNOT NULL constraint upon a foreign key column. There is never a risk of violating foreign key constraints. However, you might violate aNOT NULL constraint if you Save() the objects in the wrong order. 9.2. Loading an object The Load() methods of ISession give you a way to retrieve a persistent instance if you already know its identifier. One version takes a class object and will load the state into a newly instantiated object. The second version allows you to supply an instance into which the state will be loaded. The form which takes an instance is only useful in special circumstances (DIY instance pooling etc.) Cat fritz = (Cat) sess.Load(typeof(Cat), generatedId); long pkId = 1234;DomesticCat pk = (DomesticCat) sess.Load( typeof(Cat), pkId ); Cat cat = new DomesticCat();// load pk's state into catsess.Load( cat, pkId );ISet kittens = cat.Kittens; Note that Load() will throw an unrecoverable exception if there is no matching database row. If the class is mapped with a proxy,Load() returns an object that is an uninitialized proxy and does not actually hit the database until you invoke a method of the object. This behaviour is very useful if you wish to create an association to an object without actually loading it from the database. If you are not certain that a matching row exists, you should use the Get() method, which hits the database immediately and returns null if there is no matching row. Cat cat = (Cat) sess.Get(typeof(Cat), id);if (cat==null) {    cat = new Cat();    sess.Save(cat, id);}return cat; You may also load an objects using an SQL SELECT ... FOR UPDATE. See the next section for a discussion of NHibernateLockModes. Cat cat = (Cat) sess.Get(typeof(Cat), id, LockMode.Upgrade); Note that any associated instances or contained collections are not selected FOR UPDATE. It is possible to re-load an object and all its collections at any time, using theRefresh() method. This is useful when database triggers are used to initialize some of the properties of the object. sess.Save(cat);sess.Flush(); //force the SQL INSERTsess.Refresh(cat); //re-read the state (after the trigger executes) An important question usually appears at this point: How much does NHibernate load from the database and how many SQLSELECTs will it use? This depends on thefetching strategy and is explained in Section 19.1, “Fetching strategies”. 9.3. Querying If you don't know the identifier(s) of the object(s) you are looking for, use theFind()methods of ISession. NHibernate supports a simple but powerful object oriented query language. IList cats = sess.Find(    \"from Cat as cat where cat.Birthdate = ?\",    date,    NHibernateUtil.Date);IList mates = sess.Find(    \"select mate from Cat as cat join cat.Mate as mate \" +    \"where cat.name = ?\",    name,    NHibernateUtil.String);IList cats = sess.Find( \"from Cat as cat where cat.Mate.Birthdate is null\" );IList moreCats = sess.Find(    \"from Cat as cat where \" +     \"cat.Name = 'Fritz' or cat.id = ? or cat.id = ?\",    new object[] { id1, id2 },    new IType[] { NHibernateUtil.Int64, NHibernateUtil.Int64 });IList mates = sess.Find(    \"from Cat as cat where cat.Mate = ?\",    izi,    NHibernateUtil.Entity(typeof(Cat)));IList problems = sess.Find(    \"from GoldFish as fish \" +    \"where fish.Birthday > fish.Deceased or fish.Birthday is null\"); The second argument to Find() accepts an object or array of objects. The third argument accepts a NHibernate type or array of NHibernate types. These given types are used to bind the given objects to the? query placeholders (which map to input parameters of an ADO.NETIDbCommand). Just as in ADO.NET, you should use this binding mechanism in preference to string manipulation. The NHibernateUtil class defines a number of static methods and constants, providing access to most of the built-in types, as instances ofNHibernate.Type.IType. If you expect your query to return a very large number of objects, but you don't expect to use them all, you might get better performance from theEnumerable() methods, which return aSystem.Collections.IEnumerable. The iterator will load objects on demand, using the identifiers returned by an initial SQL query (n+1 selects total). // fetch idsIEnumerable en = sess.Enumerable(\"from eg.Qux q order by q.Likeliness\"); foreach ( Qux qux in en ){    // something we couldnt express in the query    if ( qux.CalculateComplicatedAlgorithm() ) {        // dont need to process the rest        break;    }} The Enumerable() method also performs better if you expect that many of the objects are already loaded and cached by the session, or if the query results contain the same objects many times. (When no data is cached or repeated,Find() is almost always faster.) Heres an example of a query that should be called usingEnumerable(): IEnumerable en = sess.Enumerable(    \"select customer, product \" +     \"from Customer customer, \" +    \"Product product \" +    \"join customer.Purchases purchase \" +    \"where product = purchase.Product\"); Calling the previous query using Find() would return a very large ADO.NET result set containing the same data many times. NHibernate queries sometimes return tuples of objects, in which case each tuple is returned as an array: IEnumerable foosAndBars = sess.Enumerable(    \"select foo, bar from Foo foo, Bar bar \" +    \"where bar.Date = foo.Date\");foreach (object[] tuple in foosAndBars){    Foo foo = tuple[0]; Bar bar = tuple[1];    ....} 9.3.1. Scalar queries Queries may specify a property of a class in the select clause. They may even call SQL aggregate functions. Properties or aggregates are considered \"scalar\" results. IEnumerable results = sess.Enumerable(        \"select cat.Color, min(cat.Birthdate), count(cat) from Cat cat \" +        \"group by cat.Color\");foreach ( object[] row in results ){    Color type = (Color) row[0];    DateTime oldest = (DateTime) row[1];    int count = (int) row[2];    .....} IEnumerable en = sess.Enumerable(    \"select cat.Type, cat.Birthdate, cat.Name from DomesticCat cat\"); IList list = sess.Find(    \"select cat, cat.Mate.Name from DomesticCat cat\"); 9.3.2. The IQuery interface If you need to specify bounds upon your result set (the maximum number of rows you want to retrieve and / or the first row you want to retrieve) you should obtain an instance ofNHibernate.IQuery: IQuery q = sess.CreateQuery(\"from DomesticCat cat\");q.SetFirstResult(20);q.SetMaxResults(10);IList cats = q.List(); You may even define a named query in the mapping document. (Remember to use a CDATA section if your query contains characters that could be interpreted as markup.) <query name=\"Eg.DomesticCat.by.name.and.minimum.weight\"><![CDATA[    from Eg.DomesticCat as cat        where cat.Name = ?        and cat.Weight > ?] ]><\/query> IQuery q = sess.GetNamedQuery(\"Eg.DomesticCat.by.name.and.minimum.weight\");q.SetString(0, name);q.SetInt32(1, minWeight);IList cats = q.List(); The query interface supports the use of named parameters. Named parameters are identifiers of the form:name in the query string. There are methods onIQuery for binding values to named or positional parameters. NHibernate numbers parameters from zero. The advantages of named parameters are: named parameters are insensitive to the order they occur in the query string they may occur multiple times in the same query they are self-documenting //named parameter (preferred)IQuery q = sess.CreateQuery(\"from DomesticCat cat where cat.Name = :name\");q.SetString(\"name\", \"Fritz\");IEnumerable cats = q.Enumerable(); //positional parameterIQuery q = sess.CreateQuery(\"from DomesticCat cat where cat.Name = ?\");q.SetString(0, \"Izi\");IEnumerable cats = q.Enumerable(); //named parameter listIList names = new ArrayList();names.Add(\"Izi\");names.Add(\"Fritz\");IQuery q = sess.CreateQuery(\"from DomesticCat cat where cat.Name in (:namesList)\");q.SetParameterList(\"namesList\", names);IList cats = q.List(); 9.3.3. Filtering collections A collection filter is a special type of query that may be applied to a persistent collection or array. The query string may refer tothis, meaning the current collection element. ICollection blackKittens = session.Filter(    pk.Kittens, \"where this.Color = ?\", Color.Black, NHibernateUtil.Enum(typeof(Color))); The returned collection is considered a bag. Observe that filters do not require a from clause (though they may have one if required). Filters are not limited to returning the collection elements themselves. ICollection blackKittenMates = session.Filter(    pk.Kittens, \"select this.Mate where this.Color = Eg.Color.Black\"); 9.3.4. Criteria queries HQL is extremely powerful but some people prefer to build queries dynamically, using an object oriented API, rather than embedding strings in their .NET code. For these people, NHibernate provides an intuitiveICriteria query API. ICriteria crit = session.CreateCriteria(typeof(Cat));crit.Add( Expression.Eq(\"color\", Eg.Color.Black) );crit.SetMaxResults(10);IList cats = crit.List(); If you are uncomfortable with SQL-like syntax, this is perhaps the easiest way to get started with NHibernate. This API is also more extensible than HQL. Applications might provide their own implementations of theICriterion interface. 9.3.5. Queries in native SQL You may express a query in SQL, using CreateSQLQuery(). You must enclose SQL aliases in braces. IList cats = session.CreateSQLQuery(    \"SELECT {cat.*} FROM CAT {cat} WHERE ROWNUM<10\",    \"cat\",    typeof(Cat)).List(); IList cats = session.CreateSQLQuery(    \"SELECT {cat}.ID AS {cat.Id}, {cat}.SEX AS {cat.Sex}, \" +           \"{cat}.MATE AS {cat.Mate}, {cat}.SUBCLASS AS {cat.class}, ... \" +    \"FROM CAT {cat} WHERE ROWNUM<10\",    \"cat\",    typeof(Cat)).List() SQL queries may contain named and positional parameters, just like NHibernate queries. 9.4. Updating objects 9.4.1. Updating in the same ISession Transactional persistent instances (ie. objects loaded, saved, created or queried by theISession) may be manipulated by the application and any changes to persistent state will be persisted when theISession is flushed (discussed later in this chapter). So the most straightforward way to update the state of an object is toLoad() it, and then manipulate it directly, while the ISession is open: DomesticCat cat = (DomesticCat) sess.Load( typeof(Cat), 69L );cat.Name = \"PK\";sess.Flush();  // changes to cat are automatically detected and persisted Sometimes this programming model is inefficient since it would require both an SQLSELECT (to load an object) and an SQLUPDATE (to persist its updated state) in the same session. Therefore NHibernate offers an alternate approach. 9.4.2. Updating detached objects Many applications need to retrieve an object in one transaction, send it to the UI layer for manipulation, then save the changes in a new transaction. (Applications that use this kind of approach in a high-concurrency environment usually use versioned data to ensure transaction isolation.) This approach requires a slightly different programming model to the one described in the last section. NHibernate supports this model by providing the methodSession.Update(). // in the first sessionCat cat = (Cat) firstSession.Load(typeof(Cat), catId);Cat potentialMate = new Cat();firstSession.Save(potentialMate);// in a higher tier of the applicationcat.Mate = potentialMate;// later, in a new sessionsecondSession.Update(cat);  // update catsecondSession.Update(mate); // update mate If the Cat with identifier catId had already been loaded bysecondSession when the application tried to update it, an exception would have been thrown. The application should individually Update() transient instances reachable from the given transient instance if andonly if it wants their state also updated. (Except for lifecycle objects, discussed later.) NHibernate users have requested a general purpose method that either saves a transient instance by generating a new identifier or update the persistent state associated with its current identifier. TheSaveOrUpdate() method now implements this functionality. NHibernate distinguishes \"new\" (unsaved) instances from \"existing\" (saved or loaded in a previous session) instances by the value of their identifier (or version, or timestamp) property. Theunsaved-value attribute of the<id> (or<version>, or <timestamp>) mapping specifies which values should be interpreted as representing a \"new\" instance. <id name=\"Id\" type=\"Int64\" column=\"uid\" unsaved-value=\"0\">    <generator class=\"hilo\"/><\/id> The allowed values of unsaved-value are: any - always save none - always update null - save when identifier is null valid identifier value - save when identifier is null or the given value undefined - if set for version ortimestamp, then identifier check is used If unsaved-value is not specified for a class, NHibernate will attempt to guess it by creating an instance of the class using the no-argument constructor and reading the property value from the instance. // in the first sessionCat cat = (Cat) firstSession.Load(typeof(Cat), catID);// in a higher tier of the applicationCat mate = new Cat();cat.Mate = mate;// later, in a new sessionsecondSession.SaveOrUpdate(cat);   // update existing state (cat has a non-null id)secondSession.SaveOrUpdate(mate);  // save the new instance (mate has a null id) The usage and semantics of SaveOrUpdate() seems to be confusing for new users. Firstly, so long as you are not trying to use instances from one session in another new session, you should not need to useUpdate() or SaveOrUpdate(). Some whole applications will never use either of these methods. Usually Update() or SaveOrUpdate() are used in the following scenario: the application loads an object in the first session the object is passed up to the UI tier some modifications are made to the object the object is passed back down to the business logic tier the application persists these modifications by calling Update() in a second session SaveOrUpdate() does the following: if the object is already persistent in this session, do nothing if the object has no identifier property, Save() it if the object's identifier matches the criteria specified by unsaved-value, Save() it if the object is versioned (version or timestamp), then the version will take precedence to identifier check, unless the versionsunsaved-value=\"undefined\" (default value) if another object associated with the session has the same identifier, throw an exception The last case can be avoided by using Merge(Object o). This method copies the state of the given object onto the persistent object with the same identifier. If there is no persistent instance currently associated with the session, it will be loaded. The method returns the persistent instance. If the given instance is unsaved or does not exist in the database, NHibernate will save it and return it as a newly persistent instance. Otherwise, the given instance does not become associated with the session. In most applications with detached objects, you need both methods,SaveOrUpdate() andMerge(). 9.4.3. Reattaching detached objects The Lock() method allows the application to reassociate an unmodified object with a new session. //just reassociate:sess.Lock(fritz, LockMode.None);//do a version check, then reassociate:sess.Lock(izi, LockMode.Read);//do a version check, using SELECT ... FOR UPDATE, then reassociate:sess.Lock(pk, LockMode.Upgrade); 9.5. Deleting persistent objects ISession.Delete() will remove an object's state from the database. Of course, your application might still hold a reference to it. So it's best to think ofDelete() as making a persistent instance transient. sess.Delete(cat); You may also delete many objects at once by passing a NHibernate query string toDelete(). You may now delete objects in any order you like, without risk of foreign key constraint violations. Of course, it is still possible to violate aNOT NULL constraint on a foreign key column by deleting objects in the wrong order. 9.6. Flush From time to time the ISession will execute the SQL statements needed to synchronize the ADO.NET connection's state with the state of objects held in memory. This process,flush, occurs by default at the following points from some invocations of Find() or Enumerable() from NHibernate.ITransaction.Commit() from ISession.Flush() The SQL statements are issued in the following order all entity insertions, in the same order the corresponding objects were saved usingISession.Save() all entity updates all collection deletions all collection element deletions, updates and insertions all collection insertions all entity deletions, in the same order the corresponding objects were deleted usingISession.Delete() (An exception is that objects using native ID generation are inserted when they are saved.) Except when you explicity Flush(), there are absolutely no guarantees aboutwhen theSession executes the ADO.NET calls, only theorder in which they are executed. However, NHibernate does guarantee that theISession.Find(..) methods will never return stale data; nor will they return the wrong data. It is possible to change the default behavior so that flush occurs less frequently. TheFlushMode class defines three different modes: only flush at commit time (and only when the NHibernateITransaction API is used), flush automatically using the explained routine (will only work inside an explicit NHibernateITransaction), or never flush unlessFlush() is called explicitly. The last mode is useful for long running units of work, where an ISession is kept open and disconnected for a long time (seeSection 11.4, “Optimistic concurrency control”). sess = sf.OpenSession();ITransaction tx = sess.BeginTransaction();sess.FlushMode = FlushMode.Commit; //allow queries to return stale stateCat izi = (Cat) sess.Load(typeof(Cat), id);izi.Name = \"iznizi\";// execute some queries....sess.Find(\"from Cat as cat left outer join cat.Kittens kitten\");//change to izi is not flushed!...tx.Commit(); //flush occurs 9.7. Ending a Session Ending a session involves four distinct phases: flush the session commit the transaction close the session handle exceptions 9.7.1. Flushing the Session If you happen to be using the ITransaction API, you don't need to worry about this step. It will be performed implicitly when the transaction is committed. Otherwise you should callISession.Flush() to ensure that all changes are synchronized with the database. 9.7.2. Committing the database transaction If you are using the NHibernate ITransaction API, this looks like: tx.Commit(); // flush the session and commit the transaction If you are managing ADO.NET transactions yourself you should manually Commit() the ADO.NET transaction. sess.Flush();currentTransaction.Commit(); If you decide not to commit your changes: tx.Rollback();  // rollback the transaction or: currentTransaction.Rollback(); If you rollback the transaction you should immediately close and discard the current session to ensure that NHibernate's internal state is consistent. 9.7.3. Closing the ISession A call to ISession.Close() marks the end of a session. The main implication ofClose() is that the ADO.NET connection will be relinquished by the session. tx.Commit();sess.Close(); sess.Flush();currentTransaction.Commit();sess.Close(); If you provided your own connection, Close() returns a reference to it, so you can manually close it or return it to the pool. OtherwiseClose()returns it to the pool. 9.8. Exception handling NHibernate use might lead to exceptions, usually HibernateException. This exception can have a nested inner exception (the root cause), use theInnerException property to access it. If the ISession throws an exception you should immediately rollback the transaction, callISession.Close() and discard theISession instance. Certain methods ofISession willnot leave the session in a consistent state. For exceptions thrown by the data provider while interacting with the database, NHibernate will wrap the error in an instance ofADOException. The underlying exception is accessible by callingADOException.InnerException. NHibernate converts the DbException into an appropriate ADOException subclass using the ISQLExceptionConverter attached to the SessionFactory. By default, the ISQLExceptionConverter is defined by the configured dialect; however, it is also possible to plug in a custom implementation (see the api-docs for the ISQLExceptionConverter class for details). The following exception handling idiom shows the typical case in NHibernate applications: using (ISession sess = factory.OpenSession())using (ITransaction tx = sess.BeginTransaction()){    // do some work    ...    tx.Commit();} Or, when manually managing ADO.NET transactions: ISession sess = factory.openSession();try{    // do some work    ...    sess.Flush();    currentTransaction.Commit();}catch (Exception e){    currentTransaction.Rollback();    throw;}finally{    sess.Close();} 9.9. Lifecyles and object graphs To save or update all objects in a graph of associated objects, you must either Save(), SaveOrUpdate() or Update() each individual object OR map associated objects using cascade=\"all\" or cascade=\"save-update\". Likewise, to delete all objects in a graph, either Delete() each individual object OR map associated objects using cascade=\"all\", cascade=\"all-delete-orphan\" or cascade=\"delete\". Recommendation: If the child object's lifespan is bounded by the lifespan of the of the parent object make it alifecycle object by specifyingcascade=\"all\". Otherwise, Save() and Delete() it explicitly from application code. If you really want to save yourself some extra typing, usecascade=\"save-update\" and explicitDelete(). Mapping an association (many-to-one, or collection) with cascade=\"all\" marks the association as aparent/child style relationship where save/update/deletion of the parent results in save/update/deletion of the child(ren). Futhermore, a mere reference to a child from a persistent parent will result in save / update of the child. The metaphor is incomplete, however. A child which becomes unreferenced by its parent isnot automatically deleted, except in the case of a<one-to-many> association mapped withcascade=\"all-delete-orphan\". The precise semantics of cascading operations are as follows: If a parent is saved, all children are passed to SaveOrUpdate() If a parent is passed to Update() or SaveOrUpdate(), all children are passed to SaveOrUpdate() If a transient child becomes referenced by a persistent parent, it is passed toSaveOrUpdate() If a parent is deleted, all children are passed to Delete() If a transient child is dereferenced by a persistent parent, nothing special happens (the application should explicitly delete the child if necessary) unlesscascade=\"all-delete-orphan\", in which case the \"orphaned\" child is deleted. NHibernate does not fully implement \"persistence by reachability\", which would imply (inefficient) persistent garbage collection. However, due to popular demand, NHibernate does support the notion of entities becoming persistent when referenced by another persistent object. Associations marked cascade=\"save-update\" behave in this way. If you wish to use this approach throughout your application, it's easier to specify thedefault-cascade attribute of the<hibernate-mapping> element. 9.10. Interceptors The IInterceptor interface provides callbacks from the session to the application allowing the application to inspect and / or manipulate properties of a persistent object before it is saved, updated, deleted or loaded. One possible use for this is to track auditing information. For example, the following IInterceptor automatically sets the CreateTimestamp when anIAuditable is created and updates theLastUpdateTimestamp property when an IAuditable is updated. using System;using NHibernate.Type;namespace NHibernate.Test{    [Serializable]    public class AuditInterceptor : IInterceptor    {            private int updates;        private int creates;            public void OnDelete(object entity,                             object id,                             object[] state,                             string[] propertyNames,                             IType[] types)        {            // do nothing        }            public boolean OnFlushDirty(object entity,                                     object id,                                     object[] currentState,                                    object[] previousState,                                    string[] propertyNames,                                    IType[] types) {                if ( entity is IAuditable )            {                updates++;                for ( int i=0; i < propertyNames.Length; i++ )                {                    if ( \"LastUpdateTimestamp\" == propertyNames[i] )                    {                        currentState[i] = DateTime.Now;                        return true;                    }                }            }            return false;        }            public boolean OnLoad(object entity,                               object id,                              object[] state,                              string[] propertyNames,                              IType[] types)        {            return false;        }            public boolean OnSave(object entity,                              object id,                              object[] state,                              string[] propertyNames,                              IType[] types)        {            if ( entity is IAuditable )            {                creates++;                for ( int i=0; i<propertyNames.Length; i++ )                {                    if ( \"CreateTimestamp\" == propertyNames[i] )                    {                        state[i] = DateTime.Now;                        return true;                    }                }            }            return false;        }            public void PostFlush(ICollection entities)        {            Console.Out.WriteLine(\"Creations: {0}, Updates: {1}\", creates, updates);        }            public void PreFlush(ICollection entities) {            updates=0;            creates=0;        }                ......        ......    }} The interceptor would be specified when a session is created. ISession session = sf.OpenSession( new AuditInterceptor() ); You may also set an interceptor on a global level, using the Configuration: new Configuration().SetInterceptor( new AuditInterceptor() ); 9.11. Metadata API NHibernate requires a very rich meta-level model of all entity and value types. From time to time, this model is very useful to the application itself. For example, the application might use NHibernate's metadata to implement a \"smart\" deep-copy algorithm that understands which objects should be copied (eg. mutable value types) and which should not (eg. immutable value types and, possibly, associated entities). NHibernate exposes metadata via the IClassMetadata andICollectionMetadata interfaces and theIType hierarchy. Instances of the metadata interfaces may be obtained from theISessionFactory. Cat fritz = ......;IClassMetadata catMeta = sessionfactory.GetClassMetadata(typeof(Cat));long id = (long) catMeta.GetIdentifier(fritz);object[] propertyValues = catMeta.GetPropertyValues(fritz);string[] propertyNames = catMeta.PropertyNames;IType[] propertyTypes = catMeta.PropertyTypes;// get an IDictionary of all properties which are not collections or associations// TODO: what about components?IDictionary namedValues = new Hashtable();for ( int i=0; i<propertyNames.Length; i++ ){    if ( !propertyTypes[i].IsEntityType && !propertyTypes[i].IsCollectionType )\t{        namedValues[ propertyNames[i] ] = propertyValues[i];    }} Chapter 10. Read-only entities Important NHibernate's treatment of read-only entities may differ from what you may have encountered elsewhere. Incorrect usage may cause unexpected results. When an entity is read-only: NHibernate does not dirty-check the entity's simple properties or single-ended associations; NHibernate will not update simple properties or updatable single-ended associations; NHibernate will not update the version of the read-only entity if only simple properties or single-ended updatable associations are changed; In some ways, NHibernate treats read-only entities the same as entities that are not read-only: NHibernate cascades operations to associations as defined in the entity mapping. NHibernate updates the version if the entity has a collection with changes that dirties the entity; A read-only entity can be deleted. Even if an entity is not read-only, its collection association can be affected if it contains a read-only entity. For details about the affect of read-only entities on different property and association types, seeSection 10.2, “Read-only affect on property type”. For details about how to make entities read-only, see Section 10.1, “Making persistent entities read-only” NHibernate does some optimizing for read-only entities: It saves execution time by not dirty-checking simple properties or single-ended associations. It saves memory by deleting database snapshots. 10.1. Making persistent entities read-only Only persistent entities can be made read-only. Transient and detached entities must be put in persistent state before they can be made read-only. NHibernate provides the following ways to make persistent entities read-only: you can map an entity class as immutable; when an entity of an immutable class is made persistent, NHibernate automatically makes it read-only. seeSection 10.1.1, “Entities of immutable classes” for details you can change a default so that entities loaded into the session by NHibernate are automatically made read-only; seeSection 10.1.2, “Loading persistent entities as read-only” for details you can make an HQL query or criteria read-only so that entities loaded when the query or criteria executes, or iterates, are automatically made read-only; seeSection 10.1.3, “Loading read-only entities from an HQL query/criteria” for details you can make a persistent entity that is already in the in the session read-only; seeSection 10.1.4, “Making a persistent entity read-only” for details 10.1.1. Entities of immutable classes When an entity instance of an immutable class is made persistent, NHibernate automatically makes it read-only. An entity of an immutable class can created and deleted the same as an entity of a mutable class. NHibernate treats a persistent entity of an immutable class the same way as a read-only persistent entity of a mutable class. The only exception is that NHibernate will not allow an entity of an immutable class to be changed so it is not read-only. 10.1.2. Loading persistent entities as read-only Note Entities of immutable classes are automatically loaded as read-only. To change the default behavior so NHibernate loads entity instances of mutable classes into the session and automatically makes them read-only, call: Session.DefaultReadOnly = true; To change the default back so entities loaded by NHibernate are not made read-only, call: Session.DefaultReadOnly = false; You can determine the current setting by using the property: Session.DefaultReadOnly; If Session.DefaultReadOnly property returns true, entities loaded by the following are automatically made read-only: Session.Load() and Session.Load<T> Session.Get() and Session.Get<T> Session.Merge() executing, or iterating HQL queries and criteria; to override this setting for a particular HQL query or criteria seeSection 10.1.3, “Loading read-only entities from an HQL query/criteria” Changing this default has no effect on: persistent entities already in the session when the default was changed persistent entities that are refreshed via Session.Refresh(); a refreshed persistent entity will only be read-only if it was read-only before refreshing persistent entities added by the application via Session.Persist(), Session.Save(), and Session.Update() Session.SaveOrUpdate() 10.1.3. Loading read-only entities from an HQL query/criteria Note Entities of immutable classes are automatically loaded as read-only. If Session.DefaultReadOnly returns false (the default) when an HQL query or criteria executes, then entities and proxies of mutable classes loaded by the query will not be read-only. You can override this behavior so that entities and proxies loaded by an HQL query or criteria are automatically made read-only. For an HQL query, call: Query.SetReadOnly(true); Query.SetReadOnly(true) must be called before Query.List(), Query.UniqueResult(), or Query.Iterate() For an HQL criteria, call: Criteria.SetReadOnly(true); Criteria.SetReadOnly(true) must be called before Criteria.List(), or Criteria.UniqueResult() Entities and proxies that exist in the session before being returned by an HQL query or criteria are not affected. Uninitialized persistent collections returned by the query are not affected. Later, when the collection is initialized, entities loaded into the session will be read-only if Session.DefaultReadOnly returns true. Using Query.SetReadOnly(true) or Criteria.SetReadOnly(true) works well when a single HQL query or criteria loads all the entities and intializes all the proxies and collections that the application needs to be read-only. When it is not possible to load and initialize all necessary entities in a single query or criteria, you can temporarily change the session default to load entities as read-only before the query is executed. Then you can explicitly initialize proxies and collections before restoring the session default. ISession session = factory.OpenSession();ITransaction tx = session.BeginTransaction(); session.DefaultReadOnly = true;Contract contract = session.CreateQuery(\"from Contract where CustomerName = 'Sherman'\").UniqueResult<Contract>();NHibernate.Initialize(contract.Plan);NHibernate.Initialize(contract.Variations);NHibernate.Initialize(contract.Notes);session.DefaultReadOnly = false;...tx.Commit();session.Close(); If Session.DefaultReadOnly returns true, then you can use Query.SetReadOnly(false) and Criteria.SetReadOnly(false) to override this session setting and load entities that are not read-only. 10.1.4. Making a persistent entity read-only Note Persistent entities of immutable classes are automatically made read-only. To make a persistent entity or proxy read-only, call: Session.SetReadOnly(entityOrProxy, true) To change a read-only entity or proxy of a mutable class so it is no longer read-only, call: Session.SetReadOnly(entityOrProxy, false) Important When a read-only entity or proxy is changed so it is no longer read-only, NHibernate assumes that the current state of the read-only entity is consistent with its database representation. If this is not true, then any non-flushed changes made before or while the entity was read-only, will be ignored. To throw away non-flushed changes and make the persistent entity consistent with its database representation, call: Session.Refresh(entity); To flush changes made before or while the entity was read-only and make the database representation consistent with the current state of the persistent entity: // evict the read-only entity so it is detachedsession.Evict(entity);// make the detached entity (with the non-flushed changes) persistentsession.Update(entity);// now entity is no longer read-only and its changes can be flusheds.Flush(); 10.2. Read-only affect on property type The following table summarizes how different property types are affected by making an entity read-only. Table 10.1. Affect of read-only entity on property types Property/Association Type Changes flushed to DB? Simple (Section 10.2.1, “Simple properties”) no* Unidirectional one-to-one Unidirectional many-to-one (Section 10.2.2.1, “Unidirectional one-to-one and many-to-one”) no* no* Unidirectional one-to-many Unidirectional many-to-many (Section 10.2.2.2, “Unidirectional one-to-many and many-to-many”) yes yes Bidirectional one-to-one (Section 10.2.3.1, “Bidirectional one-to-one”) only if the owning entity is not read-only* Bidirectional one-to-many/many-to-one inverse collection non-inverse collection (Section 10.2.3.2, “Bidirectional one-to-many/many-to-one”) only added/removed entities that are not read-only* yes Bidirectional many-to-many (Section 10.2.3.3, “Bidirectional many-to-many”) yes * Behavior is different when the entity having the property/association is read-only, compared to when it is not read-only. 10.2.1. Simple properties When a persistent object is read-only, NHibernate does not dirty-check simple properties. NHibernate will not synchronize simple property state changes to the database. If you have automatic versioning, NHibernate will not increment the version if any simple properties change. ISession session = factory.OpenSession();ITransaction tx = session.BeginTransaction();// get a contract and make it read-onlyContract contract = session.Get<Contract>(contractId);session.SetReadOnly(contract, true);// contract.CustomerName is \"Sherman\"contract.CustomerName = \"Yogi\";tx.Commit();tx = session.BeginTransaction();contract = session.Get<Contract>(contractId);// contract.CustomerName is still \"Sherman\"...tx.Commit();session.Close();            10.2.2. Unidirectional associations 10.2.2.1. Unidirectional one-to-one and many-to-one NHibernate treats unidirectional one-to-one and many-to-one associations in the same way when the owning entity is read-only. We use the term unidirectional single-ended association when referring to functionality that is common to unidirectional one-to-one and many-to-one associations. NHibernate does not dirty-check unidirectional single-ended associations when the owning entity is read-only. If you change a read-only entity's reference to a unidirectional single-ended association to null, or to refer to a different entity, that change will not be flushed to the database. Note If an entity is of an immutable class, then its references to unidirectional single-ended associations must be assigned when that entity is first created. Because the entity is automatically made read-only, these references can not be updated. If automatic versioning is used, NHibernate will not increment the version due to local changes to unidirectional single-ended associations. In the following examples, Contract has a unidirectional many-to-one association with Plan. Contract cascades save and update operations to the association. The following shows that changing a read-only entity's many-to-one association reference to null has no effect on the entity's database representation. // get a contract with an existing plan;// make the contract read-only and set its plan to null tx = session.BeginTransaction();Contract contract = session.Get<Contract>(contractId);session.SetReadOnly(contract, true);contract.Plan = null;tx.Commit();// get the same contracttx = session.BeginTransaction();Contract contract = session.Get<Contract>(contractId);// contract.Plan still refers to the original plan;tx.Commit();session.Close(); The following shows that, even though an update to a read-only entity's many-to-one association has no affect on the entity's database representation, flush still cascades the save-update operation to the locally changed association. // get a contract with an existing plan;// make the contract read-only and change to a new plantx = session.BeginTransaction();Contract contract = session.Get<Contract>(contractId);session.SetReadOnly(contract, true);Plan newPlan = new Plan(\"new plan\");contract.Plan = newPlan;tx.Commit();// get the same contracttx = session.BeginTransaction();contract = session.Get<Contract>(contractId);newPlan = session.Get<Plan>(newPlan.Id);// contract.Plan still refers to the original plan;// newPlan is non-null because it was persisted when // the previous transaction was committed; tx.Commit();session.Close(); 10.2.2.2. Unidirectional one-to-many and many-to-many NHibernate treats unidirectional one-to-many and many-to-many associations owned by a read-only entity the same as when owned by an entity that is not read-only. NHibernate dirty-checks unidirectional one-to-many and many-to-many associations; The collection can contain entities that are read-only, as well as entities that are not read-only. Entities can be added and removed from the collection; changes are flushed to the database. If automatic versioning is used, NHibernate will update the version due to changes in the collection if they dirty the owning entity. 10.2.3. Bidirectional associations 10.2.3.1. Bidirectional one-to-one If a read-only entity owns a bidirectional one-to-one association: NHibernate does not dirty-check the association. updates that change the association reference to null or to refer to a different entity will not be flushed to the database. If automatic versioning is used, NHibernate will not increment the version due to local changes to the association. Note If an entity is of an immutable class, and it owns a bidirectional one-to-one association, then its reference must be assigned when that entity is first created. Because the entity is automatically made read-only, these references cannot be updated. When the owner is not read-only, NHibernate treats an association with a read-only entity the same as when the association is with an entity that is not read-only. 10.2.3.2. Bidirectional one-to-many/many-to-one A read-only entity has no impact on a bidirectional one-to-many/many-to-one association if: the read-only entity is on the one-to-many side using an inverse collection; the read-only entity is on the one-to-many side using a non-inverse collection; the one-to-many side uses a non-inverse collection that contains the read-only entity When the one-to-many side uses an inverse collection: a read-only entity can only be added to the collection when it is created; a read-only entity can only be removed from the collection by an orphan delete or by explicitly deleting the entity. 10.2.3.3. Bidirectional many-to-many NHibernate treats bidirectional many-to-many associations owned by a read-only entity the same as when owned by an entity that is not read-only. NHibernate dirty-checks bidirectional many-to-many associations. The collection on either side of the association can contain entities that are read-only, as well as entities that are not read-only. Entities are added and removed from both sides of the collection; changes are flushed to the database. If automatic versioning is used, NHibernate will update the version due to changes in both sides of the collection if they dirty the entity owning the respective collections. Chapter 11. Transactions And Concurrency NHibernate is not itself a database. It is a lightweight object-relational mapping tool. Transaction management is delegated to the underlying database connection. If the connection is enlisted with a distributed transaction, operations performed by theISession are atomically part of the wider distributed transaction. NHibernate can be seen as a thin adapter to ADO.NET, adding object-oriented semantics. 11.1. Configurations, Sessions and Factories An ISessionFactory is an expensive-to-create, threadsafe object intended to be shared by all application threads. AnISession is an inexpensive, non-threadsafe object that should be used once, for a single business process, and then discarded. For example, when using NHibernate in an ASP.NET application, pages could obtain anISessionFactory using: ISessionFactory sf = Global.SessionFactory; Each call to a service method could create a new ISession,Flush() it,Commit() its transaction,Close() it and finally discard it. (TheISessionFactory may also be kept in a static Singleton helper variable.) We use the NHibernate ITransaction API as discussed previously, a singleCommit() of a NHibernateITransaction flushes the state and commits any underlying database connection (with special handling of distributed transactions). Ensure you understand the semantics of Flush(). Flushing synchronizes the persistent store with in-memory changes butnot vice-versa. Note that for all NHibernate ADO.NET connections/transactions, the transaction isolation level for that connection applies to all operations executed by NHibernate! The next few sections will discuss alternative approaches that utilize versioning to ensure transaction atomicity. These are considered \"advanced\" approaches to be used with care. 11.2. Threads and connections You should observe the following practices when creating NHibernate Sessions: Never create more than one concurrent ISession or ITransaction instance per database connection. Be extremely careful when creating more than one ISession per database per transaction. TheISession itself keeps track of updates made to loaded objects, so a differentISession might see stale data. The ISession is not threadsafe! Never access the sameISession in two concurrent threads. AnISession is usually only a single unit-of-work! 11.3. Considering object identity The application may concurrently access the same persistent state in two different units-of-work. However, an instance of a persistent class is never shared between twoISession instances. Hence there are two different notions of identity: Database Identity foo.Id.Equals( bar.Id ) CLR Identity foo == bar Then for objects attached to a particularSession, the two notions are equivalent. However, while the application might concurrently access the \"same\" (persistent identity) business object in two different sessions, the two instances will actually be \"different\" (CLR identity). This approach leaves NHibernate and the database to worry about concurrency. The application never needs to synchronize on any business object, as long as it sticks to a single thread perISession or object identity (within anISession the application may safely use == to compare objects). 11.4. Optimistic concurrency control Many business processes require a whole series of interactions with the user interleaved with database accesses. In web and enterprise applications it is not acceptable for a database transaction to span a user interaction. Maintaining isolation of business processes becomes the partial responsibility of the application tier, hence we call this process a long runningapplication transaction. A single application transaction usually spans several database transactions. It will be atomic if only one of these database transactions (the last one) stores the updated data, all others simply read data. The only approach that is consistent with high concurrency and high scalability is optimistic concurrency control with versioning. NHibernate provides for three possible approaches to writing application code that uses optimistic concurrency. 11.4.1. Long session with automatic versioning A single ISession instance and its persistent instances are used for the whole application transaction. The ISession uses optimistic locking with versioning to ensure that many database transactions appear to the application as a single logical application transaction. TheISession is disconnected from any underlying ADO.NET connection when waiting for user interaction. This approach is the most efficient in terms of database access. The application need not concern itself with version checking or with reattaching detached instances. // foo is an instance loaded earlier by the Sessionsession.Reconnect();transaction = session.BeginTransaction();foo.Property = \"bar\";session.Flush();transaction.Commit();session.Disconnect(); The foo object still knows which ISession it was loaded it. As soon as the ISession has an ADO.NET connection, we commit the changes to the object. This pattern is problematic if our ISession is too big to be stored during user think time, e.g. anHttpSession should be kept as small as possible. As theISession is also the (mandatory) first-level cache and contains all loaded objects, we can propably use this strategy only for a few request/response cycles. This is indeed recommended, as theISession will soon also have stale data. 11.4.2. Many sessions with automatic versioning Each interaction with the persistent store occurs in a new ISession. However, the same persistent instances are reused for each interaction with the database. The application manipulates the state of detached instances originally loaded in anotherISession and then \"reassociates\" them usingISession.Update() or ISession.SaveOrUpdate(). // foo is an instance loaded by a previous Sessionfoo.Property = \"bar\";session = factory.OpenSession();transaction = session.BeginTransaction();session.SaveOrUpdate(foo);session.Flush();transaction.Commit();session.Close(); You may also call Lock() instead of Update() and use LockMode.Read (performing a version check, bypassing all caches) if you are sure that the object has not been modified. 11.4.3. Customizing automatic versioning You may disable NHibernate's automatic version increment for particular properties and collections by setting theoptimistic-lock mapping attribute tofalse. NHibernate will then no longer increment versions if the property is dirty. Legacy database schemas are often static and can't be modified. Or, other applications might also access the same database and don't know how to handle version numbers or even timestamps. In both cases, versioning can't rely on a particular column in a table. To force a version check without a version or timestamp property mapping, with a comparison of the state of all fields in a row, turn onoptimistic-lock=\"all\" in the<class> mapping. Note that this concepetually only works if NHibernate can compare the old and new state, i.e. if you use a single longISession and not session-per-request-with-detached-objects. Sometimes concurrent modification can be permitted as long as the changes that have been made don't overlap. If you setoptimistic-lock=\"dirty\" when mapping the<class>, NHibernate will only compare dirty fields during flush. In both cases, with dedicated version/timestamp columns or with full/dirty field comparison, NHibernate uses a singleUPDATE statement (with an appropriateWHERE clause) per entity to execute the version check and update the information. If you use transitive persistence to cascade reattachment to associated entities, NHibernate might execute uneccessary updates. This is usually not a problem, buton update triggers in the database might be executed even when no changes have been made to detached instances. You can customize this behavior by settingselect-before-update=\"true\" in the <class> mapping, forcing NHibernate toSELECT the instance to ensure that changes did actually occur, before updating the row. 11.4.4. Application version checking Each interaction with the database occurs in a new ISession that reloads all persistent instances from the database before manipulating them. This approach forces the application to carry out its own version checking to ensure application transaction isolation. (Of course, NHibernate will still update version numbers for you.) This approach is the least efficient in terms of database access. // foo is an instance loaded by a previous Sessionsession = factory.OpenSession();transaction = session.BeginTransaction();int oldVersion = foo.Version;session.Load( foo, foo.Key );if ( oldVersion != foo.Version ) throw new StaleObjectStateException();foo.Property = \"bar\";session.Flush();transaction.Commit();session.close(); Of course, if you are operating in a low-data-concurrency environment and don't require version checking, you may use this approach and just skip the version check. 11.5. Session disconnection The first approach described above is to maintain a single ISession for a whole business process thats spans user think time. (For example, a servlet might keep anISession in the user'sHttpSession.) For performance reasons you should commit the ITransaction and then disconnect the ISession from the ADO.NET connection before waiting for user activity. The method ISession.Disconnect() will disconnect the session from the ADO.NET connection and return the connection to the pool (unless you provided the connection). ISession.Reconnect() obtains a new connection (or you may supply one) and restarts the session. After reconnection, to force a version check on data you aren't updating, you may callISession.Lock() on any objects that might have been updated by another transaction. You don't need to lock any data that youare updating. Heres an example: ISessionFactory sessions;IList fooList;Bar bar;....ISession s = sessions.OpenSession();ITransaction tx = null;try{    tx = s.BeginTransaction())    fooList = s.Find(    \t\"select foo from Eg.Foo foo where foo.Date = current date\"        // uses db2 date function    );    bar = new Bar();    s.Save(bar);    tx.Commit();}catch (Exception){    if (tx != null) tx.Rollback();    s.Close();    throw;}s.Disconnect(); Later on: s.Reconnect();try{    tx = s.BeginTransaction();    bar.FooTable = new HashMap();    foreach (Foo foo in fooList)    {        s.Lock(foo, LockMode.Read);    //check that foo isn't stale        bar.FooTable.Put( foo.Name, foo );    }    tx.Commit();}catch (Exception){    if (tx != null) tx.Rollback();    throw;}finally{    s.Close();} You can see from this how the relationship between ITransactions andISessions is many-to-one, AnISession represents a conversation between the application and the database. TheITransaction breaks that conversation up into atomic units of work at the database level. 11.6. Pessimistic Locking It is not intended that users spend much time worring about locking strategies. It's usually enough to specify an isolation level for the ADO.NET connections and then simply let the database do all the work. However, advanced users may sometimes wish to obtain exclusive pessimistic locks, or re-obtain locks at the start of a new transaction. NHibernate will always use the locking mechanism of the database, never lock objects in memory! The LockMode class defines the different lock levels that may be acquired by NHibernate. A lock is obtained by the following mechanisms: LockMode.Write is acquired automatically when NHibernate updates or inserts a row. LockMode.Upgrade may be acquired upon explicit user request usingSELECT ... FOR UPDATE on databases which support that syntax. LockMode.UpgradeNoWait may be acquired upon explicit user request using aSELECT ... FOR UPDATE NOWAIT under Oracle. LockMode.Read is acquired automatically when NHibernate reads data under Repeatable Read or Serializable isolation level. May be re-acquired by explicit user request. LockMode.None represents the absence of a lock. All objects switch to this lock mode at the end of anITransaction. Objects associated with the session via a call toUpdate() orSaveOrUpdate() also start out in this lock mode. The \"explicit user request\" is expressed in one of the following ways: A call to ISession.Load(), specifying a LockMode. A call to ISession.Lock(). A call to IQuery.SetLockMode(). If ISession.Load() is called with Upgrade or UpgradeNoWait, and the requested object was not yet loaded by the session, the object is loaded usingSELECT ... FOR UPDATE. IfLoad() is called for an object that is already loaded with a less restrictive lock than the one requested, NHibernate callsLock() for that object. ISession.Lock() performs a version number check if the specified lock mode isRead,Upgrade or UpgradeNoWait. (In the case ofUpgrade or UpgradeNoWait, SELECT ... FOR UPDATE is used.) If the database does not support the requested lock mode, NHibernate will use an appropriate alternate mode (instead of throwing an exception). This ensures that applications will be portable. 11.7. Connection Release Modes The legacy (1.0.x) behavior of NHibernate in regards to ADO.NET connection management was that aISession would obtain a connection when it was first needed and then hold unto that connection until the session was closed. NHibernate introduced the notion of connection release modes to tell a session how to handle its ADO.NET connections. Note that the following discussion is pertinent only to connections provided through a configuredIConnectionProvider; user-supplied connections are outside the breadth of this discussion. The different release modes are identified by the enumerated values ofNHibernate.ConnectionReleaseMode: OnClose - is essentially the legacy behavior described above. The NHibernate session obtains a connection when it first needs to perform some database access and holds unto that connection until the session is closed. AfterTransaction - says to release connections after aNHibernate.ITransaction has completed. The configuration parameter hibernate.connection.release_mode is used to specify which release mode to use. The possible values: auto (the default) - equivalent to after_transaction in the current release. It is rarely a good idea to change this default behavior as failures due to the value of this setting tend to indicate bugs and/or invalid assumptions in user code. on_close - says to use ConnectionReleaseMode.OnClose. This setting is left for backwards compatibility, but its use is highly discouraged. after_transaction - says to use ConnectionReleaseMode.AfterTransaction. Note that withConnectionReleaseMode.AfterTransaction, if a session is considered to be in auto-commit mode (i.e. no transaction was started) connections will be released after every operation. As of NHibernate, if your application manages transactions through .NET APIs such asSystem.Transactions library,ConnectionReleaseMode.AfterTransaction may cause NHibernate to open and close several connections during one transaction, leading to unnecessary overhead and transaction promotion from local to distributed. SpecifyingConnectionReleaseMode.OnClose will revert to the legacy behavior and prevent this problem from occuring. Chapter 12. Interceptors and events It is often useful for the application to react to certain events that occur inside NHibernate. This allows implementation of certain kinds of generic functionality, and extension of NHibernate functionality. 12.1. Interceptors The IInterceptor interface provides callbacks from the session to the application allowing the application to inspect and/or manipulate properties of a persistent object before it is saved, updated, deleted or loaded. One possible use for this is to track auditing information. For example, the following IInterceptor automatically sets the createTimestamp when anIAuditable is created and updates thelastUpdateTimestamp property when an IAuditable is updated. You may either implement IInterceptor directly or (better) extendEmptyInterceptor. using System;\tusing NHibernate;using NHibernate.Type;public class AuditInterceptor : EmptyInterceptor {    private int updates;    private int creates;    private int loads;    public override void OnDelete(object entity,                                  object id,                                  object[] state,                                  string[] propertyNames,                                  IType[] types)    {        // do nothing    }    public override bool OnFlushDirty(object entity,                                       object id, \t\t\t\t      object[] currentState,\t\t\t\t      object[] previousState, \t\t\t\t      string[] propertyNames,\t\t\t\t      IType[] types)     {        if ( entity is IAuditable ) {            updates++;            for ( int i=0; i < propertyNames.Length; i++ ) {                if ( \"lastUpdateTimestamp\".Equals( propertyNames[i] ) ) {                    currentState[i] = new DateTime();                    return true;                }            }        }        return false;    }    public override bool OnLoad(object entity,                                 object id, \t\t\t\tobject[] state, \t\t\t\tstring[] propertyNames, \t\t\t\tIType[] types)    {        if ( entity is IAuditable ) {            loads++;        }        return false;    }    public override bool OnSave(object entity,                                 object id, \t\t\t\tobject[] state, \t\t\t\tstring[] propertyNames, \t\t\t\tIType[] types)    {        if ( entity is IAuditable ) {            creates++;            for ( int i=0; i<propertyNames.Length; i++ ) {                if ( \"createTimestamp\".Equals( propertyNames[i] ) ) {                    state[i] = new DateTime();                    return true;                }            }        }        return false;    }    public override void AfterTransactionCompletion(ITransaction tx)    {        if ( tx.WasCommitted ) {            System.Console.WriteLine(\"Creations: \" + creates + \", Updates: \" + updates, \"Loads: \" + loads);        }        updates=0;        creates=0;        loads=0;    }} Interceptors come in two flavors: ISession-scoped andISessionFactory-scoped. An ISession-scoped interceptor is specified when a session is opened using one of the overloaded ISessionFactory.OpenSession() methods accepting anIInterceptor. ISession session = sf.OpenSession( new AuditInterceptor() ); An ISessionFactory-scoped interceptor is registered with theConfiguration object prior to building theISessionFactory. In this case, the supplied interceptor will be applied to all sessions opened from thatISessionFactory; this is true unless a session is opened explicitly specifying the interceptor to use.ISessionFactory-scoped interceptors must be thread safe, taking care to not store session-specific state since multiple sessions will use this interceptor (potentially) concurrently. new Configuration().SetInterceptor( new AuditInterceptor() ); 12.2. Event system If you have to react to particular events in your persistence layer, you may also use the NHibernate2event architecture. The event system can be used in addition or as a replacement for interceptors. Essentially all of the methods of the ISession interface correlate to an event. You have aLoadEvent, aFlushEvent, etc (consult the XML configuration-file XSD or theNHibernate.Event namespace for the full list of defined event types). When a request is made of one of these methods, theISession generates an appropriate event and passes it to the configured event listeners for that type. Out-of-the-box, these listeners implement the same processing in which those methods always resulted. However, you are free to implement a customization of one of the listener interfaces (i.e., the LoadEvent is processed by the registered implemenation of theILoadEventListener interface), in which case their implementation would be responsible for processing anyLoad() requests made of theISession. The listeners should be considered effectively singletons; meaning, they are shared between requests, and thus should not save any state as instance variables. A custom listener should implement the appropriate interface for the event it wants to process and/or extend one of the convenience base classes (or even the default event listeners used by NHibernate out-of-the-box as their methods are declared virtual for this purpose). Custom listeners can either be registered programmatically through theConfiguration object, or specified in the NHibernate configuration XML. Here's an example of a custom load event listener: public class MyLoadListener : ILoadEventListener {    // this is the single method defined by the LoadEventListener interface    public void OnLoad(LoadEvent theEvent, LoadType loadType)    {        if ( !MySecurity.IsAuthorized( theEvent.EntityClassName, theEvent.EntityId ) ) {            throw new MySecurityException(\"Unauthorized access\");        }    }} You also need a configuration entry telling NHibernate to use the listener in addition to the default listener: <hibernate-configuration>    <session-factory>        ...        <event type=\"load\">            <listener class=\"MyLoadListener\"/>            <listener class=\"NHibernate.Event.Default.DefaultLoadEventListener\"/>        <\/event>    <\/session-factory><\/hibernate-configuration> Instead, you may register it programmatically: Configuration cfg = new Configuration();ILoadEventListener[] stack = new ILoadEventListener[] { new MyLoadListener(), new DefaultLoadEventListener() };cfg.EventListeners.LoadEventListeners = stack; Listeners registered declaratively cannot share instances. If the same class name is used in multiple<listener/> elements, each reference will result in a separate instance of that class. If you need the capability to share listener instances between listener types you must use the programmatic registration approach. Why implement an interface and define the specific type during configuration? Well, a listener implementation could implement multiple event listener interfaces. Having the type additionally defined during registration makes it easier to turn custom listeners on or off during configuration. Chapter 13. Batch processing A naive approach to inserting 100 000 rows in the database using NHibernate might look like this: ISession session = sessionFactory.OpenSession();ITransaction tx = session.BeginTransaction();for ( int i=0; i<100000; i++ ) {    Customer customer = new Customer(.....);    session.Save(customer);}tx.Commit();session.Close(); This would fall over with an OutOfMemoryException somewhere around the 50 000th row. That's because NHibernate caches all the newly insertedCustomer instances in the session-level cache. In this chapter we'll show you how to avoid this problem. First, however, if you are doing batch processing, it is absolutely critical that you enable the use of ADO batching, if you intend to achieve reasonable performance. Set the ADO batch size to a reasonable number (say, 10-50): adonet.batch_size 20 Note that NHibernate disables insert batching at the ADO level transparently if you use anidentiy identifier generator. You also might like to do this kind of work in a process where interaction with the second-level cache is completely disabled: cache.use_second_level_cache false However, this is not absolutely necessary, since we can explicitly set the CacheMode to disable interaction with the second-level cache. 13.1. Batch inserts When making new objects persistent, you must Flush() and thenClear() the session regularly, to control the size of the first-level cache. ISession session = sessionFactory.openSession();ITransaction tx = session.BeginTransaction();   for ( int i=0; i<100000; i++ ) {    Customer customer = new Customer(.....);    session.Save(customer);    if ( i % 20 == 0 ) { //20, same as the ADO batch size        //flush a batch of inserts and release memory:        session.Flush();        session.Clear();    }}   tx.Commit();session.Close(); 13.2. The StatelessSession interface Alternatively, NHibernate provides a command-oriented API that may be used for streaming data to and from the database in the form of detached objects. AIStatelessSession has no persistence context associated with it and does not provide many of the higher-level life cycle semantics. In particular, a stateless session does not implement a first-level cache nor interact with any second-level or query cache. It does not implement transactional write-behind or automatic dirty checking. Operations performed using a stateless session do not ever cascade to associated instances. Collections are ignored by a stateless session. Operations performed via a stateless session bypass NHibernate's event model and interceptors. Stateless sessions are vulnerable to data aliasing effects, due to the lack of a first-level cache. A stateless session is a lower-level abstraction, much closer to the underlying ADO. IStatelessSession session = sessionFactory.OpenStatelessSession();ITransaction tx = session.BeginTransaction();   var customers = session.GetNamedQuery(\"GetCustomers\")    .Enumerable<Customer>();while ( customers.MoveNext() ) {    Customer customer = customers.Current;    customer.updateStuff(...);    session.Update(customer);}   tx.Commit();session.Close(); Note that in this code example, the Customer instances returned by the query are immediately detached. They are never associated with any persistence context. The insert(), update() and delete() operations defined by theStatelessSession interface are considered to be direct database row-level operations, which result in immediate execution of a SQLINSERT, UPDATE or DELETE respectively. Thus, they have very different semantics to theSave(), SaveOrUpdate() andDelete() operations defined by theISession interface. 13.3. DML-style operations As already discussed, automatic and transparent object/relational mapping is concerned with the management of object state. This implies that the object state is available in memory, hence manipulating (using the SQLData Manipulation Language (DML) statements: INSERT, UPDATE, DELETE) data directly in the database will not affect in-memory state. However, NHibernate provides methods for bulk SQL-style DML statement execution which are performed through the Hibernate Query Language (HQL). The pseudo-syntax for UPDATE and DELETE statements is: ( UPDATE | DELETE ) FROM? EntityName (WHERE where_conditions)?. Some points to note: In the from-clause, the FROM keyword is optional There can only be a single entity named in the from-clause; it can optionally be aliased. If the entity name is aliased, then any property references must be qualified using that alias; if the entity name is not aliased, then it is illegal for any property references to be qualified. No joins (either implicit or explicit) can be specified in a bulk HQL query. Sub-queries may be used in the where-clause; the subqueries, themselves, may contain joins. The where-clause is also optional. As an example, to execute an HQL UPDATE, use the IQuery.ExecuteUpdate() method: ISession session = sessionFactory.OpenSession();ITransaction tx = session.BeginTransaction();string hqlUpdate = \"update Customer c set c.name = :newName where c.name = :oldName\";// or string hqlUpdate = \"update Customer set name = :newName where name = :oldName\";int updatedEntities = s.CreateQuery( hqlUpdate )        .SetString( \"newName\", newName )        .SetString( \"oldName\", oldName )        .ExecuteUpdate();tx.Commit();session.Close(); HQL UPDATE statements, by default do not effect the version or the timestamp property values for the affected entities. However, you can force NHibernate to properly reset theversion ortimestamp property values through the use of aversioned update. This is achieved by adding theVERSIONED keyword after the UPDATE keyword. ISession session = sessionFactory.OpenSession();ITransaction tx = session.BeginTransaction();string hqlVersionedUpdate = \"update versioned Customer set name = :newName where name = :oldName\";int updatedEntities = s.CreateQuery( hqlUpdate )        .SetString( \"newName\", newName )        .SetString( \"oldName\", oldName )        .ExecuteUpdate();tx.Commit();session.Close(); Note that custom version types (NHibernate.Usertype.IUserVersionType) are not allowed in conjunction with aupdate versioned statement. To execute an HQL DELETE, use the same IQuery.ExecuteUpdate() method: ISession session = sessionFactory.OpenSession();ITransaction tx = session.BeginTransaction();String hqlDelete = \"delete Customer c where c.name = :oldName\";// or String hqlDelete = \"delete Customer where name = :oldName\";int deletedEntities = s.CreateQuery( hqlDelete )        .SetString( \"oldName\", oldName )        .ExecuteUpdate();tx.Commit();session.Close(); The int value returned by the IQuery.ExecuteUpdate() method indicate the number of entities effected by the operation. Consider this may or may not correlate to the number of rows effected in the database. An HQL bulk operation might result in multiple actual SQL statements being executed, for joined-subclass, for example. The returned number indicates the number of actual entities affected by the statement. Going back to the example of joined-subclass, a delete against one of the subclasses may actually result in deletes against not just the table to which that subclass is mapped, but also the \"root\" table and potentially joined-subclass tables further down the inheritence hierarchy. The pseudo-syntax for INSERT statements is: INSERT INTO EntityName properties_list select_statement. Some points to note: Only the INSERT INTO ... SELECT ... form is supported; not the INSERT INTO ... VALUES ... form. The properties_list is analogous to the column speficiation in the SQLINSERT statement. For entities involved in mapped inheritence, only properties directly defined on that given class-level can be used in the properties_list. Superclass properties are not allowed; and subclass properties do not make sense. In other words,INSERT statements are inherently non-polymorphic. select_statement can be any valid HQL select query, with the caveat that the return types must match the types expected by the insert. Currently, this is checked during query compilation rather than allowing the check to relegate to the database. Note however that this might cause problems between NHibernate Types which areequivalent as opposed toequal. This might cause issues with mismatches between a property defined as aNHibernate.Type.DateType and a property defined as aNHibernate.Type.TimestampType, even though the database might not make a distinction or might be able to handle the conversion. For the id property, the insert statement gives you two options. You can either explicitly specify the id property in the properties_list (in which case its value is taken from the corresponding select expression) or omit it from the properties_list (in which case a generated value is used). This later option is only available when using id generators that operate in the database; attempting to use this option with any \"in memory\" type generators will cause an exception during parsing. Note that for the purposes of this discussion, in-database generators are considered to be NHibernate.Id.SequenceGenerator (and its subclasses) and any implementors ofNHibernate.Id.IPostInsertIdentifierGenerator. The most notable exception here isNHibernate.Id.TableHiLoGenerator, which cannot be used because it does not expose a selectable way to get its values. For properties mapped as either version or timestamp, the insert statement gives you two options. You can either specify the property in the properties_list (in which case its value is taken from the corresponding select expressions) or omit it from the properties_list (in which case theseed value defined by the NHibernate.Type.IVersionType is used). An example HQL INSERT statement execution: ISession session = sessionFactory.OpenSession();ITransaction tx = session.BeginTransaction();var hqlInsert = \"insert into DelinquentAccount (id, name) select c.id, c.name from Customer c where ...\";int createdEntities = s.CreateQuery( hqlInsert )        .ExecuteUpdate();tx.Commit();session.Close(); Chapter 14. HQL: The Hibernate Query Language NHibernate is equiped with an extremely powerful query language that (quite intentionally) looks very much like SQL. But don't be fooled by the syntax; HQL is fully object-oriented, understanding notions like inheritence, polymorphism and association. 14.1. Case Sensitivity Queries are case-insensitive, except for names of .NET classes and properties. SoSeLeCT is the same assELEct is the same asSELECT butEg.FOO is not Eg.Foo and foo.barSet is not foo.BARSET. This manual uses lowercase HQL keywords. Some users find queries with uppercase keywords more readable, but we find this convention ugly when embedded in C# code. 14.2. The from clause The simplest possible NHibernate query is of the form: from Eg.Cat which simply returns all instances of the class Eg.Cat. Most of the time, you will need to assign an alias, since you will want to refer to theCat in other parts of the query. from Eg.Cat as cat This query assigns the alias cat to Cat instances, so we could use that alias later in the query. The as keyword is optional; we could also write: from Eg.Cat cat Multiple classes may appear, resulting in a cartesian product or \"cross\" join. from Formula, Parameter from Formula as form, Parameter as param It is considered good practice to name query aliases using an initial lowercase, consistent with naming standards for local variables (eg.domesticCat). 14.3. Associations and joins We may also assign aliases to associated entities, or even to elements of a collection of values, using ajoin. from Eg.Cat as cat     inner join cat.Mate as mate    left outer join cat.Kittens as kittenfrom Eg.Cat as cat left join cat.Mate.Kittens as kittensfrom Formula form full join form.Parameter param The supported join types are borrowed from ANSI SQL inner join left outer join right outer join full join (not usually useful) The inner join, left outer join andright outer join constructs may be abbreviated. from Eg.Cat as cat     join cat.Mate as mate    left join cat.Kittens as kitten In addition, a \"fetch\" join allows associations or collections of values to be initialized along with their parent objects, using a single select. This is particularly useful in the case of a collection. It effectively overrides the outer join and lazy declarations of the mapping file for associations and collections. See Section 19.1, “Fetching strategies” for more information. from Eg.Cat as cat     inner join fetch cat.Mate    left join fetch cat.Kittens The associated objects are not returned directly in the query results. Instead, they may be accessed via the parent object. It is possible to create a cartesian product by join fetching more than one collection in a query, so take care in this case. Join fetching multiple collection roles is also disabled for bag mappings. Note also that thefetch construct may not be used in queries called using Enumerable(). Finally, note thatfull join fetch andright join fetch are not meaningful. 14.4. The select clause The select clause picks which objects and properties to return in the query result set. Consider: select mate from Eg.Cat as cat     inner join cat.Mate as mate The query will select Mates of other Cats. Actually, you may express this query more compactly as: select cat.Mate from Eg.Cat cat You may even select collection elements, using the special elements function. The following query returns all kittens of any cat. select elements(cat.Kittens) from Eg.Cat cat Queries may return properties of any value type including properties of component type: select cat.Name from Eg.DomesticCat catwhere cat.Name like 'fri%'select cust.Name.FirstName from Customer as cust Queries may return multiple objects and/or properties as an array of type object[] select mother, offspr, mate.Name from Eg.DomesticCat as mother    inner join mother.Mate as mate    left outer join mother.Kittens as offspr or as an actual typesafe object select new Family(mother, mate, offspr)from Eg.DomesticCat as mother    join mother.Mate as mate    left join mother.Kittens as offspr assuming that the class Family has an appropriate constructor. 14.5. Aggregate functions HQL queries may even return the results of aggregate functions on properties: select avg(cat.Weight), sum(cat.Weight), max(cat.Weight), count(cat)from Eg.Cat cat Collections may also appear inside aggregate functions in the select clause. select cat, count( elements(cat.Kittens) ) from Eg.Cat cat group by cat.Id, cat.Weight, ... The supported aggregate functions are avg(...), sum(...), min(...), max(...) count(*) count(...), count(distinct ...), count(all...) The distinct and all keywords may be used and have the same semantics as in SQL. select distinct cat.Name from Eg.Cat catselect count(distinct cat.Name), count(cat) from Eg.Cat cat 14.6. Polymorphic queries A query like: from Eg.Cat as cat returns instances not only of Cat, but also of subclasses likeDomesticCat. NHibernate queries may nameany .NET class or interface in the from clause. The query will return instances of all persistent classes that extend that class or implement the interface. The following query would return all persistent objects: from System.Object o The interface INamed might be implemented by various persistent classes: from Eg.Named n, Eg.Named m where n.Name = m.Name Note that these last two queries will require more than one SQL SELECT. This means that the order by clause does not correctly order the whole result set. In order to use non-mapped base classes or interfaces in HQL queries, they have to be imported. SeeSection 5.1.20, “import” for more information. 14.7. The where clause The where clause allows you to narrow the list of instances returned. from Eg.Cat as cat where cat.Name='Fritz' returns instances of Cat named 'Fritz'. select foo from Eg.Foo foo, Eg.Bar barwhere foo.StartDate = bar.Date will return all instances of Foo for which there exists an instance ofBar with aDate property equal to theStartDate property of theFoo. Compound path expressions make thewhere clause extremely powerful. Consider: from Eg.Cat cat where cat.Mate.Name is not null This query translates to an SQL query with a table (inner) join. If you were to write something like from Eg.Foo foo  where foo.Bar.Baz.Customer.Address.City is not null you would end up with a query that would require four table joins in SQL. The = operator may be used to compare not only properties, but also instances: from Eg.Cat cat, Eg.Cat rival where cat.Mate = rival.Mateselect cat, mate from Eg.Cat cat, Eg.Cat matewhere cat.Mate = mate The special property (lowercase) id may be used to reference the unique identifier of an object. (You may also use its property name.) from Eg.Cat as cat where cat.id = 123from Eg.Cat as cat where cat.Mate.id = 69 The second query is efficient. No table join is required! Properties of composite identifiers may also be used. Suppose Person has a composite identifier consisting of Country andMedicareNumber. from Bank.Person personwhere person.id.Country = 'AU'     and person.id.MedicareNumber = 123456from Bank.Account accountwhere account.Owner.id.Country = 'AU'     and account.Owner.id.MedicareNumber = 123456 Once again, the second query requires no table join. Likewise, the special property class accesses the discriminator value of an instance in the case of polymorphic persistence. A .Net class name embedded in the where clause will be translated to its discriminator value. from Eg.Cat cat where cat.class = Eg.DomesticCat You may also specify properties of components or composite user types (and of components of components, etc). Never try to use a path-expression that ends in a property of component type (as opposed to a property of a component). For example, ifstore.Owner is an entity with a component Address store.Owner.Address.City    // okaystore.Owner.Address         // error! An \"any\" type has the special properties id and class, allowing us to express a join in the following way (where AuditLog.Item is a property mapped with <any>). from Eg.AuditLog log, Eg.Payment payment where log.Item.class = 'Eg.Payment, Eg, Version=...' and log.Item.id = payment.id Notice that log.Item.class and payment.class would refer to the values of completely different database columns in the above query. 14.8. Expressions Expressions allowed in the where clause include most of the kind of things you could write in SQL: mathematical operators +, -, *, / binary comparison operators =, >=, <=, <>, !=, like logical operations and, or, not string concatenation || SQL scalar functions like upper() and lower() Parentheses ( ) indicate grouping in, between, is null positional parameters ? named parameters :name, :start_date,:x1 SQL literals 'foo', 69, '1970-01-01 10:00:01.0' Enumeration values and constants Eg.Color.Tabby in and between may be used as follows: from Eg.DomesticCat cat where cat.Name between 'A' and 'B'from Eg.DomesticCat cat where cat.Name in ( 'Foo', 'Bar', 'Baz' ) and the negated forms may be written from Eg.DomesticCat cat where cat.Name not between 'A' and 'B'from Eg.DomesticCat cat where cat.Name not in ( 'Foo', 'Bar', 'Baz' ) Likewise, is null and is not null may be used to test for null values. Booleans may be easily used in expressions by declaring HQL query substitutions in NHibernate configuration: <property name=\"hibernate.query.substitutions\">true 1, false 0<\/property> This will replace the keywords true and false with the literals 1 and 0 in the translated SQL from this HQL: from Eg.Cat cat where cat.Alive = true You may test the size of a collection with the special property size, or the special size() function. from Eg.Cat cat where cat.Kittens.size > 0from Eg.Cat cat where size(cat.Kittens) > 0 For indexed collections, you may refer to the minimum and maximum indices usingminIndex andmaxIndex. Similarly, you may refer to the minimum and maximum elements of a collection of basic type usingminElement andmaxElement. from Calendar cal where cal.Holidays.maxElement > current date There are also functional forms (which, unlike the constructs above, are not case sensitive): from Order order where maxindex(order.Items) > 100from Order order where minelement(order.Items) > 10000 The SQL functions any, some, all, exists, in are supported when passed the element or index set of a collection (elements andindices functions) or the result of a subquery (see below). select mother from Eg.Cat as mother, Eg.Cat as kitwhere kit in elements(mother.Kittens)select p from Eg.NameList list, Eg.Person pwhere p.Name = some elements(list.Names)from Eg.Cat cat where exists elements(cat.Kittens)from Eg.Player p where 3 > all elements(p.Scores)from Eg.Show show where 'fizard' in indices(show.Acts) Note that these constructs - size, elements, indices, minIndex,maxIndex,minElement, maxElement - have certain usage restrictions: in a where clause: only for databases with subselects in a select clause: only elements andindices make sense Elements of indexed collections (arrays, lists, maps) may be referred to by index (in a where clause only): from Order order where order.Items[0].id = 1234select person from Person person, Calendar calendarwhere calendar.Holidays['national day'] = person.BirthDay    and person.Nationality.Calendar = calendarselect item from Item item, Order orderwhere order.Items[ order.DeliveredItemIndices[0] ] = item and order.id = 11select item from Item item, Order orderwhere order.Items[ maxindex(order.items) ] = item and order.id = 11 The expression inside [] may even be an arithmetic expression. select item from Item item, Order orderwhere order.Items[ size(order.Items) - 1 ] = item HQL also provides the built-in index() function, for elements of a one-to-many association or collection of values. select item, index(item) from Order order     join order.Items itemwhere index(item) < 5 Scalar SQL functions supported by the underlying database may be used from Eg.DomesticCat cat where upper(cat.Name) like 'FRI%' If you are not yet convinced by all this, think how much longer and less readable the following query would be in SQL: select custfrom Product prod,    Store store    inner join store.Customers custwhere prod.Name = 'widget'    and store.Location.Name in ( 'Melbourne', 'Sydney' )    and prod = all elements(cust.CurrentOrder.LineItems) Hint: something like SELECT cust.name, cust.address, cust.phone, cust.id, cust.current_orderFROM customers cust,    stores store,    locations loc,    store_customers sc,    product prodWHERE prod.name = 'widget'    AND store.loc_id = loc.id    AND loc.name IN ( 'Melbourne', 'Sydney' )    AND sc.store_id = store.id    AND sc.cust_id = cust.id    AND prod.id = ALL(        SELECT item.prod_id        FROM line_items item, orders o        WHERE item.order_id = o.id            AND cust.current_order = o.id    ) 14.9. The order by clause The list returned by a query may be ordered by any property of a returned class or components: from Eg.DomesticCat catorder by cat.Name asc, cat.Weight desc, cat.Birthdate The optional asc or desc indicate ascending or descending order respectively. 14.10. The group by clause A query that returns aggregate values may be grouped by any property of a returned class or components: select cat.Color, sum(cat.Weight), count(cat) from Eg.Cat catgroup by cat.Colorselect foo.id, avg( elements(foo.Names) ), max( indices(foo.Names) ) from Eg.Foo foogroup by foo.id Note: You may use the elements and indices constructs inside a select clause, even on databases with no subselects. A having clause is also allowed. select cat.color, sum(cat.Weight), count(cat) from Eg.Cat catgroup by cat.Color having cat.Color in (Eg.Color.Tabby, Eg.Color.Black) SQL functions and aggregate functions are allowed in the having andorder by clauses, if supported by the underlying database (ie. not in MySQL). select catfrom Eg.Cat cat    join cat.Kittens kittengroup by cat.Id, cat.Name, cat.Other, cat.Propertieshaving avg(kitten.Weight) > 100order by count(kitten) asc, sum(kitten.Weight) desc Note that neither the group by clause nor the order by clause may contain arithmetic expressions. Also note that NHibernate currently does not expand a grouped entity, so you can't writegroup by cat if all properties ofcat are non-aggregated. You have to list all non-aggregated properties explicitly. 14.11. Subqueries For databases that support subselects, NHibernate supports subqueries within queries. A subquery must be surrounded by parentheses (often by an SQL aggregate function call). Even correlated subqueries (subqueries that refer to an alias in the outer query) are allowed. from Eg.Cat as fatcat where fatcat.Weight > (     select avg(cat.Weight) from Eg.DomesticCat cat )from Eg.DomesticCat as cat where cat.Name = some (     select name.NickName from Eg.Name as name )    from Eg.Cat as cat where not exists (     from eg.Cat as mate where mate.Mate = cat )from Eg.DomesticCat as cat where cat.Name not in (     select name.NickName from Eg.Name as name ) 14.12. HQL examples NHibernate queries can be quite powerful and complex. In fact, the power of the query language is one of NHibernate's main selling points. Here are some example queries very similar to queries that I used on a recent project. Note that most queries you will write are much simpler than these! The following query returns the order id, number of items and total value of the order for all unpaid orders for a particular customer and given minimum total value, ordering the results by total value. In determining the prices, it uses the current catalog. The resulting SQL query, against the ORDER, ORDER_LINE, PRODUCT, CATALOG andPRICE tables has four inner joins and an (uncorrelated) subselect. select order.id, sum(price.Amount), count(item)from Order as order    join order.LineItems as item    join item.Product as product,    Catalog as catalog    join catalog.Prices as pricewhere order.Paid = false    and order.Customer = :customer    and price.Product = product    and catalog.EffectiveDate < sysdate    and catalog.EffectiveDate >= all (        select cat.EffectiveDate         from Catalog as cat        where cat.EffectiveDate < sysdate    )group by orderhaving sum(price.Amount) > :minAmountorder by sum(price.Amount) desc What a monster! Actually, in real life, I'm not very keen on subqueries, so my query was really more like this: select order.id, sum(price.amount), count(item)from Order as order    join order.LineItems as item    join item.Product as product,    Catalog as catalog    join catalog.Prices as pricewhere order.Paid = false    and order.Customer = :customer    and price.Product = product    and catalog = :currentCataloggroup by orderhaving sum(price.Amount) > :minAmountorder by sum(price.Amount) desc The next query counts the number of payments in each status, excluding all payments in theAwaitingApproval status where the most recent status change was made by the current user. It translates to an SQL query with two inner joins and a correlated subselect against thePAYMENT, PAYMENT_STATUS and PAYMENT_STATUS_CHANGE tables. select count(payment), status.Name from Payment as payment     join payment.CurrentStatus as status    join payment.StatusChanges as statusChangewhere payment.Status.Name <> PaymentStatus.AwaitingApproval    or (        statusChange.TimeStamp = (             select max(change.TimeStamp)             from PaymentStatusChange change             where change.Payment = payment        )        and statusChange.User <> :currentUser    )group by status.Name, status.SortOrderorder by status.SortOrder If I would have mapped the StatusChanges collection as a list, instead of a set, the query would have been much simpler to write. select count(payment), status.Name from Payment as payment    join payment.CurrentStatus as statuswhere payment.Status.Name <> PaymentStatus.AwaitingApproval    or payment.StatusChanges[ maxIndex(payment.StatusChanges) ].User <> :currentUsergroup by status.Name, status.SortOrderorder by status.SortOrder The next query uses the MS SQL Server isNull() function to return all the accounts and unpaid payments for the organization to which the current user belongs. It translates to an SQL query with three inner joins, an outer join and a subselect against the ACCOUNT, PAYMENT,PAYMENT_STATUS,ACCOUNT_TYPE, ORGANIZATION and ORG_USER tables. select account, paymentfrom Account as account    left outer join account.Payments as paymentwhere :currentUser in elements(account.Holder.Users)    and PaymentStatus.Unpaid = isNull(payment.CurrentStatus.Name, PaymentStatus.Unpaid)order by account.Type.SortOrder, account.AccountNumber, payment.DueDate For some databases, we would need to do away with the (correlated) subselect. select account, paymentfrom Account as account    join account.Holder.Users as user    left outer join account.Payments as paymentwhere :currentUser = user    and PaymentStatus.Unpaid = isNull(payment.CurrentStatus.Name, PaymentStatus.Unpaid)order by account.Type.SortOrder, account.AccountNumber, payment.DueDate 14.13. Tips & Tricks You can count the number of query results without actually returning them: int count = (int) session.CreateQuery(\"select count(*) from ....\").UniqueResult(); To order a result by the size of a collection, use the following query: select usr.id, usr.Namefrom User as usr     left join usr.Messages as msggroup by usr.id, usr.Nameorder by count(msg) If your database supports subselects, you can place a condition upon selection size in the where clause of your query: from User usr where size(usr.Messages) >= 1 If your database doesn't support subselects, use the following query: select usr.id, usr.Namefrom User usr    join usr.Messages msggroup by usr.id, usr.Namehaving count(msg) >= 1 As this solution can't return a User with zero messages because of the inner join, the following form is also useful: select usr.id, usr.Namefrom User as usr    left join usr.Messages as msggroup by usr.id, usr.Namehaving count(msg) = 0 Properties of an object can be bound to named query parameters: IQuery q = s.CreateQuery(\"from foo in class Foo where foo.Name=:Name and foo.Size=:Size\");q.SetProperties(fooBean); // fooBean has properties Name and SizeIList foos = q.List(); Collections are pageable by using the IQuery interface with a filter: IQuery q = s.CreateFilter( collection, \"\" ); // the trivial filterq.setMaxResults(PageSize);q.setFirstResult(PageSize * pageNumber);IList page = q.List(); Collection elements may be ordered or grouped using a query filter: ICollection orderedCollection = s.Filter( collection, \"order by this.Amount\" );ICollection counts = s.Filter( collection, \"select this.Type, count(this) group by this.Type\" ); Chapter 15. Criteria Queries NHibernate features an intuitive, extensible criteria query API. 15.1. Creating anICriteria instance The interface NHibernate.ICriteria represents a query against a particular persistent class. TheISession is a factory forICriteria instances. ICriteria crit = sess.CreateCriteria(typeof(Cat));crit.SetMaxResults(50);List cats = crit.List(); 15.2. Narrowing the result set An individual query criterion is an instance of the interface NHibernate.Expression.ICriterion. The class NHibernate.Expression.Expression defines factory methods for obtaining certain built-inICriterion types. IList cats = sess.CreateCriteria(typeof(Cat))    .Add( Expression.Like(\"Name\", \"Fritz%\") )    .Add( Expression.Between(\"Weight\", minWeight, maxWeight) )    .List(); Expressions may be grouped logically. IList cats = sess.CreateCriteria(typeof(Cat))    .Add( Expression.Like(\"Name\", \"Fritz%\") )    .Add( Expression.Or(        Expression.Eq( \"Age\", 0 ),        Expression.IsNull(\"Age\")    ) )    .List(); IList cats = sess.CreateCriteria(typeof(Cat))    .Add( Expression.In( \"Name\", new String[] { \"Fritz\", \"Izi\", \"Pk\" } ) )    .Add( Expression.Disjunction()        .Add( Expression.IsNull(\"Age\") )    \t.Add( Expression.Eq(\"Age\", 0 ) )    \t.Add( Expression.Eq(\"Age\", 1 ) )    \t.Add( Expression.Eq(\"Age\", 2 ) )    ) )    .List(); There are quite a range of built-in criterion types (Expression subclasses), but one that is especially useful lets you specify SQL directly.         // Create a string parameter for the SqlString below        IList cats = sess.CreateCriteria(typeof(Cat))            .Add( Expression.Sql(\"lower({alias}.Name) like lower(?)\", \"Fritz%\", NHibernateUtil.String )            .List(); The {alias} placeholder with be replaced by the row alias of the queried entity. 15.3. Ordering the results You may order the results using NHibernate.Expression.Order. IList cats = sess.CreateCriteria(typeof(Cat))    .Add( Expression.Like(\"Name\", \"F%\")    .AddOrder( Order.Asc(\"Name\") )    .AddOrder( Order.Desc(\"Age\") )    .SetMaxResults(50)    .List(); 15.4. Associations You may easily specify constraints upon related entities by navigating associations usingCreateCriteria(). IList cats = sess.CreateCriteria(typeof(Cat))    .Add( Expression.Like(\"Name\", \"F%\")    .CreateCriteria(\"Kittens\")        .Add( Expression.Like(\"Name\", \"F%\") )    .List(); note that the second CreateCriteria() returns a new instance ofICriteria, which refers to the elements of theKittens collection. The following, alternate form is useful in certain circumstances. IList cats = sess.CreateCriteria(typeof(Cat))    .CreateAlias(\"Kittens\", \"kt\")    .CreateAlias(\"Mate\", \"mt\")    .Add( Expression.EqProperty(\"kt.Name\", \"mt.Name\") )    .List(); (CreateAlias() does not create a new instance of ICriteria.) Note that the kittens collections held by the Cat instances returned by the previous two queries arenot pre-filtered by the criteria! If you wish to retrieve just the kittens that match the criteria, you must useSetResultTransformer(Transformers.AliasToEntityMap). IList cats = sess.CreateCriteria(typeof(Cat))    .CreateCriteria(\"Kittens\", \"kt\")        .Add( Expression.Eq(\"Name\", \"F%\") )    .SetResultTransformer(Transformers.AliasToEntityMap)    .List();foreach ( IDictionary map in cats ){    Cat cat = (Cat) map[CriteriaUtil.RootAlias];    Cat kitten = (Cat) map[\"kt\"];} 15.5. Dynamic association fetching You may specify association fetching semantics at runtime using SetFetchMode(). IList cats = sess.CreateCriteria(typeof(Cat))    .Add( Expression.Like(\"Name\", \"Fritz%\") )    .SetFetchMode(\"Mate\", FetchMode.Eager)    .SetFetchMode(\"Kittens\", FetchMode.Eager)    .List(); This query will fetch both Mate and Kittens by outer join. See Section 19.1, “Fetching strategies” for more information. 15.6. Example queries The class NHibernate.Expression.Example allows you to construct a query criterion from a given instance. Cat cat = new Cat();cat.Sex = 'F';cat.Color = Color.Black;List results = session.CreateCriteria(typeof(Cat))    .Add( Example.Create(cat) )    .List(); Version properties, identifiers and associations are ignored. By default, null-valued properties and properties which return an empty string from the call toToString() are excluded. You can adjust how the Example is applied. Example example = Example.Create(cat)    .ExcludeZeroes()           //exclude null- or zero-valued properties    .ExcludeProperty(\"Color\")  //exclude the property named \"color\"    .IgnoreCase()              //perform case insensitive string comparisons    .EnableLike();             //use like for string comparisonsIList results = session.CreateCriteria(typeof(Cat))    .Add(example)    .List(); You can even use examples to place criteria upon associated objects. IList results = session.CreateCriteria(typeof(Cat))    .Add( Example.Create(cat) )    .CreateCriteria(\"Mate\")        .Add( Example.Create( cat.Mate ) )    .List(); 15.7. Projections, aggregation and grouping The class NHibernate.Expression.Projections is a factory forIProjection instances. We apply a projection to a query by callingSetProjection(). IList results = session.CreateCriteria(typeof(Cat))    .SetProjection( Projections.RowCount() )    .Add( Expression.Eq(\"Color\", Color.BLACK) )    .List(); List results = session.CreateCriteria(typeof(Cat))    .SetProjection( Projections.ProjectionList()        .Add( Projections.RowCount() )        .Add( Projections.Avg(\"Weight\") )        .Add( Projections.Max(\"Weight\") )        .Add( Projections.GroupProperty(\"Color\") )    )    .List(); There is no explicit \"group by\" necessary in a criteria query. Certain projection types are defined to begrouping projections, which also appear in the SQLgroup by clause. An alias may optionally be assigned to a projection, so that the projected value may be referred to in restrictions or orderings. Here are two different ways to do this: IList results = session.CreateCriteria(typeof(Cat))    .SetProjection( Projections.Alias( Projections.GroupProperty(\"Color\"), \"colr\" ) )    .AddOrder( Order.Asc(\"colr\") )    .List(); IList results = session.CreateCriteria(typeof(Cat))    .SetProjection( Projections.GroupProperty(\"Color\").As(\"colr\") )    .AddOrder( Order.Asc(\"colr\") )    .List(); The Alias() and As() methods simply wrap a projection instance in another, aliased, instance ofIProjection. As a shortcut, you can assign an alias when you add the projection to a projection list: IList results = session.CreateCriteria(typeof(Cat))    .SetProjection( Projections.ProjectionList()        .Add( Projections.RowCount(), \"catCountByColor\" )        .Add( Projections.Avg(\"Weight\"), \"avgWeight\" )        .Add( Projections.Max(\"Weight\"), \"maxWeight\" )        .Add( Projections.GroupProperty(\"Color\"), \"color\" )    )    .AddOrder( Order.Desc(\"catCountByColor\") )    .AddOrder( Order.Desc(\"avgWeight\") )    .List(); IList results = session.CreateCriteria(typeof(DomesticCat), \"cat\")    .CreateAlias(\"kittens\", \"kit\")    .SetProjection( Projections.ProjectionList()        .Add( Projections.Property(\"cat.Name\"), \"catName\" )        .Add( Projections.Property(\"kit.Name\"), \"kitName\" )    )    .AddOrder( Order.Asc(\"catName\") )    .AddOrder( Order.Asc(\"kitName\") )    .List(); 15.8. Detached queries and subqueries The DetachedCriteria class lets you create a query outside the scope of a session, and then later execute it using some arbitraryISession. DetachedCriteria query = DetachedCriteria.For(typeof(Cat))    .Add( Expression.Eq(\"sex\", 'F') );    ISession session = ....;ITransaction txn = session.BeginTransaction();IList results = query.GetExecutableCriteria(session).SetMaxResults(100).List();txn.Commit();session.Close(); A DetachedCriteria may also be used to express a subquery. ICriterion instances involving subqueries may be obtained viaSubqueries . DetachedCriteria avgWeight = DetachedCriteria.For(typeof(Cat))    .SetProjection( Projections.Avg(\"Weight\") );session.CreateCriteria(typeof(Cat))    .Add( Subqueries.Gt(\"Weight\", avgWeight) )    .List(); DetachedCriteria weights = DetachedCriteria.For(typeof(Cat))    .SetProjection( Projections.Property(\"Weight\") );session.CreateCriteria(typeof(Cat))    .add( Subqueries.GeAll(\"Weight\", weights) )    .list(); Even correlated subqueries are possible: DetachedCriteria avgWeightForSex = DetachedCriteria.For(typeof(Cat), \"cat2\")    .SetProjection( Projections.Avg(\"Weight\") )    .Add( Expression.EqProperty(\"cat2.Sex\", \"cat.Sex\") );session.CreateCriteria(typeof(Cat), \"cat\")    .Add( Subqueries.Gt(\"weight\", avgWeightForSex) )    .List(); Chapter 16. QueryOver Queries The ICriteria API is NHibernate's implementation of Query Object. NHibernate 3.0 introduces the QueryOver api, which combines the use of Extension Methods and Lambda Expressions (both new in .Net 3.5) to provide a statically typesafe wrapper round the ICriteria API. QueryOver uses Lambda Expressions to provide some extra syntax to remove the 'magic strings' from your ICriteria queries. So, for example: .Add(Expression.Eq(\"Name\", \"Smith\")) becomes: .Where<Person>(p => p.Name == \"Smith\") With this kind of syntax there are no 'magic strings', and refactoring tools like 'Find All References', and 'Refactor->Rename' work perfectly. Note: QueryOver is intended to remove the references to 'magic strings' from the ICriteria API while maintaining it's opaqueness. It isnot a LINQ provider; NHibernate has a built-in Linq provider for this. 16.1. Structure of a Query Queries are created from an ISession using the syntax: IList<Cat> cats =    session.QueryOver<Cat>()        .Where(c => c.Name == \"Max\")        .List(); Detached QueryOver (analagous to DetachedCriteria) can be created, and then used with an ISession using: QueryOver<Cat> query =    QueryOver.Of<Cat>()        .Where(c => c.Name == \"Paddy\");        IList<Cat> cats =    query.GetExecutableQueryOver(session)        .List(); Queries can be built up to use restrictions, projections, and ordering using a fluent inline syntax: var catNames =    session.QueryOver<Cat>()        .WhereRestrictionOn(c => c.Age).IsBetween(2).And(8)        .Select(c => c.Name)        .OrderBy(c => c.Name).Asc        .List<string>(); 16.2. Simple Expressions The Restrictions class (used by ICriteria) has been extended to include overloads that allow Lambda Expression syntax. The Where() method works for simple expressions (<, <=, ==, !=, >, >=) so instead of: ICriterion equalCriterion = Restrictions.Eq(\"Name\", \"Max\") You can write: ICriterion equalCriterion = Restrictions.Where<Cat>(c => c.Name == \"Max\") Since the QueryOver class (and IQueryOver interface) is generic and knows the type of the query, there is an inline syntax for restrictions that does not require the additional qualification of class name. So you can also write: var cats =    session.QueryOver<Cat>()        .Where(c => c.Name == \"Max\")        .And(c => c.Age > 4)        .List(); Note, the methods Where() and And() are semantically identical; the And() method is purely to allow QueryOver to look similar to HQL/SQL. Boolean comparisons can be made directly instead of comparing to true/false:         .Where(p => p.IsParent)        .And(p => !p.IsRetired) Simple expressions can also be combined using the || and && operators. So ICriteria like:         .Add(Restrictions.And(                Restrictions.Eq(\"Name\", \"test name\"),                Restrictions.Or(                    Restrictions.Gt(\"Age\", 21),                    Restrictions.Eq(\"HasCar\", true)))) Can be written in QueryOver as:         .Where(p => p.Name == \"test name\" && (p.Age > 21 || p.HasCar)) Each of the corresponding overloads in the QueryOver API allows the use of regular ICriterion to allow access to private properties.         .Where(Restrictions.Eq(\"Name\", \"Max\")) It is worth noting that the QueryOver API is built on top of the ICriteria API. Internally the structures are the same, so at runtime the statement below, and the statement above, are stored as exactly the same ICriterion. The actual Lambda Expression is not stored in the query.         .Where(c => c.Name == \"Max\") 16.3. Additional Restrictions Some SQL operators/functions do not have a direct equivalent in C#. (e.g., the SQLwhere name like '%anna%'). These operators have overloads for QueryOver in the Restrictions class, so you can write:         .Where(Restrictions.On<Cat>(c => c.Name).IsLike(\"%anna%\")) There is also an inline syntax to avoid the qualification of the type:         .WhereRestrictionOn(c => c.Name).IsLike(\"%anna%\") While simple expressions (see above) can be combined using the || and && operators, this is not possible with the other restrictions. So this ICriteria:         .Add(Restrictions.Or(            Restrictions.Gt(\"Age\", 5)            Restrictions.In(\"Name\", new string[] { \"Max\", \"Paddy\" }))) Would have to be written as:         .Add(Restrictions.Or(            Restrictions.Where<Cat>(c => c.Age > 5)            Restrictions.On<Cat>(c => c.Name).IsIn(new string[] { \"Max\", \"Paddy\" }))) However, in addition to the additional restrictions factory methods, there are extension methods to allow a more concise inline syntax for some of the operators. So this:         .WhereRestrictionOn(c => c.Name).IsLike(\"%anna%\") May also be written as:         .Where(c => c..Name.IsLike(\"%anna%\")) 16.4. Associations QueryOver can navigate association paths using JoinQueryOver() (analagous to ICriteria.CreateCriteria() to create sub-criteria). The factory method QuerOver<T>() on ISession returns an IQueryOver<T>. More accurately, it returns an IQueryOver<T,T> (which inherits from IQueryOver<T>). An IQueryOver has two types of interest; the root type (the type of entity that the query returns), and the type of the 'current' entity being queried. For example, the following query uses a join to create a sub-QueryOver (analagous to creating sub-criteria in the ICriteria API): IQueryOver<Cat,Kitten> catQuery =    session.QueryOver<Cat>()        .JoinQueryOver(c => c.Kittens)            .Where(k => k.Name == \"Tiddles\"); The JoinQueryOver returns a new instance of the IQueryOver than has its root at the Kittens collection. The default type for restrictions is now Kitten (restricting on the name 'Tiddles' in the above example), while calling .List() will return an IList<Cat>. The type IQueryOver<Cat,Kitten> inherits from IQueryOver<Cat>. Note, the overload for JoinQueryOver takes an IEnumerable<T>, and the C# compiler infers the type from that. If your collection type is not IEnumerable<T>, then you need to qualify the type of the sub-criteria: IQueryOver<Cat,Kitten> catQuery =    session.QueryOver<Cat>()        .JoinQueryOver<Kitten>(c => c.Kittens)            .Where(k => k.Name == \"Tiddles\"); The default join is an inner-join. Each of the additional join types can be specified using the methods.Inner, .Left, .Right, or.Full. For example, to left outer-join on Kittens use: IQueryOver<Cat,Kitten> catQuery =    session.QueryOver<Cat>()        .Left.JoinQueryOver(c => c.Kittens)            .Where(k => k.Name == \"Tiddles\"); 16.5. Aliases In the traditional ICriteria interface aliases are assigned using 'magic strings', however their value does not correspond to a name in the object domain. For example, when an alias is assigned using.CreateAlias(\"Kitten\", \"kittenAlias\"), the string \"kittenAlias\" does not correspond to a property or class in the domain. In QueryOver, aliases are assigned using an empty variable. The variable can be declared anywhere (but should benull at runtime). The compiler can then check the syntax against the variable is used correctly, but at runtime the variable is not evaluated (it's just used as a placeholder for the alias). Each Lambda Expression function in QueryOver has a corresponding overload to allow use of aliases, and a .JoinAlias function to traverse associations using aliases without creating a sub-QueryOver. Cat catAlias = null;Kitten kittenAlias = null;IQueryOver<Cat,Cat> catQuery =    session.QueryOver<Cat>(() => catAlias)        .JoinAlias(() => catAlias.Kittens, () => kittenAlias)        .Where(() => catAlias.Age > 5)        .And(() => kittenAlias.Name == \"Tiddles\"); 16.6. Projections Simple projections of the properties of the root type can be added using the .Select method which can take multiple Lambda Expression arguments: IList selection =    session.QueryOver<Cat>()        .Select(            c => c.Name,            c => c.Age)        .List<object[]>(); Because this query no longer returns a Cat, the return type must be explicitly specified. If a single property is projected, the return type can be specified using: IList<int> ages =    session.QueryOver<Cat>()        .Select(c => c.Age)        .List<int>(); However, if multiple properties are projected, then the returned list will contain object arrays, as per a projection in ICriteria. This could be fed into an anonymous type using: var catDetails =    session.QueryOver<Cat>()        .Select(            c => c.Name,            c => c.Age)        .List<object[]>()        .Select(properties => new {            CatName = (string)properties[0],            CatAge = (int)properties[1],            });            Console.WriteLine(catDetails[0].CatName);Console.WriteLine(catDetails[0].CatAge); Note that the second .Select call in this example is an extension method on IEnumerable<T> supplied in System.Linq; it is not part of NHibernate. QueryOver allows arbitrary IProjection to be added (allowing private properties to be projected). The Projections factory class also has overloads to allow Lambda Expressions to be used: IList selection =    session.QueryOver<Cat>()        .Select(Projections.ProjectionList()            .Add(Projections.Property<Cat>(c => c.Name))            .Add(Projections.Avg<Cat>(c => c.Age)))        .List<object[]>(); In addition there is an inline syntax for creating projection lists that does not require the explicit class qualification: IList selection =    session.QueryOver<Cat>()        .SelectList(list => list            .Select(c => c.Name)            .SelectAvg(c => c.Age))        .List<object[]>(); Projections can also have arbitrary aliases assigned to them to allow result transformation. If there is a CatSummary DTO class defined as: public class CatSummary{    public string Name { get; set; }    public int AverageAge { get; set; }} ... then aliased projections can be used with the AliasToBean<T> transformer: CatSummary summaryDto = null;IList<CatSummary> catReport =    session.QueryOver<Cat>()        .SelectList(list => list            .SelectGroup(c => c.Name).WithAlias(() => summaryDto.Name)            .SelectAvg(c => c.Age).WithAlias(() => summaryDto.AverageAge))        .TransformUsing(Transformers.AliasToBean<CatSummary>())        .List<CatSummary>(); 16.7. Projection Functions In addition to projecting properties, there are extension methods to allow certain common dialect-registered functions to be applied. For example you can write the following to extract just the year part of a date:         .Where(p => p.BirthDate.YearPart() == 1971) The functions can also be used inside projections:         .Select(            p => Projections.Concat(p.LastName, \", \", p.FirstName),            p => p.Height.Abs()) 16.8. Subqueries The Subqueries factory class has overloads to allow Lambda Expressions to express sub-query restrictions. For example: QueryOver<Cat> maximumAge =    QueryOver.Of<Cat>()        .SelectList(p => p.SelectMax(c => c.Age));IList<Cat> oldestCats =    session.QueryOver<Cat>()        .Where(Subqueries.WhereProperty<Cat>(c => c.Age).Eq(maximumAge))        .List(); The inline syntax allows you to use subqueries without requalifying the type: IList<Cat> oldestCats =    session.QueryOver<Cat>()        .WithSubquery.WhereProperty(c => c.Age).Eq(maximumAge)        .List(); There is an extension method As() on (a detached) QueryOver that allows you to cast it to any type. This is used in conjunction with the overloadsWhere(), WhereAll(), andWhereSome() to allow use of the built-in C# operators for comparison, so the above query can be written as: IList<Cat> oldestCats =    session.QueryOver<Cat>()        .WithSubquery.Where(c => c.Age == maximumAge.As<int>())        .List(); Chapter 17. Native SQL You may also express queries in the native SQL dialect of your database. This is useful if you want to utilize database specific features such as query hints or theCONNECT keyword in Oracle. It also provides a clean migration path from a direct SQL/ADO.NET based application to NHibernate. NHibernate allows you to specify handwritten SQL (including stored procedures) for all create, update, delete, and load operations. 17.1. Using anISQLQuery Execution of native SQL queries is controlled via the ISQLQuery interface, which is obtained by callingISession.CreateSQLQuery(). The following describes how to use this API for querying. 17.1.1. Scalar queries The most basic SQL query is to get a list of scalars (values). sess.CreateSQLQuery(\"SELECT * FROM CATS\") .AddScalar(\"ID\", NHibernateUtil.Int64) .AddScalar(\"NAME\", NHibernateUtil.String) .AddScalar(\"BIRTHDATE\", NHibernateUtil.Date) This query specified: the SQL query string the columns and types to return This will return an IList of Object arrays (object[]) with scalar values for each column in the CATS table. Only these three columns will be returned, even though the query is using* and could return more than the three listed columns. 17.1.2. Entity queries The above query was about returning scalar values, basically returning the \"raw\" values from the result set. The following shows how to get entity objects from a native SQL query viaAddEntity(). sess.CreateSQLQuery(\"SELECT * FROM CATS\").AddEntity(typeof(Cat));sess.CreateSQLQuery(\"SELECT ID, NAME, BIRTHDATE FROM CATS\").AddEntity(typeof(Cat)); This query specified: the SQL query string the entity returned by the query Assuming that Cat is mapped as a class with the columns ID, NAME and BIRTHDATE the above queries will both return an IList where each element is a Cat entity. If the entity is mapped with a many-to-one to another entity it is required to also return its identifier when performing the native query, otherwise a database specific \"column not found\" error will occur. The additional columns will automatically be returned when using the * notation, but we prefer to be explicit as in the following example for amany-to-one to aDog: sess.CreateSQLQuery(\"SELECT ID, NAME, BIRTHDATE, DOG_ID FROM CATS\").AddEntity(typeof(Cat)); This will allow cat.Dog property access to function properly. 17.1.3. Handling associations and collections It is possible to eagerly join in the Dog to avoid the possible extra roundtrip for initializing the proxy. This is done via theAddJoin() method, which allows you to join in an association or collection. sess.CreateSQLQuery(\"SELECT c.ID, NAME, BIRTHDATE, DOG_ID, D_ID, D_NAME FROM CATS c, DOGS d WHERE c.DOG_ID = d.D_ID\") .AddEntity(\"cat\", typeof(Cat)) .AddJoin(\"cat.Dog\"); In this example the returned Cat's will have their Dog property fully initialized without any extra roundtrip to the database. Notice that we added a alias name (\"cat\") to be able to specify the target property path of the join. It is possible to do the same eager joining for collections, e.g. if theCat had a one-to-many to Dog instead. sess.CreateSQLQuery(\"SELECT ID, NAME, BIRTHDATE, D_ID, D_NAME, CAT_ID FROM CATS c, DOGS d WHERE c.ID = d.CAT_ID\") .AddEntity(\"cat\", typeof(Cat)) .AddJoin(\"cat.Dogs\"); At this stage we are reaching the limits of what is possible with native queries without starting to enhance the SQL queries to make them usable in NHibernate; the problems start to arise when returning multiple entities of the same type or when the default alias/column names are not enough. 17.1.4. Returning multiple entities Until now the result set column names are assumed to be the same as the column names specified in the mapping document. This can be problematic for SQL queries which join multiple tables, since the same column names may appear in more than one table. Column alias injection is needed in the following query (which most likely will fail): sess.CreateSQLQuery(\"SELECT c.*, m.*  FROM CATS c, CATS m WHERE c.MOTHER_ID = c.ID\") .AddEntity(\"cat\", typeof(Cat)) .AddEntity(\"mother\", typeof(Cat)) The intention for this query is to return two Cat instances per row, a cat and its mother. This will fail since there is a conflict of names since they are mapped to the same column names and on some databases the returned column aliases will most likely be on the form \"c.ID\", \"c.NAME\", etc. which are not equal to the columns specificed in the mappings (\"ID\" and \"NAME\"). The following form is not vulnerable to column name duplication: sess.CreateSQLQuery(\"SELECT {cat.*}, {mother.*}  FROM CATS c, CATS m WHERE c.MOTHER_ID = c.ID\") .AddEntity(\"cat\", typeof(Cat)) .AddEntity(\"mother\", typeof(Cat)) This query specified: the SQL query string, with placeholders for NHibernate to inject column aliases the entities returned by the query The {cat.*} and {mother.*} notation used above is a shorthand for \"all properties\". Alternatively, you may list the columns explicity, but even in this case we let NHibernate inject the SQL column aliases for each property. The placeholder for a column alias is just the property name qualified by the table alias. In the following example, we retrieve Cats and their mothers from a different table (cat_log) to the one declared in the mapping metadata. Notice that we may even use the property aliases in the where clause if we like. String sql = \"SELECT ID as {c.Id}, NAME as {c.Name}, \" +          \"BIRTHDATE as {c.BirthDate}, MOTHER_ID as {c.Mother}, {mother.*} \" +         \"FROM CAT_LOG c, CAT_LOG m WHERE {c.Mother} = c.ID\";IList loggedCats = sess.CreateSQLQuery(sql)        .AddEntity(\"cat\", typeof(Cat))        .AddEntity(\"mother\", typeof(Cat)).List(); 17.1.4.1. Alias and property references For most cases the above alias injection is needed, but for queries relating to more complex mappings like composite properties, inheritance discriminators, collections etc. there are some specific aliases to use to allow NHibernate to inject the proper aliases. The following table shows the different possibilities of using the alias injection. Note: the alias names in the result are examples, each alias will have a unique and probably different name when used. Table 17.1. Alias injection names Description Syntax Example A simple property {[aliasname].[propertyname]} A_NAME as {item.Name} A composite property {[aliasname].[componentname].[propertyname]} CURRENCY as {item.Amount.Currency}, VALUE as {item.Amount.Value} Discriminator of an entity {[aliasname].class} DISC as {item.class} All properties of an entity {[aliasname].*} {item.*} A collection key {[aliasname].key} ORGID as {coll.key} The id of an collection {[aliasname].id} EMPID as {coll.id} The element of an collection {[aliasname].element} XID as {coll.element} property of the element in the collection {[aliasname].element.[propertyname]} NAME as {coll.element.Name} All properties of the element in the collection {[aliasname].element.*} {coll.element.*} All properties of the the collection {[aliasname].*} {coll.*} 17.1.5. Returning non-managed entities It is possible to apply an IResultTransformer to native sql queries. Allowing it to e.g. return non-managed entities. sess.CreateSQLQuery(\"SELECT NAME, BIRTHDATE FROM CATS\")        .SetResultTransformer(Transformers.AliasToBean(typeof(CatDTO))) This query specified: the SQL query string a result transformer The above query will return a list of CatDTO which has been instantiated and injected the values of NAME and BIRTHNAME into its corresponding properties or fields. IMPORTANT: The custom IResultTransformer should overrideEquals andGetHashCode, otherwise the query translation won't be cached. This also will result in memory leak. 17.1.6. Handling inheritance Native SQL queries which query for entities that are mapped as part of an inheritance hierarchy must include all properties for the base class and all its subclasses. 17.1.7. Parameters Native SQL queries support positional as well as named parameters: Query query = sess.CreateSQLQuery(\"SELECT * FROM CATS WHERE NAME like ?\").AddEntity(typeof(Cat));IList pusList = query.SetString(0, \"Pus%\").List();     query = sess.createSQLQuery(\"SELECT * FROM CATS WHERE NAME like :name\").AddEntity(typeof(Cat));IList pusList = query.SetString(\"name\", \"Pus%\").List();          17.2. Named SQL queries Named SQL queries may be defined in the mapping document and called in exactly the same way as a named HQL query. In this case, we donot need to callAddEntity(). <sql-query name=\"persons\">    <return alias=\"person\" class=\"eg.Person\"/>    SELECT person.NAME AS {person.Name},           person.AGE AS {person.Age},           person.SEX AS {person.Sex}    FROM PERSON person    WHERE person.NAME LIKE :namePattern<\/sql-query> IList people = sess.GetNamedQuery(\"persons\")    .SetString(\"namePattern\", namePattern)    .SetMaxResults(50)    .List(); The <return-join> and <load-collection> elements are used to join associations and define queries which initialize collections, respectively. <sql-query name=\"personsWith\">    <return alias=\"person\" class=\"eg.Person\"/>    <return-join alias=\"address\" property=\"person.MailingAddress\"/>    SELECT person.NAME AS {person.Name},           person.AGE AS {person.Age},           person.SEX AS {person.Sex},           adddress.STREET AS {address.Street},           adddress.CITY AS {address.City},           adddress.STATE AS {address.State},           adddress.ZIP AS {address.Zip}    FROM PERSON person    JOIN ADDRESS adddress        ON person.ID = address.PERSON_ID AND address.TYPE='MAILING'    WHERE person.NAME LIKE :namePattern<\/sql-query> A named SQL query may return a scalar value. You must declare the column alias and NHibernate type using the<return-scalar> element: <sql-query name=\"mySqlQuery\">    <return-scalar column=\"name\" type=\"String\"/>    <return-scalar column=\"age\" type=\"Int64\"/>    SELECT p.NAME AS name,           p.AGE AS age,    FROM PERSON p WHERE p.NAME LIKE 'Hiber%'<\/sql-query> You can externalize the resultset mapping informations in a <resultset> element to either reuse them accross several named queries or through theSetResultSetMapping() API. <resultset name=\"personAddress\">    <return alias=\"person\" class=\"eg.Person\"/>    <return-join alias=\"address\" property=\"person.MailingAddress\"/><\/resultset><sql-query name=\"personsWith\" resultset-ref=\"personAddress\">    SELECT person.NAME AS {person.Name},           person.AGE AS {person.Age},           person.SEX AS {person.Sex},           adddress.STREET AS {address.Street},           adddress.CITY AS {address.City},           adddress.STATE AS {address.State},           adddress.ZIP AS {address.Zip}    FROM PERSON person    JOIN ADDRESS adddress        ON person.ID = address.PERSON_ID AND address.TYPE='MAILING'    WHERE person.NAME LIKE :namePattern<\/sql-query> You can alternatively use the resultset mapping information in your .hbm.xml files directly in code. IList cats = sess.CreateSQLQuery(        \"select {cat.*}, {kitten.*} from cats cat, cats kitten where kitten.mother = cat.id\"    )    .SetResultSetMapping(\"catAndKitten\")    .List(); 17.2.1. Using return-property to explicitly specify column/alias names With <return-property> you can explicitly tell NHibernate what column aliases to use, instead of using the{}-syntax to let NHibernate inject its own aliases. <sql-query name=\"mySqlQuery\">    <return alias=\"person\" class=\"eg.Person\">        <return-property name=\"Name\" column=\"myName\"/>        <return-property name=\"Age\" column=\"myAge\"/>        <return-property name=\"Sex\" column=\"mySex\"/>    <\/return>    SELECT person.NAME AS myName,           person.AGE AS myAge,           person.SEX AS mySex,    FROM PERSON person WHERE person.NAME LIKE :name<\/sql-query> <return-property> also works with multiple columns. This solves a limitation with the{}-syntax which can not allow fine grained control of multi-column properties. <sql-query name=\"organizationCurrentEmployments\">    <return alias=\"emp\" class=\"Employment\">        <return-property name=\"Salary\">            <return-column name=\"VALUE\"/>            <return-column name=\"CURRENCY\"/>        <\/return-property>        <return-property name=\"EndDate\" column=\"myEndDate\"/>    <\/return>        SELECT EMPLOYEE AS {emp.Employee}, EMPLOYER AS {emp.Employer},        STARTDATE AS {emp.StartDate}, ENDDATE AS {emp.EndDate},        REGIONCODE as {emp.RegionCode}, EID AS {emp.Id}, VALUE, CURRENCY        FROM EMPLOYMENT        WHERE EMPLOYER = :id AND ENDDATE IS NULL        ORDER BY STARTDATE ASC<\/sql-query> Notice that in this example we used <return-property> in combination with the{}-syntax for injection, allowing users to choose how they want to refer column and properties. If your mapping has a discriminator you must use <return-discriminator> to specify the discriminator column. 17.2.2. Using stored procedures for querying NHibernate introduces support for queries via stored procedures and functions. Most of the following documentation is equivalent for both. The stored procedure/function must return a resultset to be able to work with NHibernate. An example of such a stored function in MS SQL Server 2000 and higher is as follows: CREATE PROCEDURE selectAllEmployments AS    SELECT EMPLOYEE, EMPLOYER, STARTDATE, ENDDATE,    REGIONCODE, EMPID, VALUE, CURRENCY    FROM EMPLOYMENT To use this query in NHibernate you need to map it via a named query. <sql-query name=\"selectAllEmployments_SP\">    <return alias=\"emp\" class=\"Employment\">        <return-property name=\"employee\" column=\"EMPLOYEE\"/>        <return-property name=\"employer\" column=\"EMPLOYER\"/>        <return-property name=\"startDate\" column=\"STARTDATE\"/>        <return-property name=\"endDate\" column=\"ENDDATE\"/>        <return-property name=\"regionCode\" column=\"REGIONCODE\"/>        <return-property name=\"id\" column=\"EID\"/>        <return-property name=\"salary\">            <return-column name=\"VALUE\"/>            <return-column name=\"CURRENCY\"/>        <\/return-property>    <\/return>    exec selectAllEmployments<\/sql-query> Notice that stored procedures currently only return scalars and entities. <return-join> and <load-collection> are not supported. 17.2.2.1. Rules/limitations for using stored procedures To use stored procedures with NHibernate the procedures/functions have to follow some rules. If they do not follow those rules they are not usable with NHibernate. If you still want to use these procedures you have to execute them viasession.Connection. The rules are different for each database, since database vendors have different stored procedure semantics/syntax. Stored procedure queries can't be paged with SetFirstResult()/SetMaxResults(). Recommended call form is dependent on your database. For MS SQL Server use exec functionName <parameters>. For Oracle the following rules apply: A function must return a result set. The first parameter of a procedure must be anOUT that returns a result set. This is done by using aSYS_REFCURSOR type in Oracle 9 or 10. In Oracle you need to define aREF CURSOR type, see Oracle literature. For MS SQL server the following rules apply: The procedure must return a result set. NHibernate will use IDbCommand.ExecuteReader() to obtain the results. If you can enable SET NOCOUNT ON in your procedure it will probably be more efficient, but this is not a requirement. 17.3. Custom SQL for create, update and delete NHibernate can use custom SQL statements for create, update, and delete operations. The class and collection persisters in NHibernate already contain a set of configuration time generated strings (insertsql, deletesql, updatesql etc.). The mapping tags<sql-insert>,<sql-delete>, and<sql-update> override these strings: <class name=\"Person\">    <id name=\"id\">        <generator class=\"increment\"/>    <\/id>    <property name=\"name\" not-null=\"true\"/>    <sql-insert>INSERT INTO PERSON (NAME, ID) VALUES ( UPPER(?), ? )<\/sql-insert>    <sql-update>UPDATE PERSON SET NAME=UPPER(?) WHERE ID=?<\/sql-update>    <sql-delete>DELETE FROM PERSON WHERE ID=?<\/sql-delete><\/class> Note that the custom sql-insert will not be used if you useidentity to generate identifier values for the class. The SQL is directly executed in your database, so you are free to use any dialect you like. This will of course reduce the portability of your mapping if you use database specific SQL. Stored procedures are supported if the database-native syntax is used: <class name=\"Person\">    <id name=\"id\">        <generator class=\"increment\"/>    <\/id>    <property name=\"name\" not-null=\"true\"/>    <sql-insert>exec createPerson ?, ?<\/sql-insert>    <sql-delete>exec deletePerson ?<\/sql-delete>    <sql-update>exec updatePerson ?, ?<\/sql-update><\/class> The order of the positional parameters is currently vital, as they must be in the same sequence as NHibernate expects them. You can see the expected order by enabling debug logging for the NHibernate.Persister.Entity level. With this level enabled NHibernate will print out the static SQL that is used to create, update, delete etc. entities. (To see the expected sequence, remember to not include your custom SQL in the mapping files as that will override the NHibernate generated static sql.) The stored procedures are by default required to affect the same number of rows as NHibernate-generated SQL would. NHibernate usesIDbCommand.ExecuteNonQuery to retrieve the number of rows affected. This check can be disabled by usingcheck=\"none\" attribute in sql-insert element. 17.4. Custom SQL for loading You may also declare your own SQL (or HQL) queries for entity loading: <sql-query name=\"person\">    <return alias=\"pers\" class=\"Person\" lock-mode=\"upgrade\"/>    SELECT NAME AS {pers.Name}, ID AS {pers.Id}    FROM PERSON    WHERE ID=?    FOR UPDATE<\/sql-query> This is just a named query declaration, as discussed earlier. You may reference this named query in a class mapping: <class name=\"Person\">    <id name=\"Id\">        <generator class=\"increment\"/>    <\/id>    <property name=\"Name\" not-null=\"true\"/>    <loader query-ref=\"person\"/><\/class> This even works with stored procedures. You may even define a query for collection loading: <set name=\"Employments\" inverse=\"true\">    <key/>    <one-to-many class=\"Employment\"/>    <loader query-ref=\"employments\"/><\/set> <sql-query name=\"employments\">    <load-collection alias=\"emp\" role=\"Person.Employments\"/>    SELECT {emp.*}    FROM EMPLOYMENT emp    WHERE EMPLOYER = :id    ORDER BY STARTDATE ASC, EMPLOYEE ASC<\/sql-query> You could even define an entity loader that loads a collection by join fetching: <sql-query name=\"person\">    <return alias=\"pers\" class=\"Person\"/>    <return-join alias=\"emp\" property=\"pers.Employments\"/>    SELECT NAME AS {pers.*}, {emp.*}    FROM PERSON pers    LEFT OUTER JOIN EMPLOYMENT emp        ON pers.ID = emp.PERSON_ID    WHERE ID=?<\/sql-query> Chapter 18. Filtering data NHibernate provides an innovative new approach to handling data with \"visibility\" rules. ANHibernate filter is a global, named, parameterized filter that may be enabled or disabled for a particular NHibernate session. 18.1. NHibernate filters NHibernate adds the ability to pre-define filter criteria and attach those filters at both a class and a collection level. A filter criteria is the ability to define a restriction clause very similiar to the existing \"where\" attribute available on the class and various collection elements. Except these filter conditions can be parameterized. The application can then make the decision at runtime whether given filters should be enabled and what their parameter values should be. Filters can be used like database views, but parameterized inside the application. In order to use filters, they must first be defined and then attached to the appropriate mapping elements. To define a filter, use the<filter-def/> element within a<hibernate-mapping/> element: <filter-def name=\"myFilter\">    <filter-param name=\"myFilterParam\" type=\"String\"/><\/filter-def> Then, this filter can be attached to a class: <class name=\"MyClass\" ...>    ...    <filter name=\"myFilter\" condition=\":myFilterParam = MY_FILTERED_COLUMN\"/><\/class> or, to a collection: <set ...>    <filter name=\"myFilter\" condition=\":myFilterParam = MY_FILTERED_COLUMN\"/><\/set> or, even to both (or multiples of each) at the same time. The methods on ISession are: EnableFilter(string filterName),GetEnabledFilter(string filterName), andDisableFilter(string filterName). By default, filters arenot enabled for a given session; they must be explcitly enabled through use of theISession.EnableFilter() method, which returns an instance of theIFilter interface. Using the simple filter defined above, this would look like: session.EnableFilter(\"myFilter\").SetParameter(\"myFilterParam\", \"some-value\"); Note that methods on the NHibernate.IFilter interface do allow the method-chaining common to much of NHibernate. A full example, using temporal data with an effective record date pattern: <filter-def name=\"effectiveDate\">    <filter-param name=\"asOfDate\" type=\"date\"/><\/filter-def><class name=\"Employee\" ...>...    <many-to-one name=\"Department\" column=\"dept_id\" class=\"Department\"/>    <property name=\"EffectiveStartDate\" type=\"date\" column=\"eff_start_dt\"/>    <property name=\"EffectiveEndDate\" type=\"date\" column=\"eff_end_dt\"/>...    <!--        Note that this assumes non-terminal records have an eff_end_dt set to        a max db date for simplicity-sake    -->    <filter name=\"effectiveDate\"            condition=\":asOfDate BETWEEN eff_start_dt and eff_end_dt\"/><\/class><class name=\"Department\" ...>...    <set name=\"Employees\" lazy=\"true\">        <key column=\"dept_id\"/>        <one-to-many class=\"Employee\"/>        <filter name=\"effectiveDate\"                condition=\":asOfDate BETWEEN eff_start_dt and eff_end_dt\"/>    <\/set><\/class> Then, in order to ensure that you always get back currently effective records, simply enable the filter on the session prior to retrieving employee data: ISession session = ...;session.EnableFilter(\"effectiveDate\").SetParameter(\"asOfDate\", DateTime.Today);IList results = session.CreateQuery(\"from Employee as e where e.Salary > :targetSalary\")         .SetInt64(\"targetSalary\", 1000000L)         .List(); In the HQL above, even though we only explicitly mentioned a salary constraint on the results, because of the enabled filter the query will return only currently active employees who have a salary greater than a million dollars. Note: if you plan on using filters with outer joining (either through HQL or load fetching) be careful of the direction of the condition expression. It's safest to set this up for left outer joining; in general, place the parameter first followed by the column name(s) after the operator. Default all filter definitions are applied to <many-to-one/> and<one-to-one/> elements. You can turn off this behaviour by usinguse-many-to-one attribute on<filter-def/> element. <filter-def name=\"effectiveDate\" use-many-to-one=\"false\"/> Chapter 19. Improving performance 19.1. Fetching strategies A fetching strategy is the strategy NHibernate will use for retrieving associated objects if the application needs to navigate the association. Fetch strategies may be declared in the O/R mapping metadata, or overridden by a particular HQL or Criteria query. NHibernate defines the following fetching strategies: Join fetching - NHibernate retrieves the associated instance or collection in the sameSELECT, using anOUTER JOIN. Select fetching - a second SELECT is used to retrieve the associated entity or collection. Unless you explicitly disable lazy fetching by specifyinglazy=\"false\", this second select will only be executed when you actually access the association. Subselect fetching - a second SELECT is used to retrieve the associated collections for all entities retrieved in a previous query or fetch. Unless you explicitly disable lazy fetching by specifyinglazy=\"false\", this second select will only be executed when you actually access the association. \"Extra-lazy\" collection fetching - individual elements of the collection are accessed from the database as needed. NHibernate tries not to fetch the whole collection into memory unless absolutely needed (suitable for very large collections) Batch fetching - an optimization strategy for select fetching - NHibernate retrieves a batch of entity instances or collections in a singleSELECT, by specifying a list of primary keys or foreign keys. NHibernate also distinguishes between: Immediate fetching - an association, collection or attribute is fetched immediately, when the owner is loaded. Lazy collection fetching - a collection is fetched when the application invokes an operation upon that collection. (This is the default for collections.) Proxy fetching - a single-valued association is fetched when a method other than the identifier getter is invoked upon the associated object. We have two orthogonal notions here: when is the association fetched, andhow is it fetched (what SQL is used). Don't confuse them! We usefetch to tune performance. We may use lazy to define a contract for what data is always available in any detached instance of a particular class. 19.1.1. Working with lazy associations By default, NHibernate uses lazy select fetching for collections and lazy proxy fetching for single-valued associations. These defaults make sense for almost all associations in almost all applications. However, lazy fetching poses one problem that you must be aware of. Access to a lazy association outside of the context of an open NHibernate session will result in an exception. For example: s = sessions.OpenSession();Transaction tx = s.BeginTransaction();            User u = (User) s.CreateQuery(\"from User u where u.Name=:userName\")    .SetString(\"userName\", userName).UniqueResult();IDictionary permissions = u.Permissions;tx.Commit();s.Close();int accessLevel = (int) permissions[\"accounts\"];  // Error! Since the permissions collection was not initialized when theISession was closed, the collection will not be able to load its state.NHibernate does not support lazy initialization for detached objects. The fix is to move the code that reads from the collection to just before the transaction is committed. Alternatively, we could use a non-lazy collection or association, by specifyinglazy=\"false\" for the association mapping. However, it is intended that lazy initialization be used for almost all collections and associations. If you define too many non-lazy associations in your object model, NHibernate will end up needing to fetch the entire database into memory in every transaction! On the other hand, we often want to choose join fetching (which is non-lazy by nature) instead of select fetching in a particular transaction. We'll now see how to customize the fetching strategy. In NHibernate, the mechanisms for choosing a fetch strategy are identical for single-valued associations and collections. 19.1.2. Tuning fetch strategies Select fetching (the default) is extremely vulnerable to N+1 selects problems, so we might want to enable join fetching in the mapping document: <set name=\"Permissions\"             fetch=\"join\">    <key column=\"userId\"/>    <one-to-many class=\"Permission\"/><\/set <many-to-one name=\"Mother\" class=\"Cat\" fetch=\"join\"/> The fetch strategy defined in the mapping document affects: retrieval via Get() or Load() retrieval that happens implicitly when an association is navigated ICriteria queries HQL queries if subselect fetching is used No matter what fetching strategy you use, the defined non-lazy graph is guaranteed to be loaded into memory. Note that this might result in several immediate selects being used to execute a particular HQL query. Usually, we don't use the mapping document to customize fetching. Instead, we keep the default behavior, and override it for a particular transaction, usingleft join fetch in HQL. This tells NHibernate to fetch the association eagerly in the first select, using an outer join. In theICriteria query API, you would useSetFetchMode(FetchMode.Join). If you ever feel like you wish you could change the fetching strategy used by Get() or Load(), simply use a ICriteria query, for example: User user = (User) session.CreateCriteria(typeof(User))                .SetFetchMode(\"Permissions\", FetchMode.Join)                .Add( Expression.Eq(\"Id\", userId) )                .UniqueResult(); (This is NHibernate's equivalent of what some ORM solutions call a \"fetch plan\".) A completely different way to avoid problems with N+1 selects is to use the second-level cache. 19.1.3. Single-ended association proxies Lazy fetching for collections is implemented using NHibernate's own implementation of persistent collections. However, a different mechanism is needed for lazy behavior in single-ended associations. The target entity of the association must be proxied. NHibernate implements lazy initializing proxies for persistent objects using runtime bytecode enhancement (via the excellent Castle.DynamicProxy library). By default, NHibernate generates proxies (at startup) for all persistent classes and uses them to enable lazy fetching ofmany-to-one andone-to-one associations. The mapping file may declare an interface to use as the proxy interface for that class, with theproxy attribute. By default, NHibernate uses a subclass of the class.Note that the proxied class must implement a non-private default constructor. We recommend this constructor for all persistent classes! There are some gotchas to be aware of when extending this approach to polymorphic classes, eg. <class name=\"Cat\" proxy=\"Cat\">    ......    <subclass name=\"DomesticCat\">        .....    <\/subclass><\/class> Firstly, instances of Cat will never be castable to DomesticCat, even if the underlying instance is an instance of DomesticCat: Cat cat = (Cat) session.Load(typeof(Cat), id);  // instantiate a proxy (does not hit the db)if ( cat.IsDomesticCat ) {                  // hit the db to initialize the proxy    DomesticCat dc = (DomesticCat) cat;       // Error!    ....} Secondly, it is possible to break proxy ==. Cat cat = (Cat) session.Load(typeof(Cat), id);            // instantiate a Cat proxyDomesticCat dc =         (DomesticCat) session.Load(typeof(DomesticCat), id);  // acquire new DomesticCat proxy!System.out.println(cat==dc);                            // false However, the situation is not quite as bad as it looks. Even though we now have two references to different proxy objects, the underlying instance will still be the same object: cat.Weight = 11.0;  // hit the db to initialize the proxyConsole.WriteLine( dc.Weight );  // 11.0 Third, you may not use a proxy for a sealed class or a class with any non-overridable public members. Finally, if your persistent object acquires any resources upon instantiation (eg. in initializers or default constructor), then those resources will also be acquired by the proxy. The proxy class is an actual subclass of the persistent class. These problems are all due to fundamental limitations in .NET's single inheritance model. If you wish to avoid these problems your persistent classes must each implement an interface that declares its business methods. You should specify these interfaces in the mapping file. eg. <class name=\"CatImpl\" proxy=\"ICat\">    ......    <subclass name=\"DomesticCatImpl\" proxy=\"IDomesticCat\">        .....    <\/subclass><\/class> where CatImpl implements the interface ICat and DomesticCatImpl implements the interface IDomesticCat. Then proxies for instances of ICat andIDomesticCat may be returned byLoad() orEnumerable(). (Note thatList() does not usually return proxies.) ICat cat = (ICat) session.Load(typeof(CatImpl), catid);IEnumerator iter = session.Enumerable(\"from CatImpl as cat where cat.Name='fritz'\").GetEnumerator();iter.MoveNext();ICat fritz = (ICat) iter.Current; Relationships are also lazily initialized. This means you must declare any properties to be of typeICat, notCatImpl. Certain operations do not require proxy initialization Equals(), if the persistent class does not override Equals() GetHashCode(), if the persistent class does not overrideGetHashCode() The identifier getter method NHibernate will detect persistent classes that override Equals() orGetHashCode(). 19.1.4. Initializing collections and proxies A LazyInitializationException will be thrown by NHibernate if an uninitialized collection or proxy is accessed outside of the scope of theISession, ie. when the entity owning the collection or having the reference to the proxy is in the detached state. Sometimes we need to ensure that a proxy or collection is initialized before closing theISession. Of course, we can alway force initialization by callingcat.Sex orcat.Kittens.Count, for example. But that is confusing to readers of the code and is not convenient for generic code. The static methods NHibernateUtil.Initialize() and NHibernateUtil.IsInitialized() provide the application with a convenient way of working with lazily initialized collections or proxies.NHibernateUtil.Initialize(cat) will force the initialization of a proxy,cat, as long as its ISession is still open.NHibernateUtil.Initialize( cat.Kittens ) has a similar effect for the collection of kittens. Another option is to keep the ISession open until all needed collections and proxies have been loaded. In some application architectures, particularly where the code that accesses data using NHibernate, and the code that uses it are in different application layers or different physical processes, it can be a problem to ensure that theISession is open when a collection is initialized. There are two basic ways to deal with this issue: In a web-based application, a HttpModule can be used to close theISession only at the very end of a user request, once the rendering of the view is complete (theOpen Session in View pattern). Of course, this places heavy demands on the correctness of the exception handling of your application infrastructure. It is vitally important that theISession is closed and the transaction ended before returning to the user, even when an exception occurs during rendering of the view. See the NHibernate Wiki for examples of this \"Open Session in View\" pattern. In an application with a separate business tier, the business logic must \"prepare\" all collections that will be needed by the web tier before returning. This means that the business tier should load all the data and return all the data already initialized to the presentation/web tier that is required for a particular use case. Usually, the application callsNHibernateUtil.Initialize() for each collection that will be needed in the web tier (this call must occur before the session is closed) or retrieves the collection eagerly using a NHibernate query with aFETCH clause or aFetchMode.Join inICriteria. This is usually easier if you adopt theCommand pattern instead of a Session Facade. You may also attach a previously loaded object to a new ISession withMerge() orLock() before accessing uninitialized collections (or other proxies). No, NHibernate does not, and certainlyshould not do this automatically, since it would introduce ad hoc transaction semantics! Sometimes you don't want to initialize a large collection, but still need some information about it (like its size) or a subset of the data. You can use a collection filter to get the size of a collection without initializing it: (int) s.CreateFilter( collection, \"select count(*)\" ).List()[0] The CreateFilter() method is also used to efficiently retrieve subsets of a collection without needing to initialize the whole collection: s.CreateFilter( lazyCollection, \"\").SetFirstResult(0).SetMaxResults(10).List(); 19.1.5. Using batch fetching NHibernate can make efficient use of batch fetching, that is, NHibernate can load several uninitialized proxies if one proxy is accessed (or collections. Batch fetching is an optimization of the lazy select fetching strategy. There are two ways you can tune batch fetching: on the class and the collection level. Batch fetching for classes/entities is easier to understand. Imagine you have the following situation at runtime: You have 25Cat instances loaded in anISession, eachCat has a reference to itsOwner, aPerson. The Person class is mapped with a proxy,lazy=\"true\". If you now iterate through all cats and callcat.Owner on each, NHibernate will by default execute 25SELECT statements, to retrieve the proxied owners. You can tune this behavior by specifying abatch-size in the mapping ofPerson: <class name=\"Person\" batch-size=\"10\">...<\/class> NHibernate will now execute only three queries, the pattern is 10, 10, 5. You may also enable batch fetching of collections. For example, if each Person has a lazy collection of Cats, and 10 persons are currently loaded in theISesssion, iterating through all persons will generate 10SELECTs, one for every call toperson.Cats. If you enable batch fetching for theCats collection in the mapping ofPerson, NHibernate can pre-fetch collections: <class name=\"Person\">    <set name=\"Cats\" batch-size=\"3\">        ...    <\/set><\/class> With a batch-size of 3, NHibernate will load 3, 3, 3, 1 collections in fourSELECTs. Again, the value of the attribute depends on the expected number of uninitialized collections in a particularSession. Batch fetching of collections is particularly useful if you have a nested tree of items, ie. the typical bill-of-materials pattern. (Although anested set or amaterialized path might be a better option for read-mostly trees.) 19.1.6. Using subselect fetching If one lazy collection or single-valued proxy has to be fetched, NHibernate loads all of them, re-running the original query in a subselect. This works in the same way as batch-fetching, without the piecemeal loading. 19.2. The Second Level Cache A NHibernate ISession is a transaction-level cache of persistent data. It is possible to configure a cluster or process-level (ISessionFactory-level) cache on a class-by-class and collection-by-collection basis. You may even plug in a clustered cache. Be careful. Caches are never aware of changes made to the persistent store by another application (though they may be configured to regularly expire cached data).In NHibernate 1.x the second level cache does not work correctly in combination with distributed transactions. By default, NHibernate uses HashtableCache for process-level caching. You may choose a different implementation by specifying the name of a class that implementsNHibernate.Cache.ICacheProvider using the propertyhibernate.cache.provider_class. Table 19.1. Cache Providers Cache Provider class Type Cluster Safe Query Cache Supported Hashtable (not intended for production use) NHibernate.Cache.HashtableCacheProvider memory   yes ASP.NET Cache (System.Web.Cache) NHibernate.Caches.SysCache.SysCacheProvider, NHibernate.Caches.SysCache memory   yes Prevalence Cache NHibernate.Caches.Prevalence.PrevalenceCacheProvider, NHibernate.Caches.Prevalence memory, disk   yes 19.2.1. Cache mappings The <cache> element of a class or collection mapping has the following form: <cache     usage=\"read-write|nonstrict-read-write|read-only\"                (1)    region=\"RegionName\"                                              (2)/> (1) usage specifies the caching strategy: read-write, nonstrict-read-write or read-only (2) region (optional, defaults to the class or collection role name) specifies the name of the second level cache region Alternatively (preferrably?), you may specify <class-cache> and<collection-cache> elements inhibernate.cfg.xml. The usage attribute specifies a cache concurrency strategy. 19.2.2. Strategy: read only If your application needs to read but never modify instances of a persistent class, aread-only cache may be used. This is the simplest and best performing strategy. Its even perfectly safe for use in a cluster. <class name=\"Eg.Immutable\" mutable=\"false\">    <cache usage=\"read-only\"/>    ....<\/class> 19.2.3. Strategy: read/write If the application needs to update data, a read-write cache might be appropriate. This cache strategy should never be used if serializable transaction isolation level is required. You should ensure that the transaction is completed when ISession.Close() or ISession.Disconnect() is called. If you wish to use this strategy in a cluster, you should ensure that the underlying cache implementation supports locking. The built-in cache providers do not. <class name=\"eg.Cat\" .... >    <cache usage=\"read-write\"/>    ....    <set name=\"Kittens\" ... >        <cache usage=\"read-write\"/>        ....    <\/set><\/class> 19.2.4. Strategy: nonstrict read/write If the application only occasionally needs to update data (ie. if it is extremely unlikely that two transactions would try to update the same item simultaneously) and strict transaction isolation is not required, anonstrict-read-write cache might be appropriate. When using this strategy you should ensure that the transaction is completed whenISession.Close() orISession.Disconnect() is called. The following table shows which providers are compatible with which concurrency strategies. Table 19.2. Cache Concurrency Strategy Support Cache read-only nonstrict-read-write read-write Hashtable (not intended for production use) yes yes yes SysCache yes yes yes PrevalenceCache yes yes yes Refer to Chapter 25, NHibernate.Caches for more details. 19.3. Managing the caches Whenever you pass an object to Save(), Update() or SaveOrUpdate() and whenever you retrieve an object usingLoad(),Get(), List(), or Enumerable(), that object is added to the internal cache of theISession. When Flush() is subsequently called, the state of that object will be synchronized with the database. If you do not want this synchronization to occur or if you are processing a huge number of objects and need to manage memory efficiently, the Evict() method may be used to remove the object and its collections from the first-level cache. IEnumerable cats = sess.Enumerable(\"from Eg.Cat as cat\"); //a huge result setforeach( Cat cat in cats ){    DoSomethingWithACat(cat);    sess.Evict(cat);} NHibernate will evict associated entities automatically if the association is mapped withcascade=\"all\" orcascade=\"all-delete-orphan\". The ISession also provides a Contains() method to determine if an instance belongs to the session cache. To completely evict all objects from the session cache, call ISession.Clear() For the second-level cache, there are methods defined on ISessionFactory for evicting the cached state of an instance, entire class, collection instance or entire collection role. sessionFactory.Evict(typeof(Cat), catId); //evict a particular CatsessionFactory.Evict(typeof(Cat));  //evict all CatssessionFactory.EvictCollection(\"Eg.Cat.Kittens\", catId); //evict a particular collection of kittenssessionFactory.EvictCollection(\"Eg.Cat.Kittens\"); //evict all kitten collections 19.4. The Query Cache Query result sets may also be cached. This is only useful for queries that are run frequently with the same parameters. To use the query cache you must first enable it: <add key=\"hibernate.cache.use_query_cache\" value=\"true\" /> This setting causes the creation of two new cache regions - one holding cached query result sets (NHibernate.Cache.StandardQueryCache), the other holding timestamps of the most recent updates to queryable tables (NHibernate.Cache.UpdateTimestampsCache). Note that the query cache does not cache the state of any entities in the result set; it caches only identifier values and results of value type. So the query cache should always be used in conjunction with the second-level cache. Most queries do not benefit from caching, so by default queries are not cached. To enable caching, callIQuery.SetCacheable(true). This call allows the query to look for existing cache results or add its results to the cache when it is executed. If you require fine-grained control over query cache expiration policies, you may specify a named cache region for a particular query by callingIQuery.SetCacheRegion(). IList blogs = sess.CreateQuery(\"from Blog blog where blog.Blogger = :blogger\")    .SetEntity(\"blogger\", blogger)    .SetMaxResults(15)    .SetCacheable(true)    .SetCacheRegion(\"frontpages\")    .List(); If the query should force a refresh of its query cache region, you may call IQuery.SetForceCacheRefresh() to true. This is particularly useful in cases where underlying data may have been updated via a seperate process (i.e., not modified through NHibernate) and allows the application to selectively refresh the query cache regions based on its knowledge of those events. This is a more efficient alternative to eviction of a query cache region viaISessionFactory.EvictQueries(). 19.5. Understanding Collection performance We've already spent quite some time talking about collections. In this section we will highlight a couple more issues about how collections behave at runtime. 19.5.1. Taxonomy NHibernate defines three basic kinds of collections: collections of values one to many associations many to many associations This classification distinguishes the various table and foreign key relationships but does not tell us quite everything we need to know about the relational model. To fully understand the relational structure and performance characteristics, we must also consider the structure of the primary key that is used by NHibernate to update or delete collection rows. This suggests the following classification: indexed collections sets bags All indexed collections (maps, lists, arrays) have a primary key consisting of the<key> and<index> columns. In this case collection updates are usually extremely efficient - the primary key may be efficiently indexed and a particular row may be efficiently located when NHibernate tries to update or delete it. Sets have a primary key consisting of <key> and element columns. This may be less efficient for some types of collection element, particularly composite elements or large text or binary fields; the database may not be able to index a complex primary key as efficently. On the other hand, for one to many or many to many associations, particularly in the case of synthetic identifiers, it is likely to be just as efficient. (Side-note: if you wantSchemaExport to actually create the primary key of a <set> for you, you must declare all columns asnot-null=\"true\".) <idbag> mappings define a surrogate key, so they are always very efficient to update. In fact, they are the best case. Bags are the worst case. Since a bag permits duplicate element values and has no index column, no primary key may be defined. NHibernate has no way of distinguishing between duplicate rows. NHibernate resolves this problem by completely removing (in a singleDELETE) and recreating the collection whenever it changes. This might be very inefficient. Note that for a one-to-many association, the \"primary key\" may not be the physical primary key of the database table - but even in this case, the above classification is still useful. (It still reflects how NHibernate \"locates\" individual rows of the collection.) 19.5.2. Lists, maps, idbags and sets are the most efficient collections to update From the discussion above, it should be clear that indexed collections and (usually) sets allow the most efficient operation in terms of adding, removing and updating elements. There is, arguably, one more advantage that indexed collections have over sets for many to many associations or collections of values. Because of the structure of anISet, NHibernate doesn't everUPDATE a row when an element is \"changed\". Changes to anISet always work viaINSERT andDELETE (of individual rows). Once again, this consideration does not apply to one to many associations. After observing that arrays cannot be lazy, we would conclude that lists, maps and idbags are the most performant (non-inverse) collection types, with sets not far behind. Sets are expected to be the most common kind of collection in NHibernate applications. This is because the \"set\" semantics are most natural in the relational model. However, in well-designed NHibernate domain models, we usually see that most collections are in fact one-to-many associations withinverse=\"true\". For these associations, the update is handled by the many-to-one end of the association, and so considerations of collection update performance simply do not apply. 19.5.3. Bags and lists are the most efficient inverse collections Just before you ditch bags forever, there is a particular case in which bags (and also lists) are much more performant than sets. For a collection withinverse=\"true\" (the standard bidirectional one-to-many relationship idiom, for example) we can add elements to a bag or list without needing to initialize (fetch) the bag elements! This is becauseIList.Add() must always succeed for a bag orIList (unlike an ISet). This can make the following common code much faster. Parent p = (Parent) sess.Load(typeof(Parent), id);    Child c = new Child();    c.Parent = p;    p.Children.Add(c);  //no need to fetch the collection!    sess.Flush(); 19.5.4. One shot delete Occasionally, deleting collection elements one by one can be extremely inefficient. NHibernate isn't completely stupid, so it knows not to do that in the case of an newly-empty collection (if you calledlist.Clear(), for example). In this case, NHibernate will issue a singleDELETE and we are done! Suppose we add a single element to a collection of size twenty and then remove two elements. NHibernate will issue oneINSERT statement and twoDELETE statements (unless the collection is a bag). This is certainly desirable. However, suppose that we remove eighteen elements, leaving two and then add thee new elements. There are two possible ways to proceed: Delete eighteen rows one by one and then insert three rows Remove the whole collection (in one SQL DELETE) and insert all five current elements (one by one) NHibernate isn't smart enough to know that the second option is probably quicker in this case. (And it would probably be undesirable for NHibernate to be that smart; such behaviour might confuse database triggers, etc.) Fortunately, you can force this behaviour (ie. the second strategy) at any time by discarding (ie. dereferencing) the original collection and returning a newly instantiated collection with all the current elements. This can be very useful and powerful from time to time. one-shot-delete apply to collections mapped inverse=\"true\". 19.6. Batch updates NHibernate supports batching SQL update commands (INSERT,UPDATE,DELETE) with the following limitations: .NET Framework 2.0 or above is required, the Nhibernate's drive used for your RDBMS may not supports batching, since the implementation uses reflection to access members and types in System.Data assembly which are not normally visible, it may not function in environments where necessary permissions are not granted, optimistic concurrency checking may be impaired since ADO.NET 2.0 does not return the number of rows affected by each statement in the batch, only the total number of rows affected by the batch. Update batching is enabled by setting adonet.batch_size to a non-zero value. 19.7. Multi Query This functionality allows you to execute several HQL queries in one round-trip against the database server. A simple use case is executing a paged query while also getting the total count of results, in a single round-trip. Here is a simple example: IMultiQuery multiQuery = s.CreateMultiQuery()    .Add(s.CreateQuery(\"from Item i where i.Id > ?\")            .SetInt32(0, 50).SetFirstResult(10))    .Add(s.CreateQuery(\"select count(*) from Item i where i.Id > ?\")            .SetInt32(0, 50));IList results = multiQuery.List();IList items = (IList)results[0];long count = (long)((IList)results[1])[0]; The result is a list of query results, ordered according to the order of queries added to the multi query. Named parameters can be set on the multi query, and are shared among all the queries contained in the multi query, like this: IList results = s.CreateMultiQuery()    .Add(s.CreateQuery(\"from Item i where i.Id > :id\")        .SetFirstResult(10) )    .Add(\"select count(*) from Item i where i.Id > :id\")    .SetInt32(\"id\", 50)    .List();IList items = (IList)results[0];long count = (long)((IList)results[1])[0]; Positional parameters are not supported on the multi query, only on the individual queries. As shown above, if you do not need to configure the query separately, you can simply pass the HQL directly to theIMultiQuery.Add() method. Multi query is executed by concatenating the queries and sending the query to the database as a single string. This means that the database should support returning several result sets in a single query. At the moment this functionality is only enabled for Microsoft SQL Server and SQLite. Note that the database server is likely to impose a limit on the maximum number of parameters in a query, in which case the limit applies to the multi query as a whole. Queries usingin with a large number of arguments passed as parameters may easily exceed this limit. For example, SQL Server has a limit of 2,100 parameters per round-trip, and will throw an exception executing this query: IList allEmployeesId  = ...; //1,500 itemsIMultiQuery multiQuery = s.CreateMultiQuery()\t.Add(s.CreateQuery(\"from Employee e where e.Id in :empIds\")\t\t.SetParameter(\"empIds\", allEmployeesId).SetFirstResult(10))\t.Add(s.CreateQuery(\"select count(*) from Employee e where e.Id in :empIds\")\t\t.SetParameter(\"empIds\", allEmployeesId));\tIList results = multiQuery.List(); // will throw an exception from SQL Server\t An interesting usage of this feature is to load several collections of an object in one round-trip, without an expensive cartesian product (blog * users * posts). Blog blog = s.CreateMultiQuery()    .Add(\"select b from Blog b left join fetch b.Users where b.Id = :id\")    .Add(\"select b from Blog b left join fetch b.Posts where b.Id = :id\")    .SetInt32(\"id\", 123)    .UniqueResult<Blog>(); 19.8. Multi Criteria This is the counter-part to Multi Query, and allows you to perform several criteria queries in a single round trip. A simple use case is executing a paged query while also getting the total count of results, in a single round-trip. Here is a simple example: IMultiCriteria multiCrit = s.CreateMultiCriteria()    .Add(s.CreateCriteria(typeof(Item))            .Add(Expression.Gt(\"Id\", 50))            .SetFirstResult(10))    .Add(s.CreateCriteria(typeof(Item))            .Add(Expression.Gt(\"Id\", 50))            .SetProject(Projections.RowCount()));IList results = multiCrit.List();IList items = (IList)results[0];long count = (long)((IList)results[1])[0]; The result is a list of query results, ordered according to the order of queries added to the multi criteria. You can add ICriteria or DetachedCriteria to the Multi Criteria query. In fact, using DetachedCriteria in this fashion has some interesting implications. DetachedCriteria customersCriteria = AuthorizationService.GetAssociatedCustomersQuery();IList results = session.CreateMultiCriteria()\t.Add(customersCriteria)\t.Add(DetachedCriteria.For<Policy>()\t\t.Add( Subqueries.PropertyIn(\"id\", CriteriaTransformer.Clone(customersCriteria)                                                    .SetProjection(Projections.Id())                      ) )\t).List();ICollection<Customer> customers = CollectionHelper.ToArray<Customer>(results[0]);ICollection<Policy> policies = CollectionHelper.ToArray<Policy>(results[1]); As you see, we get a query that represnt the customers we can access, and then we can utlize this query further in order to perform additional logic (getting the policies of the customers we are associated with), all in a single database roundtrip. Chapter 20. Toolset Guide Roundtrip engineering with NHibernate is possible using a set of commandline tools maintained as part of the NHibernate project, along with NHibernate support built into various code generation tools (MyGeneration, CodeSmith, ObjectMapper, AndroMDA). The NHibernate main package comes bundled with the most important tool (it can even be used from \"inside\" NHibernate on-the-fly): DDL schema generation from a mapping file (aka SchemaExport,hbm2ddl) Other tools directly provided by the NHibernate project are delivered with a separate package,NHibernateContrib. This package includes tools for the following tasks: C# source generation from a mapping file (aka hbm2net) mapping file generation from .NET classes marked with attributes (NHibernate.Mapping.Attributes, or NHMA for short) Third party tools with NHibernate support are: CodeSmith, MyGeneration, and ObjectMapper (mapping file generation from an existing database schema) AndroMDA (MDA (Model-Driven Architecture) approach generating code for persistent classes from UML diagrams and their XML/XMI representation) These 3rd party tools are not documented in this reference. Please refer to the NHibernate website for up-to-date information. 20.1. Schema Generation The generated schema includes referential integrity constraints (primary and foreign keys) for entity and collection tables. Tables and sequences are also created for mapped identifier generators. You must specify a SQL Dialect via the hibernate.dialect property when using this tool. 20.1.1. Customizing the schema Many NHibernate mapping elements define an optional attribute named length. You may set the length of a column with this attribute. (Or, for numeric/decimal data types, the precision.) Some tags also accept a not-null attribute (for generating aNOT NULL constraint on table columns) and aunique attribute (for generating UNIQUE constraint on table columns). Some tags accept an index attribute for specifying the name of an index for that column. Aunique-key attribute can be used to group columns in a single unit key constraint. Currently, the specified value of theunique-key attribute is not used to name the constraint, only to group the columns in the mapping file. Examples: <property name=\"Foo\" type=\"String\" length=\"64\" not-null=\"true\"/><many-to-one name=\"Bar\" foreign-key=\"fk_foo_bar\" not-null=\"true\"/><element column=\"serial_number\" type=\"Int64\" not-null=\"true\" unique=\"true\"/> Alternatively, these elements also accept a child <column> element. This is particularly useful for multi-column types: <property name=\"Foo\" type=\"String\">    <column name=\"foo\" length=\"64\" not-null=\"true\" sql-type=\"text\"/><\/property><property name=\"Bar\" type=\"My.CustomTypes.MultiColumnType, My.CustomTypes\"/>    <column name=\"fee\" not-null=\"true\" index=\"bar_idx\"/>    <column name=\"fi\" not-null=\"true\" index=\"bar_idx\"/>    <column name=\"fo\" not-null=\"true\" index=\"bar_idx\"/><\/property> The sql-type attribute allows the user to override the default mapping of NHibernate type to SQL datatype. The check attribute allows you to specify a check constraint. <property name=\"Foo\" type=\"Int32\">    <column name=\"foo\" check=\"foo > 10\"/><\/property><class name=\"Foo\" table=\"foos\" check=\"bar < 100.0\">    ...    <property name=\"Bar\" type=\"Single\"/><\/class> Table 20.1. Summary Attribute Values Interpretation length number column length/decimal precision not-null true|false specfies that the column should be non-nullable unique true|false specifies that the column should have a unique constraint index index_name specifies the name of a (multi-column) index unique-key unique_key_name specifies the name of a multi-column unique constraint foreign-key foreign_key_name specifies the name of the foreign key constraint generated for an association, use it on <one-to-one>, <many-to-one>, <key>, and <many-to-many> mapping elements. Note thatinverse=\"true\" sides will not be considered bySchemaExport. sql-type column_type overrides the default column type (attribute of <column> element only) check SQL expression create an SQL check constraint on either column or table 20.1.2. Running the tool The SchemaExport tool writes a DDL script to standard out and/or executes the DDL statements. You may embed SchemaExport in your application: Configuration cfg = ....;new SchemaExport(cfg).Create(false, true); 20.1.3. Properties Database properties may be specified as system properties with -D<property> in hibernate.properties in a named properties file with --properties The needed properties are: Table 20.2. SchemaExport Connection Properties Property Name Description hibernate.connection.driver_class jdbc driver class hibernate.connection.url jdbc url hibernate.connection.username database user hibernate.connection.password user password hibernate.dialect dialect 20.1.4. Using Ant You can call SchemaExport from your Ant build script: <target name=\"schemaexport\">    <taskdef name=\"schemaexport\"        classname=\"net.sf.hibernate.tool.hbm2ddl.SchemaExportTask\"        classpathref=\"class.path\"/>        <schemaexport        properties=\"hibernate.properties\"        quiet=\"no\"        text=\"no\"        drop=\"no\"        delimiter=\";\"        output=\"schema-export.sql\">        <fileset dir=\"src\">            <include name=\"**/*.hbm.xml\"/>        <\/fileset>    <\/schemaexport><\/target> If you don't specify properties or a config file, the SchemaExportTask will try to use normal Ant project properties instead. In other words, if you don't want or need an external configuration or properties file, you may puthibernate.* configuration properties in your build.xml or build.properties. 20.2. Code Generation The NHibernate code generator may be used to generate skeletal C# implementation classes from a NHibernate mapping file. This tool is included in the NHibernate Contrib package (a seperate download in http://sourceforge.net/projects/nhcontrib/). hbm2net parses the mapping files and generates fully working C# source files from these. Thus withhbm2net one could \"just\" provide the.hbm files, and then don't worry about hand-writing/coding the C# files. hbm2net options mapping_files Table 20.3. Code Generator Command Line Options Option Description -output:output_dir root directory for generated code -config:config_file optional file for configuring hbm2net A more detailed guide of hbm2net is available in http://nhforge.org/blogs/nhibernate/archive/2009/12/12/t4-hbm2net-alpha-2.aspx Chapter 21. Example: Parent/Child One of the very first things that new users try to do with NHibernate is to model a parent / child type relationship. There are two different approaches to this. For various reasons the most convenient approach, especially for new users, is to model bothParent and Child as entity classes with a<one-to-many> association fromParent toChild. (The alternative approach is to declare theChild as a <composite-element>.) Now, it turns out that default semantics of a one to many association (in NHibernate) are much less close to the usual semantics of a parent / child relationship than those of a composite element mapping. We will explain how to use a bidirectional one to many association with cascades to model a parent / child relationship efficiently and elegantly. It's not at all difficult! 21.1. A note about collections NHibernate collections are considered to be a logical part of their owning entity; never of the contained entities. This is a crucial distinction! It has the following consequences: When we remove / add an object from / to a collection, the version number of the collection owner is incremented. If an object that was removed from a collection is an instance of a value type (eg, a composite element), that object will cease to be persistent and its state will be completely removed from the database. Likewise, adding a value type instance to the collection will cause its state to be immediately persistent. On the other hand, if an entity is removed from a collection (a one-to-many or many-to-many association), it will not be deleted, by default. This behavior is completely consistent - a change to the internal state of another entity should not cause the associated entity to vanish! Likewise, adding an entity to a collection does not cause that entity to become persistent, by default. Instead, the default behavior is that adding an entity to a collection merely creates a link between the two entities, while removing it removes the link. This is very appropriate for all sorts of cases. Where it is not appropriate at all is the case of a parent / child relationship, where the life of the child is bound to the lifecycle of the parent. 21.2. Bidirectional one-to-many Suppose we start with a simple <one-to-many> association fromParent toChild. <set name=\"Children\">    <key column=\"parent_id\" />    <one-to-many class=\"Child\" /><\/set> If we were to execute the following code Parent p = .....;Child c = new Child();p.Children.Add(c);session.Save(c);session.Flush(); NHibernate would issue two SQL statements: an INSERT to create the record for c an UPDATE to create the link from p to c This is not only inefficient, but also violates any NOT NULL constraint on theparent_id column. The underlying cause is that the link (the foreign key parent_id) fromp toc is not considered part of the state of theChild object and is therefore not created in theINSERT. So the solution is to make the link part of the Child mapping. <many-to-one name=\"Parent\" column=\"parent_id\" not-null=\"true\"/> (We also need to add the Parent property to the Child class.) Now that the Child entity is managing the state of the link, we tell the collection not to update the link. We use theinverse attribute. <set name=\"Children\" inverse=\"true\">    <key column=\"parent_id\"/>    <one-to-many class=\"Child\"/><\/set> The following code would be used to add a new Child. Parent p = (Parent) session.Load(typeof(Parent), pid);Child c = new Child();c.Parent = p;p.Children.Add(c);session.Save(c);session.Flush(); And now, only one SQL INSERT would be issued! To tighten things up a bit, we could create an AddChild() method ofParent. public void AddChild(Child c){    c.Parent = this;    children.Add(c);} Now, the code to add a Child looks like Parent p = (Parent) session.Load(typeof(Parent), pid);Child c = new Child();p.AddChild(c);session.Save(c);session.Flush(); 21.3. Cascading lifecycle The explicit call to Save() is still annoying. We will address this by using cascades. <set name=\"Children\" inverse=\"true\" cascade=\"all\">    <key column=\"parent_id\"/>    <one-to-many class=\"Child\"/><\/set> This simplifies the code above to Parent p = (Parent) session.Load(typeof(Parent), pid);Child c = new Child();p.AddChild(c);session.Flush(); Similarly, we don't need to iterate over the children when saving or deleting aParent. The following removesp and all its children from the database. Parent p = (Parent) session.Load(typeof(Parent), pid);session.Delete(p);session.Flush(); However, this code Parent p = (Parent) session.Load(typeof(Parent), pid);// Get one child out of the setIEnumerator childEnumerator = p.Children.GetEnumerator();childEnumerator.MoveNext();Child c = (Child) childEnumerator.Current;p.Children.Remove(c);c.Parent = null;session.Flush(); will not remove c from the database; it will only remove the link top (and cause aNOT NULL constraint violation, in this case). You need to explicitlyDelete() theChild. Parent p = (Parent) session.Load(typeof(Parent), pid);// Get one child out of the setIEnumerator childEnumerator = p.Children.GetEnumerator();childEnumerator.MoveNext();Child c = (Child) childEnumerator.Current;p.Children.Remove(c);session.Delete(c);session.Flush(); Now, in our case, a Child can't really exist without its parent. So if we remove aChild from the collection, we really do want it to be deleted. For this, we must usecascade=\"all-delete-orphan\". <set name=\"Children\" inverse=\"true\" cascade=\"all-delete-orphan\">    <key column=\"parent_id\"/>    <one-to-many class=\"Child\"/><\/set> Note: even though the collection mapping specifies inverse=\"true\", cascades are still processed by iterating the collection elements. So if you require that an object be saved, deleted or updated by cascade, you must add it to the collection. It is not enough to simply set its parent. 21.4. Using cascadingUpdate() Suppose we loaded up a Parent in one ISession, made some changes in a UI action and wish to persist these changes in a new ISession (by callingUpdate()). TheParent will contain a collection of children and, since cascading update is enabled, NHibernate needs to know which children are newly instantiated and which represent existing rows in the database. Let's assume that bothParent and Child have (synthetic) identifier properties of typelong. NHibernate will use the identifier property value to determine which of the children are new. (You may also use the version or timestamp property, seeSection 9.4.2, “Updating detached objects”.) The unsaved-value attribute is used to specify the identifier value of a newly instantiated instance.In NHibernate it is not necessary to specifyunsaved-value explicitly. The following code will update parent and child and insert newChild. //parent and child were both loaded in a previous sessionparent.AddChild(child);Child newChild = new Child();parent.AddChild(newChild);session.Update(parent);session.Flush(); Well, thats all very well for the case of a generated identifier, but what about assigned identifiers and composite identifiers? This is more difficult, sinceunsaved-value can't distinguish between a newly instantiated object (with an identifier assigned by the user) and an object loaded in a previous session. In these cases, you will probably need to give NHibernate a hint; either define an unsaved-value on a <version> or<timestamp> property mapping for the class. set unsaved-value=\"none\" and explicitly Save() newly instantiated children before calling Update(parent) set unsaved-value=\"any\" and explicitly Update() previously persistent children before calling Update(parent) null is the default unsaved-value for assigned identifiers,none is the defaultunsaved-value for composite identifiers. There is one further possibility. There is a new IInterceptor method namedIsTransient() which lets the application implement its own strategy for distinguishing newly instantiated objects. For example, you could define a base class for your persistent classes. public class Persistent{    private bool _saved = false;        public void OnSave()    {        _saved=true;    }        public void OnLoad()    {        _saved=true;    }        ......        public bool IsSaved    {        get { return _saved; }    }} (The saved property is non-persistent.) Now implementIsTransient(), along withOnLoad() andOnSave() as follows. \tpublic object IsTransient(object entity){    if (entity is Persistent)    {        return !( (Persistent) entity ).IsSaved;    }    else    {        return null;    }}public bool OnLoad(object entity,     object id,    object[] state,    string[] propertyNames,    IType[] types){    if (entity is Persistent) ( (Persistent) entity ).OnLoad();    return false;}public boolean OnSave(object entity,    object id,    object[] state,    string[] propertyNames,    IType[] types){    if (entity is Persistent) ( (Persistent) entity ).OnSave();    return false;} 21.5. Conclusion There is quite a bit to digest here and it might look confusing first time around. However, in practice, it all works out quite nicely. Most NHibernate applications use the parent / child pattern in many places. We mentioned an alternative in the first paragraph. None of the above issues exist in the case of<composite-element> mappings, which have exactly the semantics of a parent / child relationship. Unfortunately, there are two big limitations to composite element classes: composite elements may not own collections, and they should not be the child of any entity other than the unique parent. (However, theymay have a surrogate primary key, using an<idbag> mapping.) Chapter 22. Example: Weblog Application 22.1. Persistent Classes The persistent classes represent a weblog, and an item posted in a weblog. They are to be modelled as a standard parent/child relationship, but we will use an ordered bag, instead of a set. using System;using System.Collections;namespace Eg{    public class Blog    {        private long _id;        private string _name;        private IList _items;            public virtual long Id        {            get { return _id; }            set { _id = value; }        }                public virtual IList Items        {            get { return _items; }            set { _items = value; }        }                public virtual string Name        {            get { return _name; }            set { _name = value; }        }    }} using System;namespace Eg{    public class BlogItem    {        private long _id;        private DateTime _dateTime;        private string _text;        private string _title;        private Blog _blog;        public virtual Blog Blog        {            get { return _blog; }            set { _blog = value; }        }        public virtual DateTime DateTime        {            get { return _dateTime; }            set { _dateTime = value; }        }        public virtual long Id        {            get { return _id; }            set { _id = value; }        }        public virtual string Text        {            get { return _text; }            set { _text = value; }        }        public virtual string Title        {            get { return _title; }            set { _title = value; }        }    }} 22.2. NHibernate Mappings The XML mappings should now be quite straightforward. <?xml version=\"1.0\"?><hibernate-mapping xmlns=\"urn:nhibernate-mapping-2.2\"    assembly=\"Eg\" namespace=\"Eg\">    <class         name=\"Blog\"         table=\"BLOGS\"         lazy=\"true\">                <id             name=\"Id\"             column=\"BLOG_ID\">                        <generator class=\"native\"/>                    <\/id>                <property             name=\"Name\"             column=\"NAME\"             not-null=\"true\"             unique=\"true\"/>                    <bag             name=\"Items\"             inverse=\"true\"             lazy=\"true\"            order-by=\"DATE_TIME\"             cascade=\"all\">                        <key column=\"BLOG_ID\"/>            <one-to-many class=\"BlogItem\"/>                    <\/bag>            <\/class>    <\/hibernate-mapping> <?xml version=\"1.0\"?><hibernate-mapping xmlns=\"urn:nhibernate-mapping-2.2\"    assembly=\"Eg\" namespace=\"Eg\">        <class         name=\"BlogItem\"         table=\"BLOG_ITEMS\"         dynamic-update=\"true\">                <id             name=\"Id\"             column=\"BLOG_ITEM_ID\">                        <generator class=\"native\"/>                    <\/id>                <property             name=\"Title\"             column=\"TITLE\"             not-null=\"true\"/>                    <property             name=\"Text\"             column=\"TEXT\"             not-null=\"true\"/>                    <property             name=\"DateTime\"             column=\"DATE_TIME\"             not-null=\"true\"/>                    <many-to-one             name=\"Blog\"             column=\"BLOG_ID\"             not-null=\"true\"/>                <\/class>    <\/hibernate-mapping> 22.3. NHibernate Code The following class demonstrates some of the kinds of things we can do with these classes, using NHibernate. using System;using System.Collections;using NHibernate.Tool.hbm2ddl;namespace Eg{    public class BlogMain    {        private ISessionFactory _sessions;                public void Configure()        {            _sessions = new Configuration()                .AddClass(typeof(Blog))                .AddClass(typeof(BlogItem))                .BuildSessionFactory();        }                public void ExportTables()        {            Configuration cfg = new Configuration()                .AddClass(typeof(Blog))                .AddClass(typeof(BlogItem));            new SchemaExport(cfg).create(true, true);        }                public Blog CreateBlog(string name)        {            Blog blog = new Blog();            blog.Name = name;            blog.Items = new ArrayList();                        using (ISession session = _sessions.OpenSession())            using (ITransaction tx = session.BeginTransaction())            {                session.Save(blog);                tx.Commit();            }            return blog;        }                public BlogItem CreateBlogItem(Blog blog, string title, string text)        {            BlogItem item = new BlogItem();            item.Title = title;            item.Text = text;            item.Blog = blog;            item.DateTime = DateTime.Now;            blog.Items.Add(item);                        using (ISession session = _sessions.OpenSession())            using (ITransaction tx = session.BeginTransaction())            {                session.Update(blog);                tx.Commit();            }            return item;        }                public BlogItem CreateBlogItem(long blogId, string title, string text)        {            BlogItem item = new BlogItem();            item.Title = title;            item.Text = text;            item.DateTime = DateTime.Now;                        using (ISession session = _sessions.OpenSession())            using (ITransaction tx = session.BeginTransaction())            {                Blog blog = (Blog) session.Load(typeof(Blog), blogId);                item.Blog = blog;                blog.Items.Add(item);                tx.Commit();            }            return item;        }                public void UpdateBlogItem(BlogItem item, string text)        {            item.Text = text;            using (ISession session = _sessions.OpenSession())            using (ITransaction tx = session.BeginTransaction())            {                session.Update(item);                tx.Commit();            }        }                public void UpdateBlogItem(long itemId, string text)        {            using (ISession session = _sessions.OpenSession())            using (ITransaction tx = session.BeginTransaction())            {                BlogItem item = (BlogItem) session.Load(typeof(BlogItem), itemId);                item.Text = text;                tx.Commit();            }        }                public IList listAllBlogNamesAndItemCounts(int max)        {            IList result = null;            using (ISession session = _sessions.OpenSession())            using (ITransaction tx = session.BeginTransaction())            {                IQuery q = session.CreateQuery(                    \"select blog.id, blog.Name, count(blogItem) \" +                    \"from Blog as blog \" +                    \"left outer join blog.Items as blogItem \" +                    \"group by blog.Name, blog.id \" +                    \"order by max(blogItem.DateTime)\"                );                q.SetMaxResults(max);                result = q.List();                tx.Commit();            }            return result;        }                public Blog GetBlogAndAllItems(long blogId)        {            Blog blog = null;            using (ISession session = _sessions.OpenSession())            using (ITransaction tx = session.BeginTransaction())            {                IQuery q = session.createQuery(                    \"from Blog as blog \" +                    \"left outer join fetch blog.Items \" +                    \"where blog.id = :blogId\"                );                q.SetParameter(\"blogId\", blogId);                blog  = (Blog) q.List()[0];                tx.Commit();            }            return blog;        }                public IList ListBlogsAndRecentItems()        {            IList result = null;            using (ISession session = _sessions.OpenSession())            using (ITransaction tx = session.BeginTransaction())            {                IQuery q = session.CreateQuery(                    \"from Blog as blog \" +                    \"inner join blog.Items as blogItem \" +                    \"where blogItem.DateTime > :minDate\"                );                    DateTime date = DateTime.Now.AddMonths(-1);                q.SetDateTime(\"minDate\", date);                                result = q.List();                tx.Commit();            }            return result;        }    }} Chapter 23. Example: Various Mappings This chapter shows off some more complex association mappings. 23.1. Employer/Employee The following model of the relationship between Employer andEmployee uses an actual entity class (Employment) to represent the association. This is done because there might be more than one period of employment for the same two parties. Components are used to model monetary values and employee names. Here's a possible mapping document: <hibernate-mapping xmlns=\"urn:nhibernate-mapping-2.2\"    assembly=\"...\" namespace=\"...\">    <class name=\"Employer\" table=\"employers\">        <id name=\"Id\">            <generator class=\"sequence\">                <param name=\"sequence\">employer_id_seq<\/param>            <\/generator>        <\/id>        <property name=\"Name\"/>    <\/class>    <class name=\"Employment\" table=\"employment_periods\">        <id name=\"Id\">            <generator class=\"sequence\">                <param name=\"sequence\">employment_id_seq<\/param>            <\/generator>        <\/id>        <property name=\"StartDate\" column=\"start_date\"/>        <property name=\"EndDate\" column=\"end_date\"/>        <component name=\"HourlyRate\" class=\"MonetaryAmount\">            <property name=\"Amount\">                <column name=\"hourly_rate\" sql-type=\"NUMERIC(12, 2)\"/>            <\/property>            <property name=\"Currency\" length=\"12\"/>        <\/component>        <many-to-one name=\"Employer\" column=\"employer_id\" not-null=\"true\"/>        <many-to-one name=\"Employee\" column=\"employee_id\" not-null=\"true\"/>    <\/class>    <class name=\"Employee\" table=\"employees\">        <id name=\"Id\">            <generator class=\"sequence\">                <param name=\"sequence\">employee_id_seq<\/param>            <\/generator>        <\/id>        <property name=\"TaxfileNumber\"/>        <component name=\"Name\" class=\"Name\">            <property name=\"FirstName\"/>            <property name=\"Initial\"/>            <property name=\"LastName\"/>        <\/component>    <\/class><\/hibernate-mapping> And here's the table schema generated by SchemaExport. create table employers (    Id BIGINT not null,     Name VARCHAR(255),     primary key (Id))create table employment_periods (    Id BIGINT not null,    hourly_rate NUMERIC(12, 2),    Currency VARCHAR(12),     employee_id BIGINT not null,     employer_id BIGINT not null,     end_date TIMESTAMP,     start_date TIMESTAMP,     primary key (Id))create table employees (    Id BIGINT not null,     FirstName VARCHAR(255),     Initial CHAR(1),     LastName VARCHAR(255),     TaxfileNumber VARCHAR(255),     primary key (Id))alter table employment_periods     add constraint employment_periodsFK0 foreign key (employer_id) references employersalter table employment_periods     add constraint employment_periodsFK1 foreign key (employee_id) references employeescreate sequence employee_id_seqcreate sequence employment_id_seqcreate sequence employer_id_seq 23.2. Author/Work Consider the following model of the relationships between Work, Author and Person. We represent the relationship betweenWork andAuthor as a many-to-many association. We choose to represent the relationship betweenAuthor andPerson as one-to-one association. Another possibility would be to haveAuthor extendPerson. The following mapping document correctly represents these relationships: <hibernate-mapping xmlns=\"urn:nhibernate-mapping-2.2\"    assembly=\"...\" namespace=\"...\">    <class name=\"Work\" table=\"works\" discriminator-value=\"W\">        <id name=\"Id\" column=\"id\" generator=\"native\" />        <discriminator column=\"type\" type=\"character\"/>        <property name=\"Title\"/>        <set name=\"Authors\" table=\"author_work\" lazy=\"true\">            <key>                <column name=\"work_id\" not-null=\"true\"/>            <\/key>            <many-to-many class=\"Author\">                <column name=\"author_id\" not-null=\"true\"/>            <\/many-to-many>        <\/set>        <subclass name=\"Book\" discriminator-value=\"B\">            <property name=\"Text\" column=\"text\" />        <\/subclass>        <subclass name=\"Song\" discriminator-value=\"S\">            <property name=\"Tempo\" column=\"tempo\" />            <property name=\"Genre\" column=\"genre\" />        <\/subclass>    <\/class>    <class name=\"Author\" table=\"authors\">        <id name=\"Id\" column=\"id\">            <!-- The Author must have the same identifier as the Person -->            <generator class=\"assigned\"/>         <\/id>        <property name=\"Alias\" column=\"alias\" />        <one-to-one name=\"Person\" constrained=\"true\"/>        <set name=\"Works\" table=\"author_work\" inverse=\"true\" lazy=\"true\">            <key column=\"author_id\"/>            <many-to-many class=\"Work\" column=\"work_id\"/>        <\/set>    <\/class>    <class name=\"Person\" table=\"persons\">        <id name=\"Id\" column=\"id\">            <generator class=\"native\"/>        <\/id>        <property name=\"Name\" column=\"name\" />    <\/class><\/hibernate-mapping> There are four tables in this mapping. works, authors and persons hold work, author and person data respectively.author_work is an association table linking authors to works. Heres the table schema, as generated bySchemaExport. create table works (    id BIGINT not null generated by default as identity,     tempo FLOAT,     genre VARCHAR(255),     text INTEGER,     title VARCHAR(255),     type CHAR(1) not null,     primary key (id))create table author_work (    author_id BIGINT not null,     work_id BIGINT not null,     primary key (work_id, author_id))create table authors (    id BIGINT not null generated by default as identity,     alias VARCHAR(255),     primary key (id))create table persons (    id BIGINT not null generated by default as identity,     name VARCHAR(255),     primary key (id))alter table authors     add constraint authorsFK0 foreign key (id) references personsalter table author_work     add constraint author_workFK0 foreign key (author_id) references authorsalter table author_work    add constraint author_workFK1 foreign key (work_id) references works 23.3. Customer/Order/Product Now consider a model of the relationships between Customer,Order andLineItem and Product. There is a one-to-many association betweenCustomer andOrder, but how should we representOrder /LineItem / Product? I've chosen to mapLineItem as an association class representing the many-to-many association betweenOrder andProduct. In NHibernate, this is called a composite element. The mapping document: <hibernate-mapping xmlns=\"urn:nhibernate-mapping-2.2\"    assembly=\"...\" namespace=\"...\">    <class name=\"Customer\" table=\"customers\">        <id name=\"Id\" column=\"id\" generator=\"native\" />        <property name=\"Name\" column=\"name\"/>        <set name=\"Orders\" inverse=\"true\" lazy=\"true\">            <key column=\"customer_id\"/>            <one-to-many class=\"Order\"/>        <\/set>    <\/class>    <class name=\"Order\" table=\"orders\">        <id name=\"Id\" column=\"id\" generator=\"native\" />        <property name=\"Date\" column=\"date\"/>        <many-to-one name=\"Customer\" column=\"customer_id\"/>        <list name=\"LineItems\" table=\"line_items\" lazy=\"true\">            <key column=\"order_id\"/>            <index column=\"line_number\"/>            <composite-element class=\"LineItem\">                <property name=\"Quantity\" column=\"quantity\"/>                <many-to-one name=\"Product\" column=\"product_id\"/>            <\/composite-element>        <\/list>    <\/class>    <class name=\"Product\" table=\"products\">        <id name=\"Id\" column=\"id\">            <generator class=\"native\"/>        <\/id>        <property name=\"SerialNumber\" column=\"serial_number\" />    <\/class><\/hibernate-mapping> customers, orders, line_items and products hold customer, order, order line item and product data respectively.line_items also acts as an association table linking orders with products. create table customers (    id BIGINT not null generated by default as identity,     name VARCHAR(255),     primary key (id))create table orders (    id BIGINT not null generated by default as identity,     customer_id BIGINT,     date TIMESTAMP,     primary key (id))create table line_items (    line_number INTEGER not null,     order_id BIGINT not null,     product_id BIGINT,     quantity INTEGER,     primary key (order_id, line_number))create table products (    id BIGINT not null generated by default as identity,     serial_number VARCHAR(255),     primary key (id))alter table orders     add constraint ordersFK0 foreign key (customer_id) references customersalter table line_items    add constraint line_itemsFK0 foreign key (product_id) references productsalter table line_items    add constraint line_itemsFK1 foreign key (order_id) references orders Chapter 24. Best Practices Write fine-grained classes and map them using <component>. Use an Address class to encapsulate street, suburb, state, postcode. This encourages code reuse and simplifies refactoring. Declare identifier properties on persistent classes. NHibernate makes identifier properties optional. There are all sorts of reasons why you should use them. We recommend that identifiers be 'synthetic' (generated, with no business meaning) and of a non-primitive type. For maximum flexibility, useInt64 or String. Place each class mapping in its own file. Don't use a single monolithic mapping document. Map Eg.Foo in the fileEg/Foo.hbm.xml. This makes particularly good sense in a team environment. Embed mappings in assemblies. Place mapping files along with the classes they map and declare them as Embedded Resources in Visual Studio. Consider externalising query strings. This is a good practice if your queries call non-ANSI-standard SQL functions. Externalising the query strings to mapping files will make the application more portable. Use parameters. As in ADO.NET, always replace non-constant values by \"?\". Never use string manipulation to bind a non-constant value in a query! Even better, consider using named parameters in queries. Don't manage your own ADO.NET connections. NHibernate lets the application manage ADO.NET connections. This approach should be considered a last-resort. If you can't use the built-in connections providers, consider providing your own implementation ofNHibernate.Connection.IConnectionProvider. Consider using a custom type. Suppose you have a type, say from some library, that needs to be persisted but doesn't provide the accessors needed to map it as a component. You should consider implementingNHibernate.UserTypes.IUserType. This approach frees the application code from implementing transformations to / from an NHibernate type. Use hand-coded ADO.NET in bottlenecks. In performance-critical areas of the system, some kinds of operations (eg. mass update / delete) might benefit from direct ADO.NET. But please, wait until youknow something is a bottleneck. And don't assume that direct ADO.NET is necessarily faster. If need to use direct ADO.NET, it might be worth opening a NHibernateISession and using that SQL connection. That way you can still use the same transaction strategy and underlying connection provider. Understand ISession flushing. From time to time the ISession synchronizes its persistent state with the database. Performance will be affected if this process occurs too often. You may sometimes minimize unnecessary flushing by disabling automatic flushing or even by changing the order of queries and other operations within a particular transaction. In a three tiered architecture, consider using SaveOrUpdate(). When using a distributed architecture, you could pass persistent objects loaded in the middle tier to and from the user interface tier. Use a new session to service each request. UseISession.Update() orISession.SaveOrUpdate() to update the persistent state of an object. In a two tiered architecture, consider using session disconnection. Database Transactions have to be as short as possible for best scalability. However, it is often neccessary to implement long running Application Transactions, a single unit-of-work from the point of view of a user. This Application Transaction might span several client requests and response cycles. Either use Detached Objects or, in two tiered architectures, simply disconnect the NHibernate Session from the ADO.NET connection and reconnect it for each subsequent request. Never use a single Session for more than one Application Transaction usecase, otherwise, you will run into stale data. Don't treat exceptions as recoverable. This is more of a necessary practice than a \"best\" practice. When an exception occurs, roll back theITransaction and close theISession. If you don't, NHibernate can't guarantee that in-memory state accurately represents persistent state. As a special case of this, do not useISession.Load() to determine if an instance with the given identifier exists on the database; useGet() or a query instead. Prefer lazy fetching for associations. Use eager (outer-join) fetching sparingly. Use proxies and/or lazy collections for most associations to classes that are not cached in the second-level cache. For associations to cached classes, where there is a high probability of a cache hit, explicitly disable eager fetching using fetch=\"select\". When an outer-join fetch is appropriate to a particular use case, use a query with aleft join fetch. Consider abstracting your business logic from NHibernate. Hide (NHibernate) data-access code behind an interface. Combine the DAO and Thread Local Session patterns. You can even have some classes persisted by handcoded ADO.NET, associated to NHibernate via anIUserType. (This advice is intended for \"sufficiently large\" applications; it is not appropriate for an application with five tables!) Implement Equals() and GetHashCode() using a unique business key. If you compare objects outside of the ISession scope, you have to implement Equals() and GetHashCode(). Inside the ISession scope, object identity is guaranteed. If you implement these methods, never ever use the database identifier! A transient object doesn't have an identifier value and NHibernate would assign a value when the object is saved. If the object is in an ISet while being saved, the hash code changes, breaking the contract. To implementEquals() andGetHashCode(), use a unique business key, that is, compare a unique combination of class properties. Remember that this key has to be stable and unique only while the object is in an ISet, not for the whole lifetime (not as stable as a database primary key). Never use collections in theEquals() comparison (lazy loading) and be careful with other associated classes that might be proxied. Don't use exotic association mappings. Good usecases for a real many-to-many associations are rare. Most of the time you need additional information stored in the \"link table\". In this case, it is much better to use two one-to-many associations to an intermediate link class. In fact, we think that most associations are one-to-many and many-to-one, you should be careful when using any other association style and ask yourself if it is really neccessary. NHibernateContrib Documentation Preface The NHibernateContrib is various programs contributed to NHibernate by members of the NHibernate Team or by the end users. The projects in here are not considered core pieces of NHibernate but they extend it in a useful way. Chapter 25. NHibernate.Caches What is NHibernate.Caches? NHibernate.Caches namespace contains several second-level cache providers for NHibernate.A cache is place where entities are kept after being loaded from the database; once cached, they can be retrieved without going to the database. This means that they are faster to (re)load. An NHibernate session has an internal (first-level) cache where it keeps its entities. There is no sharing between these caches - a first-level cache belongs to a given session and is destroyed with it. NHibernate provides asecond-level cache system; it works at the session factory level. A second-level cache is shared by all sessions created by the same session factory. An important point is that the second-level cache does not cache instances of the object type being cached; instead it caches the individual values of the properties of that object. This provides two benefits. One, NHibernate doesn't have to worry that your client code will manipulate the objects in a way that will disrupt the cache. Two, the relationships and associations do not become stale, and are easy to keep up-to-date because they are simply identifiers. The cache is not a tree of objects but rather a map of arrays. With the session-per-request model, a high number of sessions can concurrently access the same entity without hitting the database each time; hence the performance gain. Several cache providers have been contributed by NHibernate users: NHibernate.Caches.Prevalence Uses Bamboo.Prevalence as the cache provider. Open the fileBamboo.Prevalence.license.txt for more information about its license; you can also visit itswebsite. NHibernate.Caches.SysCache Uses System.Web.Caching.Cache as the cache provider. This means that you can rely on ASP.NET caching feature to understand how it works. For more information, read (on the MSDN):Caching Application Data. NHibernate.Caches.SysCache2 Similar to NHibernate.Caches.SysCache, uses ASP.NET cache. This provider also supports SQL dependency-based expiration, meaning that it is possible to configure certain cache regions to automatically expire when the relevant data in the database changes. SysCache2 requires Microsoft SQL Server 2000 or higher and .NET Framework version 2.0 or higher. NHibernate.Caches.MemCache Uses memcached. See memcached homepage for more information. NCache provider for NHibernate Uses NCache,NCache is a commercial distributed caching system with a provider for NHibernate. The NCache Express version is free for use, seeNCache Express homepage for more information. 25.1. How to use a cache? Here are the steps to follow to enable the second-level cache in NHibernate: Choose the cache provider you want to use and copy its assembly in your assemblies directory (NHibernate.Caches.Prevalence.dll orNHibernate.Caches.SysCache.dll). To tell NHibernate which cache provider to use, add in your NHibernate configuration file (can beYourAssembly.exe.config orweb.config or a.cfg.xml file, in the latter case the syntax will be different from what is shown below): <add key=\"hibernate.cache.provider_class\" value=\"XXX\" />(1)<add key=\"expiration\" value=\"120\" />(2)\t\t\t\t\t\t (1) \"XXX\" is the assembly-qualified class name of a class implementingICacheProvider, eg. \"NHibernate.Caches.SysCache.SysCacheProvider, NHibernate.Caches.SysCache\". (2) The expiration value is the number of seconds you wish to cache each entry (here two minutes). This example applies to SysCache only. Add <cache usage=\"read-write|nonstrict-read-write|read-only\"/> (just after<class>) in the mapping of the entities you want to cache. It also works for collections (bag, list, map, set, ...). Be careful. Caches are never aware of changes made to the persistent store by another process (though they may be configured to regularly expire cached data). As the caches are created at the session factory level, they are destroyed with the SessionFactory instance; so you must keep them alive as long as you need them. 25.2. Prevalence Cache Configuration There is only one configurable parameter: prevalenceBase. This is the directory on the file system where the Prevalence engine will save data. It can be relative to the current directory or a full path. If the directory doesn't exist, it will be created. 25.3. SysCache Configuration As SysCache relies on System.Web.Caching.Cache for the underlying implementation, the configuration is based on the available options that make sense for NHibernate to utilize. expiration Number of seconds to wait before expiring each item. priority A numeric cost of expiring each item, where 1 is a low cost, 5 is the highest, and 3 is normal. Only values 1 through 5 are valid. SysCache has a config file section handler to allow configuring different expirations and priorities for different regions. Here's an example: Example 25.1. <?xml version=\"1.0\" encoding=\"utf-8\" ?><configuration>\t<configSections>\t\t<section name=\"syscache\" type=\"NHibernate.Caches.SysCache.SysCacheSectionHandler,NHibernate.Caches.SysCache\" />\t<\/configSections>\t<syscache>\t\t<cache region=\"foo\" expiration=\"500\" priority=\"4\" />\t\t<cache region=\"bar\" expiration=\"300\" priority=\"3\" />\t<\/syscache><\/configuration> 25.4. SysCache2 Configuration SysCache2 can use SqlCacheDependencies to invalidate cache regions when data in an underlying SQL Server table or query changes. Query dependencies are only available for SQL Server 2005. To use the cache provider, the application must be setup and configured to support SQL notifications as described in the MSDN documentation. To configure cache regions with SqlCacheDependencies a syscache2 config section must be defined in the application's configuration file. See the sample below. Example 25.2. <configSections>\t<section name=\"syscache2\" type=\"NHibernate.Caches.SysCache2.SysCacheSection, NHibernate.Caches.SysCache2\"/><\/configSections> 25.4.1. Table-based Dependency A table-based dependency will monitor the data in a database table for changes. Table-based dependencies are generally used for a SQL Server 2000 database but will work with SQL Server 2005 as well. Before you can use SQL Server cache invalidation with table based dependencies, you need to enable notifications for the database. This task is performed with theaspnet_regsql command. With table-based notifications, the application will poll the database for changes at a predefined interval. A cache region will not be invalidated immediately when data in the table changes. The cache will be invalidated the next time the application polls the database for changes. To configure the data in a cache region to be invalidated when data in an underlying table is changed, a cache region must be configured in the application's configuration file. See the sample below. Example 25.3. <syscache2>\t<cacheRegion name=\"Product\">\t\t<dependencies>\t\t\t<tables>\t\t\t\t<add name=\"price\"\t\t\t\t\tdatabaseEntryName=\"Default\"\t\t\t\t\ttableName=\"VideoTitle\" />\t\t\t<\/tables>\t\t<\/dependencies>\t<\/cacheRegion>\t<\/syscache2> Table-based Dependency Configuration Properties name Unique name for the dependency tableName The name of the database table that the dependency is associated with. The table must be enabled for notification support with theAspNet_SqlCacheRegisterTableStoredProcedure. databaseEntryName The name of a database defined in the databases element forsqlCacheDependency for caching (ASP.NET Settings Schema) element of the application'sWeb.config file. 25.4.2. Command-Based Dependencies A command-based dependency will use a SQL command to identify records to monitor for data changes. Command-based dependencies work only with SQL Server 2005. Before you can use SQL Server cache invalidation with command-based dependencies, you need to enable the Service Broker for query notifications. The application must also start the listener for receiving change notifications from SQL Server. With command based notifications, SQL Server will notify the application when the data of a record returned in the results of a SQL query has changed. Note that a change will be indicated if the data in any of the columns of a record change, not just the columns returned by a query. The query is a way to limit the number of records monitored for changes, not the columns. As soon as data in one of the records is modified, the data in the cache region will be invalidated immediately. To configure the data in a cache region to be invalidated based on a SQL command, a cache region must be configured in the application's configuration file. See the samples below. Example 25.4. Stored Procedure <cacheRegion name=\"Product\" priority=\"High\" >\t<dependencies>\t\t<commands>\t\t\t<add name=\"price\"\t\t\t\tcommand=\"ActiveProductsStoredProcedure\" \t\t\t\tisStoredProcedure=\"true\"/>\t\t<\/commands>\t<\/dependencies><\/cacheRegion> Example 25.5. SELECT Statement <cacheRegion name=\"Product\" priority=\"High\">\t<dependencies>\t\t<commands>\t\t\t<add name=\"price\"\t\t\t\tcommand=\"Select VideoTitleId from dbo.VideoTitle where Active = 1\"\t\t\t\tconnectionName=\"default\"\t\t\t\tconnectionStringProviderType=\"NHibernate.Caches.SysCache2.ConfigConnectionStringProvider, NHibernate.Caches.SysCache2\"/>\t\t<\/commands>\t<\/dependencies><\/cacheRegion> Command Configuration Properties name Unique name for the dependency command (required) SQL command that returns results which should be monitored for data changes isStoredProcedure (optional) Indicates if command is a stored procedure. The default is false. connectionName (optional) The name of the connection in the applications configuration file to use for registering the cache dependency for change notifications. If no value is supplied forconnectionNameor connectionStringProviderType, the connection properties from the NHibernate configruation will be used. connectionStringProviderType (optional) IConnectionStringProvider to use for retrieving the connection string to use for registering the cache dependency for change notifications. If no value is supplied forconnectionName, the unnamed connection supplied by the provider will be used. 25.4.3. Aggregate Dependencies Multiple cache dependencies can be specified. If any of the dependencies triggers a change notification, the data in the cache region will be invalidated. See the samples below. Example 25.6. Multiple commands <cacheRegion name=\"Product\">\t<dependencies>\t\t<commands>\t\t\t<add name=\"price\"\t\t\t\tcommand=\"ActiveProductsStoredProcedure\" \t\t\t\tisStoredProcedure=\"true\"/>\t\t\t<add name=\"quantity\"\t\t\t\tcommand=\"Select quantityAvailable from dbo.VideoAvailability\"/>\t\t<\/commands>\t<\/dependencies><\/cacheRegion>\t\t\t\t Example 25.7. Mixed <cacheRegion name=\"Product\">\t<dependencies>\t\t<commands>\t\t\t<add name=\"price\"\t\t\t\tcommand=\"ActiveProductsStoredProcedure\" \t\t\t\tisStoredProcedure=\"true\"/>\t\t<\/commands>\t\t<tables>\t\t\t<add name=\"quantity\"\t\t\t\tdatabaseEntryName=\"Default\"\t\t\t\ttableName=\" VideoAvailability\" />\t\t<\/tables>\t<\/dependencies><\/cacheRegion> 25.4.4. Additional Settings In addition to data dependencies for the cache regions, time based expiration policies can be specified for each item added to the cache. Time based expiration policies will not invalidate the data dependencies for the whole cache region, but serve as a way to remove items from the cache after they have been in the cache for a specified amount of time. See the samples below. Example 25.8. Relative Expiration <cacheRegion name=\"Product\" relativeExpiration=\"300\" priority=\"High\" /> Example 25.9. Time of Day Expiration <cacheRegion name=\"Product\" timeOfDayExpiration=\"2:00:00\" priority=\"High\" /> Additional Configuration Properties relativeExpiration Number of seconds that an individual item will exist in the cache before being removed. timeOfDayExpiration 24 hour based time of day that an item will exist in the cache until. 12am is specified as 00:00:00; 10pm is specified as 22:00:00. Only valid if relativeExpiration is not specified. Time of Day Expiration is useful for scenarios where items should be expired from the cache after a daily process completes. priority System.Web.Caching.CacheItemPriority that identifies the relative priority of items stored in the cache. 25.4.5. Patches There is a known issue where some SQL Server 2005 notifications might not be received when an application subscribes to query notifications by using ADO.NET 2.0. To fix this problem installSQL hotfix for kb 913364. Chapter 26. NHibernate.Mapping.Attributes What is NHibernate.Mapping.Attributes? NHibernate.Mapping.Attributes is an add-in for NHibernate contributed by Pierre Henri Kuaté (aka KPixel); the former implementation was made by John Morris.NHibernate require mapping streams to bind your domain model to your database. Usually, they are written (and maintained) in separated hbm.xml files. With NHibernate.Mapping.Attributes, you can use .NET attributes to decorate your entities and these attributes will be used to generate these mapping .hbm.xml (as files or streams). So you will no longer have to bother with thesenasty xml files ;). Content of this library. NHibernate.Mapping.Attributes: That the only project you need (as end-user) Test: a working sample using attributes and HbmSerializer as NUnit TestFixture Generator: The program used to generate attributes and HbmWriter Refly: Thanks toJonathan de Halleux for this library which make it so easy to generate code Important This library is generated using the file /src/NHibernate.Mapping.Attributes/nhibernate-mapping.xsd (which is embedded in the assembly to be able to validate generated XML streams). As this file can change at each new release of NHibernate, you should regenerate it before using it with a different version (open the Generator solution, compile and run the Generator project). But, no test has been done with versions prior to 0.8. 26.1. What's new? NHibernate. introduces many new features, improvements and changes: It is possible to import classes by simply decorating them with [Import] class ImportedClass1 {}. Note that you must use HbmSerializer.Serialize(assembly); The <import/> mapping will be added before the classes mapping. If you prefer to keep these imports in the class using them, you can specify them all on the class:[Import(ClassType=typeof(ImportedClass1))] class Query {}. [RawXmlAttribute] is a new attribute allowing to insert xml as-is in the mapping. This feature can be very useful to do complex mapping (eg: components). It may also be used to quickly move the mapping from xml files to attributes. Usage: [RawXml(After=typeof(ComponentAttribute), Content=\"<component name=\"...\">...<\/component>\")].After tells after which kind of mapping the xml should be inserted (generally, it is the type of the mapping you are inserting); it is optional (in which case the xml is inserted on the top of the mapping). Note: At the moment, all raw xmls are prefixed by a<!----> (in the generated stream); this is a known side-effect. [AttributeIdentifierAttribute] is a new attribute allowing to provide the value of a defined \"place holder\". Eg: public class Base {    [Id(..., Column=\"{{Id.Column}}\")]    [AttributeIdentifier(Name=\"Id.Column\", Value=\"ID\")] // Default value    public int Id { ... }}[AttributeIdentifier(Name=\"Id.Column\", Value=\"SUB_ID\")][Class] public class MappedSubClass : Base { } The idea is that, when you have a mapping which is shared by many subclasses but which has minor differences (like different column names), you can put the mapping in the base class with place holders on these fields and give their values in subclasses. Note that this is possible for any mapping field taking a string (column, name, type, access, etc.). And, instead ofValue, you can useValueType orValueObject (if you use an enum, you can control its formatting withValueObject). The \"place holder\" is defined like this: {{XXX}}. If you don't want to use these double curly brackets, you can change them using the propertiesStartQuote andEndQuote of the classHbmWriter. It is possible to register patterns (using Regular Expressions) to automatically transform fully qualified names of properties types into something else. Eg:HbmSerializer.Default.HbmWriter.Patterns.Add(@\"Namespace.(\\S+), Assembly\", \"$1\"); will map all properties with a not-qualified type name. Two methods have been added to allow writing: cfg.AddInputStream( HbmSerializer.Default.Serialize(typeof(XXX)) ) andcfg.AddInputStream( HbmSerializer.Default.Serialize(typeof(XXX).Assembly) ). So it is no longer required to create a MemoryStream for these simple cases. Two WriteUserDefinedContent() methods have been added toHbmWriter. They improve the extensibility of this library; it is now very easy to create a .NET attribute and integrate it in the mapping. Attributes [(Jcs)Cache], [Discriminator] and[Key] can be specified at class-level. Interfaces can be mapped (just like classes and structs). A notable \"bug\" fix is the re-ordering of (joined-)subclasses; This operation may be required when a subclass extends another subclass. In this case, the extended class mapping must come before the extending class mapping. Note that the re-ordering takes place only for \"top-level\" classes (that is not nested in other mapped classes). Anyway, it is quite unusual to put a interdependent mapped subclasses in a mapped class. There are also many other little changes; refer to the release notes for more details. 26.2. How to use it? The end-user class is NHibernate.Mapping.Attributes.HbmSerializer. This class serialize your domain model to mapping streams. You can either serialize classes one by one or an assembly. Look atNHibernate.Mapping.Attributes.Test project for a working sample. The first step is to decorate your entities with attributes; you can use: [Class], [Subclass], [JoinedSubclass] or[Component]. Then, you decorate your members (fields/properties); they can take as many attributes as required by your mapping. Eg:     [NHibernate.Mapping.Attributes.Class]    public class Example    {        [NHibernate.Mapping.Attributes.Property]        public string Name;    } After this step, you use NHibernate.Mapping.Attributes.HbmSerializer: (here, we useDefault which is an instance you can use if you don't need/want to create it yourself).     NHibernate.Cfg.Configuration cfg = new NHibernate.Cfg.Configuration();    cfg.Configure();    NHibernate.Mapping.Attributes.HbmSerializer.Default.Validate = true; // Enable validation (optional)    // Here, we serialize all decorated classes (but you can also do it class by class)    cfg.AddInputStream( NHibernate.Mapping.Attributes.HbmSerializer.Default.Serialize(        System.Reflection.Assembly.GetExecutingAssembly() ); );    // Now you can use this configuration to build your SessionFactory... Note As you can see here: NHibernate.Mapping.Attributes is not (really) intrusive. Setting attributes on your objects doesn't force you to use them with NHibernate and doesn't break any constraint on your architecture. Attributes are purely informative (like documentation)! 26.3. Tips In production, it is recommended to generate a XML mapping file from NHibernate.Mapping.Attributes and use this file each time the SessionFactory need to be built. Use:HbmSerializer.Default.Serialize(typeof(XXX).Assembly, \"DomainModel.hbm.xml\"); It is slightly faster. Use HbmSerializer.Validate to enable/disable the validation of generated xml streams (against NHibernate mapping schema); this is useful to quickly find errors (they are written in StringBuilderHbmSerializer.Error). If the error is due to this library then see if it is a know issue and report it; you can contribute a solution if you solve the problem :) Your classes, fields and properties (members) can be private; just make sure that you have the permission to access private members using reflection (ReflectionPermissionFlag.MemberAccess). Members of a mapped classes are also seek in its base classes (until we reach mapped base class). So you can decorate some members of a (not mapped) base class and use it in its (mapped) sub class(es). For a Name taking a System.Type, set the type with Name=\"xxx\" (as string) orNameType=typeof(xxx); (add \"Type\" to \"Name\") By default, .NET attributes don't keep the order of attributes; so you need to set it yourself when the order matter (using the first parameter of each attribute); it ishighly recommended to set it when you have more than one attribute on the same member. As long as there is no ambiguity, you can decorate a member with many unrelated attributes. A good example is to put class-related attributes (like<discriminator>) on the identifier member. But don't forget that the order matters (the<discriminator> must be after the <id>). The order used comes from the order of elements in the NHibernate mapping schema. Personally, I prefer using negative numbers for these attributes (if they come before!). You can add [HibernateMapping] on your classes to specify<hibernate-mapping> attributes (used when serializing the class in its stream). You can also useHbmSerializer.Hbm* properties (used when serializing an assembly or a type that is not decorated with[HibernateMapping]). Instead of using a string for DiscriminatorValue (in[Class] and[Subclass]), you can use any object you want. Example: [Subclass(DiscriminatorValueEnumFormat=\"d\", DiscriminatorValueObject=DiscEnum.Val1)] Here, the object is an Enum, and you can set the format you want (the default value is \"g\"). Note that you must put itbefore! For others types, It simply use theToString() method of the object. If you are using members of the type Nullables.NullableXXX (from the libraryNullables), then they will be mapped toNullables.NHibernate.NullableXXXType automatically; don't setType=\"...\" in [Property] (leave it null). This is also the case forSqlTypes (and you can add your own patterns). Thanks toMichael Third for the idea :) Each stream generated by NHibernate.Mapping.Attributes can contain a comment with the date of the generation; You may enable/disable this by using the propertyHbmSerializer.WriteDateComment. If you forget to provide a required xml attribute, it will obviously throw an exception while generating the mapping. The recommended and easiest way to map [Component] is to use[ComponentProperty]. The first step is to put[Component] on the component class and map its fields/properties. Note that you shouldn't set theName in[Component]. Then, on each member in your classes, add[ComponentProperty]. But you can't overrideAccess, Update or Insert for each member. There is a working example in NHibernate.Mapping.Attributes.Test (look for the classCompAddress and its usage in others classes). Another way to map [Component] is to use the way this library works: If a mapped class contains a mapped component, then this component will be include in the class.NHibernate.Mapping.Attributes.Test contains the classesJoinedBaz and Stuff which both use the componentAddress. Basically, it is done by adding [Component(Name = \"MyComp\")] private class SubComp : Comp {} in each class. One of the advantages is that you can override Access, Update or Insert for each member. But you have to add the component subclass ineach class (and it can not be inherited). Another advantage is that you can use[AttributeIdentifier]. Finally, whenever you think that it is easier to write the mapping in XML (this is often the case for[Component]), you can use[RawXml]. About customization. HbmSerializer usesHbmWriter to serialize each kind of attributes. Their methods are virtual; so you can create a subclass and override any method you want (to change its default behavior). Use the property HbmSerializer.HbmWriter to change the writer used (you may set a subclass ofHbmWriter). Example using some this tips: (0, 1 and 2 are position indexes)     [NHibernate.Mapping.Attributes.Id(0, TypeType=typeof(int))] // Don't put it after [ManyToOne] !!!        [NHibernate.Mapping.Attributes.Generator(1, Class=\"uuid.hex\")]    [NHibernate.Mapping.Attributes.ManyToOne(2, ClassType=typeof(Foo), OuterJoin=OuterJoinStrategy.True)]    private Foo Entity; Generates:     <id type=\"Int32\">        <generator class=\"uuid.hex\" />    <\/id>    <many-to-one name=\"Entity\" class=\"Namespaces.Foo, SampleAssembly\" outer-join=\"true\" /> 26.4. Known issues and TODOs First, read TODOs in the source code ;) A Position property has been added to all attributes to order them. But there is still a problem: When a parent element \"p\" has a child element \"x\" that is also the child element of another child element \"c\" of \"p\" (preceding \"x\") :D Illustration:     <p>        <c>            <x />        <\/c>        <x />    <\/p> In this case, when writing:     [Attributes.P(0)]        [Attributes.C(1)]            [Attributes.X(2)]        [Attributes.X(3)]    public MyType MyProperty; X(3) will always belong to C(1) ! (as X(2)). It is the case for <dynamic-component> and <nested-composite-element>. Another bad news is that, currently, XML elements coming after this elements can not be included in them. Eg: There is no way put a collection in<dynamic-component>. The reason is that the filenhibernate-mapping.xsd tells how elements are built and in which order, and NHibernate.Mapping.Attributes use this order. Anyway, the solution would be to add a int ParentNode property to BaseAttribute so that you can create a real graph... For now, you can fallback on [RawXml]. Actually, there is no other know issue nor planned modification. This library should be stable and complete; but if you find a bug or think of an useful improvement, contact us! On side note, it would be nice to write a better TestFixture than NHibernate.Mapping.Attributes.Test :D 26.5. Developer Notes Any change to the schema (nhibernate-mapping.xsd) implies: Checking if there is any change to do in the Generator (like updating KnowEnums / AllowMultipleValue / IsRoot / IsSystemType / IsSystemEnum / CanContainItself) Updating /src/NHibernate.Mapping.Attributes/nhibernate-mapping.xsd (copy/paste) and running the Generator again (even if it wasn't modified) Running the Test project and make sure that no exception is thrown. A class/property should be modified/added in this project to be sure that any new breaking change will be caught (=> update the reference hbm.xml files and/or the projectNHibernate.Mapping.Attributes-2.0.csproj) This implementation is based on NHibernate mapping schema; so there is probably lot of \"standard schema features\" that are not supported... The version of NHibernate.Mapping.Attributes should be the version of the NHibernate schema used to generate it (=> the version of NHibernate library). In the design of this project, performance is a (very) minor goal :) Easier implementation and maintenance are far more important because you can (and should) avoid to use this library in production (Cf. the first tip in Section 26.3, “Tips”).","title":"NHibernate - Relational Persistence for Idiomatic .NET"},{"content":"看淘宝大牛们晒一晒淘宝网技术内幕   淘宝网是一个在线商品数量突破一亿，日均成交额超过两亿元人民币，注册用户接近八千万的大型电子商务网站，是亚洲最大的购物网站。那么对于淘宝网这样大规模的一个网站，我猜想大家一定会非常关心整个网站都采用了什么样的技术？前端设计和后台架构有哪些内幕？淘宝所依赖的数据库到底是什么？它用到了哪些存储技术？淘宝网的应用服务器上采用的是Linux操作系统。在应用服务器前端，淘宝采用了Web Server做了一次转发，选择的Web服务器是大名鼎鼎的Apache。想知道淘宝的技术大牛们在淘宝技术上有哪些看点？本文将揭晓谜底，重点晒一晒淘宝大牛们在淘宝数据库、前端设计、后台架构以及存储方面的见解。   淘宝数据库篇 在淘宝网的应用中，采用了两种关系型数据库管理系统。一个是 Oracle公司的Oracle 10g，另外一个是Sun MySQL的MySQL。Oracle是一款优秀的、广泛采用的商业数据库管理软件。有很强大的功能和安全性，可以处理相对海量的数据。而MySQL是一 款非常优秀的开源数据库管理软件，非常适合用多台PC Server组成多点的存储节点阵列(这里我所指的不是MySQL自身提供的集群功能)，每单位的数据存储成本也非常的低廉。用多台PC Server安装MySQL组成一个存储节点阵列，通过MySQL自身的Replication或者应用自身的处理，可以很好的保证容错(允许部分节点失 效)，保证应用的健壮性和可靠性。可以这么说，在关系数据库管理系统的选择上，可以考虑应用本身的情况来决定。   淘宝数据库架构演进历程 淘宝余锋: 淘宝商品库MySQL优化实践 淘宝张毅: 淘宝Hbase应用和改善 淘宝王晶昱:淘宝的MySQL运维管理工具 淘宝杨传辉: OceanBase淘宝千亿级海量数据库 淘宝褚霸：利用新硬件提升数据库性能   淘宝前端设计篇 淘宝网的Web展现层的框架用的不是struts，不是webwork，不是spring mvc等等。淘宝网的Web展现层的框架用的是集团内部自主开发的一套Web框架。这个框架能够解决一些其他Web框架不能解决的、在淘宝的应用中又会出 现并需要解决的问题。在淘宝的多个应用中，也采用了一些开源的框架，比如Spring、iBatis、jBPM、Hessian、Mina等等。这些开源 软件的采用为我们构建应用系统提供了很大的帮助。   淘宝李晶：淘宝的HTML5实践 淘宝张振宇：淘宝数据化运营 淘宝蒋江伟：淘宝前台系统优化实践 淘宝周赛：淘宝开放产品前端实践 淘宝慧色：淘宝用户体验与交互设计 淘宝云谦：前端测试之淘宝实战   淘宝后台架构篇 2003年5月至2004年5月，小而快的简单架构，基于LAMP，符合当时的需求。 2004年2月至2008年3月，一个懵懂的阶段，开始分为多个层次。这个阶段需要一个能够支撑百万到千万用户级的架构，必须容易扩展；系统从WebLogic迁移至了JBoss；开发了大量软件，例如TFS、iSearch、TDBM和CDN。 2007年10月至2009年11月，开始有前瞻性，走向产品化及服务化。非核心的数据由Oracle迁移到了MySQL上，构建起了消息系统和服务框架，淘宝开放平台（TOP）正式上线。 2009年8月至今的淘宝则更系统化、智能化及专业化，这是发展的必然方向。知识经验慢慢融入工具之中，降低了门槛，减少误操作几率；操作从人工处理逐步转为系统自主决策；在稳定性和性能方面有长足发展。   淘宝天羽:淘宝核心库硬件优化 淘宝章文嵩:淘宝软件基础设施构建实践 淘宝泽远:淘宝海量数据服务平台架构与实践 淘宝岑文初：淘宝开放平台架构设计与实践 淘宝张轩丞：淘宝海量数据产品技术架构   淘宝存储篇 淘宝图片系统在整个网站中的重要性和发展历史；存储淘宝图片的分布式文件系统，以及它的架构、性能指标和现有的部署规模；基于Nginx的Image Server和Cache系统；淘宝CDN系统的总体结构，一级Cache和二级Cache的规划和基于开源的系统实现；低功耗服务器在 CDN上的试验规划；总结了淘宝图片存储和发送系统设计的原则和经验。   Flash存储设备在淘宝的应用实践 淘宝Hadoop应用--分布式数据处理实践 章文嵩：淘宝海量图片存储与CDN系统 淘宝OceanBase云存储实践 淘宝云铮：淘宝云梯分布式计算平台整体架构 淘宝王勇：淘宝海量数据的高效存储原理和实践","title":"看淘宝大牛们晒一晒淘宝网技术内幕"},{"content":"（转载地址：http://blog.csdn.net/songyubin001/article/details/588815）   java与oracle的接口：      在数据库中运行JAVA可以说是ORACLE8i的最令人激动的新特性。在你创建的使用ORACLE8i 数据库的应用程序中，你可以使用与JAVA有关的新特征，轻松的将程序发布到INTERNET或INTRANET上。 Methods for Using Java in ORACLE================================== 大家都知道JAVA在跨平台开发与INTERNET开发中已经比较流行，ORACLE8i及以后的版本中都包含了对在数据库中运行JAVA的扩展支持，这里有两种方法可以使用： JDBC：与ODBC类似, JDBC 提供了一个驱动接口使你可以在JAVA程序中访问数据库。注：JDBC驱动内嵌在数据库中虚拟机中。 SQLJ：是一个JAVA预编译器，它可以将内嵌的SQL语句转化为JAVA语句.SQLJ的使用与运行机理与其它ORACLE的与编译器（如Pro*C，Pro*COBOL）类似。实际上，为了使我们形象的记住SQLJ提供的功能，我们也可以直接将SQLJ改名为Pro*Java。       将JAVA集成到数据库中是双向的。也就是说你可以在JAVA中调用SQL与PL/SQL,也可以在SQL与PL/SQL中调用JAVA。JAVA程序可以直接通过JDBC驱动调用SQL与PL/SQL，反过来，你也可以在SQL与PL/SQL中直接调用JAVA。在数据库中，JAVA命名空间直接映射到数据库模式的命名空间中，这样可以方便JAVA的存取与调用。数据库同时提供扩展的DDL语句，通过这些语句，你可以象创建一个存储过程一样在数据中创建内嵌的JAVA程序。 Features of ORACLE JDBC Drivers ================================= 在ORACLE8i中有三种类型的JDBC驱动，他们都使用相同的 syntax, APIs, and Oracle extensions，以使JAVA代码在robust clients、Web-based Java applets, and Java stored procedures之间保持轻便灵活：三种类型如下： 1．JDBC  OCI： 此驱动类似于传统的ODBC 驱动。因为它需要Oracle Call Interface and Net8，所以它需要在运行使用此驱动的JAVA程序的机器上安装客户端软件 2．JDBC Thin： 这种驱动一般用在运行在WEB浏览器中的JAVA程序。它不是通过OCI or Net8，而是通过Java sockets进行通信 ，因此不需要在使用JDBC Thin的客户端机器上安装客户端软件。  3．JDBC KPRB： 这种驱动由直接存储在数据库中的JAVA程序使用，如Java Stored Procedures 、triggers、Database JSP's。It uses the default/ current database session and thus requires no additional database username, password or URL. 如何配置使JAVA可以通过Oracle JDBC Drivers连接到数据库：1.安装Sun JDK.   2. 修改PATH环境变量，使其指向JDK的bin目录  3. 设置CLASSPATH环境变量，使其指向正确的JDK的lib及oracle的JDBC接口。 CLASSPATH = \".;????\" 3. 运行\"java ?version\" ，验证java的版本。 如何在不同的操作系统上根据接口类型设置客户端： 对JDBC THIN接口： 在windows与unix下的设置方法一样： 1．根据jdk的版本，只需要将classesxx.zip拷贝到指定的目录，不需要安装Oracle Client。在装完数据库后，该文件会在$ORACLE_HOME/jdbc/lib目录下。2．设置CLASSPATH，使其包含上面的classesxx.zip 3．根据需要，拷贝oracle的其它zip文件并设置CLASSPATH 对JDBC OCI接口： Fow Windows： 1．安装Oracle Client. 2．根据jdk的版本，设置CLASSPATH，使其包含正确的classesxx.zip 3．根据需要设置CLASSPATH，使其指向Oracle的其它zip文件 4．设置PATH，使其包含$ORACLE_HOME/bin目录 For unix： 1．安装Oracle Client. 2．根据jdk的版本，设置CLASSPATH，使其包含正确的classesxx.zip 3．根据需要设置CLASSPATH，使其指向Oracle的其它zip文件 4．设置LD_LIBRARY_PATH，使其包含$ORACLE_HOME/lib目录 备注： classesxx.zip一般在ORACLE_HOME/jdbc/lib目录下。      在ORACLE_HOME/jdbc/lib目录下的与Oracle JDBC Drives驱动有关的文件的解释：   - classes12.zip      Classes for use with JDK 1.2.x.  It contains the JDBC driver      classes except classes necessary for NLS support in Object and      Collection types.    - nls_charset12.zip      NLS classes for use with JDK 1.2.x.  It contains classes necessary      for NLS support in Object and Collection types.    - classes12_g.zip      Same as classes12.zip, except that classes were compiled with      \"javac -g\".  JDBC连接数据库的语法： JDBC THIN:   Code: [Copy to clipboard]    Connection conn=         DriverManager.getConnection           (\"jdbc:oracle:thin:@dlsun511:1521:ora1\",\"scott\",\"tiger\");                                  |       |     |                         machine(ip@) : port# : sid     JDBC OCI:   Code: [Copy to clipboard]    Connection conn=         DriverManager.getConnection           (\"jdbc:oracle:oci8[9]:@RAC\",\"scott\",\"tiger\");                                  |                                 Net Service    JDBC THIN与JDBC THIN对比： 相同之处：       The JDBC Thin, JDBC OCI, and JDBC Server drivers all provide the same functionality.  They all support the following standards and features:          * JDBC 2.0          * Partial JDBC 3.0 (in JDBC driver version 9.2)          * the same syntax and APIs          * the same Oracle extensions  至于不同之处是一个表格，不好上传，大家自己总结吧！！ 主要是JDBC OCI 接口比JDBC THIN接口效率高！ How does one connect with the JDBC Thin Driver?       The the JDBC thin driver provides the only way to access Oracle from the Web (applets). It is smaller and slower than the OCI drivers. import java.sql.*;   Code: [Copy to clipboard]    class dbAccess {   public static void main (String args []) throws SQLException   {     DriverManager.registerDriver (       new oracle.jdbc.driver.OracleDriver()     );     Connection conn = DriverManager.getConnection       (\"jdbc:oracle:thin:@dbhost:1521:ORA1\", \"scott\", \"tiger\");                       // @machine:port:SID,   userid,  password     Statement stmt = conn.createStatement();     ResultSet rset = stmt.executeQuery (       \"select BANNER from SYS.V_$VERSION\"     );     while (rset.next())        System.out.println (rset.getString(1));   // Print col 1     stmt.close();   } }    How does one connect with the JDBC OCI Driver?       One must have Net8 (SQL*Net) installed and working before attempting to use one of the OCI drivers.   Code: [Copy to clipboard]    import java.sql.*; class dbAccess {   public static void main (String args []) throws SQLException   {     try {       Class.forName (\"oracle.jdbc.driver.OracleDriver\");     } catch (ClassNotFoundException e) {       e.printStackTrace();     }     Connection conn = DriverManager.getConnection        (\"jdbc:oracle:oci8:@ORA1\", \"scott\", \"tiger\");               // or oci9 @Service, userid,  password     Statement stmt = conn.createStatement();     ResultSet rset = stmt.executeQuery (       \"select BANNER from SYS.V_$VERSION\"     );     while (rset.next())       System.out.println (rset.getString(1)); // Print col 1     stmt.close();   } }    How does one connect with the JDBC KPRB Driver?       One can obtain a handle to the default or current connection (KPRB driver) by calling the OracleDriver.defaultConenction() method. Please note that you do not need to specify a database URL, username or password as you are already connected to a database session. Remember not to close the default connection. Closing the default connection might throw an exception in future releases of Oracle.  import java.sql.*;   Code: [Copy to clipboard]    class dbAccess {   public static void main (String args []) throws SQLException   {     Connection conn = (new       oracle.jdbc.driver.OracleDriver()).defaultConnection();     Statement stmt = conn.createStatement();     ResultSet rset = stmt.executeQuery (       \"select BANNER from SYS.V_$VERSION\"     );     while (rset.next())       System.out.println (rset.getString(1));   // Print col 1     stmt.close();   } }    与JAVA有关的初始化参数：====================================== Executing initjvm.sql also highlights some new initsid.ora parameters that are used to support Java in your Oracle8i database. These parameters, their descriptions, and the settings required for running initjvm.sql, are all shown in the following list: ?      SHARED_POOL_SIZE? Defines the size of your shared pool in bytes. This should be set to at least 50MB to run initjvm.sql.  ?      JAVA_POOL_SIZE? Defines the size of the Java pool, a new area of the SGA  in Oracle8i used to store shared Java objects. This should be set to 50MB when running initjvm.sql, but can be as low as 20MB for normal use          of Java stored procedures.  ?      JAVA_SOFT_SESSIONSPACE_LIMIT? Identifies a soft limit on memory used by Java in a session. The default is 1MB. If this limit is exceeded, a warning is written to the ALERT log.  ?      JAVA_MAX_SESSIONSPACE_SIZE? Identifies the maximum amount of memory that can be used by a Java procedure; the default is 4GB. When the limit set by this parameter is exceeded, the executing Java procedure is killed by Oracle8i automatically.         如果将JAVA程序存放在数据库中，并运行存储在数据库中的JAVA程序，则数据库中会启用JAVA的虚拟机，为了保证JAVA虚拟机有效的运行，你需要设置上面介绍的参数。 如何将一个JAVA程序装载到数据库并且发布出去？===================================       就像前面说得，java程序或类可以被存储到数据库中，作为PL/SQL的替换或补充。Java可以被用来作为数据库的触发器、存储过程、函数、对象的成员函数。在按照下面的过程开发完java存储过程后，就可以从SQL或PL/SQL中调用JAVA存储过程，就像调用普通的PL/SQL过程一样。下面的代码描述了如何在SQL*PLUS中开发和使用一个 输出\"Hello, World\" 的JAVA程序的例子： 1. Write the Java program using a Java development environment like Jdeveloper or JBuilder. 2. Load the Java program into Oracle8i using either the create or replace         java source command, or with the LOADJAVA utility. 3. Publish your Java procedure to SQL. This step identifies your Java         procedure to SQL and PL/SQL by exposing the procedure entry point,         mapping datatypes in Java to PL/SQL or SQL, and indicating         parameter-passing between Java and PL/SQL or SQL. （1）编写java程序 ---可以直接在SQL*PLUS中创建JAVA的源文件，当然如果有已经编译好的java class,则可以直接跳过这一步，直接到将java程序发布出去这一步 SQL> -- first, create the Java source code SQL> create or replace java source named \"Hello\" as      public class Hello {        static public String Message(String name) {           return \"Hello, \" + name;        }      }     / Java created. （2）发布java程序 SQL> -- Now, publish it to SQL SQL> create or replace function hello (name VARCHAR2) return VARCHAR2       as language java name      'Hello.Message (java.lang.String) return java.lang.String'; Function created. （3）使用发布的JAVA程序 SQL> -- Now, you can use the Java procedure from a SQL statement SQL> select hello('world!') from dual; HELLO('world!') --------------- Hello world! --- hello函数在8i中不支持中文，9i中支持。如： SQL> select hello('你好!') from dual; HELLO('你好!') ------------------ Hello, 你好!","title":"（转）Methods for Using Java in ORACLE"},{"content":"今天做了一个修改控制文件的练习，出现了一个错误，随手记下： 添加或者移动控制文件的时候出现如下警告： ORA-02095: specified  initialization  parameter  cannot  be  modified   解决：要么是权限不够，要用sys 的sysdba登录，要么是语法错误。典型的错误是 Alter system set control_files= ‘d:\\oracle\\product\\10.1.0\\oradata\\orcl\\control01.ctl’, scope=spfile; 就多了那一个逗号。   如果出现如下错误： ORA-00205:error  in  identifying   control  file ,check  alert  log  for  more  info 这个时候一般都是控制文件出现错误，查看告警日志D:\\oracle\\product\\10.1.0\\admin\\orcl\\bdump\\alert_orcl.log 会发现这样的话：   ALTER DATABASE   MOUNT Sat Apr 24 21:46:31 2010 ORA-00202: controlfile: 'G:\\CRONT\\CONTROL02.CTL' ORA-27041: unable to open file OSD-04002: unable to open file O/S-Error: (OS 2) 系统找不到指定的文件。   说明二号控制文件'G:\\CRONT\\CONTROL02.CTL 出现了错误，这时把数据库启动在nomount状态，把可用的控制文件拷贝到这个路径里一份，然后用alter  database  mount 和 alter  database  open 两条命令启动数据库。","title":"修改控制文件时的一个小错误"},{"content":"从前一直以为“replace into” 在sqlite3  中的功能和大型数据库中的语句“IF NOT EXISTS(SELECT * FROM Book WHERE ….) THEN INSERT INTO ... ELSE  UPDATE SET ...”(如果存在Id相同的，就把原来的数据更新；如果不存在Id相同的，那就增加一条新的记录)类似， 后来才发现时这种情况：新的数据字段中有和原来的数据相同的部分(有数据重叠的部分)，就把原来的数据删掉，再增加一条新的； 如果没有重叠相同的部分就直接增加一条新的记录。 “replace into”和\"insert or replace into\" 在Sqlite3 具有相同的功能。","title":"“replace into” 在Android 项目中应用的一点理解"},{"content":"  --%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   && 数据库报告 &&   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  conn /as sysdba -- 把文件输出到指定路径  spool c:\\output --（set echo on 把查询语句一概输出出来）  set line 150 -- 关闭每页头部显示  tti off -- 关闭每页底部显示  bti off  set pagesize 25 tti '***** 数据库版本 ******' --数据库版本：  select banner 数据库版本 from v$version; tti '***** 数据库相关信息 ******' --数据库名称、创建日期、读写模式、归档模式  select name 数据库名称,created 创建日期,log_mode 归档模式,open_mode 读写模式, platform_name 系统平台  from v$database; tti '***** 实例相关信息 ******' --实例数量、实例名称、实例状态  select instance_number 实例数量,instance_name 实例名称,host_name 主机名,status 实例状态 from v$instance; tti '*****数据库所使用的数据块的大小******' --查看数据库所使用的数据块的大小  show parameter block_size; tti '***** SGA分配情况 ******' --SGA分配情况(show sga 也可以）  select name 类别,round(value/1024/1024,2) 大小 from v$sga; tti '***** 日志文件 ******' --日志组数、组成员数及每组的大小  select group# 组号,members 成员数量,bytes/1024/1024 大小 from v$log order by 组号; --日志组、状态、在线情况、文件位置及名称  col 位置 for a70  select group# 组号,status 状态,type 在线情况,member 位置 from v$logfile order by 组号; tti '***** 控制文件 ******' --控制文件的数量、名称及存放路径  col 路径 for a70  select name 路径 from v$controlfile; tti '***** 临时文件 ******' --临时文件数量、状态、大小、名称及路径  select file# 文件号,status 状态,bytes/1024/1024 大小,name 路径 from v$tempfile; tti '***** 数据文件 ******' --数据文件号、名称及存放路径、文件所在表空间、大小及状态  col 文件名 for a65  col 表空间 for a15  col 文件号 for 999  select a.file_id 文件号,a.file_name 文件名,a.tablespace_name 表空间,a.bytes/1024/1024 大小, a.status 状态,b.status 联机,b.CREATION_TIME  from dba_data_files a,v$datafile b where a.file_name=b.name order by a.file_id; tti '***** 表空间 ******' --查看表空间的管理方式（本地管理还是数据字典管理），所属表空间是何种类型（系统表空间还是唯一表空间），段的的管理方式（自动增减还是手动管理）。  select tablespace_name 表空间,extent_management 段管理,allocation_type 表空间类型,segment_space_management 段空间管理 from dba_tablespaces; tti '***** 各个表空间使用情况 ******' --查询表空间大小及使用情况（已使用空间、剩余空间及剩余百分比）  select f.tablespace_name,a.total,a.total-f.free \"已使用（M）\",f.free \"剩余\",round((f.free/a.total)*100) \"剩余百分比\"  from (select tablespace_name,sum(bytes/1024/1024) total        from dba_data_files group by tablespace_name)a,       (select tablespace_name,round(sum(bytes/1024/1024)) free        from dba_free_space group by tablespace_name)f  where a.tablespace_name=f.tablespace_name(+) order by \"剩余百分比\"; --set echo off spool off       --%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   && Database Report &&   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%  conn /as sysdba -- Output file to somewhere  spool c:\\output  set line 150  tti off  bti off  set pagesize 25 tti '***** Database Version ******'  select banner AS DBVersion from v$version; tti '***** Database information ******'  select name DBName,created AS Createdate,log_mode AS ArchMode,open_mode RWMode,platform_name  from v$database; tti '***** Instance information ******'  select instance_number AS IstNum,instance_name AS InsName,host_name,status InsStatus from v$instance; tti '*****Database Block_size******'  show parameter block_size; tti '***** SGA Allot  ******'  select name Type,round(value/1024/1024,2) MB from v$sga; tti '***** Log Files ******'  select group# AS GroupNum,members AS GroupMem,bytes/1024/1024 MB from v$log order by GroupNum;  col Locate for a70  select group# AS GroupNum,status ,type ,member AS Locate from v$logfile order by GroupNum; tti '***** Control Files ******'  col Locate for a70  select name AS Locate from v$controlfile; tti '***** Temp Files ******'  select file#,status AS Status,bytes/1024/1024 MB,name Locate from v$tempfile; tti '***** Data File ******'  col FileName for a65  col TableSP for a15  col FileNum for 999  select a.file_id AS FileNum,a.file_name AS FileName,a.tablespace_name AS TableSP,a.bytes/1024/1024 MB,  a.status AS Status,b.status AS status ,b.CREATION_TIME  from dba_data_files a,v$datafile b where a.file_name=b.name order by a.file_id; tti '***** Tablespace ******'  select tablespace_name AS TName,extent_management AS SegMana,allocation_type AS TType,segment_space_management AS SegSMana from dba_tablespaces; tti '***** TUsed ******'  select f.tablespace_name,a.total \"total(M)\",a.total-f.free \"Used（M）\",f.free \"Leave(M)\",round((f.free/a.total)*100) \"Leave(%)\"  from (select tablespace_name,sum(bytes/1024/1024) total        from dba_data_files group by tablespace_name)a,       (select tablespace_name,round(sum(bytes/1024/1024)) free        from dba_free_space group by tablespace_name)f  where a.tablespace_name=f.tablespace_name(+) order by \"Leave(%)\"; --set echo off spool off  ","title":"数据库环境简易检测"},{"content":"项目需要连接SyBase数据，去网上找了点资料大致找到三种连接方式：        1.  ODBC方式：              a. 需要安装SyBase客户端，安装ODBC驱动。              b. 然后在控制面板->管理工具->数据源(ODBC)中选择系统DSN。然后添加在弹出的对话框中选择Sybase ASE ODBC Driver 驱动点击完成，弹出Sybase ODBC详细配置窗口。              c. 在Sybase ODBC详细配置窗口中输入Data Source Name 、.NETWork Address 、Database Name；其中Data Source Name这个是ODBC数据源名字自己随便起个连接字符串要用到，.NETWork Address 的格式为“Sybase数据库服务器的IP,端口号”，Database Name是你要访问的数据库名称。              d. .NET连接时使用连接串 如“Driver={Sybase System 11};Srvr=yourDataSourceName;database=yourDatabaseName;uid=yourUid;pwd=yourPwd;”。        2.  OLEDB方式：              a. 和ODBC方式类似，也需要安装SyBase客服端安装OLEDB驱动。              b. 进入Sybase Configuration Manager 中添加一个OLEDB数据源。输入Data Source Name、选择Sybase ASE OLEDB Provider 驱动。Data Source Name这个是连接串中Data Source要用的。              c. 在Sybase ASE OLEDB Provider 详细设置窗口配置Server Name、Database Name；Server Name 的格式为“Sybase数据库服务器的IP,端口号”，Database Name是你要访问的数据库名称。              d. .NET连接时使用连接串,如“Provider=Sybase.ASEOLEDBProvider.2;Data Source=yourDataSourceName;User ID=yourUid;Password=yourPwd;charset=eucgb; Server Name=SyBase数据库服务器IP; ”         3.  用Sybase.Data.AseClient连接：              此种连接方式为此次项目采用方式，主要优点是无需安装SyBase客户端,而且使用方便，              .NET连接SyBase数据首先需要下载三个DLL：Sybase.Data.AseClient.dll，sybdrvado11.dll，sybdrvssl.dll下载地址：http://download.csdn.net/detail/jallymn/4866144               把sybdrvado11.dll，sybdrvssl.dll拷贝到项目BIN文件夹下，              web.config中配置连接字符串： <add name=\"sybaseconn\" connectionString=\"Data Source=Sybase数据库服务器IP;port=5000;Initial Catalog=数据库名字;User ID=yourUid;Password=yourPwd\"/>              在项目中添加Sybase.Data.AseClient.dll的引用,然后在代码中： using Sybase.Data.AseClient;//数据库连接字符串(web.config来配置)public static string connectionString = System.Configuration.ConfigurationManager.ConnectionStrings[\"sybaseconn\"].ConnectionString.ToString();#region 执行SQL语句，通过影响的记录数判断是否成功public bool ExecuteSQL(string sql){      using (AseConnection conn = new AseConnection(connectionString))      {            using (AseCommand comm = new AseCommand(sql, conn))            {                try                {                    conn.Open();                    int rows = comm.ExecuteNonQuery();                    conn.Close();                    if (rows > 0)                        return true;                    else                        return false;                }                catch (Exception E)                {                    conn.Close();                    throw new Exception(E.Message);                }            }        }    }#endregion              至此小小测试下，连接查询什么的都ok，但是查询语句中如果有中文字符的时候查询老是查不到，让SyBase数据库组的同事帮忙看了下发现我传过去的中文字符在SyBase里都成了乱码。才发现.net连接SyBase数据库还有中文编码的问题。后发现项目中SyBase数据库用的字符集是“iso-8859-1”，于是拼接SQL语句时，把编码转化： strSql = System.Text.Encoding.GetEncoding(\"iso-8859-1\").GetString(System.Text.Encoding.GetEncoding(\"gbk\").GetBytes(strSql));              再次测试，查询OK，问题解决。        ","title":".NET连接SyBase数据库及中文乱码解决办法"},{"content":"（转载地址：http://www.oracle-base.com/articles/9i/consuming-web-services-9i.php）   Consuming Web Services in Oracle Over the last few years web services have increased in popularity to the point where most new application incorporate them to some degree. At the heart of web services is SOAP (Simple Object Access Protocol), a simple XML based protocol to let applications exchange information over HTTP. For more information about SOAP read theSOAP Tutorial. Oracle9i allows direct access to web services from PL/SQL using the UTL_HTTP package. In Oracle10g it will be possible to publish PL/SQL as web services directly from the database, rather than via Oracle9iAS as is currently the case. In this article I'll present a simple example of accessing a web service from PL/SQL. First the soap_api.sql code must be loaded into the database. The function below uses the SOAP_API package to access a web services from PL/SQL. The URL of the WDSL file describing the web service is shown here (http://www.oracle-base.com/webservices/server.php?wsdl). The web service accepts two number parameters and returns the sum of those values. CREATE OR REPLACE FUNCTION add_numbers (p_int_1  IN  NUMBER,                                        p_int_2  IN  NUMBER)  RETURN NUMBERAS  l_request   soap_api.t_request;  l_response  soap_api.t_response;  l_return    VARCHAR2(32767);    l_url          VARCHAR2(32767);  l_namespace    VARCHAR2(32767);  l_method       VARCHAR2(32767);  l_soap_action  VARCHAR2(32767);  l_result_name  VARCHAR2(32767);BEGIN  l_url         := 'http://www.oracle-base.com/webservices/server.php';  l_namespace   := 'xmlns=\"http://www.oracle-base.com/webservices/\"';  l_method      := 'ws_add';  l_soap_action := 'http://www.oracle-base.com/webservices/server.php/ws_add';  l_result_name := 'return';    l_request := soap_api.new_request(p_method       => l_method,                                    p_namespace    => l_namespace);  soap_api.add_parameter(p_request => l_request,                         p_name    => 'int1',                         p_type    => 'xsd:integer',                         p_value   => p_int_1);  soap_api.add_parameter(p_request => l_request,                         p_name    => 'int2',                         p_type    => 'xsd:integer',                         p_value   => p_int_2);  l_response := soap_api.invoke(p_request => l_request,                                p_url     => l_url,                                p_action  => l_soap_action);  l_return := soap_api.get_return_value(p_response  => l_response,                                        p_name      => l_result_name,                                        p_namespace => NULL);  RETURN l_return;END;/ The output below shows the function in action. SELECT add_numbers(1, 5) FROM dual;ADD_NUMBERS(1,5)----------------               6SQL>SELECT add_numbers(10, 15) FROM dual;ADD_NUMBERS(10,15)------------------                25SQL> For further information see: UTL_HTTP UTL_DBWS (10g) UTL_HTTP and SSL (HTTPS) using Oracle Wallets   soap_api.sql： CREATE OR REPLACE PACKAGE soap_api AS-- ---------------------------------------------------------------------------- Name         : http://www.oracle-base.com/dba/miscellaneous/soap_api-- Author       : Tim Hall-- Description  : SOAP related functions for consuming web services.-- Ammedments   :--   When         Who       What--   ===========  ========  =================================================--   04-OCT-2003  Tim Hall  Initial Creation--   23-FEB-2006  Tim Hall  Parameterized the \"soap\" envelope tags.--   25-MAY-2012  Tim Hall  Added debug switch.--   29-MAY-2012  Tim Hall  Allow parameters to have no type definition.--                          Change the default envelope tag to \"soap\".--                          add_complex_parameter: Include parameter XML manually.-- --------------------------------------------------------------------------TYPE t_request IS RECORD (  method        VARCHAR2(256),  namespace     VARCHAR2(256),  body          VARCHAR2(32767),  envelope_tag  VARCHAR2(30));TYPE t_response IS RECORD(  doc           XMLTYPE,  envelope_tag  VARCHAR2(30));FUNCTION new_request(p_method        IN  VARCHAR2,                     p_namespace     IN  VARCHAR2,                     p_envelope_tag  IN  VARCHAR2 DEFAULT 'soap')  RETURN t_request;PROCEDURE add_parameter(p_request  IN OUT NOCOPY  t_request,                        p_name     IN             VARCHAR2,                        p_value    IN             VARCHAR2,                        p_type     IN             VARCHAR2 := NULL);PROCEDURE add_complex_parameter(p_request  IN OUT NOCOPY  t_request,                                p_xml      IN             VARCHAR2);FUNCTION invoke(p_request  IN OUT NOCOPY  t_request,                p_url      IN             VARCHAR2,                p_action   IN             VARCHAR2)  RETURN t_response;FUNCTION get_return_value(p_response   IN OUT NOCOPY  t_response,                          p_name       IN             VARCHAR2,                          p_namespace  IN             VARCHAR2)  RETURN VARCHAR2;PROCEDURE debug_on;PROCEDURE debug_off;END soap_api;/SHOW ERRORSCREATE OR REPLACE PACKAGE BODY soap_api AS-- ---------------------------------------------------------------------------- Name         : http://www.oracle-base.com/dba/miscellaneous/soap_api-- Author       : Tim Hall-- Description  : SOAP related functions for consuming web services.-- Ammedments   :--   When         Who       What--   ===========  ========  =================================================--   04-OCT-2003  Tim Hall  Initial Creation--   23-FEB-2006  Tim Hall  Parameterized the \"soap\" envelope tags.--   25-MAY-2012  Tim Hall  Added debug switch.--   29-MAY-2012  Tim Hall  Allow parameters to have no type definition.--                          Change the default envelope tag to \"soap\".--                          add_complex_parameter: Include parameter XML manually.-- --------------------------------------------------------------------------g_debug  BOOLEAN := FALSE;PROCEDURE show_envelope(p_env     IN  VARCHAR2,                        p_heading IN  VARCHAR2 DEFAULT NULL);-- ---------------------------------------------------------------------FUNCTION new_request(p_method        IN  VARCHAR2,                     p_namespace     IN  VARCHAR2,                     p_envelope_tag  IN  VARCHAR2 DEFAULT 'soap')  RETURN t_request AS-- ---------------------------------------------------------------------  l_request  t_request;BEGIN  l_request.method       := p_method;  l_request.namespace    := p_namespace;  l_request.envelope_tag := p_envelope_tag;  RETURN l_request;END;-- ----------------------------------------------------------------------- ---------------------------------------------------------------------PROCEDURE add_parameter(p_request  IN OUT NOCOPY  t_request,                        p_name     IN             VARCHAR2,                        p_value    IN             VARCHAR2,                        p_type     IN             VARCHAR2 := NULL) AS-- ---------------------------------------------------------------------BEGIN  IF p_type IS NULL THEN    p_request.body := p_request.body||'<'||p_name||'>'||p_value||'<\/'||p_name||'>';  ELSE    p_request.body := p_request.body||'<'||p_name||' xsi:type=\"'||p_type||'\">'||p_value||'<\/'||p_name||'>';  END IF;END;-- ----------------------------------------------------------------------- ---------------------------------------------------------------------PROCEDURE add_complex_parameter(p_request  IN OUT NOCOPY  t_request,                                p_xml      IN             VARCHAR2) AS-- ---------------------------------------------------------------------BEGIN  p_request.body := p_request.body||p_xml;END;-- ----------------------------------------------------------------------- ---------------------------------------------------------------------PROCEDURE generate_envelope(p_request  IN OUT NOCOPY  t_request,\t\t                        p_env      IN OUT NOCOPY  VARCHAR2) AS-- ---------------------------------------------------------------------BEGIN  p_env := '<'||p_request.envelope_tag||':Envelope xmlns:'||p_request.envelope_tag||'=\"http://schemas.xmlsoap.org/soap/envelope/\" ' ||               'xmlns:xsi=\"http://www.w3.org/1999/XMLSchema-instance\" xmlns:xsd=\"http://www.w3.org/1999/XMLSchema\">' ||             '<'||p_request.envelope_tag||':Body>' ||               '<'||p_request.method||' '||p_request.namespace||' '||p_request.envelope_tag||':encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\">' ||                   p_request.body ||               '<\/'||p_request.method||'>' ||             '<\/'||p_request.envelope_tag||':Body>' ||           '<\/'||p_request.envelope_tag||':Envelope>';END;-- ----------------------------------------------------------------------- ---------------------------------------------------------------------PROCEDURE show_envelope(p_env     IN  VARCHAR2,                        p_heading IN  VARCHAR2 DEFAULT NULL) AS-- ---------------------------------------------------------------------  i      PLS_INTEGER;  l_len  PLS_INTEGER;BEGIN  IF g_debug THEN    IF p_heading IS NOT NULL THEN      DBMS_OUTPUT.put_line('*****' || p_heading || '*****');    END IF;    i := 1; l_len := LENGTH(p_env);    WHILE (i <= l_len) LOOP      DBMS_OUTPUT.put_line(SUBSTR(p_env, i, 60));      i := i + 60;    END LOOP;  END IF;END;-- ----------------------------------------------------------------------- ---------------------------------------------------------------------PROCEDURE check_fault(p_response IN OUT NOCOPY  t_response) AS-- ---------------------------------------------------------------------  l_fault_node    XMLTYPE;  l_fault_code    VARCHAR2(256);  l_fault_string  VARCHAR2(32767);BEGIN  l_fault_node := p_response.doc.extract('/'||p_response.envelope_tag||':Fault',                                         'xmlns:'||p_response.envelope_tag||'=\"http://schemas.xmlsoap.org/soap/envelope/');  IF (l_fault_node IS NOT NULL) THEN    l_fault_code   := l_fault_node.extract('/'||p_response.envelope_tag||':Fault/faultcode/child::text()',                                           'xmlns:'||p_response.envelope_tag||'=\"http://schemas.xmlsoap.org/soap/envelope/').getstringval();    l_fault_string := l_fault_node.extract('/'||p_response.envelope_tag||':Fault/faultstring/child::text()',                                           'xmlns:'||p_response.envelope_tag||'=\"http://schemas.xmlsoap.org/soap/envelope/').getstringval();    RAISE_APPLICATION_ERROR(-20000, l_fault_code || ' - ' || l_fault_string);  END IF;END;-- ----------------------------------------------------------------------- ---------------------------------------------------------------------FUNCTION invoke(p_request IN OUT NOCOPY  t_request,                p_url     IN             VARCHAR2,                p_action  IN             VARCHAR2)  RETURN t_response AS-- ---------------------------------------------------------------------  l_envelope       VARCHAR2(32767);  l_http_request   UTL_HTTP.req;  l_http_response  UTL_HTTP.resp;  l_response       t_response;BEGIN  generate_envelope(p_request, l_envelope);  show_envelope(l_envelope, 'Request');  l_http_request := UTL_HTTP.begin_request(p_url, 'POST','HTTP/1.1');  UTL_HTTP.set_header(l_http_request, 'Content-Type', 'text/xml');  UTL_HTTP.set_header(l_http_request, 'Content-Length', LENGTH(l_envelope));  UTL_HTTP.set_header(l_http_request, 'SOAPAction', p_action);  UTL_HTTP.write_text(l_http_request, l_envelope);  l_http_response := UTL_HTTP.get_response(l_http_request);  UTL_HTTP.read_text(l_http_response, l_envelope);  UTL_HTTP.end_response(l_http_response);  show_envelope(l_envelope, 'Response');  l_response.doc := XMLTYPE.createxml(l_envelope);  l_response.envelope_tag := p_request.envelope_tag;  l_response.doc := l_response.doc.extract('/'||l_response.envelope_tag||':Envelope/'||l_response.envelope_tag||':Body/child::node()',                                           'xmlns:'||l_response.envelope_tag||'=\"http://schemas.xmlsoap.org/soap/envelope/\"');  check_fault(l_response);  RETURN l_response;END;-- ----------------------------------------------------------------------- ---------------------------------------------------------------------FUNCTION get_return_value(p_response   IN OUT NOCOPY  t_response,                          p_name       IN             VARCHAR2,                          p_namespace  IN             VARCHAR2)  RETURN VARCHAR2 AS-- ---------------------------------------------------------------------BEGIN  RETURN p_response.doc.extract('//'||p_name||'/child::text()',p_namespace).getstringval();END;-- ----------------------------------------------------------------------- ---------------------------------------------------------------------PROCEDURE debug_on AS-- ---------------------------------------------------------------------BEGIN  g_debug := TRUE;END;-- ----------------------------------------------------------------------- ---------------------------------------------------------------------PROCEDURE debug_off AS-- ---------------------------------------------------------------------BEGIN  g_debug := FALSE;END;-- ---------------------------------------------------------------------END soap_api;/SHOW ERRORS   WDSL file： <?xml version=\"1.0\" encoding=\"ISO-8859-1\"?>-<definitions targetNamespace=\"http://www.oracle-base.com/webservices/\" xmlns=\"http://schemas.xmlsoap.org/wsdl/\" xmlns:wsdl=\"http://schemas.xmlsoap.org/wsdl/\" xmlns:soap=\"http://schemas.xmlsoap.org/wsdl/soap/\" xmlns:tns=\"http://www.oracle-base.com/webservices/\" xmlns:SOAP-ENC=\"http://schemas.xmlsoap.org/soap/encoding/\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:SOAP-ENV=\"http://schemas.xmlsoap.org/soap/envelope/\"> -<types> -<xsd:schema targetNamespace=\"http://www.oracle-base.com/webservices/\"> <xsd:import namespace=\"http://schemas.xmlsoap.org/soap/encoding/\"/> <xsd:import namespace=\"http://schemas.xmlsoap.org/wsdl/\"/> <\/xsd:schema> <\/types> -<message name=\"ws_addRequest\"> <part name=\"int1\" type=\"xsd:string\"/> <part name=\"int2\" type=\"xsd:string\"/><\/message> -<message name=\"ws_addResponse\"> <part name=\"return\" type=\"xsd:string\"/><\/message> -<portType name=\"CalculatorPortType\"> -<operation name=\"ws_add\"> <input message=\"tns:ws_addRequest\"/> <output message=\"tns:ws_addResponse\"/> <\/operation> <\/portType> -<binding name=\"CalculatorBinding\" type=\"tns:CalculatorPortType\"> <soap:binding transport=\"http://schemas.xmlsoap.org/soap/http\" style=\"rpc\"/> -<operation name=\"ws_add\"> <soap:operation style=\"rpc\" soapAction=\"http://oracle-base.com/webservices/server.php/ws_add\"/> -<input><soap:body namespace=\"http://www.oracle-base.com/webservices/\" encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\" use=\"encoded\"/><\/input> -<output><soap:body namespace=\"http://www.oracle-base.com/webservices/\" encodingStyle=\"http://schemas.xmlsoap.org/soap/encoding/\" use=\"encoded\"/><\/output> <\/operation> <\/binding> -<service name=\"Calculator\"> -<port name=\"CalculatorPort\" binding=\"tns:CalculatorBinding\"> <soap:address location=\"http://oracle-base.com/webservices/server.php\"/> <\/port> <\/service> <\/definitions>    ","title":"（转）Consuming Web Services in Oracle"},{"content":"一、控制文件的定位 启动到nomount状态后，Oracle就可以从参数文件中获得控制文件的位置信息，并根据控制文件中记录的数据文件位置进行数据文件的存在性判断。 在nomount状态，可以查询v$parameter视图，获得控制文件，这部分信息来自启动的参数文件； SQL> select * from v$controlfile;no rows selectedSQL> show parameter control_filesNAME\t\t\t\t     TYPE\t VALUE------------------------------------ ----------- ------------------------------control_files\t\t\t     string\t /home/oracle/app/oracle/oradat\t\t\t\t\t\t a/orcl/control01.ctl, /home/or\t\t\t\t\t\t acle/app/oracle/flash_recovery\t\t\t\t\t\t _area/orcl/control02.ctl当数据库mount之后，可以查询v$controlfile视图获得关于控制文件的信息，此时，这部分信息来自控制文件： SQL> alter database mount;Database altered.SQL> select STATUS, NAME from v$controlfile;STATUS    NAME--------- --------------------------------------------------------------          /home/oracle/app/oracle/oradata/orcl/control01.ctl          /home/oracle/app/oracle/flash_recovery_area/orcl/control02.ctl在mount数据库的过程中，Oracle需要找到控制文件，锁定控制文件。Oracle的3个控制文件内容完全相同，丢失了其中一个可以通过复制来回复丢失的控制文件；如果丢失了所有控制文件，就需要恢复或重建控制文件来打开数据库。 二、数据文件的存在性判断 当mount数据库后，后台进程就可以根据控制文件中记录的数据文件信息来验证数据文件是否存在。 SQL> select name from v$datafile;NAME--------------------------------------------------------------------------------/home/oracle/app/oracle/oradata/orcl/system01.dbf/home/oracle/app/oracle/oradata/orcl/sysaux01.dbf/home/oracle/app/oracle/oradata/orcl/undotbs01.dbf/home/oracle/app/oracle/oradata/orcl/users01.dbf/home/oracle/app/oracle/oradata/orcl/example01.dbf 三、控制文件的HeartBeat 在mount数据库的过程中，数据库需要计算mount id并将其记录在控制文件中，然后启动心跳（HeartBeat），每3秒更新一次控制文件。控制文件在mount状态下发生改变的只有这个HeartBeat。 HeartBeat值可以从一个内部表X$kCCCP中查到： SQL> select cphbt from X$KCCCP;     CPHBT---------- 801632556Oracle在数据库内部通过等待时间control file heartbeat来记录这个事件的相关等待；如果使用自动存储管理技术，那么还会增加一个ASM实例的心跳事件。 SQL> select event#, name  2  from v$event_name where name like '%heart%';    EVENT# NAME---------- ----------------------------------------------------------------\t75 heartbeat monitor sleep       380 ASM mount : wait for heartbeat       563 control file heartbeat 四、口令文件的作用 数据库的口令文件位于$ORACLE_HOME/dbs目录下，缺省的名称为orapw<ORACLE_SID>。口令文件中存放SYSDBA/SYSOPER用户的用户名及口令。 对于口令文件，Oracle缺省查找orapw<ORACLE_SID>文件，如果该文件不存在，则继续查找orapw文件。 如果口令文件丢失，可以通过orapw工具即可重建，所以备份时可以不包含口令文件： SQL> !orapwdUsage: orapwd file=<fname> entries=<users> force=<y/n> ignorecase=<y/n> nosysdba=<y/n>  where    file - name of password file (required),    password - password for SYS will be prompted if not specified at command line,    entries - maximum number of distinct DBA (optional),    force - whether to overwrite existing file (optional),    ignorecase - passwords are case-insensitive (optional),    nosysdba - whether to shut out the SYSDBA logon (optional Database Vault only).      There must be no spaces around the equal-to (=) character.启动过程中如果口令文件丢失，和口令文件相关的部分功能将无法使用，比如进行SYSDBA的授权或者尝试远程通过SYSDBA身份登录都会出现错误。 数据库例具有SYSDBA/SYSOPER权限的用户可以通过v$pwfile_users视图查询得到： SQL> select * from v$pwfile_users;USERNAME\t\t       SYSDB SYSOP SYSAS------------------------------ ----- ----- -----SYS\t\t\t       TRUE  TRUE  FALSE 五、lk<ORACLE_SID>文件及作用 存在于$ORACLE_HOME/dbs目录下，该文件在数据库启动时创建，用于操作系统对数据库的锁定。当数据库启动时获得锁定，数据库关闭时释放。 在Oracle 10g中Oracle引入了db_unique_name参数。如果想在同一台机器上mount相同DB_NAME的数据库需要修改此参数。 SQL> show parameter db_unique_name;NAME\t\t\t\t     TYPE\t VALUE------------------------------------ ----------- ------------------------------db_unique_name\t\t\t     string\t orcl","title":"ORACLE学习笔记（二）——数据库启动（mount）"},{"content":"/********************************************************************************* *函数名称:f_reg_db *参数列表:无 *返回值:0-失败,1-成功 *作者:李永结 *函数功能:注册数据库(sybase anywhere) *创建时间:2011/10/03 *说明:需要文件:dbodbc9.dll,dbeng9.exe *********************************************************************************/ string ls_dbfile,ls_driver string ls_dbodbc_dll,ls_dbeng_dll string ls_db_path,ls_db_name,ls_ds_name String ls_start string ls_location long ll_rtn string ls_dbms //设置数据库路径及文件名 ls_db_path = gs_rootpath +\"\\modeldb.db\"  //设置数据库名称 ls_db_name = \"modeldb\"  //设置ODBC数据源名称 ls_ds_name = \"modeldb\" //如果连接数据库方式不是ODBC,则不需要注册数据库 ls_dbms = trim(profilestring(\"system.ini\",\"database\",\"DBMS\",\"ODBC\")) if upper(ls_dbms) <> \"ODBC\" then f_log(\"连接数据库方式不是ODBC,不需注册数据库\") return 1 end if //检查数据库是否已经注册 ll_rtn=RegistryGet(\"HKEY_current_user\\Software\\ODBC\\ODBC.INI\\ODBC Data Sources\",\"modeldb\",RegString!,ls_driver) IF ll_rtn=1 THEN f_log(ls_db_name+\"数据库已经注册\") RETURN 2 ELSE f_log(ls_db_name+\"数据库没有注册,准备注册\") END IF ll_rtn = RegistryGet(\"HKEY_LOCAL_MACHINE\\Software\\ODBC\\ODBCINST.INI\\Adaptive Server Anywhere 9.0\",\"Driver\", RegString!, ls_driver) if ll_rtn =  1 then f_log(\"已经设置好ODBC驱动\") else f_log(\"ODBC驱动没有设置\") end if ll_rtn = RegistryGet(\"HKEY_LOCAL_MACHINE\\SOFTWARE\\ODBC\\ODBC.INI\\modeldb\",\"DatabaseFile\", RegString!, ls_dbfile) if ll_rtn =  1 then f_log(\"已经设置好数据文件\") else f_log(\"数据文件没有设置\") end if IF right(ls_driver,11) = 'dbodbc9.dll' and right(ls_dbfile,10) = 'modeldb.db' THEN  IF FileExists(ls_driver) And FileExists(ls_dbfile) THEN //MessageBox(\"^_^\",\"已经设置好数据源\") f_log(\"已经设置好数据源\") RETURN 1 ELSE f_log(\"没有驱动文件或数据文件\") return -1 END IF END IF //获得该应用的目录 ls_location = gs_rootpath + \"\\\"  ls_dbodbc_dll = ls_location + \"dbodbc9.dll\" ls_dbeng_dll = ls_location + \"dbeng9.exe\" IF Not FileExists(ls_dbodbc_dll) And Not FileExists(ls_dbeng_dll) THEN f_logbox(\"系统中没有数据库驱动引擎和动态链接库！系统将终止运行!\") RETURN -1 END IF ll_rtn = RegistrySet(\"HKEY_LOCAL_MACHINE\\Software\\ODBC\\ODBCINST.INI\\ODBC Drivers\",\"Adaptive Server Anywhere 9.0\",RegString!,\"Installed\") IF ll_rtn = -1 THEN f_logbox(\"系统设置Adaptive Server Anywhere 9的驱动出现错误\") RETURN -1 END IF //设置ODBC\\ODBCINST.INI /* ll_rtn = RegistrySet(\"HKEY_LOCAL_MACHINE\\Software\\ODBC\\ODBCINST.INI\\Adaptive Server Anywhere 9.0\",\"CPTimeout\",RegString!,\"not pooled\") IF ll_rtn = -1 THEN f_logbox(\"系统设置注册表ODBC\\ODBCINST错误!系统将终止运行!\") RETURN -1 END IF ll_rtn = RegistrySet(\"HKEY_LOCAL_MACHINE\\Software\\ODBC\\ODBCINST.INI\\Adaptive Server Anywhere 9.0\",\"Driver\",RegString!,ls_driver) IF ll_rtn = -1 THEN f_logbox(\"系统设置注册表ODBC\\ODBCINST错误!系统将终止运行!\") RETURN -1 END IF ll_rtn = RegistrySet(\"HKEY_LOCAL_MACHINE\\Software\\ODBC\\ODBCINST.INI\\Adaptive Server Anywhere 9.0\",\"Setup\",RegString!,ls_driver) IF ll_rtn = -1 THEN f_logbox(\"系统设置注册表ODBC\\ODBCINST错误!系统将终止运行!\") RETURN -1 END IF ll_rtn = RegistrySet(\"HKEY_CURRENT_USER\\Software\\ODBC\\ODBCINST.INI\\ODBC Data Sources\",ls_ds_name,RegString!,\"Adaptiver Server Anywhere 9.0\") IF ll_rtn = -1 THEN f_logbox(\"系统设置ODBC数据源错误!系统将终止运行!\") RETURN -1 END IF */ //设置ODBC.INI的细节 ll_rtn = RegistrySet(\"HKEY_LOCAL_MACHINE\\Software\\ODBC\\ODBC.ini\\\" + ls_ds_name,\"Driver\",RegString!,ls_driver) IF ll_rtn = -1 THEN f_logbox(\"系统设置 ODBC\\ODBC.INI\\\" + ls_ds_name + \"\\Driver 错误!系统将终止运行!\") RETURN -1 ELSE f_log(\"设置 ODBC\\ODBC.INI\\\" + ls_ds_name + \"\\Driver ok\") END IF ls_start = gs_rootpath + \"\\dbeng9.exe -d -Q -c200m\" ll_rtn = RegistrySet(\"HKEY_LOCAL_MACHINE\\Software\\ODBC\\ODBC.ini\\\" + ls_ds_name,\"start\",RegString!,ls_start) IF ll_rtn = -1 THEN f_logbox(\"系统设置 ODBC\\ODBC.INI\\\" + ls_ds_name + \"\\start 错误!系统将终止运行!\") RETURN -1 END IF ll_rtn = RegistrySet(\"HKEY_LOCAL_MACHINE\\Software\\ODBC\\ODBC.INI\\\" + ls_ds_name,\"AutoStop\",RegString!,\"yes\") IF ll_rtn = -1 THEN f_logbox(\"系统设置 ODBC\\ODBC.INI\\\" + ls_ds_name + \"\\autostop 错误!系统将终止运行!\") RETURN -1 END IF ll_rtn = RegistrySet(\"HKEY_LOCAL_MACHINE\\Software\\ODBC\\ODBC.INI\\\" + ls_ds_name,\"DatabaseFile\",RegString!,ls_db_path) IF ll_rtn = -1 THEN f_logbox(\"系统设置 ODBC\\ODBC.INI\\\" + ls_ds_name + \"\\DataBaseFile 错误!系统将终止运行!\") RETURN -1 END IF ll_rtn = RegistrySet(\"HKEY_LOCAL_MACHINE\\Software\\ODBC\\ODBC.INI\\\" + ls_ds_name,\"DatabaseName\",RegString!,ls_db_name) IF ll_rtn = -1 THEN f_logbox(\"系统设置 ODBC\\ODBC.INI\\\" + ls_ds_name + \"\\DataBaseName 错误!系统将终止运行!\") RETURN -1 END IF ll_rtn = RegistrySet(\"HKEY_LOCAL_MACHINE\\Software\\ODBC\\ODBC.INI\\\" + ls_ds_name,\"UID\",RegString!,\"DBA\") IF ll_rtn = -1 THEN f_logbox(\"系统设置 ODBC\\ODBC.INI\\\" + ls_ds_name + \"\\UID 错误!系统将终止运行!\") RETURN -1 END IF ll_rtn = RegistrySet(\"HKEY_LOCAL_MACHINE\\Software\\ODBC\\ODBC.INI\\\" + ls_ds_name,\"PWD\",RegString!,\"SQL\") IF ll_rtn = -1 THEN f_logbox(\"系统设置 ODBC\\ODBC.INI\\\" + ls_ds_name + \"\\PWD 错误!系统将终止运行!\") RETURN -1 END IF //ll_rtn = RegistrySet(\"HKEY_LOCAL_MACHINE\\Software\\ODBC\\ODBC.INI\\\" + ls_ds_name,\"EncryptedPassword\",RegString!,\"22f4c70a26ceba1afda291a1fda9\") //IF ll_rtn = -1 THEN // f_logbox(\"系统设置 ODBC\\ODBC.INI\\\" + ls_ds_name + \"\\EncryptedPassword 错误!系统将终止运行!\") // RETURN -1 //END IF ll_rtn = RegistrySet(\"HKEY_LOCAL_MACHINE\\Software\\ODBC\\ODBC.INI\\\" + ls_ds_name,\"EngineName\",RegString!,ls_ds_name) IF ll_rtn = -1 THEN f_logbox(\"系统设置 ODBC\\ODBC.INI\\\" + ls_ds_name + \"\\EngineName 错误!系统将终止运行!\") RETURN -1 END IF //ll_rtn = RegistrySet(\"HKEY_LOCAL_MACHINE\\Software\\ODBC\\ODBC.INI\\\" + ls_ds_name,\"Compress\",RegString!,\"YES\") //IF ll_rtn = -1 THEN // f_logbox(\"系统设置 ODBC\\ODBC.INI\\\" + ls_ds_name + \"\\Compress 错误!系统将终止运行!\") // RETURN -1 //END IF ll_rtn = RegistrySet(\"HKEY_LOCAL_MACHINE\\Software\\ODBC\\ODBC.INI\\\" + ls_ds_name,\"Integrated\",RegString!,\"No\") IF ll_rtn = -1 THEN f_logbox(\"系统设置 ODBC\\ODBC.INI\\\" + ls_ds_name + \"\\Compress 错误!系统将终止运行!\") RETURN -1 END IF f_log(ls_db_name + \"数据库注册完成\") RETURN 1","title":"PB连接sybase anywhere数据库"},{"content":"（转载地址：http://www.itpub.net/thread-399905-1-1.html）   有个需求，需要把oracle 数据库中表的数据，变化的结果反馈到消息服务器中。 这里的消息服务器用的是active mq。 考虑到可以使用oracle java存储过程实现这个功能。 经过一番辛苦。主要在破机器上折腾点了半天。 java 对内存的要求还是比较高的。 具体步骤如下： java函数或存储过程创建过程 调整数据库初始化参数:   *.java_max_sessionspace_size   =2073741824 *.java_soft_sessionspace_limit =104857600 *.java_pool_size=312m *.utl_file_dir=* 环境变量: $JAVA_HOME--must be set to the top directory of the installed JDK base $PATH--requires $JAVA_HOME/bin $LD_LIBRARY_PATH for Solaris must include $JAVA_HOME/lib $CLASSPATH  must include $JAVA_HOME/lib 示例: PATH=$ORACLE_HOME/jdk/bin:$ORACLE_HOME/bin:/bin:/usr/bin:/usr/ucb:/etc:/usr/openwin/bin:/usr/ccs/bin;export PATH JAVA_HOME=$ORACLE_HOME/jdk;export JAVA_HOME LD_LIBRARY_PATH=$JAVA_HOME/lib;export LD_LIBRARY_PATH CLASSPATH=$JAVA_HOME/lib;export CLASSPATH java -version 看看jdk 的版本. 我这里用的必须是1.4. 创建用户: 新建立用户UJAVA UJAVA 用户需要单独的表空间. 授权: 以sys用户授权 execute dbms_java.grant_permission( 'UJAVA', 'SYSracle.aurora.security.JServerPermission', 'Verifier', '' ); execute dbms_java.grant_permission( 'UJAVA', 'SYS:java.net.SocketPermission', '172.18.10.116:61616', 'accept, connect, listen, resolve' ); 具体授权根据情况而定. 上面的授权语句都是在loadjava 和后来执行中总结出来的. 注:如果,出现权限问题,就把下面的脚本全部执行. execute dbms_java.grant_permission('UJAVA','java.util.PropertyPermission','*','*'); execute dbms_java.grant_permission('UJAVA','java.io.SerializablePermission','*','*'); execute dbms_java.grant_permission('UJAVA','java.io.FilePermission','*','*'); execute dbms_java.grant_permission('UJAVA','java.net.NetPermission','*','*'); execute dbms_java.grant_permission('UJAVA','java.net.SocketPermission','*','*'); execute dbms_java.grant_permission('UJAVA','java.lang.RuntimePermission','*','*'); execute dbms_java.grant_permission('UJAVA','java.lang.reflect.ReflectPermission','*','*'); execute dbms_java.grant_permission('UJAVA','java.security.SecurityPermission','*','*'); execute dbms_java.grant_permission('UJAVA','oracle.aurora.rdbms.security.PolicyTablePermission','*','*'); execute dbms_java.grant_permission('UJAVA','oracle.aurora.security.JServerPermission','*','*'); 加载jar包到数据库: 所有这些jar包用ftp binary方式提供。 loadjava -u ujava/ujava@tsolaris -v  -o -noverify  -f jdom.jar     commons-logging-1.0.3.jar    commons-cli-1.0.jar  commons-configuration-1.0-dev.jar    geronimo-spec-jms-1.1-rc4.jar        geronimo-spec-j2ee-management-1.0-rc4.jar    concurrent-1.3.4.jar activemq-core-3.0.jar        log4j-1.2.8.jar      jce1_2_1.jar         jakarta-regexp-1.3.jar       servlet.jar  activeio-1.0.jar     geronimo-spec-j2ee-jacc-1.0-rc4.jar  geronimo-spec-jta-1.0.1B-rc4.jar     spring-1.1.jar       jmssyn.jar   loadjava -u ujava/ujava@tsolaris -v  -o -noverify  -r jdom.jar     commons-logging-1.0.3.jar    commons-cli-1.0.jar  commons-configuration-1.0-dev.jar    geronimo-spec-jms-1.1-rc4.jar        geronimo-spec-j2ee-management-1.0-rc4.jar    concurrent-1.3.4.jar activemq-core-3.0.jar        log4j-1.2.8.jar      jce1_2_1.jar         jakarta-regexp-1.3.jar       servlet.jar  activeio-1.0.jar     geronimo-spec-j2ee-jacc-1.0-rc4.jar  geronimo-spec-jta-1.0.1B-rc4.jar     spring-1.1.jar       jmssyn.jar   编译无效的对象: Select 'alter java class   \"'||dbms_java.longname (object_name)||'\" resolve;' from user_objects    where object_type = 'JAVA CLASS' and status = 'INVALID';    该语句的执行结果反复执行,直到剩下的无效的对象不能在编译成功为止. 可以从试图user_errors查询编译错误. 创建java类: 见dataprocess.jsp脚本. #这个文件不方便提供了。 该脚本需要在pl/sql develop 的java source窗口中执行. 创建调用java类的函数或存储过程: CREATE OR REPLACE Function test_java(Name Varchar2) Return Varchar2 AS LANGUAGE Java NAME ' DataProcess.deal(java.lang.String  )  return  java.lang.String'; 使用java函数: set serveroutput on size 5000; execute dbms_java.set_output(2000); 这个命令用于调试java存储过程 在$ORACLE_BASE/admin/$ORACLE_SID/dump目录中会出现trc文件. ALTER SESSION SET EVENTS '10046 trace name context forever, level 4'; 不知道java在数据库如何调试，只好如此了。 select test_java('y') from dual;  ","title":"（转）java 存储过程或函数开发(总结)"},{"content":"最近又重新安装了oracle10g ，又碰见这个错误，想起来好像每次安装10g都会遇到这样的问题，随手记下，方便下次查阅。 正常情况下，在sqlplus下一切正常，但是通过jar包驱动访问数据库报ora-12505错误。那么下面的解决方案往往有效： 找到listener.ora文件：我的Oracle是安装在D盘，路径为：D:\\oracle\\product\\10.2.0\\db_1\\network\\admin\\listener.ora 修改前的配置如下：# listener.ora Network Configuration File: D:\\oracle\\product\\10.2.0\\db_1\\network\\admin\\listener.ora # Generated by Oracle configuration tools. SID_LIST_LISTENER =   (SID_LIST =     (SID_DESC =       (SID_NAME = PLSExtProc)       (ORACLE_HOME = D:\\oracle\\product\\10.2.0\\db_1)       (PROGRAM = extproc)     )   ) LISTENER =   (DESCRIPTION_LIST =     (DESCRIPTION =       (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1))       (ADDRESS = (PROTOCOL = TCP)(HOST = 127.0.0.1)(PORT = 1521))     ) ) 修改后的配置如下： # listener.ora Network Configuration File: D:\\oracle\\product\\10.2.0\\db_1\\network\\admin\\listener.ora # Generated by Oracle configuration tools. SID_LIST_LISTENER =   (SID_LIST =     (SID_DESC =       (SID_NAME = PLSExtProc)       (ORACLE_HOME = D:\\oracle\\product\\10.2.0\\db_1)       (PROGRAM = extproc)     )     (SID_DESC =              (GLOBAL_DBNAME = ORCL)        (ORACLE_HOME = D:\\oracle\\product\\10.2.0\\db_1)        (SID_NAME = ORCL)       ) ) LISTENER =   (DESCRIPTION_LIST =     (DESCRIPTION =       (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1))       (ADDRESS = (PROTOCOL = TCP)(HOST = 127.0.0.1)(PORT = 1521))     )   ) 红色部分为增加的内容，个人建议绿色部分写成localhost或者127.0.0.1，而不是计算机名称——默认是计算机名称。 重启监听器","title":"oracle10g下ora-12505_错误解决方案"},{"content":"被忽略的Spring3小改进——支持多数据源的@Transactional事务注解 [问题] 近日，有同事问起，有个项目在配置Spring事务时，使用了@Transactional注解，但这个项目使用了多个数据源，而事务注解只对第一个起作用，咋办？   [探幽] 一听之下，想起在用@Transactional配置事务时，确实没注意过多数据源问题，但是记得之前常用的XML配置方式中，对多数据源支持很简单，我想注解配置起来应该也不会太麻烦。   先回顾一下之前个人习惯使用的 <tx:advice> + <aop:config>配置方式，大致步骤如下： 1）定义与事务管理器对应的事务通知 2）配置需要拦截的方法调用切面 3）将切入点连接到相应的事务通知 整个系统的事务，三下配置，一处搞定，相比注解方式，个人觉得更简单、省力、统一；而要支持多数据源，再做一遍这123即可，非常简单。   不过同事在网上百度了一圈，说大部分的结论是Spring的@Transactional注解不支持，听到这一点我很诧异，不应该啊，要不查查Spring的官方文档？ 一查马上发现，在Spring3.0的参考文档中，针对这个问题的，真新增了一节（10.5.6.2）来解决，参见： （http://static.springsource.org/spring/docs/3.0.x/spring-framework-reference/html/transaction.html#transaction-declarative-annotations ） Most Spring applications only need a single transaction manager, but there may be situations where you want multiple independent transaction managers in a single application. The value attribute of the @Transactional annotation can be used to optionally specify the identity of the PlatformTransactionManager to be used. This can either be the bean name or the qualifier value of the transaction manager bean   也就是说，在Spring2.5之前，@Transactional注解确实不支持多数据源，但是Spring3为其增加了value属性配置，可以指定当前事务通知对应的事务管理器。   检查了一下Spring的changelogs，这个特性是在3.0M4版中加入的： @Transactional supports qualifier value for choosing between multiple transaction managers [解难] 看来，或许这是一个有用的小改进，但很可能被大家忽略了。下面是从官方文档中摘抄出来的示例配置方式，供需要的同学参考： 1、配置事务注解驱动、每个数据源对应的事务管理器，并定义“限定符” Xml代码   <tx:annotation-driven/>      <bean id=\"transactionManager1\" class=\"org.springframework.jdbc.DataSourceTransactionManager\">   ...    <qualifier value=\"order\"/>   <\/bean>   <bean id=\"transactionManager2\" class=\"org.springframework.jdbc.DataSourceTransactionManager\">   ...    <qualifier value=\"account\"/>   <\/bean>    <tx:annotation-driven/><bean id=\"transactionManager1\" class=\"org.springframework.jdbc.DataSourceTransactionManager\">...<qualifier value=\"order\"/><\/bean><bean id=\"transactionManager2\" class=\"org.springframework.jdbc.DataSourceTransactionManager\">...<qualifier value=\"account\"/><\/bean>   2、在需要事务的地方，指定“限定符”     Java代码   public class TransactionalService {       @Transactional(\"order\")    public void setSomething(String name) { ... }       @Transactional(\"account\")    public void doSomething() { ... }    }   public class TransactionalService {@Transactional(\"order\")public void setSomething(String name) { ... }@Transactional(\"account\")public void doSomething() { ... }}  3、如果不指定“限定符”，将默认使用“transationManager”命名对应的事务管理器 Java代码   The default <tx:annotation-driven> target bean name transactionManager will still be used if no specifically qualified PlatformTransactionManager bean is found   The default <tx:annotation-driven> target bean name transactionManager will still be used if no specifically qualified PlatformTransactionManager bean is found    呼呼，小改进，大作用啊。","title":"被忽略的Spring3小改进——支持多数据源的@Transactional事务注解"},{"content":"ExamSoftware1.0要发布了。基于图片的考试系统1.0别具风格的使用图片显示考试题目，使本来枯燥无味的考试学习变的极为有趣。 l  知识条件： 通过导师的指导和自学，现在已经了解及掌握的技术包括(但不局限于)：C语言，C++，C#，Qt，数字图像处理，音频插件开发，动态图形界面设计，ADO.NET，ASP.NET,多线程，简单SQL数据库，XML, Oracle, Java。 l  预研成果： 考虑到目前学生学习缺乏激情的现状，我们开发了这样一套基于图片的考试系统。对于这一项目，我们预期能达到实际的应用效果，能够极大的提高学生的学习热情，能够收到广大学生、老师、家长的欢迎，一定程度上解决学习的枯燥无味的问题。 l  项目科学性： 根据调查结果，本项目立足于现实生活中的实际应用，操作性极强，若软件最终能应用到广大学生当中去，将会给学生们的学习带来极大的便利。学生可以通过此系统进行自我提高，家长也可以通过此系统来督促教导自己的孩子学习，老师们也可以通过此系统对自己的学生进行评测和一对一的辅导，提高。并且，这便于储存与随时随地的查询。本系统的一大特色就是基于图片，处理起来有些麻烦，对于具体的解决方案，简单的图片文件的存取算法在理论上虽有一定难度，但并不是过于复杂，而且Qt、sqlite数据库及文件数据保存和处理的算法在综合实现起来有很大难度，但在导师的指导和我们的探索下，项目应该可以顺利进行，并在预定的时间内完成，得到应有的实践效果。 l  项目创新性： 本项目的主要亮点在于基于图片的自测系统。该项目包涵用户登录，文件系统，考试系统，管理系统等几大块。思路清晰，操作简单，用户容易上手。并且，本系统的更新与维护十分方便，可以做到及时，同步，满足不同类型的客户的需要，涵盖面广。还有一点就是通过此系统的自测，可以让学生自己全面了解自己的知识缺乏点，从而做到对症下药。 l  技术可行性：        本系统主要用到的是Qt、sqlite数据库及文件数据保存和处理级大块的知识。通过小组成员对各大知识点的系统学习，加上学长，导师的指导，对各大知识的应用都很熟悉。几大成员每个人分别负责一个模块，将自己的模块任务做好，再把几个系统综合起来。进行综合的调试。在实行起来没有特别的困难。 如今教育的重要性早已深入了学生与家长心中，对家长来说，在家里对孩子所学的知识的辅导和了解仍然存在着巨大的困难。我们立足于实际背景，根据对周边的长一辈的父亲母亲进行调查，我们发现，依旧存在父母由于和孩子存在代沟而无法理解孩子学习的状况，在辅导孩子中，对孩子不知道的知识既存在自己也不知道的情况，也存在自己知道却怕误导孩子的情况，因此考试软件系统迫切的需要来解决大量学习上的问题。该项目不仅可以很好的减少孩子和家长对学习的盲目支出，还可以很好的解决孩子学习上的困惑。","title":"ExamSoftware介绍"},{"content":"在某些偶然的情况下，会引起SQL Server 2005数据库日志文件的损坏，比如：硬件故障、计算机非正常重启或关机。 当SQL Server 2005数据库日志文件损坏时，可能会出现以下情况： 1、在SQL Server Management Studio中显示数据库处于置疑(suspect)状态。 2、事件日志可能会出现如下错误信息：    Could not redo log record (21737:686:9), for transaction ID (0:2334886), on page (1:37527), database 'Test' (database ID 15). Page: LSN = (21735:299:5), type = 2. Log: OpCode = 3, context 19, PrevPageLSN: (21737:615:1). Restore from a backup of the database, or repair the database.    During redoing of a logged operation in database 'Test', an error occurred at log record ID (76116:286:2). Typically, the specific failure is previously logged as an error in the Windows Event Log service. Restore the database from a full backup, or repair the database.  3、无法分离数据库 4、用CREATE DATABASE DBName ON ( FILENAME = N'DBFile' )  FOR ATTACH_REBUILD_LOG附加数据库时出现提示：The log cannot be rebuilt because the database was not cleanly shut down. 恢复方法： 1、停止数据库服务。 2、将需要恢复的数据库文件复制到另外的位置。 3、启动数据库服务。 4、确认要恢复的数据库文件已经成功复制到另外的位置，然后在SQL Server Management Studio中删除要恢复的数据库。 5、新建同名的数据库(数据库文件名也要相同)。 6、停止数据库服务。 7、用第2步中备份的.mdf文件覆盖新数据库的同名文件。 8、启动数据库服务。 9、运行alter database dbname set emergency，将数据库设置为emergency mode 10、运行下面的命令就可以恢复数据库： use master  declare @databasename varchar(255)  set @databasename='要恢复的数据库名称'  exec sp_dboption @databasename, N'single', N'true' --将目标数据库置为单用户状态  dbcc checkdb(@databasename,REPAIR_ALLOW_DATA_LOSS)  dbcc checkdb(@databasename,REPAIR_REBUILD)  exec sp_dboption @databasename, N'single', N'false'--将目标数据库置为多用户状态 ","title":"SQL Server 2005数据库日志文件损坏的情况下如何恢复数据库"},{"content":"在SQL Server中，除了系统数据库外，你创建的每一个数据库都有三种可供选择的恢复模式: Simple(简单), full(完整), bulk-logged(批量日志)。 下面这条语句可以显示出所有在线数据库的恢复模式: SELECT name, (SELECT DATABASEPROPERTYEX(name, 'RECOVERY')) RecoveryModel FROM master..sysdatabases ORDER BY name SQL Server 2005及以上版本也可以使用下面这条语句来查看: SELECT name, recovery_model_desc FROM master.sys.databases ORDER BY name 如果想改变数据库的恢复模式，可以使用下面SQL语句: 简单恢复模式:ALTER DATABASE AdventureWorks SET RECOVERY SIMPLE 完整恢复模式:ALTER DATABASE AdventureWorks SET RECOVERY FULL 批量日志恢复模式:ALTER DATABASE AdventureWorks SET RECOVERY BULK_LOGGED 在实际情况中，你应该选择使用哪种恢复模式呢？答案在于你能承受丢失多少数据。让我们用下面这些图表来说明这三种恢复模式之间的不同。下面这张图是一个数据库分别在9点和11点进行了一次完整备份。 1.简单恢复模式 假设硬件在10:45分时坏了。 如果数据库使用的是简历模型的话，那你将要丢失105分钟的数据。因为你可以恢复的最近的时间点是9点，9点之后的数据将全部丢失。当然你可以使用差异备份来分段运行，如下图: 像这样使用差异性备份的话，你将丢失45分钟的数据。现在，假设用户在9:50删除了一张很重要的表，你能恢复删除点之前的数据吗？答案当然是No。因为差异性备份仅仅包含数据页的修改，它不能用于恢复一个指定的时间点。你不得不把数据库恢复到9点的状态，然后重做后面49分钟的事情。 2.完整恢复模式 假如在9点和11点之间没有进行事务日志的备份，那么你将面临和使用简单恢复模式一样的情况。另外，事务日志文件会很大，因为SQL Server不会删除已经提交和已经CheckPoint的事务，直到它们被备份。 假设每30分钟备份一次事务日志： 假如硬件在10:45分时坏了，那你只会丢失15分钟的数据。你可以使用9点的完整备份及直到10:30的事务日志来恢复。假如9:50分删除了重要数据怎么办呢？没关系，你可以使用在10点备份的事务日志，把数据库恢复到9:49分的状态。 因为你恢复时无法直接跳过9:50那次误删除的操作日志而恢复9:50之后的数据, 所以你还必须重做误删除之后的操作。不过，这已经是不错的选择了。 注意：市场上有一些工具，可以使用事务日志来恢复用户误操作而丢失的数据，就是利用了上述原理 3.批量日志恢复模式 批量日志恢复模式被定义成一种最小化事务日志的完整恢复模式。例如select into就是一种最小化事务日志，假设这种事务发生在9:40分 这个事务将被最小化的记录下来，这就意味着SQL Server仅仅记录由于这个事务而产生的数据页的变化，它不记录每一条插入到数据表中的数据。假如9:50时一个重要的表数据被删除了，那意味着什么呢？意味着你不能把数据库再恢复到9:49分的状态了，因为事务日志在10点时被备份并且不能恢复到一个指定的时间点上。你只能把数据库恢复到9:30分的状态。你要记住，无论在什么时候，只要事务日志备份包含一个或多个最小化日志事务，那你就不能再把备份还原到一个指定的时间点了。   既然如此，那人们为什么还要使用批量日志恢复模式呢？一个最主要的原因就是性能。让我们以select into以例，从一个结果集来创建一张大表。假如你使用完整备份模型，那这张表中的每一条插入的数据都被记录下来，事务日志会消耗很多磁盘空间。假如你使用批量日志恢复模式，那么仅仅会记录数据页的修改细节以达到最好的性能。就像我们刚才描述的那样，使用事务日志的好处就是可以恢复到某一个指定的恢复点，但是会大大影响性能。 下面的几种操作都会最小化日志操作: ·批量导入操作(例如:INSERT ... SELECT * FROM OPENROWSET(BULK...), and BULK INSERT) ·select into 操作 ·使用update来更新部分的大数据值数据类型。写入语句是插入或是追加数据，注意当被更新的数据存在时最小化日志不会被记录 ·假如数据库恢复模式被设置为批量恢复或是简单恢复，那么一些索引的DDL操作会产生最小化日志，无论这个操作是在线还是离线被执行 ·删除索引新建堆时 注意：当一个数据库的数据文件不可用时(也许是硬件坏了)，假如媒介依旧在线可用，那么你依然可以备份事务日志文件。但是你需要确定backup log命令一定要加上no_truncate选项。这样你就可以备份硬件毁坏前的事务日志了，这种方法常用来备份事务日志结尾。 然则，假如你的数据库使用批量日志恢复模式且事务日志包括最小化日志事务，那么包括被修改过的页的数据文件一定要可用，假如数据文件不可用了，也就意味着你将不能备份事务日志结尾。这也是使用批量日志恢复模式另一个需要考虑的地方。 总之，简单恢复模式提供了数量最少的恢复选项和最简单的管理模型。完整恢复模式在恢复数据库时允许更复杂的情况存在。批量恢复模式简化了一些复杂性，从而得到了更好的性能。大家可以从Books Online中得到这三种恢复更细致的对比。","title":"SqlServer2005备份模式与恢复模式"},{"content":"问题描述：          平台登陆的时候没有问题，但是当从平台进入各个子平台的时候会出现用户名不存在的问题，但是当再次进入这个子系统的时候就是正常的。 解决方法：          后来经过认真的分析，发现是我们连接的数据库有问题，数据库放在了一个个人电脑了，经常会关机，所以导致数据库连接经常性断了，所以出现了上述情况。 1、  设置validationQuery属性 validationQuery：用于验证连接是否成功的查询SQL语句，SQL语句必须至少要返回一行数据，如你可以简单地设置为：“select 1 from dual”； 2、  把maxActive设置大于0，maxActive：最大连接数据库连接数，设置为0时，表示没有限制； 问题总结： 当数据库连接池中的连接被创建而长时间不使用的情况下，该连接会自动回收并失效，但客户端并不知道，在进行数据库操作时仍然使用的是无效的数据库连接，这样，就导致客户端程序报“ java.sql.SQLException: Io 异常: Connection resetby peer”或“java.sql.SQLException 关闭的连接”异常，加上<propertyname=\"validationQuery\" value=\"select * from dual\"/> 配置后，客户端在使用一个无效的连接时会先对该连接进行测试，如果发现该连接已经无效，则重新从连接池获取有效数据库连接来使用 以上是个人的分析和理解，有不对的地方请大家指出共同讨论~~~     出现Connection reset bypeer: socket write error 异常的几种可能：    1.  客户端发出请求时，没有完全获得服务器端的响应，客户端与服务器端发生断链（例如网络中断、用户点击了停止按钮、浏览器关闭等）时  2.  服务器的并发连接数超过了最大链接数，服务器关掉了其中的一些链接。  3.  数据传输时的等待时间过长，超出了数据库的会话时间限制。  以上服务器端都有可能报出 socket write error 异常。  l>\u001f\u0005�\u0010n\u0010l\u0001\b�<\u0010�57\u0010> response.setContentType(\"text/html;charset=GBK\"); 也可把这句加到上面的Filter中，如注释掉的部分。   有人说用 response.setCharacterEncoding(\"GBK\"); 无效，必须用 response.setContentType(\"text/html;charset=GBK\"); 本人没试过。   对于JSP，是比较方便的，只需要在JSP最前部分按如下方式声明：   <%@ pagecontentType=\"text/html;charset=GBK\"%>   对于HTML，其和JSP文件基本类似，也是在页面最前部分按如下方式声明：   <head>   <METAHTP-EQUIV=\"contentType\" CONTENT=\"text/html;charset=GBK\">   <\/head>   3.? 国际化资源文件的中文问题   一个Struts应用程序中，可以配置多个资源包，无论是Action、ActionForm还是JSP都可以访问这些包中的资源。资源包就是由扩展名为.properties的文件组成的一组具有相同前缀的文件，如ApplicationResources_zh_CN.properties、ApplicationResources_zh.properties和ApplicationResources.properties。这些文件就构成一个Struts的资源包，它们都有一个统一的前缀ApplicationResources，凡是有相同前缀的资源文件就都属于一个包。   当用MyEclipse编写资源文件时，默认是不能保存中文的，因为默认保存编码的格式是ISO-8859-1，这就需要修改为gb2312或者gbk编码格式。Windons-->Preferences-->General -->Content Types-->Text-->JavaProperties File，在最下方把其Default encoding改为\"UTF-8”，然后\"update”就可以保存中文了。但就这样保存的中文还是不能够在页面上使用的，因为Web容器默认是使用ISO-8859-1，也就会把中文用ISO-8859-1的格式发送给客户页面，显示的还是乱码，这就是JAVA国际化的问题。JAVA是支持unicode编码格式的，unicode是国际统一通用编码，所以不管什么格式的编码转化为unicode编码肯定不会显示乱码的。这个时候就是需要把资源文件的UTG-8编码格式转化为unicode编码格式，而SUN公司又提供了这样的一种工具。在JDK的安装目录bin下，有一个叫native2ascii可执行文件，这个是专门来进行资源文件转码的。打开cmd，进入JDK的bin目录下，把资源文件拷贝到该目录下，执行该命令。比如：   native2ascii –encoding GBK ApplicationResources.propertiesApplicationResources_zh_CN.properties 就是把GBK编码格式ApplicationResources.properties转化为unicode编码格式ApplicationResources_zh_CN.properties，这样显示页面时就不会出现乱码了。","title":"部署应用到websphere上发现的问题"},{"content":"VC开发数据库基础之ADO篇  VC开发数据库基础之ADO篇    一、ADO简介 ADO(ActiveX Data Object)是Microsoft数据库应用程序开发的新接口，是建立在OLE DB之上的高层数据库访问技术，请不必为此担心，即使你对OLE DB，COM不了解也能轻松对付ADO,因为它非常简单易用，甚至比你以往所接触的ODBC API、DAO、RDO都要容易使用，并不失灵活性。本文将详细地介绍在VC下如何使用ADO来进行数据库应用程序开发，并给出示例代码。 二、基本流程 万事开头难，任何一种新技术对于初学者来说最重要的还是“入门”，掌握其要点。让我们来看看ADO数据库开发的基本流程吧！ (1)初始化COM库，引入ADO库定义文件 (2)用Connection对象连接数据库 (3)利用建立好的连接，通过Connection、Command对象执行SQL命令，或利用Recordset对象取得结果记录集进行查询、处理。 (4)使用完毕后关闭连接释放对象。 准备工作: 为了大家都能测试本文提供的例子，我们采用Access数据库，您也可以直接在我们提供的示例代码中找到这个test.mdb。 下面我们将详细介绍上述步骤并给出相关代码。 【1】COM库的初始化 我们可以使用AfxOleInit()来初始化COM库，这项工作通常在CWinApp::InitInstance()的重载函数中完成，请看如下代码: BOOL CADOTest1App::InitInstance() { AfxOleInit(); ...... 【2】用#import指令引入ADO类型库 我们在stdafx.h中加入如下语句：(stdafx.h这个文件哪里可以找到?你可以在FileView中的Header Files里找到) #import \"c:\\program files\\common files\\system\\ado\\msado15.dll\" no_namespace rename(\"EOF\",\"adoEOF\") 这一语句有何作用呢？其最终作用同我们熟悉的#include类似,编译的时候系统会为我们生成msado15.tlh,ado15.tli两个C++头文件来定义ADO库。 几点说明: (1) 您的环境中msado15.dll不一定在这个目录下，请按实际情况修改 (2) 在编译的时候肯能会出现如下警告，对此微软在MSDN中作了说明，并建议我们不要理会这个警告。 msado15.tlh(405) : warning C4146: unary minus operator applied to unsigned type, result still unsigned 【3】创建Connection对象并连接数据库 首先我们需要添加一个指向Connection对象的指针: _ConnectionPtr m_pConnection; 下面的代码演示了如何创建Connection对象实例及如何连接数据库并进行异常捕捉。 BOOL CADOTest1Dlg::OnInitDialog() { CDialog::OnInitDialog(); HRESULT hr; try { hr = m_pConnection.CreateInstance(\"ADODB.Connection\");///创建Connection对象 if(SUCCEEDED(hr)) { hr = m_pConnection->Open(\"Provider=Microsoft.Jet.OLEDB.4.0;Data Source=test.mdb\",\"\",\"\",adModeUnknown);///连接数据库 ///上面一句中连接字串中的Provider是针对ACCESS2000环境的，对于ACCESS97,需要改为:Provider=Microsoft.Jet.OLEDB.3.51; } } catch(_com_error e)///捕捉异常 { CString errormessage; errormessage.Format(\"连接数据库失败!\\r\\n错误信息:%s\",e.ErrorMessage()); AfxMessageBox(errormessage);///显示错误信息 } 在这段代码中我们是通过Connection对象的Open方法来进行连接数据库的，下面是该方法的原型 HRESULT Connection15::Open ( _bstr_t ConnectionString, _bstr_t UserID, _bstr_t Password, long Options ) ConnectionString为连接字串,UserID是用户名, Password是登陆密码,Options是连接选项,用于指定Connection对象对数据的更新许可权, Options可以是如下几个常量: adModeUnknown:缺省。当前的许可权未设置 adModeRead:只读 adModeWrite:只写 adModeReadWrite:可以读写 adModeShareDenyRead:阻止其它Connection对象以读权限打开连接 adModeShareDenyWrite:阻止其它Connection对象以写权限打开连接 adModeShareExclusive:阻止其它Connection对象打开连接 adModeShareDenyNone:允许其它程序或对象以任何权限建立连接 我们给出一些常用的连接方式供大家参考: (1)通过JET数据库引擎对ACCESS2000数据库的连接 m_pConnection->Open(\"Provider=Microsoft.Jet.OLEDB.4.0;Data Source=C:\\\\test.mdb\",\"\",\"\",adModeUnknown); (2)通过DSN数据源对任何支持ODBC的数据库进行连接: m_pConnection->Open(\"Data Source=adotest;UID=sa;PWD=;\",\"\",\"\",adModeUnknown); (3)不通过DSN对SQL SERVER数据库进行连接： m_pConnection->Open(\"driver={SQL Server};Server=127.0.0.1;DATABASE=vckbase;UID=sa;PWD=139\",\"\",\"\",adModeUnknown); 其中Server是SQL服务器的名称，DATABASE是库的名称 Connection对象除Open方法外还有许多方法，我们先介绍Connection对象中两个有用的属性ConnectionTimeOut与State ConnectionTimeOut用来设置连接的超时时间，需要在Open之前调用，例如: m_pConnection->ConnectionTimeout = 5;///设置超时时间为5秒 m_pConnection->Open(\"Data Source=adotest;\",\"\",\"\",adModeUnknown); State属性指明当前Connection对象的状态，0表示关闭，1表示已经打开，我们可以通过读取这个属性来作相应的处理，例如: if(m_pConnection->State) m_pConnection->Close(); ///如果已经打开了连接则关闭它 【4】执行SQL命令并取得结果记录集 为了取得结果记录集，我们定义一个指向Recordset对象的指针:_RecordsetPtr m_pRecordset; 并为其创建Recordset对象的实例: m_pRecordset.CreateInstance(\"ADODB.Recordset\"); SQL命令的执行可以采用多种形式，下面我们一进行阐述。 (1)利用Connection对象的Execute方法执行SQL命令 Execute方法的原型如下所示: _RecordsetPtr Connection15::Execute ( _bstr_t CommandText, VARIANT * RecordsAffected, long Options ) 其中CommandText是命令字串，通常是SQL命令。参数RecordsAffected是操作完成后所影响的行数, 参数Options表示CommandText中内容的类型，Options可以取如下值之一： adCmdText:表明CommandText是文本命令 adCmdTable:表明CommandText是一个表名 adCmdProc:表明CommandText是一个存储过程 adCmdUnknown:未知 Execute执行完后返回一个指向记录集的指针，下面我们给出具体代码并作说明。 _variant_t RecordsAffected; ///执行SQL命令：CREATE TABLE创建表格users,users包含四个字段:整形ID,字符串username,整形old,日期型birthday m_pConnection->Execute(\"CREATE TABLE users(ID INTEGER,username TEXT,old INTEGER,birthday DATETIME)\",&RecordsAffected,adCmdText); ///往表格里面添加记录 m_pConnection->Execute(\"INSERT INTO users(ID,username,old,birthday) valueS (1, ''''''''Washington'''''''',25,''''''''1970/1/1'''''''')\",&RecordsAffected,adCmdText); ///将所有记录old字段的值加一 m_pConnection->Execute(\"UPDATE users SET old = old+1\",&RecordsAffected,adCmdText); ///执行SQL统计命令得到包含记录条数的记录集 m_pRecordset = m_pConnection->Execute(\"SELECT COUNT(*) FROM users\",&RecordsAffected,adCmdText); _variant_t vIndex = (long)0; _variant_t vCount = m_pRecordset->GetCollect(vIndex);///取得第一个字段的值放入vCount变量 m_pRecordset->Close();///关闭记录集 CString message; message.Format(\"共有%d条记录\",vCount.lVal); AfxMessageBox(message);///显示当前记录条数 (2)利用Command对象来执行SQL命令 _CommandPtr m_pCommand; m_pCommand.CreateInstance(\"ADODB.Command\"); _variant_t vNULL; vNULL.vt = VT_ERROR; vNULL.scode = DISP_E_PARAMNOTFOUND;///定义为无参数 m_pCommand->ActiveConnection = m_pConnection;///非常关键的一句，将建立的连接赋值给它 m_pCommand->CommandText = \"SELECT * FROM users\";///命令字串 m_pRecordset = m_pCommand->Execute(&vNULL,&vNULL,adCmdText);///执行命令，取得记录集 在这段代码中我们只是用Command对象来执行了SELECT查询语句，Command对象在进行存储过程的调用中能真正体现它的作用。下次我们将详细介绍。 (3)直接用Recordset对象进行查询取得记录集  例如 m_pRecordset->Open(\"SELECT * FROM users\",_variant_t((IDispatch *)m_pConnection,true),adOpenStatic,adLockOptimistic,adCmdText); Open方法的原型是这样的: HRESULT Recordset15::Open ( const _variant_t & Source, const _variant_t & ActiveConnection, enum CursorTypeEnum CursorType, enum LockTypeEnum LockType, long Options )  其中： ①Source是数据查询字符串 ②ActiveConnection是已经建立好的连接（我们需要用Connection对象指针来构造一个_variant_t对象)  ③CursorType光标类型，它可以是以下值之一,请看这个枚举结构: enum CursorTypeEnum { adOpenUnspecified = -1,///不作特别指定 adOpenForwardOnly = 0,///前滚静态光标。这种光标只能向前浏览记录集，比如用MoveNext向前滚动,这种方式可以提高浏览速度。但诸如BookMark,RecordCount,AbsolutePosition,AbsolutePage都不能使用 adOpenKeyset = 1,///采用这种光标的记录集看不到其它用户的新增、删除操作，但对于更新原有记录的操作对你是可见的。 adOpenDynamic = 2,///动态光标。所有数据库的操作都会立即在各用户记录集上反应出来。 adOpenStatic = 3///静态光标。它为你的记录集产生一个静态备份，但其它用户的新增、删除、更新操作对你的记录集来说是不可见的。 }; ④LockType锁定类型，它可以是以下值之一，请看如下枚举结构： enum LockTypeEnum { adLockUnspecified = -1,///未指定 adLockReadOnly = 1,///只读记录集 adLockPessimistic = 2,悲观锁定方式。数据在更新时锁定其它所有动作，这是最安全的锁定机制 adLockOptimistic = 3,乐观锁定方式。只有在你调用Update方法时才锁定记录。在此之前仍然可以做数据的更新、插入、删除等动作 adLockBatchOptimistic = 4，乐观分批更新。编辑时记录不会锁定，更改、插入及删除是在批处理模式下完成。 };  ⑤Options请参考本文中对Connection对象的Execute方法的介绍 【5】记录集的遍历、更新 根据我们刚才通过执行SQL命令建立好的users表，它包含四个字段:ID,username,old,birthday 以下的代码实现：打开记录集，遍历所有记录，删除第一条记录，添加三条记录，移动光标到第二条记录，更改其年龄，保存到数据库。 _variant_t vUsername,vBirthday,vID,vOld; _RecordsetPtr m_pRecordset; m_pRecordset.CreateInstance(\"ADODB.Recordset\"); m_pRecordset->Open(\"SELECT * FROM users\",_variant_t((IDispatch*)m_pConnection,true),adOpenStatic,adLockOptimistic,adCmdText); while(!m_pRecordset->adoEOF)///这里为什么是adoEOF而不是EOF呢?还记得rename(\"EOF\",\"adoEOF\")这一句吗? { vID = m_pRecordset->GetCollect(_variant_t((long)0));///取得第1列的值,从0开始计数，你也可以直接给出列的名称，如下一行 vUsername = m_pRecordset->GetCollect(\"username\");///取得username字段的值 vOld = m_pRecordset->GetCollect(\"old\"); vBirthday = m_pRecordset->GetCollect(\"birthday\"); ///在DEBUG方式下的OUTPUT窗口输出记录集中的记录 if(vID.vt != VT_NULL && vUsername.vt != VT_NULL && vOld.vt != VT_NULL && vBirthday.vt != VT_NULL) TRACE(\"id:%d,姓名:%s,年龄:%d,生日:%s\\r\\n\",vID.lVal,(LPCTSTR)(_bstr_t)vUsername,vOld.lVal,(LPCTSTR)(_bstr_t)vBirthday); m_pRecordset->MoveNext();///移到下一条记录 } m_pRecordset->MoveFirst();///移到首条记录 m_pRecordset->Delete(adAffectCurrent);///删除当前记录 ///添加三条新记录并赋值 for(int i=0;i<3;i++) { m_pRecordset->AddNew();///添加新记录 m_pRecordset->PutCollect(\"ID\",_variant_t((long)(i+10))); m_pRecordset->PutCollect(\"username\",_variant_t(\"叶利钦\")); m_pRecordset->PutCollect(\"old\",_variant_t((long)71)); m_pRecordset->PutCollect(\"birthday\",_variant_t(\"1930-3-15\")); } m_pRecordset->Move(1,_variant_t((long)adBookmarkFirst));///从第一条记录往下移动一条记录,即移动到第二条记录处 m_pRecordset->PutCollect(_variant_t(\"old\"),_variant_t((long)45));///修改其年龄 m_pRecordset->Update();///保存到库中 【6】关闭记录集与连接  记录集或连接都可以用Close方法来关闭 m_pRecordset->Close();///关闭记录集 m_pConnection->Close();///关闭连接 至此，我想您已经熟悉了ADO操作数据库的大致流程，也许您已经胸有成竹，也许您还有点胡涂，不要紧！建议你尝试写几个例子，这样会更好地熟悉ADO,最后我给大家写了一个小例子，例子中读出所有记录放到列表控件中、并可以添加、删除、修改记录。 点这里下载示例代码 后记：限于篇幅ADO中的许多内容还没有介绍，下次我们将详细介绍Recordset对象的属性、方法并解决几个关键的技术：绑定方式处理记录集数据、存储过程的调用、事务处理、图象在数据库中的保存与读取、与表格控件的配合使用等 //-------------------------------------------------------------------------------------- 又一个说明： 在vc中怎么使用ADO访问数据库? 1、#import \"msado15.dll\" no_namespace rename(\"EOF\",\"ADOEOF\")   引入\"msado15.dll\"动态库。 2、定义一个变量  _ConnectionPtr m_AdoCon；代表一个代表与数据源进行的唯一会话 3、打开数据库          _bstr_t connString;   //连接字符串 try { connString = _T(\"Provider=MSDASQL.1;Data Source=kong;Persist Security Info=False\"); m_AdoCon.CreateInstance(__uuidof(Connection));//??? m_AdoCon->Open(connString, \"\", \"\", -1); } catch (_com_error& comerr) { IErrorInfo* pErrorInfo = comerr.ErrorInfo(); HRESULT hr = comerr.Error(); if (pErrorInfo) { BSTR bsDesc = NULL; pErrorInfo->GetDescription( &bsDesc ); _bstr_t sDesc( bsDesc, false ); AfxMessageBox(sDesc.operator LPCTSTR()); pErrorInfo->Release(); }            } 4、使用 CString strIp, SQL_STR, strTemp, strResult; UINT port; _RecordsetPtr   AdoRst;               //RecordSet的实例 _StreamPtr AdoStream;                 //Ado数据流 SQL_STR = m_strText;                   //SQL语句 if (m_AdoCon->State == adStateClosed) //判断连接是否已经关闭 { strTemp = \"Ado connection hasn't set up.\"; m_pWnd->SendMessage(WM_FRESHWATCHLIST, (WPARAM)(&strTemp)); SendMsg(strTemp, FALSE); return; } try { //Create Recordset Interface AdoRst.CreateInstance(__uuidof(Recordset)); AdoRst->Open((LPCTSTR)SQL_STR, m_AdoCon.GetInterfacePtr(),  adOpenDynamic,adLockOptimistic,adCmdUnknown);       //打开并且执行SQL（SQL_STR）语句 if (strTemp != \"SELECT\") strResult =_T(\"OK!\"); else { //Save the xmlResult to strResult AdoStream.CreateInstance(__uuidof(Stream));        // AdoRst->Save(AdoStream.GetInterfacePtr(), adPersistXML); strResult = ((BSTR)AdoStream->ReadText(adReadAll));      //转换为XML格式 } } catch (_com_error& comerr) { //catch the COM exception IErrorInfo* pErrorInfo = comerr.ErrorInfo(); HRESULT hr = comerr.Error(); if (pErrorInfo) { BSTR bsDesc = NULL; pErrorInfo->GetDescription( &bsDesc ); _bstr_t sDesc( bsDesc, false); strResult = sDesc.operator LPCTSTR(); pErrorInfo->Release(); } } 5.取得表中的字段 GetCollect（） int nItem; _variant_t vUsername,vBirthday,vID,vOld; try { m_pRecordset.CreateInstance(\"ADODB.Recordset\"); m_pRecordset->Open(\"SELECT * FROM users\",_variant_t((IDispatch*)theApp.m_pConnection,true),adOpenStatic,adLockOptimistic,adCmdText); m_bSuccess = TRUE; while(!m_pRecordset->adoEOF) { vID = m_pRecordset->GetCollect(\"ID\"); vUsername = m_pRecordset->GetCollect(\"username\"); vOld = m_pRecordset->GetCollect(\"old\"); vBirthday = m_pRecordset->GetCollect(\"birthday\"); nItem=m_userlist.InsertItem(0xffff,(_bstr_t)vID); m_userlist.SetItem(nItem,1,1,(_bstr_t)vUsername,NULL,0,0,0); m_userlist.SetItem(nItem,2,1,(_bstr_t)vOld,NULL,0,0,0); m_userlist.SetItem(nItem,3,1,(_bstr_t)vBirthday,NULL,0,0,0); m_pRecordset->MoveNext(); } } 6.添加数据 PutCollect() if(!m_pRecordset->adoEOF && m_nCurrentSel >= 0 && m_bAutoSave) { vUserID = (long)m_nUserID; vUsername = m_sUsername; vOld = (long)m_nOld; vBirthday = m_tBirthday; m_pRecordset->PutCollect(\"ID\",vUserID); m_pRecordset->PutCollect(\"username\",vUsername); m_pRecordset->PutCollect(\"old\",vOld); m_pRecordset->PutCollect(\"birthday\",vBirthday)         } //-------------------------------------------------------------------------------------- 在ado中获取access中表的信息 void OpenSchemaX(TCHAR *TableName) {     HRESULT  hr = S_OK; IADORecordBinding   *picRs = NULL; _RecordsetPtr pRstSchema(\"ADODB.Recordset\"); _ConnectionPtr pConnection(\"ADODB.Connection\" ); pConnection->ConnectionString = TableName; pConnection->Provider = \"Microsoft.Jet.OLEDB.4.0\";    try     { pConnection->Open(pConnection->ConnectionString, \"\", \"\", adModeUnknown);   pRstSchema->QueryInterface(           __uuidof(IADORecordBinding), (LPVOID*)&picRs);         pRstSchema = pConnection->OpenSchema(adSchemaTables);//枚举表的名称处理         while(!(pRstSchema->EndOfFile))         { CString strTableType;             _bstr_t table_name = pRstSchema->Fields->                 GetItem(\"TABLE_NAME\")->Value;//获取表的名称             _bstr_t table_type = pRstSchema->Fields->                 GetItem(\"TABLE_TYPE\")->Value;//获取表的类型             strTableType.Format(\"%s\",(LPCSTR) table_type); if(!lstrcmp(strTableType,_T(\"TABLE\")))             { m_cbTeam.AddString((LPCSTR) table_name);//添加表的名称 }             pRstSchema->MoveNext();         }         // Clean up objects before exit.         pRstSchema->Close();         pConnection->Close();     }     catch (_com_error &e)     {         // Notify the user of errors if any.         // Pass a connection pointer accessed from the Connection.                 PrintProviderError(pConnection);         PrintComError(e);     } } -------------------------------------------------------------------------------- CSDN VC编程经验总结   ADO 2.8 Samples  See Also Clear Method | Command Object | Connection Object | Errors Collection | Execute Method (ADO Command) | Execute Method (ADO Connection) | Requery Method Execute, Requery, and Clear Methods Example (VC++) This example demonstrates the Execute method when run from both a Command object and a Connection object. It also uses the Requery method to retrieve current data in a recordset, and the Clear method to clear the contents of the Errors collection. The ExecuteCommand and PrintOutput functions are required for this example to run. // BeginExecuteCpp #include <ole2.h> #include <stdio.h> #import \"c:\\Program Files\\Common Files\\System\\ADO\\msado15.dll\" \\     no_namespace rename(\"EOF\", \"EndOfFile\") // Function declarations inline void TESTHR(HRESULT x) {if FAILED(x) _com_issue_error(x);}; void ExecuteX(void); void ExecuteCommand(_CommandPtr pCmdTemp, _RecordsetPtr pRstTemp); void PrintOutput(_RecordsetPtr pRstTemp); void PrintProviderError(_ConnectionPtr pConnection); void PrintComError(_com_error &e); //////////////////////////////// //      Main Function         // //////////////////////////////// void main() {     if(FAILED(::CoInitialize(NULL)))         return;     ExecuteX();     ::CoUninitialize(); } /////////////////////////////////// //      ExecuteX Function        // /////////////////////////////////// void ExecuteX(void)  {    HRESULT    hr = S_OK;     // Define string variables.    _bstr_t strSQLChange(\"UPDATE Titles SET Type = \"             \"'self_help' WHERE Type = 'psychology'\");    _bstr_t strSQLRestore(\"UPDATE Titles SET Type = \"             \"'psychology' WHERE Type = 'self_help'\");    _bstr_t strCnn(\"Provider='sqloledb';Data Source='MySqlServer';\"             \"Initial Catalog='pubs';Integrated Security='SSPI';\");     // Define ADO object pointers.     // Initialize pointers on define.     // These are in the ADODB::  namespace.     _ConnectionPtr  pConnection = NULL;     _CommandPtr     pCmdChange  = NULL;     _RecordsetPtr   pRstTitles  = NULL;     try     {         // Open connection.         TESTHR(pConnection.CreateInstance(__uuidof(Connection)));         pConnection->Open (strCnn, \"\", \"\", adConnectUnspecified);         // Create command object.         TESTHR(pCmdChange.CreateInstance(__uuidof(Command)));         pCmdChange->ActiveConnection = pConnection;         pCmdChange->CommandText = strSQLChange;         // Open titles table, casting Connection pointer to an          // IDispatch type so converted to correct type of variant.         TESTHR(pRstTitles.CreateInstance(__uuidof(Recordset)));         pRstTitles->Open (\"Titles\", _variant_t((IDispatch *) pConnection,              true), adOpenStatic, adLockOptimistic, adCmdTable);         // Print report of original data.         printf(             \"\\n\\nData in Titles table before executing the query: \\n\");         // Call function to print loop recordset contents.         PrintOutput(pRstTitles);         // Clear extraneous errors from the Errors collection.         pConnection->Errors->Clear();         // Call ExecuteCommand subroutine to execute pCmdChange command.         ExecuteCommand(pCmdChange, pRstTitles);         // Print report of new data.         printf(             \"\\n\\n\\tData in Titles table after executing the query: \\n\");         PrintOutput(pRstTitles);         // Use the Connection object's execute method to         // execute SQL statement to restore data.         pConnection->Execute(strSQLRestore, NULL, adExecuteNoRecords);         // Retrieve the current data by requerying the recordset.         pRstTitles->Requery(adCmdUnknown);         // Print report of restored data.         printf(             \"\\n\\n\\tData after exec. query to restore original info: \\n\");         PrintOutput(pRstTitles);     }     catch (_com_error &e)     {         PrintProviderError(pConnection);         PrintComError(e);     }     // Clean up objects before exit.     if (pRstTitles)         if (pRstTitles->State == adStateOpen)             pRstTitles->Close();     if (pConnection)         if (pConnection->State == adStateOpen)             pConnection->Close(); } ////////////////////////////////////////// //      ExecuteCommand Function         // ////////////////////////////////////////// void ExecuteCommand(_CommandPtr pCmdTemp, _RecordsetPtr pRstTemp) {     try     {         // CommandText property already set before function was called.         pCmdTemp->Execute(NULL, NULL, adCmdText);         // Retrieve the current data by requerying the recordset.         pRstTemp->Requery(adCmdUnknown);     }     catch(_com_error &e)     {         // Notify user of any errors that result from         // executing the query.         // Pass a connection pointer accessed from the Recordset.         PrintProviderError(pRstTemp->GetActiveConnection());         PrintComError(e);     } } ///////////////////////////////////// //      PrintOutput Function       // ///////////////////////////////////// void PrintOutput(_RecordsetPtr pRstTemp) {     // Ensure at top of recordset.     pRstTemp->MoveFirst();     // If EOF is true, then no data and skip print loop.     if( pRstTemp->EndOfFile )     {         printf(\"\\tRecordset empty\\n\");     }     else     {         // Define temporary strings for output conversions.         // Initialize to first record's values.         _bstr_t bstrTitle;         _bstr_t bstrType;         // Enumerate Recordset and print from each.         while(!(pRstTemp->EndOfFile))             {             // Convert variant string to convertable string type.             bstrTitle = pRstTemp->Fields->GetItem(\"Title\")->Value;             bstrType  = pRstTemp->Fields->GetItem(\"Type\")->Value;             printf(\"\\t%s, %s \\n\",                  (LPCSTR) bstrTitle,                 (LPCSTR) bstrType);                  pRstTemp->MoveNext();         }     } } /////////////////////////////////////////////// //      PrintProviderError Function          // /////////////////////////////////////////////// void PrintProviderError(_ConnectionPtr pConnection) {     // Print Provider Errors from Connection object.     // pErr is a record object in the Connection's Error collection.     ErrorPtr  pErr = NULL;     if( (pConnection->Errors->Count) > 0)     {         long nCount = pConnection->Errors->Count;         // Collection ranges from 0 to nCount -1.         for(long i = 0; i < nCount; i++)         {             pErr = pConnection->Errors->GetItem(i);             printf(\"\\t Error number: %x\\t%s\", pErr->Number,                 pErr->Description);         }     } } ////////////////////////////////////// //      PrintComError Function      // ////////////////////////////////////// void PrintComError(_com_error &e) {     _bstr_t bstrSource(e.Source());     _bstr_t bstrDescription(e.Description());          // Print Com errors.     printf(\"Error\\n\");     printf(\"\\tCode = %08lx\\n\", e.Error());     printf(\"\\tCode meaning = %s\\n\", e.ErrorMessage());     printf(\"\\tSource = %s\\n\", (LPCSTR) bstrSource);     printf(\"\\tDescription = %s\\n\", (LPCSTR) bstrDescription); } // EndExecuteCpp 【 原文由 wesley 所发表 】  本文摘自http://www.codeguru.com/mfc_database/Ado_Aok.shtml。作者：Bob Place     翻译改写：wesley at 水木清华。 Email: wesley@video.mdc.tsinghua.edu.cn。     前言：      有人经常问：现在最好的数据访问方法是什么？回答当然是ADO！      M$花了不少时间，推出了一种叫 UDA(Universal Data Access)的东东，还有一套看  起来蛮简单的数据访问对象ADO(ActiveX Data Object)，用来替代过时的 DAO(Data Ac  cess Object)、RDO(Remote Data Object)。      DAO 的底层是 JET 引擎，主要用来提供对 ACCESS 数据库的访问，比较新的版本也  支持访问其他数据库，不过对于其他数据库，需经过 JET 的中间层，访问速度比较差。  在所有对 ACCESS 数据库的访问方法中， JET是最快的。最新的 JET Engine版本为4.0  ，对应的 DAO 版本为3.6，可以访问 ACCESS 2000 的数据库。MFC里面 CDAODatabase  和 CDAORecordset 即为 DAO 的 MFC 包装。      RDO 的底层是 ODBC，RDO仅仅是对ODBC API的一个薄包装层，薄得简直有点不象样  ，很多人都用 ODBC API写过程序 (我的第一个SQL Server客户端程序就是用ODBC API写  的一个Console Application)，把那些并不复杂的API跟RDO一比就能发现，包装得简直  没有专业精神。也正因为薄，所以速度较快，在ADO出现以前，访问MS SQL Server最快  的方法就是 RDO 了(不要跟我说还有DB-Library，不论是看MS的文档，还是我亲自实验  ，DB-Library都没有ODBC/RDO快)。最新的 RDO 版本为 2.0，说是最新，似乎也有好几  年没有更新了，原因是MS早已经决定将其淘汰。不过遗憾的是，现在大家都还在用的 C  Database、CRecordset 就是 RDO 的 MFC 包装。现在还用这两个类，就象有了宝马奔驰  ，还骑破永久上下班，只是因为不会开车。 :-(      ADO 的底层是 OLE DB，不仅能访问关系型数据库，也可以访问非关系型数据库，这  可是现在最快速的数据库访问中间层啊！ADO对OLE DB的包装可以说相当成功，对象模型  简明扼要，没有一点多余的东西，功能还远超DAO、RDO。直到此时，我才算是有点佩服  MS，OLE DB里面数十个密密麻麻的接口对我来说实在是太恐怖了，还是乖乖的用ADO吧。         有一点很不幸，微软提供的ADO文档几乎没有有关VC的内容，象我这样的VC菜鸟，坐  进了宝马舒适的驾驶仓，不知道该怎么上手下脚，郁闷之极！      这篇文章真是救黎民于水火之中，不容我不把它贡献出来让大家共享。     开始：      在用ADO以前，一定得让你的程序知道去哪里找ADO。在stdafx.h文件里，需要加上  下面的代码：   #import \"c:\\program files\\common files\\system\\ado\\msado15.dll\" no_namespace   rename(\"EOF\", \"adoEOF\")      这行代码的作用是，告诉编译器去哪里找ADO的库文件(可能在你的机器上路径有所  不同)，然后说明不用namespace，并且将 EOF 更名为 adoEOF(如果不这样干，很有可能  会碰到常量冲突)。      只要加了这句话，准备工作就全干完了，很简单是吗？不用包含任何头文件，不用  为link指定任何lib文件，我也觉得有点神奇。//shrug     _ConnectionPtr, _CommandPtr, 和 _RecordsetPtr (本文中未提及 _CommandPtr)：      ADO，和 CDAODatabase、CDatabase 非常相似，也分这么几块，不同的是，ADO 以   COM 为基础，这几块都是标准的COM组件，而 CDatabase 等等则是 MFC 类。有一点必  须提请注意，要学习ADO编程，学点COM是不可避免的了，不过这是件好事，现在如果不  会一点COM、OLE什么的，估计很难适应Windows编程的形势。ADO里面的三个组成部份就  是三个COM组件：Connection、Command、Recordset。(还有两个暂时用不上的:)      Connection用于建立数据库连接，执行不返回任何结果集的SQL语句。      Command用于返回结果集，并提供简单的方法执行存储过程或者任何返回结果集的S  QL语句。      Recordset就是结果集，可进行数据的存取、滚动操作。      如果给Command和Recordset正确的Connection string，而不是一个Connection对象  的指针，它们一样可以打开记录集，这种情况适用于单数据库操作。当程序里需要频繁  进行数据库操作时，最好还是预先定义一个Connection对象，用它连接数据库，而用Re  cordset处理数据。本文中将大量讨论这两个对象。      _ConnectionPtr是一个Connection的接口，与CDatabase和CDAODatabase类似，实际  工作原理也差不多。在程序里创建它的实例，通过某个OLE DB provider指向一个数据源  ，并开启连接。下面的代码是CDAODatabase和_ConnectionPtr的开启实例：     DAO:      CDaoDatabase MyDb = new CDaoDatabase();      m_DaoServerDB.Open(NULL,FALSE,FALSE,\"ODBC;DSN=SAMS_SVR;UID=admin;PWD=adm  in\");     ADO:      _ConnectionPtr MyDb;      MyDb.CreateInstance(__uuidof(Connection));      MyDb->Open(\"DSN=SAMS_SVR;UID=admin;PWD=admin\",\"\",\"\",-1);         _RecordsetPtr是记录集接口，与CDAORecordset类似。先看看它的开启方式与CDAO  Recordset有多么相似：     DAO:      CDaoRecordset MySet = new CDaoRecordset(MyDb);      MySet->Open(AFX_DAO_USE_DEFAULT_TYPE,\"SELECT * FROM some_table\");     ADO:      _RecordsetPtr MySet;      MySet.CreateInstance(__uuidof(Recordset));      MySet->Open(\"SELECT * FROM some_table\", MyDb.GetInterfacePtr(), adOpenDy  namic, adLockOptimistic, adCmdText);         (译者注：请注意ADO在Open Recordset的时候，使用了MyDb.GetInterfacePtr()作  为参数之一，当时我用了_ConnectionPtr, &(_ConnectionPtr)都不行，原来要这么用，  真是不服不行。:()      ADO只是略微的麻烦一点，不过花这点功夫获得ADO的多多好处还是很值的。      现在有了一个Connection和一个Recordset，下面该用这两个东东取点数据出来了。  不妨先假定有一个名为m_List的Listbox，我们把数据取出来往里塞。     DAO:      VARIANT *vFieldValue;      COleVariant covFieldValue;      CString Holder;      while(!MySet->IsEOF())      {          MySet->GetFieldValue(\"FIELD_1\", covFieldValue);          vFieldValue = (LPVARIANT)covFieldValue;          if(vFieldValue->vt!-VT_NULL)          {              Holder.Format(\"%s\",vFieldValue->pbVal);              m_List.AddString(Holder);          }          MySet.MoveNext();      }     ADO:      _variant_t Holder      while(!MySet->adoEOF)      {          Holder = MySet->GetCollect(\"FIELD_1\");          if(Holder.vt!=VT_NULL)          m_List.AddString((char*)_bstr_t(Holder));          MySet->MoveNext();      }         注意：在微软所有的文档里，都没找到GetCollect方法。我找了所有的地方，也从  没人提起过，在文档里的示例方式是这样：          Holder = MySet->GetFields->Field->(_variant_t(FieldNumber))->Value;      你喜欢哪一种呢，反正我是喜欢GetCollect。(译者注：鬼知道他从哪里搞到这个方  法，难道是从MS自己人的程序里？I 服了 him。)     动态绑定 vs DFX(CRecordset 和 CDAORecordset的预先字段绑定，Data Field Exchan  ge)：      动态绑定即使用SQL语句动态构造结果字段，而不是象 CDAORecordset 里面用DFX去  把所有原始字段映射成成员变量。动态绑定的例子：      SELECT (SUM(field_1) + SUM(field_2)) AS answer FROM some_table      如果用DFX，估计就得在程序里自己写了：      m_answer = m_field_1 + m_field2;      (译者注：尽管很多人喜欢 DFX 的字段预先绑定，宁可这么写代码，不过我很少用   DFX，当然在 VB 里面更是从来不会用到，好象用得比较多的也就是在 Delphi 里面，  用起来还比较爽，大概是 MS 的文档里让我别用，而 Borland 的破文档里却没说吧。  :-)      相比之下，动态绑定确有其优越的地方，减少了代码量，也让程序更小、更易维护  。再说，这也是MS推荐的获取数据方式，更灵活，速度更快，更易维护，我们还能要求  什么呢？      对于大多数程序来说，都是创建一个全局的Connection，然后用Recordset来处理数  据，如果Recordset数量很多，可以想象光是花费在DFX上面的代码就有多少。如果使用  动态绑定，这些都省掉了。     _variant_t 和 _bstr_t 到底是什么玩意？      很不幸，我们喜爱的CString类在COM里用不了(CStringEx也一样)，因为COM必须设  计成跨平台，它需要一种更普遍的方式来处理字符串以及其他数据。这就是VARIANT数据  类型的来历，还有BSTR类型。VARIANT就是一个巨大的 union，包含了你能想得到的所有  的数据类型，除了char*，不过还好，BSTR取代了char*。      (译者注：似乎VARIANT是个很慢的东西，大家都不愿意使它，不过按我看来，情况  没这么糟糕，union照理说不应该慢到哪去，要说慢，也是慢在给VARIANT分配地址空间  上，这点在VC里面做得比VB要好      这些东西看起来的确有点恐怖，不过实在用不着怕，等下面熟悉了这两个东西之后  ，你会很快喜欢的)      简单来说，_variant_t是一个类，包装了VARIANT数据类型，并允许我们简单的对之  进行强制类型转换(相信大家都喜欢这个)，_bstr_t对BSTR干了同样的事情。在下面的例  子里，你将看到怎么用GetCollect把数据取到VARIANT里，又怎么把它放到_bstr_t里，  最后强制转换成char*，以及把_variant_t强制转换成long、double或者其他一切东西：         _variant_t Holder;      // first get the VARIANT and put it into the _variant_t      Holder = MySet->GetCollect(\"FIELD_1\");      // now put it into a _bstr_t and cast it to a char*      m_List.AddString((char*)_bstr_t(Holder));         对比一下没有用 _variant_t 和 _bstr_t 的代码：         COleVariant covFieldValuel      VARIANT vFieldValue      CString Holder;      MySet->GetFieldValue(\"FIELD_1\", covFieldValue);      vFieldValue = (LPVARIANT)covFieldValue;      Holder.Format(\"%s\",vFieldValue->pbVal);      m_List.AddString(Holder);         区别大了！  世界上既无所谓幸福也无所谓不幸  只有一种状况和另一种状况的比较  只有体验过极度不幸的人  才能品尝到极度的幸福     Update，Insert，Delete：     当我进行Update，Insert，Delete操作时，通常我喜欢用Connection和Command对象 ，原因是，用CString来构造SQL语句简单一些，然后直接用Connection.Execute就行了 。当然，用Recordset干这些也是可以的。       Update方法有下面三种方法调用：     1: 给某个Field对象(或某些个)的Value属性赋值，然后调用Update方法；     2: 将字段名和字段值作为参数传给Update方法；     3: 将字段名和字段值的数组作为参数传给Update方法。       AddNew方法如下调用：     1: 直接调用，然后同Update调用方法一；     2: 将字段名数组、字段值数组作为参数传给AddNew方法。       Delete方法最简单，直接调用就行了，删除当前记录！       做完这些事情，可能需要调用Requery方法才能看到效果。     下面的示例代码需要我们创建一个简单的MFC Application，然后在CWinApp类里面 声明三个接口的对象：       // Global ADO Objects     // connection     _ConnectionPtr m_pConnection;     _CommandPtr  m_pCommand;     _RecordsetPtr m_pRecordset;       在VC6里面有一点很有意思，如果敲 \"m_pConnection.\"，你会看到一个方法和属性 列表，如果敲\"m_pConnection->\"，还会看到一个方法和属性列表，当然里面的内容完全 不同，因为你实际是在指向两个不同的东西。下面就是这两种混用的代码：       _ConnectionPtr MyDb;     MyDb.CreateInstance(__uuidof(Connection));     MyDb->Open(\"DSN=SAMS_SVR;UID=admin;PWD=admin\",\"\",\"\",-1);       回到示例代码，在 application 的 InitInstance 方法里，我打开数据连接，指向我 机器上的一个数据库，你需要更改ConnectionString，使用你自己的ODBC数据源或指定 一个OLE DB provider。       // When we open the application we will open the ADO connection     m_pConnection.CreateInstance(__uuidof(Connection));     m_pConnection->Open(\"DSN=ADOTest\",\"\",\"\",-1);       如果你打开about对话框，就会看到一个Listbox，还有一个叫button1的按钮，这里 面包含了 ADO 调用的核心代码。我创建了一个_RecordsetPtr接口的实例，打开我需要 的记录集，然后遍历所有记录，将它们塞到Listbox里去：       _variant_t TheValue;     theApp.m_pRecordset.CreateInstance(__uuidof(Recordset));     try     {         theApp.m_pRecordset->Open(\"SELECT DISTINCT FLDESC FROM tblFALines\",                 theApp.m_pConnection.GetInterfacePtr(),                 adOpenDynamic,                 adLockOptimistic,                 adCmdText);         while(!theApp.m_pRecordset->adoEOF)         {                 TheValue = theApp.m_pRecordset->GetCollect(\"FLDESC\");                 if(TheValue.vt!=VT_NULL)                 m_List.AddString((char*)_bstr_t(TheValue));                 theApp.m_pRecordset->MoveNext();         }         theApp.m_pRecordset->Close();     }     catch(_com_error *e)     {         CString Error = e->ErrorMessage();         AfxMessageBox(e->ErrorMessage());     }     catch(...)     {         MessageBox(\"Whoa this is bad\");     }       记得一定要用try和catch，否则ADO调用错误有可能使你的程序崩溃，一定要随时记 得捕捉_com_error例外以及其它错误。     我尽可能的使代码简单，所以省略了很多细节，尤其是忽略了很多好的编程习惯(比 如检查大多数COM方法都返回的HRESULT值)。本文的目的是想说，ADO并没什么难的，CO M也一样，而不是想表现ADO能做的所有事情。我甚至都没仔细想过ADO能为你带来什么， 不过我肯定一点，那就是ADO比DAO、RDO更快、更容易使用、并且功能强大得多。看看本 站点其它的文章，你就会知道，通过ADO调用存储过程有多么容易！     最后，我想向大家推荐两本书，其中有一本是完全免费的，在www.informit.com可 以找到电子版，另一本必须得付钱买了，不过我还是推荐两本都买，除非你家浴池里、 床头边也放了计算机。 :)     免费的那本是<Learn Database Programming with Visual C++ in 21 days>。哦， 我知道你在想什么，我也知道那些'in 21 days'的书通常都很烂，而且当着其它程序员 的面买这样的书的确有点丢面子，并且还很不好意思把这样的书摆在书架上显眼的位置 。不过这一本绝对是个例外！里面的内容简直太棒了！     要花钱的那本是<ADO 2.0>，由WROC出版... (译者注：细节就省了吧，反正我们也 不会花美元去买英文书)。       译者注：一年以前，我在www.mcp.com(现在已经更名为informit)看到这本书，看过 之后觉得实在是本难得一见的好书，不仅讲ADO深入浅出，COM的来历、基础、发展都说 得很清楚，还有不少C++的高级知识，这也是我看过的唯一一本“21天”的书，与其它的 “21天”简直是天壤之别。强烈建议大家买一本。     中译本：Visual C++ 数据库编程...(一时记不起了)，清华大学出版社出版，清华 书店有卖，大家快去买啊！注意不要买机械工业出版社那本 VC 数据库编程的书，看起 来名字很象，不过内容烂得可以。     如果要看相关的文章，请访问站点www.codeguru.com，祝大家早日成为编程高手， 已经是高手的更加高！ 在stdafx.h中添加： #import \"c:\\program files\\common files\\system\\ado\\msado15.dll\" no_namespace rename(\"EOF\",\"adoEOF\") 正式代码： _RecordsetPtr m_pRs; _ConnectionPtr m_pConn; try {  CoInitialize(NULL);  m_pConn.CreateInstance(__uuidof(Connection));  m_pRs.CreateInstance(__uuidof(Recordset));    //设置服务器端游标  m_pConn->CursorLocation = adUseServer;//adUseClient;adUseNone      //连接ORACLE数据库  m_pConn->Open(L\"Provider=OraOLEDB.Oracle.1;User ID=pkuwh_za;password=a;Data Source=213;Persist Security Info=False\",       L\"\",L\"\",adOpenUnspecified);  //上面的语句按下面的方式写可以不用配置oracle数据源         //m_pConn->Open(L\"Provider=OraOLEDB.Oracle.1;User ID=pkuwh_za;Password=a;Data Source=(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=192.168.3.213)(PORT=1521))(CONNECT_DATA=(SERVICE_NAME = ZAGL)));Persist Security Info=False\",L\"\",L\"\",adOpenUnspecified);     m_pRs->PutRefActiveConnection(m_pConn);  CString t = \"select * from case_acceptinfo where rownum <= 3\";  m_pRs->Open(_variant_t(t),_variant_t((IDispatch*)m_pConn,true),adOpenDynamic,adLockOptimistic,adCmdUnknown);    while(!m_pRs->adoEOF)  {   CString m_s1 = _com_util::ConvertBSTRToString((_bstr_t)m_pRs->GetCollect(\"reporttime\"));   MessageBox(m_s1);   m_pRs->MoveNext();  }  m_pRs->Close();  m_pConn->Close();  m_pRs=NULL;  m_pConn=NULL;  CoUninitialize(); } catch(_com_error &e) {   AfxMessageBox(e.Description()); }     Trackback: http://tb.blog.csdn.net/TrackBack.aspx?PostId=218477","title":"VC开发数据库基础之ADO篇"},{"content":"  实现对数据的增删改   BOOL CDiaDlg::OnInitDialog(){\tCDialog::OnInitDialog();\t// Add \"About...\" menu item to system menu.\t// IDM_ABOUTBOX must be in the system command range.\tASSERT((IDM_ABOUTBOX & 0xFFF0) == IDM_ABOUTBOX);\tASSERT(IDM_ABOUTBOX < 0xF000);\tCMenu* pSysMenu = GetSystemMenu(FALSE);\tif (pSysMenu != NULL)\t{\t\tCString strAboutMenu;\t\tstrAboutMenu.LoadString(IDS_ABOUTBOX);\t\tif (!strAboutMenu.IsEmpty())\t\t{\t\t\tpSysMenu->AppendMenu(MF_SEPARATOR);\t\t\tpSysMenu->AppendMenu(MF_STRING, IDM_ABOUTBOX, strAboutMenu);\t\t}\t}\t// Set the icon for this dialog.  The framework does this automatically\t//  when the application's main window is not a dialog\tSetIcon(m_hIcon, TRUE);\t\t\t// Set big icon\tSetIcon(m_hIcon, FALSE);\t\t// Set small icon\t\t// TODO: Add extra initialization here\tm_Grid.SetExtendedStyle(LVS_EX_FLATSB\t\t|LVS_EX_FULLROWSELECT\t\t|LVS_EX_HEADERDRAGDROP\t\t|LVS_EX_ONECLICKACTIVATE\t\t|LVS_EX_GRIDLINES);\tm_Grid.InsertColumn(0,\"id\",LVCFMT_LEFT,110,0);\tm_Grid.InsertColumn(1,\"name\",LVCFMT_LEFT,110,1);\tm_Grid.InsertColumn(2,\"sex\",LVCFMT_LEFT,110,2);\tm_Grid.InsertColumn(3,\"xueli\",LVCFMT_LEFT,110,3);\tAddToGrid();\t\treturn TRUE;  // return TRUE  unless you set the focus to a control}void CDiaDlg::OnSysCommand(UINT nID, LPARAM lParam){\tif ((nID & 0xFFF0) == IDM_ABOUTBOX)\t{\t\tCAboutDlg dlgAbout;\t\tdlgAbout.DoModal();\t}\telse\t{\t\tCDialog::OnSysCommand(nID, lParam);\t}}// If you add a minimize button to your dialog, you will need the code below//  to draw the icon.  For MFC applications using the document/view model,//  this is automatically done for you by the framework.void CDiaDlg::OnPaint() {\tif (IsIconic())\t{\t\tCPaintDC dc(this); // device context for painting\t\tSendMessage(WM_ICONERASEBKGND, (WPARAM) dc.GetSafeHdc(), 0);\t\t// Center icon in client rectangle\t\tint cxIcon = GetSystemMetrics(SM_CXICON);\t\tint cyIcon = GetSystemMetrics(SM_CYICON);\t\tCRect rect;\t\tGetClientRect(&rect);\t\tint x = (rect.Width() - cxIcon + 1) / 2;\t\tint y = (rect.Height() - cyIcon + 1) / 2;\t\t// Draw the icon\t\tdc.DrawIcon(x, y, m_hIcon);\t}\telse\t{\t\tCDialog::OnPaint();\t}}// The system calls this to obtain the cursor to display while the user drags//  the minimized window.HCURSOR CDiaDlg::OnQueryDragIcon(){\treturn (HCURSOR) m_hIcon;}void CDiaDlg::OnInitADOConn(){\ttry\t{\t\t//创建连接对象实例\t\tm_pConnection.CreateInstance(\"ADODB.Connection\");\t\t//设置连接字符串（2000的在代码中有！）\t\tCString strConnect=\"DRIVER={Microsoft Access Driver (*.mdb)};\\\t\t\tuid=;pwd=;DBQ=shujuku.mdb\";\t\t//使用Open方法连接数据库\t\tm_pConnection->Open((_bstr_t)strConnect,\"\",\"\",adModeUnknown);  \t}\tcatch(_com_error e)\t{\t\tAfxMessageBox(e.Description());\t}}void CDiaDlg::ExitConnect(){\t//关闭记录集和连接\tif(m_pRecordset!=NULL)\t\tm_pRecordset->Close();\tm_pConnection->Close();}void CDiaDlg::AddToGrid(){\t//连接数据库\tOnInitADOConn();\t//设置查询字符串\t_bstr_t bstrSQL = \"select * from 表1 order by id desc\";\t//创建记录集指针对象实例\tm_pRecordset.CreateInstance(__uuidof(Recordset));\t//打开记录集\tm_pRecordset->Open(bstrSQL,m_pConnection.GetInterfacePtr(),adOpenDynamic,\t\tadLockOptimistic,adCmdText);\twhile(!m_pRecordset->adoEOF)\t{\t\tm_Grid.InsertItem(0,\"\");\t\tm_Grid.SetItemText(0,0,(char*)(_bstr_t)m_pRecordset->GetCollect(\"id\"));\t\tm_Grid.SetItemText(0,1,(char*)(_bstr_t)m_pRecordset->GetCollect(\"name\"));\t\tm_Grid.SetItemText(0,2,(char*)(_bstr_t)m_pRecordset->GetCollect(\"sex\"));\t\tm_Grid.SetItemText(0,3,(char*)(_bstr_t)m_pRecordset->GetCollect(\"xueli\"));\t\t//将记录集指针移动到下一条记录\t\tm_pRecordset->MoveNext();\t}\t//断开数据库连接\tExitConnect();}void CDiaDlg::OnButton3() {\t// TODO: Add your control notification handler code here\tUpdateData(TRUE);\tif(m_Id.IsEmpty() || m_Name.IsEmpty() || m_Sex.IsEmpty() || m_Xueli.IsEmpty())\t{\t\tMessageBox(\"基础信息不能为空！\");\t\treturn;\t}\tOnInitADOConn();\t_bstr_t sql;\tsql = \"select * from 表1\";\tm_pRecordset.CreateInstance(__uuidof(Recordset));\tm_pRecordset->Open(sql,m_pConnection.GetInterfacePtr(),adOpenDynamic,\t\tadLockOptimistic,adCmdText);\ttry\t{\t\tm_pRecordset->AddNew(); //添加新行\t\tm_pRecordset->PutCollect(\"id\",(_bstr_t)m_Id);\t\tm_pRecordset->PutCollect(\"name\",(_bstr_t)m_Name);\t\tm_pRecordset->PutCollect(\"sex\",(_bstr_t)m_Sex);\t\tm_pRecordset->PutCollect(\"xueli\",(_bstr_t)m_Xueli);\t\tm_Name=m_Sex=m_Id=m_Xueli=\"\";\t\tm_pRecordset->Update(); //更新数据表\t\tm_Name=m_Sex=m_Id=m_Xueli=\"\";\t\tUpdateData(FALSE);\t\tExitConnect();\t}\tcatch(...)\t{\t\tMessageBox(\"操作失败\");\t\treturn;\t}\tMessageBox(\"添加成功\");\tm_Grid.DeleteAllItems(); //删除列表控件\tAddToGrid();\t\t\t}void CDiaDlg::OnButton2() {\t// TODO: Add your control notification handler code here\tOnInitADOConn();\t_bstr_t sql;\tsql = \"select * from 表1\";\tm_pRecordset.CreateInstance(__uuidof(Recordset));\tm_pRecordset->Open(sql,m_pConnection.GetInterfacePtr(),adOpenDynamic,\t\tadLockOptimistic,adCmdText);\tlong pos = m_Grid.GetSelectionMark();\ttry\t{\t\tm_pRecordset->Move((long)pos,vtMissing);\t\tm_pRecordset->Delete(adAffectCurrent);\t\tm_pRecordset->Update();\t\tm_Name=m_Sex=m_Id=m_Xueli=\"\";\t\tUpdateData(FALSE);\t\tExitConnect();\t}\tcatch(...)\t{\t\tMessageBox(\"操作失败\");\t\treturn;\t}\tMessageBox(\"删除成功\");\tm_Grid.DeleteAllItems();\tAddToGrid();\t}void CDiaDlg::OnClickList1(NMHDR* pNMHDR, LRESULT* pResult) {\t// TODO: Add your control notification handler code here\tlong pos = m_Grid.GetSelectionMark();\tm_Id = m_Grid.GetItemText(pos,0);\tm_Name = m_Grid.GetItemText(pos,1);\tm_Sex = m_Grid.GetItemText(pos,2);\tm_Xueli = m_Grid.GetItemText(pos,3);\tUpdateData(FALSE);\t\t*pResult = 0;}void CDiaDlg::OnButton1() {\t// TODO: Add your control notification handler code here\tUpdateData(TRUE);\tif(m_Id.IsEmpty() || m_Name.IsEmpty() || m_Sex.IsEmpty() || m_Xueli.IsEmpty())\t{\t\tMessageBox(\"基础信息不能为空！\");\t\treturn;\t}\tOnInitADOConn();\t_RecordsetPtr pRs(\"ADODB.Recordset\");\t_bstr_t sql;\tsql = \"select * from 表1\";\tm_pRecordset.CreateInstance(__uuidof(Recordset));\tm_pRecordset->Open(sql,m_pConnection.GetInterfacePtr(),adOpenDynamic,\t\tadLockOptimistic,adCmdText);\tlong pos = m_Grid.GetSelectionMark();\t_variant_t var,varIndex;\tCString vSQL;\t_variant_t RecordsAffected;\ttry\t{\t\tUpdateData(TRUE);\t\tm_pRecordset->AddNew(); //添加新行\t\tif(m_Id.IsEmpty())\t\t\treturn ;\t\t\t\t//m_pRecordset->Move((long)pos,vtMissing);\t\t//m_pRecordset->Delete(adAffectCurrent);\t//\tm_pRecordset->Update();\t\t\tm_pRecordset->PutCollect(\"id\",(_bstr_t)m_Id);\t\tm_pRecordset->PutCollect(\"name\",(_bstr_t)m_Name);\t\tm_pRecordset->PutCollect(\"sex\",(_bstr_t)m_Sex);\t\tm_pRecordset->PutCollect(\"xueli\",(_bstr_t)m_Xueli);\t\tm_pRecordset->Move((long)pos,vtMissing);\t\tm_pRecordset->Delete(adAffectCurrent);\t\t\t\tm_pRecordset->Update();\t\tm_Name=m_Sex=m_Id=m_Xueli=\"\";\t\tUpdateData(FALSE);\t}\t\tcatch(...)\t{\t\t\tMessageBox(\"操作失败\");\t\treturn;\t\t}\tMessageBox(\"修改成功\");\tm_Grid.DeleteAllItems();\tAddToGrid();\t}void CDiaDlg::OnButton5() {\t// TODO: Add your control notification handler code here\tm_Id= \"\";\tm_Name = \"\";\tm_Sex = \"\";\tm_Xueli = \"\";\tUpdateData(FALSE);\t}","title":"vc++ ado 操作数据库实现对数据的增删 access"},{"content":"调优 LAMP 的 5 种简单方法 Wikipedia、Facebook 和 Yahoo! 等主要 web 属性使用 LAMP 架构来为每天数百万的请求提供服务，而 WordPress、Joomla、Drupal 和 SugarCRM 等 web 应用程序软件使用其架构来让组织轻松部署基于 web 的应用程序。 该架构的优势在于其简单性。而 .NET 这样的堆栈和 Java™ 技术可能使用大量硬件、昂贵的软件栈和复杂的性能调优，LAMP 堆栈可以运行于商品硬件之上，使用开源软件栈。由于软件栈是一个松散的组件集，而非一个整体堆栈，性能调优是一大挑战，因为需要分析和调优每个组件。 然而，这有几个个简单性能任务会对任何规模的网站的性能产生巨大的影响。在本文中，我们将探讨旨在优化 LAMP 应用程序性能的 5 个这样的任务。这些项目应当很少需要对您的应用程序进行架构更改，使其成为最大化您的 web 应用程序所需的响应能力和硬件需求的安全、便捷的选择。 1. 使用操作码缓存 提高任何 PHP 应用程序（当然是 LAMP 中的 “P”）的性能的最简单方式是利用一个操作码缓存。对于我使用的任何网站，它是我确保存在的一项内容，因为性能影响很大（很多时候有了操作码缓存，响应时间可减少一半）。但是对 PHP 不熟悉的大部分人的一个很大的疑问是，为何改进会如此之大。答案在于 PHP 如何处理 web 请求。图 1 概览了 PHP 请求的流程。 由于 PHP 是一种解释语言，而非 C 或 Java 等编译语言，对每个请求执行了 “解析-编译-执行” 的整个步骤。您可以看到为何这会耗时、耗资源，特别是当脚本在请求之间很少变化时。解析和编译脚本之后，脚本作为一系列操作码处于机器可解析状态。这是操作码缓存发挥效用的地方。它作为一系列操作码缓存这些编译脚本，以避免为解析和编译每个请求步骤。您将在图 2 中看到这样的工作流是如何运作的。 因此当 PHP 脚本的缓存操作码存在时，我们可以跳过 PHP 请求流程的解析和编译步骤，直接执行缓存操作码并输出结果。检查算法负责处理您可能对脚本文件进行了更改的情况，因此在已变更脚本的第一个请求后，会为随后的请求自动重新编译和缓存操作码，替换缓存的脚本。 操作码缓存对于 PHP 流行已久，其中早期的一些要追溯到 PHP V4 的全盛期。目前有一些流行选项正在积极开发和使用中： 替代 PHP 缓存（APC）可能是 PHP 最流行的操作码缓存。它由若干核心 PHP 开发人员所开发，做出了很大贡献，Facebook 和 Yahoo! 的工程师赋予了其速度和稳定性。它还支持用于处理 PHP 请求的若干其他速度改进，包括一个用户缓存组件，这将在本文后面探讨。 Wincache 是主要由 Microsoft的 Internet Information Services (IIS) 团队积极开发的一个操作码缓存，仅供在使用 IIS web 服务器的 Windows上使用。开发它的主要动力在于使 PHP 成为 Windows-IIS-PHP 堆栈上的一流开发平台，因为据知 APC 在该堆栈上运作的不是很好。它在功能上非常类似于 APC，且支持一个用户缓存组件，以及一个内置会话处理程序，以将 Wincache 作为一个会话处理程序直接加以利用。 eAccelerator 是原始 PHP 缓存之一 Turck MMCache 操作码缓存的一个派生。不同于 APC 和 Wincache，它仅是一个操作码缓存和优化器，因此它不包含用户缓存组件。它在 UNIX® 和 Windows 堆栈上完全兼容，且对于不打算利用 APC 或 Wincache 提供的其他功能的站点很流行。如果您要使用 memcache 这样的解决方案来为多 web 服务器环境提供一个单独的用户缓存服务器，那么这就是常见情况。 毫无疑问，一个操作码缓存是通过在每次请求后消除解析和编译脚本的需要来加速 PHP 的第一步。完成第一步之后，您应当看到响应时间和服务器负载方面的改进。但是优化 PHP 可以做的不止这些，我们接下来将加以讨论。 2. 优化 PHP 设置 虽然实现操作码缓存是性能改进的一大创举，不过也有大量其他优化选项可供您基于 php.ini 文件中的设置优化您的 PHP 设置。这些设置更适合于生产实例；在开发或测试实例上，您可能不希望做这些变更，因为它会使得应用程序问题的调试变得更难。 让我们看一下对于性能提升很重要的一些项目。 (1) 应当禁用的选项 有若干 php.ini 设置应当予以禁用，因为它们常用作向后兼容性： register_globals — 在 PHP V4.2 之前该功能常常是默认值，其中传入的请求变量被自动赋给普通 PHP 变量。这样做除了引起重大安全问题之外（使未过滤的传入请求数据与普通 PHP 变量内容相混），对每一个请求这样做还会产生开销。因此禁用这一设置使您的应用程序更安全且能提高性能。 magic_quotes_* — 这是 PHP V4 的另一遗留项，其中传入的数据会自动避开有风险的表单数据。它旨在作为一个安全特性，在将传入的数据发送到数据库之前对其进行整理，但不是很有效，因为它不能帮助用户预防常见的 SQL 注入攻击。由于大部分数据库层支持能更好地处理该风险的准备语句，禁用该设置会再次消除这个烦人的性能问题。 always_populate_raw_post_data — 这仅当您出于某些原因需要查看传入的未过滤 POST 数据的整个负载时才需要。否则，它仅在内存中存储 POST 数据的一个副本，而这没有必要。 然而，在遗留代码上禁用这些选项会有风险，因为它们可能取决于其设置来实现正确执行。不应当基于被设置的这些选项来开发任何新代码，而且可能的话，您应当寻求方法来重构您的现有代码，避免使用它们。 (2 ) 应当禁用或调整设置的选项 您可以启用 php.ini 文件的一些优秀性能选项，来提升您的脚本速度： output_buffering — 您应当确保启用该选项，因为它会以块为单位将输出刷回到浏览器，而非以每个 echo 或 print 语句为单位，而后者会大大减缓您的请求响应时间。 variables_order — 这个指令控制传入请求的 EGPCS（Environment、Get、Post、Cookie和 Server）变量解析顺序。如果您没有使用某种超全局变量（比如环境变量），您可以安全地删除它们来获得一点加速，从而避免在每一个请求上解析它们。 date.timezone — 这是在 PHP V5.1 中添加的一个指令，用于设置默认时区，然后用于后面将要介绍的 DateTime 函数。如果您不在 php.ini 文件中设置该选项，PHP 会执行大量系统请求来弄清它是什么，且在 PHP V5.3 中，对每一个请求会发出一个警告。 就以应当在您的生产实例上配置的设置而言，这些被看作是 “唾手可得”。就 PHP 而言，还有一件事需要考虑。这就是您的应用程序中 require() 和 include()（以及其同级 require_once() 和 include_once()）的使用。这些函数优化您的 PHP 配置和代码，以防止对每个请求进行不必要的文件状态检查，从而减少响应时间。 3. 管理 require() 和 include() 从性能来看，文件状态调用（即为检查一个文件是否存在而对底层文件系统进行的调用）相当昂贵。文件状态的最大元凶之一以require() 和 include() 语句的形式出现，这两个语句用于将代码带到脚本中。require_once() 和 include_once() 的同级调用更成问题，因为它们不仅需要验证文件是否存在，而且它之前没有包含在内。 那么解决这个问题的最好方式是什么？您可以做一些事来加快解决。 为所有 require() 和 include() 调用使用绝对路径。这将使 PHP 更清楚您希望包含的确切文件，因此无需为您的文件检查整个 include_path。 保持 include_path 中的条目数较低。这在很难为每个 require() 和 include() 调用提供绝对路径的情况（通常在大型遗留应用程序中会出现这种情况）下很有用，方法就是不检查您包含的文件不在的位置。 APC 和 Wincache 还有用于缓存 PHP 进行的文件状态检查结果的机制，因此无需进行反复的文件系统检查。当您将 include 文件名保留为静态而非变量驱动的时，它们最有效，因此尽可能尝试这样做很有用。 4. 优化数据库 数据库优化很快会成为一个前沿话题，我几乎没有空间在这里完全公正地做这个话题。但是如果您在寻求优化您的数据库的速度，首先应当采取一些步骤，这应当对常见问题有所帮助。 (1) 将数据库放在自己的机器上 数据库查询自身可以变得相当激烈，通常在对大小合理的数据集执行简单的 SELECT 语句时限定在 100% 的 CPU。如果您的 web 服务器和数据库服务器都在竟用单一机器上的 CPU 时间，这无疑将减慢您的请求速度。因此我想第一步最好是将 web 服务器和数据库服务器放在单独的机器上，确保您的数据库服务器是两者中更强健的（数据库服务器喜欢大量内存和多个 CPU）。 (2) 合理设计和编制表索引 数据库性能的最大问题可能源自于不良数据库设计和缺失索引。SELECT 语句通常是运行在典型 web 应用程序中的最常见的查询类型。它们也是在数据库服务器上运行的最耗时的查询。此外，这些类型的 SQL 语句对适当的索引和数据库设计最敏感，因此查看以下指示，获取实现最优性能的技巧。 确保每个表都有一个主键。这为表提供一个默认顺序和快速方式来联接其他表。 确保一个表中的任何外键（即链接记录到另一个表中的记录的键）的索引得到合理编制。许多数据库会自动对这些键施加约束，以便值真正匹配另一个表中的一条记录，这有助于摆脱这一困难。 试图限制一个表中的列数。一个表中有太多列比仅有一些列时进行查询所需的扫描时间要长。此外，如果您有不常用的含多个列的一个表，您也在通过 NULL 值字段浪费磁盘空间。文本或 blob 等可变大小字段也是如此，其中表大小的增长可以远超过需求。在这种情况下，您应当考虑将其他栏分成不同的表，在记录的主键上将其联合起来。 (3) 分析在服务器上运行的查询 改进数据库性能的最佳方法是分析在您的数据库服务器上运行什么查询，且运行它们需要多长时间。几乎每个数据库都有具有这种功能的工具。对于 MySQL，您可以利用慢查询日志来查找有问题的查询。要使用它，在 MySQL 配置文件中将 slow_query_log 设置为 1，然后将 log_output 设置为 FILE，将它们记录到文件 hostname-slow.log 中。您可以设置 long_query_time 阈值，确定查询必须运行多少秒才被看作是 “慢查询”。我想建议将该阈值首先设置为 5 秒，随着时间的推移将其缩减为 1 秒，具体取决于您的数据集。如果您探究该文件，您会看到类似于清单 1 的详细查询。 /usr/local/mysql/bin/mysqld, Version: 5.1.49-log, started with:Tcp port: 3306  Unix socket: /tmp/mysql.sockTime                 Id Command    Argument# Time: 030207 15:03:33# User@Host: user[user] @ localhost.localdomain [127.0.0.1]# Query_time: 13  Lock_time: 0  Rows_sent: 117  Rows_examined: 234use sugarcrm;select * from accounts inner join leads on accounts.id = leads.account_id; 我们想要考虑的关键对象是 Query_time，显示查询需要的时间。另一项要考虑的是 Rows_sent和 Rows_examined 的数量，因为这些可指这样的情况：其中如果一个查询察看太多行或返回太多行，就会被错误地书写。您可以更深入地钻研如何写查询，即在查询开始处加上 EXPLAIN，它会返回查询计划，而非结果集，如清单 2 所示。 mysql> explain select * from accounts inner join leads on accounts.id = leads.account_id;+----+-------------+----------+--------+--------------------------+---------+---| id | select_type | table    | type   | possible_keys            | key     | key_len | ref                       | rows | Extra |+----+-------------+----------+--------+--------------------------+---------+--------|  1 | SIMPLE      | leads    | ALL    | idx_leads_acct_del       | NULL    | NULL    | NULL                      |  200 |       ||  1 | SIMPLE      | accounts | eq_ref | PRIMARY,idx_accnt_id_del | PRIMARY | 108    | sugarcrm.leads.account_id |    1 |       |+----+-------------+----------+--------+--------------------------+---------+---------2 rows in set (0.00 sec) MySQL 手册更深入探究 EXPLAIN 输出的主题，但是我考虑的一项重要内容是 ‘type’ 列为 ‘ALL’ 的地方，因为这需要 MySQL 做一个全表扫描，且不需要键来执行查询。这些帮助您在添加索引时会大幅提高查询速度。 5. 有效缓存数据 正如我们在上一节看到的，数据库往往容易成为您 web 应用程序性能的最大痛点。但是如果您要查询的数据不经常改变怎么办？在这种情况下，一个好的选择就是在本地存储这些结果，而非针对每个请求调用查询。 我们之前探究的两个操作码缓存 APC 和 Wincache 具有实现上述操作的工具，其中您可以将 PHP 数据直接存储到一个共享内存段中，便于快速查询。清单 3 提供了具体示例。 1234567891011121314151617 <?phpfunction getListOfUsers(){    $list = apc_fetch('getListOfUsers');     if ( empty($list) ) {        $conn = new PDO('mysql:dbname=testdb;host=127.0.0.1', 'dbuser', 'dbpass');        $sql = 'SELECT id, name FROM users ORDER BY name';        foreach ($conn-&gt;query($sql) as $row) {            $list[] = $row;        }         apc_store('getListOfUsers',$list);    }     return $list;} 我们仅需一次执行查询。之后，我们将结果推送到 getListOfUsers 键下的 APC 缓存中。从这里开始，直到缓存到期，您就能够直接从缓存中获取结果数组，跳过 SQL 查询。 APC 和 Wincache 并非一个用户缓存的惟一选择；memcache 和 Redis 是不需要您在与 Web 服务器相同的服务器上运行用户缓存的其他流行选择。这就提高了性能和灵活性，特别是当您的 web 应用程序跨多个 Web 服务器向外扩展时。   在本文中，我们探究了调优您的 LAMP 性能的 5 种简单方法。我们不仅通过利用一个操作码缓存和优化 PHP 配置探究了 PHP 级别的技术，而且探究了如何优化您的数据库设计来实现合理的索引编制。我们还探讨了如何利用一个用户缓存（以 APC 为例）来展示如何在数据不经常改变时避免重复的数据库调用。","title":"分享_调优LAMP的5种简单方法"},{"content":"GPRS怎样将数据传入数据库，我在做远程监控的课题，本人小硕，望大牛指点迷津，并推荐相关好书书本以供学习 利用TCP/IP协议将数据终端采集的数据发送到SQL数据库，有什么协议，怎样规定的？还有这些采集的数据参数不同，数据类型不同，存入到数据库中的数据表也不同，如何设置将这些采集的数据准确无误的发送到数据库，另外采用C/S模式进行访问，核心技术该如何呢？望大牛们推荐好的网站或书本给本人，好好专研 关键问题： ① 监听TCP端口；② 接收数据包分析数据、存储数据，发送接收应答帧；③ 显示接收到的数据 服务器接收程序怎样设计？才能正确接收IP数据包并正确解析存入数据库，网上资料太多，但在这点不够深入、详细，一看到这就有点迷惑关键设计的具体程序，不知所措而遥望长空，无法释怀 求助求助，万望众网友勿爱莫能助","title":"旧贴重发"},{"content":"一、nomount状态 数据库启动到nomount状态后会创建Instance，分配相应的内存区域，启动先应的后台进程。启动过程可以在告警日志文件（alert_<ORACLE_SID>.log）中查阅到，这一过程会对去参数文件，使用参数启动实例。 二、v$process视图 通过v$process视图，可以找到对应于操作系统的每一个进程信息 三、参数文件的选择 spfile<ORACLE_SID>.ora -> spfile.ora -> init<ORACLE_SID>.ora SQL> show parameter spfileNAME\t\t\t\t     TYPE\t VALUE------------------------------------ ----------- ------------------------------spfile\t\t\t\t     string\t $ORACLE_HOME/dbs/spfile<SID>.ora 四、实例启动最小参数需求 实例启动的最小参数需求是DB_NAME。 如果不设置background_dump_dest目录（告警日志文件的存放地点）缺省位于$ORACLE_HOME/rdbms/log目录下： SQL> show parameter background_dumpNAME\t\t\t\t     TYPE\t VALUE------------------------------------ ----------- ------------------------------background_dump_dest\t\t     string\t /home/oracle/app/oracle/diag/r\t\t\t\t\t\t dbms/orcl/orcl/trace其它几个缺省路径地点： SQL> show parameter dump_destNAME\t\t\t\t     TYPE\t VALUE------------------------------------ ----------- ------------------------------background_dump_dest\t\t     string\t /home/oracle/app/oracle/diag/r\t\t\t\t\t\t dbms/orcl/orcl/tracecore_dump_dest\t\t\t     string\t /home/oracle/app/oracle/diag/r\t\t\t\t\t\t dbms/orcl/orcl/cdumpuser_dump_dest\t\t\t     string\t /home/oracle/app/oracle/diag/r\t\t\t\t\t\t dbms/orcl/orcl/trace SQL> show parameter control_fileNAME\t\t\t\t     TYPE\t VALUE------------------------------------ ----------- ------------------------------control_file_record_keep_time\t     integer\t 7control_files\t\t\t     string\t /home/oracle/app/oracle/oradat\t\t\t\t\t\t a/orcl/control01.ctl, /home/or\t\t\t\t\t\t acle/app/oracle/flash_recovery\t\t\t\t\t\t _area/orcl/control02.ctl 五、ORACL_SID的含义 ORACLE_SID就是Oracle System IDentifier的缩写，当Oracle实例启动时，在操作系统上fork的进程就一句这个ORACLE_SID来创建。 Oracle的实例是由一块共享内存区域（SGA）和一组后台进程共同组成的，而后台进程是数据库和操作系统进行交互的通道，这些进程的名称就是通过ORACLE_SID决定的。 ORACLE_SID还决定实例启动时所需参数文件的名称。 在不同的$ORACLE_HOME下，即使在同一台主机上，Oracle也能够创建相同ORACLE_SID的实例。 六、INSTANCE_NAME的含义 Oracle数据库内部存在一个初始化参数INSTANCE_NAME，用于表示数据库实例的名称，其缺省值通常就是ORACLE_SID；INSTANCE_NAME与ORACLE_SID可以不同，不同的实例也可以用于相同的INSTANCE_NAME. 在同一个ORACLE_HOME下，只要ORACLE_SID不同，数据库并不校验INSTANCE_NAME参数。 在数据库内部视图v$instance中也记录着一个INSTANCE_NAME，这个INSTANCE_NAME来自数据库实例的SID，始终和ORACLE_SID保持一致，这就可能出现数据库中这两个INSTANCE_NAME不一致的情况。 从Oracle 10g开始，参数文件中缺省不再记录INSTANCE_NAME，此时INSTANCE_NAME可以动态从系统获得。 INSTANCE_NAME除了用来标识实例名称之外，在监听器动态注册时还会用于监听器注册。监听器动态注册信息中的Instance内容就来自INSTANCE_NAME参数设置。 v$instance视图和数据库实例的生命周期相关，用于显示当前实例的状态，通过这个视图可以获得包括实例的启动时间、运行主机等重要信息。 七、DB_NAME与INSTANCE_NAME DB_NAME代表了实例即将挂接的数据库名称，关系到具体的物理文件。通常缺省的数据库INSTANCE_NAME和DB_NAME可以设置相同（在RAC环境下，由于多个实例对应一个数据库，所以INSTANCE_NAME和DB_NAME不同）。 DB_NAME被记录在数据文件、日志文件和控制文件中。如果数据库实例启动过程中参数文件中的DB_NAME和控制文件中的数据库名称不一致，则数据库不能启动。 常见的几个结论有： 一个实例可以MOUNT并打开任何数据库，但是同一时间一个实例只能打开一个数据库。 一个数据库可以被一个或多个实例所MOUNT并打开（在OPS/RAC环境下，一个数据库可以被多个实例所打开） 在非并行模式（OPS/RAC）下，一个数据库同时只能被一个实例加载。 DB_NAME的另外一个作用是在监听器动态注册时作为缺省服务名注册。 参数文件中的db_name和控制文件中的db_name不一致，数据库无法启动，错误提示指定的数据库名称和控制文件中记录的名称不符。 八、RMAN的缺省实例 在使用RMAN（Recovery Manager）时存在更为特殊的情况，Oracle允许在不存在参数文件的情况下启动一个实例，数据库的db_name会被缺省地命名为DUMMY。 九、小结 数据库的nomount过程实质上就是在创建实例，这个步骤只和参数文件相关。","title":"ORACLE学习笔记（一）——数据库启动（nomount）"},{"content":"例子用到的数据库是MySql 添加数据源 创建MFC 基佬于对话框的工程ODBC 在工程里添加头文件 #include \"afxdb.h\" 创建CDatabase类的对象 CDatabase   db; 接下来就是连接数据库了，在OnInitDialog函数里添加 \t//判断数据库是否打开\tif(!db.IsOpen())\t{\t\t//连接数据库,两种open方式\t\tBOOL  flag=db.Open(\"test\",FALSE,FALSE,\"ODBC;UID=root;PWD=2009101185\");//\t\tBOOL  flag=db.Open(\"test\");\t\tif(!flag)\t\t{\t\t\tMessageBox(\"打开数据库失败!\");\t\t\treturn FALSE;\t\t}\t\telse\t\t{\t\t\tMessageBox(\"打开数据库成功!\");\t\t}\t} 接着在对话框中添加一个List Control控件，用来显示数据库表中的内容，为控件关联一个变量m_list \t//设置ListControl控件的状态\tm_list.SetExtendedStyle(LVS_EX_GRIDLINES|LVS_EX_FULLROWSELECT);\tm_list.InsertColumn(0,\"\",LVCFMT_CENTER,0);\tm_list.InsertColumn(1,\"编号\",LVCFMT_CENTER,195);\tm_list.InsertColumn(2,\"姓名\",LVCFMT_CENTER,195);        m_list.DeleteColumn(0);我用来测试的数据库表中只有两个字段，因为MFC不允许修改List Control控件第一列的状态，所以可以通过上面的方式去让界面上的第一列居中（实际是我创建的第二列） 接下来，实例化CRecordset类，CRecordset类代表一个记录集，是MFC的ODBC类中最重要、功能最强大的类。 CRecordset   db_recordset(&db); 接下来就来执行一条SELECT语句，并把结果显示在List Control中 \tCString      str=\"select * from dept\";\t//执行\"select * from dept\"语句\tdb_recordset.Open(CRecordset::forwardOnly,str); 在MSDN里对CRecordset::Open函数的第二个参数有这样一句描述 An SQL SELECT statement (optionally with an SQL WHERE orORDER BY clause). 所以在CRecordset::Open函数只能执行SELECT语句，其它的语句可用CDatabase::ExecuteSQL函数 接下来就是获取查询到的结果了 //获取查询结果，并将结果显示在ListControl控件里\tfor(int i=0;!db_recordset.IsEOF()&&!db_recordset.IsBOF();i++)\t{\t\tdb_recordset.GetFieldValue((short)0,str);\t\tm_list.InsertItem(i,str);\t\tdb_recordset.GetFieldValue((short)1,str);\t\tm_list.SetItemText(i,1,str);\t\tdb_recordset.MoveNext();\t}\tdb_recordset.Close(); 不要忘记调用Close函数关闭CRecordset对象 最后就是关闭CDatabase对象了 db.Close();完整代码运行结果如下，添加了增、删、查、改四个功能","title":"利用ODBC连接数据库"},{"content":"方法 算法思路是从W. Randolph Franklin的这篇文章而来： http://www.ecse.rpi.edu/Homepages/wrf/Research/Short_Notes/pnpoly.html SQL 代码 数据表： polygon polygonID vertexID latitude longitude 1 1 -79.64452 44.06773 1 2 -79.62194 43.97181 1 3 -79.45356 43.92827 1 4 -79.31599 44.02789 1 5 -79.36526 44.13045 1 6 -79.45459 44.04116 下面是SQL函数 ufn_PointInPolygon 的定义，这个函数会判断一个点是否在多边形中。代码在SQL Server 2005中测试通过。 SET ANSI_NULLS ON   GO   SET QUOTED_IDENTIFIER ON   GO   -- =============================================   -- http://www.sql-statements.com/point-in-polygon.html   -- Test: select dbo.ufn_PointInPolygon(-79.37553, 44.06699,1)   -- =============================================   CREATE FUNCTION [dbo].[ufn_PointInPolygon]   (       -- Add the parameters for the function here       @pointLat REAL, @pointLon REAL, @polygonID INT   )   RETURNS INT   AS   BEGIN          DECLARE @insidePolygon INT          DECLARE @nvert INT       DECLARE @lineLat1 REAL       DECLARE @lineLon1 REAL       DECLARE @lineLat2 REAL       DECLARE @lineLon2 REAL          DECLARE @i INT       DECLARE @j INT          SELECT @nvert=count(*) FROM polygon WHERE polygonID=@polygonID          SET @insidePolygon = -1       SET @i=0       SET @j=@nvert-1          WHILE (@i<@nvert)       BEGIN           SELECT @lineLat1 = latitude, @lineLon1 = longitude           FROM polygon           WHERE polygonID=@polygonID AND vertexID = @i              SELECT @lineLat2 = latitude, @lineLon2 = longitude           FROM polygon           WHERE polygonID=@polygonID AND vertexID = @j              IF( ((@lineLon1>@pointLon and @lineLon2<=@pointLon) OR (@lineLon1<=@pointLon and @lineLon2>@pointLon))               AND (@pointLat < (                           (@lineLat2 - @lineLat1) * (@pointLon - @lineLon1) / (@lineLon2 - @lineLon1)    + @lineLat1                       )                   )               )               SET @insidePolygon = -1 * @insidePolygon              SET @j = @i           SET @i = @i + 1          END          IF (@@ERROR <> 0) RETURN 0          RETURN @insidePolygon      END   GO  ","title":"判断 点 是否 在 任意多边形 内部 采用射线法"},{"content":"今天要在mssql里处理一串Email地址。以分号分开的。以前自己写过一个split函数的。这次想使用xml来处理。 mssql 2000和mssql 2005数据库对xml的支持有些不同。至少mssql 2005的功能多些。   --这个代码在MSSQL 2005测试成功。最后生成一个表变量。使用者可以把表变量转成需要的数据declare @cc varchar(1000)set @cc = 'hello@163.com;world@hotmail.com;iloveyou@yahoo.com'declare @emailtable table( email varchar(50))declare @xml xmlset @xml = cast('<email>'+replace(@cc,';','<\/email><email>')+'<\/email>' as xml)insert into @emailtable (email)select t.i.value('.', 'varchar(50)') from @xml.nodes('email') t(i)select * from @emailtable","title":"在MSSQL里把字串转成table变量"},{"content":"环境如下 MySQL安装在192.168.137.100 Ubuntu 12.04 LTS 客户端在 192.168.137.200 win7 客户端希望访问MySQL数据库，会出现如下错误“ERROR 2003 (HY000): Can't connect\u0007 to MySQL server on '192.168.137.100' (10061)” C:\\>mysql -h 192.168.137.100 -u root -pEnter password: ****ERROR 2003 (HY000): Can't connect\u0007 to MySQL server on '192.168.137.100' (10061) 解除地址绑定 这是因为缺省情况下MySQL是只允许本机登录的。修改MySQL的配置文件位于/etc/mysql/my.cnf，不进行地址绑定 # Instead of skip-networking the default is now to listen only on# localhost which is more compatible and is not less secure.#bind-address  = 127.0.0.1  <---注释掉这一行 再次进行访问，错误变成了我这个”ERROR 1130 (HY000): Host 'abbuggy-PC.mshome.net' is not allowed to connect to this MySQL server“。主机不允许连接这个MySQL，看起来已经连上了但是由于权限不够才被拒绝的。 C:\\>mysql -h 192.168.137.100 -u root -pEnter password: ****\u0007ERROR 1130 (HY000): Host 'abbuggy-PC.mshome.net' is not allowed to connect to this MySQL server 进行授权 有两种方法，直接修改表内容或者通过授权命令 改表法 将 \"mysql\" 数据库的 \"user\" 表里的 \"host\" 字段，从\"localhost\"改为\"%\"。%相当于所有地址，也可以指定某些地址。 ~$ mysql -uroot -proot>use mysql;>update user set host = '%' where user = 'root'>SELECT host, user FROM user; 授权法 例如，你想用root从任何主机连接到mysql服务器的话。 >GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'root' WITH GRANT OPTION; 如果你想允许用户myuser从ip为192.168.137.100的主机连接到mysql服务器，并使用root作为密码 GRANT ALL PRIVILEGES ON *.* TO 'root'@'192.168.137.100' IDENTIFIED BY 'root' WITH GRANT OPTION; 问题得到解决","title":"通过非本机访问MySQL报 ERROR 2003 和 ERROR 1130 问题解决方法"},{"content":"如何得到一个sql server 数据库连接字符串 步骤： 1、新建一个txt文本文档，然后把后缀名改为udl 2、打开  新建文本文档.udl ，并选择相应的数据库进行连接，之后点击 “测试连接”，成功之后关闭。 3、将后缀名改回txt，打开txt文本文档就可以看到已经创建好了数据库连接字符串了。","title":"如何得到一个sql server 数据库连接字符串"},{"content":"首先，我们开始回顾一下T-SQL的基本语法： 函数 abs(x)：求绝对值； 例： 　　　select abs(-3)   　　值为：3 sqrt(x)：求平方根； 例： 　　　select sqrt(4) 　　  值为：2.0 rand([0])：返回0~1之间的随机float值； floor(X)：返回小于或等于X值的最大整数； 例:　　　　select floor(34.5) 　　值为：34 ceiling(X)：返回大于或等于X值的最小整数； 例：　　　　select ceiling(34.5)　　值为：35 round(x，length)：四舍五入函数，length为正，则对X小数位数四舍五入，length为负，则对X从小数点左边length位起四舍五入，若length既为负数且其绝对值大于X整数部分 数字个数，则函数值为0； 例：　　　　select ROUND(63.567, 1) 　  　　值为：63.600　　　　　　select ROUND(63.567, -1)  　　　值为：60.000　　　　　　select ROUND(63.567, 0) 　　　  值为：64.000　　　　　　select ROUND(63.567, -3) 　　    值为：0.000 Sign(X)：求符号函数，X>0则sign(x)=1; X=0 则sign(X)=0;X<0 则sign(X)=-1 例：　　　　　select sign(-3)    　　　 值为：-1　　　　  　　select sign(3)  　　　　　 值为：1　　　　  　　select sign(0) 　　　　    值为：0 Power(X,y)：求X的y次方； 例：　　　　select power(4,2)  　　值为 ：16 字符串函数 ASCII(串)：返回字符表达式最左端字符的ASCII 码值； 例：　　　　select ASCII('bc') 　　值为：98 CHAR(ASCII码)：用于将ASCII 码转换为字符，如果没有输入0 ~ 255 之间的ASCII 码值，返回值为NULL ； 例：　　　　select char(97)  　　值为：a Lower(串)：把字符串全部转换为小写；　　　　 例：　　　　select lower('QingPingGuo')   　　值为： qingpingguo Upper(串) ：把字符串全部转换为大写； 例：　　　　select upper('QingPingGuo')  　　值为： QINGPINGGUO LTrim(串), RTrim(串)：去掉左右空格； 例(去左空格)：　　select '博客园'+LTrim('   青苹果   ')+'博客园'  　　值为：博客园青苹果    博客园 space(个数)：返回指定个数的空格； replicate(串,次数)：将串重复指定次数； 例：　　　　select replicate('青苹果',2)　　　　值为：青苹果青苹果 Left(串, 个数)：返回已知串从左边开始指定个数的字符； 例：　　　　select left('青苹果在博客园', 4)　　　　值为：青苹果在 Right(串, 个数)：返回已知串从右边开始指定个数的字符； 例：　　　　select right('青苹果在博客园', 4)　　　　值为：在博客园 DataLength(串)：返回串的字节数长度，计算串尾空格。可以用它检查varchar，text等的动态长度； 例：　　　　select datalength('青苹果在博客园')　　　　值为：14 SubString(串, 开始位置, 长度)：返回从字符串左边’开始位置’起数量为’长度’的字符串。其中表达式可以是字符串或二进制串或含字段名或字符型变量的表达式。在这里要注意一下SUBSTRING（）函数不能用于TEXT 和IMAGE 数据类型； 例：　　　　select substring('青苹果在博客园',5,2) 　　　　值为：博客 Len(串) ：返回表达式的长度。注意它返回的是字符数，而不是字节数。不计算串尾空格； 例：　　　　select   len('青苹果cnblogs    ')　　　　　　值为：10 Replace('串1','串2','串3')：用串3替换串1中出现的所有串2字符； 例：　　　　select replace('青苹果在北京','北京','博客园')　　　　值为：青苹果在博客园 Stuff(串1, 开始位置, 长度, 串2)：删除串1指定位置开始指定长度的字符串，并在指定位置插入串2； 例：　　　　select stuff('青苹果是程序猿吗？',5,3,'攻城狮')　　　　值为：青苹果是攻城狮吗？ reverse(串) ：将指定的字符串的字符排列顺序颠倒； 例：　　　　select reverse('12345')　　　　值为：54321 charindex(串1，串2)：返回串1在串2的开始位置，可从所给出的‘开始位置’进行查找； 例：　　　　select charindex('guo','qingpingguo')　　　　值为：9 转换函数 所谓转换函数就是把某种数据类型转换的表达式显示转换成另一种数据类型的函数。 CAST(表达式 AS 数据类型[(长度)]) 例：　　select  '今天是：' + Cast(GetDate() as char(10))　　值为：今天是：07 23 2012 CONVERT(转换后的目标数据类型[(length)],表达式[style]) 例：　　select  '今天是：' +convert(char(10),getdate())    值为：今天是：07 23 2012 下面来看一个求差值的函数datediff函数； DATEDIFF(datepart,date1,date2) 例：　　select  datediff(yy,'1988.09.14','2012.12.21')　　值为：24　　　　select  datediff(mm,'1988.09.14','2012.12.21')　　值为：291 聚合函数 聚合函数也就是统计函数，它主要是对一组值进行计算，它的功能分别是：求和(sum)、求最小(min)、求最大(max)、求总行数(count)、求平均值(avg) 例：　　 求和：select sum(Name) from TableName    　  求最小：select min(Name) from TableName     　 求最大：select max(Name) from TableName    　　求总数：select count(Name) from TableName    　　求平均：select avg(Name) from TableName T-SQL的一些关键字 Print 向客户端返回用户信息 例：　　print '青苹果'         屏幕上就会显示“青苹果三个字“ Go 用来通知SQL一批语句的结束 Distinct 去掉重复值 Declare 用来声明变量 例：　　declare @a int Set 为变量赋值 例：　　set @a='青苹果' While 在SQL中用来循环(好像在SQL中用来做循环的关键字不多) 语法：　　　　WHILE <条件表达式>                 BEGIN                    <命令行或程序块>                   [BREAK]                   [CONTINUE]                   [命令行或程序块]                 END While比较重要，我们来做个例子加深一下对While循环的理解： declare @a intset @a=1while @a<5begin print '青苹果'set @a=@a+1end 输出结果：青苹果 　　　　　青苹果 　　　　　青苹果 　　　　　青苹果 if else 判断语句 判断语句用的还是比较多的我们还是来做个例子说明一下； 求：a、b、c三个数的最大值？ declare  @a int,@b int,@c int,@max  intset @a=1 set @b=2 set @c=3 if  @a>@b                  set  @max=@aelse   set  @max=@bif  @max<@c   set  @max=@c      print   @max 输出结果：3 begin end 用来设定一个程序块，将在BEGIN…END内的所有程序视为一个单元执行。 Exists 判断是否存在 Case 也是用来判断的，和IF语句差不多，它的格式为： 　CASE  <运算式>     　　 WHEN <运算式1> THEN  <结果1>          …            WHEN<运算式n> THEN   <结果n>          [ELSE  <结果n+1>]  END Return 　　用于结束当前程序的执行，返回到上一个调用它的程序或其它程序。在括号内可指定一个返回值。 Goto标示符 用来改变程序执行的流程，使程序跳到标有标识符的指定的程序行再继续往下执行。要注意的是作为跳转目标的标识符可为数字与字符的组合，但必须以“：”结尾，如：“1023：” “qingpingguo:” 例子：        declare @a int      　　set @a = 1  　　　　　qingpignguo:       　　　　　print @a            　　set @a = @a + 1      　　while @a < 6     　　　　goto qingpignguo 输出结果：12345 最后一个给大家看个好玩的： Waitfor 用来暂停程序执行，直到等待指定时间之后，或所设定的时间已到才继续往下运行程序。 语法：　　waitfor {delay '时间'|time '时间'} 解释： （1）‘时间’必须为DATETIME类型数据，且不能包括日期，如‘10:12:05’ （2）DELAY:用来设定等待的时间长短，最多为24小时。(是一个时间间隔) （3）TIME：用来设定等待结束的时间点（是一个具体的时间) 例子：    waitfor  delay '00:00:03' 　　print '你好,我是青苹果' 　　go 以上就是T-SQL的所有内容了，接下来我们来利用最后的时间画几个图形： 直角三角形： declare @a int set @a=1while(@a<11)beginprint replace(space(@a),' ','*')set @a=@a+1end 直角三角形 输出结果： 正方形： declare @a intdeclare @b intdeclare @c nvarchar(100)set @a=1set @b=1set @c=''while (@a<9)begin   while (@b<15)   begin     set @c=@c+'*'    set @b=@b+1   end    print @c set @a=@a+1end 正方形 输出结果： 菱形： declare @a int,@b intset @a=1 set @b=15if(@b%2!=1)print '数字必须都是奇数'elsewhile(@a<=@b)beginif(@a%2=1)print space((@b-@a)/2)+replace(space(@a),' ','*')+space((@b-@a)/2)set @a=@a+1endset @a=@a-2while (@a<=@b)beginif(@a%2=1)print space((@b-@a)/2)+replace(space(@a),' ','*')+space((@b-@a)/2)set @a=@a-1    if (@a<0)breakend 菱形 输出结果： 梯形： declare @a int,@b intset @a=7 set @b=21if(@a%2=1)while(@a<@b)beginprint space((@b-@a)/2)+replace(space(@a),' ','*')+space((@b-@a)/2)set @a=@a+2end 梯形 输出结果： 矩形： declare @a intdeclare @b intdeclare @c nvarchar(100)set @a=1set @b=1set @c=''while (@a<9)begin   while (@b<23)   begin     set @c=@c+'*'    set @b=@b+1   end    print @c set @a=@a+1end 矩形 输出结果： 圆形： declare @a int,@b intset @a=9 set @b=13while (@a<=@b)beginif(@a%2=1)print space((@b-@a)/2)+replace(space(@a),' ','*')+space((@b-@a)/2)set @a=@a+1endset @a=@a-1beginprint space((@b-@a)/2)+replace(space(@a),' ','*')+space((@b-@a)/2)endwhile (@a<=@b)beginif(@a%2=1)print space((@b-@a)/2)+replace(space(@a),' ','*')+space((@b-@a)/2)set @a=@a-1if(@a<10)breakendset @a=@a-2beginprint space((@b-@a)/2)+replace(space(@a),' ','*')+space((@b-@a)/2)end 圆形输出结果： The End! 以上就是本文的所有内容，可能写的不够全面，有不足的地方希望大家多多补充，多多发表意见","title":"SQL语句【T-SQL汇总】"},{"content":"  0   或   100   (*)     默认值   mon   dd   yyyy   hh:miAM（或   PM）        1   101   美国   mm/dd/yyyy        2   102   ANSI   yy.mm.dd        3   103   英国/法国   dd/mm/yy        4   104   德国   dd.mm.yy        5   105   意大利   dd-mm-yy        6   106   -   dd   mon   yy        7   107   -   mon   dd,   yy        8   108   -   hh:mm:ss        -   9   或   109   (*)     默认值   +   毫秒   mon   dd   yyyy   hh:mi:ss:mmmAM（或   PM）        10   110   美国   mm-dd-yy        11   111   日本   yy/mm/dd        12   112   ISO   yymmdd        -   13   或   113   (*)     欧洲默认值   +   毫秒   dd   mon   yyyy   hh:mm:ss:mmm(24h)        14   114   -   hh:mi:ss:mmm(24h)        -   20   或   120   (*)     ODBC   规范   yyyy-mm-dd   hh:mm:ss[.fff]        -   21   或   121   (*)     ODBC   规范（带毫秒）   yyyy-mm-dd   hh:mm:ss[.fff]        -   126(***)   ISO8601   yyyy-mm-dd   Thh:mm:ss:mmm（不含空格）        -   130*   科威特   dd   mon   yyyy   hh:mi:ss:mmmAM        -   131*   科威特   dd/mm/yy   hh:mi:ss:mmmAM    Sql Server 中一个非常强大的日期格式化函数 Select CONVERT(varchar(100), GETDATE(), 0): 05 16 2006 10:57AM Select CONVERT(varchar(100), GETDATE(), 1): 05/16/06 Select CONVERT(varchar(100), GETDATE(), 2): 06.05.16 Select CONVERT(varchar(100), GETDATE(), 3): 16/05/06 Select CONVERT(varchar(100), GETDATE(), 4): 16.05.06 Select CONVERT(varchar(100), GETDATE(), 5): 16-05-06 Select CONVERT(varchar(100), GETDATE(), 6): 16 05 06 Select CONVERT(varchar(100), GETDATE(), 7): 05 16, 06 Select CONVERT(varchar(100), GETDATE(), 8): 10:57:46 Select CONVERT(varchar(100), GETDATE(), 9): 05 16 2006 10:57:46:827AM Select CONVERT(varchar(100), GETDATE(), 10): 05-16-06 Select CONVERT(varchar(100), GETDATE(), 11): 06/05/16 Select CONVERT(varchar(100), GETDATE(), 12): 060516 Select CONVERT(varchar(100), GETDATE(), 13): 16 05 2006 10:57:46:937 Select CONVERT(varchar(100), GETDATE(), 14): 10:57:46:967 Select CONVERT(varchar(100), GETDATE(), 20): 2006-05-16 10:57:47 Select CONVERT(varchar(100), GETDATE(), 21): 2006-05-16 10:57:47.157 Select CONVERT(varchar(100), GETDATE(), 22): 05/16/06 10:57:47 AM Select CONVERT(varchar(100), GETDATE(), 23): 2006-05-16 Select CONVERT(varchar(100), GETDATE(), 24): 10:57:47 Select CONVERT(varchar(100), GETDATE(), 25): 2006-05-16 10:57:47.250 Select CONVERT(varchar(100), GETDATE(), 100): 05 16 2006 10:57AM Select CONVERT(varchar(100), GETDATE(), 101): 05/16/2006 Select CONVERT(varchar(100), GETDATE(), 102): 2006.05.16 Select CONVERT(varchar(100), GETDATE(), 103): 16/05/2006 Select CONVERT(varchar(100), GETDATE(), 104): 16.05.2006 Select CONVERT(varchar(100), GETDATE(), 105): 16-05-2006 Select CONVERT(varchar(100), GETDATE(), 106): 16 05 2006 Select CONVERT(varchar(100), GETDATE(), 107): 05 16, 2006 Select CONVERT(varchar(100), GETDATE(), 108): 10:57:49 Select CONVERT(varchar(100), GETDATE(), 109): 05 16 2006 10:57:49:437AM Select CONVERT(varchar(100), GETDATE(), 110): 05-16-2006 Select CONVERT(varchar(100), GETDATE(), 111): 2006/05/16 Select CONVERT(varchar(100), GETDATE(), 112): 20060516 Select CONVERT(varchar(100), GETDATE(), 113): 16 05 2006 10:57:49:513 Select CONVERT(varchar(100), GETDATE(), 114): 10:57:49:547 Select CONVERT(varchar(100), GETDATE(), 120): 2006-05-16 10:57:49 Select CONVERT(varchar(100), GETDATE(), 121): 2006-05-16 10:57:49.700 Select CONVERT(varchar(100), GETDATE(), 126): 2006-05-16T10:57:49.827 Select CONVERT(varchar(100), GETDATE(), 130): 18 ???? ?????? 1427 10:57:49:907AM Select CONVERT(varchar(100), GETDATE(), 131): 18/04/1427 10:57:49:920AM 常用： Select CONVERT(varchar(100), GETDATE(), 8): 10:57:46 Select CONVERT(varchar(100), GETDATE(), 24): 10:57:47 Select CONVERT(varchar(100), GETDATE(), 108): 10:57:49 Select CONVERT(varchar(100), GETDATE(), 12): 060516 Select CONVERT(varchar(100), GETDATE(), 23): 2006-05-16 SQL中CONVERT转化函数的用法 CONVERT的使用方法: //////////////////////////////////////////////////////////////////////////////////////// 格式: CONVERT(data_type,e xpression[,style]) 说明: 此样式一般在时间类型(datetime,smalldatetime)与字符串类型(nchar,nvarchar,char,varchar) 相互转换的时候才用到. 例子: Select CONVERT(varchar(30),getdate(),101) now 结果为 now --------------------------------------- 09/15/2001 ///////////////////////////////////////////////////////////////////////////////////// style数字在转换时间时的含义如下 ------------------------------------------------------------------------------------------------- Style(2位表示年份) | Style(4位表示年份) | 输入输出格式 ------------------------------------------------------------------------------------------------- - | 0 or 100 | mon dd yyyy hh:miAM(或PM) ------------------------------------------------------------------------------------------------- 1 | 101 | mm/dd/yy ------------------------------------------------------------------------------------------------- 2 | 102 | yy-mm-dd ------------------------------------------------------------------------------------------------- 3 | 103 | dd/mm/yy ------------------------------------------------------------------------------------------------- 4 | 104 | dd-mm-yy ------------------------------------------------------------------------------------------------- 5 | 105 | dd-mm-yy ------------------------------------------------------------------------------------------------- 6 | 106 | dd mon yy ------------------------------------------------------------------------------------------------- 7 | 107 | mon dd,yy ------------------------------------------------------------------------------------------------- 8 | 108 | hh:mm:ss ------------------------------------------------------------------------------------------------- - | 9 or 109 | mon dd yyyy hh:mi:ss:mmmmAM(或PM) ------------------------------------------------------------------------------------------------- 10 | 110 | mm-dd-yy ------------------------------------------------------------------------------------------------- 11 | 111 | yy/mm/dd ------------------------------------------------------------------------------------------------- 12 | 112 | yymmdd ------------------------------------------------------------------------------------------------- - | 13 or 113 | dd mon yyyy hh:mi:ss:mmm(24小时制) ------------------------------------------------------------------------------------------------- 14 | 114 | hh:mi:ss:mmm(24小时制) ------------------------------------------------------------------------------------------------- - | 20 or 120 | yyyy-mm-dd hh:mi:ss(24小时制) ------------------------------------------------------------------------------------------------- - | 21 or 121 | yyyy-mm-dd hh:mi:ss:mmm(24小时制","title":"SQL日期格式化"},{"content":"SELECT CONVERT(VARCHAR , GETDATE (), 120 ) 2012-12-08 09:51:22 SELECT replace(REPLACE (REPLACE (CONVERT(VARCHAR , GETDATE (), 120 ),'-',''),'',''),':','') 20121208 095139 SELECT CONVERT(VARCHAR (12) , GETDATE (), 111 ) 2012/12/08 SELECT CONVERT(VARCHAR (12) , GETDATE (), 112 ) 20121208 SELECT CONVERT(VARCHAR (12) , GETDATE (), 102 ) 2012.12.08 SELECT CONVERT(VARCHAR (12) , GETDATE (), 101 ) 12/08/2012 SELECT CONVERT(VARCHAR (12) , GETDATE (), 103 ) 08/12/2012 SELECT CONVERT(VARCHAR (12) , GETDATE (), 104 ) 08.12.2012 SELECT CONVERT(VARCHAR (12) , GETDATE (), 105 ) 08-12-2012 SELECT CONVERT(VARCHAR (12) , GETDATE (), 106 ) 08 Dec 2012 SELECT CONVERT(VARCHAR (12) , GETDATE (), 107 ) Dec 08, 2012 SELECT CONVERT(VARCHAR (12) , GETDATE (), 108 ) 09:54:50 SELECT CONVERT(VARCHAR (12) , GETDATE (), 109 ) Dec  8 2012 SELECT CONVERT(VARCHAR (12) , GETDATE (), 110 ) 12-08-2012 SELECT CONVERT(VARCHAR (12) , GETDATE (), 113 ) 08 Dec 2012 SELECT CONVERT(VARCHAR (12) , GETDATE (), 114 ) 09:56:03:770  ","title":"日期转换参数,值得收藏"},{"content":"--查询所有数据库 use master select * from sysdatabases where dbid>4;--系统自带的数据库分别是master->1,model->3,msdb->4,tempdb->2 --查询数据库中所有数据库（存储过程） exec sp_helpdb; --查询指定数据库中的表 use master select * from sysobjects where xtype='u' ; if object_id('#test1') is not null drop table #test1 go create table #test1 ( id int not null primary key, name nvarchar default('haha') ) drop table #test1 set nocount off select name from sysobjects where xtype='u'--读数据库中表名 select name from syscolumns where id=(select max(id) from sysobjects where xtype='u' and name='表名')--读取某表的列名 --exec调用保存在变量中的批处理代码 declare @sql as varchar(100); set @sql='print''this is a message......;'';'; exec(@sql) ---------------------------------------- --DDL--数据定义语言 --DML--数据操作语言 --数据库定期备份 if day(current_timestamp)=9 begin print '今天是一个月的第一天，数据库备份' print '开始完全备份' backup database dbtest to disk='E:\\backup\\backup_dbtest_full.bak' with init; print '完全备份成功' end else begin print '今天是一个月的最后一天，数据库备份' print '开始差异备份' backup database dbtest to disk='E:\\backup\\backup_dbtest_diff.bak' with differential; print '差异备份成功' end ------------------------------------------------------------ use tempdb; if object_id('dbo.Orders','u') is not null drop table dbo.Orders; create table dbo.Orders ( orderid int not null constraint pk_order primary key, orderdate datetime not null constraint def_orderdate default(current_timestamp) ) ----------------子查询-------------------------------------------- --子查询分为1-独立子查询2-相关子查询 --返回结果可以是一个单独的值（标量）或者多个值或者整个表变量 declare @maxid as int = (select max(orderid) from Sales.Orders); select orderid,orderdate,empid,custid from Sales.Orders where orderid=@maxid; --sql2005 select orderid,orderdate,empid,custid from Sales.Orders where orderid=(select max(orderid) from Sales.Orders); --对于有效的标量子查询，它的返回值不能超过一个，如果标量子查询返回了多个值，在运行时可能会失败。 --比如 select orderid from Sales.Orders where empid=(select E.empid from HR.Employees as E where E.lastname like N'B%') select E.lastname from HR.Employees as E --因为恰巧该表中只有一个人的名字是以B开头的所以,sql会认为右边子查询是标量值 --假如右边表达式没有返回任何值，那么两者比较得出的结果是NULL,而与NULL比较的结果都为UNKNOW，所以不会返回任何值 --当然上面的查询还可以用联结查询 select O.orderid from HR.Employees as E join Sales.Orders as O on E.empid=O.empid where E.lastname like N'D%' --独立多值子查询IN------ --<标量表达式> IN <多值子查询> --用某表的偶数行数据填充tempdb use tempdb select * into dbo.tempdb from TSQLFundamentals2008.Sales.Orders where orderid%2=0; select * from tempdb; --返回tempdb中介于min(orderid)与max(orderid)并且不在表中的orderid select n from tempdb where n between (select min(O.orderid) from tempdb as O) and (select max(E.orderid) from tempdb as E) and n not in(select orderid from tempdb); -------------------------游标使用------------------------------------------- --游标通常步骤 --1.在某个查询的基础上声明游标 --2.打开游标 --3.从第一个游标记录中把列值提取到指定的变量 --4.当还没有超出游标最后一行时，（@@fetch_status函数返回值为0），循环遍历游标记录，在每一次遍历中，从当前游标记录把列 --值提取到指定的变量，再为当前执行相应的处理 --5.关闭游标 --6.释放游标 use TSQLFundamentals2008 declare @result table ( custid int, ordermonth datetime, qty int, runqty int, primary key(custid,ordermonth) ); declare @custid as int, @prvcustid as int, @ordermonth as datetime, @qty as int, @runqty as int; declare c cursor fast_forward for select custid,ordermonth,qty from Sales.CustOrders order by custid,ordermonth; open c fetch next from c into @custid,@ordermonth,@qty; select @prvcustid=@custid,@runqty=0; while @@fetch_status=0 begin if @custid<>@prvcustid set @runqty=@runqty+@qty; insert into @result values(@custid,@ordermonth,@qty,@runqty); fetch next from c into @custid,@ordermonth,@qty; end close c; deallocate c; select custid,convert(varchar(7),ordermonth,121) as ordermonth,qty,runqty from @result order by custid,ordermonth; ------------------------------------------- --1）接受数据导入的表已经存在。 insert into t1 select * from OPENROWSET('MICROSOFT.JET.OLEDB.4.0' , 'Excel 5.0;HDR=YES;DATABASE=c:\\\\test.xls',sheet1$); --2）导入数据并生成表。 select * into t1 from OPENROWSET('MICROSOFT.JET.OLEDB.4.0', 'Excel 5.0;HDR=YES;DATABASE=c:\\\\test.xls',sheet1$); -- --3) 导入Excel中指定的列到数据库表中指定的列。 INSERT INTO t1(a1,a2,a3) SELECT a1,a2,a3 FROM OPENROWSET 'MICROSOFT.JET.OLEDB.4.0' ,'Excel5.0; HDR=YES; DATABASE=c:\\\\test.xls',sheet1$); -- --需要注意的地方。 --1）外围应用配置器的设置。 -- 从“功能外围应用配置器”中选择“启动 OPENROWSET 和 OPENDATASOURCE 支持”选项。 --2）关闭Excel表。 -- 如果在导入时要导入的Excel表格处于打开状态，会提示： -- “无法初始化链接服务器 \"(null)\" 的 OLE DB 访问接口 \"microsoft.jet.oledb.4.0\" 的数据源对象。” --3）导入数据时，Excel的首行会作为表头，若导入到已存在的数据库表，则忽略首行。 --------------------------------------直接从数据库将表导出到EXCEL------------------------------------------------------------- EXEC master..xp_cmdshell 'bcp master.dbo.t2 out d:\\Temp.xls -c -q -S\"127.0.0.1\" -U\"sa\" -P\"123456\"' --参数：S 是SQL服务器名；U是用户；P是密码   --查询优化------------------------------------------ set nocount on; use master; if db_id('performance') is null create database performance; go use performance; go --创建填充的数字辅助表 set nocount on; if object_id('dbo.nums','u') is not null drop table nums; create table dbo.nums(n int not null primary key); declare @max as int,@rc as int; set @max=1000; set @rc=1; insert into dbo.nums(n) values(1); while @rc*2<=@max begin insert into dbo.nums(n) select n+@rc from dbo.nums; set @rc=@rc*2; end insert into dbo.nums(n) select n+@rc from dbo.nums where n+@rc<=@max; go --如果数据表存在，则先删除 ------------------------------------------------------------ use insideTSQL2008; set nocount off; select orderid,custid from sales.orders where orderid=(select max(orderid) from sales.orders );--取出orderid最大的订单信息（标量子查询） -------相关子查询,返回每个客户最大的订单信息 select orderid,custid from sales.orders as T1 where orderid=(select max(orderid) from sales.orders as T2 where T1.custid=T2.custid) order by custid; ---在期待多个值的地方可以使用多值子查询,返回下过订单的客户 select custid,companyname from sales.customers where custid not in (select custid from sales.orders); --在期待表的地方还可以使用 表值子查询 或 表表达式 --查询每个订单年份返回最大的订单ID select * from sales.orders; select * from sales.customers; select order_year,max(orderid) as max_orderid from (select orderid,year(orderdate) as order_year from sales.orders) as T1 group by order_year; --子查询可以按两种方式进行分类，按期望值的数量可以分为标量子查询，多值子查询 --按子查询对外部的依赖，分为独立子查询，相关子查询，标量子查询和多值子查询既可以是独立子查询，也可以是相关子查询 --查询由每个美国雇员至少为其处理过的一个订单的所有客户 --假设知道美国雇员的empid是1，2，3，4，8 --(1) select custid from sales.orders where empid in(1,2,3,4,8) group by custid having count( distinct empid)=5; --(2) select custid from sales.orders where empid in (select empid from hr.employees where country='usa') group by custid having count(distinct empid)=5 --返回每个月最后实际订单日期发生的订单 select orderid,custid,empid,orderdate from sales.orders where orderdate in( select max(orderdate) from sales.orders group by year(orderdate),month(orderdate)); --相关子查询，是引用了在外部查询中出现的列的子查询，从逻辑上讲，子查询会为外部查询的每一行进行一次计算。 --决胜属性（tiebreaker）,是一个属性或属性列表，可以惟一的对元素进行排名 --先创建2张表 use master; if db_id('DbTest') is not null drop database DbTest; create database DbTest; go use DbTest; go --创建Customers表 create table Customers ( custid INT NOT NULL IDENTITY, companyname NVARCHAR(40) NOT NULL, country NVARCHAR(15) NOT NULL, constraint pk_customer primary key(custid) ); --创建Orders表 CREATE TABLE Orders ( orderid INT NOT NULL IDENTITY, custid INT NULL, CONSTRAINT PK_Orders PRIMARY KEY(orderid), CONSTRAINT FK_Orders_Customers FOREIGN KEY(custid) REFERENCES Customers(custid), ); set identity_insert Customers on; INSERT INTO Customers(custid, companyname,country) VALUES(1, N'大众', N'中国'); INSERT INTO Customers(custid, companyname,country) VALUES(2, N'宝马', N'美国'); INSERT INTO Customers(custid, companyname,country) VALUES(3, N'奔驰', N'中国'); INSERT INTO Customers(custid, companyname,country) VALUES(4, N'奇瑞', N'德国'); INSERT INTO Customers(custid, companyname,country) VALUES(5, N'福特', N'美国'); set identity_insert Customers off; set identity_insert Orders on; --custid代表员工号 INSERT INTO Orders(orderid, custid) VALUES(1,1); INSERT INTO Orders(orderid, custid) VALUES(2,2); INSERT INTO Orders(orderid, custid) VALUES(3,3); INSERT INTO Orders(orderid, custid) VALUES(4,4); INSERT INTO Orders(orderid, custid) VALUES(5,5); --查看表的数据 select custid,companyname,country from Customers; select orderid,custid from Orders; --插入数据成功 --咱们回到正题,比较Exists与in,not exists与 not in --查询来自中国,而且下过订单的所有客户 select custid,companyname from Customers as C where country=N'中国' and exists (select * from Orders as O where O.custid=C.custid); --返回 --custid companyname --1 大众 --3 奔驰 --外部查询返回来自中国的客户信息,对于这个客户,exists谓词在Orders表查找是否至少存在一个与外部客户行信息相同的custid订单行 --用IN查询刚刚的需求 select custid,companyname from Customers as C where country=N'中国' and custid in(select custid from Orders); --结果跟上面的返回一样的值 --下面的知识点我们需要认识到: --当列表中有NULL时，in实际会产生一个UNKNOWN的结果，例如 a in(d,b,null)的结果是UNKNOWN,而a not in (d,b,null)返回的是not unknowd仍然是unknowd --而not in与not exists则结果会很不同，例如a in(a,b,null)返回的是TRUE,而a not in(a,b,null)返回的肯定是not true即为false --有了上面的认识，好继续开工了.... --我们现在向Orders表插入一行数据（6,null） set identity_insert Orders on; insert into Orders(orderid,custid) values(6,null); set identity_insert Orders off; set identity_insert Customers on; insert into Customers(custid,companyname,country) values(7,N'雷克萨斯',N'美国'); set identity_insert Customers off; select * from Orders; select * from Customers; --合并字符串 select ','+companyname from Customers where country=N'中国' for xml path('') --假设现在要返回来自美国且没有订单的客户 select custid,companyname from Customers as C where country=N'美国' and not exists (select * from Orders as O where O.custid=C.custid ); --返回 --custid companyname --7 雷克萨斯 --我们再用IN方法 select custid,companyname from Customers as C where country=N'美国' and custid not in(select custid from Orders); --返回的结果为空!!! --为什么呢?? --因为还记得我们刚插入的一行数据中custid为null么，这就是问题所在 --not in (select custid from Orders)返回的实际是unknown，所以返回结果集为空，除非你显示的规定custid不能为空 --下面是正确的解决方法 select custid,companyname from Customers as C where country=N'美国' and custid not in (select custid from Orders where custid is not null); --返回 --custid companyname --7 雷克萨斯 --所以在含有NULL值的列的时候，就要小心了，not exists与not in在逻辑上是不等价的 use tempdb go if object_id('dbo.sales') is not null drop table dbo.sales; go --无法绑定由多个部分组成的标识符 \"dbo.sales\"? create table sales ( empid varchar(10) not null primary key, mgrid varchar(10) not null, qty int not null ) delete from sales; insert into sales(empid,mgrid,qty) select 'B','X','300' union select 'C','Z','300' union select 'D','X','200' union select 'E','Z','300' union select 'F','Y','150' union select 'G','Y','300' union select 'H','Z','240' union select 'I','Y','300' union select 'J','Z','350' union select 'K','Z','300'; select * from sales; --row_number()函数编号 select empid,qty,mgrid, row_number() over ( partition by mgrid order by qty) as rowrank from sales order by qty; --用基本方法计算行号(列的值不为NULL) select empid,(select count(*) from sales s where s.empid<ss.empid)+1 as rowrank from sales ss order by empid; --更新某列的值为null update sales set empid=null where empid=N'F'; --select 字段 into 表 from 表 use tempdb; if object_id('tempdb..#myshippers') is not null drop table #myshippers; select shipperid,companyname,phone into #myshippers from InsideTSQL2008.sales.shippers; --如果需要为某个表创建应急的空副本，使用select into 很容易就可以得到它，只需提交以下语句 select * into target_table from source_table where 1=2; --创建名为MyOrders的表 select * into MyOrders from InsideTSQL2008.sales.orders where 1=2; --OUTPUT子句 --支持output子句有INSERT,DELETE,UPDATE,MERGE，可以引用特殊的inserted，deleted表 --SCOPE_IDENTITY()函数可以返回当前范围内会话最后生成的标识值 --@@IDENTITY 中包含语句生成的最后一个标识值,如果语句未影响任何包含标识列的表，则 @@IDENTITY 返回 NULL -- use tempdb; if object_id('CustomersDim') is not null drop table CustomersDim; go create table CustomersDim ( keycol int not null identity primary key, custid int not null, companyname nvarchar(40) not null ) --@@rowcount返回受上一语句影响的行数。 如果行数大于 20 亿，请使用 ROWCOUNT_BIG --声明一个表变量 declare @NewCusts table ( custid int not null primary key, keycol int not null unique ) insert into CustomersDim(Custid,companyname) output inserted.custid,inserted.keycol into @NewCusts--表变量 --output inserted.custid,inserted.keycol select custid,companyname from InsideTSQL2008.Sales.Customers where country=N'UK'; select * from @NewCusts; select @@identity ; --谨慎使用，现在我们想下，假设上面表 A 和表 B 都有IDENTITY自增域，那么我们在表 A 插入一条数据后， --使用了 SELECT @@IDENTITY 输出时，输出的到底是 A 还是 B 的自增域的值呢？ --答案很明显，是谁最后插入就输出谁，那么就是 B 了。 --于是，我本意是想得到 A 的自增域值，结果得到了 B 的自增域值，一只 BUG 随之诞生，搞不好还会影响到整个系统数据的混乱。 --因此，对于这种情况，建议大家慎用 @@IDENTITY，而尽量采用 SCOPE_IDENTITY() 函数替换之。SCOPE_IDENTITY() 也是得到最后一条自增域的值， --但是它是仅限在一个操作范围之内，而@@IDENTITY 是取全局操作的最后一步操作所产生的自增域的值的。 select scope_identity(); --从表中删除大量数据，并避免日志爆炸式增长和锁升级 --假如要删除2006年之前所有订单 --那我们采取分批方法，每次删除5000行 while 1=1 begin delete top(5000) from LargeOrders where orderdate<'20060101'; if(@@rowcount<5000) break;--如果没有5000行，则循环一次就跳出循环 end; --返回一个随机的数 --select N'随机'+right('000000000'+cast(1+ abs(checksum(newid())) as varchar(10)),10) as 随机值; --5分钟内向某表随机插入值 use tempdb; if object_id('randtable') is not null drop table randtable; go create table randtable ( ID int not null identity primary key, msg varchar(max) not null ) declare @msg as varchar(max); declare @now as datetime; set @now=current_timestamp; while 1=1 and datediff(second,@now,current_timestamp)<300 begin set @msg=N'随机'+right('000000000'+cast(1+ abs(checksum(newid())) as varchar(10)),10); insert into randtable(msg) values (@msg); end --select @@rowcount--返回影响行数 select * from randtable; select (max(ID)-min(ID)) as N'总行数' from randtable; select max(ID)as N'最大ID' from randtable;-- select min(ID) as N'最小ID'from randtable;-- --比较几种删除数据的执行效率 --我们一分钟内随机插入数据 delete from randtable;--用这种直接删除数据方式，删除415850条数据 用时52秒： --删除5686094条数据 用时29秒; --删除7679924条数据 用时19秒; --删除11248379条数据 用时2秒; --删除10803495条数据 用时2秒; --下面我们采取另一种方式删除，即分批删除 while 1=1 begin delete top(5000) from randtable --where ID<19061681; --if(@@rowcount<5000) break;--如果没有5000行，则循环一次就跳出循环 end; --比较现在时间与之后之间的差值 datediff(second,@now,current_timestamp); --更新表结构 alter table tablename add constraint pk_name primary key(columnname); --将空值转换为实际值 --coalesce(comm,0) --与COALESCE(expression1,...n) 的功能与以下 CASE 表达式相同： -- --CASE -- -- WHEN (expression1 IS NOT NULL) THEN expression1 -- -- WHEN (expression2 IS NOT NULL) THEN expression2 -- -- ... -- -- ELSE expressionN -- --END 类似 --利用case指定order by的列动态排序 select ename,sal,job,comm case when job='saleman' then comm else sal end as ordered from emp order by 5; --UNION ALL(包括重复行) --将多个来源的行组合起来，放到一个结果集，所有select列表的项目数 --和对应项目的数据类型必须要匹配 --UNION(不包括重复行) --创建数字辅助表(Nums) if object_id('Nums') is not null drop table Nums; go create table Nums(n int not null primary key); declare @max as int, @rc as int; set @max=10000; set @rc=1; insert into Nums values(1); while @rc*2<=@max begin insert into Nums select n+@rc from Nums; set @rc=@rc*2; end insert into Nums select n+@rc from Nums where n+@rc<=@max; -- 创建一个“天”表，把Customers表与Employees表生成雇员-客户-每天组合 select custid,empid,dateadd(day,n-1,'20090101') as orderdate ,row_number() over (order by (select 0))as orderid from sales.customers cross join HR.employees cross join Nums where n<31; --对于每个订单，计算订单价格占总价格的百分比，以及它与所有订单平均价格的差额 drop table Myordervalues select * into MyorderValues from sales.Ordervalues; alter table myordervalues add constraint pk_myordervalues primary key (orderid); create index idx_val on myordervalues(val); select orderid,custid,val ,cast(val/(select sum(val) from myordervalues)*100 as numeric(5,2)) as pct, cast(val-(select avg(val) from myordervalues)*100 as numeric(12,2)) as diff from myordervalues; --内联结（inner） --关于ON与where，如果一个查询既包含ON，又要包含where字句，逻辑上他们会依次应用，除了一个 --外，在Inner Join的on字句中指定逻辑表达式，还是在where字句中指定逻辑表达式，没有任何区别，因为 --两个步骤没有中间步骤会添加外部行。 --这个例外，就是当指定了group by all选项时，group by all会把where字句过滤掉的组再添加到结果集 --但不会添加ON字句过滤掉的组。 --如何规范的去放置逻辑条件呢？ --参考：把表之间匹配属性的筛选器应该位于ON字句中，而只对一个表的属性进行筛选的筛选器应该位于在where字句中 --例如: select c.custid,companyname,orderid from sales.customers as c,sales.orders as o on c.custid=o.custid and country=N'USA'; --外联接（OUTER） --外联接用于返回两个表中按一定条件匹配的行，以及“保留”表中不能被匹配的行 --可以用left,right,full,关键字保留表，left把坐标标记为保留表，right把右表标记为保留表，full把两个表都标记为保留表 --外联接有三个阶段：笛卡尔积-》ON筛选器-》添加外部行，对于保留表中未找到匹配的行，将作为外部行添加到结果集，并用 --null作为相应非保留表属性的取值 --以下查询返回客户及其订单ID select c.custid,o.orderid into #tb from sales.Customers as c left outer join sales.orders as o on c.custid=o.custid; --返回订单是NULL的客户行 select* from #tb where orderid is null; --关键字outer是可选的，因为使用left,right,full就隐含着这是一个外联接，通常使用 --内联接不加关键字inner,而使用外联接通常加上关键字outer --其他联接 --自联接（是在同一个表的两个实例之间进行的联接） --以下是一个简单的自联接例子，对Employees表的两个实例进行联接，一个代表雇员（E），另一个代表经理(M) --当联接同一个表的两个实例时,必须至少为其中一个表应用别名,为每一个实例,提供惟一的一个名称 select E.firstname,E.lastname as emp, M.firstname,M.lastname as mgr from HR.Employees as E left outer join HR.Employees as M on E.mgrid=M.empid; --不等联接 --等值联接是联接条件基于等号(=)运算符的联接，不等联接的联接条件中包含的是除等号以外的其他运算符 --存储过程 --o(∩_∩)o ，终于到存储过程这一环节了，不容易啊.... --存储过程是把一个或多个T-SQL语句组合到一个逻辑单元，在sqls中保存为一个对象，当首次执行时，sqlserver创建执行计划 --并把它存在计划内缓存中，然后进行重用，重用计划使得存储过程提供了可靠的性能 --优点： --（1）提升应用程序的可支持性 --（2）减少网络流量 --（3）促进代码可复用性 --（4）淡化数据的获取方式 --（5）查询时间比较稳定 --（6）有效防止SQL Injection --（7）能作为控制层，控制一定的权限 --基本语法 --没有参数的存储过程 --create procedure [schema_name.] procedure_name--是架构和存储过程的名字 --as {<sql_statement>[...n]}--主体 --创建一个查询master数据库的存储过程 use master go create procedure select_master as select * from spt_values; go --执行存储过程 exec select_master;--不需要加exec procedure proc_name --go关键字用于标记存储过程结束 --在创建存储过程的时候，会检查sql语法的正确性，不会去检查引用表是否存在，这意味着你可能引用了不存在 --的表，并且直到运行的时候才报错，这叫做延迟名称解析 --创建带参数的存储过程，一个存储过程可以传入2100个参数 --语法如下 --create {proc|procedure} [schema_name] procedure_name[;number] --[{@parameter[type_shacema_name.]data_type}[varying][=default][out|output][readonly]][,...n] --[with <procedure_option>[,...n]] --[for replaction] --as {<sql_statement>[;][...n]|<method_specifier>} --参数以@为前缀后面是参数的数据类型和可选的默认值 -- create procedure shoppingitem (@shoppingcartid nvarchar(50), @quantity int =1, @productid int) as if exists(select * from Sales.ShoppingCartItem where shoopingcartid=@shoppingcartid and productid=@productid) begin update sale.shoppingcartitem set quantity=@quantity where shoppingcartid=@shoppingcartid and productid=@productid print'updated....' end else begin insert sale.shoppingcartitem(shoppingcartid,productid,quantity)values (@shoppingcartid,@productid,@quantity) print 'inserted.....' end go --执行，传入三个参数 exec shoppingitem '1000',2,316 --output参数 --该参数是把信息返回给存储过程调用者，无论是另外的存储过程或即席调用（嵌入程序中sql语句） --例子 --创建一个返回某个组的部门列表 create procedure seldepartment @groupname nvarchar(50), @deptcount int putput as select [name] from hr.department where groupname=@groupname order by [name] select @deptcount=@@rowcount go --执行 declare @deptcount int exec deldepartment 'hr',@deptcount output --更新存储过程 alter procedure .... --删除存储过程 drop procedure .... --创建自动执行的存储过程 --每当重启sql时，自动向一张表中插入重启的时间 use master go create table sqlstartlog ( startid int identity(1,1) primary key not null, startdatetime datetime not null ) go --创建一个存储过程向表中插入值 create procedure insertstartlog as insert sqlstartlog(startdatetime) values(getdate()) go --设置自动执行的存储过程 exec sp_procoption @ProcName='insertstartlog',@OptionName='startup',@OptionValue='true'; --重启后，查看insertstartlog select * from sqlstartlog; --如果需要禁用 exec sp_procoption @ProcName='insertstartlog',@OptionName='startup',@OptionValue='false'; --在这个更总sql server启动的例子中，存储过程必须创建在master数据库中 --加密 --只需要在创建存储过程的名字后面加入with encryption --查看存过程 alter procedure sampleencryption with encryption as set nocount on--使不提示受T-SQL语句影响的行数，@@rowcount不受其影响 select * from sqlstartlog go -- exec sp_helptext sampleencryption; --使用execute as来指定过程的安全上下文 --with execute as 关键字允许你指定存储过程执行所在的安全上下文，覆盖存储过程调用者的默认安全 --概念：权链 --当创建一个对象（例如存储过程，或者视图），并将其用来对另外一个数据库对象进行Insert,Delete,Select,Update对象的时候 --就出现了“所有权链”，如果存储过程对象的架构和它引用对象的架构一样，sqlserver只会检查存储过程调用者是否有对存储过程execute的 --权限 --重新编译与缓存 --存储过程的性能优势主要是在重用计划 --当存储过程的计划自动或先是重建的时候就会发生重新编译，当存储过程中引用的基础表或其他对象 --发生变化后，存储过程就会在其执行期间自动重新编译。计划使用的索引发生变动或者存储过程引用的表键发生了大量的更新也可能引起重新编译 --sql server存储过程使用的是语句级别的重新编译，能够减小负载。 --查询缓存数量 select count(*) 'CachedPlansBefore' from sys.dm_exec_cached_plans; --清空缓存 dbcc freeproccache; --注意事项 --不能在一个存储过程中删除另一个存储过程，只能调用另一个存储过程 --存储过程常用命令 --显示所有存储过程的基本信息 show procedure status;   -- 显示使用的时间 declare @BeginDate datetime set @BeginDate=getdate(); begin end SELECT BeginDate = @dt, EndDate = GETDATE(), Second = DATEDIFF(Second, @dt, GETDATE()); --生成多少万条不重复的n位数字 use tempdb go --创建测试表 create table testtable(id char(8) ); --创建用于自动过滤重复值的唯一索引 create unique index ui_tb on testtable(id) with IGNORE_DUP_KEY go --测试数据插入的时间 declare @dt datetime set @dt=getdate() set nocount on; declare @row int set @row=100000 while @row>0 begin raiserror('need %d rows',10,1,@row) with nowait set rowcount @row insert testtable select id=right(100000000+convert(bigint,abs(checksum(newid()))),8) from syscolumns c1,syscolumns c2--syscolumns为每个表和视图中的每列返回一行，并为数据库中的存储过程的每个参数返回一行。 set @row=@row-@@rowcount; end select BeginDate=@dt,EndDate=getdate(),Second=datediff(Second,@dt,getdate()) go drop table testtable; --------------------------------------------------- use tempdb go --我写的这种只有5秒左右时间,而上面却有40几秒 --创建测试表 create table testtable(id int identity(1,1) not null,num char(8) ); --创建用于自动过滤重复值的唯一索引 create unique index ui_tb on testtable(num) with IGNORE_DUP_KEY go --测试数据插入的时间 declare @dt datetime set @dt=getdate() set nocount on; declare @row int set @row=100000 declare @xx char(8) while @row>0 begin set @xx=right(100000000+convert(bigint,abs(checksum(newid()))),8); --print @xx; insert testtable(num) values(@xx) set @row=@row-@@rowcount; end select BeginDate=@dt,EndDate=getdate(),Second=datediff(Second,@dt,getdate()) select count(*) from testtable; go drop table testtable; select * from dbo.testtable --这是第二次温习not in与exists ，not exists了 use tempdb; go if object_id(N'test') is not null drop table test create table test ( ID int not null identity(1,1) primary key, depno char(10) ) insert into test(depno) values(20); insert into test(depno) values (10); insert into test(depno) values(40); insert into test(depno) values (30); insert into test(depno) values (null); create table test2 ( ID int not null identity(1,1) primary key, depno char(10) ) insert into test2(depno) values(10); insert into test2(depno) values (100); insert into test2(depno) values (20); select * from test; select * from test2; select t.depno from test t where t.depno not in (select t2.depno from test2 t2 ) --下面查询查不到任何值，因为子查询中depno含有null值，并且是用not in判断 select t2.depno from test2 t2 where t2.depno not in (select t.depno from test t ) --采用exists select t2.depno from test2 t2 where not exists (select null from test t where t.depno=t2.depno ) ESCAPE --如果要以文本的形式搜索，而不是被sql解释为通配符，可以使用escape关键字 where description like '%/%%' escape '/'--搜索与“%”匹配的 create table a (name varchar(10)) go insert into a select '11%22' union all select '11%33' union all select '12%33' go select * from a WHERE name LIKE '%/%33' ESCAPE '/' --指定用'/'符号来说明跟在其后面的通配符字符为普能字符。(第二个%是字符不是通配符来的) go drop table a --结果为： -- name ---------- -- 11%33 -- 12%33 --再来一个 SELECT * FROM finances WHERE description LIKE 'gs_' ESCAPE 's' --意思就是： 比如，我们要搜索一个字符串 \"g_\" ,如果直接 like \"g_\"，那么 \"_\"的作用就是通配符，而不是字符，结果，我们会查到比如 \"ga\",\"gb\",\"gc\",而不是我们需要的 \"g_\". 用 LIKE 'gs_' ESCAPE 'S' 's'表示特殊用法标志 --声明变量 --在sql2005不允许声明变量后紧接着就赋值 --而在sql2008可以省略set关键字直接赋值 use InsideTSQL2008 go select top 10percent * from MyorderValues;--返回10%的行 --建议 --避免使用不兼容的数据类型。例如float和int、char和varchar、binary和 --varbinary是不兼容的 --避免使用不兼容的数据类型。例如float和int、char和varchar、binary和 --varbinary是不兼容的。数据类型的不兼容可能使优化器无法执行一些本来可以进 --行的优化操作。例如: SELECT name FROM employee WHERE salary >60000 --在这条语句中,如salary字段是money型的,则优化器很难对其进行优化,因为60000 --是个整型数。我们应当在编程时将整型转化成为货币型,而不要等到运行时转化。 --尽量避免在WHERE子句中对字段进行函数或表达式操作，这将导致引擎放弃 --使用索引而进行全表扫描。如： SELECT * FROM T1 WHERE F1/2=100 --应改为: SELECT * FROM T1 WHERE F1=100*2 SELECT * FROM RECORD WHERE SUBSTRING(CARD_NO,1,4)=’5378’ --应改为: SELECT * FROM RECORD WHERE CARD_NO LIKE ‘5378%’ SELECT member_number, first_name, last_name FROM members WHERE DATEDIFF(yy,datofbirth,GETDATE()) > 21 --应改为: SELECT member_number, first_name, last_name FROM members WHERE dateofbirth < DATEADD(yy,-21,GETDATE()) --即：任何对列的操作都将导致表扫描，它包括数据库函数、计算表达式等等，查询 --时要尽可能将操作移至等号右边。 --尽量使用数字型字段，一部分开发人员和数据库管理人员喜欢把包含数值信 --息的字段 --设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在 --处理查询和连接回逐个比较字符串中每一个字符，而对于数字型而言只需要比较一 --次就够了。 --创建用','分隔的列表 select * from nums declare @splitstring nvarchar(50) set @splitstring=''; select @splitstring=@splitstring+convert(char(2),n)+','--因为n是数值型，需要转换，不然就是求和了 from Nums where n<15; select @splitstring; --select into到临时表 select n into #tempdb from nums; select * from #tempdb; --在频繁执行的查询中，发生隐式转换，将会非常影响性能例如nchar转为char --复习索引 --索引是在表上创建的数据库对象，它可以提供到数据更快的访问，并且可以使查询执行更快 --sql中，存储单位最小的是页，页是不可再分的，换句话说，要么整个读取,要么不读 --如果表上没有索引，那么就是存放在堆Heap中，即使你想找的数据就是第一项，那么sql引擎也需要进行全表扫描 --对于数据库检索来说，对于磁盘的IO是最消耗时间的 --测试sql IO次数 use tempdb go create table testio ( id int, c1 int, c2 int, c3 int, c4 char(2) ) insert into testio values(1,1,1,'a'); insert into testio values(2,2,2,'a'); insert into testio values(3,3,3,'a'); insert into testio values(4,4,4,'a'); insert into testio values(5,5,5,'a'); insert into testio values(6,6,6,'a'); insert into testio values(7,7,7,'a'); insert into testio values(8,8,8,'a'); insert into testio values(9,9,9,'a'); insert into testio values(10,10,10,'a'); insert into testio values(11,11,11,'a'); insert into testio values(12,12,12,'a'); insert into testio values(13,13,13,'a'); insert into testio values(14,14,14,'a'); insert into testio values(15,15,15,'a'); insert into testio values(16,16,16,'a'); insert into testio values(170,170,170,'a'); --开启IO数量 set statistics io on; select * from testio where c1=170; --建立索引 create index idx_testio on testio(c1); select * from testio where c1=170; use HR go select top 10(ID) from Talent_Big; select * from Talent_Big where ID=480000; --建立索引 drop index idx_talent_big on Talent_Big; --理解聚集和聚集索引 -- -- 在SQL Server中，最主要的两类索引时聚集索引和非聚集索引。可以看到，这两个分类都是围绕聚集这个关键字进行的，那么首先理解什么是聚集。 -- -- 聚集在索引中的定义： -- -- 为了提高某个属性（或属性组）的查询速度，把这个或这些属性（成为聚集码）上具有相同值的元组集合中存放在连续的物理块成为聚集。 -- --非聚集索引 -- -- 因为每个表只能有一个聚集索引，如果我们对一个表的查询不仅仅限于聚集索引上的字段。我们又对聚集索引列之外还有索引的要求，那么就需要非聚集索引了。 -- -- 非聚集索引，本质上来说也是聚集索引的一种，非聚集索引并不改变其所在表的物理结构，而是额外生成一个聚集索引的B树结构，但叶节点是对于其所在表的引用， --这个引用分为两种，如果其所在表上没有聚集索引，则引用行号；如果其所在表上已经有了聚集索引，则引用聚集索引的页，从而实现更大限度的使用。 --随着数据量的增长，产生了索引碎片，很多存储的数据进行了不适当的跨页,会造成碎片 --这时我们可以通过重建索引来提高速度: ALTER INDEX idx_text_tb2_EmployeeID ON test_tb2 REBUILD -- --还有一种情况是，当随着表数据量的增大，有时候需要更新表上的统计信息，让查询分析器根据这些信息选择路径，使用: -- --UPDATE STATISTICS 表名 -- --那么什么时候知道需要更新这些统计信息呢，就是当执行计划中估计行数和实际表的行数有出入时: -- 当然索引的使用也是要付出代价的： -- -- 1、通过聚集索引的原理我们知道，当表建立索引后，就可以B树来存储数据，所以当对其进行更新插入删除，就需要页在物理上移动以调整B树，因此当更新插入删除数据时，会带来性能的下降。 --而对于非聚集索引，当更新表后，非聚集索引需要进行更新，相当于多更新了N(N=非聚集索引数量）个表。因此也下降了性能。 -- -- 2、通过上面对非聚集索引原理的介绍，可以看到，非聚集索引需要额外的磁盘空间。 -- -- 3、前文提过，不恰当的非聚集索引反而会减低性能。 -- -- 所以使用索引需要根据实际情况进行权衡.通常我都会将非聚集索引全部放到另外一个独立硬盘上，这样可以分散IO，从而使查询并行. --视图 --sql中分为3种视图 --普通视图，在数据库中不保存实际数据，只是视图定义 --索引视图，保存了真实的索引数据 --分布式分区视图，可以用UNION ALL来把多个跨两个以上sql实例的较小的表组合成一个虚拟表 --select语句允许一个视图定义1024个列，然而，不可以在视图定义中使用某些select元素，包括into，option,compute,compute by 或者对 --表变量或临时表的引用。除非使用了top关键字，否则也不可以使用order by --创建视图 create view view_somedefin as select * from testio go --查看某个视图的定义 select definition from sys.sql_modules where object_id=object_id('view_somedefin'); --删除视图 drop view view_somedefin; --视图加密 create view view_somedefinencrypt with encryption as select * from testio; go --此时通过sys.sql_modules系统目录视图来查看该视图的definition是null --使用视图修改数据 --可以像普通表一样对视图进行插入，更新，删除，但是这些操作只能引用一个表中的列，而且，这些操作中引用列不能进行 --衍生，例如它们不能基于聚合函数被计算或受group by ,distinct 或having子句 --例子 create view view_production as select ID,proname,proprice,num,num*prpprice totalcost from production go --以上创建了一个视图，现在向其中插入一条数据 insert view_production (proname,proprice,num,totalcost) values ('可乐',2,10,20); --发生错误 --对视图或函数’view_production‘的更新或插入失败、因其包含派生域或常量域 --其实问题是出生在’totalcost‘中，它引用了两列，只要去掉插入该列的值即可 --创建索引视图 use InsideTSQL2008 go create view view_Employees with schemabinding as select E.empid ,E.lastname,E.firstname,E.title,E.address,E.city,O.orderdate,O.shipname from HR.Employees E join Sales.Orders O on O.empid=E.empid ; go --drop view view_Employees; set statistics io on; select * from view_Employees --查询完毕后，我们发现empid这列是无序的，并且Orders表的逻辑读取次数为21次，Employees的逻辑读取次数2次 --因为empid为主键与外键，所以已经有了聚集索引，而一个表中只能有一个聚集索引，所以为视图创建非聚集索引 create nonclustered index uci_index_Employees_Orders on Sales.Orders(orderdate) go --删除索引 drop index Sales.Orders.uci_index_Employees_Orders;","title":"分享自己这近一个月的sql温习笔记"},{"content":"一切看图吧，懒得解释，解释了又不如图来的直观。 需求： 首先有四个表，如右图： 代理商的管理员账户的姓名存到了用户信息里面的，现在需要取出代理商的所有信息，以及它的管理员的名字。 哎，自己研究了老半天，本身好久没有操作数据库了。其实很简单啦，就是个左外连接嘛，哈哈。 先说一下这个左外连接：　left join是以A表的记录为基础的,A可以看成左表,B可以看成右表,left join是以左表为准的。换句话说,左表(A)的记录将会全部表示出来,而右表(B)只会显示符合搜索条件的记录(例子中为: A.aID = B.bID)。B表记录不足的地方均为NULL。 看完之后，恍然大悟。贴下代码，方便以后查看：  SELECT C.*,U.User_Name          FROM Company_Information C,Company_System CS  LEFT JOIN User_Information U on CS.System_ID=U.User_Account          where C.Company_ID=CS.Company_ID","title":"数据库存储过程使用左外连接left join"},{"content":"在大学的时候学习了JSP，其中使用JDBC进行数据库操作，有一个语句是Statement.ExecuteUpdate，这个语句执行一个SQL的更新操作（如delete，update，insert），返回所影响的行数。当返回0时，则表示没有更新任何行。我以为可以判断返回值是否大于0来判断更新是否成功，但是，下面的两种情况均返回0：     1：没有找到需要更新的数据        比如，我们进行update的时候，条件是id=5，但是id=5的数据不存在。这种情况下，更新是失败的，返回0，很正确。     2：要更新的数据和更新的值是完全一样的        比如，我们要对id=5的记录进行更新，把title变成hello。虽然这条记录存在，但是这条记录的title本来就是hello，那么，返回值也是0   这样就有个问题，当第2种情况发生时，从逻辑上讲，更新操作是成功的，你可以理解成title被重新覆盖了，不管它原来是不是hello，但是现在就被更新成hello了。 因此，如果要对Update进行是否更新成功的判断，就需要在Update之前，调用Statement.ExecuteQuery进行查询，如果能查询到记录，则表示更新会成功。ExecuteUpdate的返回值仅仅代表更新了多少行。 这样，一个Update操作就会执行2次SQL语句的，效率会降低。我当时就纳闷，为什么ExecuteUpdate对于第2种情况会不返回0，虽然从数据库的角度上，它是可以忽略更新这条记录，但是从逻辑的角度上看，这条记录被更新似乎更加合乎情理，返回大于0的值似乎更有意义。 不过，为什么基本上所有的编程语言，只要有类似的函数，都会在第2种情况返回0呢？ 最近，这个问题总算想通了，之所以返回0，其实是为了解决同步的问题。 举个例子，现在，著名的开心网要对菜园的功能进行扩展，不光是能让玩家种菜，还要能让玩家偷别人家的菜。我们的程序逻辑如下：   某菜园：有成熟的菜N颗 A：     有偷来的菜0颗 =========================== A：     某菜园有多少颗成熟的菜？ 某菜园：N A：     偷1颗 某菜园：成熟的菜=N-1 A：     口袋里的菜+1 =========================== 某菜园：有成熟的菜N-1颗 A：     有偷来的菜1颗       这段程序的逻辑没有任何问题。 好了，现在程序开始给玩家用了，有一颗超级无敌白金大青菜快成熟了，众玩家垂涎欲滴等着偷。成熟的那一刻，众玩家以瞬间的爆发力点击了鼠标左键，进行了偷菜。 假设有2个人A和B，几乎同时点击了鼠标，我们看服务器上程序的逻辑：   某菜园：有成熟的菜N颗 A：     有偷来的菜0颗 B：     有偷来的菜0颗 =========================== A：     某菜园有多少颗成熟的菜？ B：     某菜园有多少颗成熟的菜？ 某菜园：N 某菜园：N A：     偷过来 B：     偷过来 某菜园：成熟的菜=N-1 某菜园：成熟的菜=N-1 A：     口袋里的菜+1 A：     口袋里的菜+1 =========================== 某菜园：有成熟的菜N-1颗 A：     有偷来的菜1颗   B：     有偷来的菜1颗       大家可以看到，现在的超级无敌白金大青菜总数变成了N+1了，无故多出了1颗，显然，这个结果是不对的，也不是我们想要的。 开心网的代码是用PHP开发的，PHP中可没有Java中的Synchronous关键字。如果用一个本地文件来实现锁的功能，服务器的运行效率就会大大打折。那么，我们如何高效的解决这个同步问题呢？这时候，执行Update返回所影响的行数就具有了超人般的意义了。  请看上面第2段中的粗体代码，在执行这个逻辑的时候，我们会得到的Update的返回值是0，因为在做这个操作之前，菜园里的蔬菜数量已经被更新成N-1了，所以这个更新操作会被忽略，这样，我们就可以在程序中加一个判断：如果更新的返回值是0，则表示偷菜失败，虽然Update是成功的。虽然B问菜园的时候是有菜的，但是偷的时候却没有了，那也表示B没有偷到。 可见，返回所影响的行数是非常有意义的，对于并发量大的网站，可以好好利用这个返回值，能在保证效率的状态下，解决同步的问题。","title":"浅谈SQL Update返回影响行数的意义"},{"content":"grant 权限 on 数据库对象 to 用户 password mysql> grant all on *.* to root@\"%\" identified by 'abc123'; Query OK, 0 rows affected (0.01 sec) mysql> select host,User,password  from user; +--------------+---------+------------------+ | host         | User    | password         | +--------------+---------+------------------+ | localhost    | root    |                  | | selfserv     | root    |                  | | 127.0.0.1    | root    |                  | | localhost    |         |                  | | selfserv     |         |                  | | %            | abc     | 4b5698aa4603595b | | 172.17.15.50 | zsgd    | 032c41e8435273a7 | | %            | sysuser | 3256e6786e6650e9 | | %            | sg      | 032c41e8435273a7 | | %            | root    | 3256e6786e6650e9 | +--------------+---------+------------------+ 10 rows in set (0.00 sec) mysql> grant 权限 on 数据库对象 to 用户 一、grant 普通数据用户，查询、插入、更新、删除 数据库中所有表数据的权利。 grant select on testdb.* to common_user@’%’ grant insert on testdb.* to common_user@’%’ grant update on testdb.* to common_user@’%’ grant delete on testdb.* to common_user@'%' 或者 grant select, insert, update, delete on testdb.* to common_user@’%’   二、grant 数据库开发人员，创建表、索引、视图、存储过程、函数。。。等权限。 grant 创建、修改、删除 MySQL 数据表结构权限。 grant create on testdb.* to developer@’192.168.0.%’; grant alter on testdb.* to developer@’192.168.0.%’; grant drop on testdb.* to developer@’192.168.0.%’; grant 操作 MySQL 外键权限。 grant references on testdb.* to developer@’192.168.0.%’; grant 操作 MySQL 临时表权限。 grant create temporary tables on testdb.* to developer@’192.168.0.%’; grant 操作 MySQL 索引权限。 grant index on testdb.* to developer@’192.168.0.%’; grant 操作 MySQL 视图、查看视图源代码 权限。 grant create view on testdb.* to developer@’192.168.0.%’; grant show view on testdb.* to developer@’192.168.0.%’; grant 操作 MySQL 存储过程、函数 权限。 grant create routine on testdb.* to developer@’192.168.0.%’; — now, can show procedure status grant alter routine on testdb.* to developer@’192.168.0.%’; — now, you can drop a procedure grant execute on testdb.* to developer@’192.168.0.%’;   三、grant 普通 DBA 管理某个 MySQL 数据库的权限。 grant all privileges on testdb to dba@’localhost’ 其中，关键字 “privileges” 可以省略。   四、grant 高级 DBA 管理 MySQL 中所有数据库的权限。 grant all on *.* to dba@’localhost’   五、MySQL grant 权限，分别可以作用在多个层次上。 1. grant 作用在整个 MySQL 服务器上： grant select on *.* to dba@localhost; — dba 可以查询 MySQL 中所有数据库中的表。 grant all on *.* to dba@localhost; — dba 可以管理 MySQL 中的所有数据库 2. grant 作用在单个数据库上： grant select on testdb.* to dba@localhost; — dba 可以查询 testdb 中的表。 3. grant 作用在单个数据表上： grant select, insert, update, delete on testdb.orders to dba@localhost; 这里在给一个用户授权多张表时，可以多次执行以上语句。例如： grant select(user_id,username) on smp.users to mo_user@’%’ identified by ‘123345′; grant select on smp.mo_sms to mo_user@’%’ identified by ‘123345′; 4. grant 作用在表中的列上： grant select(id, se, rank) on testdb.apache_log to dba@localhost; 5. grant 作用在存储过程、函数上： grant execute on procedure testdb.pr_add to ‘dba’@'localhost’ grant execute on function testdb.fn_add to ‘dba’@'localhost’   六、查看 MySQL 用户权限 查看当前用户（自己）权限： show grants; 查看其他 MySQL 用户权限： show grants for zhangkh@localhost;   七、撤销已经赋予给 MySQL 用户权限的权限。 revoke 跟 grant 的语法差不多，只需要把关键字 “to” 换成 “from” 即可： grant all on *.* to dba@localhost; revoke all on *.* from dba@localhost;   八、MySQL grant、revoke 用户权限注意事项 1. grant, revoke 用户权限后，该用户只有重新连接 MySQL 数据库，权限才能生效。 2. 如果想让授权的用户，也可以将这些权限 grant 给其他用户，需要选项 “grant option“ grant select on testdb.* to dba@localhost with grant option; 这个特性一般用不到。实际中，数据库权限最好由 DBA 来统一管理。 mysql授权表共有5个表：user、db、host、tables_priv和columns_priv。 授权表的内容有如下用途： user表 user表列出可以连接服务器的用户及其口令，并且它指定他们有哪种全局（超级用户）权限。在user表启用的任何权限均是全局权限，并适用于所有数据库。例如，如果你启用了DELETE权限，在这里列出的用户可以从任何表中删除记录，所以在你这样做之前要认真考虑。 db表 db表列出数据库，而用户有权限访问它们。在这里指定的权限适用于一个数据库中的所有表。 host表 host表与db表结合使用在一个较好层次上控制特定主机对数据库的访问权限，这可能比单独使用db好些。这个表不受GRANT和REVOKE语句的影响，所以，你可能发觉你根本不是用它。   tables_priv表 tables_priv表指定表级权限，在这里指定的一个权限适用于一个表的所有列。 columns_priv表 columns_priv表指定列级权限。这里指定的权限适用于一个表的特定列。 注： 对于GRANT USAGE ON，查看手册有如下介绍和实例： mysql> GRANT USAGE ON *.* TO ‘zhangkh’@'localhost’; 一个账户有用户名zhangkh，没有密码。该账户只用于从本机连接。未授予权限。通过GRANT语句中的USAGE权限，你可以创建账户而不授予任何权限。它可以将所有全局权限设为’N'。假定你将在以后将具体权限授予该账户。","title":"mysql 添加用户访问权限"},{"content":"一、查看创建函数的功能是否开启 mysql> show variables like '%func%'; +-----------------------------------------+-------+ | Variable_name                            | Value | +-----------------------------------------+-------+ | log_bin_trust_function_creators | ON    | +-----------------------------------------+-------+ 1 row in set (0.02 sec) 二、如果Value处值为OFF，则需将其开启 mysql> set global log_bin_trust_function_creators=1; 三、创建函数时，先选择数据库 mysql> use xxx; Database changed delimiter $$是设置 $$为命令终止符号，代替分号，因为分号在begin...end中会用到； mysql> delimiter $$ CREATE FUNCTION`nextval`(seq_name varchar(50)) RETURNS decimal(10,0) begin declare ret numeric(10); update  sequence set current_value=current_value+increment where name=seq_name; select  current_value into ret from   sequence      where name=seq_name; return  ret; END; 函数创建成功后需恢复分号为命令终止符号。 mysql> delimiter ; 四、测试 mysql> nextval('xxx'); 五、删除函数 mysql> drop function nextval ; Query OK, 0 rows affected (0.11 sec) 六、查看函数 1) show function status 显示数据库中所有函数的基本信息  2)查看某个具体函数  mysql>show create function function","title":"MySQL数据库函数操作相关知识"},{"content":"(转载地址：http://blog.csdn.net/iihero/article/details/2149547)   其实，这篇短文，我早就应该写了。因为，java存储过程今后在各大数据库厂商中越来越流行，功能也越来越强大。这里以Oracle为例，介绍一下java存储过程的具体用法。 任何转载，请尊重版权。(作者：iihero  on csdn) 一、如何创建java存储过程？ 通常有三种方法来创建java存储过程。 1. 使用oracle的sql语句来创建： e.g. 使用create or replace and compile java source named \"<name>\" as        后边跟上java源程序。要求类的方法必须是public static的，才能用于存储过程。 SQL>create or replaceand compile java source named \"javademo1\"  2  as  3  import java.sql.*;  4  public class JavaDemo1  5  {  6  public static void main(String[] argv)  7  {  8  System.out.println(\"hello, java demo1\");  9  } 10  } 11  / Java 已创建。 SQL> show errors java source \"javademo1\" 没有错误。 SQL>create or replaceprocedure javademo1  2  as  3  language java name 'JavaDemo1.main(java.lang.String[])';  4  / 过程已创建。 SQL>set serveroutputon SQL> call javademo1(); 调用完成。 SQL> call dbms_java.set_output(5000); 调用完成。 SQL> call javademo1(); hello, java demo1 调用完成。 SQL> call javademo1(); hello, java demo1 调用完成。 2. 使用外部class文件来装载创建 e.g. 这里既然用到了外部文件，必然要将class文件放到oracle Server的某一目录下边。 public class OracleJavaProc {    public static void main(String[] argv)     {         System.out.println(\"It's a Java Oracle procedure.\");     } } SQL> grant create any directory to scott; 授权成功。 SQL> connscott/tiger@iihero.oracledb 已连接。 SQL> create or   replace   directory   test_dir   as 'd:/oracle'; 目录已创建。 SQL> create or replace java class using bfile(test_dir,'OracleJavaProc.CLASS')   2  / Java 已创建。 SQL> create or replace procedure testjavaproc as language java name'OracleJavaProc.main(java.lang.String[])';   2  / 过程已创建。 SQL> call testjavaproc(); 调用完成。 SQL> execute testjavaproc; PL/SQL 过程已成功完成。 SQL> set serveroutput on size 5000 SQL> call dbms_java.set_output(5000); 调用完成。 SQL> execute testjavaproc; It's a Java Oracleprocedure. 3. 我推荐的一种方法，直接使用loadjava命令远程装载并创建。     先创建一个类, e.g. import java.sql.*; import oracle.jdbc.*; publicclass OracleJavaProc...{   //Add a salgrade to the database.   public static void addSalGrade(int grade,int losal, int hisal) ...{       System.out.println(\"Creating new salgrade for EMPLOYEE...\");      try ...{          Connection conn=             DriverManager.getConnection(\"jdbc:default:connection:\");          String sql=            \"INSERT INTO salgrade\" +            \"(GRADE,LOSAL,HISAL)\" +            \"VALUES(?,?,?)\";          PreparedStatement pstmt= conn.prepareStatement(sql);          pstmt.setInt(1,grade);          pstmt.setInt(2,losal);          pstmt.setInt(3,hisal);          pstmt.executeUpdate();          pstmt.close();          }      catch(SQLException e)...{          System.err.println(\"ERROR! Adding Salgrade:\"           + e.getMessage());          }    } } 使用loadjava命令将其装载到服务器端并编译： D:eclipse3.1workspacedbtest>loadjava -u scott/tiger@iihero.oracledb -v -resolve Or acleJavaProc.java arguments: '-u' 'scott/tiger@iihero.oracledb '-v' '-resolve' 'OracleJavaProc.java' creating : source OracleJavaProc loading  : source OracleJavaProc resolving: source OracleJavaProc 查询一下状态： 连接到: Oracle9i Enterprise Edition Release9.2.0.1.0- Production With the Partitioning, OLAPand Oracle Data Mining options JServer Release9.2.0.1.0- Production SQL>SELECT object_name, object_type, statusFROM user_objectsWHERE object_typeLIKE 'JAVA%'; OBJECT_NAME -------------------------------------------------------------------------------- OBJECT_TYPE                          STATUS ------------------------------------ -------------- OracleJavaProc JAVA CLASS                           VALID OracleJavaProc JAVA SOURCE                          VALID 测试一下存储过程： SQL>create or replaceprocedure add_salgrade(idnumber, losal number, hisal num ber)as language java name'OracleJavaProc.addSalGrade(int, int, int)';  2  / 过程已创建。 SQL>set serveroutputon size 2000 SQL> call dbms_java.set_output(2000); 调用完成。 SQL>execute add_salgrade(6,10000, 15000); Creating new salgradefor EMPLOYEE... PL/SQL 过程已成功完成。 SQL>select * from salgradewhere grade=6;      GRADE      LOSAL      HISAL ---------- ---------- ----------         6      10000     15000 二、如何更新你已经编写的java存储过程？  假如要往类OracleJavaProc里添加一个存储过程方法，如何开发？ 正确的步骤应该是先dropjava, 改程序，再loadjava。 e.g.修改OracleJavaProc类内容如下： import java.sql.*; import oracle.jdbc.*; publicclass OracleJavaProc...{   // Add a salgrade to the database.   public static void addSalGrade(int grade,int losal, int hisal) ...{       System.out.println(\"Creating new salgrade for EMPLOYEE...\");      try ...{          Connection conn=             DriverManager.getConnection(\"jdbc:default:connection:\");          String sql=            \"INSERT INTO salgrade\" +            \"(GRADE,LOSAL,HISAL)\" +            \"VALUES(?,?,?)\";          PreparedStatement pstmt= conn.prepareStatement(sql);          pstmt.setInt(1,grade);          pstmt.setInt(2,losal);          pstmt.setInt(3,hisal);          pstmt.executeUpdate();          pstmt.close();          }      catch(SQLException e)...{          System.err.println(\"ERROR! Adding Salgrade:\"           + e.getMessage());          }    }      publicstatic int getHiSal(int grade)   ...{    try ...{         Connection conn=           DriverManager.getConnection(\"jdbc:default:connection:\");         String sql= \"SELECT hisal FROM salgrade WHERE grade = ?\";         PreparedStatement pstmt= conn.prepareStatement(sql);pstmt.setInt(1, grade);         ResultSet rset= pstmt.executeQuery();        int res = 0;        if (rset.next())        ...{             res= rset.getInt(1);         }         rset.close();        return res;        }    catch (SQLException e)    ...{         System.err.println(\"ERROR! Querying Salgrade:\"           + e.getMessage());           return -1;     }       }       } 如何更新呢？ D:eclipse3.1workspacedbtest>dropjava -u scott -v OracleJavaProc D:/tiger@iihero.oracledbeclipse3.1workspacedbtest>loadjava -u scott -v -resolve Or acleJavaProc/tiger@iihero.oracledb.java arguments: '-u' 'scott/tiger@iihero.oracledb' '-v' '-resolve' 'OracleJavaProc.java' creating : source OracleJavaProc loading  : source OracleJavaProc resolving: source OracleJavaProc 后边的应用示例： SQL>create or replacefunction query_hisal(gradenumber) returnnumber as langu age java name 'OracleJavaProc.getHiSal(int) return int';   2  / 函数已创建。 SQL>set serveroutputon size 2000 SQL> call dbms_java.set_output(2000); 调用完成。 SQL> select query_hisal(5)from dual; QUERY_HISAL(5) --------------           9999 全文完！ 用法个人见解：不要手动drop java source, 不要手动drop procedure。","title":"（转）如何在Oracle中使用Java存储过程 (详解)"},{"content":"(转载地址:http://blog.csdn.net/vic_wang/article/details/1709364)   CAST With Collections Using Multiset With A VARRAY CAST(MULTISET(<select statement>) AS <data_type>) CREATE OR REPLACE TYPE cust_address_t OID '53A970B3F5024BEC8EFD4F84CAD5E09E' AS OBJECT ( street_address VARCHAR2(40), postal_code    VARCHAR2(10), city           VARCHAR2(30), state_province VARCHAR2(2), country_id     VARCHAR(2)); / CREATE OR REPLACE TYPE address_book_t AS TABLE OF cust_address_t; / CREATE TABLE cust_address ( custno         NUMBER(10), street_address VARCHAR2(40), postal_code    VARCHAR2(10), city           VARCHAR2(30), state_province VARCHAR2(2), country_id     VARCHAR2(2)); INSERT INTO cust_address VALUES (1,'123 Main St.','98040','Mercer Island','WA','US'); INSERT INTO cust_address VALUES (2,'1 Broadway','10202','New York','NY','US'); INSERT INTO cust_address VALUES (3,'2462 Edgar Crest','V6L 2C4','Vancouver','BC','CN'); COMMIT; CREATE TABLE cust_short ( custno NUMBER(10), name   VARCHAR2(30)); INSERT INTO cust_short VALUES (1,'Morgan'); INSERT INTO cust_short VALUES (2,'Cline'); INSERT INTO cust_short VALUES (3,'Scott'); SELECT s.custno, s.name, CAST(MULTISET(SELECT ca.street_address,     ca.postal_code,     ca.city,     ca.state_province,     ca.country_id   FROM cust_address ca   WHERE s.custno = ca.custno) AS address_book_t) FROM cust_short s;   Using Multiset With a PL/SQL Table CAST(MULTISET(<select statement>) AS <data_type>) CREATE OR REPLACE TYPE project_table_t AS TABLE OF VARCHAR2(25); / CREATE TABLE projects ( person_id    NUMBER(10), project_name VARCHAR2(20)); CREATE TABLE pers_short ( person_id NUMBER(10), last_name VARCHAR2(25)); INSERT INTO projects VALUES (1, 'Teach'); INSERT INTO projects VALUES (1, 'Code'); INSERT INTO projects VALUES (2, 'Code'); INSERT INTO pers_short VALUES (1, 'Morgan'); INSERT INTO pers_short VALUES (2, 'Cline'); INSERT INTO pers_short VALUES (3, 'Scott'); COMMIT; SELECT * FROM projects; SELECT * FROM pers_short; SELECT e.last_name,CAST(MULTISET(   SELECT p.project_name   FROM projects p   WHERE p.person_id = e.person_id   ORDER BY p.project_name) AS project_table_t) FROM pers_short e;   Using Multiset With A Multi-column Collection CAST(MULTISET(<select statement>) AS <data_type>) CREATE OR REPLACE TYPE uob_type AS OBJECT ( object_name VARCHAR2(128), object_type VARCHAR2(18)); / CREATE OR REPLACE TYPE t_uob_type AS TABLE OF uob_type; / set serveroutput on DECLARE x t_uob_type; BEGIN   SELECTCAST(MULTISET(     SELECT object_name, object_type     FROM user_objects     WHERE rownum <10) AS t_uob_type)   INTO x   FROM dual;   FOR i IN 1 .. x.COUNT   LOOP     dbms_output.put_line(x(i).object_name || ' - '     || x(i).object_type);   END LOOP; END; /   Converting a Varray Type Column Into A Nested Table CAST(<column_or_value> AS <data_type>) CREATE OR REPLACE TYPE district_t AS OBJECT ( region_no NUMBER(2), title VARCHAR2(35), cost NUMBER(7,2)); / CREATE TYPE DistList_t AS TABLE OF district_t; / CREATE TYPE DistrictList AS VARRAY(10) OF district_t; / CREATE TABLE region_tab ( reg_id NUMBER(2), reg_name VARCHAR2(15), district DistrictList); set describe depth all linenum on indent on desc region_tab SELECT * FROM region_tab; INSERT INTO region_tab VALUES(30, 'Northwest', DistrictList (District_t(1, 'Alaska', 3250), District_t(2, 'Washington', 12350), District_t(3, 'Oregon', 2750), District_t(4, 'Idaho', 1425))); INSERT INTO region_tab VALUES(40, 'Southwest', DistrictList (District_t(1, 'Arizona', 3250), District_t(2, 'California', 12350), District_t(3, 'Nevada', 2750), District_t(4, 'New Mexico', 1425))); SELECTCAST(s.district AS DistList_t) FROM region_tab s WHERE s.reg_id = 30;   CAST With Dates Date CAST(<column_or_value> AS <data_type>) SELECTCAST('01-JAN-2004' AS DATE) CDate FROM dual; Timestamp CAST(<column_or_value> AS <data_type>) SELECTCAST(SYSDATE AS TIMESTAMP WITH LOCAL TIME ZONE) DTWTZ FROM dual;   CAST With Numbers Number CAST(<column_or_value> AS <data_type>) SELECT 1 +CAST(3.14 * 0.152 AS NUMBER(10,7)) FLOATING FROM dual;   CAST With Strings Varchar2 CAST(<column_or_value> AS <data_type>) SELECT object_name FROM user_objects; SELECTCAST(object_name AS VARCHAR2(30)) OBJ_NAME FROM user_objects;   Related Topics Types VArrays   CAST With Collections Using Multiset With A VARRAY CAST(MULTISET(<select statement>) AS <data_type>) CREATE OR REPLACE TYPE cust_address_t OID '53A970B3F5024BEC8EFD4F84CAD5E09E' AS OBJECT ( street_address VARCHAR2(40), postal_code    VARCHAR2(10), city           VARCHAR2(30), state_province VARCHAR2(2), country_id     VARCHAR(2)); / CREATE OR REPLACE TYPE address_book_t AS TABLE OF cust_address_t; / CREATE TABLE cust_address ( custno         NUMBER(10), street_address VARCHAR2(40), postal_code    VARCHAR2(10), city           VARCHAR2(30), state_province VARCHAR2(2), country_id     VARCHAR2(2)); INSERT INTO cust_address VALUES (1,'123 Main St.','98040','Mercer Island','WA','US'); INSERT INTO cust_address VALUES (2,'1 Broadway','10202','New York','NY','US'); INSERT INTO cust_address VALUES (3,'2462 Edgar Crest','V6L 2C4','Vancouver','BC','CN'); COMMIT; CREATE TABLE cust_short ( custno NUMBER(10), name   VARCHAR2(30)); INSERT INTO cust_short VALUES (1,'Morgan'); INSERT INTO cust_short VALUES (2,'Cline'); INSERT INTO cust_short VALUES (3,'Scott'); SELECT s.custno, s.name, CAST(MULTISET(SELECT ca.street_address,     ca.postal_code,     ca.city,     ca.state_province,     ca.country_id   FROM cust_address ca   WHERE s.custno = ca.custno) AS address_book_t) FROM cust_short s;   Using Multiset With a PL/SQL Table CAST(MULTISET(<select statement>) AS <data_type>) CREATE OR REPLACE TYPE project_table_t AS TABLE OF VARCHAR2(25); / CREATE TABLE projects ( person_id    NUMBER(10), project_name VARCHAR2(20)); CREATE TABLE pers_short ( person_id NUMBER(10), last_name VARCHAR2(25)); INSERT INTO projects VALUES (1, 'Teach'); INSERT INTO projects VALUES (1, 'Code'); INSERT INTO projects VALUES (2, 'Code'); INSERT INTO pers_short VALUES (1, 'Morgan'); INSERT INTO pers_short VALUES (2, 'Cline'); INSERT INTO pers_short VALUES (3, 'Scott'); COMMIT; SELECT * FROM projects; SELECT * FROM pers_short; SELECT e.last_name,CAST(MULTISET(   SELECT p.project_name   FROM projects p   WHERE p.person_id = e.person_id   ORDER BY p.project_name) AS project_table_t) FROM pers_short e;   Using Multiset With A Multi-column Collection CAST(MULTISET(<select statement>) AS <data_type>) CREATE OR REPLACE TYPE uob_type AS OBJECT ( object_name VARCHAR2(128), object_type VARCHAR2(18)); / CREATE OR REPLACE TYPE t_uob_type AS TABLE OF uob_type; / set serveroutput on DECLARE x t_uob_type; BEGIN   SELECTCAST(MULTISET(     SELECT object_name, object_type     FROM user_objects     WHERE rownum <10) AS t_uob_type)   INTO x   FROM dual;   FOR i IN 1 .. x.COUNT   LOOP     dbms_output.put_line(x(i).object_name || ' - '     || x(i).object_type);   END LOOP; END; /   Converting a Varray Type Column Into A Nested Table CAST(<column_or_value> AS <data_type>) CREATE OR REPLACE TYPE district_t AS OBJECT ( region_no NUMBER(2), title VARCHAR2(35), cost NUMBER(7,2)); / CREATE TYPE DistList_t AS TABLE OF district_t; / CREATE TYPE DistrictList AS VARRAY(10) OF district_t; / CREATE TABLE region_tab ( reg_id NUMBER(2), reg_name VARCHAR2(15), district DistrictList); set describe depth all linenum on indent on desc region_tab SELECT * FROM region_tab; INSERT INTO region_tab VALUES(30, 'Northwest', DistrictList (District_t(1, 'Alaska', 3250), District_t(2, 'Washington', 12350), District_t(3, 'Oregon', 2750), District_t(4, 'Idaho', 1425))); INSERT INTO region_tab VALUES(40, 'Southwest', DistrictList (District_t(1, 'Arizona', 3250), District_t(2, 'California', 12350), District_t(3, 'Nevada', 2750), District_t(4, 'New Mexico', 1425))); SELECTCAST(s.district AS DistList_t) FROM region_tab s WHERE s.reg_id = 30;   CAST With Dates Date CAST(<column_or_value> AS <data_type>) SELECTCAST('01-JAN-2004' AS DATE) CDate FROM dual; Timestamp CAST(<column_or_value> AS <data_type>) SELECTCAST(SYSDATE AS TIMESTAMP WITH LOCAL TIME ZONE) DTWTZ FROM dual;   CAST With Numbers Number CAST(<column_or_value> AS <data_type>) SELECT 1 +CAST(3.14 * 0.152 AS NUMBER(10,7)) FLOATING FROM dual;   CAST With Strings Varchar2 CAST(<column_or_value> AS <data_type>) SELECT object_name FROM user_objects; SELECTCAST(object_name AS VARCHAR2(30)) OBJ_NAME FROM user_objects;   Related Topics Types VArrays","title":"（转）ORACLE中非常好用的类型转换函数CAST"},{"content":"(转载地址:http://blog.csdn.net/vic_wang/article/details/1733796)   利用Java存储过程简化数据库操作 作者：Kuassi Mensah 利用Java存储过程沟通SQL、XML、Java、J2EE和Web服务。 存储过程（stored procedure）允许将运行于数据库层中的持久性逻辑与运行于中间层中的商务逻辑有效地分离开来。这种分离可以降低整个应用程序的复杂性，并提供其重用性、安全性、性能和可伸缩性。 但是，妨碍存储过程广泛采用的一个主要障碍是不同数据库厂商使用各种专有的、且依赖于数据库的实现语言。使用基于Java的存储过程可以解决这一问题。Oracle已经实现了ANSI标准，这些标准规定了从SQL中将静态Java方法作为过程或函数进行调用的能力。这种实现被简单地称作\"Java存储过程\"。 在本文中，你将了解基于Java的存储过程如何帮助简化商务逻辑、提高其性能，并扩展数据库的功能。本文将介绍Oracle如何在数据库内启用基于Java的存储过程。还会介绍Java存储过程如何访问数据，以及如何创建基本Java存储过程。 选择PL/SQL还是Java 在考虑Oracle存储过程时，你可能会想到PL/SQL。不过，从Oracle8i开始，Oracle已经在数据库中支持Java，从而为存储过程提供了不同于PL/SQL的开放式和可移植的方法。我可以听到\"$64 000问题\"：\"我如何在PL/SQL和Java之间做出选择？我是否应当忘记已经学习的所有PL/SQL相关知识，而变为一个Java天地的新手？\" 两种语言都适用于数据库编程，都有自己的优点和弱点。在决定选择哪一种语言时，可以参考下面根据经验得出的通用规则： 对于要求与SQL进行无缝集成的数据库中心来说则逻辑使用PL/SQL，从而完成对数据库对象、类型和特性的访问。 出于与数据库的无关性考虑时，可以选择Java作为开放式的语言来取代PL/SQL，同时也为了集成和沟通SQL、XML、J2EE和Web服务等各个领域。 OralceJVM使得Java可以运行在数据库中 从Oracle8i版本1（Oralce8.1.5）开始，Oracle便提供紧密集成的Java虚拟机（JVM），JVM支持Oralce的数据库会话期结构。任何数据库对话期都可以在第一Java代码调用时启动一个虚拟上专用的JVM，后续的用户可以使用这一已经存在的支持Java的会话期。事实上，所有会话共享同一JVM代码并保持\"仅静态\"的私有状态，而垃圾则收集在单个对话期空间内，从而为各个Java对话期提供了和SQL操作相同的对话期隔离和数据完整性能力。这里，不需要为了数据完整性而进行单独的Java支持的过程。这一基于对话期的结构提供了较小的内存占用率，并使OracleJVM具有与Oracle数据库一样的线性SMP可伸缩性。 创建Java存储过程 要将Java方法转换为Java存储过程需要几个步骤，包括：用loadjava实用程序将Java类加载到数据库中，利用调用规范（Call Spec）发布Java方法，将Java方法、参数类型和返回类型映射到其SQL的对应部分。下面部分说明如何完成这些步骤。 我将使用一个简单的Hello类，它有一个方法Hello.world()，返回字符串\"Hello world\"： public class Hello { public static String world () { return \"Hello world\"; } } Loadjava 实用程序 Loadjava是加载Java源文件、Java类文件和Java资源文件的实用程序，它可以用来验证字节码，并将Java类和JAR文件布置到数据库中。它既可以通过命令行调用，也可以通过包含于DBMS_JAVA类中的loadjava()方法调用。为了加载我们的Hello.class示例，输入： loadjava -user scott/tiger Hello.class 从Oracle9i版本2开始，loadjava允许通过为包含在被处理的类中的方法创建相应的Call Specs来自动将Java类发布为存储过程。Oracle为开发、测试、调试和布置Java存储过程提供了Oracle9i JDeveloper。 The Resolver Spec 基于JDK的JVM在列于CLASSPATH中的目录中查找类引用，并对其进行解析。因为Oracle数据库类存在于数据库模式中，所以OracleJVM利用数据库解析器（resolver）通过列于Resolver Spec中的模式查找并解析类引用。与CLASSPATH不同（CLASSPATH可以应用于所有的类），Resover Spec根据每类的情况进行应用。缺省解析器首先在加载类的模式中搜寻类，然后在公共同义词（public synonyms）中搜索。 loadjava -resolve <myclass> 你可能需要指定不同的解析器，也可以在使用loadjava时强制进行解析，从而在布置时确定可能在以后运行时发生的任何问题。 loadjava -resolve -resolver \"((* SCOTT) (foo/bar/* OTHERS) (* PUBLIC))\" Call Spec和存储过程调用 为了从SQL中调用Java方法（以及从PL/SQl和JDBC中调用），必须首先通过Call Spec发布公共静态方法，它为SQL定义方法采用的参数以及返回的SQL类型。 在我们的例子中，我们将利用SQL＊Plus连接到数据库，并为Hello.world()定义一个顶级Call Spec： SQL> connect scott/tiger SQL> create or replace function helloworld return VARCHAR2 as language java name 'Hello.world () return java.lang.String'; / Function created. 可以像下面这样调用Java存储过程： SQL> variable myString varchar2[20]; SQL> call helloworld() into :myString; Call completed. SQL> print myString; MYSTRING --------------------- Hello world Java存储过程可以通过其Call Spec从以下各项中进行调用：SQL DML语句（INSERT, UPDATE、DELETE、SELECT、CALL、EXPLAIN PLAN、LOCK TABLE和MERGE）、PL/SQL块、子程序、程序包以及数据库触发器。Call Spec的美妙之处在于存储过程实现可以从PL/SQL转换为Java，反之亦可，这一点对于请求者是透明的。 Call Spec从实现语言中（PL/SQL或Java）中抽象出调用界面，因而使之能够在原有应用程序和新的基于Java／J2EE的应用程序之间共享商务逻辑。但是，在从Java客户程序调用在数据库驻留的Java类时，你可能不希望通过PL/SQL包装器(wrapper)。在以后的版本中，Oracle计划提供一种机制，它可以使开发人员略过Call Spec。 高级数据访问控制 Java存储过程可用于控制和限制对Oracle数据的访问，其方法是只允许用户通过存储过程管理数据，而存储过程在其调用者的权限内执行，而不能对表本身进行访问。例如，你可以在特定时间内禁止更新数据，或者使管理者只具有查询工资数据的权利，而不能进行更新，或者记录所有的访问并通知某一安全机构。 原有应用程序与J2EE应用程序之间的数据逻辑共享 因为原有应用程序与J2EE应用程序都通过Call Spec调用存储过程，所以J2EE和非J2EE应用程序可以共享相同的数据逻辑。由于有了Call Spec，所以不用考虑所用的是何种实现语言（无论是PL/SQL还是Java），该数据逻辑都可以共享。 为BMP实体Bean自动生成主关键字 在对EJB实体bean应用BMP时，一个bean实例可以由自动生成的与新插入的数据相关联的主关键字惟一确定，它是ejbCreate()的返回值。可以利用一个插入相应数据的存储过程在一个数据库操作中检索ejbCeater()中的该值，并检索或计算主关键字。作为另一种方法，也可以利用JDBC3.0的RETURN_GENERATED_KEYS特性，以一个SQL语句插入该数据并检索相应的关键字（或ROWID）。但是，存储过程方法在各个JDBC驱动器版本和数据库之间更具可移植性。 可以用以下三个步骤实现这一模式： 创建一个Java存储过程，在公共GenPk类中定义一个公共静态Java方法insertAccount()。此方法将插入数据、计算惟一的关键字（通过发出一个序列号），并返回计算出的关键字作为主关键字。 定义Call Spec CREATE OR REPLACE PROCEDURE insertAccount(owner IN varchar, bal IN number, newid OUT number) AS LANGUAGE JAVA NAME 'GenPK.insertAccount( java.lang.String [])'; / 在ejbCreate()内调用存储过程 Public AccountPK ejbCreate(String ownerName, int balance) throws CreateException { try { CallableStatement call = conn.prepareCall{ \"{call insertAccount(?, ?, ?)}\"}; return new AccountPK(accountID); } } 为CMP实体Bean定制主关键字查找器 查找器方法（Finder methods）用于检索已存在的EJB实体bean实例。主关键字查找器使你能够检索惟一标识的EJB实例。对于CMP实体bean，EJB容器根据声明描述，自动生成主关键字查找器findByPrimaryKey()方法。但是，在某些情况下，可能需要更多的控制，例如可能需要专门的查找器，如findByStoredProcKey()。在这些情况下，你可以结合使用Java存储过程和对象关系框架（如Oracle9i应用服务器[Oracle9iAS] TopLink）来实现定制的主关键字查找器方法。在将EJB查找器定义为REDIRECT或NAMED查找器后，TopLink将生成一个SQL查询用于检索bean实例。 数据驱动的EJB调用 在数据驱动体系结构中，商务逻辑调用可以作为数据库操作（如插入、更新或删除）的结果来触发。实现该数据逻辑的Java存储过程可以被声明为数据库触发器，用以调用运行于中间层J2EE应用服务器的EJB。EJB的调用既可以采用J2EE1.3兼容的服务器通过Interoperable Inter-ORB Protocol（IIOP）标准远程方法调用（remote method invocation，RMI）实现，也可以通过销售商特定的传输协议（如Oracle9iAS/Oc4J的ORMI，或者通过BEA WebLogic的T3）用RMI来实现。每个应用服务器提供商在提供基于IIOP的RMI，以提供互操作性的同时，都有其自己优化的协议。Oracle9iAS同时支持基于IIOP的RMI调用和基于ORMI协议的RMI调用。 数据驱动的消息传送 Oracle9i数据库嵌入了Advanced Queuing（AQ，高级排队），它是一种集成的、稳定、可靠、安全、可扩展和事务处理式的消息排队框架。Oracle通过标准的Java消息传送系统（Java Messaging System，JMS）API为Java开发人员提供AQ功能。Java存储过程可以通过JMS接口调用AQ操作，从而能够实现快速、在会话期内、可扩展的、数据驱动的消息传送。 Java存储过程可以利用JMS调用AQ操作。可以用以下4个步骤实现这一模式： 创建并启动JMS Queue（为此，可以将以下一些操作嵌入SQL脚本内）： execute dbms_aqadm.create_queue_table(queue_table => 'queue1', queue_payload_type => 'SYS.AQ$_JMS_TEXT_MESSAGE', comment => 'a test queue', multiple_consumers => false, compatible => '8.1.0'); execute dbms_aqadm.create_queue( queue_name => 'queue1', queue_table => 'queue1' ); execute dbms_aqadm.start_queue(queue_name => 'queue1'); 创建Java存储过程（代码摘录如下）： public static void runTest(String msgBody) { try { // get database connection ora_drv = new OracleDriver(); db_conn = ora_drv.defaultConnection(); // setup sender (cf online code sample) .. // create message s_msg = s_session.createTextMessage(msgBody); // send message sender.send(s_msg); s_session.commit(); // receive message r_msg = (TextMessage) receiver.receive(); r_session.commit(); // output message text String body = r_msg.getText(); System.out.println(\"message was '\"+body+\"'\"); ..} } 创建Call Spec： create or replace procedure jmsproc (t1 IN VARCHAR) as language java name 'jmsSample.main (java.lang.String[])'; / 调用存储过程： call jmsproc('hello'); 数据库辅助的Web发布（缓冲失效） 各应用程序结构必须面对的一个共同问题是如果可靠地将数据库信息进行缓存，以提高整个系统的性能。JCACHE是一种即将公布的标准规范（JSR 107），它可以解决这一问题。它说明了一种对Java对象临时在内存中进行缓存的方法，包括对象的创建、共享访问、假脱机（spooling）、失效、各JVM的一致性等。它可被用于缓存JSP内最经常读取的数据，如产品目录和价格列表。利用JCACHE，多数查询的反应时间会因为有缓存的数据而加快（内部测试表明反应时间大约快15倍）。 为了跟踪原始数据的所有变化，并刷新已缓存的数据，Java存储过程会作为一个触发器被附加在一个表上。这个表的任何变化都会自动调用该存储过程，后者再调出一个已定义的JSP使JCACHE对象失效，该对象将其状态映射到该数据库表。在失效时，紧跟其后的查询将强制缓存器根据数据库的数据进行更新。 下面的步骤 阅读关于Java存储过程的更多信息 本文摘自白皮书\"释放Java存储过程的能量（Unleash the Power of Java Stored Procedures）\"，可以在以下位置找到该白皮书： otn.oracle.com/tech/java/java_db/pdf/ OW_30820_JAVA_STORED_PROC_paper.PDF Oracle9i数据库第2版中的新PL/SQL特性 otn.oracle.com/tech/pl_sql/pdf/ Paper_30720_Doc.pdf Resolver Spec otn.oracle.com/docs/products/oracle9i/ doc_library/release2/java.920/a96659.pdf OracleJVM and Java 2 Security otn.oracle.com/docs/products/oracle9i/ doc_library/release2/java.920/a96656.pdf 下载代码 练习本文中的代码示例： otn.oracle.com/sample_code/tech/ java/jsp/Oracle9iJSPSamples.html 了解作为Web服务的存储过程 otn.oracle.com/tech/webservices 扩展数据库的功能 在数据库中直接运行Java代码的一个妙处就在于要实现新的功能，只需要简单地加载代码或库，并利用Call Spec制作可用于SQL、PL/SQL、Java、J2EE和非Java API的进入点（公共静态方法）。Oracle9i数据库用户可以很容易地扩展数据库功能。Oracle自己利用这种能力来获得新的应用程序和工具包，如XML Developer Kits（XDKs）。 沟通SQL、PL/SQL、Java、J2EE、.NET和XML Oracle XDK是用Java编写的，并将其公共方法可用作Java存储过程，从而扩展了数据库的XML可编程能力。SQL、PL/SQL、Java、J2EE和非Java（.NET）商务逻辑都能够访问XML分析器、XSLT处理器、XPath引擎和XML SQL Utility（XSU）。 XML分析器可以通过xmlparser和xmldom包进行访问。XSU是一种Java实用程序，它可以由SQL查询结果或JDBC ResultSet生成XML文档，并将XML文档中的数据写入数据库表或视图中。利用XSU，XML输出可以输出为文本、Dom树或DTS。通过dbms_xmlquery和dbms_xmlsave包，XSU即可用于PL/SQL。 结论 Oracle数据库与Java VM的集成可以创建可移植、功能强大和与数据库无关的数据逻辑和持续性逻辑（persistence logic）。运行于中间层的商务逻辑和运行于数据库层的数据逻辑之间的分离提高了应用程序的可扩展性、灵活性和可维护性。    ","title":"（转）JAVA存储过程"},{"content":"       Java Stored Procedures（简称JSP，此JSP非彼JSP，哈哈哈），即JAVA存储过程，是通过Oracle数据库中的DML、package等调用JAVA程序，从而实现Oracle数据库与JAVA集成。由于工作需要，要通过Oracle数据库调用JAVA程序，与ActiveMQ集成实现消息发送，网上大多数例子都是通过Oracle数据库调用java程序实现最基本的Hello程序，更深入的研究也比较少。经过长时间的纠结，最终实现了消息发送，现总结如下，供需要的童鞋们参考。本文基于Oracle Database11g Release2。 1、主要参考资料 最基本参考资料就是Oracle官方文档：Oracle Database Java Developer's Guide 其他的就百度吧。   2、开发步骤 （1）编写JAVA程序 跟平常JAVA开发一样，该怎么编写就怎么编写，但要注意，通过数据库调用的方法必须为static的，下面为发送消息的JAVA代码框架： package com.test;/** *  * */public class JspSendMsg {\t\tpublic static String sendMsg(String str){\t\t//发送消息成功标志\t\tString b = \"Y\"; \t\tSystem.out.println(\"发送消息开始。。。。\");\t\ttry {\t\t\t//实现消息发送，此处略\t\t\t//......\t\t\t\t\t\tSystem.out.println(\"发送消息成功！\");\t\t} catch (Exception e) {\t\t\t// TODO: handle exception\t\t\tSystem.out.println(\"发送消息失败！\");\t\t\tb = \"N\";\t\t\te.printStackTrace();\t\t}\t\treturn b;\t}\t} （2）加载JAVA类到数据库中 有两种方式： a、通过pl/sql新建Java source，把第（1）步中java代码直接copy进来，编译即可； create or replace and compile java source named JspSendMsg aspackage com.test;/** *  * */public class JspSendMsg {    public static String sendMsg(String str){    //发送消息成功标志    String b = \"Y\";     System.out.println(\"发送消息开始。。。。\");    try {      //实现消息发送，此处略      //......            System.out.println(\"发送消息成功！\");    } catch (Exception e) {      // TODO: handle exception      System.out.println(\"发送消息失败！\");  \t\tb = \"N\";\t\t\te.printStackTrace();\t\t}\t\treturn b;\t}\t}   b、利用loadjava工具 loadjava工具是oracle数据库提供的一个命令行工具，它可加载java源文件、java class类、jar包、资源文件到数据库中，根据需要自行选择。 --加载java源文件 loadjava -u scott/scott@orcl -v -r g:\\com\\test\\JspSendMsg.java 其中，   u---参数表示连接数据库的用户   v---加载时输出详细日志   r---加载时利用oracle jvm进行解析，生成class文件   --加载java class文件 loadjava -u scott/scott@orcl -v g:\\com\\test\\JspSendMsg.class 注意，加载已编译的class文件时需注意编译java类的JDK版本与Oracle jvm版本必须一致，否则可能会出问题，11g对应的JDK为1.5，10g为1.4。 （3）发布java类 发布java需在数据库中进行，通过package调用JspSendMsg类，发布如下： package头：   function sendMsg(msg varchar2) return VARCHAR2; package体：   function sendMsg(msg varchar2) return VARCHAR2 as   LANGUAGE JAVA NAME 'com.test.JspSendMsg.sendMsg(java.lang.String) return java.lang.String';      至此，编码部分基本完毕，在测试前还有些事情需要做。 （4）加载jar包 由于是实现消息发送，需要把activemq-all-5.2.0.jar加载进数据中。通过loadjava工具加载jar包时，由于待加载jar包可能依赖其他第三方jar包，需提供-genmissing参数，否则有些class文件无法编译。如有多个jar包，可一起加载。loadjava加载jar包时会解压jar文件，把jar中每个class进行分别加载。 命令形式： loadjava -u scott/scott@orcl -genmissing -r -v -f -fileout active.txt activemq-all-5.2.0.jar 其中，   genmissing---表示如果该jar包里依赖其他jar包，而其他jar包数据库中并不存在，此时数据库会忽略，并产生该class文件，具体可参见loadjava工具说明。   f---强制加载   fileout---输出日志到文件active.txt中   （5）加载资源文件ia.properties 为编译维护，把消息服务器IP地址、端口、消息队列名称配置在配置文件中，需加载到数据库中，用户java程序解析该配置文件。 命令形式： loadjava -user scott/scott@orcl -v ia.properties 注意，ia.properties前不能加其他路径，需在当前路径下执行，否则java程序找不到该配置文件。 （6）授权 通过Oracle数据库调用java程序时，需要进行授权，授权时需要DBA权限用户。本文主要用到以下两种： --使用java类加载器时需进行此授权，本例中需要读取配置文件，因此需要此授权 call dbms_java.grant_permission( 'scott', 'SYS:java.lang.RuntimePermission', 'getClassLoader', '') --访问网络时需要进行此授权 call dbms_java.grant_permission( 'scott', 'SYS:java.net.SocketPermission', '消息服务器IP地址:消息port', 'connect,resolve') （7）至此，可以进行消息发送测试了。本例实现了简单的消息发送。 3、设置重定向 通过Oracle数据库调用java程序，不太好查看java程序里的输出信息，pl/sql提供了设置重定向功能，可将java程序里System.out等输出信息进行重定向，在pl/sql命令行窗口执行： SET SERVEROUTPUT ON;  CALL dbms_java.set_output(2000); 然后调用程序时即可看到输出信息到命令行窗口。 4、最后提供一些有用的脚本。 --删除单个class dropjava -user scott/scott@orcl -r -v -f com/test/JspSendMsg   --执行loadjava后查询一下状态 SELECT uo.created ,uo.object_name, uo.object_type, dbms_java.longname(uo.object_name),uo.status,uo.*   FROM user_objects uo WHERE 1=1   --and object_type like 'JAVA%'   order by uo.created desc;   --生成批量删除java类命令 select 'dropjava -u scott/scott@orcl -r -v -f '||dbms_java.longname(uo.object_name) FROM user_objects uo WHERE object_type='JAVA CLASS';   --java数据库对象原名称与别名对应关系 select * from javasnm js;   --编译java源文件错误信息视图 select * from USER_ERRORS ue where ue.type like 'JAVA%';   --数据库中policy视图，用户查看当前用户被授予的权限 select * from USER_JAVA_POLICY; --权限操作 --授权 见本文前面 --删除权限：需先收回再删除 call dbms_java.revoke_permission('scott', 'SYS:java.lang.RuntimePermission', 'getClassLoader', '*'); call dbms_java.delete_permission(key => 153); --153对应表user_java_policy.KIND列值    ","title":"[置顶] java存储过程开发总结"},{"content":"Title:ShowRsUseBean discription:1、将数据库的相关东西封装在一个类中，在用到的时候可以调用。    2、在封装时，可以运用重载。 @Copyright: @Company: @autor:firefly @version:1.0 @time:2013.1.1   import javax.servlet.*; import javax.servlet.http.*; import java.io.*; import java.sql.*; public class ShowRsUseBean extends HttpServlet {  @Override  protected void doGet(HttpServletRequest request,    HttpServletResponse response) throws ServletException, IOException {   response.setContentType(\"text/html\");   response.setCharacterEncoding(\"gb2312\");   PrintWriter out = response.getWriter();   out.println(\"<table border=1>\");   out.println(\"<tr><td>Content:<\/td><\/tr>\");   Connection conn = DB.getConn();   Statement stmt = DB.getStatement(conn);   String sql = \"select * from article\";   ResultSet rs = DB.getResultSet(stmt, sql);   try {    while (rs.next()) {     out.println(\"<tr>\");     out.println(\"<td>\" + rs.getString(\"title\") + \"<\/td>\");     out.println(\"<\/tr>\");    }    out.println(\"<\/table>\");   } catch (SQLException e) {    e.printStackTrace();   } finally {    DB.closeRs(rs);    DB.closeStmt(stmt);    DB.closeConn(conn);   }  } }  ","title":"ShowRsUseBean(42_2)"},{"content":"Title:DB discription:1、将数据库的相关东西封装在一个类中，在用到的时候可以调用。    2、在封装时，可以运用重载。 @Copyright: @Company: @autor:firefly @version:1.0 @time:2013.1.1   import java.sql.*; public class DB {  public static Connection getConn() {   Connection conn = null;   try {    Class.forName(\"com.mysql.jdbc.Driver\");    conn = DriverManager.getConnection(\"jdbc:mysql://localhost/test?user=root&password=root\");   } catch (ClassNotFoundException e) {    e.printStackTrace();   } catch (SQLException e) {    e.printStackTrace();   }      return conn;  }    public static Statement getStatement(Connection conn) {   Statement stmt = null;   try {    if(conn != null) {     stmt = conn.createStatement();    }   } catch (SQLException e) {    e.printStackTrace();   }   return stmt;  }    public static ResultSet getResultSet(Statement stmt, String sql) {   ResultSet rs = null;   try {    if(stmt != null) {     rs = stmt.executeQuery(sql);    }   } catch (SQLException e) {    e.printStackTrace();   }   return rs;  }    public static void closeConn(Connection conn) {   try {    if(conn != null) {     conn.close();     conn = null;    }   } catch (SQLException e) {    e.printStackTrace();   }  }    public static void closeStmt(Statement stmt) {   try {    if(stmt != null) {     stmt.close();     stmt = null;    }   } catch (SQLException e) {    e.printStackTrace();   }  }    public static void closeRs(ResultSet rs) {   try {    if(rs != null) {     rs.close();     rs = null;    }   } catch (SQLException e) {    e.printStackTrace();   }  } }  ","title":"DB(42_1)"}]